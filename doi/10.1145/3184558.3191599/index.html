<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>A Discovery and Analysis Engine for Semantic
  Web⁎⁎http://spend.semihyumusak.com.tr,
  https://github.com/semihyumusak/SpEnD</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">A Discovery and Analysis Engine
          for Semantic Web<a class="fn" href="#fn1" id=
          "foot-fn1"><sup>*</sup></a></span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <a href="https://orcid.org/0000-0002-8878-4991" ref=
          "author"><span class="givenName">Semih</span>
          <span class="surName">Yumusak</span></a><a class="fn"
          href="#fn3" id="foot-fn3"><sup>†</sup></a>, KTO Karatay
          University, Turkey, <a href=
          "mailto:semih.yumusak@karatay.edu.tr">semih.yumusak@karatay.edu.tr</a>,
          AI4BD GmbH, Switzerland, <a href=
          "mailto:s.yumusak@ai4bd.com">s.yumusak@ai4bd.com</a>
        </div>
        <div class="author">
          <span class="givenName">Andreas</span> <span class=
          "surName">Kamilaris</span>, Department of Computer
          Science, University of Twente The Netherlands, <a href=
          "mailto:a.kamilaris@utwente.nl">a.kamilaris@utwente.nl</a>
        </div>
        <div class="author">
          <span class="givenName">Erdogan</span> <span class=
          "surName">Dogdu</span>, Cankaya University, Ankara,
          Turkey, <a href=
          "mailto:edogdu@cankaya.edu.tr">edogdu@cankaya.edu.tr</a>
        </div>
        <div class="author">
          <span class="givenName">Halife</span> <span class=
          "surName">Kodaz</span>, Selcuk University, Konya, Turkey,
          <a href=
          "mailto:hkodaz@selcuk.edu.tr">hkodaz@selcuk.edu.tr</a>
        </div>
        <div class="author">
          <span class="givenName">Elif</span> <span class=
          "surName">Uysal</span>, KTO Karatay University, Konya,
          Turkey, <a href=
          "mailto:elif.uysal@ogrenci.karatay.edu.tr">elif.uysal@ogrenci.karatay.edu.tr</a>
        </div>
        <div class="author">
          <span class="givenName">Riza Emre</span> <span class=
          "surName">Aras</span>, KTO Karatay University, Konya,
          Turkey, <a href=
          "mailto:riza.emre.aras@ogrenci.karatay.edu.tr">riza.emre.aras@ogrenci.karatay.edu.tr</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191599"
        target=
        "_blank">https://doi.org/10.1145/3184558.3191599</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>The Semantic Web promotes common data formats and
        exchange protocols on the web towards better
        interoperability among systems and machines. Although
        Semantic Web technologies are being used to semantically
        annotate data and resources for easier reuse, the ad hoc
        discovery of these data sources remains an open issue.
        Popular Semantic Web endpoint repositories such as
        SPARQLES, Linking Open Data Project (LOD Cloud), and
        LODStats do not include recently published datasets and are
        not updated frequently by the publishers. Hence, there is a
        need for a web-based dynamic search engine that discovers
        these endpoints and datasets at frequent intervals. To
        address this need, a novel web meta-crawling method is
        proposed for discovering Linked Data sources on the Web. We
        implemented the method in a prototype system named SPARQL
        Endpoints Discovery (SpEnD). In this paper, we describe the
        design and implementation of SpEnD, together with an
        analysis and evaluation of its operation, in comparison to
        the aforementioned static endpoint repositories in terms of
        time performance, availability, and size. Findings indicate
        that SpEnD outperforms existing Linked Data resource
        discovery methods.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS
        Concepts:</span> • <strong>Information systems</strong> →
        <strong>Web searching and information
        discovery;</strong></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Linked Data</small>,</span>
          <span class="keyword"><small>Semantic Web</small>,</span>
          <span class="keyword"><small>SPARQL
          Endpoints</small>,</span> <span class=
          "keyword"><small>Discovery</small>,</span> <span class=
          "keyword"><small>Search Engine</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Semih Yumusak, Andreas Kamilaris, Erdogan Dogdu, Halife
          Kodaz, Elif Uysal, and Riza Emre Aras. 2018. A Discovery
          and Analysis Engine for Semantic Web. In <em>WWW '18
          Companion: The 2018 Web Conference Companion,</em>
          <em>April 23–27, 2018,</em> <em>Lyon, France</em>. ACM,
          New York, NY, USA, 9 Pages. <a href=
          "https://doi.org/10.1145/3184558.3191599" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3191599</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Semantic Web standards and technologies<a class="fn" href=
      "#fn4" id="foot-fn4"><sup>1</sup></a> are becoming more and
      more popular on the web, promoting common data formats and
      protocols for better interoperability among systems and
      machines, and seamless data integration. Linked Data is a
      term referring to large structured data sources that conform
      to Semantic Web standards, specifically the <em>Resource
      Description Framework</em> (RDF) <a class="fn" href="#fn5"
      id="foot-fn5"><sup>2</sup></a> data model. [inline]Revised
      based on Reviewer B comment: I could not find the definition
      of ”Linked Data endpoints”. Are they SPARQL endpoints? A
      subset/superset of SPARQL endpoints?Linked Data sources are
      published and served on the web through Linked Data endpoints
      (specifically named as SPARQL endpoints), which allows the
      Linked Data sources to be queried by using the SPARQL query
      language. Linked Data sources or endpoints are used in an
      increasing number of web applications to semantically
      annotate data [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0012">12</a>], in order to enhance search results
      and facilitate information retrieval and knowledge
      extraction. Recent statistics<a class="fn" href="#fn6" id=
      "foot-fn6"><sup>3</sup></a> refer to more than one thousand
      datasets and billions of triples in the LOD Cloud [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0012">12</a>]. The
      quality of a Linked Data source is highly dependent on its
      availability and the content of the data it contains, and it
      is being tracked by a number of projects [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0039">39</a>]. A common problem is that
      Linked Data sources are not always available, often not
      responding due to request overload or maintenance. Moreover,
      some of them stop being maintained and disappear after a few
      months. Hence, it is critical to monitor, discover, report,
      and verify Linked Data sources’ availability in frequent
      intervals (e.g. hours, days), in order to allow use of these
      endpoints online by web clients and web-connected machines.
      It is also critical to deliver information about the quality,
      correctness, integrity, and conformance of these datasets
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0023">23</a>], in
      frequent intervals. To the best of our knowledge, there exist
      four major Linked Data static repositories that regularly
      keep track of Linked Data resources on the web. These are the
      Linking Open Data Community project (LOD Cloud) [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0012">12</a>], SPARQL
      Endpoint Status (SPARQLES) [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0039">39</a>], LODStats [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0015">15</a>] and DataHub<a class="fn"
      href="#fn7" id="foot-fn7"><sup>4</sup></a>. These projects
      list available Linked Data endpoints, analyzing their quality
      and connectivity. Additionally, the LOD Cloud presents an
      image of all Linked Data endpoints discovered, representing
      data sources with circles and the references between them as
      links. The SPARQLES project focuses on monitoring the
      accessibility of SPARQL endpoints. Similarly, LODStats
      focuses on statistical monitoring of these data sources.
      Eventually, Datahub is used as a data sharing platform for
      all other three static repositories which are explained more
      in detail in Section <a class="sec" href="#sec-10">2.1</a>.
      Although the aforementioned repositories contain hundreds of
      Linked Data endpoints, they cannot discover new online
      endpoints fast enough nor keep track of offline endpoints
      efficiently, relying on the publishers to update the
      information related to the data sources (see Section
      <a class="sec" href="#sec-9">2</a>). More importantly, around
      half of the data sources currently listed by these projects
      are offline (see Section <a class="sec" href=
      "#sec-20">5</a>). Aiming to address this need for a web-based
      dynamic search engine that discovers Linked Data endpoints in
      frequent intervals (e.g. hours, days), we propose SPARQL
      Endpoints Discovery (SpEnD), a novel web crawling approach
      for discovering, analyzing, and publishing Linked Data
      sources on the Web.</p>
      <p>SpEnD is able to serve the most up-to-date list of Linked
      Data sources and their metadata. Thus, the main contribution
      of this paper is a new dynamic discovery and analysis method
      for Linked Data endpoints, which outperforms all other
      existing approaches for discovery of data sources on the
      Semantic Web, in terms of availability, and size of Linked
      Data endpoints discovered (See Section <a class="sec" href=
      "#sec-20">5</a>). The rest of the paper is organized as
      follows: Section <a class="sec" href="#sec-9">2</a> presents
      related work in Linked Data and crawling-related studies.
      Section <a class="sec" href="#sec-13">3</a> describes our
      general methodology for discovering Linked Data endpoints.
      Then, Section <a class="sec" href="#sec-14">4</a> presents
      the implementation of the SpEnD system while Section
      <a class="sec" href="#sec-20">5</a> evaluates SpEnD by
      comparing its performance in relation to the other four
      Linked Data repositories. Finally, Section <a class="sec"
      href="#sec-23">6</a> concludes the paper by pointing out
      future work.</p>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related
          Work</h2>
        </div>
      </header>
      <p>Related work spans two categories: (1) Linked Data,
      metadata and collections, and (2) web crawling and
      meta-crawling. The former category deals with the evolution
      of Linked Data, while the latter presents various
      crawling-based studies which relate to the Semantic Web.</p>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Linked
            Data</h3>
          </div>
        </header>
        <p>The work in [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0006">6</a>] explains Linked Data as a way to
        interconnect data sources on the web, so that data becomes
        machine-readable, semantically annotated, and linked to
        other data sources. Guides for Linked Data publishing
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0006">6</a>] recommend
        that data is named or identified using URIs, just like
        other web content, and linked to each other using the RDF
        model. Hence, Linked Data sources are either published as
        RDF documents or SPARQL endpoints on the web [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0006">6</a>]. If some
        Linked Data sources are published on the web by following
        the linked data publishing principles (Availability,
        Machine-Readability, Open Format, URI identification, and
        Linked Data)<a class="fn" href="#fn8" id=
        "foot-fn8"><sup>5</sup></a> , then it is called Linked Open
        Data (LOD). An LOD source is qualified to be included in
        the LOD Cloud project if it meets certain criteria
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0012">12</a>]. The LOD
        Cloud currently consists of more than 1,000 datasets. The
        most connected source is the DBpedia<a class="fn" href=
        "#fn9" id="foot-fn9"><sup>6</sup></a> dataset, derived from
        Wikipedia. As mentioned in the introduction, there are four
        major Linked Data collections available in the field. These
        are the LOD Cloud [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0012">12</a>], SPARQLES [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0039">39</a>], LODStats [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0002">2</a>], and
        Datahub. The SPARQLES project utilizes the VoID vocabulary
        to define Linked Data sources, monitoring datasets
        according to their availability, performance,
        interoperability and discoverability [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0008">8</a>]. In relation to the
        SPARQLES project, the Dynamic Linked Data Observatory
        Project [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0026">26</a>] makes weekly crawls of Linked Data
        sources, which are then published on the project's
        website<a class="fn" href="#fn10" id=
        "foot-fn10"><sup>7</sup></a>. LODStats currently has 9,960
        datasets indexed on its website<a class="fn" href="#fn11"
        id="foot-fn11"><sup>8</sup></a>. The project reports
        statistical information about every individual dataset in
        the VoID vocabulary while the summarized statistical
        information is reported using the RDF Datacube
        vocabulary<a class="fn" href="#fn12" id=
        "foot-fn12"><sup>9</sup></a>. Finally, Datahub<a class="fn"
        href="#fn13" id="foot-fn13"><sup>10</sup></a> is a Linked
        Data sharing website, which is used by SPARQLES, LOD Cloud
        and LODStats projects to share and store metadata about
        linked datasets. Although Datahub intends to keep track of
        all Linked Data datasets available on the web, a large
        number of datasets are not listed (see Section <a class=
        "sec" href="#sec-20">5</a>). Table <a class="tbl" href=
        "#tab1">1</a> compares the aforementioned repositories in
        terms of data collection method, resources used,
        definitions employed, metadata formats used and number of
        endpoints listed.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Current Linked Metadata
            Collections.</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:center;">
                <strong>Definition</strong></td>
                <td style="text-align:center;">
                <strong>Format</strong></td>
                <td style="text-align:center;"><strong># of
                Endpoints</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;"><strong>LOD
                Cloud</strong></td>
                <td style="text-align:center;">VoID</td>
                <td style="text-align:center;">Turtle[1]</td>
                <td style="text-align:center;">149</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                <strong>SPARQLES</strong></td>
                <td style="text-align:center;">VoID, Datacube</td>
                <td style="text-align:center;">JSON</td>
                <td style="text-align:center;">496</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                <strong>LODStats</strong></td>
                <td style="text-align:center;">web</td>
                <td style="text-align:center;">HTML</td>
                <td style="text-align:center;">335</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                <strong>Datahub</strong></td>
                <td style="text-align:center;">CKAN API</td>
                <td style="text-align:center;">CKAN API</td>
                <td style="text-align:center;">527</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>As the LOD cloud gets larger, the need for Linked Data
        consumption tools increases as well. In order to browse and
        query Linked Data sources, many browsers have been
        developed, such as the Tabulator [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0004">4</a>], Openlink Data
        Explorer<a class="fn" href="#fn14" id=
        "foot-fn14"><sup>11</sup></a> and Sig.ma [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0036">36</a>], as well as search
        engines such as Swoogle [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0017">17</a>], Falcons [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0010">10</a>], Sindice [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0037">37</a>] and SWSE
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0020">20</a>]. In
        order to improve data availability and re-usability, a
        common need for all these consumer applications is a
        metadata reference for Linked Data sources. Meta-analysis
        in this domain is about standardizing retrieval and
        interpretation of Linked Data sources’ description
        information. In order to provide domain-independent
        metadata definition, the VoID vocabulary [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0001">1</a>] was created for
        describing metadata about RDF datasets, such as SPARQL
        endpoint URLs and various statistics (e.g. number of
        triples, entities, classes and properties).</p>
      </section>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Web
            Crawling and Meta-crawling</h3>
          </div>
        </header>
        <p>The rapid growth of the web increased the need for
        content-based search and information retrieval, and this
        was facilitated by the use of web crawlers [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0007">7</a>], defined also as
        spiders, nomads, worms, wanderers, and robots [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0028">28</a>]. Early
        crawlers were differentiated by their storage, indexing
        (cataloging), search, and crawling methods. Most of them
        had performance limitations due to connection problems. As
        a solution for the performance issues in web crawling,
        multi-threaded and distributed crawling has emerged
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0022">22</a>], while
        many different multi-threaded (e.g. Crawler4j<a class="fn"
        href="#fn15" id="foot-fn15"><sup>12</sup></a>, Websphinx
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0030">30</a>]), and
        distributed (e.g. Nutch<a class="fn" href="#fn16" id=
        "foot-fn16"><sup>13</sup></a>, UbiCrawler [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0007">7</a>]) web crawlers have been
        developed. In today's massive web, even these
        multi-threaded and distributed crawlers fell short of
        retrieving adequate information in limited time with
        limited resources. Therefore, some crawlers focused
        crawling only in a limited scope or domain [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0034">34</a>]. The announcement of
        the Semantic Web [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0005">5</a>] in 2001 had an impact on web
        crawlers too. In the Semantic Web domain, classical web
        crawling and indexing techniques are incapable of
        collecting semantically annotated data. Thus, in order to
        create appropriate crawling and indexing methodologies for
        Linked Data, new retrieval techniques were developed, such
        as BioCrawler [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0003">3</a>] and MultiCrawler [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0021">21</a>]. Also, OntoCrawler
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0042">42</a>] used
        ontology-based website modeling for crawling and
        classifying classical web documents. Slug [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0014">14</a>] was designed to crawl
        both the classical and the Semantic Web, for the retrieval
        of relevant documents. On the client side, many search
        engines were developed, such as Semplore [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0040">40</a>], SemSearch [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0029">29</a>], Sindice
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0009">9</a>], SWSE
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0020">20</a>], Falcons
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0011">11</a>], and
        Watson [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0013">13</a>], for searching and indexing
        semantic Web sources and ontologies, or semantic content
        from the classical Web. As web crawling for the Semantic
        Web also fell short of retrieving adequate information in
        limited time and resources [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0025">25</a>], meta-crawling was proposed as an
        effective way to extend classical crawling methods, by
        including search engines in the crawling stage [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0027">27</a>].
        Examples of meta-crawling the classical web include
        SavvySearch [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0024">24</a>], Helios [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0019">19</a>], and
        WebCrawler<a class="fn" href="#fn17" id=
        "foot-fn17"><sup>14</sup></a>. In the Semantic Web domain,
        meta-search is not currently employed in the aforementioned
        semantic search engines [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0020">20</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0029">29</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0035">35</a>].</p>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.3</span> Our
            Contribution</h3>
          </div>
        </header>
        <p>Whereas existing projects/repositories for Linked Data
        sources are mainly based on community-based crowd-sourcing
        to collect relevant information, in this paper we propose
        an automatic, dynamic Linked Data endpoints discovery
        method based on meta crawling. Meta-crawling is a common
        approach in the web search domain; however, SpEnD approach
        is unique in applying meta-crawling to the semantic web
        domain (i.e. the discovery of SPARQL endpoints). In this
        study, the complete design of SpEnD on discovering,
        analyzing, and publishing Linked Data endpoints is
        explained in detail and we compare SpEnD repository with
        DataHub, LOD Cloud, SPARQLES and LODStats repositories
        unlike the previous study [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0044">44</a>] which consists of describing SpEnD
        software and comparing SpEnD repository with only DataHub
        repository. In this way, we address the existing need of
        the Semantic Web community for a web-based search engine
        that is capable of discovering Linked Data endpoints and
        datasets in frequent intervals (e.g. hours, days) which are
        published anywhere on the web. Although LOD Cloud also
        claims to use crawling, its crawling service is very basic
        and inefficient (see our performance comparison in Section
        <a class="sec" href="#sec-20">5</a>). We outperform its
        service by employing continuous meta-crawling (being able
        to harness any available search engine offering an open
        API, through a uniform plug and play approach), as an easy
        and effective way to keep up-to-date metadata about Linked
        Data sources on the web.</p>
      </section>
    </section>
    <section id="sec-13">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span>
          Methodology</h2>
        </div>
      </header>
      <p>SPARQL Endpoints Discovery (SpEnD) is a novel web crawling
      approach for discovering Linked Data sources on the Web and
      it consists of four steps: (1) Web crawling, (2) Web-page
      analysis, (3) Domain learning, and (4) Repository
      Creation.</p>
      <p>Fig. <a class="fig" href="#fig1">1</a> shows the general
      methodology employed in SpEnD, based on the four steps listed
      and explained above. In the first step, we propose the use of
      web crawlers that crawl continuously the web for semantically
      annotated data and Linked Data sources. A technique to
      improve the performance of web crawling is by employing
      meta-crawling (see Section <a class="sec" href=
      "#sec-15">4.1</a>). An important process here is to identify
      keywords that can be used to describe Linked Data endpoints,
      i.e. common patterns that appear in all websites containing
      Semantic Web-related content (see Section <a class="sec"
      href="#sec-16">4.2</a>). A way to achieve this is by manually
      parsing a large number of available Linked Data sources,
      trying to identify the most common elements that are evident
      in all associated web pages. To easily get a complete list of
      (currently) available Linked Data sources, we can harness
      existing repositories for Linked Data sources (e.g. LOD
      Cloud, SPARQLES, LODStats, and DataHub).</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3200000/3191599/images/www18companion-338-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">General Methodology.</span>
        </div>
      </figure>
      <p></p>
      <p>In the second step, web-page analysis is performed to
      consider whether some of the websites being parsed contain
      some of the common patterns defined in the first step. If
      yes, then this is a strong indication that the parsed
      websites contain Linked Data endpoints and semantically
      annotated data. There are various techniques to examine
      whether these endpoints are available and active, with more
      popular the one of performing some query on the endpoint,
      expecting to get some response and results (see Section
      <a class="sec" href="#sec-17">4.3</a>). In the third step,
      domain information is harnessed for more targeted and
      effective web-page analysis. In this case, the current domain
      is used in various combinations together with the common
      patterns identified, in order to perform a sophisticated
      search for Linked Data endpoints and relevant Semantic Web
      content (see Section <a class="sec" href="#sec-18">4.4</a>).
      In the final step, the information about Linked Data
      endpoints needs to become available to the public so that
      clients could discover relevant datasets and directly
      interact with them (or retrieve historical data), and
      machines could locate relevant information/knowledge required
      for their reasoning operations. Thus, a new Linked Data
      endpoint should be provided by the SpEnD search engine, which
      could be then used by web clients/machines for discovery of
      relevant datasets/information. A web and/or desktop
      application could also be created to serve humans (i.e.
      through a graphical user interface) as well as machines (i.e.
      through an API) (see Section <a class="sec" href=
      "#sec-19">4.5</a>).</p>
    </section>
    <section id="sec-14">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span>
          Implementation</h2>
        </div>
      </header>
      <p>We implemented SpEnD by adopting a meta-crawling approach.
      Harnessing commercial search engines allowed us to avoid
      costs for infrastructure and increase system's performance.
      Our intention is not to promote the use of search engines for
      the web crawling task (as this would clearly increase the
      dependency on them for important web-related tasks), but only
      to demonstrate the possible effectiveness and potential of
      web crawling for realizing a search engine for the Semantic
      Web. Moreover, we considered Linked Data sources to be
      represented as SPARQL endpoints, as SPARQL is currently the
      most popular way to retrieve and manipulate data stored in
      RDF format. In the future, we are willing to include other
      Linked Data endpoints too, if available and widely used. The
      system's architecture is visualized in Fig. <a class="fig"
      href="#fig2">2</a>. The SpEnD system implementation has five
      major steps: (1) meta-crawling, (2) creating search keywords
      for meta-crawling (3) web-page analysis, (4) domain learning
      and (5) creation of a repository of SPARQL endpoints. These
      steps are explained in the following sub-sections.</p>
      <figure id="fig2">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3200000/3191599/images/www18companion-338-fig2.jpg"
        class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class=
          "figure-title">System Diagram.</span>
        </div>
      </figure>
      <p></p>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span>
            Meta-Crawling SPARQL Endpoints</h3>
          </div>
        </header>
        <p>Search engine APIs<a class="fn" href="#fn18" id=
        "foot-fn18"><sup>15</sup></a><a class="fn" href="#fn19" id=
        "foot-fn19"><sup>16</sup></a>, have various specifications.
        In the discovery stage, a unified meta-crawling approach
        (applicable to any search engine) was applied on all four
        major search engines (Bing, Yahoo, Google and Yandex),
        based on standardized configuration files. By using this
        approach, the limitations of the different search API
        interfaces could be overcome. Besides, a new search engine
        can be included in the system by simply inserting its XML
        record in the configuration file. The XML schema is
        designed to specify the common features and parameters for
        meta-crawling using any search engine. Some search engines
        have further limitations to restrict access for common web
        crawlers. For example, Google search engine results in a
        403 HTML error response for (frequent) requests coming from
        Crawler4J and WebSphinx [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0030">30</a>]. In the SpEnD system, a crawling
        object is created by using parameter values from a
        configuration file defined by a XML schema, and then a
        crawling thread is created for each search engine. These
        threads obey the limitation rules of the corresponding
        search engines.</p>
        <p>Inside the search engine objects, a meta-crawling
        algorithm is called for every meta search task. The
        algorithm related to this task is displayed in Algorithm
        <a class="fig" href="#fig3a">4.1</a> as the extraction,
        parsing and filtering processes are shown in
        pseudo-code.</p>
        <p>In this algorithm, a meta-crawling task is performed for
        each search keyword on every search engine, as follows:</p>
        <ul class="list-no-style">
          <li id="list1" label="•">At the beginning, the search
          engine parameters specified in the configuration file are
          initialized for the search engine object.<br /></li>
          <li id="list2" label="•">Afterwards, a search task is
          performed for each search keyword (see Table <a class=
          "tbl" href="#tab2">2</a>). The algorithm visits all
          search result pages listed under the search task until
          the end. Through this meta-crawling process, all URLs
          hidden under the HTML source code are extracted,
          irrelevant file types (e.g. pdf, gif, jpeg) and the
          excluded keywords are filtered out.<br />
          </li>
          <li id="list3" label="•">All pages containing some of the
          search keywords are temporarily saved.<br /></li>
        </ul>
        <figure id="fig3a">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191599/images/algo4-1.jpg"
          class="img-responsive" alt="" longdesc="" />
        </figure>
      </section>
      <section id="sec-16">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Creating
            Search Keywords for Meta-Crawling.</h3>
          </div>
        </header>
        <p>In general, meta-search keywords are selected by domain
        experts, an operation which is critical for the complete
        coverage of the potential results. In this study, our
        meta-crawling approach starts with a keyword set, which is
        extracted by our preliminary crawler that collects known
        SPARQL endpoint pages. This keyword extraction process
        eliminates the need for domain knowledge in meta-crawling
        by analyzing and identifying common keyword patterns in the
        web pages Linked Data resource gateways. In total, 275 HTML
        pages containing SPARQL endpoints were crawled, by scanning
        available Linked Data repositories (LOD Cloud, SPARQLES,
        LODStats, and DataHub), and analyzed to find common
        patterns evident in all cases by using a term frequency
        scoring. The most commonly used keywords found are the
        following: sparql, query, rdf, virtuoso, openlink,
        inference, iri and endpoint. Besides single words, common
        HTML tags used along with the aforementioned keywords are
        the following: label, a, span, title, meta, h1, h2, h3, li,
        dt, p and option. We then combined these results and
        gathered a list of meta-crawling search keywords and
        specific search directives. Table <a class="tbl" href=
        "#tab2">2</a> lists some examples from the final list of
        search keywords. By using this method, we collected and
        experimented all keywords and phrases which exist in known
        SPARQL endpoint pages. Further, we enriched the keyword
        list with search operators<a class="fn" href="#fn20" id=
        "foot-fn20"><sup>17</sup></a> for meta-crawling
        purposes.</p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Sample Search Keywords and Directives
            [<a class="bib" data-trigger="hover" data-toggle=
            "popover" data-placement="top" href=
            "#BibPLXBIB0043">43</a>].</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:center;"><strong>Search
                Text</strong></td>
                <td style="text-align:center;">
                <strong>Description</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">sparql</td>
                <td style="text-align:left;">Results having
                sparql</td>
              </tr>
              <tr>
                <td style="text-align:left;">sparql -language</td>
                <td style="text-align:left;">Results having sparql
                and not language</td>
              </tr>
              <tr>
                <td style="text-align:left;">”sparql endpoint”</td>
                <td style="text-align:left;">Exact phrase</td>
              </tr>
              <tr>
                <td style="text-align:left;">allintitle: sparql
                query</td>
                <td style="text-align:left;">Results having title
                sparql and/or query</td>
              </tr>
              <tr>
                <td style="text-align:left;">intitle:sparql</td>
                <td style="text-align:left;">Results having title
                sparql</td>
              </tr>
              <tr>
                <td style="text-align:left;">”Virtuoso SPARQL”</td>
                <td style="text-align:left;">Exact phrase</td>
              </tr>
              <tr>
                <td style="text-align:left;">inurl:PoolParty inurl:
                sparql</td>
                <td style="text-align:left;">Results with PoolParty
                and sparql in URL</td>
              </tr>
              <tr>
                <td style="text-align:left;">”sparql endpoint”
                site:gov</td>
                <td style="text-align:left;">Results with extension
                gov</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Web-page
            (URL) Analysis</h3>
          </div>
        </header>
        <p>In this step, the HTML source codes of the URLs listed
        in the search engine result pages are extracted and parsed.
        These URLs are filtered by using web data extraction
        methods such as pre-defined regular expressions and
        filtering criteria [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0016">16</a>]. In parallel to the meta-search
        algorithm, every candidate URL identified is checked if it
        was tested before. If not, then it is tested whether it is
        a SPARQL endpoint, based on the simple SELECT query by
        using the Jena Framework<a class="fn" href="#fn21" id=
        "foot-fn21"><sup>18</sup></a>.</p>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.4</span> Domain
            Learning</h3>
          </div>
        </header>
        <p>After the preliminary search trials by means of search
        keywords (as those listed in Table <a class="tbl" href=
        "#tab2">2</a>), a simple learning algorithm makes one more
        sophisticated search on the candidate URLs. Although the
        algorithm in Fig. 4 is capable of locating Linked
        Data-related web sites, the SPARQL endpoint pages may not
        show up in the search result pages with the common keywords
        listed in Table <a class="tbl" href="#tab2">2</a>. To avoid
        this possibility, the Pay Level Domain (PLD) names are
        extracted from the candidate URLs and then a new search
        query is created by using the ”site” keyword (e.g. ”sparql
        site:domain.com”). With this search extension, a more
        complete search is performed for each domain, by means of
        the Google Guava libraries<a class="fn" href="#fn22" id=
        "foot-fn22"><sup>19</sup></a>. The next step here is to
        perform a statistical meta-analysis of each Linked Data
        source discovered. To perform this, the VoID vocabulary is
        used, which includes a set of properties to define a Linked
        Data source in terms of numbers, names and statistics. For
        example, the VoID vocabulary implementation
        project<a class="fn" href="#fn23" id=
        "foot-fn23"><sup>20</sup></a> offers several SPARQL queries
        to collect statistical information about existing data
        sources. From the available methods, seven queries were
        selected for our purposes, listed in Table <a class="tbl"
        href="#tab3">3</a>. By sending these queries to the SPARQL
        endpoints, various statistics were collected. The results
        from these queries provide useful information about the
        size and range of the Linked Data sources listed at each
        repository. These statistical results are also used to
        filter out same URLs during the URL collection procedure,
        i.e. URLs having the same number of triples and entities
        are marked as being the same.</p>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class=
            "table-title">SPARQL Queries for Statistical Analysis
            [<a class="bib" data-trigger="hover" data-toggle=
            "popover" data-placement="top" href=
            "#BibPLXBIB0043">43</a>].</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:center;">
                <strong>ID</strong></td>
                <td style="text-align:left;"><strong>SPARQL
                Query</strong></td>
                <td style="text-align:left;">
                <strong>Definition</strong></td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>1</strong></td>
                <td style="text-align:left;">SELECT COUNT (*) { ?s
                ?p ?o }</td>
                <td style="text-align:left;"># of triples</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>2</strong></td>
                <td style="text-align:left;">SELECT COUNT (distinct
                ?s)</td>
                <td style="text-align:left;"># of entities</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">{ ?s a [] }</td>
                <td style="text-align:left;"></td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>3</strong></td>
                <td style="text-align:left;">SELECT COUNT (DISTINCT
                ?s)</td>
                <td style="text-align:left;"># of distinct</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">{ ?s ?p ?o }</td>
                <td style="text-align:left;">resource URIs</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">UNION { ?o ?p ?s }
                FILTER</td>
                <td></td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">(!isBlank (?s)
                &amp;&amp; !isLiteral (?s))</td>
                <td style="text-align:left;"></td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>4</strong></td>
                <td style="text-align:left;">SELECT COUNT (distinct
                ?o)</td>
                <td style="text-align:left;"># of distinct</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">{ ?s rdf:type ?o
                }</td>
                <td style="text-align:left;">classes</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>5</strong></td>
                <td style="text-align:left;">SELECT count (distinct
                ?p)</td>
                <td style="text-align:left;"># of distinct</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">{ ?s ?p ?o }</td>
                <td style="text-align:left;">predicates</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>6</strong></td>
                <td style="text-align:left;">SELECT COUNT (DISTINCT
                ?s)</td>
                <td style="text-align:left;"># of distinct</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">{ ?s ?p ?o }</td>
                <td style="text-align:left;">subject nodes</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>7</strong></td>
                <td style="text-align:left;">SELECT COUNT (DISTINCT
                ?o)</td>
                <td style="text-align:left;"># of distinct</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">?s ?p ?o</td>
                <td style="text-align:left;">object nodes</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">filter (!isLiteral
                (?o))</td>
                <td style="text-align:left;"></td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-19">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.5</span> Repository
            Creation</h3>
          </div>
        </header>
        <p>In this final step, a repository has been created for
        storing the SPARQL endpoints discovered. This repository
        involves a Virtuoso RDF store, for permanently storing the
        endpoints discovered, and also a Java application that
        provides a graphical interface for web and desktop clients
        to run the SpEnD system. This Java application can perform
        meta-crawling on search engines, analyze the resulting
        candidate URLs, and perform statistical analysis on the
        discovered SPARQL endpoints. The main screen of this
        application (see Figure <a class="fig" href="#fig3">3</a>)
        performs search engine crawling (see Section <a class="sec"
        href="#sec-15">4.1</a>) and web-page analysis (see Section
        <a class="sec" href="#sec-17">4.3</a>). The screen has a
        search text input box for search keywords and queries (see
        Section <a class="sec" href="#sec-16">4.2</a>), a list of
        search engines to be selected, and a table grid for
        displaying the ongoing search results.</p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191599/images/www18companion-338-fig4.jpg"
          class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">Desktop/Web Application:
            Crawler Tab [<a class="bib" data-trigger="hover"
            data-toggle="popover" data-placement="top" href=
            "#BibPLXBIB0043">43</a>].</span>
          </div>
        </figure>
        <p>Additionally, through the analysis interface, results
        from the other four projects can be traced in the Dataset
        Collection container. Additional features (in the
        Monitoring&amp;Analysis container) include status
        monitoring to trace the availability of each SPARQL
        endpoint and statistical analysis of each SPARQL endpoint
        by using the SPARQL queries listed in Table <a class="tbl"
        href="#tab3">3</a>. The software has been designed to run
        continuously, enabling an on-going crawling and analysis of
        SPARQL endpoints available on the web.</p>
      </section>
    </section>
    <section id="sec-20">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Evaluation</h2>
        </div>
      </header>
      <p>Evaluation focuses on two different aspects. First, the
      search results produced by harnessing various search engines
      (Bing, Yahoo, Google and Yandex) are analyzed and then, the
      SpEnD SPARQL endpoints repository is compared with the LOD
      Cloud, SPARQLES, LODStats, and DataHub repositories. In the
      following experiments, we left the SpEnD system to work for
      24 hours and then we collected the results. All the results
      of this experimental study, including raw search findings,
      are available on the SpEnD project's website<a class="fn"
      href="#fn24" id="foot-fn24"><sup>21</sup></a>.</p>
      <section id="sec-21">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.1</span> Search
            Engine Results</h3>
          </div>
        </header>
        <p>A total of 117K unique URLs have been extracted from
        search engines. Fig. <a class="fig" href="#fig4">4</a>
        shows the number of crawled URLs vs. the total number of
        (unique and duplicate) SPARQL endpoints found. After about
        44K URLs collected, the number of unique endpoints
        discovered does not increase anymore. Between 18K and 19K
        collected URLs, there is a significant increase on the
        number of unique endpoints discovered. The reason is the
        operation of the domain learning task (see Section
        <a class="sec" href="#sec-18">4.4</a>), which starts after
        the initial querying of search texts (see Table <a class=
        "tbl" href="#tab2">2</a>). More than 1K unique SPARQL
        endpoints have been discovered in total during this
        experiment. After the discovery process, these 1,037 unique
        endpoints were analyzed to consider their availability and
        meta-information. Out of them, 211 were not available
        (listed in the search engine results but not accessible).
        Of the remaining endpoints, 168 were also eliminated after
        further analysis<a class="fn" href="#fn25" id=
        "foot-fn25"><sup>22</sup></a>, as they were listed in the
        results set more than once. [inline]Revised based on
        Revivewer B comment: In the subsection 5.1, for two SPARQL
        endpoints including the same dataset, is one endpoint
        removed from the list? Because there is not one-to-one
        correspondence between datasets and SPARQL endpoints, you
        do not have to remove duplicated endpoints.Although there
        is no one-to-one correspondence between datasets and SPARQL
        endpoints, SPARQL endpoints with duplicate datasets (one of
        them) are excluded from further analysis, in order to
        compare the number of unique Linked Data sources available
        more precisely. Although these endpoints are excluded from
        analysis, they are not excluded from the final list of
        published endpoints, where such endpoints are marked with a
        <strong>sameAs</strong> connection and not removed from the
        final repository list. Hence, a total of 658 unique online
        endpoints were finally stored in our SPARQL endpoints
        repository for analysis.</p>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191599/images/www18companion-338-fig5.jpg"
          class="img-responsive" alt="Figure 5" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">Number of Endpoints vs.
            Number of Crawled URLs [<a class="bib" data-trigger=
            "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0043">43</a>].</span>
          </div>
        </figure>
        <p>Table <a class="tbl" href="#tab4">4</a> offers some
        insights over the 658 discovered SPARQL endpoints, in terms
        of search terms which result in more than 60 endpoints. For
        example, by searching the ”sparql query” phrase in all
        search engines, 207 unique SPARQL endpoints were
        discovered. Some endpoints have been apparently discovered
        by multiple search terms. For example, the search terms
        ”sparql -w3” and ”sparql -wiki” returned almost the same
        SPARQL endpoint URLs.</p>
        <div class="table-responsive" id="tab4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class=
            "table-title">Search terms resulting in more than 60
            endpoints.</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:right;"><strong>Search
                Text</strong></td>
                <td style="text-align:right;"><strong># of
                Endpoints</strong></td>
              </tr>
              <tr>
                <td style="text-align:right;">”sparql endpoint”
                site:PLD</td>
                <td style="text-align:center;">518</td>
              </tr>
              <tr>
                <td style="text-align:right;">sparql query</td>
                <td style="text-align:center;">207</td>
              </tr>
              <tr>
                <td style="text-align:right;">”sparql
                endpoint”</td>
                <td style="text-align:center;">179</td>
              </tr>
              <tr>
                <td style="text-align:right;">sparql -language</td>
                <td style="text-align:center;">171</td>
              </tr>
              <tr>
                <td style="text-align:right;">inurl:sparql</td>
                <td style="text-align:center;">150</td>
              </tr>
              <tr>
                <td style="text-align:right;">allintitle: sparql
                query</td>
                <td style="text-align:center;">144</td>
              </tr>
              <tr>
                <td style="text-align:right;">sparql -w3</td>
                <td style="text-align:center;">126</td>
              </tr>
              <tr>
                <td style="text-align:right;">sparql -wiki</td>
                <td style="text-align:center;">125</td>
              </tr>
              <tr>
                <td style="text-align:right;">sparql -blog -wiki
                -w3 -pdf -news</td>
                <td style="text-align:center;">124</td>
              </tr>
              <tr>
                <td style="text-align:right;">sparql -blog -wiki
                -w3 -pdf</td>
                <td style="text-align:center;">120</td>
              </tr>
              <tr>
                <td style="text-align:right;">sparql -blog</td>
                <td style="text-align:center;">115</td>
              </tr>
              <tr>
                <td style="text-align:right;">allinurl:sparql
                data</td>
                <td style="text-align:center;">105</td>
              </tr>
              <tr>
                <td style="text-align:right;">”sparql endpoint”
                -blog -wiki -w3 -pdf</td>
                <td style="text-align:center;">93</td>
              </tr>
              <tr>
                <td style="text-align:right;">”Virtuoso SPARQL
                Query Editor”</td>
                <td style="text-align:center;">87</td>
              </tr>
              <tr>
                <td style="text-align:right;">”sparql endpoint”
                -blog</td>
                <td style="text-align:center;">84</td>
              </tr>
              <tr>
                <td style="text-align:right;">”sparql endpoint”
                -wiki</td>
                <td style="text-align:center;">76</td>
              </tr>
              <tr>
                <td style="text-align:right;">”sparql
                endpoint”</td>
                <td style="text-align:center;">66</td>
              </tr>
              <tr>
                <td style="text-align:right;">”Virtuoso SPARQL
                Query Editor”</td>
                <td style="text-align:center;">65</td>
              </tr>
              <tr>
                <td style="text-align:right;">”sparql endpoint”
                -w3</td>
                <td style="text-align:center;">61</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-22">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.2</span> Comparison
            of SpEnD with Existing SPARQL Endpoints
            Repositories</h3>
          </div>
        </header>
        <p>In this subsection, the results from SpEnD's 24-hour
        discovery process were compared with those from the other
        four major endpoint repositories (LOD Cloud, LODStats,
        SPARQLES, and Datahub). In order to determine the status of
        every endpoint listed on the four repositories plus SpEnD,
        a simple SPARQL query was sent daily to each listed SPARQL
        endpoint during June, 2016, for a total period of one
        month. Table <a class="tbl" href="#tab5">5</a> lists the
        number of online and offline endpoints at those
        repositories as well as at the SpEnD dataset. Almost half
        of the SPARQL endpoints listed in the repositories are
        offline (passive), which is an indication that the SPARQL
        endpoint collection is not updated frequently on these
        repositories. Moreover, there are 211 offline endpoints
        discovered in the SpEnD dataset.</p>
        <div class="table-responsive" id="tab5">
          <div class="table-caption">
            <span class="table-number">Table 5:</span> <span class=
            "table-title">Comparison of SPARQL Endpoints Discovered
            in Terms of their Availability [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href=
            "#BibPLXBIB0043">43</a>].</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:left;">
                <strong>Dataset</strong></td>
                <td colspan="3" style="text-align:center;">
                <strong>Available Online</strong></td>
                <td style="text-align:center;">
                <strong>Offline</strong></td>
                <td style="text-align:center;">
                <strong>Total</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:center;">
                <strong>High</strong></td>
                <td style="text-align:center;">
                <strong>Low</strong></td>
                <td style="text-align:center;"><strong>Total
                Online</strong></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
              </tr>
              <tr>
                <td style="text-align:right;">Datahub</td>
                <td style="text-align:center;">210</td>
                <td style="text-align:center;">63</td>
                <td style="text-align:center;">273</td>
                <td style="text-align:center;">254</td>
                <td style="text-align:center;">527</td>
              </tr>
              <tr>
                <td style="text-align:right;">LOD Cloud</td>
                <td style="text-align:center;">69</td>
                <td style="text-align:center;">13</td>
                <td style="text-align:center;">82</td>
                <td style="text-align:center;">67</td>
                <td style="text-align:center;">149</td>
              </tr>
              <tr>
                <td style="text-align:right;">LodStats</td>
                <td style="text-align:center;">136</td>
                <td style="text-align:center;">39</td>
                <td style="text-align:center;">175</td>
                <td style="text-align:center;">160</td>
                <td style="text-align:center;">335</td>
              </tr>
              <tr>
                <td style="text-align:right;">SPARQLES</td>
                <td style="text-align:center;">205</td>
                <td style="text-align:center;">61</td>
                <td style="text-align:center;">266</td>
                <td style="text-align:center;">230</td>
                <td style="text-align:center;">496</td>
              </tr>
              <tr>
                <td style="text-align:right;">
                <strong>SpEnD</strong></td>
                <td style="text-align:center;">
                <strong>537</strong></td>
                <td style="text-align:center;">
                <strong>121</strong></td>
                <td style="text-align:center;">
                <strong>658</strong></td>
                <td style="text-align:center;">
                <strong>211</strong></td>
                <td style="text-align:center;">
                <strong>869</strong></td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>Fig. <a class="fig" href="#fig5">5</a> visualizes the
        total number of distinctive and common endpoints found by
        all projects. The SpEnD repository has 520 distinctive
        endpoints. However, there are also some SPARQL endpoints
        that could not be discovered by SpEnD, because they were
        not linkable with the rest of the web, hence search engines
        could not discover them. Fig. <a class="fig" href=
        "#fig6">6</a> shows only the active and available endpoints
        as listed in the four repositories and SpEnD dataset. As
        this figure shows, 224 out of the 277 active endpoints
        listed in other collections, were found by SpEnD as well
        (80.9% Accuracy). SPARQLES and LOD Cloud had no distinctive
        URLs, while only three distinctive URLs were listed in
        Datahub and only one distinctive URL listed in LODStats.
        The Datahub repository mostly covers other lists in terms
        of active URLs, except SpEnD. Although Fig. <a class="fig"
        href="#fig5">5</a> shows a significant amount of unique
        URLs in SpEnD data collection (434 endpoints), some of
        these URLs are not domain-significant, i.e. there are
        several SPARQL endpoints under the same domain names. Thus,
        we also analyzed the SPARQL endpoint URLs based on their
        PLDs. Fig. <a class="fig" href="#fig7">7</a> shows the
        number of active PLDs and Table <a class="tbl" href=
        "#tab6">6</a> lists those PLDs including more than 10
        SPARQL endpoint URLs. In this case, SpEnD discovers 119 out
        of 130 domains listed in other collections (91%
        accuracy).</p>
        <figure id="fig5">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191599/images/www18companion-338-fig6.jpg"
          class="img-responsive" alt="Figure 6" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span>
            <span class="figure-title">Set of Repositories’ Total #
            of SPARQL Endpoints [<a class="bib" data-trigger=
            "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0043">43</a>].</span>
          </div>
        </figure>
        <figure id="fig6">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191599/images/www18companion-338-fig7.jpg"
          class="img-responsive" alt="Figure 7" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 6:</span>
            <span class="figure-title">Set of Repositories’ # of
            Available SPARQL Endpoints [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href=
            "#BibPLXBIB0043">43</a>].</span>
          </div>
        </figure>
        <figure id="fig7">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191599/images/www18companion-338-fig8.jpg"
          class="img-responsive" alt="Figure 8" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 7:</span>
            <span class="figure-title">Set of Repositories’ Active
            SPARQL Set Domains (PLD) [<a class="bib" data-trigger=
            "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0043">43</a>].</span>
          </div>
        </figure>
        <p></p>
        <p>We note that the 434 unique endpoint URLs and 146
        significant domains discovered by SpEnD project are not
        validated/qualified by using quality measures (Acosta et
        al. 2013; Kontokostas and Westphal 2014; Mendes, Mühleisen,
        and Bizer 2012); however, the authors consider them still
        valuable as they are not listed and included in any other
        collections.</p>
        <div class="table-responsive" id="tab6">
          <div class="table-caption">
            <span class="table-number">Table 6:</span> <span class=
            "table-title">Number of SPARQL Endpoint URLs under the
            same PLD [<a class="bib" data-trigger="hover"
            data-toggle="popover" data-placement="top" href=
            "#BibPLXBIB0043">43</a>].</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:right;"><strong>Pay Level
                Domains</strong></td>
                <td style="text-align:center;"><strong>#Endpoints
                (&gt;10)</strong></td>
              </tr>
              <tr>
                <td style="text-align:right;">rkbexplorer.com</td>
                <td style="text-align:center;">65</td>
              </tr>
              <tr>
                <td style="text-align:right;">b3kat.de</td>
                <td style="text-align:center;">58</td>
              </tr>
              <tr>
                <td style="text-align:right;">insee.fr</td>
                <td style="text-align:center;">34</td>
              </tr>
              <tr>
                <td style="text-align:right;">dbpedia.org</td>
                <td style="text-align:center;">27</td>
              </tr>
              <tr>
                <td style="text-align:right;">
                fundacionctic.org</td>
                <td style="text-align:center;">23</td>
              </tr>
              <tr>
                <td style="text-align:right;">data.gov.uk</td>
                <td style="text-align:center;">21</td>
              </tr>
              <tr>
                <td style="text-align:right;">270a.info</td>
                <td style="text-align:center;">15</td>
              </tr>
              <tr>
                <td style="text-align:right;">ign.fr</td>
                <td style="text-align:center;">13</td>
              </tr>
              <tr>
                <td style="text-align:right;">linkeddata.es</td>
                <td style="text-align:center;">13</td>
              </tr>
              <tr>
                <td style="text-align:right;">eagle-i.net</td>
                <td style="text-align:center;">12</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>In Table <a class="tbl" href="#tab7">7</a>, the total
        number of online and offline PLDs and endpoint URLs are
        listed, comparing SpEnD with the other four repositories.
        The SpEnD dataset has the highest number of PLDs (265) and
        the highest number of endpoint URLs (658).</p>
        <div class="table-responsive" id="tab7">
          <div class="table-caption">
            <span class="table-number">Table 7:</span> <span class=
            "table-title">Number of PLDs and URLs Discovered by
            SpEnD and Repositories [<a class="bib" data-trigger=
            "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0043">43</a>].</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:right;"></td>
                <td colspan="2" style="text-align:center;">
                <strong># PLDs</strong></td>
                <td colspan="2" style="text-align:center;">
                <strong># Endpoints</strong></td>
              </tr>
              <tr>
                <td style="text-align:right;"></td>
                <td style="text-align:right;">
                <strong>Online</strong></td>
                <td style="text-align:right;">
                <strong>Offline</strong></td>
                <td style="text-align:right;">
                <strong>Online</strong></td>
                <td style="text-align:right;">
                <strong>Offline</strong></td>
              </tr>
              <tr>
                <td style="text-align:right;">
                <strong>SpEnD</strong></td>
                <td style="text-align:center;">
                <strong>265</strong></td>
                <td style="text-align:center;">59</td>
                <td style="text-align:center;">
                <strong>658</strong></td>
                <td style="text-align:center;">211</td>
              </tr>
              <tr>
                <td style="text-align:right;">
                <strong>SPARQLES</strong></td>
                <td style="text-align:center;">125</td>
                <td style="text-align:center;">110</td>
                <td style="text-align:center;">266</td>
                <td style="text-align:center;">230</td>
              </tr>
              <tr>
                <td style="text-align:right;">
                <strong>LodStats</strong></td>
                <td style="text-align:center;">76</td>
                <td style="text-align:center;">78</td>
                <td style="text-align:center;">175</td>
                <td style="text-align:center;">160</td>
              </tr>
              <tr>
                <td style="text-align:right;"><strong>LOD
                Cloud</strong></td>
                <td style="text-align:center;">45</td>
                <td style="text-align:center;">34</td>
                <td style="text-align:center;">82</td>
                <td style="text-align:center;">67</td>
              </tr>
              <tr>
                <td style="text-align:right;">
                <strong>Datahub</strong></td>
                <td style="text-align:center;">130</td>
                <td style="text-align:center;">119</td>
                <td style="text-align:center;">273</td>
                <td style="text-align:center;">254</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
    </section>
    <section id="sec-23">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Conclusion and
          Future Work</h2>
        </div>
      </header>
      <p>Although static repositories such as LOD Cloud, SPARQLES,
      and LODStats are popular on discovering and monitoring Linked
      Data sources, this paper shows that they are not capturing
      the whole spectrum of Linked Data endpoints available on the
      web, nor effectively tracing new endpoints identifying those
      going persistently offline. This paper addresses this gap by
      proposing a dynamic approach for discovery of Linked Data
      endpoints available on the web. We have presented SpEnD,
      which is a discovery engine for the Semantic Web based on web
      crawling. Our implementation involved a meta-crawling
      approach taking advantage of existing commercial search
      engines, to demonstrate the potential of web crawling in
      terms of effectively tracing Linked Data resources in less
      than 24 hours. An evaluation procedure indicated that SpEnD
      outperforms static repositories in regard to time
      performance, availability, and size of Linked Data endpoints
      discovered. A direct comparison revealed that the SpEnD
      dataset included significantly more SPARQL endpoints, PLDs,
      triples, entities, resource URIs, classes, predicates,
      subject nodes and object nodes than all other repositories.
      Our SPARQL endpoints collection is growing day by day and is
      available for further analysis and research by the academic
      community, even though our dataset is not yet rich on
      semantic annotations and classification. Regular crawling
      tasks are daily performed, and newly discovered SPARQL
      endpoints are incrementally added and published on the
      project's web site. As future work, our next step will be a
      semantic analysis [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0038">38</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0041">41</a>], and ranking [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0018">18</a>] of the collected SPARQL
      endpoints. This will help to get a better understanding about
      the contents of the discovered Linked Data sources, making it
      possible to classify SPARQL endpoints according to their
      domain or context [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0033">33</a>]. Moreover, since it was observed
      that a small number of endpoints was not discovered by SpEnD
      (due to search engines’ limitations) but were still available
      on the static repositories, we will put some effort into
      improving our overall approach to better include, in an
      automatic way, endpoints and datasets listed only on those
      repositories.</p>
    </section>
    <section id="sec-24">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span>
          Acknowledgement</h2>
        </div>
      </header>
      <p>This research paper is written based on the results
      accomplished in the PhD thesis prepared by Semih Yumusak and
      enhanced with the help of additional authors. This research
      is partly supported by The Scientific and Technological
      research council of Turkey with grant number 1059B141500052
      (Ref.No: B.14.2. TBT.0.06.01-21514107-020-155998).</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Keith Alexander and
        Michael Hausenblas. 2009. Describing linked datasets-on the
        design and usage of void, the'vocabulary of interlinked
        datasets. In <em><em>Linked Data on the Web Workshop (LDOW
        09), in conjunction with 18th International World Wide Web
        Conference (WWW 09)</em></em> .</li>
        <li id="BibPLXBIB0002" label="[2]">Sören Auer, Ivan
        Ermilov, Jens Lehmann, and Michael Martin. n. d.. LODStats
        - a statement-stream-based approach for gathering
        comprehensive statistics about RDF datasets. <a class=
        "link-inline force-break" href="http://lodstats.aksw.org/"
          target="_blank">http://lodstats.aksw.org/</a>
        </li>
        <li id="BibPLXBIB0003" label="[3]">Alexandros Batzios,
        Christos Dimou, Andreas&nbsp;L Symeonidis, and
        Pericles&nbsp;A Mitkas. 2008. BioCrawler: An intelligent
        crawler for the semantic web. <em><em>Expert Systems with
        Applications</em></em> 35, 1-2 (2008), 524–530. <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1016/j.eswa.2007.07.054" target=
        "_blank">https://doi.org/10.1016/j.eswa.2007.07.054</a>
        </li>
        <li id="BibPLXBIB0004" label="[4]">Tim Berners-lee, Yuhsin
        Chen, Lydia Chilton, Dan Connolly, Ruth Dhanaraj, James
        Hollenbach, Adam Lerer, and David Sheets. 2006. Tabulator :
        Exploring and Analyzing linked data on the Semantic Web. In
        <em><em>Proceedings of the 3rd International Semantic Web
        User Interaction Workshop</em></em> .</li>
        <li id="BibPLXBIB0005" label="[5]">Tim Berners-Lee, James
        Hendler, and Ora Lassila. 2001. The Semantic Web.
        <em><em>Scientific American</em></em> May(2001).</li>
        <li id="BibPLXBIB0006" label="[6]">Christian Bizer, Tom
        Heath, and Tim Berners-Lee. 2009. Linked data-the story so
        far. <em><em>International Journal on Semantic Web and
        Information Systems</em></em> 5, 3(2009), 1–22.</li>
        <li id="BibPLXBIB0007" label="[7]">Paolo Boldi, Bruno
        Codenotti, Massimo Santini, and Sebastiano Vigna. 2004.
        UbiCrawler: a scalable fully distributed Web crawler. <em>
          <em>Software: Practice and Experience</em></em> 34, 8
          (jul 2004), 711–726. <a class="link-inline force-break"
          href="https://doi.org/10.1002/spe.587" target=
          "_blank">https://doi.org/10.1002/spe.587</a>
        </li>
        <li id="BibPLXBIB0008" label="[8]">C Buil-Aranda and Aidan
        Hogan. 2013. SPARQL Web-Querying Infrastructure: Ready for
        Action?. In <em><em>The Semantic Web–ISWC 2013</em></em> .
        Springer Berlin Heidelberg, 277–293.</li>
        <li id="BibPLXBIB0009" label="[9]">Stephane Campinas and
        Diego Ceccarelli. 2011. The Sindice-2011 dataset for
        entity-oriented search in the web of data. In
        <em><em>Proceedings of the 1st International Workshop on
        Entity-Oriented Search (EOS)</em></em> . 26–32. <a class=
        "link-inline force-break" href=
        "http://research.microsoft.com/en-us/um/beijing/events/eos2011/13.pdf"
          target=
          "_blank">http://research.microsoft.com/en-us/um/beijing/events/eos2011/13.pdf</a>
        </li>
        <li id="BibPLXBIB0010" label="[10]">Gong Cheng, Weiyi Ge,
        Honghan Wu, and Yuzhong Qu. 2008. Searching Semantic Web
        Objects Based on Class Hierarchies. <em><em>LDOW</em></em>
        (2008). <a class="link-inline force-break" href=
        "http://www.ambuehler.ethz.ch/CDstore/www2008/events.linkeddata.org/ldow2008/papers/12-cheng-ge-searching-semantic-web-objects.pdf"
          target=
          "_blank">http://www.ambuehler.ethz.ch/CDstore/www2008/events.linkeddata.org/ldow2008/papers/12-cheng-ge-searching-semantic-web-objects.pdf</a>
        </li>
        <li id="BibPLXBIB0011" label="[11]">Gong Cheng and Yuzhong
        Qu. 2009. Searching Linked Objects with Falcons.
        <em><em>International Journal on Semantic Web and
        Information Systems</em></em> 5, 3(2009), 49–70.
          <a class="link-inline force-break" href=
          "https://doi.org/10.4018/jswis.2009081903" target=
          "_blank">https://doi.org/10.4018/jswis.2009081903</a>
        </li>
        <li id="BibPLXBIB0012" label="[12]">Richard Cyganiak and
        Anja Jentzsch. 2014. The Linking Open Data cloud diagram.
        (2014). <a class="link-inline force-break" href=
        "http://lod-cloud.net/" target=
        "_blank">http://lod-cloud.net/</a>
        </li>
        <li id="BibPLXBIB0013" label="[13]">M D'Aquin, E Motta,
        Jérôme Euzenat, Inria&nbsp;Grenoble Rhône-alpes, Walton
        Hall, and Milton Keynes. 2011. Watson , more than a
        Semantic Web search engine. <em><em>Semantic Web</em></em>
        2, 1 (2011), 55–63.</li>
        <li id="BibPLXBIB0014" label="[14]">Leigh Dodds. 2006.
        Slug: A semantic web crawler. In <em><em>Proceedings of
        Jena User Conference</em></em> .</li>
        <li id="BibPLXBIB0015" label="[15]">Ivan Ermilov, Jens
        Lehmann, Michael Martin, and Sören Auer. 2016.
        <em><em>LODStats: The Data Web Census Dataset</em></em> .
        Springer International Publishing, Cham, 38–46. <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1007/978-3-319-46547-0_5" target=
        "_blank">https://doi.org/10.1007/978-3-319-46547-0_5</a>
        </li>
        <li id="BibPLXBIB0016" label="[16]">Emilio Ferrara,
        Pasquale De Meo, Giacomo Fiumara, and Robert Baumgartner.
        2014. Web data extraction, applications and techniques: A
        survey. <em><em>Knowledge-Based Systems</em></em> 70
        (2014), 301–323. <a class="link-inline force-break" href=
        "https://doi.org/10.1016/j.knosys.2014.07.007" target=
        "_blank">https://doi.org/10.1016/j.knosys.2014.07.007</a>
        </li>
        <li id="BibPLXBIB0017" label="[17]">Tim Finin, Li Ding, Tim
        Finnin, Anupam Joshi, Rong Pan, R.&nbsp;Scott Cost, Yun
        Peng, Pavan Reddivari, Vishal Doshi, and Joel Sachs. 2004.
        Swoogle : A Search and Metadata Engine for the Semantic
        Web. In <em><em>Proceedings of the Thirteenth ACM
        International Conference on Information and Knowledge
        Management</em></em> . ACM, 652–659.</li>
        <li id="BibPLXBIB0018" label="[18]">Jose&nbsp;Maria Garcia,
        Martin Junghans, David Ruiz, Sudhir Agarwal, and Antonio
        Ruiz-Cortes. 2013. Integrating semantic Web services
        ranking mechanisms using a common preference model.
        <em><em>Knowledge-Based Systems</em></em> 49 (2013), 22–36.
        <a class="link-inline force-break" href=
        "https://doi.org/10.1016/j.knosys.2013.04.007" target=
        "_blank">https://doi.org/10.1016/j.knosys.2013.04.007</a>
        </li>
        <li id="BibPLXBIB0019" label="[19]">a. Gulli and A.
        Signorini. 2005. Building an open source meta-search
        engine. <em><em>Special interest tracks and posters of the
        14th international conference on World Wide Web - WWW
        ’05</em></em> (2005), 1004. <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/1062745.1062840" target="_blank">
          https://doi.org/10.1145/1062745.1062840</a>
        </li>
        <li id="BibPLXBIB0020" label="[20]">Andreas Harth, Aidan
        Hogan, Renaud Delbru, Sean&nbsp;O Riain, and Stefan Decker.
        2007. SWSE : Answers Before Links !. In <em><em>Semantic
        Web Challenge</em></em> .</li>
        <li id="BibPLXBIB0021" label="[21]">Andreas Harth, J
        Umbrich, and Stefan Decker. 2006. Multicrawler: A pipelined
        architecture for crawling and indexing semantic web data.
        In <em><em>ISWC</em></em> . 258–271. <a class=
        "link-inline force-break" href=
        "http://link.springer.com/chapter/10.1007/11926078"
          target="_blank">http://link.springer.com/chapter/10.1007/11926078</a>
        </li>
        <li id="BibPLXBIB0022" label="[22]">Allan Heydon and Marc
        Najork. 1999. Mercator: A scalable, extensible Web crawler.
        <em><em>World Wide Web</em></em> 2, 4 (1999), 219–229.
        <a class="link-inline force-break" href=
        "https://doi.org/10.1023/A:1019213109274" target="_blank">
          https://doi.org/10.1023/A:1019213109274</a>
        </li>
        <li id="BibPLXBIB0023" label="[23]">Aidan Hogan, Jürgen
        Umbrich, Andreas Harth, Richard Cyganiak, Axel Polleres,
        and Stefan Decker. 2012. An empirical survey of Linked Data
        conformance. <em><em>Web Semantics: Science, Services and
        Agents on the World Wide Web</em></em> 14 (jul 2012),
        14–44. <a class="link-inline force-break" href=
        "https://doi.org/10.1016/j.websem.2012.02.001" target=
        "_blank">https://doi.org/10.1016/j.websem.2012.02.001</a>
        </li>
        <li id="BibPLXBIB0024" label="[24]">Adele&nbsp;E Howe and
        Daniel Dreilinger. 1997. SavvySearch: A Meta-Search Engine
        that Learns which Search Engines to Query. <em><em>AI
        Magazine</em></em> 18, 2 (1997), 12–25. <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1.1.43.8157" target=
        "_blank">https://doi.org/10.1.1.43.8157</a>
        </li>
        <li id="BibPLXBIB0025" label="[25]">Robert Isele, Christian
        Bizer, and Andreas Harth. 2010. LDSpider An open-source
        crawling framework for the Web of Linked Data. In
        <em><em>International Semantic Web Conference</em></em> .
        6–9.</li>
        <li id="BibPLXBIB0026" label="[26]">Tobias Käfer and J
        Umbrich. 2012. Towards a Dynamic Linked Data Observatory.
        In <em><em>Linked Data on the Web at WWW
        Conference</em></em> , Vol.&nbsp;1380. <a class=
        "link-inline force-break" href=
        "http://events.linkeddata.org/ldow2012/slides/ldow2012-slides-14.pdf"
          target=
          "_blank">http://events.linkeddata.org/ldow2012/slides/ldow2012-slides-14.pdf</a>
        </li>
        <li id="BibPLXBIB0027" label="[27]">Andrew Kenneth, John
        Mcmahon, and C&nbsp;A Us. 2012. United States Patent
        US7805432 B2 Meta Search Engine. (2012). <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1197/jamia.M1139.Adar" target="_blank">
          https://doi.org/10.1197/jamia.M1139.Adar</a>
        </li>
        <li id="BibPLXBIB0028" label="[28]">Jon&nbsp;P. Knight.
        1996. Resource discovery on the internet. <em><em>New
        Review of Information Networking</em></em> 2 (1996), 3–14.
        <a class="link-inline force-break" href=
        "https://doi.org/10.1080/13614579609516865" target=
        "_blank">https://doi.org/10.1080/13614579609516865</a>
        </li>
        <li id="BibPLXBIB0029" label="[29]">Yuangui Lei, Victoria
        Uren, and Enrico Motta. 2006. SemSearch : A Search Engine
        for the Semantic Web. In <em><em>Managing Knowledge in a
        World of Networks</em></em> . Springer Berlin Heidelberg,
        238–245.</li>
        <li id="BibPLXBIB0030" label="[30]">Robert&nbsp;C. Miller
        and Krishna Bharat. 1998. SPHINX: a framework for creating
        personal, site-specific Web crawlers. <em><em>Computer
        Networks and ISDN Systems</em></em> 30 (1998), 119–130.
        <a class="link-inline force-break" href=
        "https://doi.org/10.1016/S0169-7552(98)00064-6" target=
        "_blank">https://doi.org/10.1016/S0169-7552(98)00064-6</a>
        </li>
        <li id="BibPLXBIB0031" label="[31]">B. Mutlu, M. Mutlu, K.
        Oztoprak, and E. Dogdu. 2016. Identifying trolls and
        determining terror awareness level in social networks using
        a scalable framework. In <em><em>2016 IEEE International
        Conference on Big Data (Big Data)</em></em> . 1792–1798.
        <a class="link-inline force-break" href=
        "https://doi.org/10.1109/BigData.2016.7840796" target=
        "_blank">https://doi.org/10.1109/BigData.2016.7840796</a>
        </li>
        <li id="BibPLXBIB0032" label="[32]">Kasim Oztoprak. 2015.
        Profiling subscribers according to their internet usage
        characteristics and behaviors. <em><em>Proceedings - 2015
        IEEE International Conference on Big Data, IEEE Big Data
        2015</em></em> (2015), 1492–1499. <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1109/BigData.2015.7363912" target=
        "_blank">https://doi.org/10.1109/BigData.2015.7363912</a>
        </li>
        <li id="BibPLXBIB0033" label="[33]">Kasim Oztoprak. 2016.
        Subscriber Profiling for Connection Service Providers by
        Considering Individuals and Different Timeframes. <em><em>
          IEICE Transactions on Communications</em></em> E99.B, 6
          (2016), 1353–1361. <a class="link-inline force-break"
          href="https://doi.org/10.1587/transcom.2015EBP3467"
          target=
          "_blank">https://doi.org/10.1587/transcom.2015EBP3467</a>
        </li>
        <li id="BibPLXBIB0034" label="[34]">V Shah, Riya Patni,
        Vivek Patani, and Rhythm Shah. 2014. Understanding Focused
        Crawler. <em><em>International Journal of Computer Science
        &amp; Information Technologies</em></em> 5, 5(2014),
        6849–6852. <a class="link-inline force-break" href=
        "http://ijcsit.com/docs/Volume5/vol5issue05/ijcsit20140505183.pdf"
          target=
          "_blank">http://ijcsit.com/docs/Volume5/vol5issue05/ijcsit20140505183.pdf</a>
        </li>
        <li id="BibPLXBIB0035" label="[35]">Thanh Tran, Haofen
        Wang, and Peter Haase. 2009. Hermes: Data Web search on a
        pay-as-you-go integration infrastructure. <em><em>Web
        Semantics: Science, Services and Agents on the World Wide
        Web</em></em> 7, 3 (sep 2009), 189–203. <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1016/j.websem.2009.07.001" target=
        "_blank">https://doi.org/10.1016/j.websem.2009.07.001</a>
        </li>
        <li id="BibPLXBIB0036" label="[36]">Giovanni Tummarello,
        Richard Cyganiak, Michele Catasta, Szymon Danielczyk,
        Renaud Delbru, and Stefan Decker. 2010. Sig.ma: Live views
        on the Web of Data. <em><em>Web Semantics: Science,
        Services and Agents on the World Wide Web</em></em> 8, 4
        (nov 2010), 355–364. <a class="link-inline force-break"
        href="https://doi.org/10.1016/j.websem.2010.08.003"
          target="_blank">https://doi.org/10.1016/j.websem.2010.08.003</a>
        </li>
        <li id="BibPLXBIB0037" label="[37]">Giovanni Tummarello,
        Renaud Delbru, and Eyal Oren. 2007. Sindice. com: Weaving
        the open linked data. In <em><em>The Semantic Web</em></em>
        . Springer Berlin Heidelberg, 552–565.</li>
        <li id="BibPLXBIB0038" label="[38]">Elif Uysal, Semih
        Yumusak, Kasim Oztoprak, and Erdogan Dogdu. 2017. Sentiment
        Analysis for the Social Media : A Case Study for Turkish
        General Elections Categories and Subject Descriptors.
        <em><em>Proceedings of the SouthEast Conference.
        ACM</em></em> (2017), 215–218.</li>
        <li id="BibPLXBIB0039" label="[39]">PY Vandenbussche, CB
        Aranda, Aidan Hogan, and J Umbrich. 2013. Monitoring the
        Status of SPARQL Endpoints. In <em><em>International
        Semantic Web Conference (Posters &amp; Demos)</em></em> ,
        Vol.&nbsp;1380. 3–6.</li>
        <li id="BibPLXBIB0040" label="[40]">Haofen Wang, Qiaoling
        Liu, Thomas Penin, Linyun Fu, Lei Zhang, Thanh Tran, Yong
        Yu, and Yue Pan. 2009. Semplore: A scalable IR approach to
        search the Web of Data. <em><em>Web Semantics: Science,
        Services and Agents on the World Wide Web</em></em> 7, 3
        (sep 2009), 177–188. <a class="link-inline force-break"
        href="https://doi.org/10.1016/j.websem.2009.08.001"
          target="_blank">https://doi.org/10.1016/j.websem.2009.08.001</a>
        </li>
        <li id="BibPLXBIB0041" label="[41]">Zhichun Wang, Juanzi
        Li, Yue Zhao, Rossi Setchi, and Jie Tang. 2013. A unified
        approach to matching semantic data on the web.
        <em><em>Knowledge-Based Systems</em></em> 39 (2013),
        173–184. <a class="link-inline force-break" href=
        "https://doi.org/10.1016/j.knosys.2012.10.015" target=
        "_blank">https://doi.org/10.1016/j.knosys.2012.10.015</a>
        </li>
        <li id="BibPLXBIB0042" label="[42]">Sheng-Yuan Yang. 2010.
        OntoCrawler: A focused crawler with ontology-supported
        website models for information agents. <em><em>Expert
        Systems with Applications</em></em> 37, 7 (jul 2010),
        5381–5389. <a class="link-inline force-break" href=
        "https://doi.org/10.1016/j.eswa.2010.01.018" target=
        "_blank">https://doi.org/10.1016/j.eswa.2010.01.018</a>
        </li>
        <li id="BibPLXBIB0043" label="[43]">Semih Yumusak. 2017.
        <em>A Novel Method to Discover and Analyze Linked Data
        Sources</em>. Ph.D. Dissertation.</li>
        <li id="BibPLXBIB0044" label="[44]">Semih Yumusak, Erdogan
        Dogdu, Halife Kodaz, Andreas Kamilaris, and Pierre-Yves
        Vandenbussche. 2017. SpEnD: Linked Data SPARQL Endpoints
        Discovery Using Search Engines. <em><em>IEICE Transactions
        on Information and Systems,</em></em> E100-D, 4(2017),
        758–767. <a class="link-inline force-break" href=
        "https://doi.org/10.1587/transinf.2016DAP0025" target=
        "_blank">https://doi.org/10.1587/transinf.2016DAP0025</a>arxiv:1608.02761
        </li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>*</sup></a><a class=
    "link-inline force-break" href=
    "http://spend.semihyumusak.com.tr">http://spend.semihyumusak.com.tr</a>,
    <a class="link-inline force-break" href=
    "https://github.com/semihyumusak/SpEnD">https://github.com/semihyumusak/SpEnD</a></p>
    <p id="fn3"><a href="#foot-fn3"><sup>†</sup></a>Corresponding
    author.</p>
    <p id="fn4"><a href="#foot-fn4"><sup>1</sup></a><a class=
    "link-inline force-break" href=
    "http://www.w3.org/2001/sw">http://www.w3.org/2001/sw</a></p>
    <p id="fn5"><a href="#foot-fn5"><sup>2</sup></a><a class=
    "link-inline force-break" href=
    "http://www.w3.org/RDF">http://www.w3.org/RDF</a></p>
    <p id="fn6"><a href="#foot-fn6"><sup>3</sup></a><a class=
    "link-inline force-break" href=
    "http://linkeddatacatalog.dws.informatik.uni-mannheim.de/state/">http://linkeddatacatalog.dws.informatik.uni-mannheim.de/state/</a></p>
    <p id="fn7"><a href="#foot-fn7"><sup>4</sup></a><a class=
    "link-inline force-break" href=
    "http://datahub.io/">http://datahub.io/</a></p>
    <p id="fn8"><a href="#foot-fn8"><sup>5</sup></a><a class=
    "link-inline force-break" href=
    "http://www.w3.org/DesignIssues/LinkedData.html">http://www.w3.org/DesignIssues/LinkedData.html</a></p>
    <p id="fn9"><a href="#foot-fn9"><sup>6</sup></a><a class=
    "link-inline force-break" href=
    "http://dbpedia.org/">http://dbpedia.org/</a></p>
    <p id="fn10"><a href="#foot-fn10"><sup>7</sup></a><a class=
    "link-inline force-break" href=
    "http://swse.deri.org/dyldo/">http://swse.deri.org/dyldo/</a></p>
    <p id="fn11"><a href="#foot-fn11"><sup>8</sup></a><a class=
    "link-inline force-break" href=
    "http://stats.lod2.eu/">http://stats.lod2.eu/</a></p>
    <p id="fn12"><a href="#foot-fn12"><sup>9</sup></a><a class=
    "link-inline force-break" href=
    "http://www.w3.org/TR/vocab-data-cube/">http://www.w3.org/TR/vocab-data-cube/</a></p>
    <p id="fn13"><a href="#foot-fn13"><sup>10</sup></a><a class=
    "link-inline force-break" href=
    "http://datahub.io/">http://datahub.io/</a></p>
    <p id="fn14"><a href="#foot-fn14"><sup>11</sup></a><a class=
    "link-inline force-break" href=
    "http://ode.openlinksw.com/">http://ode.openlinksw.com/</a></p>
    <p id="fn15"><a href="#foot-fn15"><sup>12</sup></a><a class=
    "link-inline force-break" href=
    "https://code.google.com/p/crawler4j/">https://code.google.com/p/crawler4j/</a></p>
    <p id="fn16"><a href="#foot-fn16"><sup>13</sup></a><a class=
    "link-inline force-break" href=
    "http://nutch.apache.org">http://nutch.apache.org</a></p>
    <p id="fn17"><a href="#foot-fn17"><sup>14</sup></a><a class=
    "link-inline force-break" href=
    "http://www.webcrawler.com/">http://www.webcrawler.com/</a></p>
    <p id="fn18"><a href="#foot-fn18"><sup>15</sup></a><a class=
    "link-inline force-break" href=
    "http://datamarket.azure.com/dataset/bing/search">http://datamarket.azure.com/dataset/bing/search</a></p>
    <p id="fn19"><a href="#foot-fn19"><sup>16</sup></a><a class=
    "link-inline force-break" href=
    "https://developers.google.com/custom-search">https://developers.google.com/custom-search</a></p>
    <p id="fn20"><a href="#foot-fn20"><sup>17</sup></a><a class=
    "link-inline force-break" href=
    "http://www.googleguide.com/advanced_operators_reference.html">http://www.googleguide.com/advanced_operators_reference.html</a></p>
    <p id="fn21"><a href="#foot-fn21"><sup>18</sup></a><a class=
    "link-inline force-break" href=
    "https://jena.apache.org/">https://jena.apache.org/</a></p>
    <p id="fn22"><a href="#foot-fn22"><sup>19</sup></a><a class=
    "link-inline force-break" href=
    "https://github.com/google/guava">https://github.com/google/guava</a></p>
    <p id="fn23"><a href="#foot-fn23"><sup>20</sup></a><a class=
    "link-inline force-break" href=
    "https://code.google.com/p/void-impl/wiki/">https://code.google.com/p/void-impl/wiki/</a></p>
    <p>SPARQLQueriesForStatistics</p>
    <p id="fn24"><a href="#foot-fn24"><sup>21</sup></a><a class=
    "link-inline force-break" href=
    "http://spend.semihyumusak.com.tr/">http://spend.semihyumusak.com.tr/</a></p>
    <p id="fn25"><a href="#foot-fn25"><sup>22</sup></a>Each dataset
    was inspected using the queries listed in Table <a class="tbl"
    href="#tab3">3</a> (number of triples, entities, classes,
    etc.). If two endpoints had exactly the same results for all
    the queries, then they were considered as the same dataset (but
    duplicated in two separate URL endpoints).</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18 Companion, April 23-27, 2018, Lyon,
      France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License.<br />
      ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3191599">https://doi.org/10.1145/3184558.3191599</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
