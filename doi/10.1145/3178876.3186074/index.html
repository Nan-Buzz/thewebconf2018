<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Leveraging Fine-Grained Wikipedia Categories for Entity Search</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
<link rel="cite-as" href="https://doi.org/10.1145/3178876.3186074"/></head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186074'>https://doi.org/10.1145/3178876.3186074</a>.
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186074'>https://w3id.org/oa/10.1145/3178876.3186074</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Leveraging Fine-Grained Wikipedia Categories for Entity Search</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Denghao</span> <span class="surName">Ma</span>, Renmin University of China, <a href="mailto:madenghao@ruc.edu.cn">madenghao@ruc.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Yueguo</span> <span class="surName">Chen</span>, Renmin University of China<a class="fn" href="#fn1" id="foot-fn1"><sup>⁎</sup></a>, <a href="mailto:chenyueguo@ruc.edu.cn">chenyueguo@ruc.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Kevin Chen-Chuan</span> <span class="surName">Chang</span>, UIUC, <a href="mailto:kcchang@illinois.edu">kcchang@illinois.edu</a>
        </div>
        <div class="author">
          <span class="givenName">Xiaoyong</span> <span class="surName">Du</span>, Renmin University of China, <a href="mailto:duyong@ruc.edu.cn">duyong@ruc.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Chuanfei</span> <span class="surName">Xu</span>, Huawei Technologies Co. Ltd, <a href="mailto:xuchuanfei@huawei.com">xuchuanfei@huawei.com</a>
        </div>
        <div class="author">
          <span class="givenName">Yi</span> <span class="surName">Chang</span>, Huawei Research America, <a href="mailto:Yi.Chang@huawei.com">Yi.Chang@huawei.com</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.3186074" target="_blank">https://doi.org/10.1145/3178876.3186074</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Ad-hoc entity search, which is to retrieve a ranked list of relevant entities in response to a query of natural language question, has been widely studied. It has been shown that category matching of entities, especially when matching to fine-grained entity types/categories, is critical to the performance of entity search. However, the potentials of the fine-grained Wikipedia entity categories, has not been well exploited by existing studies. Based on the observation of how people describe entities of a specific type, we propose a headword-and-modifier model to deeply interpret both queries and fine-grained entity types/categories. Probabilistic generative models are designed to effectively estimate the relevance of headwords and modifiers as a pattern-based matching problem, taking the Wikipedia type taxonomy as an important input to address the ad-hoc representations of concepts/entities in queries. Extensive experimental results on three widely-used test sets: INEX-XER 2009, SemSearch-LS and TREC-Entity, show that our method achieves a significant improvement of the entity search performance over the state-of-the-art methods.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS Concepts:</span> • <strong>Information systems</strong> → <strong>Information retrieval;</strong> <strong>Retrieval models and ranking;</strong></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style="font-weight:bold;"><small>Keywords:</small></span> <span class="keyword"><small>Entity search; Category matching; Language model</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Denghao Ma, Yueguo Chen, Kevin Chen-Chuan Chang, Xiaoyong Du, Chuanfei Xu, and Yi Chang. 2018. Leveraging Fine-Grained Wikipedia Categories for Entity Search. In <em>WWW 2018: The 2018 Web Conference,</em> <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New York, NY, USA</em> 10 Pages. <a href="https://doi.org/10.1145/3178876.3186074" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3178876.3186074</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <p>A common definition of ad-hoc (list) entity search is to retrieve a ranked list of relevant entities in response to an entity search query [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>]. For example, for a query <em>Japanese players in Major League Baseball</em>, we may expect to retrieve a list of Japanese baseball players such as <em>Hideki Matsui, Kazuhiro Sasaki, Ichiro Suzuki</em> who have ever played in Major League Baseball as immediate answers. This is a large difference from general web search engines which mainly return relevant documents as search results.</p>
      <p>Early studies of entity search [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>] assume that at least one target type (also called category alternatively throughout the paper) of relevant entities has been explicitly specified in the query. This is important because many studies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] have shown that category matching plays a very important role for finding relevant entities. However, in many situations, providing explicit target entity types in a query leads to cognitive overhead to users, especially when they are not familiar with the underlying type taxonomy of entities to be retrieved. This motivates some studies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] by assuming that a query topic is only a natural language question. They address the absence of the target entity types by retrieving top-<em>k</em> relevant entity types of the query and treating them as substitutes of the missing target entity types. Consequently, existing entity search methods, achieving category matching by computing the relevance of entity types/categories to target entity types, still work even without explicit target entity types in the query.</p>
      <p>To find the top-<em>k</em> relevant entity types of a natural language question is then a critical component of category matching. Balog et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>] apply a bag-of-words model to evaluate the relevance of entity types to a query using language models. However, such a term-centric method does not perform well because the BOW based language models are often not effective enough to estimate the relevance of short texts where vocabulary gaps commonly exist. Kaptein et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>] propose an entity-centric method to vote relevant entity types from the top relevant entities retrieved from the query. This however does not perform well because some popular and general types/categories are likely to be more relevant. Balog et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>] also try to rank entity types based on their profiles (type-centric method) built from the entities of each entity type, but find that it is not as good as entity-centric methods. A learning to rank approach [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>] has also been tried to apply more features for ranking entity types. The target entity types retrieved by this method however tend to be general entity types.</p>
      <p>The above category matching framework of many entity search methods has some shortcomings: 1) The category matching models are mainly lexicon-based. Important concepts and entities, which are critical for interpreting the query intent as well as the type semantics, are not identified from queries and entity types. The pure term-based category matching methods therefore lead to a low recall because users may present their intent using alternative concepts/entities. 2) Due to the limitation of existing ranking models of category matching, many relevant entity types of a query are incorrect interpretations of the query intent [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>], whose impact on the entity search performance will be further amplified when they are used as target entity types of the query.</p>
      <p>The Wikipedia collection has been widely used by many entity search methods [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>], as the underlying corpus to support entity search. Entities (Wiki documents) in Wikipedia are collectively labelled with many fine-grained types/categories, which provide much semantics to the entities. They have been exploited by some recent studies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>], which show that the performance of entity search benefits a lot from the usage of fine-grained Wikipedia categories. However, we believe that existing category matching methods [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] do not unleash the power of fine-grained Wikipedia categories due to the above mentioned shortcomings.</p>
      <p>We observe that in many cases of list entity search, people try to find entities of a specific type, whose intent can usually be represented in a similar way of creating fine-grained Wikipedia categories. They tend to use a general concept to describe the basic type of relevant entities, and then apply some terms/entities to constrain the type to be a more specific one. As our key idea of this paper, we propose to model both queries and fine-grained entity categories as a headword plus some modifiers, where the headword represents the general query/type intent and the modifiers limit the scope of the intent. For example, in the case of <em>Japanese players in Major League Baseball</em>, we may use <em>players</em> as the headword, and the other terms/entities as modifiers. By interpreting queries and categories using headword-modifier patterns, other than the bag-of-words model, we are able to design a comprehensive category matching model that matches patterned queries against patterned categories, as a novel pattern-based document (category) retrieval model. However, there are two challenges to achieve such a headword-modifier pattern-based retrieval model.</p>
      <p>First, given the decomposed headwords and modifiers of queries and categories, how to construct the match effectively and holistically from the matches of individual components (i.e., headword to headword, modifier to modifier, and headword to modifier)? We treat headwords as first-class citizens and effectively decompose the relevance model into four individual components which are further estimated using probabilistic generative models.</p>
      <p>Second, when matching individual components, how do we address the vocabulary/conceptual gap of important concepts/entities? Word embedding techniques [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>] are not promising. For example, <em>Novels by Alan Moore</em> will be highly relevant to <em>Novels by Frank Miller</em> under the embedding model. We exploit the structure of fine-grained Wikipedia categories to discover alternative representation of concepts/entities in the Wikipedia type taxonomy.</p>
      <p>To the best of our knowledge, this is the first work to model both queries and categories as a headword-modifier model, and design comprehensive pattern-based document (category) retrieval models to quantify the relevance of a patterned category to a patterned query. We conduct extensive experiments on three widely-used entity search test sets: INEX-XER 2009 [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>], SemSearch-LS [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>] and TREC-Entity [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>]. The experimental results show that our method achieves a significant improvement of the entity search performance over the state-of-the-art methods.</p>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related Work</h2>
        </div>
      </header>
      <p>In recent years, much attention has been paid to the list entity search problem. The expert finding task (TREC Enterprise track [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>]) is focused on retrieving a list of persons relevant to a query. The INEX Entity Ranking task [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>] extends the expert finding task to include more entity types in Wikipedia. Topics in this task include both query terms and one or more target entity types [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>]. The TREC 2009 Entity track [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>] introduces the Related Entity Finding task, which is to identify homepages of target entities that satisfy a specified relation with a source entity and have a target type as constraints. These tasks use text corpus as the basis of entity search. Some recent tasks such as the Semantic Search challenge [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>], the INEX Linked Data track [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>] and the Question Answering over Linked Data challenge [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>] apply structured knowledge bases (e.g., DBpedia) to support entity search. However, they are beyond the scope of this work.</p>
      <p>Solutions of entity search are focused on context matching (evaluating the relevance to query terms) and category matching (evaluating the relevance to target entity types) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>]. The document model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>] has been shown to be an effective model of context matching [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>]. Category matching has been verified to be critical for the performance of entity search [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>]. To fully utilize the entity categories, people assume that some target entity types are explicitly provided in the query topics [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>]. Authors in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] evaluate three methods of estimating the relevance between an entity category and a target entity type: 1) binary distance: a simple binary function based on whether two entity types are identical or not; 2) title distance, which evaluates the relevance based on pure text similarity of terms in both entity types; 3) content distance, which estimates the relevance based on the profiles of two entity types, that are generated by collecting the contexts of entities of each type. They show that binary distance works only when the target entity types are from the type taxonomy (i.e. they are well defined), and title distance is a better choice when the target entity types are specific categories.</p>
      <p>The target entity types used in the queries directly affect the effectiveness of category matching. However, providing specific and accurate target entity types is an extra burden for users since they often do not have the knowledge of categories in the type taxonomy [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>]. Consequently, authors in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] propose to retrieve top relevant entity types of the query as the target entity types fed to the entity search methods. Strategies on ranking target entity types can be majorly classified as: 1) term-centric strategy [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>]: a standard language model is proposed to estimate the relevance between an entity type and a query based on their terms. However, its performance is not good because estimating the relevance of short texts is very challenging due to the vocabulary gap problem. The work [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>] estimates the different weights of individual query terms by using some NLP features, but it does not address the vocabulary gap problem; 2) type-centric strategy [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>]: for each entity type, a pseudo-document is created by concatenating the descriptions of all entities that belong to the type. Then, a standard language model is used to estimate the relevance between the query and the pseudo-documents; 3) entity-centric strategy [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>]: it first finds relevant entities of the query. Then, the entities vote for their categories, which however often retrieves general entity types; 4) learning-to-rank strategy [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>]: it considers not only type-centric and entity-centric strategies, but also other relevant signals such as taxonomy-driven features and type similarities. It shows that [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>] the learning-to-rank strategy performs better than the other two strategies. However, it faces the problem of often retrieving general entity types that do not match to the query intent accurately.</p>
      <p>The entities (with each having a Wiki document) in the Wikipedia collection are collectively labelled with many fine-grained Wikipedia categories. These fine-grained entity categories are organized as a type taxonomy of overlapping “trees”, with a very small number of top-level entity categories. Each category beyond the top-level may have multiple parent categories [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>]. The Wikipedia entity categories are created and labelled by many different human editors. It therefore potentially has some data quality problems. However, to control the quality of category labelling, Wikipedia provides some guidelines when editors assign some categories to a Wiki document. For example, two general rules for category labelling are: 1) a labelled category should be as specific as possible; and 2) similar categories should be avoided. It also provides a peer reviewing mechanism to further control the quality of category labelling.</p>
      <p>The work [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>] shows that more than 90% entity-bearing web queries contain headword and some modifiers. Some studies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0024">24</a>] of entity search have tried to use the headword and modifiers to model entity categories. They show that category matching benefits from a simple usage of term-based headword and modifiers. Although headwords and modifiers have been widely used for query understanding [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>], they however are seldom used in modelling documents. The work [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>] tries to extract headword-modifier pairs from queries and documents, and index them as terms. A language model is then applied to rank documents based on terms as well as headword-modifier pairs, in the setting of document retrieval. It however is still based on the bag-of-words model that does not address the vocabulary/conceptual gap challenge.</p>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Problem Definition</h2>
        </div>
      </header>
      <p>For entity search, we formalize the relevance of a candidate entity <em>e</em> to a query <em>q</em> as a generative probability <em>p</em>(<em>e</em>|<em>q</em>). According to the Bayes’ Theorem, such a probability can be rewritten as follows:</p>
      <div class="table-responsive" id="eq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{eqnarray} p(e|q)&amp;=&amp;\frac{p(q|e)p(e)}{p(q)}\\\nonumber &amp;\propto &amp;p(q|e)\end{eqnarray}</span><br />
          <span class="equation-number">(1)</span>
        </div>
      </div>
      <p></p>
      <p>where <em>p</em>(<em>q</em>|<em>e</em>) is the probability of generating the query <em>q</em> from an entity <em>e</em>, <em>p</em>(<em>e</em>) is a priori probability of the entity <em>e</em>, and <em>p</em>(<em>q</em>) is the probability of a query. We assume that <em>p</em>(<em>e</em>) is uniformly distributed over all entities, and thus it does not affect the ranking. The probability <em>p</em>(<em>q</em>) is consistent for a given query <em>q</em>. Consequently, we have <em>p</em>(<em>e</em>|<em>q</em>)∝<em>p</em>(<em>q</em>|<em>e</em>), and therefore <em>p</em>(<em>q</em>|<em>e</em>) can be used to estimate the relevance of the entity <em>e</em> to the query <em>q</em>.</p>
      <p>It is has been shown [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>] that context matching and category matching are two important components of entity search. We therefore decompose <em>p</em>(<em>q</em>|<em>e</em>) into two components, <em>p<sub>c</sub></em> (<em>q</em>|<em>e</em>) and <em>p<sub>t</sub></em> (<em>q</em>|<em>e</em>), which model the relevance of context matching and that of category matching respectively. They are unified by a weighted aggregation of the two relevance scores:</p>
      <div class="table-responsive" id="eq2">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} p(q|e)=p_{c}(q|e)^{1-\alpha _0}\cdot p_{t}(q|e)^{\alpha _0} \end{equation}</span><br />
          <span class="equation-number">(2)</span>
        </div>
      </div>
      <p></p>
      <p>where the parameter <em>α</em> <sub>0</sub> is applied to tune the weight between the context matching component and the category matching component. When <em>α</em> <sub>0</sub> = 0, only context matching model is applied for ranking entities. Correspondingly, if <em>α</em> <sub>0</sub> = 1, only category matching model is applied. In this paper, our focus is on devising the category matching model. The context matching model of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>] is directly applied in our study.</p>
      <p>The relevance of category matching is estimated as:</p>
      <div class="table-responsive" id="eq3">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} p_{t}(q|e)=\max _{t \in T(e)} p(q|t)p(t|e) \end{equation}</span><br />
          <span class="equation-number">(3)</span>
        </div>
      </div>
      <p></p>
      <p>where <em>T</em>(<em>e</em>) = {<em>t</em>|<em>e</em> ∈ <em>t</em>}, is the set of types that <em>e</em> belongs to, and <em>p</em>(<em>t</em>|<em>e</em>) is the probability of generating the type <em>t</em> from an entity <em>e</em>. The component <em>p</em>(<em>q</em>|<em>t</em>) is the probability of generating the query <em>q</em> from the type/category <em>t</em>. It is to capture the relevance of a type to a query. Since entities are labelled using the fine-grained Wikipedia categories with a very high confidence, we therefore set <em>p</em>(<em>t</em>|<em>e</em>) = 1, for <em>t</em> ∈ <em>T<sub>e</sub></em> . Other studies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] also apply the max function for category matching, by using the highest relevance score of a type <em>t</em> ∈ <em>T</em>(<em>e</em>) as the category matching relevance of the entity <em>e</em>. The estimation of <em>p<sub>t</sub></em> (<em>q</em>|<em>e</em>) is then to find a category <em>t</em> of <em>e</em> that has the maximal relevance score <em>p</em>(<em>q</em>|<em>t</em>) with regard to the query <em>q</em>. We therefore define the basic category matching problem as:</p>
      <p><strong>Problem Definition</strong>: Given a natural language question <em>q</em>, and a fine-grained entity category <em>t</em> ∈ <em>T</em> where <em>T</em> is the type taxonomy, estimate the relevance <em>p</em>(<em>q</em>|<em>t</em>).</p>
      <p>Such a way category matching supports ranking entity types in a unified model, without generating target entity types as the intermediate results. In the whole solution of entity search, we do not need to compute the category relevance of every type, but only those categories of the candidate entities derived from the context matching model.</p>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Category Matching Model</h2>
        </div>
      </header>
      <p>In our method, both queries and entity categories are modeled using headwords and modifiers, so that they are treated as basic elements for effective category matching. How to effectively extract entities and concepts, and how to detect headwords from short texts have been studied by many query understanding techniques (e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>]). It is therefore not the focus of this paper. We simply apply an open source tool [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>] to recognize entities/concepts from queries and entity types. For detecting headwords, we apply the following natural language patterns:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">Pattern 1: If a query/type is a sequence of nouns and adjectives (e.g., <em>Italian Nobel prize <span style="text-decoration: underline;">winners</span></em> ), the last noun is extracted as the headword (underlined).<br /></li>
        <li id="list2" label="•">Pattern 2: If a query/type contains some prepositions for connecting two components (e.g. “A for B”, “A of B”, “A with B”), it is almost true that A includes the headword [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>]. For example, <em>Noble english <span style="text-decoration: underline;">person</span> from the Hundred Years’ War</em>. Then, we process the component A by using the Pattern 1.<br />
        </li>
        <li id="list3" label="•">Pattern 3: If a query/type is an attributive clause (which often includes “WH” terms such as “where”, “which”), the modifier of the “WH” term is used as the headword. For example, <em><span style="text-decoration: underline;">Musicians</span> who appeared in the Blues Brothers movies</em>.<br /></li>
      </ul>
      <p>The modifiers are composed of all the other non-stop words in the query/type, as well as those entities/concepts extracted from the query/type (except the detected headword).</p>
      <p>In our category matching method, we treat headwords and modifiers individually and emphasize more on the headword part. This is because headwords often serve as the root (general type) of entity categories. An effective matching of headwords between queries and entity categories is therefore a prerequisite of guaranteeing the performance of category matching. On the other hand, the effective matching of modifiers between queries and entity categories is also important because it help us to exploit the semantic constraints implied by the modifiers of the fine-grained entity categories. For a query <em>q</em>, let <em>h<sub>q</sub></em> be its headword, and <em>M<sub>q</sub></em> = {<em>m</em> <sub>1</sub>, ...<em>m<sub>k</sub></em> } be the set of its modifiers. Let <em>h<sub>t</sub></em> and <em>M<sub>t</sub></em> be the headword and the modifiers of the entity type <em>t</em>. By assuming the independence between the headword and the modifiers, we estimate <em>p</em>(<em>q</em>|<em>t</em>) as follows:</p>
      <div class="table-responsive" id="eq4">
        <div class="display-equation">
          <span class="tex mytex">\begin{eqnarray} p(q|t)&amp;=&amp;p(h_q,M_q|t)=p(h_q|t)p(M_q|t)\\\nonumber &amp;=&amp;\frac{p(t|h_q)p(h_q)}{p(t)}\frac{p(t|M_q)p(M_q)}{p(t)}\\\nonumber &amp;\propto &amp;p(t|h_q)p(t|M_q)\\\nonumber &amp;=&amp;p(h_t,M_t|h_q)p(h_t,M_t|M_q)\\\nonumber &amp;=&amp;p(h_t|h_q)p(M_t|h_q)p(h_t|M_q)p(M_t|M_q)\end{eqnarray}</span><br />
          <span class="equation-number">(4)</span>
        </div>
      </div>where <em>p</em>(<em>h<sub>q</sub></em> ) is the probability the headword <em>h<sub>q</sub></em> , <em>p</em>(<em>M<sub>q</sub></em> ) is the probability the modifiers <em>M<sub>q</sub></em> , and <em>p</em>(<em>t</em>) is the probability of entity category <em>t</em> which is assumed to be uniformly distributed over all entity types. The probability <em>p</em>(<em>q</em>|<em>t</em>) can then be estimated as a pattern-based matching of 4 components <em>p</em>(<em>h<sub>t</sub></em> |<em>h<sub>q</sub></em> ), <em>p</em>(<em>M<sub>t</sub></em> |<em>h<sub>q</sub></em> ), <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ), and <em>p</em>(<em>M<sub>t</sub></em> |<em>M<sub>q</sub></em> ). The probability <em>p</em>(<em>h<sub>t</sub></em> |<em>h<sub>q</sub></em> ) is called headword relevance, and <em>p</em>(<em>M<sub>t</sub></em> |<em>M<sub>q</sub></em> ) is called modifier relevance. The components <em>p</em>(<em>M<sub>t</sub></em> |<em>h<sub>q</sub></em> ) and <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ) are called headword-modifier relevance.
      <p></p>
      <p>To avoid the impacts of different scales when estimating these components, we assigned some weights to them so that the probability <em>p</em>(<em>q</em>|<em>t</em>) is actually estimated as:</p>
      <div class="table-responsive" id="eq5">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} p(q|t)=p(h_t|h_q)^{\alpha _1}p(M_t|h_q)^{\alpha _2}p(h_t|M_q)^{\alpha _3}p(M_t|M_q)^{\alpha _4} \end{equation}</span><br />
          <span class="equation-number">(5)</span>
        </div>
      </div>
      <p></p>
      <p>These parameters satisfy <em>α</em> <sub>1</sub> + <em>α</em> <sub>2</sub> + <em>α</em> <sub>3</sub> + <em>α</em> <sub>4</sub> = 1.0, and their values can be learned from some validation set of particular test cases. We then introduce probabilistic generative models to estimate the relevance of these components respectively.</p>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Headword Relevance</h3>
          </div>
        </header>
        <p>The component <em>p</em>(<em>h<sub>t</sub></em> |<em>h<sub>q</sub></em> ) is to capture the relevance of two headwords <em>h<sub>t</sub></em> and <em>h<sub>q</sub></em> , to handle the cases of conceptual gap when <em>h<sub>t</sub></em> and <em>h<sub>q</sub></em> are different. For example, for a query <em><span style="text-decoration: underline;">Works</span> by Charles Rennie Mackintosh</em>. The concrete query intent are actually <em>buildings, structures</em>, which are often used as the headwords of the relevant entity categories in the Wikipedia type taxonomy. If we simply retrieve entity categories having the same headword (i.e., <em>Works</em>) as the query, we will definitely obtain a low recall of category matching. To effectively estimate <em>p</em>(<em>h<sub>t</sub></em> |<em>h<sub>q</sub></em> ), we build a headword hypernymy graph by using the type taxonomy of fine-grained Wikipedia entity categories. In this directed graph, vertexes are those headwords extracted from the Wikipedia entity types/categories. One edge <span class="inline-equation"><span class="tex">$h_t\rightarrow h_{t^{\prime }}$</span></span> will be created if a headword <em>h<sub>t</sub></em> is a direct hypernym of another headword <span class="inline-equation"><span class="tex">$h_{t^{\prime }}$</span></span> .</p>
        <p>To build the headword hypernymy graph, we statistically identify the headword-headword hypernymy pairs based on the hypernymy of Wikipedia categories. Given two entity categories <em>t</em> and <em>t</em>′ (e.g., <em>American <span style="text-decoration: underline;">people</span> by occupation</em> and <em>American <span style="text-decoration: underline;">writers</span></em> ), that satisfy <em>t</em> is the parent category of <em>t</em>′, we create an edge <span class="inline-equation"><span class="tex">$h_t\rightarrow h_{t^{\prime }}$</span></span> (e.g., <em>people</em> → <em>writers</em>) and count the number of category pairs having such a headword hypernymy relationship as the weight of the edge. By this way, a preliminary headword hypernymy graph can be generated. We then filter those possible noisy edges whose weight is less than 3, to partially avoid the impacts of those noisy pairs of hypernymy categories. Those remaining edges then form the headword hypernymy graph for estimating the headword relevance. Note that such a way of building the headword hypernymy graph may occasionally generate loops. For example, both <em>works</em> → <em>books</em> and <em>books</em> → <em>works</em> exist in the headword hypernymy graph. They however do not affect the estimation of the headword relevance. With the headword hypernymy graph, we are able to estimate the headword relevance <em>p</em>(<em>h<sub>t</sub></em> |<em>h<sub>q</sub></em> ) as:</p>
        <div class="table-responsive" id="eq6">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} p(h_t|h_q)= \left\lbrace \begin{array}{l@{\;\;}l}1 &amp; if\;h_t\;is\;a\;child\; or \;grandchild\;of\;h_q\\ \frac{1}{|H(h_t)|} &amp; else\;if\;h_t\;is\;a\;parent\;of\;h_q\\ \frac{1}{|S(h_t)|} &amp; else\;if\;h_t\;is\;a\;grandparent\;of\;h_q\\ 0 &amp; otherwise \end{array} \right. \end{equation}</span><br />
            <span class="equation-number">(6)</span>
          </div>
        </div>where <em>H</em>(<em>h<sub>t</sub></em> ) is a set of headwords which are children of <em>h<sub>t</sub></em> and <em>S</em>(<em>h<sub>t</sub></em> ) is a set of headwords which are grandchildren of <em>h<sub>t</sub></em> . Obviously, those hyponym headwords (which often appear in fine-grained entity categories) of <em>h<sub>q</sub></em> will have larger relevance than those hypernym headword (general headwords, which may deviate from the query intent). According to the above equation, relevant headwords of <em>h<sub>q</sub></em> are limited to those headwords whose graph distance to <em>h<sub>q</sub></em> is no more than two. This is designed to reduce the impacts of noisy pairs of hypernymy headwords.
        <p></p>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Modifier Relevance</h3>
          </div>
        </header>
        <p>To estimate the modifier relevance <em>p</em>(<em>M<sub>t</sub></em> |<em>M<sub>q</sub></em> ), we propose to apply a language model which utilizes the type taxonomy <em>T</em>. The modifier relevance is estimated as:</p>
        <div class="table-responsive" id="eq7">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray} p(M_t|M_q)&amp;=&amp;\frac{p(M_q|M_t)p(M_t)}{p(M_q)}\\\nonumber &amp;\propto &amp;p(M_q|M_t)\\\nonumber &amp;=&amp;\prod _{m\in M_q}p(m|M_t)^{n(m,M_q)}\end{eqnarray}</span><br />
            <span class="equation-number">(7)</span>
          </div>
        </div>where <em>p</em>(<em>M<sub>t</sub></em> ) is the probability of the modifiers <em>M<sub>t</sub></em> , and <em>n</em>(<em>m</em>, <em>M<sub>q</sub></em> ) measures the times of the modifier <em>m</em> presenting in the modifiers <em>M<sub>q</sub></em> . The component <em>p</em>(<em>M<sub>q</sub></em> |<em>M<sub>t</sub></em> ) is the probability of generating the modifiers <em>M<sub>q</sub></em> from the modifiers <em>M<sub>t</sub></em> . By assuming that the probability <em>p</em>(<em>M<sub>t</sub></em> ) is uniformly distributed over all entity types, we are able to transform the estimation of <em>p</em>(<em>M<sub>t</sub></em> |<em>M<sub>q</sub></em> ) as <em>p</em>(<em>M<sub>q</sub></em> |<em>M<sub>t</sub></em> ), so that a standard language model can be applied to estimate the probability <em>p</em>(<em>M<sub>q</sub></em> |<em>M<sub>t</sub></em> ). We therefore need to estimate the component <em>p</em>(<em>m</em>|<em>M<sub>t</sub></em> ), which is the probability of generating the modifier <em>m</em> from <em>M<sub>t</sub></em> , as the basis of estimiting the modifier relevance.
        <p></p>
        <p>To estimate the probability <em>p</em>(<em>m</em>|<em>M<sub>t</sub></em> ) using a language model, we need to address the cases when <em>m</em> does not present in the <em>M<sub>t</sub></em> by using some smoothing factors. The component <em>p</em>(<em>m</em>|<em>M<sub>t</sub></em> ) is then estimated as:</p>
        <div class="table-responsive" id="Xeq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} p(m|M_t)=(1-\lambda _1-\lambda _2)\frac{n(m,M_t)}{n(M_t)} +\lambda _1 p(m|T)+\lambda _2 p(m|D) \end{equation}</span><br />
            <span class="equation-number">(8)</span>
          </div>
        </div>where <em>n</em>(<em>M<sub>t</sub></em> ) is the number of modifiers in <em>M<sub>t</sub></em> , <em>p</em>(<em>m</em>|<em>T</em>) is a background probability of generating the modifier <em>m</em> from the type taxonomy <em>T</em>, and <em>p</em>(<em>m</em>|<em>D</em>) is a background probability of generating the term/entity of <em>m</em> from the corpus <em>D</em>. The parameters <em>λ</em> <sub>1</sub> and <em>λ</em> <sub>2</sub> are used as the weights of the two smoothing factors. As a background probability, the component <em>p</em>(<em>m</em>|<em>T</em>) can then be estimated as <span class="inline-equation"><span class="tex">$\frac{\sum _{t}n(m, M_{t})}{\sum _{t}n(M_{t})}$</span></span> . Considering that the modifier <em>m</em> may also not appear in the type taxonomy <em>T</em>, we therefore apply the second smoothing factor <em>p</em>(<em>m</em>|<em>D</em>).
        <p></p>
        <p>To address the vocabulary gap of those entities/concepts between the query <em>q</em> and the entity category <em>t</em>, we extend the entities/concepts in <em>M<sub>q</sub></em> to generate more expanded modifiers as part of the query. The expansion is achieved in the following way. For each entity/concept <em>e</em> (which is also a modifier) of <em>M<sub>q</sub></em> , we extract the entity categories of <em>e</em> as <em>T</em>(<em>e</em>). Then, an expanded modifier set <em>M<sub>e</sub></em> will be generated by merging the modifiers <em>M<sub>t</sub></em> of each entity type <em>t</em> ∈ <em>T</em>(<em>e</em>). With the expanded modifier set <em>M<sub>e</sub></em> of each entity/concept in <em>M<sub>q</sub></em> , the estimation of the modifier relevance <em>p</em>(<em>M<sub>t</sub></em> |<em>M<sub>q</sub></em> ) in Equation <a class="eqn" href="#eq7">7</a> can then be revised as:</p>
        <div class="table-responsive" id="eq8">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray} p(M_t|M_q)&amp;\propto &amp;p(M_q|M_t)\prod _{e\in M_q}p(M_e|M_t)\\\nonumber &amp;=&amp;p(M_q|M_t)\prod _{e\in M_q}\sum _{m\in M_e}p(m|M_t)\end{eqnarray}</span><br />
            <span class="equation-number">(9)</span>
          </div>
        </div>
        <p></p>
      </section>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Headword-Modifier Relevance</h3>
          </div>
        </header>
        <p>To estimate the headword-modifier relevance <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ) of the Equation <a class="eqn" href="#eq5">5</a>, we need to utilize the context of the modifiers in the document corpus. The reason of not applying the type taxonomy to estimate <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ) is that, due to ad-hoc query terms may be used in the query, modifiers of <em>M<sub>q</sub></em> may not present in any entity type of <em>T</em>. This will lead to the failure of find enough evidence to evaluate <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ) effectively. The headword-modifier relevance <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ) is therefore estimated using a language model:</p>
        <div class="table-responsive" id="eq9">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray} p(h_t|M_q)&amp;=&amp;\frac{p(M_q|h_t)p(h_t)}{p(M_q)}\\\nonumber &amp;\propto &amp; p(M_q|h_t)=\prod _{m\in M_q} p(m|h_t)^{n(m,M_q)}\\\nonumber &amp;=&amp;\prod _{m\in M_q} (\frac{p(h_t|m)p(m)}{p(h_t)})^{n(m,M_q)}\\\nonumber &amp;\propto &amp;\prod _{m\in M_q}p(h_t|m)^{n(m,M_q)}\end{eqnarray}</span><br />
            <span class="equation-number">(10)</span>
          </div>
        </div>where <em>p</em>(<em>M<sub>q</sub></em> |<em>h<sub>t</sub></em> ) is the probability of generating the query modifiers <em>M<sub>q</sub></em> from the headword <em>h<sub>t</sub></em> . The component <em>p</em>(<em>m</em>|<em>h<sub>t</sub></em> ) is the generative probability of the modifier <em>m</em> from the headword <em>h<sub>t</sub></em> , and the component <em>p</em>(<em>h<sub>t</sub></em> |<em>m</em>) is the generative probability of the headword <em>h<sub>t</sub></em> from the modifier <em>m</em>. The component <em>p</em>(<em>m</em>) is the probability of a modifier <em>m</em>, which is assumed to be uniformly distributed over all modifiers. The component <em>p</em>(<em>h<sub>t</sub></em> ) is also assumed to be uniformly distributed over all headwords. According to the Bayes’ Theorem, as shown in the above equation, we are therefore able to model the relevance <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ) using a language model. The estimation of <em>p</em>(<em>h<sub>t</sub></em> |<em>m</em>)is then the only component to be resolved.
        <p></p>
        <p>We propose to estimate <em>p</em>(<em>h<sub>t</sub></em> |<em>m</em>) from the text contexts of <em>m</em> and <em>h<sub>t</sub></em> . It is then estimated as:</p>
        <div class="table-responsive" id="eq10">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray} p(h_t|m)&amp;=&amp;p(h_t|ctx(m))\\\nonumber &amp;=&amp;(1-\lambda _3)\frac{n(h_t,ctx(m))}{\sum _{w} n(w,ctx(m))}+ \lambda _3 p(h_t|D)\end{eqnarray}</span><br />
            <span class="equation-number">(11)</span>
          </div>
        </div>where <em>ctx</em>(<em>m</em>) is the contexts of the modifier <em>m</em>, which is composed of the surrounding texts of <em>m</em>. The component <em>n</em>(<em>w</em>, <em>ctx</em>(<em>m</em>)) measures the frequency of the word <em>w</em> appearing in the context <em>ctx</em>(<em>m</em>). Correspondingly, <em>n</em>(<em>h<sub>t</sub></em> , <em>ctx</em>(<em>m</em>)) measures the frequency of entities which have a category with the headword <em>h<sub>t</sub></em> , presenting in the context <em>ctx</em>(<em>m</em>). The component <em>p</em>(<em>h<sub>t</sub></em> |<em>D</em>), as a smoothing factor with a weight <em>λ</em> <sub>3</sub>, represents the probability of generating <em>h<sub>t</sub></em> from the document corpus <em>D</em>, which is also evaluated based on the frequency of entities having a category of the headword <em>h<sub>t</sub></em> over all possible words that can be extracted from <em>D</em>. Equation <a class="eqn" href="#eq10">11</a> is therefore an application of the language model for estimating the generative probability of <em>h<sub>t</sub></em> in the contexts of modifier <em>m</em>. To estimate the probability <em>p</em>(<em>h<sub>t</sub></em> |<em>m</em>), we need build a context profile for each modifier in <em>M<sub>q</sub></em> . We first retrieve top relevant documents of <em>q</em> as the document set for building the context profile of its modifiers. The context profile <em>ctx</em>(<em>m</em>) is then the aggregation of contexts (sentences) where <em>m</em> appears in the selected document set.
        <p></p>
        <p>Note that the headword relevance <em>p</em>(<em>h<sub>t</sub></em> |<em>h<sub>q</sub></em> ) (in Equation <a class="eqn" href="#eq6">6</a>) allows us to find some relevant headwords of the query headword <em>h<sub>q</sub></em> . However, it is not enough to constrain the query intent without the support of the headword-modifier relevance <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ). For example, for the query <em>Works by Charles Rennie Mackintosh</em>, candidate headwords such as <em>Films, Novels, Stories, Books, Buildings, Structures, Architecture</em> will be the relevant headwords of <em>h<sub>q</sub></em> , in terms of <em>p</em>(<em>h<sub>t</sub></em> |<em>h<sub>q</sub></em> ). The headword-modifier relevance <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ) somehow makes up the shortcoming of the headword relevance <em>p</em>(<em>h<sub>t</sub></em> |<em>h<sub>q</sub></em> ) by also considering the relevance of headwords in the contexts of <em>M<sub>q</sub></em> .</p>
        <p>The estimation of the other headword-modifier relevance <em>p</em>(<em>M<sub>t</sub></em> |<em>h<sub>q</sub></em> ) in the Equation <a class="eqn" href="#eq5">5</a> is quite similar to that of <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ).</p>
        <div class="table-responsive" id="eq11">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray} p(M_t|h_q)&amp;=&amp;\prod _{m\in M_t} p(m|h_q)^{\frac{n(m,M_t)}{n(M_t)}}\\\nonumber &amp;=&amp;\prod _{m\in M_t} (\frac{p(h_q|m)p(m)}{p(h_q)})^{\frac{n(m,M_t)}{n(M_t)}}\\\nonumber &amp;\propto &amp;\prod _{m\in M_t}p(h_q|m)^{\frac{n(m,M_t)}{n(M_t)}}\end{eqnarray}</span><br />
            <span class="equation-number">(12)</span>
          </div>
        </div>where the component <em>n</em>(<em>M<sub>t</sub></em> ) is designed to normalize the headword-modifier relevance <em>p</em>(<em>M<sub>t</sub></em> |<em>h<sub>q</sub></em> ) so that it is not affected by the number of modifiers in <em>M<sub>t</sub></em> . The component <em>p</em>(<em>h<sub>q</sub></em> |<em>m</em>) is estimated using the same way of Equation <a class="eqn" href="#eq10">11</a>, by switching <em>h<sub>t</sub></em> as <em>h<sub>q</sub></em> . The major difference of computing <em>p</em>(<em>M<sub>t</sub></em> |<em>h<sub>q</sub></em> ) from computing <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ) is that, the documents used for building the context profiles of modifiers come from the Wikipedia documents of the entities having a type of <em>t</em>, instead of the top relevant results using <em>M<sub>q</sub></em> as query terms when computing <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ).
        <p></p>
      </section>
    </section>
    <section id="sec-14">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Experimental Setup</h2>
        </div>
      </header>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.1</span> Data Sets</h3>
          </div>
        </header>
        <p>We evaluate the performance of our method and that of the baselines in the settings of three entity search test sets:</p>
        <ul class="list-no-style">
          <li id="list4" label="•">INEX-XER 2009 (INEX): The INEX 2009 Entity Ranking track [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>] launched an entity search test set with 55 topics whose answers are Wikipedia entities. We ignore those target entity types explicitly given in INEX for each topic. An example query is <em>Alan Moore graphic <span style="text-decoration: underline;">novels</span> adapted to film.</em><br />
          </li>
          <li id="list5" label="•">SemSearch-LS (LS): This test set is used in the list search task at the 2011 Semantic Search challenge [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>]. Same as [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>], we use 43 out of 50 topics which have answers from Wikipedia. An example is <em>Apollo <span style="text-decoration: underline;">astronauts</span> who walked on the Moon.</em><br />
          </li>
          <li id="list6" label="•">TREC-Entity (TREC): It is built for the related entity finding task at the TREC 2009 Entity track [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>]. Same as [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>], we use 17 out of 20 topics which have answers from Wikipedia. An example query is <em><span style="text-decoration: underline;">Members</span> of the band Jefferson Airplane.</em><br />
          </li>
        </ul>
        <p>According to these test sets, a document collection of Wikipedia Corpus of 2008 edition is used in our experiments. It contains 2.67 millions entities with each of them having a Wikipedia document, 371,797 fine-grained entity categories, and 8,074,151 entity-to-category pairs. To extract entities from pure texts, we utilize an open source toolkit Wikipedia-Miner [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0022">22</a>], which takes the unstructured texts as inputs and detects mentions of the Wikipedia entities in the inputs using machine learning techniques.</p>
        <p>Although experiments of these test sets report the overall performance of entity search, the performance of category matching models can however be evaluated by substituting the category matching model of an entity search method with other alternatives.</p>
      </section>
      <section id="sec-16">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.2</span> Evaluation Metrics</h3>
          </div>
        </header>
        <p>We adopt the following metrics to evaluate the performance of the tested methods:</p>
        <ul class="list-no-style">
          <li id="list7" label="•"><em>p</em>@<em>k</em>: the percentage of relevant entities in the top-<em>k</em> results.<br /></li>
          <li id="list8" label="•"><em>R</em>-pre: the percentage of relevant entities in the top-<em>R</em> results, where <em>R</em> is the number of given correct results for a topic.<br /></li>
          <li id="list9" label="•">MRR: the reciprocal rank of a topic is the multiplicative inverse of the rank of the first correct answer. The mean reciprocal rank (MRR) is the average of the reciprocal ranks of all topics.<br /></li>
          <li id="list10" label="•">MAP: the Mean Average Precision over all topics in a test set. It is estimated as follows [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0020">20</a>]:
            <div class="table-responsive" id="Xeq2">
              <div class="display-equation">
                <span class="tex mytex">\begin{equation} MAP=\frac{1}{|Q|}\sum _{j=1}^{|Q|} \frac{1}{|M_{j}|}\sum _{i=1}^{|M_{j}|}p@R_{k} \end{equation}</span><br />
                <span class="equation-number">(13)</span>
              </div>
            </div>where Q is the topic set, <em>M<sub>j</sub></em> is the answer set of the query <em>j</em>, and <em>R<sub>k</sub></em> is the rank of the <em>k</em>th answer in the <em>M<sub>j</sub></em> .<br />
          </li>
          <li id="list11" label="•">xinfAP: an extended inferred AP incorporating non-random relevance judgments by employing stratified random sampling [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0030">30</a>]. In the evaluation of the INEX Entity Ranking track, it replaces the MAP as an official evaluation metric.<br />
          </li>
        </ul>
      </section>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.3</span> Baselines</h3>
          </div>
        </header>
        <p>Our method is compared with three baselines of entity search:</p>
        <p>BBR [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>]: It applies a term-centric category matching method. Both entities and queries are modeled using a term-based representation and a category-based representation. KL divergence is then applied to compute the probability of generating the term-based/category-based representation of a query, given the term-based/category-based representation of an entity. To build the category-based representation of a query, it applies a standard language model to estimate the relevance of entity categories to the query. The top-10 relevant entity categories are used to construct the category-based representation of the query.</p>
        <p>KK [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>]: A language model with Jelinek-mercer smoothing is applied to estimate the relevance between query terms and entity contexts for context matching. For category matching, it shows that, on the INEX test set, the title distance gives the best results on estimating the relevance between an entity category and a target entity type. It applies an entity-centric strategy to obtain target entity types. The top 50 relevant entities from the context matching model are used to vote for relevant categories. The derived top 2 relevant categories are taken as target entity types.</p>
        <p>CGS [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>]: It incorporates context matching, category matching, and result ranking for achieving a good performance of entity search. It however assumes that the target entity types are explicitly given. To compare with our method, we apply the learning-to-rank method proposed in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>] to find some relevant entity categories for each query. Still, the top 2 relevant categories are taken as the target entity types in our experiments.</p>
        <p>PBM (stands for patterned-based matching): This is our proposed method that also applies the same context matching model of CGS.</p>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.4</span> Parameter Setting</h3>
          </div>
        </header>
        <p>To estimate the parameters of our models as well as those of the compared solutions, we apply the Coordinate Ascent (CA) algorithm under the sum normalization and non-negativity constraints [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0021">21</a>] and directly optimize the MAP/xinfAP metric. The CA algorithm is a commonly used optimization technique, which iteratively optimizes a single parameter while holding all other parameters fixed. We use 5-fold cross validation for parameter tuning in each test set. For our method, we do not tune the parameters <em>λ</em> <sub>1</sub>, <em>λ</em> <sub>2</sub> and <em>λ</em> <sub>3</sub>, by setting them as <span class="inline-equation"><span class="tex">$\lambda _1=\lambda _2=\frac{1}{3}$</span></span> , and <em>λ</em> <sub>3</sub> = 0.5. When estimating <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ), we use top-20 relevant documents to build the profiles of modifiers. We focus on the setting of parameters <em>α</em> <sub>0</sub>, <em>α</em> <sub>1</sub>, <em>α</em> <sub>2</sub>, <em>α</em> <sub>3</sub> and <em>α</em> <sub>4</sub>. As <em>α</em> <sub>1</sub> + <em>α</em> <sub>2</sub> + <em>α</em> <sub>3</sub> + <em>α</em> <sub>4</sub> = 1.0 is required, we initialize them as [0.5, 1, 0, 0, 0] to run the CA algorithm with 3 random restarts.</p>
        <p>To measure the statistical significance, a two-tailed paired t-test is applied. We use the <sup>*</sup> to denote the difference at the 0.01 level and † to denote the difference at the 0.05 level.</p>
      </section>
    </section>
    <section id="sec-19">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Results</h2>
        </div>
      </header>
      <section id="sec-20">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.1</span> Research Questions</h3>
          </div>
        </header>
        <p>We address the following research questions:</p>
        <ul class="list-no-style">
          <li id="list12" label="•">
            <strong>RQ1</strong>: Can entity search performance be improved by exploiting the fine-grained Wikipedia entity categories using the proposed models of this work? (§<a class="sec" href="#sec-21">6.2</a>)<br />
          </li>
          <li id="list13" label="•">
            <strong>RQ2</strong>: Can the proposed pattern-based category matching method improve the performance of the baselines? (§<a class="sec" href="#sec-22">6.3</a>)<br />
          </li>
          <li id="list14" label="•">
            <strong>RQ3</strong>: How do the proposed method as well as the baselines perform on different test sets? (§<a class="sec" href="#sec-23">6.4</a>)<br />
          </li>
          <li id="list15" label="•">
            <strong>RQ4</strong>: How robust is our method with respect to different parameter settings? (§<a class="sec" href="#sec-24">6.5</a>)<br />
          </li>
          <li id="list16" label="•">
            <strong>RQ5</strong>: What are the impacts of entity search performance if the headword or entities cannot be accurately recognized from the query? (§<a class="sec" href="#sec-25">6.6</a>)<br />
          </li>
        </ul>
      </section>
      <section id="sec-21">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.2</span> Overall Performance</h3>
          </div>
        </header>
        <p>We derive a mixed test set by combining all the topics of the three test set, so the it finally contains 115 topics. Our <em>PBM</em> method is compared against the three baselines using the mixed test set. In addition, we also test three alternatives of our method: <em>PBM<sub>H</sub></em> , <em>PBM<sub>M</sub></em> , and <em>PBM</em> <sub><em>H</em>+<em>M</em></sub> . The <em>PBM<sub>H</sub></em> method only applies headword relevance (i.e., <em>α</em> <sub>1</sub> = 1); the <em>PBM<sub>M</sub></em> method only applies modifier relevance (i.e., <em>α</em> <sub>4</sub> = 1); the <em>PBM</em> <sub><em>H</em>+<em>M</em></sub> method applies both headword relevance and modifier relevance, but not the headword-modifier relevance (i.e., <em>α</em> <sub>1</sub> + <em>α</em> <sub>4</sub> = 1). The results are shown in Table <a class="tbl" href="#tab1">1</a>.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class="table-title">Performance comparison on the mixed test set. Significance is tested against the BBR baseline.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Models</th>
                <th style="text-align:center;" colspan="6">
                  INEX+LS+TREC Topics
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">p@5</th>
                <th style="text-align:center;">p@10</th>
                <th style="text-align:center;">p@20</th>
                <th style="text-align:center;">MRR</th>
                <th style="text-align:center;">R-pre</th>
                <th>MAP</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;"><em>BBR</em></td>
                <td style="text-align:center;">0.256</td>
                <td style="text-align:center;">0.243</td>
                <td style="text-align:center;">0.201</td>
                <td style="text-align:center;">0.350</td>
                <td style="text-align:center;">0.206</td>
                <td>0.202</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>KK</em></td>
                <td style="text-align:center;">0.231</td>
                <td style="text-align:center;">0.203</td>
                <td style="text-align:center;">0.164</td>
                <td style="text-align:center;">0.345</td>
                <td style="text-align:center;">0.186</td>
                <td>0.178</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>CGS</em></td>
                <td style="text-align:center;">0.179</td>
                <td style="text-align:center;">0.147</td>
                <td style="text-align:center;">0.131</td>
                <td style="text-align:center;">0.290</td>
                <td style="text-align:center;">0.117</td>
                <td>0.110</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>PBM<sub>H</sub></em></td>
                <td style="text-align:center;">0.332†</td>
                <td style="text-align:center;">0.301†</td>
                <td style="text-align:center;">0.248†</td>
                <td style="text-align:center;">0.441†</td>
                <td style="text-align:center;">0.263†</td>
                <td>0.232</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>PBM<sub>M</sub></em></td>
                <td style="text-align:center;">0.209</td>
                <td style="text-align:center;">0.213</td>
                <td style="text-align:center;">0.183</td>
                <td style="text-align:center;">0.296</td>
                <td style="text-align:center;">0.178</td>
                <td>0.164</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>PBM</em> <sub><em>H</em>+<em>M</em></sub></td>
                <td style="text-align:center;">0.356<sup>*</sup></td>
                <td style="text-align:center;">0.333<sup>*</sup></td>
                <td style="text-align:center;">0.272<sup>*</sup></td>
                <td style="text-align:center;">0.490<sup>*</sup></td>
                <td style="text-align:center;">0.289<sup>*</sup></td>
                <td>0.254<sup>*</sup></td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>PBM</em></td>
                <td style="text-align:center;"><strong>0.374</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.356</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.284</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.534</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.298</strong> <sup>*</sup></td>
                <td><strong>0.272</strong> <sup>*</sup></td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>The results of Table <a class="tbl" href="#tab1">1</a> show that <em>PBM</em> performs much better than the baselines, in terms of all metrics used. By comparing <em>PBM</em> with its alternatives, we may find that the headword relevance (<em>PBM<sub>H</sub></em> ) plays a more significant role than the modifier relevance (<em>PBM<sub>M</sub></em> ). However, by combining the individual components in the <em>PBM</em>, we are able to largely improve the search performance. This addresses the RQ1 that the proposed category matching method <em>PBM</em> does exploit more information from the fine-grained Wikipedia categories, to achieve a higher search performance than the baselines.</p>
      </section>
      <section id="sec-22">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.3</span> Improvements of Baselines</h3>
          </div>
        </header>
        <p>In this experiment, we address RQ2 by applying our category matching method to the baselines. There are two strategies to improve the baselines using <em>PBM</em>. Strategy 1 (labelled with “+”): only apply the <em>PBM</em> to find target entity types (top-2 relevant types in our experiments) for the baselines. Strategy 2 (labelled with “++”): use our category matching method (Equation <a class="eqn" href="#eq3">3</a>) to substitute the category matching methods of baselines. The substitution is easy for baselines because they all model context matching and category matching individually as two weighted probabilities. We also test the performance of the pure context matching method (labelled with “-”) of each baseline, so that the performance improvement of category matching methods can be easily identified. The results are shown in Table <a class="tbl" href="#tab2">2</a>. Significances are tested against the baselines BBR, KK and CGS respectively.</p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class="table-title">Performance comparison when applying PBM</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Models</th>
                <th style="text-align:center;" colspan="6">
                  INEX+LS+TREC Topics
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">p@5</th>
                <th style="text-align:center;">p@10</th>
                <th style="text-align:center;">p@20</th>
                <th style="text-align:center;">MRR</th>
                <th style="text-align:center;">R-pre</th>
                <th>MAP</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;"><em>BBR</em>-</td>
                <td style="text-align:center;">0.184</td>
                <td style="text-align:center;">0.177</td>
                <td style="text-align:center;">0.156</td>
                <td style="text-align:center;">0.312</td>
                <td style="text-align:center;">0.174</td>
                <td>0.151</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>BBR</em></td>
                <td style="text-align:center;">0.256</td>
                <td style="text-align:center;">0.243</td>
                <td style="text-align:center;">0.201</td>
                <td style="text-align:center;">0.350</td>
                <td style="text-align:center;">0.206</td>
                <td>0.202</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>BBR</em>+</td>
                <td style="text-align:center;">0.290</td>
                <td style="text-align:center;">0.267</td>
                <td style="text-align:center;">0.206</td>
                <td style="text-align:center;">0.418†</td>
                <td style="text-align:center;">0.231</td>
                <td>0.218</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>BBR</em>++</td>
                <td style="text-align:center;"><strong>0.367</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.308</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.251</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.506</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.275</strong> <sup>*</sup></td>
                <td><strong>0.253</strong> <sup>*</sup></td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>KK</em>-</td>
                <td style="text-align:center;">0.186</td>
                <td style="text-align:center;">0.179</td>
                <td style="text-align:center;">0.155</td>
                <td style="text-align:center;">0.322</td>
                <td style="text-align:center;">0.149</td>
                <td>0.152</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>KK</em></td>
                <td style="text-align:center;">0.231</td>
                <td style="text-align:center;">0.203</td>
                <td style="text-align:center;">0.164</td>
                <td style="text-align:center;">0.345</td>
                <td style="text-align:center;">0.186</td>
                <td>0.178</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>KK</em>+</td>
                <td style="text-align:center;">0.292†</td>
                <td style="text-align:center;">0.270<sup>*</sup></td>
                <td style="text-align:center;">0.216<sup>*</sup></td>
                <td style="text-align:center;">0.435<sup>*</sup></td>
                <td style="text-align:center;">0.223<sup>*</sup></td>
                <td>0.215<sup>*</sup></td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>KK</em>++</td>
                <td style="text-align:center;"><strong>0.329</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.296</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.234</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.475</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.255</strong> <sup>*</sup></td>
                <td><strong>0.234</strong> <sup>*</sup></td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>CGS</em>-</td>
                <td style="text-align:center;">0.111</td>
                <td style="text-align:center;">0.110</td>
                <td style="text-align:center;">0.107</td>
                <td style="text-align:center;">0.243</td>
                <td style="text-align:center;">0.107</td>
                <td>0.099</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>CGS</em></td>
                <td style="text-align:center;">0.179</td>
                <td style="text-align:center;">0.147</td>
                <td style="text-align:center;">0.131</td>
                <td style="text-align:center;">0.290</td>
                <td style="text-align:center;">0.117</td>
                <td>0.110</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>CGS</em>+</td>
                <td style="text-align:center;">0.317<sup>*</sup></td>
                <td style="text-align:center;">0.290<sup>*</sup></td>
                <td style="text-align:center;">0.231<sup>*</sup></td>
                <td style="text-align:center;">0.427<sup>*</sup></td>
                <td style="text-align:center;">0.232<sup>*</sup></td>
                <td>0.217<sup>*</sup></td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>CGS</em>++</td>
                <td style="text-align:center;"><strong>0.374</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.356</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.284</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.534</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.298</strong> <sup>*</sup></td>
                <td><strong>0.272</strong> <sup>*</sup></td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>As the results show in Table <a class="tbl" href="#tab2">2</a>, Strategy 1 (“+”) does help to improve the search performance of each corresponding baseline (without notations). Strategy 2 (“++”) further improves the performance of Strategy 1. All the baselines benefit from the usage of our category matching method. Note that <em>CGS</em>++ is exactly our proposed method <em>PBM</em> that applies the context matching of <em>CGS</em> as its context matching component. We may notice that the improvement of <em>CGS</em> is much larger than that of <em>BBR</em> and <em>KK</em>. This is mainly because the context matching model <em>CGS</em>- performs worse than the other two context matching models (<em>BBR</em>- and <em>KK</em>-). The <em>CGS</em> applies a document model for context matching, and the other two baselines build their context matching model more like a candidate model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>]. It has been shown that [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>] although pure document model for context matching performs worse than the candidate model, it however outperforms the others when combining with category matching model. This is because candidate model benefits from the implicit category information embedded in the contexts of entities. When comparing <em>CGS</em>+ with <em>CGS</em>, we find that <em>CGS</em>+ significantly outperforms <em>CGS</em>. Their only difference is the methods used for finding target entity types. Method <em>CGS</em>+ applies <em>PBM</em> to help to find many fine-grained target entity types. Method <em>CGS</em> however applies the learning-to-rank method [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>], which is assumed to be the-state-of-art method for finding target entity types. It however usually finds general entity types, which are not that beneficial to the overall entity search performance.</p>
      </section>
      <section id="sec-23">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.4</span> Breakdown by Query Subsets</h3>
          </div>
        </header>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class="table-title">Performance comparison on INEX-XER 2009</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Models</th>
                <th style="text-align:center;" colspan="6">
                  INEX-XER 2009 Topics
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">p@5</th>
                <th style="text-align:center;">p@10</th>
                <th style="text-align:center;">p@20</th>
                <th style="text-align:center;">MRR</th>
                <th style="text-align:center;">R-pre</th>
                <th>xinfAP</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;"><em>BBR</em></td>
                <td style="text-align:center;">0.338</td>
                <td style="text-align:center;">0.324</td>
                <td style="text-align:center;">0.269</td>
                <td style="text-align:center;">0.413</td>
                <td style="text-align:center;">0.255</td>
                <td>0.237</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>KK</em></td>
                <td style="text-align:center;">0.269</td>
                <td style="text-align:center;">0.271</td>
                <td style="text-align:center;">0.241</td>
                <td style="text-align:center;">0.372</td>
                <td style="text-align:center;">0.223</td>
                <td>0.197</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>CGS</em></td>
                <td style="text-align:center;">0.255</td>
                <td style="text-align:center;">0.204</td>
                <td style="text-align:center;">0.179</td>
                <td style="text-align:center;">0.392</td>
                <td style="text-align:center;">0.171</td>
                <td>0.138</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>PBM</em></td>
                <td style="text-align:center;"><strong>0.506</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.495</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.416</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.639</strong> <sup>*</sup></td>
                <td style="text-align:center;"><strong>0.386</strong> <sup>*</sup></td>
                <td><strong>0.356</strong> <sup>*</sup></td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="table-responsive" id="tab4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class="table-title">Performance comparison on SemSearch-LS</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Models</th>
                <th style="text-align:center;" colspan="6">
                  SemSearch-LS Topics
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">p@5</th>
                <th style="text-align:center;">p@10</th>
                <th style="text-align:center;">p@20</th>
                <th style="text-align:center;">MRR</th>
                <th style="text-align:center;">R-pre</th>
                <th>MAP</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;"><em>BBR</em></td>
                <td style="text-align:center;">0.205</td>
                <td style="text-align:center;">0.170</td>
                <td style="text-align:center;">0.147</td>
                <td style="text-align:center;">0.344</td>
                <td style="text-align:center;">0.176</td>
                <td>0.184</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>KK</em></td>
                <td style="text-align:center;">0.195</td>
                <td style="text-align:center;">0.174</td>
                <td style="text-align:center;">0.144</td>
                <td style="text-align:center;">0.374</td>
                <td style="text-align:center;">0.183</td>
                <td>0.182</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>CGS</em></td>
                <td style="text-align:center;">0.140</td>
                <td style="text-align:center;">0.123</td>
                <td style="text-align:center;">0.100</td>
                <td style="text-align:center;">0.258</td>
                <td style="text-align:center;">0.085</td>
                <td>0.088</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>PBM</em></td>
                <td style="text-align:center;"><strong>0.326</strong>†</td>
                <td style="text-align:center;"><strong>0.290</strong>†</td>
                <td style="text-align:center;"><strong>0.216</strong></td>
                <td style="text-align:center;"><strong>0.475</strong>†</td>
                <td style="text-align:center;"><strong>0.254</strong></td>
                <td><strong>0.237</strong></td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="table-responsive" id="tab5">
          <div class="table-caption">
            <span class="table-number">Table 5:</span> <span class="table-title">Performance comparison on TREC-Entity</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Models</th>
                <th style="text-align:center;" colspan="6">
                  TREC-Entity Topics
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">p@5</th>
                <th style="text-align:center;">p@10</th>
                <th style="text-align:center;">p@20</th>
                <th style="text-align:center;">MRR</th>
                <th style="text-align:center;">R-pre</th>
                <th>MAP</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;"><em>BBR</em></td>
                <td style="text-align:center;">0.129</td>
                <td style="text-align:center;">0.176</td>
                <td style="text-align:center;">0.121</td>
                <td style="text-align:center;">0.167</td>
                <td style="text-align:center;">0.121</td>
                <td>0.133</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>KK</em></td>
                <td style="text-align:center;">0.118</td>
                <td style="text-align:center;">0.112</td>
                <td style="text-align:center;">0.091</td>
                <td style="text-align:center;">0.259</td>
                <td style="text-align:center;">0.134</td>
                <td>0.141</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>CGS</em></td>
                <td style="text-align:center;">0.059</td>
                <td style="text-align:center;">0.047</td>
                <td style="text-align:center;">0.068</td>
                <td style="text-align:center;">0.097</td>
                <td style="text-align:center;">0.030</td>
                <td>0.068</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>PBM</em></td>
                <td style="text-align:center;"><strong>0.201</strong></td>
                <td style="text-align:center;"><strong>0.213</strong></td>
                <td style="text-align:center;"><strong>0.175</strong></td>
                <td style="text-align:center;"><strong>0.279</strong></td>
                <td style="text-align:center;"><strong>0.185</strong></td>
                <td><strong>0.196</strong></td>
              </tr>
            </tbody>
          </table>
        </div>
        <figure id="fig1">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186074/images/www2018-83-fig1.jpg" class="img-responsive" alt="Figure 1" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span> <span class="figure-title">Topic-level difference in xinfAP for INEX, and in MAP for LS and TREC.</span>
          </div>
        </figure>
        <p>We then compare <em>PBM</em> with baselines on three individual test sets to address RQ3. On each test set, we perform a 5-fold cross validation for parameter tuning. The results for three test sets are shown in Table <a class="tbl" href="#tab3">3</a>-<a class="tbl" href="#tab5">5</a> respectively. Significance is all tested against BBR. According to the results, we find that <em>PBM</em> consistently outperforms the other baselines on the three test sets. Comparatively, the advantage of <em>PBM</em> is more prominent on the INEX test set. This is because the INEX test set is created directly based on the Wikipedia corpus. The other two test sets are not built on top of Wikipedia, and many of their result entities are short of relevant Wikipedia categories.</p>
        <p>Figure <a class="fig" href="#fig1">1</a> illustrates the per-topic difference by comparing <em>PBM</em> against two baselines <em>BBR</em> and <em>KK</em>. It can be find that <em>PBM</em> perform better than the other two baselines on a large number of topics than vice versa, with the most significance difference achieved by the INEX test set. We select some examples from which the advantage of <em>PBM</em> can be observed. For topic <em>operating <span style="text-decoration: underline;">systems</span> to which Steve Jobs related</em>, the most relevant entity type retrieved by <em>PBM</em> is <em>Apple inc. operating <span style="text-decoration: underline;">systems</span></em> where the expanded modifier <em>Apple inc.</em> is discovered from the categories of the entity <em>steve jobs</em>. A good example of headword relevance is the match of a query <em><span style="text-decoration: underline;">astronauts</span> who landed on the moon</em> with a type <em><span style="text-decoration: underline;">people</span> who have walked on the moon</em>. For topic <em>Nordic <span style="text-decoration: underline;">authors</span> who are known for children's literature</em>, three most relevant entity types are <em>Swedish children's <span style="text-decoration: underline;">writers</span></em> , <em>Danish children's <span style="text-decoration: underline;">writers</span></em> and <em>Norwegian children's <span style="text-decoration: underline;">writers</span></em> , which all benefit from the way of estimating headword relevance and modifier relevance. However, <em>PBM</em> sometimes performs worse when the identified headword is a tailed headword or it does not appear in the type taxonomy, e.g., <em>axis <span style="text-decoration: underline;">powers</span> of world war ii</em>.</p>
        <figure id="fig2">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186074/images/www2018-83-fig2.jpg" class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span> <span class="figure-title">Impacts of parameters</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-24">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.5</span> Impacts of Parameter Settings</h3>
          </div>
        </header>
        <p>To study the impacts of parameters, we first fix <em>α</em> <sub>1 − 4</sub> as [0.3, 0.1, 0.4, 0.2] and adjust <em>α</em> <sub>0</sub>, the impacts of <em>α</em> <sub>0</sub> on different test sets are then plotted in Figure <a class="fig" href="#fig2">2</a>(a). It shows that the best performance on various test sets is achieved when <em>α</em> <sub>0</sub> is set between 0.6-0.8, which indicates that category matching is more important than context matching. We then fix <em>α</em> <sub>0</sub> as 0.7, and optimize <em>α</em> <sub>1 − 4</sub> for individual test sets using the CA algorithm [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0021">21</a>]. The derived parameter settings for different test sets are shown in Figure <a class="fig" href="#fig2">2</a>(b). We can find that, in general, <em>α</em> <sub>1</sub> and <em>α</em> <sub>3</sub> are assigned more weights than <em>α</em> <sub>2</sub> and <em>α</em> <sub>4</sub>. This is reasonable because they are used to estimate the relevance of the headwords, i.e., <em>α</em> <sub>1</sub> for <em>p</em>(<em>h<sub>t</sub></em> |<em>h<sub>q</sub></em> ), and <em>α</em> <sub>3</sub> for <em>p</em>(<em>h<sub>t</sub></em> |<em>M<sub>q</sub></em> ). We finally fix the parameters <em>α</em> <sub>0 − 4</sub> in the mixed test set, and adjust the parameters <em>λ</em> <sub>1 − 3</sub>. When adjusting the parameter <em>λ</em> <sub>1</sub> (or <em>λ</em> <sub>2</sub>), we set the parameter <em>λ</em> <sub>2</sub> (or <em>λ</em> <sub>1</sub>) as 0.1, so that it can be tuned in a large range. The results in Figure <a class="fig" href="#fig2">2</a>(c) show that the impacts of <em>λ</em> <sub>1 − 3</sub> are not obvious. We therefore apply their default values in all the other experiments.</p>
      </section>
      <section id="sec-25">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.6</span> Impacts of Headwords and Entities</h3>
          </div>
        </header>
        <p>The performance of <em>PBM</em> will be affected if headwords and entities cannot be recognized from the queries which are more ad-hoc than entity categories. We conduct two experiments by assuming that headwords and entities are not extracted from the queries respectively. Table <a class="tbl" href="#tab6">6</a> shows the results. It can be observed that when headword detection fails, the MAP of <em>PBM</em> drops from 0.272 to 0.234. It is still better than that of the baselines in Table <a class="tbl" href="#tab1">1</a> (e.g., 0.202 for <em>BBR</em>). In this case, the headword relevance and a headword-modifier relevance (<em>p</em>(<em>M<sub>t</sub></em> |<em>h<sub>q</sub></em> )) cannot be estimated. However, we are still able to estimate category matching relevance (in Equation <a class="eqn" href="#eq5">5</a>) using the other two components. This makes our method robust in terms of headword recognition. The results also show that when entity recognition fails, the impact is less than that of the headword failure. This is reasonable because it only affects the query expansion of the modifier relevance in Equation <a class="eqn" href="#eq8">9</a>.</p>
        <p>We also test two alternatives of <em>PBM</em> by substituting its headword relevance and modifier relevance using the similarities of headword embeddings and modifier (terms/entities) embeddings respectively. The relevance model of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>] is applied for evaluating the relevance of modifier embeddings. The results in Table <a class="tbl" href="#tab6">6</a> show that their performance is not as good as the proposed <em>PBM</em> method that exploits the type taxonomy for addressing the conceptual/vocabulary gap.</p>
        <div class="table-responsive" id="tab6">
          <div class="table-caption">
            <span class="table-number">Table 6:</span> <span class="table-title">Impacts of headwords and entities</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Models</th>
                <th style="text-align:center;" colspan="6">
                  INEX+LS+TREC Topics
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">p@5</th>
                <th style="text-align:center;">p@10</th>
                <th style="text-align:center;">p@20</th>
                <th style="text-align:center;">MRR</th>
                <th style="text-align:center;">R-pre</th>
                <th>MAP</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">no headword</td>
                <td style="text-align:center;">0.313</td>
                <td style="text-align:center;">0.292</td>
                <td style="text-align:center;">0.237</td>
                <td style="text-align:center;">0.445</td>
                <td style="text-align:center;">0.250</td>
                <td>0.234</td>
              </tr>
              <tr>
                <td style="text-align:center;">no entities</td>
                <td style="text-align:center;">0.336</td>
                <td style="text-align:center;">0.315</td>
                <td style="text-align:center;">0.256</td>
                <td style="text-align:center;">0.454</td>
                <td style="text-align:center;">0.269</td>
                <td>0.242</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>PBM</em></td>
                <td style="text-align:center;"><strong>0.374</strong></td>
                <td style="text-align:center;"><strong>0.356</strong></td>
                <td style="text-align:center;"><strong>0.284</strong></td>
                <td style="text-align:center;"><strong>0.534</strong></td>
                <td style="text-align:center;"><strong>0.298</strong></td>
                <td><strong>0.272</strong></td>
              </tr>
              <tr>
                <td style="text-align:center;">headword embedding</td>
                <td style="text-align:center;">0.327</td>
                <td style="text-align:center;">0.317</td>
                <td style="text-align:center;">0.260</td>
                <td style="text-align:center;">0.450</td>
                <td style="text-align:center;">0.271</td>
                <td>0.245</td>
              </tr>
              <tr>
                <td style="text-align:center;">modifier embedding</td>
                <td style="text-align:center;">0.353</td>
                <td style="text-align:center;">0.328</td>
                <td style="text-align:center;">0.267</td>
                <td style="text-align:center;">0.495</td>
                <td style="text-align:center;">0.280</td>
                <td>0.255</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
    </section>
    <section id="sec-26">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span> Conclusion</h2>
        </div>
      </header>
      <p>We show that entity search, especially the category matching part of entity search, benefits a lot from the usage of pattern-based query-to-category matching techniques by modeling both queries and entity categories as a headword plus some modifiers. Such a headword-and-modifier model allows us to exploit the benefits of fine-grained Wikipedia categories, and to design a unified model of category matching where the pattern matching of headwords and modifiers is holistically constructed and further decomposed into headword relevance, modifier relevance, as well as headword-modifier relevance. By exploiting Wikipedia type taxonomy for addressing the vocabulary gap of concepts/entities in the query, we are able to effectively utilize the rich semantics in fine-grained Wikipedia categories.</p>
    </section>
    <section id="sec-27">
      <header>
        <div class="title-info">
          <h2><span class="section-number">8</span> Acknowledgments</h2>
        </div>
      </header>
      <p>Yueguo Chen is supported by the National Science Foundation of China under grants No. 61472426, U1711261, 61432006, and the State Visiting Scholar Funds from the China Scholarship Council under Grant Number 201706365018. Denghao Ma is supported by the Outstanding Innovative Talents Cultivation Funded Programs 2017 of Renmin University of China and the State Scholarship Fund from China Scholarship Council under Grant Number 201706360309. Kevin Chang is supported by a gift from Huawei.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Krisztian Balog, Leif Azzopardi, and Maarten de Rijke. 2006. Formal models for expert finding in enterprise corpora. In <em><em>SIGIR 2006: Proceedings of the 29th ACM SIGIR</em></em> . ACM, 43–50.</li>
        <li id="BibPLXBIB0002" label="[2]">Krisztian Balog, Marc Bron, and Maarten de Rijke. 2011. Query modeling for entity search based on terms, categories, and examples. <em><em>ACM Trans. Inf. Syst.</em></em> 29, 4 (2011), 22.</li>
        <li id="BibPLXBIB0003" label="[3]">Krisztian Balog, Arjen&nbsp;P. de Vries, Pavel Serdyukov, Paul Thomas, and Thijs Westerveld. 2009. Overview of the TREC 2009 Entity Track. In <em><em>Proceedings of The 18th TREC</em></em> .</li>
        <li id="BibPLXBIB0004" label="[4]">Krisztian Balog and Robert Neumayer. 2012. Hierarchical target type identification for entity-oriented queries. In <em><em>21st ACM CIKM</em></em> . ACM, 2391–2394.</li>
        <li id="BibPLXBIB0005" label="[5]">Krisztian Balog and Robert Neumayer. 2013. A test collection for entity search in DBpedia. In <em><em>The 36th ACM SIGIR</em></em> . ACM, 737–740.</li>
        <li id="BibPLXBIB0006" label="[6]">Roi Blanco, Harry Halpin, Daniel M&nbsp;Herzig, Peter Mika, Jeffrey Pound, David R&nbsp;Cheriton, and Henry Thompson. 2017. Entity Search Evaluation over Structured Web Data. In <em><em>Proceedings of the 1st International Workshop on EOS</em></em> . 65–71.</li>
        <li id="BibPLXBIB0007" label="[7]">Marc Bron, Krisztian Balog, and Maarten de Rijke. 2013. Example Based Entity Search in the Web of Data. In <em><em>Advances in Information Retrieval - 35th ECIR</em></em> . 392–403.</li>
        <li id="BibPLXBIB0008" label="[8]">Yueguo Chen, Lexi Gao, Shuming Shi, Xiaoyong Du, and Ji-Rong Wen. 2014. Improving Context and Category Matching for Entity Search. In <em><em>Proceedings of the 28th AAAI</em></em> . 16–22.</li>
        <li id="BibPLXBIB0009" label="[9]">Marek Ciglan, Kjetil Nørvåg, and Ladislav Hluchý. 2012. The SemSets model for ad-hoc semantic list search. In <em><em>Proceedings of the 21st WWW</em></em> . 131–140.</li>
        <li id="BibPLXBIB0010" label="[10]">Nick Craswell, Arjen&nbsp;P. de Vries, and Ian Soboroff. 2005. Overview of the TREC 2005 Enterprise Track. In <em><em>Proceedings of the 14th TREC</em></em> .</li>
        <li id="BibPLXBIB0011" label="[11]">Arjen&nbsp;P. de Vries, Anne-Marie Vercoustre, James&nbsp;A. Thom, Nick Craswell, and Mounia Lalmas. 2007. Overview of the INEX 2007 Entity Ranking Track. In <em><em>Focused Access to XML Documents, 6th Workshop of INEX</em></em> . 245–251.</li>
        <li id="BibPLXBIB0012" label="[12]">Gianluca Demartini, Arjen&nbsp;P. de Vries, Tereza Iofciu, and Jianhan Zhu. 2008. Overview of the INEX 2008 Entity Ranking Track. In <em><em>Advances in Focused Retrieval, 7th Workshop of the INEX</em></em> . 243–252.</li>
        <li id="BibPLXBIB0013" label="[13]">Gianluca Demartini, Tereza Iofciu, and Arjen&nbsp;P. de Vries. 2009. Overview of the INEX 2009 Entity Ranking Track. In <em><em>Focused Retrieval and Evaluation, 8th Workshop of INEX</em></em> . 254–264.</li>
        <li id="BibPLXBIB0014" label="[14]">Darío Garigliotti and Krisztian Balog. 2017. On Type-Aware Entity Retrieval. In <em><em>Proceedings of the ACM SIGIR ICTIR</em></em> . ACM, 27–34.</li>
        <li id="BibPLXBIB0015" label="[15]">Darío Garigliotti, Faegheh Hasibi, and Krisztian Balog. 2017. Target Type Identification for Entity-Bearing Queries. In <em><em>Proceedings of the 40th ACM SIGIR</em></em> . ACM, 845–848.</li>
        <li id="BibPLXBIB0016" label="[16]">Rianne Kaptein and Jaap Kamps. 2013. Exploiting the category structure of Wikipedia for entity ranking. <em><em>Artif. Intell.</em></em> 194(2013), 111–129.</li>
        <li id="BibPLXBIB0017" label="[17]">Rianne Kaptein, Pavel Serdyukov, Arjen&nbsp;P. de Vries, and Jaap Kamps. 2010. Entity ranking using Wikipedia as a pivot. In <em><em>Proceedings of the 19th ACM CIKM</em></em> . ACM, 69–78.</li>
        <li id="BibPLXBIB0018" label="[18]">Tom Kenter and Maarten de Rijke. 2015. Short Text Similarity with Word Embeddings. In <em><em>Proceedings of the 24th ACM CIKM</em></em> . ACM, 1411–1420.</li>
        <li id="BibPLXBIB0019" label="[19]">Vanessa López, Christina Unger, Philipp Cimiano, and Enrico Motta. 2013. Evaluating question answering over linked data. <em><em>J. Web Sem.</em></em> 21(2013), 3–13.</li>
        <li id="BibPLXBIB0020" label="[20]">Christopher&nbsp;D. Manning, Prabhakar Raghavan, and Hinrich Schütze. 2008. <em><em>Introduction to information retrieval</em></em> . Cambridge University Press.</li>
        <li id="BibPLXBIB0021" label="[21]">Donald Metzler and W.&nbsp;Bruce Croft. 2007. Linear feature-based models for information retrieval. <em><em>Inf. Retr.</em></em> 10, 3 (2007), 257–274.</li>
        <li id="BibPLXBIB0022" label="[22]">David&nbsp;N. Milne and Ian&nbsp;H. Witten. 2008. Learning to link with wikipedia. In <em><em>Proceedings of the 17th ACM CIKM</em></em> . ACM, 509–518.</li>
        <li id="BibPLXBIB0023" label="[23]">Fedor Nikolaev, Alexander Kotov, and Nikita Zhiltsov. 2016. Parameterized Fielded Term Dependence Models for Ad-hoc Entity Retrieval from Knowledge Graph. In <em><em>Proceedings of the 39th SIGIR</em></em> . 435–444.</li>
        <li id="BibPLXBIB0024" label="[24]">Madhu Ramanathan, Srikant Rajagopal, S.&nbsp;Venkatesh Karthik, Meenakshi&nbsp;Sundaram Murugeshan, and Saswati Mukherjee. 2009. A Recursive Approach to Entity Ranking and List Completion Using Entity Determining Terms, Qualifiers and Prominent n-Grams. In <em><em>Focused Retrieval and Evaluation, 8th Workshop of the INEX</em></em> . 292–302.</li>
        <li id="BibPLXBIB0025" label="[25]">Lev-Arie Ratinov and Dan Roth. 2009. Design Challenges and Misconceptions in Named Entity Recognition. In <em><em>Proceedings of the 13th CoNLL</em></em> . 147–155.</li>
        <li id="BibPLXBIB0026" label="[26]">Alan Ritter, Sam Clark, Mausam, and Oren Etzioni. 2011. Named Entity Recognition in Tweets: An Experimental Study. In <em><em>Proceedings of the 2011 EMNLP</em></em> . 1524–1534.</li>
        <li id="BibPLXBIB0027" label="[27]">Young-In Song, Kyoung-Soo Han, Sang-Bum Kim, So-Young Park, and Hae-Chang Rim. 2008. A novel retrieval approach reflecting variability of syntactic phrase representation. <em><em>J. Intell. Inf. Syst.</em></em> 31, 3 (2008), 265–286.</li>
        <li id="BibPLXBIB0028" label="[28]">Qiuyue Wang, Jaap Kamps, Georgina&nbsp;Ramírez Camps, Maarten Marx, Anne Schuth, Martin Theobald, Sairam Gurajada, and Arunav Mishra. 2012. Overview of the INEX 2012 Linked Data Track. In <em><em>CLEF 2012 Evaluation Labs and Workshop, Online Working Notes</em></em> .</li>
        <li id="BibPLXBIB0029" label="[29]">Zhongyuan Wang, Haixun Wang, and Zhirui Hu. 2014. Head, modifier, and constraint detection in short texts. In <em><em>30th IEEE ICDE</em></em> . 280–291.</li>
        <li id="BibPLXBIB0030" label="[30]">Emine Yilmaz, Evangelos Kanoulas, and Javed&nbsp;A. Aslam. 2008. A simple and efficient sampling method for estimating AP and NDCG. In <em><em>Proceedings of the 31st ACM SIGIR</em></em> . ACM, 603–610.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>⁎</sup></a>Corresponding author.</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&nbsp;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3178876.3186074">https://doi.org/10.1145/3178876.3186074</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
