<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>Conversational Query Understanding Using Sequence to Sequence Modeling</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main">  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">Conversational Query Understanding Using Sequence to Sequence Modeling</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author">     <span class="givenName">Gary</span>     <span class="surName">Ren</span>,     Microsoft Bing Core Relevance, Sunnyvale, California, <a href="mailto:gren@microsoft.com">gren@microsoft.com</a>    </div>    <div class="author">     <span class="givenName">Xiaochuan</span>     <span class="surName">Ni</span>,     Microsoft Bing Core Relevance, Sunnyvale, California, <a href="mailto:xiaon@microsoft.com">xiaon@microsoft.com</a>    </div>    <div class="author">     <span class="givenName">Manish</span>     <span class="surName">Malik</span>,     Microsoft Bing Core Relevance, Sunnyvale, California, <a href="mailto:manisma@microsoft.com">manisma@microsoft.com</a>    </div>    <div class="author">     <span class="givenName">Qifa</span>     <span class="surName">Ke</span>,     Microsoft Bing Core Relevance, Sunnyvale, California, <a href="mailto:qke@microsoft.com">qke@microsoft.com</a>    </div>                    </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3178876.3186083" target="_blank">https://doi.org/10.1145/3178876.3186083</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>Understanding conversations is crucial to enabling conversational search in technologies such as chatbots, digital assistants, and smart home devices that are becoming increasingly popular. Conventional search engines are powerful at answering open domain queries but are mostly capable of stateless search. In this paper, we define a conversational query as a query that depends on the context of the current conversation, and we formulate the conversational query understanding problem as context-aware query reformulation, where the goal is to reformulate the conversational query into a search engine friendly query in order to satisfy users&#x2019; information needs in conversational settings. Such context-aware query reformulation problem lends itself to sequence to sequence modeling. We present a large scale open domain dataset of conversational queries and various sequence to sequence models that are learned from this dataset. The best model correctly reformulates over half of all conversational queries, showing the potential of sequence to sequence modeling for this task.</small>    </p>    </div>    <div class="CCSconcepts">    <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Computing methodologies </strong>&#x2192; <strong>Discourse, dialogue and pragmatics;</strong> <em>Artificial intelligence;</em> <em>Natural language processing;</em></small> </p>    </div>    <div class="classifications">    <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Search; deep learning; conversations; query understanding; sequence to sequence</small>     </span>    </div>    <br/>    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Gary Ren, Xiaochuan Ni, Manish Malik, and Qifa Ke. 2018. Conversational Query Understanding Using Sequence to Sequence Modeling. In <em>WWW 2018: The 2018 Web Conference,</em>       <em>April 23&#x2013;27, 2018 (WWW 2018),</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 10 Pages. <a href="https://doi.org/10.1145/3178876.3186083" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3178876.3186083</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-5">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>    </div>    </header>    <p>The recent rise of technologies such as chatbots, digital personal assistants, and smart home devices [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>] has led to much more conversational interactions between humans and machines than ever before. In conversations, humans naturally ask questions that depend on the context of the current conversation. A basic example is asking &#x201D;When was California founded?&#x201D; followed by &#x201D;Who is its governor?&#x201D; and &#x201D;What is the population?&#x201D;, where both the follow up questions refer to California. For this paper, we define a conversational query to be a query that depends on the context of the current conversation, and the query can be either a natural language question or a traditional keyword query. Some more examples of conversational queries can be seen in Table <a class="tbl" href="#tab1">1</a>.</p>    <div class="table-responsive" id="tab1">    <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Examples of conversational queries.</span>    </div>    <table class="table"> 			 <thead>      <tr>       <th style="text-align:left;">       <strong>Previous query</strong>       </th>       <th style="text-align:left;">       <strong>Current conversational query</strong>       </th>       <th style="text-align:left;">       <strong>Current conversational query including context</strong>       </th>      </tr> 			 </thead>     <tbody>      <tr>       <td style="text-align:left;">when was California founded?</td>       <td style="text-align:left;">who is its governor?</td>       <td style="text-align:left;">who is California&#x0027;s governor?</td>      </tr>      <tr>       <td style="text-align:left;">California</td>       <td style="text-align:left;">population in 1990</td>       <td style="text-align:left;">population of California in 1990</td>      </tr>      <tr>       <td style="text-align:left;">Space Needle Seattle</td>       <td style="text-align:left;">its mayor</td>       <td style="text-align:left;">Seattle&#x0027;s mayor</td>      </tr>      <tr>       <td style="text-align:left;">how tall is Kobe Bryant?</td>       <td style="text-align:left;">what about Lebron James?</td>       <td style="text-align:left;">how tall is Lebron James?</td>      </tr>      <tr>       <td style="text-align:left;">when was the last summer Olympics?</td>       <td style="text-align:left;">and the winter one?</td>       <td style="text-align:left;">when was the last winter Olympics?</td>      </tr>      <tr>       <td style="text-align:left;">animals that live in Asia?</td>       <td style="text-align:left;">and are endangered?</td>       <td style="text-align:left;">animals that live in Asia and are endangered?</td>      </tr>      <tr>       <td style="text-align:left;">similarities between bacteria and viruses</td>       <td style="text-align:left;">differences</td>       <td style="text-align:left;">differences between bacteria and viruses</td>      </tr>     </tbody>    </table>    </div>    <p>Humans use this type of questions in conversations because it is tedious to continuously repeat the context and because we can maintain context and understand these questions. Therefore, users also naturally issue conversational queries when interacting with conversational technologies and expect these technologies to understand them.</p>    <p>However, information retrieval and question answering systems have traditionally been designed for stateless or standalone queries, and existing conversational query understanding capabilities are very limited. For even the simple aforementioned example about California, neither of two popular commercial search engines was able to correctly understand both the follow up queries (as of October 23, 2017).</p>    <p>Therefore, we want to improve query understanding for conversational search, by tackling the task of conversational query understanding (referred to as CQU from now on), which we formulate as a context-aware query reformulation task that consists of determining 1) whether or not a query depends on the previous context, and 2) if so, how to reformulate that query to include the necessary context. This will enable conversational queries to be reformulated to more search friendly standalone queries that can be understood by search engines or any other IR/QnA system.</p>    <p>Since we are targeting the open domain search scenario, our goal is CQU that is also open domain and can handle a wide variety of queries, both in terms of topic and structure. This is a major challenge of this open domain CQU task. Other challenges include: handling different types of context (Table <a class="tbl" href="#tab1">1</a> shows that the context to be maintained can be an entity, concept, question, etc.); knowing when to reformulate (e.g. &#x201D;it&#x201D; is not always referring to previous context); and knowing which part of the context to use (e.g. using &#x201D;Seattle&#x201D; instead of &#x201D;Space Needle&#x201D; for &#x201D;its mayor&#x201D;). It is infeasible for a rule based solution to address all of these challenges, therefore we sought to create a suitable dataset and apply machine learning. The main contributions of our work are:</p>    <ol class="list-no-style">    <li id="list1" label="(1)">Defining and presenting the task of CQU.<br/></li>    <li id="list2" label="(2)">First open domain and large scale dataset of conversational queries.<br/></li>    <li id="list3" label="(3)">Novel sequence to sequence based model for CQU.<br/></li>    <li id="list4" label="(4)">Demonstrating the potential of deep learning for CQU.<br/></li>    </ol>   </section>   <section id="sec-6">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>    </div>    </header>    <p>For conversational queries that include an anaphora, coreference resolution is a related problem. Coreference resolution seeks to resolve an anaphora to the term(s) that it refers to. There has been lots of research done on coreference resolution and recent research with deep learning has achieved state of the art results [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>] on this challenging task. However, existing coreference resolution systems have several limitations when applied to CQU. The following examples were tried with the coreference resolution service from the Stanford CoreNLP toolkit [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>]:</p>    <ol class="list-no-style">    <li id="list5" label="(1)">Multiple possible entities (e.g. for &#x201D;Is Space Needle in Seattle? Who is its mayor?&#x201D;, the &#x201D;its&#x201D; is incorrectly resolved to &#x201D;Space&#x201D; instead of &#x201D;Seattle&#x201D;)<br/></li>    <li id="list6" label="(2)">Knowing when a reformulation is actually needed (e.g. for &#x201D;When was California founded? How long does it take bruised ribs to heal?&#x201D;, the &#x201D;it&#x201D; is incorrectly resolved to &#x201D;California&#x201D;).<br/></li>    <li id="list7" label="(3)">When there isn&#x0027;t an explicit referring anaphora (e.g. for &#x201D;When was California founded? What is the population?&#x201D;, there is no anaphora in the second query that explicitly refers to &#x201D;California&#x201D;).<br/></li>    </ol>    <p>Example 3 shows that even the perfect coreference resolution system will not be able to handle the conversational queries that lack anaphoras, such as some of the examples in Table <a class="tbl" href="#tab1">1</a>.</p>    <p>Paraphrase generation, where the goal is to generate a paraphrase for a given sentence, is also a related task. Research has been done on applying deep learning to paraphrase generation with state of the art results [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>]; however, no existing research has been done on generating paraphrases that depend on context beyond just the input sentence.</p>    <p>There has also been research on dialogue agents using neural networks and reinforcement learning [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>]. While these research show promising results, they are limited by being very domain specific, e.g. finding a movie.</p>    <p>Another related area is context-aware search or context-aware query suggestion for search. Bar-Yossef et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>], Li et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>], Cao et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>], Sordoni et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>] and Dehghani et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>] used previous queries as context along with auto-completion logs and/or click logs to improve query suggestions for query auto-completion. Their work consists of either ranking or generating query suggestions. The query ranking task fundamentally differs from our query reformulation/generation task. For the solutions that generated query suggestions, they were focused on completing the query instead of modifying existing parts of the query. Also, these solutions are well suited for a traditional search engine interface where query suggestions can be shown to the user for them to select, but not as suited for the conversational technologies that we are targeting.</p>    <p>Research conducted by Cao et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>], Shen et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>] and Sun et al [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>] focused on how context can be leveraged to improve document ranking accuracy. Grbovic et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>] proposed a context-aware query rewriting approach for sponsored search. He et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>] proposed using sequence to sequence for query rewriting. These research overlap with only individual aspects of our work, such as leveraging context or sequence to sequence modeling, and they are focused on the traditional query rewriting task of adding alternative queries to improve ranking performance by reducing mismatches.</p>    <p>For deep learning, the architecture that we built on top of is the sequence to sequence model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>]. More details about sequence to sequence can be found in section 4.2. We also used the technique of adding attention mechanism to sequence to sequence, which has been shown in existing research to improve performance [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>]. Another deep learning technique that we used is multiple perspective matching, which has been shown to help with natural language sentence matching [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>]. For our task of CQU, this matching was applied between the query and the context; more details can be found in section 4.3.4. For all these deep learning techniques, previous works have not yet explored applying them to the task of CQU.</p>   </section>   <section id="sec-7">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> Dataset</h2>    </div>    </header>    <p>To apply deep learning for open domain CQU, we need a dataset that is large (at least tens of thousands samples), open domain, and, of course, containing conversational queries. Several existing datasets were considered, but unfortunately none of them met all the criteria, as shown in Figure <a class="fig" href="#fig1">1</a>. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186083/images/www2018-92-fig1.jpg" class="img-responsive" alt="Figure 1"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Existing datasets.</span>     </div>    </figure>    </p>    <p>The movie dialogue [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>] and MSR twitter [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>] datasets were both large and not domain specific, but they contained few conversational queries, and it would have been very difficult to filter for those queries. The Ubuntu tech support [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>] and Wikipedia editors [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>] datasets were both large and contained good examples of conversational queries, but they were specific to Ubuntu tech support queries and Wikipedia editing queries, respectively. The Cortana (internal dataset), Dialog State Tracking Challenge [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>], and UCSB datasets [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>] were also domain specific, and not large enough.</p>    <p>Since there was no suitable existing dataset, data collection was the crucial first step. We hypothesized that there are users who interact with search engines as if they&#x0027;ve having a conversation, and issue conversational queries, expecting the context of their previous queries to be maintained. From examining search engine logs, we did in fact find such queries, and what was particularly interesting is that because the search engine does not currently have great CQU, users themselves would often have to reformulate those queries to include the necessary context.</p>    <p>Therefore, we mined a commercial search engine&#x0027;s query logs for triplets of consecutive queries from the same user session, i.e. consisting of query 1, 2, and 3. The queries are already stored in sessions based on the search engine&#x0027;s definition of session. Then a filtering logic was applied to obtain the triplets where:</p>    <ol class="list-no-style">    <li id="list8" label="(1)">query 1 can be any query<br/></li>    <li id="list9" label="(2)">query 2 is a conversational query that depends on context from query 1<br/></li>    <li id="list10" label="(3)">query 3 is the user&#x0027;s own reformulation of query 2 that includes context from query 1<br/></li>    </ol>    <p>For example: query 1 = &#x201D;when was California founded&#x201D;, query 2 = &#x201D;who is its governor&#x201D;, query 3 = &#x201D;who is California&#x0027;s governor&#x201D;. Note that query 2 is conversational, and it was reformulated to query 3, which is non-conversational and can be a standalone query.</p>    <p>Some of the important criteria in the filtering logic include:</p>    <ul class="list-no-style">    <li id="list11" label="&#x2022;">query 2 doesn&#x0027;t result in any clicks (implies that the search engine did not understand the query and did not return any good results)<br/></li>    <li id="list12" label="&#x2022;">query 3 does result in a satisfied user click (implies that the search engine did understand the query and did return a good result)<br/></li>    <li id="list13" label="&#x2022;">query 3 consists of terms from query 2 and terms from query 1 that weren&#x0027;t in query 2 (implies that query 3 is a reformulation of query 2 to include context from query 1)<br/></li>    <li id="list14" label="&#x2022;">query 3 was issued within 30 seconds of query 2 (implies that the user quickly noticed that the search engine did not understand query 2, and immediately reformulated it to query 3)<br/></li>    </ul>    <p>These criteria combined with the fact that the search engine currently has low coverage for conversational queries and shows unsatisfactory results, leads to the assumption that query 2 is a conversational query that depends on context from query 1.</p>    <p>Recall that the task of CQU involves reformulating the conversational query to include the correct context. Therefore, query 1 and query 2 (previous query and current query) can be treated as the inputs and query 3 (reformulation of current query) can be treated as the labels. This dataset currently does not include the previous answer, but we will explore adding it in the future.</p>    <p>These triplets are the positive samples, and we also mined for negative samples where no reformulation was needed. This was done by applying a filtering logic with the criteria that query 2 already resulted in a satisfied user click (implying that the search engine understood query 2 and returned a good result). In this case, no user reformulation was needed, so we can just set query 3 to be equal to query 2. For example: query 1 = &#x201D;where is California&#x201D;, query 2 = &#x201D;how to split string in Python&#x201D;, query 3 = &#x201D;how to split string in Python&#x201D;. For these queries, we don&#x0027;t want to reformulate query 2, so the desired output query 3 is just the original query 2. These negative samples were added so that a model trained on this dataset can also learn whether or not a query depends on previous context.</p>    <p>For the mined search engine queries, only about 5% were natural language questions, with the rest being keyword queries. However, since users tend to issue more natural language questions for the conversational technologies that we are targeting, we upsampled the natural language questions to be 50% of our dataset. This upsampling was done for both positive and negative samples.</p>    <p>Note that the filtering logics for both positive and negative samples are not perfect and will result in some false positive/negative samples. This is not a surprise because if there is a perfect filtering logic for conversational queries, then the task of CQU can be solved by simply applying that logic. From manually checking 1000 samples, we found that 71% of positive samples actually contained conversational queries while 98% of negative samples actually contained standalone queries. Improving the filtering logic to generate cleaner data is something that we will continue to explore.</p>    <p>Even though the vast majority of search engine queries are not conversational, we were still able to create a large dataset because of the massive amount of queries in the search engine logs. The dataset that we used for our models consists of &#x00A0;3.6 million conversational query sessions, and also &#x00A0;3.6 million negative samples. This dataset was mined from only a subset of search engine logs, so additional samples can easily be obtained; and as new queries continue to come in daily, this dataset can continue to grow.</p>    <p>Another advantage of this dataset is that it includes human labels for free, without the need to hire crowdsourced judges to generate labels. Also, search engine data is very diverse and covers many domains, and this dataset reflects that. It contains a very wide range of context that are passed between queries, everything from various named entities to concepts/noun phrases to verbs. Therefore, this dataset satisfies the criteria mentioned earlier, making it the first ever large scale and open domain dataset of conversational queries.</p>   </section>   <section id="sec-8">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> Algorithms</h2>    </div>    </header>    <section id="sec-9">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Problem Formulation</h3>     </div>    </header>    <p>As stated in the introduction, we formulate the problem as a context-aware query reformulation task. In a generic form, the inputs of the task are: context (conversation history), which includes previous queries and answers/results, and current input query; output of the task is a generated query which reformulates the input query by infusing information which exists in the context but is missing from the current query.</p>    <p>We use <em>C</em> to represent conversation history: <span class="inline-equation"><span class="tex">$C=\lbrace Q_t,A_t\rbrace _{t=-1}^{-K}$</span>     </span> where <em>K</em> represents the window size of looking back at history, use <em>Q</em>     <sub>0</sub> to represent current input query, and use <em>Q</em>&#x2032; to represent the output after reformulation. The goal of the task can be formulated to find a function <em>F</em>: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\[ F(C,Q_0)\rightarrow Q^{\prime } \] </span>       <br/>      </div>     </div> In addition, both query and answer are comprised of sequence of words: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\[ Q=\lbrace w_t^Q\rbrace _{t=1}^M, A=\lbrace w_t^A\rbrace _{t=1}^N \] </span>       <br/>      </div>     </div> We use <em>w<sub>t</sub>     </em> to represent a word at position or time step <em>t</em> in a sequence.</p>    <p>In the simplest form where we only use the previous query in a conversation history as context, <em>C</em> becomes: <em>C</em> = <em>Q</em>     <sub>&#x2212; 1</sub>. For simplicity, we remove the subscripts from <em>C</em> and <em>Q</em>     <sub>0</sub> and represent them as: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\[ C=\lbrace w_t^C\rbrace _{t=1}^N,Q=\lbrace w_t^Q\rbrace _{t=1}^M \] </span>       <br/>      </div>     </div> The goal remains as: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\[ F(\lbrace w_t^C\rbrace _{t=1}^N,\lbrace w_t^Q\rbrace _{t=1}^M)\rightarrow \lbrace w_t^{Q^{\prime }}\rbrace _{t=1}^P \] </span>       <br/>      </div>     </div> Words generated in <span class="inline-equation"><span class="tex">$Q^{\prime }: w_t^{Q^{\prime } }$</span>     </span> can either be from the context: <span class="inline-equation"><span class="tex">$\lbrace w_t^C \rbrace _{t=1}^N$</span>     </span> or current input query: <span class="inline-equation"><span class="tex">$\lbrace w_t^Q \rbrace _{t=1}^M$</span>     </span>, or a predefined vocabulary.</p>    <p>This problem setting fits very well as a sequence to sequence problem. We first briefly review the general sequence to sequence approach, and then introduce our approaches of applying the sequence to sequence technique to solve the context-aware query reformulation problem.</p>    </section>    <section id="sec-10">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Sequence to Sequence Modeling</h3>     </div>    </header>    <p>In the general sequence to sequence scenario, a collection of source-target sequence pairs is given, and the task is to learn to generate target sequences from source sequences. Let&#x0027;s use <em>S</em> and <em>T</em> to represent a source sequence and a target sequence, respectively: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\[ S=\lbrace w_t^S \rbrace _{t=1}^M,T=\lbrace w_t^T \rbrace _{t=1}^N \] </span>       <br/>      </div>     </div> Words in <em>S</em> and <em>T</em> can be from different vocabularies, like in machine translation, or the same vocabulary, like in text summarization. Sequences <em>S</em> and <em>T</em> can have different lengths and they represent a many-to-many relationship.</p>    <p>Sequence to sequence belongs to the broader class of encoder-decoder models [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0007">7</a>], which has two stages: encoding and decoding. In the encoding stage, an encoder is used to transform the source sequence into an encoded representation. There are many different types of encoders targeting different source domains [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0018">18</a>]. Here we are agnostic to the form of the encoder and simply use a general recurrent neural network (RNN) to present the encoding process as: <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} {u}_t^S=RNN^S ({u}_{t-1}^S, {e}_t^S) \end{equation} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div> Here <span class="inline-equation"><span class="tex">$ {e}_t^S$</span>     </span> is the word embedding representation of word <span class="inline-equation"><span class="tex">$w_t^S$</span>     </span> in source sequence <span class="inline-equation"><span class="tex">$S=\lbrace {e}_t^S \rbrace _{t=1}^M$</span>     </span> and <span class="inline-equation"><span class="tex">$ {u}_t^S$</span>     </span> represents the internal RNN state at time step <em>t</em>. After running the RNN through the entire source sequence, we obtain <span class="inline-equation"><span class="tex">$ {u}^S=\lbrace {u}_t^S \rbrace _{t=1}^M$</span>     </span>, which is considered as the encoded representation of the source sequence. Instead of using the entire sequence u<sup>      <em>S</em>     </sup> as the encoded representation of the source, usually the last RNN state, <span class="inline-equation"><span class="tex">$ {u}_M^S$</span>     </span>, is treated as the representation of the entire source sequence and is used for decoding.</p>    <p>Once the source sequence is encoded, sequence to sequence models generate a target sequence in the decoding stage. In this stage, a decoder, which is usually another RNN, generates the target sequence sequentially one word at a time by conditioning on the source sequence and the previously generated words. <div class="table-responsive" id="Xeq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} {s}_t= RNN^T ({s}_{t-1},h({y}_{t-1},S)) \end{equation} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div>     <div class="table-responsive" id="eq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} p(y_t|\lbrace y_{{\lt}t}\rbrace ,S)=g({s}_t) \end{equation} </span>       <br/>       <span class="equation-number">(3)</span>      </div>     </div> Here s<sub>      <em>t</em>     </sub> represents the internal state of RNN at time <em>t</em> and <em>y<sub>t</sub>     </em> stands for the word generated at time <em>t</em>. We use bold font y<sub>      <em>t</em>     </sub> to represent <em>y<sub>t</sub>     </em>&#x2019;s corresponding word embedding representation. <em>g</em> is usually an affine layer followed by a softmax. Usually dependence on <em>S</em> can be captured by setting s<sub>0</sub> to be <span class="inline-equation"><span class="tex">$ {u}_M^S$</span>     </span>, which passes the source information to the target. Since the source information is already passed, we can set <em>h</em>(y<sub>      <em>t</em> &#x2212; 1</sub>, <em>S</em>) = y<sub>      <em>t</em> &#x2212; 1</sub>.</p>    <p>On top of above sequence to sequence framework, a technique called attention has been shown to significantly improve sequence to sequence models&#x2019; performances and has become a default component in many sequence to sequence applications [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0036">36</a>].</p>    <p>Instead of using a fixed vector, e.g. u<sup>      <em>S</em>     </sup>, to represent the source sequence <em>S</em> during decoding, attention mechanism introduces a dynamically changing attention vector c<sub>      <em>t</em>     </sub> to the decoding process. <div class="table-responsive" id="eq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} {c}_t= \sum _{k=1}^M\alpha _{t,k} {u}_k^S \end{equation} </span>       <br/>       <span class="equation-number">(4)</span>      </div>     </div>     <div class="table-responsive" id="eq3">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \alpha _{t,k} = \frac{e^{f({s_t}, {u}_k^S)}}{\sum _{k^{\prime }}e^{f({s_t}, {u}_{k^{\prime }}^S)}} \end{equation} </span>       <br/>       <span class="equation-number">(5)</span>      </div>     </div> Equations <a class="eqn" href="#eq2">4</a> and <a class="eqn" href="#eq3">5</a> give the computation of c<sub>      <em>t</em>     </sub>. Intuitively, <em>&#x03B1;</em>     <sub>      <em>t</em>, <em>k</em>     </sub> represents the strength of attention on the <span class="inline-equation"><span class="tex">$k^\textrm {th}$</span>     </span> word in source sequence at time step <em>t</em> during decoding. <em>f</em> is the attention function which is usually a multi-layer neural network with non-linear layers. In this paper, we use the Bahdanau mechanism introduced in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>]. c<sub>      <em>t</em>     </sub> is computed by a weighted sum of the source words&#x2019; representations based on their corresponding attention strengths. With the attention mechanism, the decoding process then becomes: <div class="table-responsive" id="eq4">      <div class="display-equation">       <span class="tex mytex">\begin{equation} {s}_t=RNN^T ({s}_{t-1},h({y}_{t-1}, {c}_{t-1})) \end{equation} </span>       <br/>       <span class="equation-number">(6)</span>      </div>     </div> In this paper, we simply consider concatenating y<sub>      <em>t</em> &#x2212; 1</sub> and c<sub>      <em>t</em> &#x2212; 1</sub>: <em>h</em>(y<sub>      <em>t</em> &#x2212; 1</sub>, c<sub>      <em>t</em> &#x2212; 1</sub>) = [y<sub>      <em>t</em> &#x2212; 1</sub>, c<sub>      <em>t</em> &#x2212; 1</sub>]. Equation <a class="eqn" href="#eq1">3</a> then becomes: <div class="table-responsive" id="eq5">      <div class="display-equation">       <span class="tex mytex">\begin{equation} p(y_t|\lbrace y_{{\lt}t}\rbrace ,S)=g({s}_t, {c}_t) \end{equation} </span>       <br/>       <span class="equation-number">(7)</span>      </div>     </div> Here an attention layer is applied above the RNN cells, and <em>g</em>(s<sub>      <em>t</em>     </sub>, c<sub>      <em>t</em>     </sub>) is set to be <em>g</em>([s<sub>      <em>t</em>     </sub>, c<sub>      <em>t</em>     </sub>]). Figure <a class="fig" href="#fig2">2</a> illustrates the general sequence to sequence model with attention, where LSTM [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0018">18</a>] is selected the as RNN cell and the <START> token is used to kick off decoding process. <figure id="fig2">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186083/images/www2018-92-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">General sequence to sequence with attention.</span>      </div>     </figure>    </p>    </section>    <section id="sec-11">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Context-Aware Query Reformulation with Sequence to Sequence Modeling</h3>     </div>    </header>    <p>This section will provide details on how we tackled the context-aware query reformulation problem with various sequence to sequence approaches. We proposed four approaches, with each one building on top of the previous.</p>    <section id="sec-12">     <p><em>4.3.1 Concatenated Sequence to Sequence (Concate_S2S, Baseline).</em> The unique property of our query reformulation problem, which doesn&#x0027;t exist in general sequence to sequence settings, is that there are two source sequences: 1) context <span class="inline-equation"><span class="tex">$C=\lbrace w_t^C \rbrace _{t=1}^N$</span>      </span> and 2) current query <span class="inline-equation"><span class="tex">$Q=\lbrace w_t^Q \rbrace _{t=1}^M$</span>      </span>. Our first approach is just to concatenate <em>C</em> and <em>Q</em> to form one source sequence, and then directly adopt general sequence to sequence: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ S=[\lbrace w_t^C \rbrace _{t=1}^N,\_SEP ,\lbrace w_t^Q \rbrace _{t=1}^M] \] </span>       <br/>       </div>      </div>      <span class="inline-equation"><span class="tex">$\_SEP$</span>      </span> represents a special word used to be able to separate context and query sequences. This approach is considered as our baseline, and we derived more advanced approaches on top of it.</p>    </section>    <section id="sec-13">     <p><em>4.3.2 Pair Sequences to Sequence (Pair_S2S).</em> Instead of concatenating context and query sequences, we keep them separate and use different RNNs to encode them: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ {u}_t^C=RNN^C ({u}_{t-1}^C, {e}_t^C) \] </span>       <br/>       </div>      </div>      <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ {u}_t^Q=RNN^Q ({u}_{t-1}^Q, {e}_t^Q) \] </span>       <br/>       </div>      </div>      <span class="inline-equation"><span class="tex">$ {u}_0^Q$</span>      </span> is set to be <span class="inline-equation"><span class="tex">$ {u}_N^C$</span>      </span> to pass information from context to current query, simulating natural conversation flow. With this encoding process, we obtain the encoded context representation <span class="inline-equation"><span class="tex">$ {u}^C=\lbrace {u}_t^C \rbrace _{t=1}^N$</span>      </span>, and the encoded query representation <span class="inline-equation"><span class="tex">$ {u}^Q=\lbrace {u}_t^Q \rbrace _{t=1}^M$</span>      </span>.</p>     <p>In decoding stage, <span class="inline-equation"><span class="tex">$ {u}_M^Q$</span>      </span> is used to initialize RNN state s<sub>0</sub>. While for attention, we expand the traditional attention mechanism to a two-layer attention. First, attention is conducted on context and query sequences separately and independently: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\begin{align*} {c}_t^C= \sum _{k=1}^N\alpha _{t,k}^C {u}_k^C &#x0026;&#x0026; {c}_t^Q= \sum _{k=1}^M\alpha _{t,k}^Q {u}_k^Q\end{align*} </span>       <br/>       </div>      </div>      <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\begin{align*} \alpha _{t,k}^C = \frac{e^{f({s}_t, {u}_k^C)}}{\sum _{k^{\prime }}e^{f({s}_t, {u}_{k^{\prime }}^C)}} &#x0026;&#x0026; \alpha _{t,k}^Q = \frac{e^{f({s}_t, {u}_k^Q)}}{\sum _{k^{\prime }}e^{f({s}_t, {u}_{k^{\prime }}^Q)}}\end{align*} </span>       <br/>       </div>      </div> Second, another attention is conducted to merge attention vectors <span class="inline-equation"><span class="tex">$ {c}_t^C$</span>      </span> and <span class="inline-equation"><span class="tex">$ {c}_t^Q$</span>      </span>: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ {c}_t^{C+Q}= a\_\alpha _{t,k}^C {c}_t^C+ a\_\alpha _{t,k}^Q {c}_t^Q \] </span>       <br/>       </div>      </div>      <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ a\_\alpha _{t,k}^C = \frac{e^{f({s}_t, {c}_t^C)}}{e^{f({s}_t, {c}_t^C)} + e^{f({s}_t, {c}_t^Q)}} \] </span>       <br/>       </div>      </div>      <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ a\_\alpha _{t,k}^Q = \frac{e^{f({s}_t, {c}_t^Q)}}{e^{f({s}_t, {c}_t^C)} + e^{f({s}_t, {c}_t^Q)}} \] </span>       <br/>       </div>      </div> where <span class="inline-equation"><span class="tex">$a\_\alpha _{t,k}^C$</span>      </span> and <span class="inline-equation"><span class="tex">$a\_\alpha _{t,k}^Q$</span>      </span> can be considered as the attention strength at the sequence level on context and query, respectively. <span class="inline-equation"><span class="tex">$ {c}_t^{C+Q}$</span>      </span>, the weighted-sum vector of <span class="inline-equation"><span class="tex">$ {c}_t^C$</span>      </span> and <span class="inline-equation"><span class="tex">$ {c}_t^Q$</span>      </span>, will be used as the final attention vector for decoding. The rest of the decoding is the same as general sequence to sequence using Equations <a class="eqn" href="#eq4">6</a> and <a class="eqn" href="#eq5">7</a>.</p>     <p>Figure <a class="fig" href="#fig3">3</a> illustrates the pair sequences to sequence approach with two layers of attentions. Figure <a class="fig" href="#fig4">4</a> zooms in to the computation of attention vectors. <figure id="fig3">       <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186083/images/www2018-92-fig3.jpg" class="img-responsive" alt="Figure 3"        longdesc=""/>       <div class="figure-caption">       <span class="figure-number">Figure 3:</span>       <span class="figure-title">Pair sequences to sequence with two layers of attentions.</span>       </div>      </figure>      <figure id="fig4">       <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186083/images/www2018-92-fig4.jpg" class="img-responsive" alt="Figure 4"        longdesc=""/>       <div class="figure-caption">       <span class="figure-number">Figure 4:</span>       <span class="figure-title">Computation of two layers of attentions.</span>       </div>      </figure>     </p>     <p>Keeping context and query separate when encoding makes the overall model structure more flexible. It provides better support for incorporating richer context in the future, such as including multiple previous turns from the conversation history with both queries and answers. Furthermore, it empowers the model to more efficiently and deeply capture the relationship between the context and query, instead of just concatenating them and treating them equally.</p>    </section>    <section id="sec-14">     <p><em>4.3.3 Pair Sequences to Sequence With Context Embedding (Pair_S2S_Cxt_Embed).</em> Based on Pair_S2S, we developed a new model which embeds context information into query sequence during encoding, with the purpose of capturing the semantic relationship between context and query.</p>     <p>In encoding stage, the context sequence is first encoded as done in model Pair_S2S. Then, the query sequence is encoded. When encoding the query, attention mechanism over the context is applied. <div class="table-responsive" id="eq6">       <div class="display-equation">       <span class="tex mytex">\begin{equation} {c}_t^{QC}= \sum _{k=1}^N\alpha _{t,k}^{QC} {u}_k^C \end{equation} </span>       <br/>       <span class="equation-number">(8)</span>       </div>      </div>      <div class="table-responsive" id="eq7">       <div class="display-equation">       <span class="tex mytex">\begin{equation} \alpha _{t,k}^{QC} = \frac{e^{f({u}_t^Q, {u}_k^C)}}{\sum _{k^{\prime }}e^{f({u}_t^Q, {u}_{k^{\prime }}^C)}} \end{equation} </span>       <br/>       <span class="equation-number">(9)</span>       </div>      </div> In Equations <a class="eqn" href="#eq6">8</a> and <a class="eqn" href="#eq7">9</a>, <span class="inline-equation"><span class="tex">$\alpha _{t,k}^{QC}$</span>      </span> represents the attention strength on the <em>k<sup>th</sup>      </em> word in the context sequence at time <em>t</em> while encoding the query. <span class="inline-equation"><span class="tex">$ {c}_t^{QC}$</span>      </span> is the corresponding weighted-sum vector over the encoded context representation. Then the query encoder becomes: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ {u}_t^Q=RNN^Q ({u}_{t-1}^Q,[ {e}_t^Q, {c}_{t-1}^{QC}]) \] </span>       <br/>       </div>      </div> The decoding stage remains the same as in Pair_S2S.</p>     <p>You can see the unique property of this approach is the computation of <span class="inline-equation"><span class="tex">$ {c}_t^{QC}$</span>      </span> and its embedding usage. The attention mechanism enables <span class="inline-equation"><span class="tex">$ {c}_t^{QC}$</span>      </span> to capture matching information between each word in the query sequence to all the words in the context sequence. This additional information was expected to produce better source representations to be used for decoding. The effectiveness of this approach can be seen in our experiment results.</p>    </section>    <section id="sec-15">     <p><em>4.3.4 Pair Sequences to Sequence With Context Embedding From Multiple Perspective Matching (Pair_S2S_Cxt_Embed_MP).</em> The effectiveness of Pair_S2S_Cxt_Embed inspired us to develop this new model, with the motivation of further improving the context embedding <span class="inline-equation"><span class="tex">$ {c}_t^{QC}$</span>      </span>.</p>     <p>[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0037">37</a>] proposed a multiple perspective matching (MP-matching) approach to measure similarity between two natural language sentences. We borrowed that idea to compute a new context embedding <span class="inline-equation"><span class="tex">$ {c}_t^{QC}$</span>      </span>. Let&#x0027;s rephrase MP-matching for our reformulation scenario and describe how we&#x0027;re using it.</p>     <p>In MP-matching, a multiple perspective matching function <em>f<sub>m</sub>      </em> is proposed to compute similarity of two vectors: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ {m}=f_m ({v}_1, {v}_2; {W}) \] </span>       <br/>       </div>      </div> where v<sub>1</sub> and v<sub>2</sub> are two same sized vectors, e.g. with dimension <em>d</em>, and <span class="inline-equation"><span class="tex">$ {W}\in \mathbb {R}^{l\times d}$</span>      </span> is a trainable parameter with <em>l</em> representing the number of perspectives. The returned value of m is a <em>l</em>-dimensional vector m = [<em>m</em>      <sub>1</sub>, ..., <em>m<sub>l</sub>      </em>], with each dimension <em>m<sub>k</sub>      </em> &#x2208; m representing the matching score from the <em>k<sup>th</sup>      </em> perspective. <em>m<sub>k</sub>      </em> is calculated by the following formula: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ m_k=cosine({W}_k \odot {v}_1, {W}_k \odot {v}_2) \] </span>       <br/>       </div>      </div> where &#x2299; is the element-wise multiplication, and W<sub>       <em>k</em>      </sub> is the <em>k<sup>th</sup>      </em> row of W.</p>     <p>A few matching strategies based on <em>f<sub>m</sub>      </em> are proposed in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0037">37</a>]. In the following equations, we use <em>BiRNN</em> to represent a bi-directional RNN. Before matching the query against the context, we first encode them to new representations: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ \overrightarrow{ {u}_t^C},\overleftarrow{ {u}_t^C} = BiRNN({u}_{t-1}^C, {e}_t^C) \] </span>       <br/>       </div>      </div>      <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ \overrightarrow{ {u}_t^Q},\overleftarrow{ {u}_t^Q} = BiRNN({u}_{t-1}^Q, {e}_t^Q) \] </span>       <br/>       </div>      </div> Note that context and query are encoded using the same RNN as proposed in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0037">37</a>].</p>     <p>Matching strategies:</p>     <p>1. Full matching. In this strategy, each time step of the query representation <span class="inline-equation"><span class="tex">$\overrightarrow{ {u}_t^Q}$</span>      </span> (or <span class="inline-equation"><span class="tex">$\overleftarrow{ {u}_t^Q}$</span>      </span>) is compared with the final time step of the context representation <span class="inline-equation"><span class="tex">$\overrightarrow{ {u}_N^C}$</span>      </span> (or <span class="inline-equation"><span class="tex">$\overleftarrow{ {u}_N^C}$</span>      </span>): <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ \overrightarrow{ {m}_t^{full}} = f_m(\overrightarrow{ {u}_t^Q}, \overrightarrow{ {u}_N^C}; \overrightarrow{ {W}^{full}}) \] </span>       <br/>       </div>      </div>     </p>     <p>2. Max pooling matching. In this strategy, each time step of the query representation <span class="inline-equation"><span class="tex">$\overrightarrow{ {u}_t^Q}$</span>      </span> (or <span class="inline-equation"><span class="tex">$\overleftarrow{ {u}_t^Q}$</span>      </span>) is compared with every time step of the context representation <span class="inline-equation"><span class="tex">$\overrightarrow{ {u}_i^C}$</span>      </span> (or <span class="inline-equation"><span class="tex">$\overleftarrow{ {u}_i^C}$</span>      </span>), and the maximum value of each dimension is selected: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ \overrightarrow{ {m_t}^{max}} = \max _{i \in 1,...,N} f_m(\overrightarrow{ {u}_t^Q}, \overrightarrow{ {u}_i^C}; \overrightarrow{ {W}^{max}}) \] </span>       <br/>       </div>      </div>     </p>     <p>3. Attentive matching. In this strategy, first, at each time step of the query representation <span class="inline-equation"><span class="tex">$\overrightarrow{ {u}_t^Q}$</span>      </span> (or <span class="inline-equation"><span class="tex">$\overleftarrow{ {u}_t^Q}$</span>      </span>), attentions over the context representation are computed. Attention weight is computed with cosine similarity: <div class="table-responsive" id="eq8">       <div class="display-equation">       <span class="tex mytex">\begin{equation} \overrightarrow{a_{t,i}} = \frac{cosine(\overrightarrow{ {u}_t^Q},\overrightarrow{ {u}_i^C})}{\sum _{j=1}^N cosine(\overrightarrow{ {u}_t^Q},\overrightarrow{ {u}_j^C}) } \quad i=1,...,N \end{equation} </span>       <br/>       <span class="equation-number">(10)</span>       </div>      </div> Then an attention vector over the entire context representation <span class="inline-equation"><span class="tex">$\overrightarrow{ {u}^C}$</span>      </span> (or <span class="inline-equation"><span class="tex">$\overleftarrow{ {u}^C}$</span>      </span>) is computed by weighted summing all time steps of the context representation: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ \overrightarrow{ {u}_t^{C,mean}} = \sum _{i=1}^N \overrightarrow{a_{t,i}} \cdot \overrightarrow{ {u}_i^C} \] </span>       <br/>       </div>      </div> Finally, each time step of the query representation is matched with its corresponding attention vector by the <em>f<sub>m</sub>      </em> function: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ \overrightarrow{ {m}_t^{att}} = f_m(\overrightarrow{ {u}_t^Q}, \overrightarrow{ {u}_t^{C,mean}}; \overrightarrow{ {W}^{att}}) \] </span>       <br/>       </div>      </div>     </p>     <p>4. Max attentive matching. This strategy is similar to attentive matching. It picks the time step from the context representation which has the highest attention score (cosine similarity computed by Equation <a class="eqn" href="#eq8">10</a>) as the attention vector, instead of taking the weighted sum of all the time steps as the attention vector. We use <span class="inline-equation"><span class="tex">$\overrightarrow{ {m}_t^{max\_att}}$</span>      </span> to represent the max attentive matching vectors.</p>     <p>All these match strategies are applicable to the query&#x0027;s and context&#x0027;s word embedding representations as well by simply replacing u<sup>       <em>Q</em>      </sup> and u<sup>       <em>C</em>      </sup> with e<sup>       <em>Q</em>      </sup> and e<sup>       <em>C</em>      </sup> respectively and removing the direction. In our model, we expand max attentive matching with word embedding representations and represent it as: <span class="inline-equation"><span class="tex">$ {m}_t^{e,max\_att}$</span>      </span>. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0037">37</a>] has demonstrated that applying all strategies together works best. Therefore, we aggregate all the above matching vectors with an aggregation layer. The matchings at each time step in the query sequence are concatenated: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\begin{multline*} {m}_t^{QC} = [\overrightarrow{ {m}_t^{full}},\overleftarrow{ {m}_t^{full}}, \overrightarrow{ {m}_t^{max}},\overleftarrow{ {m}_t^{max}},\overrightarrow{ {m}_t^{att}}, \overleftarrow{ {m}_t^{att}}, \\ \overrightarrow{ {m}_t^{max\_att}},\overleftarrow{ {m}_t^{max\_att}}, {m}_t^{e,max\_att}]\end{multline*} </span>       <br/>       </div>      </div> Then <span class="inline-equation"><span class="tex">$\lbrace {m}_t^{QC} \rbrace _{t=1}^M$</span>      </span> is fed into another RNN: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ \overrightarrow{ {v}_t^{QC}},\overleftarrow{ {v}_t^{QC}} = BiRNN^{Agg}({v}_{t-1}^{QC}, {m}_t^{QC}) \] </span>       <br/>       </div>      </div> Finally, the context embedding is obtained as: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ {c}_t^{QC} = [\overrightarrow{ {v}_t^{QC}},\overleftarrow{ {v}_t^{QC}}] \] </span>       <br/>       </div>      </div> Figure <a class="fig" href="#fig5">5</a> illustrates the Pair_S2S_Cxt_Embed_MP model. <figure id="fig5">       <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186083/images/www2018-92-fig5.jpg" class="img-responsive" alt="Figure 5"        longdesc=""/>       <div class="figure-caption">       <span class="figure-number">Figure 5:</span>       <span class="figure-title">Sequences to sequence with context embedding from multiple perspective matching. There are two stages: 1) building context-aware query 2) feeding the context-aware query representation to pair sequences to sequence with two layers attentions.</span>       </div>      </figure>     </p>    </section>    </section>   </section>   <section id="sec-16">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Experiments</h2>    </div>    </header>    <p>For all the proposed models, the loss function that was optimized during training is the cross entropy loss, which is given by: <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\[ CE = -\sum _i \log (p_{y_i}) \] </span>      <br/>     </div>    </div> where <span class="inline-equation"><span class="tex">$p_{y_i}$</span>    </span> is the model&#x0027;s predicted probability of the correct target word <em>y<sub>i</sub>    </em>. Often the cross entropy loss is expressed as perplexity, which is just the exponential of cross entropy loss, exp(<em>CE</em>). Stochastic gradient descent was the chosen optimizer because of its popularity for other sequence to sequence models [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>].</p>    <p>The final metrics that the models were evaluated on are exact match and BLEU score. Exact match is the percentage of predicted sequences that match word for word with the labels. BLEU score is the standard BLEU score [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>]. BLEU score is included as a metric because the ultimate goal of this task is to allow IR/QnA systems to answer conversational query and an exact match is not always needed to correctly answer the query. For example, &#x201D;what is the population of California&#x201D; and &#x201D;what is California population&#x201D; should both result in the same answer for most QnA systems. Exact match is a very strict metric but it provides a precise measurement of our approaches. During evaluation, we removed stop-words from both target and generated sequences.</p>    <p>The dataset described in Section 3 was split into train/dev/test sets by a 80/10/10 split. Train set was used for training, dev set was used for hyperparameter tuning, and test set was used for final evaluations. The test set was also split into the positive (conversational) and negative (non-conversational) examples.</p>    <p>A vocabulary size of 200k was chosen because &#x00A0;600k unique words were found in the inputs of the train set and the top 200k words covered 99% of all words. Batch size of 32 was chosen based on recommendation from [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>]. Word embedding size of 300 was chosen since we hypothesized that the model would need as much expressivity at the word level as possible. The encoder and decoder share the same embeddings because for this task, the meaning of a word should be the same in both the input and output. The embeddings were trained from random initialization and using pretrained GloVe embeddings [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>] did not help. Hidden size of 300 was chosen based on recommendation to have hidden size &#x2265; embedding size [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>]. Larger hidden sizes of 400 and 600 were experimented with but did not result in improvements. Further tuning of these hyperparameters would be a worthwhile next step.</p>    <p>During training, a checkpoint was saved every 1/20th of an epoch, and the checkpoint is evaluated on the entire dev set. Training stopped when the perplexity on the dev set did not improve over 5 consecutive checkpoints.</p>    <p>We first studied the impact of different model architectures for the Concate_S2S model, including type of RNN cell, with or without attention, yes or no bidirectional encoder.</p>    <p>Table <a class="tbl" href="#tab2">2</a> shows the results of different settings of Concate_S2S model on the test set, which had about 700k samples total. LSTM provided an improvement over GRU and adding attention provided the biggest improvement, while using bidirectional encoders did not help.</p>    <div class="table-responsive" id="tab2">    <div class="table-caption">     <span class="table-number">Table 2:</span>     <span class="table-title">Test set evaluation for different baseline (Concate_S2S) model setups.</span>    </div>    <table class="table"> 			 <thead>      <tr>       <th style="text-align:left;"/>       <th colspan="2" style="text-align:center;">       <strong>Conversational</strong>       <hr/>       </th>       <th colspan="2" style="text-align:center;">       <strong>Non-conversational</strong>       <hr/>       </th>      </tr>      <tr>       <th style="text-align:left;">       <strong>Model</strong>       </th>       <th style="text-align:left;">       <strong>EM</strong>       </th>       <th style="text-align:left;">       <strong>BLEU</strong>       </th>       <th style="text-align:left;">       <strong>EM</strong>       </th>       <th style="text-align:left;">       <strong>BLEU</strong>       </th>      </tr> 			 </thead>     <tbody>      <tr>       <td style="text-align:left;">GRU, no att</td>       <td style="text-align:left;">20.5</td>       <td style="text-align:left;">52.1</td>       <td style="text-align:left;">40.7</td>       <td style="text-align:left;">54.7</td>      </tr>      <tr>       <td style="text-align:left;">LSTM, no att</td>       <td style="text-align:left;">23.8</td>       <td style="text-align:left;">53.1</td>       <td style="text-align:left;">40.6</td>       <td style="text-align:left;">54.1</td>      </tr>      <tr>       <td style="text-align:left;">LSTM, att</td>       <td style="text-align:left;">44.8</td>       <td style="text-align:left;">76.7</td>       <td style="text-align:left;">75.3</td>       <td style="text-align:left;">87.7</td>      </tr>      <tr>       <td style="text-align:left;">LSTM, att, bidir</td>       <td style="text-align:left;">43.7</td>       <td style="text-align:left;">75.6</td>       <td style="text-align:left;">73.6</td>       <td style="text-align:left;">86.5</td>      </tr>     </tbody>    </table>    </div>    <p>Based on these results, subsequent experiments with the other models used single direction LSTM with attention.</p>   </section>   <section id="sec-17">    <header>    <div class="title-info">     <h2>      <span class="section-number">6</span> Results</h2>    </div>    </header>    <p>The final results of the various models on the test set are shown in Table <a class="tbl" href="#tab3">3</a>.</p>    <div class="table-responsive" id="tab3">    <div class="table-caption">     <span class="table-number">Table 3:</span>     <span class="table-title">Test set evaluation for different models.</span>    </div>    <table class="table"> 			 <thead>      <tr>       <th style="text-align:left;"/>       <th colspan="2" style="text-align:center;">       <strong>Conv</strong>       <hr/>       </th>       <th colspan="2" style="text-align:center;">       <strong>Non-conv</strong>       <hr/>       </th>      </tr>      <tr>       <th style="text-align:left;">       <strong>Model</strong>       </th>       <th style="text-align:left;">       <strong>EM</strong>       </th>       <th style="text-align:left;">       <strong>BLEU</strong>       </th>       <th style="text-align:left;">       <strong>EM</strong>       </th>       <th style="text-align:left;">       <strong>BLEU</strong>       </th>      </tr> 			 </thead>     <tbody>      <tr>       <td style="text-align:left;">Concate_S2S</td>       <td style="text-align:left;">44.8</td>       <td style="text-align:left;">76.7</td>       <td style="text-align:left;">75.3</td>       <td style="text-align:left;">87.7</td>      </tr>      <tr>       <td style="text-align:left;">Pair_S2S</td>       <td style="text-align:left;">48.5</td>       <td style="text-align:left;">75.6</td>       <td style="text-align:left;">74.5</td>       <td style="text-align:left;">82.9</td>      </tr>      <tr>       <td style="text-align:left;">Pair_S2S_Cxt_Embed</td>       <td style="text-align:left;">50.2</td>       <td style="text-align:left;">76.6</td>       <td style="text-align:left;">74.9</td>       <td style="text-align:left;">83.3</td>      </tr>      <tr>       <td style="text-align:left;">Pair_S2S_Cxt_Embed_MP</td>       <td style="text-align:left;">55.0</td>       <td style="text-align:left;">79.2</td>       <td style="text-align:left;">80.0</td>       <td style="text-align:left;">86.8</td>      </tr>      <tr>       <td style="text-align:left;">Pair_S2S_Cxt_Embed_MP + vocab truncate</td>       <td style="text-align:left;">       <strong>55.7</strong>       </td>       <td style="text-align:left;">       <strong>82.6</strong>       </td>       <td style="text-align:left;">       <strong>84.0</strong>       </td>       <td style="text-align:left;">       <strong>92.5</strong>       </td>      </tr>     </tbody>    </table>    </div>    <p>As mentioned earlier, Concate_S2S model is considered as our baseline due to its direct application of general sequence to sequence.</p>    <p>Pair_S2S model is better than the baseline in terms of EM on the conversational set but is worse in terms of EM on the non-conversational set. This might be because Pair_S2S tends to be more aggressive at reformulating the query. This is actually a good sign because reformulation on the conversational set is the more difficult task with much lower EM scores. Pair_S2S_Cxt_Embed model is better than Pair_S2S on all numbers. It indicates that embedding the context while encoding the current query can bring valuable information which is beneficial for reformulating the current query. Results of model Pair_S2S_Cxt_Embed_MP further verify that an advanced context embedding approach improves both EM and BLEU on both conversational and non-conversational sets.</p>    <p>For model Pair_S2S_Cxt_Embed_MP, the number of perspectives was set to be 50, and single layer bi-directional LSTM was used following the settings in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>]. The hidden size of LSTM is 200 and the final context embedding dimension is 400. To accommodate the 400 dimensions, the hidden size of LSTM in the encoder and decoder was set to be 700 (400 + 300). We also tried 300 hidden size, which performed slightly worse but still better than the other models.</p>    <p>We optimized model Pair_S2S_Cxt_Embed_MP further with the goal of improving latency during online prediction. The performance bottleneck for sequence to sequence model is at decoding. The last layer at each time step projects the LSTM output to a vocabulary-sized vector (200K here) and then runs a softmax on top of that, which involves a huge matrix multiplication and element summation. To mitigate the burden here, during prediction, we truncate the vocabulary to just the words that appear in the inputs (context + current query), plus some pre-selected stop-words (to maintain the language model information learned from training). This optimization improves latency by 10 times. Furthermore, accuracy is also improved, as you can see in the results for Pair_S2S_Cxt_Embed_MP + vocabulary truncation in Table <a class="tbl" href="#tab3">3</a>.</p>    <p>This might be because users do not often use new words to reformulate their conversational queries, they mostly use words that they already used in the context. This might also expose a limitation of our current dataset: the lack of paraphrases in target outputs, due to the constrain that query 3 has to contain terms from query 2 and query 1, as described in Section 3. To obtain more paraphrase-style target reformulations, human labeling is required, which will be part of our future work.</p>    <section id="sec-18">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.1</span> Examples and Analysis</h3>     </div>    </header>    <p>Here is a sample query session that was inputted to the best sequence to sequence model. The arrow indicates the output of the model. No arrow means that the model outputted the original query without any reformulation. The model and this paper is not concerned with answering the queries, so the answers were simply obtained by issuing these queries to a commercial search engine.</p>    <ul class="list-no-style">     <li id="uid41" label="Q:">When was California founded?<br/></li>     <li id="uid42" label="A:">September 9, 1850<br/></li>     <li id="uid43" label="Q:">Who is its governor? &#x2192; Who is California governor?<br/></li>     <li id="uid44" label="A:">Jerry Brown<br/></li>     <li id="uid45" label="Q:">Where is Stanford?<br/></li>     <li id="uid46" label="A:">Palo Alto, California<br/></li>     <li id="uid47" label="Q:">Who founded it? &#x2192; Who founded Stanford?<br/></li>     <li id="uid48" label="A:">Leland and Jane Stanford<br/></li>     <li id="uid49" label="Q:">Tuition costs &#x2192; Tuition costs Stanford<br/></li>     <li id="uid50" label="A:"><font style="normal">&#x0024;</font>47,940 USD<br/></li>     <li id="uid51" label="Q:">How to split string in Python?<br/></li>     <li id="uid52" label="A:">split()<br/></li>     <li id="uid53" label="Q:">How to read file? &#x2192; How to read file in Python?<br/></li>     <li id="uid54" label="A:">open()<br/></li>     <li id="uid55" label="Q:">Kobe Bryant height<br/></li>     <li id="uid56" label="A:">6&#x2019;6&#x201D;<br/></li>     <li id="uid57" label="Q:">His birth date &#x2192; Kobe Bryant birth date<br/></li>     <li id="uid58" label="A:">August 23, 1978<br/></li>     <li id="uid59" label="Q:">What are the similarities between bacteria and viruses?<br/></li>     <li id="uid60" label="A:">The similarities are...<br/></li>     <li id="uid61" label="Q:">What are the differences? &#x2192; What are the differences between bacteria and viruses?<br/></li>     <li id="uid62" label="A:">The differences are...<br/></li>    </ul>    <p>This sample session shows that the model is able to perform reformulations that involve coreference resolution and also when there aren&#x0027;t any anaphoras. The model is able to pass different types of context, from &#x201D;Kobe Bryant&#x201D; to &#x201D;between bacteria and viruses&#x201D;. The model is also able to determine when the topic changes and the query no longer depends on previous context, e.g. when the topic switched from Stanford to Python, the context of Stanford is no longer passed. Natural language questions and keyword queries are both handled.</p>    <p>To illustrate how the Pair_S2S_Cxt_Embed_MP + vocab truncate model improves on the baseline Concate_S2S model, Table <a class="tbl" href="#tab4">4</a> shows a few examples where this final model produced the correct output while the baseline was incorrect. For the first example, the baseline model added the wrong term from the context. For the second and third examples, it did not append any context. We suspect this is because both Q2s could be valid standalone queries, only by paying careful attention to Q1 can it be determined that context needs to be added.</p>    <p>In summary, the baseline model generated predictions that were not conditioned as strongly on Q1, a problem that was mitigated in the final model because of its context-aware query and pair sequences to sequence architecture, which provide greater dependence on the context, Q1, at both the encoding and decoding steps.</p>    <div class="table-responsive" id="tab4">     <div class="table-caption">      <span class="table-number">Table 4:</span>      <span class="table-title">Example predictions from different models.</span>     </div>     <table class="table">      <tbody>       <tr style="border-bottom: solid 2px">       <td style="text-align:center; border-right: solid 2px"/>       <td style="text-align:center; border-right: solid 2px">Concate_S2S</td>       <td style="text-align:center;">Pair_S2S_Cxt_Embed_MP + vocab truncate</td>       </tr>       <tr>       <td colspan="3" style="text-align:left;">Q1 = common math letter for scalar, Q2 = what is the integral<hr/>       </td>       </tr>       <tr style="border-bottom: solid 2px">       <td style="text-align:center; border-right: solid 2px">Prediction</td>       <td style="text-align:center; border-right: solid 2px">what is the integral in common</td>       <td style="text-align:center;">what is the integral in math</td>       </tr>       <tr>       <td colspan="3" style="text-align:left;">Q1 = who is andy from toy story, Q2 = what happened to sid<hr/>       </td>       </tr>       <tr style="border-bottom: solid 2px">       <td style="text-align:center; border-right: solid 2px">Prediction</td>       <td style="text-align:center; border-right: solid 2px">what happened to sid</td>       <td style="text-align:center;">what happened to sid on toy story</td>       </tr>       <tr>       <td colspan="3" style="text-align:left; border-right: solid 2px">Q1 = what major studies multiculturalism in college<br/>Q2 = how to ask for a reference<hr/>       </td>       </tr>       <tr>       <td style="text-align:center; border-right: solid 2px">Prediction</td>       <td style="text-align:center; border-right: solid 2px">how to ask for a reference</td>       <td style="text-align:center;">how to ask for a reference for college</td>       </tr>      </tbody>     </table>    </div>    <p>However, this final model still has several weaknesses. It does well with common entities and concepts, but struggles with rare entities and concepts. For example, the model does not reformulate &#x201D;His birth date&#x201D; if the previous query was about Sasha Vujacic, a less popular basketball player. The model also still sometimes struggle with copying over the entire original query when it is necessary, especially for long queries. Some kind of pointer mechanism might help here [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0016">16</a>]. Another weakness of the model is that it can&#x0027;t recognize some specific patterns of conversational queries, such as &#x201D;How tall is Kobe Bryant? What about Lebron James?&#x201D;. This is likely because even among the millions of samples in the dataset, there is not enough samples of such patterns for the model to learn from.</p>    </section>   </section>   <section id="sec-19">    <header>    <div class="title-info">     <h2>      <span class="section-number">7</span> Conclusion</h2>    </div>    </header>    <p>In conclusion, using the first ever large scale and general dataset of conversational queries, a few sequence to sequence models were proposed, with the best one successfully reformulating more than half of all conversational queries across a very wide range of topics. There is still a ton of progress to be made, due to the many challenges of CQU presented earlier in this paper.</p>    <p>Immediate future work includes mining more data from the search engine logs to increase the size of the dataset, and retraining and further tuning the existing models. Incorporating the pointer mechanism might help as described above. Also based on the errors, augmenting the dataset with entity types, POS tags, and other NLP properties might help with generalization to uncommon entities. Another approach would be to artificially generating new samples by swapping entities for other entities of the same type, which has been shown to improve performance on other tasks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>]. We will also continue to explore new model architectures. For example, models proposed in Sordoni et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>] and Dehghani et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>] might be worth trying because they also modeled consecutive queries in a session using sequence to sequence, although they focused on the query suggestion scenario.</p>    <p>Despite the tremendous potential for further improvements on this task, the results in this paper already demonstrate a significant first step towards CQU, which can be incorporated into and improve any of the aforementioned conversational technologies, and have shown that deep learning is a promising approach for this task.</p>   </section>  </section>  <section class="back-matter">   <section id="sec-20">    <header>    <div class="title-info">     <h2>ACKNOWLEDGMENTS</h2>    </div>    </header>    <p>We would like to thank the anonymous reviewers for their helpful comments. We would aso like to thank our colleagues from Microsoft Research: Wei Wu, Can Xu and Ming Zhou for their constructive suggestion and feedbacks during the development of this work, particularly the vocabulary truncation idea for latency optimization; Wenhan Wang and Yuxiong He for their effort on optimizing inference latency.</p>   </section>   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. <em>      <em>arXiv preprint arXiv:1409.0473</em>     </em>(2014).</li>    <li id="BibPLXBIB0002" label="[2]">Rafael&#x00A0;E Banchs. 2012. Movie-DiC: a movie dialogue corpus for research and development. In <em>      <em>Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2</em>     </em>. Association for Computational Linguistics, 203&#x2013;207.</li>    <li id="BibPLXBIB0003" label="[3]">Ziv Bar-Yossef and Naama Kraus. 2011. Context-sensitive query auto-completion. In <em>      <em>Proceedings of the 20th international conference on World wide web</em>     </em>. ACM, 107&#x2013;116.</li>    <li id="BibPLXBIB0004" label="[4]">Yoshua Bengio. 2012. Practical recommendations for gradient-based training of deep architectures. In <em>      <em>Neural networks: Tricks of the trade</em>     </em>. Springer, 437&#x2013;478.</li>    <li id="BibPLXBIB0005" label="[5]">Huanhuan Cao, Daxin Jiang, Jian Pei, Enhong Chen, and Hang Li. 2009. Towards context-aware search by learning a very large variable length hidden markov model from search logs. In <em>      <em>Proceedings of the 18th international conference on World wide web</em>     </em>. ACM, 191&#x2013;200.</li>    <li id="BibPLXBIB0006" label="[6]">Huanhuan Cao, Daxin Jiang, Jian Pei, Qi He, Zhen Liao, Enhong Chen, and Hang Li. 2008. Context-aware query suggestion by mining click-through and session data. In <em>      <em>Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</em>     </em>. ACM, 875&#x2013;883.</li>    <li id="BibPLXBIB0007" label="[7]">Kyunghyun Cho, Bart Van&#x00A0;Merri&#x00EB;nboer, Dzmitry Bahdanau, and Yoshua Bengio. 2014. On the properties of neural machine translation: Encoder-decoder approaches. <em>      <em>arXiv preprint arXiv:1409.1259</em>     </em>(2014).</li>    <li id="BibPLXBIB0008" label="[8]">Kyunghyun Cho, Bart Van&#x00A0;Merri&#x00EB;nboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. <em>      <em>arXiv preprint arXiv:1406.1078</em>     </em>(2014).</li>    <li id="BibPLXBIB0009" label="[9]">Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. <em>      <em>arXiv preprint arXiv:1412.3555</em>     </em>(2014).</li>    <li id="BibPLXBIB0010" label="[10]">Kevin Clark and Christopher&#x00A0;D Manning. 2016. Deep reinforcement learning for mention-ranking coreference models. <em>      <em>arXiv preprint arXiv:1609.08667</em>     </em>(2016).</li>    <li id="BibPLXBIB0011" label="[11]">Cristian Danescu-Niculescu-Mizil, Lillian Lee, Bo Pang, and Jon Kleinberg. 2012. Echoes of power: Language effects and power differences in social interaction. In <em>      <em>Proceedings of the 21st international conference on World Wide Web</em>     </em>. ACM, 699&#x2013;708.</li>    <li id="BibPLXBIB0012" label="[12]">Mostafa Dehghani, Sascha Rothe, Enrique Alfonseca, and Pascal Fleury. 2017. Learning to attend, copy, and generate for session-based query suggestion. <em>      <em>arXiv preprint arXiv:1708.03418</em>     </em>(2017).</li>    <li id="BibPLXBIB0013" label="[13]">Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, and Li Deng. 2017. Towards end-to-end reinforcement learning of dialogue agents for information access. In <em>      <em>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>     </em>, Vol.&#x00A0;1. 484&#x2013;495.</li>    <li id="BibPLXBIB0014" label="[14]">John&#x00A0;W Du&#x00A0;Bois, Wallace&#x00A0;L Chafe, Charles Meyer, Sandra&#x00A0;A Thompson, and Nii Martey. 2000. Santa Barbara Corpus of Spoken American English. <em>      <em>CD-ROM. Philadelphia: Linguistic Data Consortium</em>     </em> (2000).</li>    <li id="BibPLXBIB0015" label="[15]">Mihajlo Grbovic, Nemanja Djuric, Vladan Radosavljevic, Fabrizio Silvestri, and Narayan Bhamidipati. 2015. Context-and content-aware embeddings for query rewriting in sponsored search. In <em>      <em>Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>     </em>. ACM, 383&#x2013;392.</li>    <li id="BibPLXBIB0016" label="[16]">Caglar Gulcehre, Sungjin Ahn, Ramesh Nallapati, Bowen Zhou, and Yoshua Bengio. 2016. Pointing the unknown words. <em>      <em>arXiv preprint arXiv:1603.08148</em>     </em>(2016).</li>    <li id="BibPLXBIB0017" label="[17]">Yunlong He, Jiliang Tang, Hua Ouyang, Changsung Kang, Dawei Yin, and Yi Chang. 2016. Learning to Rewrite Queries. In <em>      <em>Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</em>     </em>. ACM, 1443&#x2013;1452.</li>    <li id="BibPLXBIB0018" label="[18]">Sepp Hochreiter and J&#x00FC;rgen Schmidhuber. 1997. Long short-term memory. <em>      <em>Neural computation</em>     </em>9, 8 (1997), 1735&#x2013;1780.</li>    <li id="BibPLXBIB0019" label="[19]">Seokhwan Kim, Luis&#x00A0;Fernando D&#x0027;Haro, Rafael&#x00A0;E Banchs, Jason&#x00A0;D Williams, and Matthew Henderson. 2017. The fourth dialog state tracking challenge. In <em>      <em>Dialogues with Social Robots</em>     </em>. Springer, 435&#x2013;449.</li>    <li id="BibPLXBIB0020" label="[20]">Liangda Li, Hongbo Deng, Jianhui Chen, and Yi Chang. 2017. Learning parametric models for context-aware query auto-completion via hawkes processes. In <em>      <em>Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</em>     </em>. ACM, 131&#x2013;139.</li>    <li id="BibPLXBIB0021" label="[21]">Liangda Li, Hongbo Deng, Anlei Dong, Yi Chang, Ricardo Baeza-Yates, and Hongyuan Zha. 2017. Exploring Query Auto-Completion and Click Logs for Contextual-Aware Web Search and Query Suggestion. In <em>      <em>Proceedings of the 26th International Conference on World Wide Web</em>     </em>. International World Wide Web Conferences Steering Committee, 539&#x2013;548.</li>    <li id="BibPLXBIB0022" label="[22]">Ryan Lowe, Nissan Pow, Iulian Serban, and Joelle Pineau. 2015. The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems. <em>      <em>arXiv preprint arXiv:1506.08909</em>     </em>(2015).</li>    <li id="BibPLXBIB0023" label="[23]">Minh-Thang Luong, Hieu Pham, and Christopher&#x00A0;D Manning. 2015. Effective approaches to attention-based neural machine translation. <em>      <em>arXiv preprint arXiv:1508.04025</em>     </em>(2015).</li>    <li id="BibPLXBIB0024" label="[24]">Christopher&#x00A0;D Manning, Mihai Surdeanu, John Bauer, Jenny&#x00A0;Rose Finkel, Steven Bethard, and David McClosky. 2014. The stanford corenlp natural language processing toolkit.. In <em>      <em>ACL (System Demonstrations)</em>     </em>. 55&#x2013;60.</li>    <li id="BibPLXBIB0025" label="[25]">Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In <em>      <em>Proceedings of the 40th annual meeting on association for computational linguistics</em>     </em>. Association for Computational Linguistics, 311&#x2013;318.</li>    <li id="BibPLXBIB0026" label="[26]">Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word representation. In <em>      <em>Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</em>     </em>. 1532&#x2013;1543.</li>    <li id="BibPLXBIB0027" label="[27]">Aaditya Prakash, Sadid&#x00A0;A Hasan, Kathy Lee, Vivek Datla, Ashequl Qadir, Joey Liu, and Oladimeji Farri. 2016. Neural Paraphrase Generation with Stacked Residual LSTM Networks. <em>      <em>arXiv preprint arXiv:1610.03098</em>     </em>(2016).</li>    <li id="BibPLXBIB0028" label="[28]">Gil Press. 2017. AI By The Numbers: 33 Facts And Forecasts About Chatbots And Voice Assistants. (2017). <a class="link-inline force-break"      href="https://www.forbes.com/sites/gilpress/2017/05/15/ai-by-the-numbers-33-facts-and-forecasts-about-chatbots-and-voice-assistants"      target="_blank">https://www.forbes.com/sites/gilpress/2017/05/15/ai-by-the-numbers-33-facts-and-forecasts-about-chatbots-and-voice-assistants</a> Retrieved October 23, 2017 from</li>    <li id="BibPLXBIB0029" label="[29]">Jonathan Raiman and John Miller. 2017. Globally normalized reader. <em>      <em>arXiv preprint arXiv:1709.02828</em>     </em>(2017).</li>    <li id="BibPLXBIB0030" label="[30]">Xuehua Shen, Bin Tan, and ChengXiang Zhai. 2005. Context-sensitive information retrieval using implicit feedback. In <em>      <em>Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</em>     </em>. ACM, 43&#x2013;50.</li>    <li id="BibPLXBIB0031" label="[31]">Satinder&#x00A0;P Singh, Michael&#x00A0;J Kearns, Diane&#x00A0;J Litman, and Marilyn&#x00A0;A Walker. 2000. Reinforcement learning for spoken dialogue systems. In <em>      <em>Advances in Neural Information Processing Systems</em>     </em>. 956&#x2013;962.</li>    <li id="BibPLXBIB0032" label="[32]">Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob Grue&#x00A0;Simonsen, and Jian-Yun Nie. 2015. A hierarchical recurrent encoder-decoder for generative context-aware query suggestion. In <em>      <em>Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</em>     </em>. ACM, 553&#x2013;562.</li>    <li id="BibPLXBIB0033" label="[33]">Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015. A neural network approach to context-sensitive generation of conversational responses. <em>      <em>arXiv preprint arXiv:1506.06714</em>     </em>(2015).</li>    <li id="BibPLXBIB0034" label="[34]">Aixin Sun and Chii-Hian Lou. 2014. Towards context-aware search with right click. In <em>      <em>Proceedings of the 37th international ACM SIGIR conference on Research &#x0026; development in information retrieval</em>     </em>. ACM, 847&#x2013;850.</li>    <li id="BibPLXBIB0035" label="[35]">Ilya Sutskever, Oriol Vinyals, and Quoc&#x00A0;V Le. 2014. Sequence to sequence learning with neural networks. In <em>      <em>Advances in neural information processing systems</em>     </em>. 3104&#x2013;3112.</li>    <li id="BibPLXBIB0036" label="[36]">Oriol Vinyals, &#x0141;ukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, and Geoffrey Hinton. 2015. Grammar as a foreign language. In <em>      <em>Advances in Neural Information Processing Systems</em>     </em>. 2773&#x2013;2781.</li>    <li id="BibPLXBIB0037" label="[37]">Zhiguo Wang, Wael Hamza, and Radu Florian. 2017. Bilateral multi-perspective matching for natural language sentences. <em>      <em>arXiv preprint arXiv:1702.03814</em>     </em>(2017).</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186083">https://doi.org/10.1145/3178876.3186083</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
