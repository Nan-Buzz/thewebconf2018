<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Fast and Accurate Random Walk with Restart on Dynamic Graphs with Guarantees</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
  <link rel="cite-as" href="https://doi.org/10.1145/3178876.3186107"/>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186107'>https://doi.org/10.1145/3178876.3186107</a>.
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186107'>https://w3id.org/oa/10.1145/3178876.3186107</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Fast and Accurate Random Walk with Restart on Dynamic Graphs with Guarantees</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Minji</span> <span class="surName">Yoon</span>, Seoul National University, <a href="mailto:riin55@snu.ac.kr">riin55@snu.ac.kr</a>
        </div>
        <div class="author">
          <span class="givenName">Woojeong</span> <span class="surName">Jin</span>, Seoul National University, <a href="mailto:woojung211@snu.ac.kr">woojung211@snu.ac.kr</a>
        </div>
        <div class="author">
          <span class="givenName">U</span> <span class="surName">Kang</span>, Seoul National University, <a href="mailto:ukang@snu.ac.kr">ukang@snu.ac.kr</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.33186107" target="_blank">https://doi.org/10.1145/3178876.33186107</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Given a time-evolving graph, how can we track similarity between nodes in a fast and accurate way, with theoretical guarantees on the convergence and the error? Random Walk with Restart (RWR) is a popular measure to estimate the similarity between nodes and has been exploited in numerous applications. Many real-world graphs are dynamic with frequent insertion/deletion of edges; thus, tracking RWR scores on dynamic graphs in an efficient way has aroused much interest among data mining researchers. Recently, dynamic RWR models based on the propagation of scores across a given graph have been proposed, and have succeeded in outperforming previous other approaches to compute RWR dynamically. However, those models fail to guarantee exactness and convergence time for updating RWR in a generalized form.</small></p>
        <p><small>In this paper, we propose <font style="font-variant: small-caps">OSP</font>, a fast and accurate algorithm for computing dynamic RWR with insertion/deletion of nodes/edges in a directed/undirected graph. When the graph is updated, <font style="font-variant: small-caps">OSP</font> first calculates offset scores around the modified edges, propagates the offset scores across the updated graph, and then merges them with the current RWR scores to get updated RWR scores. We prove the exactness of <font style="font-variant: small-caps">OSP</font> and introduce <font style="font-variant: small-caps">OSP-T</font>, a version of <font style="font-variant: small-caps">OSP</font> which regulates a trade-off between accuracy and computation time by using error tolerance ϵ. Given restart probability <em>c</em>, <font style="font-variant: small-caps">OSP-T</font> guarantees to return RWR scores with <em>O</em>(ϵ/<em>c</em>) error in <span class="inline-equation"><span class="tex">$O(\log _{(1-c)}(\frac{\epsilon }{2}))$</span></span> iterations. Through extensive experiments, we show that <font style="font-variant: small-caps">OSP</font> tracks RWR exactly up to 4605 × faster than existing static RWR method on dynamic graphs, and <font style="font-variant: small-caps">OSP-T</font> requires up to 15 × less time with 730 × lower <em>L</em>1 norm error and 3.3 × lower rank error than other state-of-the-art dynamic RWR methods.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS Concepts:</span> • <strong>Information systems</strong> → <em>Data mining;</em> • <strong>Networks</strong> → <strong>Online social networks;</strong></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style="font-weight:bold;"><small>Keywords:</small></span> <span class="keyword"><small>Random Walk with Restart</small>,</span> <span class="keyword"><small>Online algorithm</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Minji Yoon, Woojeong Jin, and U Kang. 2018. Fast and Accurate Random Walk with Restart on Dynamic Graphs with Guarantees. In <em>WWW 2018: The 2018 Web Conference,</em> <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New York, NY, USA</em> 11 Pages. <a href="https://doi.org/10.1145/3178876.33186107" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3178876.33186107</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class="table-title">Comparison of our proposed <font style="font-variant: small-caps">OSP</font>, <font style="font-variant: small-caps">OSP-T</font> and existing methods for RWR computation on dynamic graphs. <font style="font-variant: small-caps">OSP</font> computes dynamic RWR exactly with reasonable time, while <font style="font-variant: small-caps">OSP-T</font> shows the best trade-off between speed and accuracy among approximate methods. <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> apply to the most general settings with guarantees.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:left;"><strong>Method</strong></th>
              <th style="text-align:left;"><strong>Speed</strong></th>
              <th style="text-align:left;"><strong>Accuracy</strong></th>
              <th style="text-align:left;"><strong>Coverage</strong></th>
              <th style="text-align:left;"><strong>Accuracy Bound</strong></th>
              <th style="text-align:left;"><strong>Time complexity model</strong></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:left;">
                TrackingPPR&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>]
              </td>
              <td style="text-align:left;">Fast</td>
              <td style="text-align:left;">Low</td>
              <td style="text-align:left;">Undirected graph</td>
              <td style="text-align:left;">No</td>
              <td style="text-align:left;">Only with insertion of edges</td>
            </tr>
            <tr>
              <td style="text-align:left;">
                LazyForward&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>]
              </td>
              <td style="text-align:left;">Fast</td>
              <td style="text-align:left;">Low</td>
              <td style="text-align:left;">Undirected graph</td>
              <td style="text-align:left;">No</td>
              <td style="text-align:left;">Only with undirected graph</td>
            </tr>
            <tr>
              <td style="text-align:left;"><font style="font-variant: small-caps"><strong>OSP</strong></font></td>
              <td style="text-align:left;"><strong>Medium</strong></td>
              <td style="text-align:left;"><strong>High</strong></td>
              <td style="text-align:left;"><strong>Directed/Undirected graph</strong></td>
              <td style="text-align:left;"><strong>Yes</strong></td>
              <td style="text-align:left;"><strong>General</strong></td>
            </tr>
            <tr>
              <td style="text-align:left;"><font style="font-variant: small-caps"><strong>OSP-T</strong></font></td>
              <td style="text-align:left;"><strong>Faster</strong></td>
              <td style="text-align:left;"><strong>Medium</strong></td>
              <td style="text-align:left;"><strong>Directed/Undirected graph</strong></td>
              <td style="text-align:left;"><strong>Yes</strong></td>
              <td style="text-align:left;"><strong>General</strong></td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>Identifying similarity score between two nodes in a graph has been recognized as a fundamental tool to analyze the graph&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>] and has been exploited in various graph mining tasks&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>]. Among numerous methods&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>] to measure the similarity, random walk with restart (RWR)&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>] has aroused considerable attention due to its ability to account for the global network structure from a particular user's point of view. To avoid expensive costs incurred by RWR computation, various methods have been proposed to calculate RWR scores efficiently, and the majority of them have focused on static graphs&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0024">24</a>]. However, many real-world graphs are dynamic. For example, in an online social network of Facebook which has more than 1.3 billion users, 5 new users are added every second&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>]. Thus it is an indispensable task to track RWR scores on time-evolving graphs.</p>
      <p>Various approaches have been proposed to handle dynamic RWR problem efficiently. Chien et al.&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>] introduced an approximate aggregation/disaggregation method which updates RWR scores only around modified edges. Bahmani et al.&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>] applied the Monte-Carlo method&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>] on the dynamic RWR problem. Recently, score propagation models were proposed by Ohsaka et al.&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>] and Zhang et al.&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>]; Ohsaka et al. proposed TrackingPPR which propagates scores using Gauss-Southwell algorithm; Zhang et al. proposed LazyForward which optimizes the initial step from TrackingPPR and propagates scores using Forward Push algorithm. They succeed in outperforming the previous approaches in both running time and accuracy&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>]. However, they fail to provide theoretical analysis of accuracy bound. Furthermore, they narrow down the scope of their analyses on time complexity to graph modifications only with insertion of edges or graph modifications on undirected graphs.</p>
      <p>In this paper, we propose <font style="font-variant: small-caps">OSP</font> &nbsp;(Offset Score Propagation for RWR), a fast and accurate method model for computing RWR scores on dynamic graphs. <font style="font-variant: small-caps">OSP</font> is based on cumulative power iteration (<font style="font-variant: small-caps">CPI</font>)&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>] which interprets an RWR problem as propagation of scores from a seed node across a graph in an iterative matrix-vector multiplication form. When the graph is updated, <font style="font-variant: small-caps">OSP</font> first calculates offset scores made around the updated edges, and then propagates the offset scores across the modified graph using <font style="font-variant: small-caps">CPI</font>. The small size of the offset scores leads to fast convergence. Then <font style="font-variant: small-caps">OSP</font> merges the result of the propagation with the current RWR scores to get an updated RWR scores. We also propose <font style="font-variant: small-caps">OSP-T</font>, a version of <font style="font-variant: small-caps">OSP</font>, with provable error bound and running time: given restart probability <em>c</em> and error tolerance ϵ, <font style="font-variant: small-caps">OSP-T</font> computes RWR scores with <em>O</em>(ϵ/<em>c</em>) error in <span class="inline-equation"><span class="tex">$O(\log _{(1-c)}(\frac{\epsilon }{2}))$</span></span> iterations in dynamic graphs. Through extensive experiments with various real-world graphs, we demonstrate the superior performance of <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> over existing methods. Table&nbsp;<a class="tbl" href="#tab1">1</a> and Figure&nbsp;<a class="fig" href="#fig1">1</a> show a comparison of <font style="font-variant: small-caps">OSP</font>, <font style="font-variant: small-caps">OSP-T</font>, and existing methods. The main contributions of this paper are the followings:</p>
      <ul class="list-no-style">
        <li id="list1" label="•"><strong>Algorithm.</strong> We introduce <font style="font-variant: small-caps">OSP</font>, a fast and accurate method to compute RWR on dynamic graphs. We also propose <font style="font-variant: small-caps">OSP-T</font>, a version of <font style="font-variant: small-caps">OSP</font> which regulates a trade-off between accuracy and computation time by using an error tolerance parameter.<br /></li>
        <li id="list2" label="•"><strong>Analysis.</strong> We present a theoretical analysis on exactness of <font style="font-variant: small-caps">OSP</font>, and time complexity and error bound of <font style="font-variant: small-caps">OSP-T</font>. Our analysis is applicable to general dynamic graphs: insertion / deletion of nodes / edges in directed / undirected graphs.<br /></li>
        <li id="list3" label="•"><strong>Experiment.</strong> We present extensive empirical evidences for the performance of <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> using various dynamic real-world graphs.<br />
        We show that <font style="font-variant: small-caps">OSP</font> tracks RWR exactly up to 4605 × faster than existing static RWR method, and <font style="font-variant: small-caps">OSP-T</font> requires up to 15 × less time with 730 × lower <em>L</em>1 norm error and 3.3 × lower rank error than other dynamic RWR methods.<br /></li>
      </ul>
      <p>The code of our method and datasets used in the paper are available at <a class="link-inline force-break" href="http://datalab.snu.ac.kr/osp">http://datalab.snu.ac.kr/osp</a>. The rest of the paper is organized as follows. In Section&nbsp;<a class="sec" href="#sec-5">2</a>, we describe preliminaries on RWR and <font style="font-variant: small-caps">CPI</font>. In Section&nbsp;<a class="sec" href="#sec-8">3</a>, we present the proposed model <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> in detail along with theoretical analyses. After presenting our experimental results in Section&nbsp;<a class="sec" href="#sec-17">4</a>, we provide a review on related works in Section&nbsp;<a class="sec" href="#sec-30">5</a> and conclude in Section&nbsp;<a class="sec" href="#sec-31">6</a>. The symbols frequently used in this paper are summarized in Table&nbsp;<a class="tbl" href="#tab2">2</a>.</p>
      <figure id="fig1">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186107/images/www2018-116-fig1.jpg" class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class="figure-title">Trade-off between accuracy and time: <font style="font-variant: small-caps">OSP-T</font> shows the best trade-off between speed and accuracy among approximate methods for dynamic RWR.</span>
        </div>
      </figure>
      <p></p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Preliminaries</h2>
        </div>
      </header>
      <p>In this section, we briefly review RWR&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>], and explain <font style="font-variant: small-caps">CPI</font> &nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>], an iterative method for RWR computation.</p>
      <section id="sec-6">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Random Walk with Restart</h3>
          </div>
        </header>
        <p>Random walk with restart (RWR)&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>] estimates each node's relevance with regard to a given seed node <em>s</em> in a graph. RWR assumes a random surfer who starts at node <em>s</em>. In each step, the surfer follows edges with probability 1 − <em>c</em>, or jumps to the seed node with probability <em>c</em>. The surfer chooses an edge to move on with uniform probability among all current outgoing edges. The vector <strong>r</strong> representing each node's visiting probability satisfies the following equation:</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf {r}=(1-c) \mathbf {\tilde{A}}^{\top }\mathbf {r}+ c \mathbf {q} \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>where <span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}$</span></span> is a row-normalized adjacency matrix and <strong>q</strong> is a starting vector whose <em>s</em>th element is 1 and other elements are 0.
        <p></p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class="table-title">Table of symbols.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;"><strong>Symbol</strong></th>
                <th style="text-align:left;"><strong>Definition</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;"><em>G</em></td>
                <td style="text-align:left;">input graph</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>ΔG</em></td>
                <td style="text-align:left;">update in graph</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>n</em>, <em>m</em></td>
                <td style="text-align:left;">numbers of nodes and edges in <em>G</em></td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>s</em></td>
                <td style="text-align:left;">seed node (= query node, source node)</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>c</em></td>
                <td style="text-align:left;">restart probability</td>
              </tr>
              <tr>
                <td style="text-align:center;">ϵ</td>
                <td style="text-align:left;">error tolerance</td>
              </tr>
              <tr>
                <td style="text-align:center;"><strong>q</strong></td>
                <td style="text-align:left;">(<em>n</em> × 1) starting vector whose <em>s</em>th element is 1</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">and other elements are 0</td>
              </tr>
              <tr>
                <td style="text-align:center;"><span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}$</span></span></td>
                <td style="text-align:left;">(<em>n</em> × <em>n</em>) row-normalized adjacency matrix of <em>G</em></td>
              </tr>
              <tr>
                <td style="text-align:center;"><span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}$</span></span></td>
                <td style="text-align:left;">(<em>n</em> × <em>n</em>) row-normalized adjacency matrix of <em>G</em> + <em>ΔG</em></td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>Δ</em> <strong>A</strong></td>
                <td style="text-align:left;">(<em>n</em> × <em>n</em>) difference between <span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}$</span></span> and <span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}$</span></span> (<span class="inline-equation"><span class="tex">$= \mathbf {\tilde{B}}- \mathbf {\tilde{A}}$</span></span> )</td>
              </tr>
              <tr>
                <td style="text-align:center;"><strong>r</strong> <sub>old</sub></td>
                <td style="text-align:left;">(<em>n</em> × 1) RWR vector on <em>G</em></td>
              </tr>
              <tr>
                <td style="text-align:center;"><strong>r</strong> <sub>new</sub></td>
                <td style="text-align:left;">(<em>n</em> × 1) updated RWR vector on <em>G</em> + <em>ΔG</em></td>
              </tr>
              <tr>
                <td style="text-align:center;"><strong>q</strong> <sub>offset</sub></td>
                <td style="text-align:left;">(<em>n</em> × 1) offset seed vector</td>
              </tr>
              <tr>
                <td style="text-align:center;"><span class="inline-equation"><span class="tex">$\mathbf {x}_{\text{offset}}^{(i)}$</span></span></td>
                <td style="text-align:left;">(<em>n</em> × 1) interim offset score vector at <em>i</em>th iteration in <font style="font-variant: small-caps">OSP</font></td>
              </tr>
              <tr>
                <td style="text-align:center;"><strong>r</strong> <sub>offset</sub></td>
                <td style="text-align:left;">(<em>n</em> × 1) offset score vector</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> <font style="font-variant: small-caps">CPI</font>: Cumulative Power Iteration</h3>
          </div>
        </header>
        <p>Cumulative power iteration (<font style="font-variant: small-caps">CPI</font>)&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>] interprets an RWR problem as a propagation of scores across a graph in an iterative matrix-vector multiplication form: at first, a score <em>c</em> is generated from a seed node; at each iteration, scores are divided and propagated evenly into out-edges with decaying coefficient 1 − <em>c</em>. <strong>x</strong> <sup>(<em>i</em>)</sup> is an interim score vector computed from the iteration <em>i</em> and has scores propagated across nodes at <em>i</em>th iteration as entries. When multiplied with <span class="inline-equation"><span class="tex">$(1-c)\mathbf {\tilde{A}}^{\top }$</span></span> , scores in <strong>x</strong> <sup>(<em>i</em>)</sup> are propagated into their outgoing neighbors, and the propagated scores are stored in <strong>x</strong> <sup>(<em>i</em> + 1)</sup>. <font style="font-variant: small-caps">CPI</font> accumulates interim score vectors <strong>x</strong> <sup>(<em>i</em>)</sup> to get the final RWR score vector <span class="inline-equation"><span class="tex">$\mathbf {r}_{\text{CPI}}$</span></span> as follows.</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{align*} \mathbf {x}^{(0)} &amp;= \mathbf {q}_{\text{CPI}} \\\mathbf {x}^{(i)} &amp;= (1-c)\mathbf {\tilde{A}}^{\top }\mathbf {x}^{(i-1)} = \left((1-c)\mathbf {\tilde{A}}^{\top }\right)^{i}\mathbf {q}_{\text{CPI}} \\\mathbf {r}_{\text{CPI}} &amp;= \sum _{i=0}^{\infty }\mathbf {x}^{(i)} = \sum _{i=0}^{\infty }\left((1-c)\mathbf {\tilde{A}}^{\top }\right)^{i}\mathbf {q}_{\text{CPI}}\end{align*}</span><br />
          </div>
        </div><span class="inline-equation"><span class="tex">$\mathbf {q}_{\text{CPI}}$</span></span> is a seed vector which contains initial scores for propagation. To satisfy Equation&nbsp;<a class="eqn" href="#eq1">1</a>, <span class="inline-equation"><span class="tex">$\mathbf {q}_{\text{CPI}}$</span></span> needs to be set with <em>c</em> <strong>q</strong> where an initial score <em>c</em> is located at seed index <em>s</em>. In other words, setting the seed vector <span class="inline-equation"><span class="tex">$\mathbf {q}_{\text{CPI}}$</span></span> with other values leads to wrong RWR values in <font style="font-variant: small-caps">CPI</font>. Unlike other propagation methods such as Gauss-Southwell algorithm&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>] and Forward Local Push algorithm&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>], <font style="font-variant: small-caps">CPI</font> computes RWR with accuracy assurance and general time complexity model. Thus we propose dynamic RWR method <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> using <font style="font-variant: small-caps">CPI</font> to provide theoretical guarantees on the error and the convergence.
        <p></p>
      </section>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Proposed Method</h2>
        </div>
      </header>
      <p>In this section, we describe our proposed method <font style="font-variant: small-caps">OSP</font> for tracking RWR on dynamic graphs, and introduce <font style="font-variant: small-caps">OSP-T</font>, a version of <font style="font-variant: small-caps">OSP</font> which regulates a trade-off between accuracy and computation time on dynamic graphs.</p>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> <font style="font-variant: small-caps">OSP</font>: Offset Score Propagation</h3>
          </div>
        </header>
        <p>In <font style="font-variant: small-caps">CPI</font>, scores are propagated following underlying edges, and the score accumulated in each node becomes RWR score of the node in a given graph. In other words, RWR scores of nodes are determined by arrangement of edges. In this sense, when the graph <em>G</em> is updated with an insertion/deletion of edges (<em>ΔG</em>), propagation of scores around <em>ΔG</em> is changed: with insertion of an edge <em>e</em> = (<em>u</em>, <em>v</em>), score <em>x<sub>u</sub></em> from the node <em>u</em> would be propagated into each out-edges with smaller scores <span class="inline-equation"><span class="tex">$\frac{x_{u}}{d_{u}+1}$</span></span> than previous propagated scores <span class="inline-equation"><span class="tex">$\frac{x_{u}}{d_{u}}$</span></span> where <em>d<sub>u</sub></em> is the number of out-edges of node <em>u</em> before <em>ΔG</em>; with deletion of an edge <em>e</em> = (<em>u</em>, <em>v</em>), score <em>x<sub>u</sub></em> from the node <em>u</em> would be propagated into each out-edges with higher scores <span class="inline-equation"><span class="tex">$\frac{x_u}{d_u-1}$</span></span> . Then, these changes are propagated, affect the previous propagation pattern across the whole graph, and finally lead to a different RWR vector <em>r</em> <sub>new</sub> of the updated graph <em>G</em> + <em>ΔG</em> from <em>r</em> <sub>old</sub> of the original graph <em>G</em>. Based on this observation, <font style="font-variant: small-caps">OSP</font> first calculates an offset seed vector <strong>q</strong> <sub>offset</sub> and propagates the offset scores across the updated graph <em>G</em> + <em>ΔG</em> using <font style="font-variant: small-caps">CPI</font> to get an offset score vector <strong>r</strong> <sub>offset</sub>. Finally, <font style="font-variant: small-caps">OSP</font> adds up <strong>r</strong> <sub>old</sub> and <strong>r</strong> <sub>offset</sub> to get the final RWR score vector <strong>r</strong> <sub>new</sub> as follows:</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{align*} &amp;\mathbf {q}_{\text{offset}} \leftarrow (1-c)(\mathbf {\tilde{B}}^{\top }- \mathbf {\tilde{A}}^{\top })\mathbf {r}_{\text{old}} = (1-c){(\Delta \mathbf {A})}^{\top }\mathbf {r}_{\text{old}} \\ &amp;\mathbf {x}_{\text{offset}}^{(i)} \leftarrow ((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}_{\text{offset}}\\ &amp;\mathbf {r}_{\text{offset}} \leftarrow \sum _{i=0}^{\infty }\mathbf {x}_{\text{offset}}^{(i)} = \sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}_{\text{offset}} \\ &amp;\mathbf {r}_{\text{new}} \leftarrow \mathbf {r}_{\text{old}} + \mathbf {r}_{\text{offset}}\end{align*}</span><br />
          </div>
        </div>where <span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}$</span></span> is a row-normalized adjacency matrix of <em>G</em>, <span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}$</span></span> is a row-normalized adjacency matrix of <em>G</em> + <em>ΔG</em>, and <span class="inline-equation"><span class="tex">$\Delta \mathbf {A}=\mathbf {\tilde{B}}-\mathbf {\tilde{A}}$</span></span> is the difference between <span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}$</span></span> and <span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}$</span></span> . Before proving the exactness of <strong>r</strong> <sub>new</sub> computed by <font style="font-variant: small-caps">OSP</font>, we first show the convergence of <strong>r</strong> <sub>offset</sub> in Lemma&nbsp;<a class="enc" href="#enc1">3.1</a>.
        <p></p>
        <div class="lemma" id="enc1">
          <label>Lemma 3.1 (Convergence of roffset).</label>
          <p><strong>r</strong> <sub>offset</sub> converges to a constant value.</p>
        </div>
        <div class="proof" id="proof1">
          <label>Proof.</label>
          <p><strong>r</strong> <sub>offset</sub> is represented in <font style="font-variant: small-caps">OSP</font> as follows:</p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} \mathbf{r}_{\text{offset}} &amp;= \sum_{i=0}^{\infty}\mathbf{x}_{\text{offset}}^{(i)} = \sum_{i=0}^{\infty}((1-c)\mathbf{\tilde{B}}^{\top})^{i}\mathbf{q}_{\text{offset}} \\ &amp;= \sum_{i=0}^{\infty}(1-c)^{i}(\mathbf{\tilde{B}}^{\top})^{i}(1-c)(\mathbf{\tilde{B}}^{\top} - \mathbf{\tilde{A}}^{\top})\mathbf{r}_{\text{old}}\\ &amp;= \sum_{i=0}^{\infty}((1-c)\mathbf{\tilde{B}}^{\top})^{(i+1)}\mathbf{r}_{\text{old}} - \sum_{i=0}^{\infty}(1-c)^{(i+1)}(\mathbf{\tilde{B}}^{\top})^{i}\mathbf{\tilde{A}}^{\top}\mathbf{r}_{\text{old}}\\ \end{align*}</span><br />
            </div>
          </div>Note that <span class="inline-equation"><span class="tex">$\Vert \mathbf {r}_{\text{old}}\Vert _{1} = \Vert \mathbf {\tilde{A}}^{\top }\Vert _{1} = \Vert \mathbf {\tilde{B}}^{\top }\Vert _{1} = 1$</span></span> since <strong>r</strong> <sub>old</sub> is an RWR score vector, and <span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}$</span></span> and <span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}$</span></span> are row-normalized stochastic matrices. Then <span class="inline-equation"><span class="tex">$\sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{(i+1)}r_{\text{old}}$</span></span> and <span class="inline-equation"><span class="tex">$\sum _{i=0}^{\infty }(1-c)^{(i+1)}(\mathbf {\tilde{B}}^{\top })^{i}\mathbf {\tilde{A}}^{\top }\mathbf {r}_{\text{old}}$</span></span> converge, and thus, <strong>r</strong> <sub>offset</sub> also converges to a constant value.
          <p></p>
        </div>
        <p>In Theorem&nbsp;<a class="enc" href="#enc2">3.2</a>, we show that the sum of <strong>r</strong> <sub>old</sub> and <strong>r</strong> <sub>offset</sub> becomes the exact RWR score vector of the updated graph <em>G</em> + <em>ΔG</em>. Our result is the first exactness guarantee for propagation approaches&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>] on dynamic graphs.</p>
        <div class="theorem" id="enc2">
          <label>Theorem 3.2 (Exactness of.</label>
          <p><font style="font-variant: small-caps"><strong>OSP</strong></font> <strong>)</strong> <strong>r</strong> <sub>new</sub> computed by <font style="font-variant: small-caps">OSP</font> is the exact RWR score vector of the updated graph <em>G</em> + <em>ΔG</em>.</p>
        </div>
        <div class="proof" id="proof2">
          <label>Proof.</label>
          <p>For brevity, let <span class="inline-equation"><span class="tex">$\mathbf {\bar{A}}\leftarrow (1-c)\mathbf {\tilde{A}}, \mathbf {\bar{B}}\leftarrow (1-c)\mathbf {\tilde{B}}, \mathbf {\bar{q}}\leftarrow c\mathbf {q}$</span></span> during this proof. Thus, the spectral radii of <span class="inline-equation"><span class="tex">$\mathbf {\bar{A}}$</span></span> and <span class="inline-equation"><span class="tex">$\mathbf {\bar{B}}$</span></span> become less than 1 during this proof.</p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} \!\!\!\mathbf {r}_{\text{offset}} &amp;= \sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^i\mathbf {q}_{\text{offset}} \\ &amp;= \sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^i(\mathbf {\bar{B}}^{\top }-\mathbf {\bar{A}}^{\top })\mathbf {r}_{\text{old}} \\ &amp;= \sum _{i=0}^{\infty }\left((\mathbf {\bar{B}}^{\top })^i(\mathbf {\bar{B}}^{\top }-\mathbf {\bar{A}}^{\top })\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}\right) \\ &amp;= \sum _{i=0}^{\infty }\left((\mathbf {\bar{B}}^{\top })^{i+1}\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}- (\mathbf {\bar{B}}^{\top })^i\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k+1}\mathbf {\bar{q}}\right)\end{align*}</span><br />
            </div>
          </div>Note that <strong>r</strong> <sub>old</sub> is represented as <span class="inline-equation"><span class="tex">$\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}$</span></span> in <font style="font-variant: small-caps">CPI</font>. The third summation <span class="inline-equation"><span class="tex">$\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k+1}\mathbf {\bar{q}}$</span></span> in the last equation is expressed as follows:
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} \sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k+1}\mathbf {\bar{q}}= (\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}) - \mathbf {\bar{q}}\end{align*}</span><br />
            </div>
          </div>Using this equation, <strong>r</strong> <sub>offset</sub> is
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} \!\!\!\mathbf {r}_{\text{offset}} &amp;= \sum _{i=0}^{\infty }\left((\mathbf {\bar{B}}^{\top })^{i+1}\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}- (\mathbf {\bar{B}}^{\top })^i\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}+ (\mathbf {\bar{B}}^{\top })^{i}\mathbf {\bar{q}}\right) \\ &amp;= \sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^{i+1}\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^k\mathbf {\bar{q}}- \sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^{i}\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^k\mathbf {\bar{q}}+ \sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^{i}\mathbf {\bar{q}}\end{align*}</span><br />
            </div>
          </div>The first term of the last equation, <span class="inline-equation"><span class="tex">$\sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^{i+1}\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^k\mathbf {\bar{q}}$</span></span> is expressed as follows:
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} \sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^{i+1}\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^k\mathbf {\bar{q}}= \sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^{i}\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^k\mathbf {\bar{q}}- \sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}\end{align*}</span><br />
            </div>
          </div>Then <strong>r</strong> <sub>offset</sub> is expressed as follows:
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} \mathbf {r}_{\text{offset}} = -\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}+ \sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^{i}\mathbf {\bar{q}}\end{align*}</span><br />
            </div>
          </div>Note <span class="inline-equation"><span class="tex">$\mathbf {r}_{\text{old}} = \sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}$</span></span> in <font style="font-variant: small-caps">CPI</font>. Then <strong>r</strong> <sub>new</sub> becomes as follows:
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} \mathbf {r}_{\text{new}} &amp;= \mathbf {r}_{\text{old}} + \mathbf {r}_{\text{offset}} \\ &amp;= \sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}-\sum _{k=0}^{\infty }(\mathbf {\bar{A}}^{\top })^{k}\mathbf {\bar{q}}+ \sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^{i}\mathbf {\bar{q}}\\ &amp;= \sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^{i}\mathbf {\bar{q}}\end{align*}</span><br />
            </div>
          </div>Note that RWR score vector of the updated graph <em>G</em> + <em>ΔG</em> is expressed as <span class="inline-equation"><span class="tex">$\sum _{i=0}^{\infty }(\mathbf {\bar{B}}^{\top })^{i}\mathbf {\bar{q}}$</span></span> in <font style="font-variant: small-caps">CPI</font>.
          <p></p>
        </div>
        <p>Algorithm&nbsp;1 describes how <font style="font-variant: small-caps">OSP</font> works. <font style="font-variant: small-caps">OSP</font> first calculates a seed offset vector <strong>q</strong> <sub>offset</sub> (line 1). Then <font style="font-variant: small-caps">OSP</font> initializes RWR score vector <strong>r</strong> <sub>offset</sub> and <span class="inline-equation"><span class="tex">$\mathbf {x}_{\text{offset}}^{(0)}$</span></span> using the offset vector <strong>q</strong> <sub>offset</sub> (line 2). In <em>i</em>th iteration, scores in <span class="inline-equation"><span class="tex">$\mathbf {x}_{\text{offset}}^{(i-1)}$</span></span> from the previous iteration (<em>i</em> − 1) are propagated through <span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}+\Delta \mathbf {A}$</span></span> with decaying coefficient 1 − <em>c</em> (line 4). Then, interim score vector <span class="inline-equation"><span class="tex">$\mathbf {x}_{\text{offset}}^{(i)}$</span></span> is accumulated in <strong>r</strong> <sub>offset</sub> (line 5). <font style="font-variant: small-caps">OSP</font> stops when <span class="inline-equation"><span class="tex">$\Vert \mathbf {x}_{\text{offset}}^{(i)} \Vert _{1} \le \epsilon$</span></span> which is a condition for the final score vector <strong>r</strong> <sub>offset</sub> to converge (line 3). Finally, <font style="font-variant: small-caps">OSP</font> sums up <strong>r</strong> <sub>old</sub> and <strong>r</strong> <sub>offset</sub> (line 7). To retrieve exact RWR scores, <font style="font-variant: small-caps">OSP</font> sets error tolerance ϵ to a very small value such as 10<sup>− 9</sup>. Using higher values for ϵ, we propose an approximate method <font style="font-variant: small-caps">OSP-T</font> which trades off the accuracy against the running time for users who put more priority on speed than accuracy in the following section.</p>
      </section>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> <font style="font-variant: small-caps">OSP-T</font>: OSP with Tradeoff</h3>
          </div>
        </header>
        <p><font style="font-variant: small-caps">OSP-T</font> is an approximate method for dynamic RWR computation which is based on <font style="font-variant: small-caps">OSP</font>. As described in Algorithm&nbsp;1, the algorithm of <font style="font-variant: small-caps">OSP-T</font> is the same as <font style="font-variant: small-caps">OSP</font>, but <font style="font-variant: small-caps">OSP-T</font> regulates its accuracy and speed using error tolerance parameter ϵ. In the following, we analyze how much <font style="font-variant: small-caps">OSP-T</font> sacrifices its accuracy and increases its speed when an error tolerance ϵ is given.</p>
        <p></p>
        <figure id="fig9">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186107/images/www2018-116-img1.jpg" class="img-responsive" alt="" longdesc="" />
        </figure>
        <p></p>
        <div class="theorem" id="enc3">
          <label>Theorem 3.3 (Time Complexity of.</label>
          <p><font style="font-variant: small-caps"><strong>OSP-T</strong></font> <strong>)</strong> With error tolerance ϵ, <font style="font-variant: small-caps">OSP-T</font> takes <span class="inline-equation"><span class="tex">$O(m\log _{(1-c)}(\frac{\epsilon }{2}))$</span></span> where <em>m</em> is the number of nonzeros in <span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}+ \Delta \mathbf {A}$</span></span> .</p>
        </div>
        <div class="proof" id="proof3">
          <label>Proof.</label>
          <p><span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}$</span></span> denotes <span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}+\Delta \mathbf {A}$</span></span> , the row-normalized matrix for the updated graph. In each iteration, <font style="font-variant: small-caps">OSP-T</font> computes <span class="inline-equation"><span class="tex">$\mathbf {x}_{\text{offset}}^{(i)} = (1-c)\mathbf {\tilde{B}}^{\top }\mathbf {x}_{\text{offset}}^{(i-1)}$</span></span> , and takes <em>O</em>(<em>m</em>) time where <em>m</em> is the number of nonzeros in <span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}^{\top }$</span></span> . It also means the upper bound of number of edges visited in each iteration. <font style="font-variant: small-caps">OSP-T</font> stops the iteration with error tolerance ϵ when <span class="inline-equation"><span class="tex">$\Vert \mathbf {x}_{\text{offset}}^{(i)} \Vert _{1} = \Vert ((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}_{\text{offset}}\Vert _{1}=(1-c)^{i}\Vert \mathbf {q}_{\text{offset}}\Vert _{1} \le \epsilon$</span></span> . Note that <span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}^{\top }$</span></span> is a column stochastic matrix and <span class="inline-equation"><span class="tex">$\Vert \mathbf {\tilde{B}}^{\top }\Vert _{1}=1$</span></span> . Then the number of iterations to be converged is <span class="inline-equation"><span class="tex">$\log _{(1-c)}(\frac{\epsilon }{\Vert \mathbf {q}_{\text{offset}}\Vert _{1}})$</span></span> and total computation time becomes <span class="inline-equation"><span class="tex">$O(m\log _{(1-c)}(\frac{\epsilon }{\Vert \mathbf {q}_{\text{offset}}\Vert _{1}}))$</span></span> . The upper bound of ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> is presented as follows:</p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} \Vert \mathbf {q}_{\text{offset}}\Vert _{1} &amp;= \Vert (1-c)(\mathbf {\tilde{B}}^{\top }-\mathbf {\tilde{A}}^{\top })\mathbf {r}_{\text{old}}\Vert _{1} \\ &amp;= (1-c)\Vert (\mathbf {\tilde{B}}^{\top }-\mathbf {\tilde{A}}^{\top })\Vert _{1} \\ &amp;\le (1-c)(\Vert \mathbf {\tilde{B}}^{\top }\Vert _{1}+\Vert \mathbf {\tilde{A}}^{\top }\Vert _{1}) = 2(1-c)\end{align*}</span><br />
            </div>
          </div>where <span class="inline-equation"><span class="tex">$\Vert \mathbf {r}_{\text{old}}\Vert _{1} = \Vert \mathbf {\tilde{A}}^{\top }\Vert _{1} = \Vert \mathbf {\tilde{B}}^{\top }\Vert _{1} = 1$</span></span> . Then upper bounds of number of iterations and time are as follows:
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} O(iteration) = \log _{(1-c)}(\frac{\epsilon }{2(1-c)}) {\lt} \log _{(1-c)}(\frac{\epsilon }{2})\\O(time) = m\log _{(1-c)}(\frac{\epsilon }{2(1-c)}) {\lt} m\log _{(1-c)}(\frac{\epsilon }{2})\end{align*}</span><br />
            </div>
          </div>
          <p></p>
          <p>Note that the upper bound of ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> determines the upper bound of time complexity: ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> is a denominator in <span class="inline-equation"><span class="tex">$\log _{(1-c)}(\frac{\epsilon }{\Vert \mathbf {q}_{\text{offset}}\Vert _{1}})$</span></span> and the base of the logarithm is 1 − <em>c</em> which is smaller than 1.</p>
        </div>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class="table-title">Practical performance of <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> on the LiveJournal dataset. Even though <font style="font-variant: small-caps">CPI</font>, <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> share the same theoretical upper bound <em>O</em>(<em>m</em>) of the number of visited edges per iteration, they show the different numbers of iterations and visited edges due to the different starting vectors <strong>q</strong> and error tolerance ϵ. <font style="font-variant: small-caps">OSP</font> converges faster than <font style="font-variant: small-caps">CPI</font> with the help of smaller size of the starting vector, <font style="font-variant: small-caps">OSP-T</font> (ϵ = 5 × 10<sup>− 3</sup>) converges faster than <font style="font-variant: small-caps">OSP</font> (ϵ = 10<sup>− 9</sup>) with the help of higher error tolerance. Note that the total number of edges of LiveJournal is 34,681,189.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <td style="text-align:left;"></td>
                <td colspan="3" style="text-align:center;">
                  <font style="font-variant: small-caps"><strong>CPI</strong></font>
                  <hr />
                </td>
                <td colspan="3" style="text-align:center;">
                  <font style="font-variant: small-caps"><strong>OSP</strong></font>
                  <hr />
                </td>
                <td colspan="3" style="text-align:center;">
                  <font style="font-variant: small-caps"><strong>OSP-T</strong></font>
                  <hr />
                </td>
                <td></td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:left;"></td>
                <td style="text-align:left;"></td>
                <td style="text-align:left;"><strong>#visited</strong></td>
                <td style="text-align:left;"></td>
                <td style="text-align:left;"></td>
                <td style="text-align:left;"><strong>#visited</strong></td>
                <td style="text-align:left;"></td>
                <td style="text-align:left;"></td>
                <td style="text-align:left;"><strong>#visited</strong></td>
                <td></td>
              </tr>
              <tr>
                <td style="text-align:left;">#modified edges</td>
                <td style="text-align:left;"><span class="inline-equation"><span class="tex">$\Vert \mathbf {q}_{\text{CPI}}\Vert _{1}$</span></span></td>
                <td style="text-align:left;"><strong># iter</strong></td>
                <td style="text-align:left;"><strong>edges(× 10<sup>3</sup>)</strong></td>
                <td style="text-align:left;">‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub></td>
                <td style="text-align:left;"><strong># iter</strong></td>
                <td style="text-align:left;"><strong>edges(× 10<sup>3</sup>)</strong></td>
                <td style="text-align:left;">‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub></td>
                <td style="text-align:left;"><strong># iter</strong></td>
                <td style="text-align:left;"><strong>edges(× 10<sup>3</sup>)</strong></td>
                <td><strong>L1 norm error</strong></td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">116</td>
                <td style="text-align:left;">3,910,864</td>
                <td style="text-align:left;">2.60 × 10<sup>− 9</sup></td>
                <td style="text-align:left;">2</td>
                <td style="text-align:left;">2,145</td>
                <td style="text-align:left;">2.60 × 10<sup>− 9</sup></td>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">25</td>
                <td>2.84 × 10<sup>− 8</sup></td>
              </tr>
              <tr>
                <td style="text-align:left;">10</td>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">116</td>
                <td style="text-align:left;">3,910,863</td>
                <td style="text-align:left;">1.51 × 10<sup>− 7</sup></td>
                <td style="text-align:left;">14</td>
                <td style="text-align:left;">405,717</td>
                <td style="text-align:left;">1.51 × 10<sup>− 7</sup></td>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">147</td>
                <td>3.42 × 10<sup>− 7</sup></td>
              </tr>
              <tr>
                <td style="text-align:left;">10<sup>2</sup></td>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">116</td>
                <td style="text-align:left;">3,910,858</td>
                <td style="text-align:left;">2.19 × 10<sup>− 6</sup></td>
                <td style="text-align:left;">26</td>
                <td style="text-align:left;">839,137</td>
                <td style="text-align:left;">2.19 × 10<sup>− 6</sup></td>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">788</td>
                <td>1.77 × 10<sup>− 6</sup></td>
              </tr>
              <tr>
                <td style="text-align:left;">10<sup>3</sup></td>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">116</td>
                <td style="text-align:left;">3,910,808</td>
                <td style="text-align:left;">2.31 × 10<sup>− 5</sup></td>
                <td style="text-align:left;">35</td>
                <td style="text-align:left;">1,169,546</td>
                <td style="text-align:left;">2.31 × 10<sup>− 5</sup></td>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">4,098</td>
                <td>1.64 × 10<sup>− 5</sup></td>
              </tr>
              <tr>
                <td style="text-align:left;">10<sup>4</sup></td>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">116</td>
                <td style="text-align:left;">3,910,300</td>
                <td style="text-align:left;">2.30 × 10<sup>− 4</sup></td>
                <td style="text-align:left;">47</td>
                <td style="text-align:left;">1,604,965</td>
                <td style="text-align:left;">2.30 × 10<sup>− 4</sup></td>
                <td style="text-align:left;">2</td>
                <td style="text-align:left;">44,960</td>
                <td>1.11 × 10<sup>− 4</sup></td>
              </tr>
              <tr>
                <td style="text-align:left;">10<sup>5</sup></td>
                <td style="text-align:left;">1</td>
                <td style="text-align:left;">116</td>
                <td style="text-align:left;">3,905,224</td>
                <td style="text-align:left;">2.05 × 10<sup>− 3</sup></td>
                <td style="text-align:left;">61</td>
                <td style="text-align:left;">2,104,446</td>
                <td style="text-align:left;">2.05 × 10<sup>− 3</sup></td>
                <td style="text-align:left;">4</td>
                <td style="text-align:left;">130,470</td>
                <td>7.51 × 10<sup>− 4</sup></td>
              </tr>
            </tbody>
          </table>
        </div>
        <p><strong>Fast convergence.</strong> From Theorem&nbsp;<a class="enc" href="#enc3">3.3</a>, <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> share the same upper bound <em>O</em>(<em>m</em>) for the number of visited edges per iteration with their baseline method <font style="font-variant: small-caps">CPI</font> &nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>]. In practice, <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> visit only small portion of edges since the starting vector <strong>q</strong> <sub>offset</sub> of <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> has a small <em>L</em>1 length: <strong>q</strong> <sub>offset</sub> = (1 − <em>c</em>)(<em>Δ</em> <strong>A</strong>)<sup>⊤</sup> <strong>r</strong> <sub>old</sub>, and thus ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> ≤ (1 − <em>c</em>)‖(<em>Δ</em> <strong>A</strong>)<sup>⊤</sup>‖<sub>1</sub> with a unit RWR score vector <strong>r</strong> <sub>old</sub>; then, with small update <em>ΔG</em>, (<em>Δ</em> <strong>A</strong>)<sup>⊤</sup> is a sparse matrix with small <em>L</em>1 length and leads to a small value of ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub>. When <span class="inline-equation"><span class="tex">$(\mathbf {\tilde{A}}+ \Delta \mathbf {A})$</span></span> is multiplied with <strong>q</strong> <sub>offset</sub>, only small number of edges in <em>G</em> + <em>ΔG</em> would be visited. Table&nbsp;<a class="tbl" href="#tab3">3</a> shows the <em>L</em>1 length of the starting vector (‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub>), the total number of iterations, and the total number of visited edges of <font style="font-variant: small-caps">CPI</font>, <font style="font-variant: small-caps">OSP</font>, and <font style="font-variant: small-caps">OSP-T</font> varying the number of deleted edges from the LiveJournal dataset. The error tolerance ϵ is set to 10<sup>− 9</sup>, 10<sup>− 9</sup>, and 5 × 10<sup>− 3</sup> for <font style="font-variant: small-caps">CPI</font>, <font style="font-variant: small-caps">OSP</font>, and <font style="font-variant: small-caps">OSP-T</font>, respectively. <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> have smaller size of the starting vector <strong>q</strong> <sub>offset</sub> than <font style="font-variant: small-caps">CPI</font>, resulting in fewer numbers of iterations and visited edges. Considering the total number of edges (<em>m</em>) of the LiveJournal dataset is 34,681,189, <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> visit only small portion of edges in the graph thus converge much faster than <font style="font-variant: small-caps">CPI</font> does. <font style="font-variant: small-caps">OSP-T</font> converges faster than <font style="font-variant: small-caps">OSP</font> by trading off accuracy. As size of <em>ΔG</em> increases, numbers of iterations and visited edges, and <em>L</em>1 errors all increase. The reason is analyzed theoretically in Section&nbsp;<a class="sec" href="#sec-11">3.3</a>.</p>
        <p>According to Theorem&nbsp;<a class="enc" href="#enc3">3.3</a>, error tolerance ϵ determines the computation cost of <font style="font-variant: small-caps">OSP-T</font>. With error tolerance ϵ and restart probability <em>c</em>, we show that error bound of <font style="font-variant: small-caps">OSP-T</font> is <span class="inline-equation"><span class="tex">$O(\frac{\epsilon }{c})$</span></span> in the following theorem.</p>
        <div class="theorem" id="enc4">
          <label>Theorem 3.4 (Error bound of.</label>
          <p><font style="font-variant: small-caps"><strong>OSP-T</strong></font> <strong>)</strong> When <font style="font-variant: small-caps">OSP-T</font> converges under error tolerance ϵ, error bound of RWR score vector <strong>r</strong> <sub>new</sub> computed by <font style="font-variant: small-caps">OSP-T</font> is <span class="inline-equation"><span class="tex">$O(\frac{\epsilon }{c})$</span></span> .</p>
        </div>
        <div class="proof" id="proof4">
          <label>Proof.</label>
          <p>When <font style="font-variant: small-caps">OSP-T</font> iterates until (<em>k</em> − 1)th iteration, error bound is presented as follows:</p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} O(error) &amp;= \Vert \sum _{i=k}^{\infty }x_{\text{offset}}^{(i)}\Vert _{1} = \Vert \sum _{i=k}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}_{\text{offset}}\Vert _{1}\\ &amp;= \Vert \sum _{i=k}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}(1-c)(\mathbf {\tilde{B}}^{\top }-\mathbf {\tilde{A}}^{\top })\mathbf {r}_{\text{old}}\Vert _{1}\\ &amp;\le \sum _{i=k}^{\infty }(1-c)^{i+1}\Vert (\mathbf {\tilde{B}}^{\top })^{i}\Vert _{1}\Vert \mathbf {\tilde{B}}^{\top }-\mathbf {\tilde{A}}^{\top }\Vert _{1}\Vert \mathbf {r}_{\text{old}}\Vert _{1}\\ &amp;\le \sum _{i=k}^{\infty }2(1-c)^{i+1} = \frac{2}{c}(1-c)^{k+1}\end{align*}</span><br />
            </div>
          </div>From the proof of Theorem&nbsp;<a class="enc" href="#enc3">3.3</a>, <span class="inline-equation"><span class="tex">$k=\log _{(1-c)}(\frac{\epsilon }{2(1-c)})$</span></span> . Then error is bounded as:
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} O(error) = \frac{2}{c}\frac{\epsilon }{2(1-c)}(1-c) = \frac{\epsilon }{c}\end{align*}</span><br />
            </div>
          </div>
          <p></p>
        </div>
        <p>From Theorem&nbsp;<a class="enc" href="#enc3">3.3</a> and Theorem&nbsp;<a class="enc" href="#enc4">3.4</a>, <font style="font-variant: small-caps">OSP-T</font> trades off the running time and accuracy using ϵ. We show the effects of ϵ on the experimental performance of <font style="font-variant: small-caps">OSP-T</font> in Section&nbsp;<a class="sec" href="#sec-26">4.4</a>.</p>
      </section>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span> Effects of <em>ΔG</em></h3>
          </div>
        </header>
        <p>Including our model, propagation-based methods&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>] for dynamic RWR computation have sporadically observed long running time which is considerably longer than the average in real-world graphs. Previous works&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>] detect the fact but do not provide any further investigation on reasons. Based on <font style="font-variant: small-caps">OSP-T</font>, we analyze the root cause of the long running time occasionally happened in the propagation models.</p>
        <p>From the proof of Theorem&nbsp;<a class="enc" href="#enc3">3.3</a>, the running time of <font style="font-variant: small-caps">OSP-T</font> is determined by the <em>L</em>1 length of its seed vector <strong>q</strong> <sub>offset</sub>. When <strong>D</strong> is a diagonal matrix where <span class="inline-equation"><span class="tex">$\mathbf {D}_{ii} = \sum _{j=1}^{n}|\Delta \mathbf {A}_{ij}|$</span></span> , <span class="inline-equation"><span class="tex">$\Delta \mathbf {\tilde{A}}=\mathbf {D}^{-1}\Delta \mathbf {A}$</span></span> is a row-normalized matrix and <span class="inline-equation"><span class="tex">${\Delta \mathbf {\tilde{A}}}^{\top }$</span></span> is a column stochastic matrix. Then <strong>q</strong> <sub>offset</sub> and its <em>L</em>1 length are presented as follows:</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{align*} \mathbf {q}_{\text{offset}} &amp;= (1-c){(\Delta \mathbf {A})}^{\top }\mathbf {r}_{\text{old}}\\ &amp;=(1-c)(\mathbf {D}\mathbf {D}^{-1}\Delta \mathbf {A})^\top \mathbf {r}_{\text{old}}\\ &amp;=(1-c)(\mathbf {D}\Delta \mathbf {\tilde{A}})^\top \mathbf {r}_{\text{old}}\\ &amp;=(1-c){\Delta \mathbf {\tilde{A}}}^{\top }(\mathbf {D}\mathbf {r}_{\text{old}}) \\\Vert \mathbf {q}_{\text{offset}}\Vert _{1} &amp;= (1-c)\Vert {\Delta \mathbf {\tilde{A}}}^{\top }(\mathbf {D}\mathbf {r}_{\text{old}})\Vert _{1}\\ &amp;= (1-c)\Vert(\mathbf {Dr}_{\text{old}})\Vert_{1} \end{align*}</span><br />
          </div>
        </div>Then ‖<strong>D</strong> <strong>r</strong> <sub>old</sub>‖<sub>1</sub> is a decisive factor for running time. When edges are inserted to node <em>i</em> or deleted from node <em>i</em>, <em>i</em>th row in <span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}$</span></span> is updated from <em>i</em>th row in <span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}$</span></span> ; then <em>i</em>th row in <span class="inline-equation"><span class="tex">$\Delta \mathbf {A}= \mathbf {\tilde{B}}- \mathbf {\tilde{A}}$</span></span> has nonzero values; finally, (<em>i</em>, <em>i</em>)th element in <strong>D</strong> has a nonzero value. In summary, <strong>D</strong> is a sparse diagonal matrix which has nonzero values at (<em>i</em>, <em>i</em>)th element when node <em>i</em> is modified by a graph modification <em>ΔG</em>. Then, there are two main components in determining the value of ‖<strong>D</strong> <strong>r</strong> <sub>old</sub>‖<sub>1</sub>: 1) how many nodes are modified (i.e. the number of nonzeros in <strong>D</strong>), 2) which nodes are modified (i.e. the location of nonzeros in <strong>D</strong>).
        <p></p>
        <section id="sec-12">
          <header>
            <div class="title-info">
              <h4><span class="section-number">3.3.1</span> Size of <em>ΔG</em></h4>
            </div>
          </header>
          <p>When there are many nodes affected by <em>ΔG</em>, many nonzero values are located in <strong>D</strong>’s diagonal and multiplied with <strong>r</strong> <sub>old</sub>. This leads to a high value of ‖<strong>D</strong> <strong>r</strong> <sub>old</sub>‖<sub>1</sub>. In other words, ‖<strong>D</strong> <strong>r</strong> <sub>old</sub>‖<sub>1</sub> is determined by the size of <em>ΔG</em>. Intuitively, when the scope of a graph modification gets larger, the computation time for updating RWR takes longer time. As shown in Table&nbsp;<a class="tbl" href="#tab3">3</a>, as <em>ΔG</em> increases, ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> increases in <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font>, then total numbers of iterations and visited edges until convergence also increase. <em>L</em>1 error also increases since the error bound is also determined by ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> as shown in the proof of Theorem&nbsp;<a class="enc" href="#enc4">3.4</a>. In Section&nbsp;<a class="sec" href="#sec-28">4.5.1</a>, we show the effects of size of <em>ΔG</em> on performance of <font style="font-variant: small-caps">OSP-T</font> in real-world graphs.</p>
        </section>
        <section id="sec-13">
          <header>
            <div class="title-info">
              <h4><span class="section-number">3.3.2</span> Location of <em>ΔG</em></h4>
            </div>
          </header>
          <p>When the number of nonzeros is fixed, the location of nonzeros in <strong>D</strong> is a crucial factor for determining the value of ‖<strong>D</strong> <strong>r</strong> <sub>old</sub>‖<sub>1</sub>. When nonzeros in <strong>D</strong> are multiplied with high scores in <strong>r</strong> <sub>old</sub>, the product becomes large. Otherwise, when nonzeros in <strong>D</strong> are multiplied with low scores in <strong>r</strong> <sub>old</sub>, the product becomes small. In other words, location of <em>ΔG</em> determines the running time of <font style="font-variant: small-caps">OSP-T</font>. When <em>ΔG</em> appears around high RWR score nodes, running time skyrockets. On the other hand, when <em>ΔG</em> appears around low score nodes, <font style="font-variant: small-caps">OSP-T</font> converges quickly. Note that most real-world graphs follow power-law degree distribution&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>] with few nodes having high RWR scores and majority of nodes having low scores. Thus <em>ΔG</em> is less likely to happen around high RWR score nodes. This leads to sporadic occurrence of long running time in propagation models. In Section&nbsp;<a class="sec" href="#sec-29">4.5.2</a>, we show the effects of location of <em>ΔG</em> on running time of <font style="font-variant: small-caps">OSP-T</font> in real-world graphs.</p>
        </section>
      </section>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.4</span> Discussions</h3>
          </div>
        </header>
        <p>In addition to edge insertion/deletion, <font style="font-variant: small-caps">OSP</font> (and <font style="font-variant: small-caps">OSP-T</font>) easily handles node insertion/deletion. We also show how <font style="font-variant: small-caps">OSP</font> handles dead-end nodes efficiently.</p>
        <section id="sec-15">
          <p><em>3.4.1 Node insertion/deletion.</em> <font style="font-variant: small-caps">OSP</font> easily handles both node insertion and deletion. When a node is inserted with its edges, <font style="font-variant: small-caps">OSP</font> adds one column and one row, respectively, to the previous (<em>n</em> × <em>n</em>) matrix <span class="inline-equation"><span class="tex">$\mathbf {\tilde{A}}$</span></span> with all zero values. In (<em>n</em> + 1)th row of the updated matrix <span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}$</span></span> , edge distribution of the new node is stored. Likewise, <font style="font-variant: small-caps">OSP</font> adds one row to the (<em>n</em> × 1) vector <strong>r</strong> <sub>old</sub> with a zero value and stores an RWR score of the new node in (<em>n</em> + 1)th row of <strong>r</strong> <sub>new</sub>. On the other hand, when a node is deleted from a given graph, the corresponding row in <span class="inline-equation"><span class="tex">$\mathbf {\tilde{B}}$</span></span> is simply set to all zero values to express the deletion. The remaining process is the same as that of edge insertion/deletion as described in Algorithm&nbsp;1 .</p>
        </section>
        <section id="sec-16">
          <p><em>3.4.2 Dead-end.</em> Dead-ends which do not have any out-edges cause scores to leak out. Without handling dead-ends, total sum of RWR scores across a given graph would be less than 1. One common way&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>] to tackle the leakage problem is inserting edges from dead-end nodes to a seed node. However, inserting edges for every dead-end node leads to explosive computation time as the given graph gets larger proportional to the number of dead-ends. Thus RWR experiments have been frequently conducted without handling dead-ends&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>]. In this section, we introduce an efficient dead-end handling for <font style="font-variant: small-caps">OSP</font> which brings the same effect as inserting new edges: we just need to scale <em>L</em>1 length of an RWR vector, computed from <font style="font-variant: small-caps">OSP</font>, to 1 at the end. We prove the exactness of this dead-end handling in Theorem&nbsp;<a class="enc" href="#enc5">3.5</a>.</p>
          <div class="theorem" id="enc5">
            <label>Theorem 3.5 (Exactness of Dead-end handling).</label>
            <p>When <strong>r</strong> <sub>temp</sub> denotes a result score vector in <font style="font-variant: small-caps">OSP</font> without any handling for dead-ends, scaling <strong>r</strong> <sub>temp</sub> to <span class="inline-equation"><span class="tex">$\frac{\mathbf {r}_{\text{temp}}}{\Vert \mathbf {r}_{\text{temp}}\Vert _{1}}$</span></span> results in an exact RWR score vector <strong>r</strong> <sub>final</sub> which resolves a score leakage problem caused by dead-ends.</p>
          </div>
          <div class="proof" id="proof5">
            <label>Proof.</label>
            <p>As proved in Theorem&nbsp;<a class="enc" href="#enc2">3.2</a>, the resulting score vector <strong>r</strong> <sub>temp</sub> computed by <font style="font-variant: small-caps">OSP</font> is presented as <span class="inline-equation"><span class="tex">$c\sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}$</span></span> . Let <span class="inline-equation"><span class="tex">$d_{\text{total}_1}$</span></span> be the whole score handed over to the seed node from dead-ends after propagating the initial score <em>c</em> from the seed. Then <span class="inline-equation"><span class="tex">$d_{\text{total}_1}$</span></span> is propagated across the graph to fill the leaked scores. We do not need to perform long calculation to propagate <span class="inline-equation"><span class="tex">$d_{\text{total}_1}$</span></span> from the seed node: <span class="inline-equation"><span class="tex">$\mathbf {r}_{\text{temp}}=c\sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}$</span></span> , and thus scaling <strong>r</strong> <sub>temp</sub> with <span class="inline-equation"><span class="tex">$(d_{\text{total}_1}/c)$</span></span> results in <span class="inline-equation"><span class="tex">$d_{\text{total}_1}\sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}$</span></span> which is the result of propagating score <span class="inline-equation"><span class="tex">$d_{\text{total}_1}$</span></span> from the seed. At this time, the propagation of <span class="inline-equation"><span class="tex">$d_{\text{total}_1}$</span></span> is leaked out again from the dead-ends. Repeatedly, we collect the leaked scores <span class="inline-equation"><span class="tex">$(d_{\text{total}_2}, d_{\text{total}_3}, \cdots)$</span></span> which are inserted into the dead-ends, and propagate them from the seed. However, we do not need to do long calculation to collect the leaked scores <span class="inline-equation"><span class="tex">$d_{\text{total}_1}, d_{\text{total}_2}, \cdots$</span></span> and propagate them from the seed again and again, since we know that</p>
            <div class="table-responsive">
              <div class="display-equation">
                <span class="tex mytex">\begin{align*} \Vert \mathbf {r}_{\text{temp}}\Vert _{1} = c\Vert \sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}\Vert _{1}\\\Vert \sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}\Vert _{1} =\frac{\Vert \mathbf {r}_{\text{temp}}\Vert _{1}}{c}\end{align*}</span><br />
              </div>
            </div>Then the final RWR vector <strong>r</strong> <sub>final</sub> with dead-end handling is presented as follows:
            <div class="table-responsive">
              <div class="display-equation">
                <span class="tex mytex">\begin{align*} \mathbf {r}_{\text{final}} &amp;= c\sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}+ d_{\text{total}_1}\sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}\\ &amp;+ d_{\text{total}_2}\sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}+ \cdots \\ &amp;=(c+d_{\text{total}_1}+d_{\text{total}_2}+d_{\text{total}_3}+\cdots)\sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}\\\Vert \mathbf {r}_{\text{final}}\Vert _{1} &amp;=(c+d_{\text{total}_1}+d_{\text{total}_2}+d_{\text{total}_3}+\cdots)\Vert \sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}\Vert _{1} = 1\end{align*}</span><br />
              </div>
            </div>Then <span class="inline-equation"><span class="tex">$(c+d_{\text{total}_1}+d_{\text{total}_2}+d_{\text{total}_3}+\cdots)$</span></span> is expressed as follows:
            <div class="table-responsive">
              <div class="display-equation">
                <span class="tex mytex">\begin{align*} c+d_{\text{total}_1}+d_{\text{total}_2}+d_{\text{total}_3}+\cdots &amp;= 1/\Vert \sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}\Vert _{1} =\frac{c}{\Vert \mathbf {r}_{\text{temp}}\Vert _{1}}\end{align*}</span><br />
              </div>
            </div>Thus we get <strong>r</strong> <sub>final</sub> by scaling <strong>r</strong> <sub>temp</sub> with 1/‖<strong>r</strong> <sub>temp</sub>‖<sub>1</sub> as follows:
            <div class="table-responsive">
              <div class="display-equation">
                <span class="tex mytex">\begin{align*} \mathbf {r}_{\text{final}} &amp;=(c+d_{\text{total}_1}+d_{\text{total}_2}+d_{\text{total}_3}+\cdots)\sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}\\ &amp;= \frac{c}{\Vert \mathbf {r}_{\text{temp}}\Vert _{1}}\sum _{i=0}^{\infty }((1-c)\mathbf {\tilde{B}}^{\top })^{i}\mathbf {q}\\ &amp;=\frac{1}{\Vert \mathbf {r}_{\text{temp}}\Vert _{1}}\mathbf {r}_{\text{temp}}\end{align*}</span><br />
              </div>
            </div>
            <p></p>
          </div>
        </section>
      </section>
    </section>
    <section id="sec-17">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Experiments</h2>
        </div>
      </header>
      <div class="table-responsive" id="tab4">
        <div class="table-caption">
          <span class="table-number">Table 4:</span> <span class="table-title">Dataset statistics</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:left;"></th>
              <th style="text-align:left;"></th>
              <th style="text-align:left;"></th>
              <th style="text-align:left;"></th>
              <th style="text-align:left;"><strong>Error</strong></th>
            </tr>
            <tr>
              <td style="text-align:left;"></td>
              <td style="text-align:left;"></td>
              <td style="text-align:left;"></td>
              <td style="text-align:left;"></td>
              <td style="text-align:left;"><strong>tolerance</strong></td>
            </tr>
            <tr>
              <td style="text-align:left;"><strong>Dataset</strong></td>
              <td style="text-align:left;"><strong>Nodes</strong></td>
              <td style="text-align:left;"><strong>Edges</strong></td>
              <td style="text-align:left;"><strong>Direction</strong></td>
              <td style="text-align:left;"><strong>(</strong> <font style="font-variant: small-caps"><strong>OSP-T</strong></font> <strong>)</strong></td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:left;">WikiLink<sup>1</sup></td>
              <td style="text-align:left;">12,150,976</td>
              <td style="text-align:left;">378,142,420</td>
              <td style="text-align:left;">Directed</td>
              <td style="text-align:left;">10<sup>− 2</sup></td>
            </tr>
            <tr>
              <td style="text-align:left;">Orkut<sup>2</sup></td>
              <td style="text-align:left;">3,072,441</td>
              <td style="text-align:left;">117,185,083</td>
              <td style="text-align:left;">Undirected</td>
              <td style="text-align:left;">5 × 10<sup>− 3</sup></td>
            </tr>
            <tr>
              <td style="text-align:left;">LiveJournal<sup>2</sup></td>
              <td style="text-align:left;">3,997,962</td>
              <td style="text-align:left;">34,681,189</td>
              <td style="text-align:left;">Undirected</td>
              <td style="text-align:left;">5 × 10<sup>− 3</sup></td>
            </tr>
            <tr>
              <td style="text-align:left;">Berkstan<sup>2</sup></td>
              <td style="text-align:left;">685,230</td>
              <td style="text-align:left;">7,600,595</td>
              <td style="text-align:left;">Directed</td>
              <td style="text-align:left;">10<sup>− 4</sup></td>
            </tr>
            <tr>
              <td style="text-align:left;">DBLP<sup>2</sup></td>
              <td style="text-align:left;">317,080</td>
              <td style="text-align:left;">1,049,866</td>
              <td style="text-align:left;">Undirected</td>
              <td style="text-align:left;">10<sup>− 4</sup></td>
            </tr>
            <tr>
              <td style="text-align:left;">Slashdot<sup>2</sup></td>
              <td style="text-align:left;">82,144</td>
              <td style="text-align:left;">549,202</td>
              <td style="text-align:left;">Directed</td>
              <td style="text-align:left;">10<sup>− 4</sup></td>
            </tr>
          </tbody>
          <tfoot>
            <tr>
              <td>
                <sup>1</sup>http://konect.uni-koblenz.de/networks/ <sup>2</sup><a class="link-inline force-break" href="http://snap.stanford.edu/data/">http://snap.stanford.edu/data/</a>
              </td>
              <td></td>
              <td></td>
              <td></td>
              <td></td>
            </tr>
          </tfoot>
        </table>
      </div>
      <figure id="fig2">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186107/images/www2018-116-fig2.jpg" class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class="figure-title">Performance of <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font>: <font style="font-variant: small-caps">OSP</font> computes the exact RWR faster than <font style="font-variant: small-caps">CPI</font> on dynamic graphs.<font style="font-variant: small-caps">OSP-T</font> achieves faster speed than <font style="font-variant: small-caps">OSP</font> while sacrificing accuracy using higher error tolerance ϵ. ϵ is set to 10<sup>− 9</sup> for <font style="font-variant: small-caps">CPI</font> and <font style="font-variant: small-caps">OSP</font>, and set to higher values for <font style="font-variant: small-caps">OSP-T</font> as described in Table&nbsp;<a class="tbl" href="#tab4">4</a>. Experiments for accuracy of <font style="font-variant: small-caps">OSP-T</font> are presented in Section&nbsp;<a class="sec" href="#sec-28">4.5.1</a>.</span>
        </div>
      </figure>
      <p>In this section, we experimentally evaluate the performance of <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> compared to other dynamic RWR methods. We aim to answer the following questions:</p>
      <ul class="list-no-style">
        <li id="list4" label="•">
          <strong>Q1 Performance of</strong> <font style="font-variant: small-caps"><strong>OSP</strong></font> <strong>.</strong>How much does <font style="font-variant: small-caps">OSP</font> improve performance for dynamic RWR computation from the baseline static method <font style="font-variant: small-caps">CPI</font>? (Section&nbsp;<a class="sec" href="#sec-21">4.2</a>)<br />
        </li>
        <li id="list5" label="•">
          <strong>Q2 Performance of</strong> <font style="font-variant: small-caps"><strong>OSP-T</strong></font> <strong>.</strong>How much does <font style="font-variant: small-caps">OSP-T</font> enhance computation efficiency, accuracy and scalability compared with its competitors? (Section&nbsp;<a class="sec" href="#sec-22">4.3</a>)<br />
        </li>
        <li id="list6" label="•">
          <strong>Q3 Effects of</strong> ϵ<strong>, error tolerance.</strong>How does the error tolerance ϵ affect the accuracy and the speed of <font style="font-variant: small-caps">OSP-T</font>? (Section&nbsp;<a class="sec" href="#sec-26">4.4</a>)<br />
        </li>
        <li id="list7" label="•">
          <strong>Q4 Effects of</strong> <em>ΔG</em> <strong>, a graph modification.</strong>How does the size of <em>ΔG</em> affect the performance of <font style="font-variant: small-caps">OSP-T</font>? (Section&nbsp;<a class="sec" href="#sec-28">4.5.1</a>) How does the location of <em>ΔG</em> in the given graph <em>G</em> affect the performance of <font style="font-variant: small-caps">OSP-T</font>? (Section&nbsp;<a class="sec" href="#sec-29">4.5.2</a>)<br />
        </li>
      </ul>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Setup</h3>
          </div>
        </header>
        <section id="sec-19">
          <p><em>4.1.1 Datasets.</em> We use 6 real-world graphs to evaluate the effectiveness and efficiency of our methods. The datasets and their statistics are summarized in Table&nbsp;<a class="tbl" href="#tab4">4</a>. Among them, Orkut, LiveJournal, and Slashdot are social networks, whereas DBLP is a collaboration network, and WikiLink and Berkstan are hyperlink networks.</p>
        </section>
        <section id="sec-20">
          <p><em>4.1.2 Environment.</em> All experiments are conducted on a workstation with a single core Intel(R) Xeon(R) CPU E5-2630 @ 2.2GHz and 512GB memory. We compare <font style="font-variant: small-caps">OSP</font> with its baseline static method <font style="font-variant: small-caps">CPI</font>, and compare <font style="font-variant: small-caps">OSP-T</font> with two state-of-the-art approximate methods for dynamic RWR, TrackingPPR&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>] and LazyForward&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>], all of which are described in Section&nbsp;<a class="sec" href="#sec-30">5</a>. All these methods including <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> are implemented in C++. We set the restart probability <em>c</em> to 0.15 as in the previous works&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>]. For each dataset, we measure the average value for 30 random seed nodes. <font style="font-variant: small-caps">CPI</font> &nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>] is used to provide the exact RWR values in all experiments.</p>
        </section>
      </section>
      <section id="sec-21">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Performance of <font style="font-variant: small-caps">OSP</font></h3>
          </div>
        </header>
        <p>We evaluate performance of <font style="font-variant: small-caps">OSP</font> by measuring computation time for tracking RWR exactly on a dynamic graph <em>G</em> varying the size of <em>ΔG</em>. We set the initial graph G as a graph with all its edges and modify <em>G</em> by deleting edges. The size of <em>ΔG</em> varies from one edge to 10<sup>5</sup> edges. For space efficiency, we show the results on Orkut, LiveJournal, Berkstan, and DBLP; results on other graphs are similar. Error tolerance for <font style="font-variant: small-caps">CPI</font> and <font style="font-variant: small-caps">OSP</font> is set to 10<sup>− 9</sup> for all datasets, and error tolerance for <font style="font-variant: small-caps">OSP-T</font> on each dataset is described in Table 4. From Figure&nbsp;<a class="fig" href="#fig2">2</a>, <font style="font-variant: small-caps">OSP</font> tracks the exact RWR on dynamic graphs up to 4605 × faster than <font style="font-variant: small-caps">CPI</font> with the help of small size of the starting vector <strong>q</strong> <sub>offset</sub>. Note that <font style="font-variant: small-caps">CPI</font> is initialized with <span class="inline-equation"><span class="tex">$\mathbf {q}_{\text{CPI}} = c\mathbf {q}$</span></span> . <font style="font-variant: small-caps">OSP-T</font> trades off accuracy against speed using higher error tolerance ϵ, thus results in superior speed than <font style="font-variant: small-caps">CPI</font> and <font style="font-variant: small-caps">OSP</font>. Note that <font style="font-variant: small-caps">CPI</font> and <font style="font-variant: small-caps">OSP</font> compute the exact RWR scores while <font style="font-variant: small-caps">OSP-T</font> results in the approximate RWR scores on dynamic graphs. As size of <em>ΔG</em> becomes larger, computation time of <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> increases while <font style="font-variant: small-caps">CPI</font> maintains similar computation time. The effects of size of <em>ΔG</em> on computation time of <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> are discussed concretely in Section&nbsp;<a class="sec" href="#sec-28">4.5.1</a>.</p>
      </section>
      <section id="sec-22">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Performance of <font style="font-variant: small-caps">OSP-T</font></h3>
          </div>
        </header>
        <p>From each dataset, we generate a uniformly random edge stream and divide the stream into two parts. We extract 10 snapshots from the second part of the edge stream. At first, we initialize each graph with the first part of the stream, and then update the graph for each new snapshot arrival. At the end of the updates, we compare the performance of each algorithm.</p>
        <section id="sec-23">
          <p><em>4.3.1 Computational Efficiency.</em> We evaluate the computational efficiency of <font style="font-variant: small-caps">OSP-T</font> in terms of running time when error tolerance is given. Error tolerance used in TrackingPPR and LazyForward means maximum permissible <em>L</em>1 error per node, while error tolerance in <font style="font-variant: small-caps">OSP-T</font> indicates maximum permissible <em>L</em>1 error per RWR score vector. For TrackingPPR and LazyForward, we set error tolerance to 10<sup>− 8</sup> across all datasets. For <font style="font-variant: small-caps">OSP-T</font>, we set error tolerance close to <span class="inline-equation"><span class="tex">$10^{-8}\times (\# nodes)$</span></span> for each graph, respectively, to give the same error tolerance effect with the competitors. Error tolerance ϵ for each dataset is described in Table&nbsp;<a class="tbl" href="#tab4">4</a>. The wall-clock running time is shown in Figure&nbsp;3(a) . <font style="font-variant: small-caps">OSP-T</font> runs faster than other methods by up to 15 × while maintaining higher accuracy as shown in Figures&nbsp;3(b) and&nbsp;3(c) . This performance difference comes from the different definitions of error tolerance which are described earlier. In <font style="font-variant: small-caps">OSP-T</font>, error tolerance works per RWR score vector, and thus convergence condition is checked after all nodes that could be reached in one hop are updated. On the other hand, error tolerance works per node in TrackingPPR and LazyForward, and thus convergence condition is checked every time a node is updated.</p>
          <figure id="fig3">
            <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186107/images/www2018-116-fig3.jpg" class="img-responsive" alt="Figure 3" longdesc="" />
            <div class="figure-caption">
              <span class="figure-number">Figure 3:</span> <span class="figure-title">Performance of <font style="font-variant: small-caps">OSP-T</font>: (a) compares the running time among dynamic RWR methods; (b) and (c) compare the L1 norm of error and the rank accuracy of RWR scores of <font style="font-variant: small-caps">OSP-T</font> and other methods with those of the exact RWR scores, respectively. While other methods show different performance on directed/undirected graphs, <font style="font-variant: small-caps">OSP-T</font> maintains superior performance on overall graphs.</span>
            </div>
          </figure>
          <p></p>
        </section>
        <section id="sec-24">
          <p><em>4.3.2 Accuracy.</em> After all updates with snapshots, we get an approximate RWR vector for a given graph from each method. We compare <em>L</em>1 norm error between an approximate RWR vector and its exact RWR vector. To measures the rank accuracy, we use Spearman correlation&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>]. Note that the higher the Spearman correlation, the higher is the rank accuracy. As shown in Figures&nbsp;3(b) and 3(c), <font style="font-variant: small-caps">OSP-T</font> outperforms other state-of-the-art methods with higher accuracy by up to 730 × in <em>L</em>1 norm and 3.3 × in ranking. This difference in accuracy comes from the different propagation models used in <font style="font-variant: small-caps">OSP-T</font> and its competitors. Gauss-Southwell algorithm and Forward Local Push algorithm used in TrackingPPR and LazyForward, respectively, propagate scores toward the top-ranked node in terms of residual scores, while <font style="font-variant: small-caps">CPI</font> used in <font style="font-variant: small-caps">OSP-T</font> propagates scores toward the whole nodes which could be reached in one hop. Note that <font style="font-variant: small-caps">OSP-T</font> maintains high accuracy on overall graphs, whereas LazyForward and TrackingPPR show different accuracy on directed and undirected graphs; since Gauss-Southwell algorithm and Forward Local Push algorithm are based on Local Push algorithm&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>] which is designed for undirected graphs, they both show considerably lower accuracy on directed graphs than on undirected graphs.</p>
          <figure id="fig4">
            <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186107/images/www2018-116-fig4.jpg" class="img-responsive" alt="Figure 4" longdesc="" />
            <div class="figure-caption">
              <span class="figure-number">Figure 4:</span> <span class="figure-title">Scalability: <font style="font-variant: small-caps">OSP-T</font> shows the best scalability among the competitors.</span>
            </div>
          </figure>
          <p></p>
        </section>
        <section id="sec-25">
          <p><em>4.3.3 Scalability.</em> In this experiment, we estimate scalability of each method by comparing running time when a given graph incrementally grows/shrinks by inserting/deleting <em>ΔG</em> of a fixed size. For brevity, we show the result on Orkut; results on other graphs are similar. |<em>ΔG</em>| is fixed to 5 × 10<sup>6</sup> edges and the error tolerance for each method is the same as that in Section&nbsp;<a class="sec" href="#sec-23">4.3.1</a>. When the graph incrementally grows, <font style="font-variant: small-caps">OSP-T</font> shows different tendency compared to other methods. While all methods take a longer time as the graph grows, <font style="font-variant: small-caps">OSP-T</font> occasionally shows a sudden drop in time as shown in Figure&nbsp;4(a) . Similarly, <font style="font-variant: small-caps">OSP-T</font> shows a sudden jump when the given graph incrementally shrinks as shown in Figure&nbsp;4(b) . From the proof of Theorem&nbsp;<a class="enc" href="#enc3">3.3</a>, time complexity of <font style="font-variant: small-caps">OSP-T</font> is <span class="inline-equation"><span class="tex">$O(m\log _{(1-c)}(\frac{\epsilon }{\Vert \mathbf {q}_{\text{offset}}\Vert _{1}}))$</span></span> . The first term <em>m</em> indicates the upper bound of number of edges which could be visited in each iteration. When a graph grows, the number of visited edges in each iteration would increase as shown in Figure&nbsp;5(a) . The second term <span class="inline-equation"><span class="tex">$\log _{(1-c)}(\frac{\epsilon }{\Vert \mathbf {q}_{\text{offset}}\Vert _{1}})$</span></span> indicates the number of iterations needed to converge, and is positively correlated with ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub>. From Section&nbsp;<a class="sec" href="#sec-11">3.3</a>, ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> is decided by RWR scores of updated nodes: as RWR scores of updated nodes increase, ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> increases. Assume that <em>ΔG</em> of a fixed size updates <em>k</em> nodes in the graph. As the graph grows, the average RWR score of the <em>k</em> nodes decreases since the total number of nodes in the graph increases while the total sum of RWR scores among nodes is always 1. As a result, as the graph grows, ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> becomes smaller as shown in Figure&nbsp;5(a) . This leads to fewer iterations for convergence. In Figure&nbsp;4(a), the number of iterations changes from 3 to 2 when |<em>E</em>| + |<em>ΔE</em>| is 8 × 10<sup>7</sup>, thus the running time suddenly drops. When the number of iterations is consistent (5.5 × 10<sup>7</sup> &lt; |<em>E</em>| + |<em>ΔE</em>| &lt; 7.5 × 10<sup>7</sup> and 8 × 10<sup>7</sup> &lt; |<em>E</em>| + |<em>ΔE</em>| &lt; 10<sup>8</sup>), the running time is decided by the first term <em>m</em> thus increasing constantly as the graph grows. In case of deletion, the opposite process is applied. As the graph shrinks, the average RWR score of updated nodes increases, thus ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> becomes larger as shown in Figure&nbsp;5(b) . This leads to increased number of iterations for convergence. The number of iterations changes from 2 to 3 when |<em>E</em>| − |<em>ΔE</em>| is 7.5 × 10<sup>7</sup> with a sudden jump in running time. When the number of iterations is consistent, the running time decreases constantly as the graph shrinks. In LazyForward, time complexity of an undirected graph is <span class="inline-equation"><span class="tex">$O(|\Delta E| + 1/(\bar{d}\delta))$</span></span> &nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>] where <em>δ</em> is the error tolerance per node and <span class="inline-equation"><span class="tex">$\bar{d}$</span></span> is the average degree &nbsp;<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> of the graph which increases as the graph grows. In the time complexity model, running time would decrease as the graph grows, and increase as the graph shrinks. However, running time constantly increases when the graph grows in Figure&nbsp;4(a) and maintains a constant value when the graph shrinks in Figure&nbsp;4(b) . Thus, the time complexity model fails to explain scalability of LazyForward. Since TrackingPPR&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>] does not provide a time complexity model for general insertion/deletion, we could not investigate further. Only <font style="font-variant: small-caps">OSP-T</font> succeeds in analyzing its scalability based on its time complexity model.</p>
          <figure id="fig5">
            <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186107/images/www2018-116-fig5.jpg" class="img-responsive" alt="Figure 5" longdesc="" />
            <div class="figure-caption">
              <span class="figure-number">Figure 5:</span> <span class="figure-title">Two deciding factors for running time: ‖<strong>q</strong> <sub>offset</sub>‖<sub>1</sub> and the number of visited edges per iteration show different tendencies when a graph grows/shrinks. Note that |<em>ΔE</em>| is fixed.</span>
            </div>
          </figure>
          <p></p>
        </section>
      </section>
      <section id="sec-26">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.4</span> Effects of ϵ, error tolerance</h3>
          </div>
        </header>
        <p>To examine the effects of error tolerance ϵ on the performance of <font style="font-variant: small-caps">OSP-T</font>, we check the <em>L</em>1 error and running time varying ϵ. We report results on DBLP and Berkstan for brevity; results on other graphs are similar. As shown in Figure&nbsp;<a class="fig" href="#fig6">6</a>, as ϵ increases, the running time of <font style="font-variant: small-caps">OSP-T</font> decreases and <em>L</em>1 error increases across all datasets. Note that we theoretically proved O(running time) is proportional to <em>log</em>(ϵ) in Theorem&nbsp;<a class="enc" href="#enc3">3.3</a>, and O(<em>L</em>1 error) is proportional to ϵ in Theorem&nbsp;<a class="enc" href="#enc4">3.4</a>. We verify those theorems experimentally in this experiment. In Figure&nbsp;<a class="fig" href="#fig6">6</a>, error tolerance and <em>L</em>1 error are plotted in log scale while running time is plotted in linear scale. Relations among them are near linear. This shows that the theorems describing the relations among <em>L</em>1 error, running time and ϵ work in real-world datasets.</p>
        <figure id="fig6">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186107/images/www2018-116-fig6.jpg" class="img-responsive" alt="Figure 6" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 6:</span> <span class="figure-title">Effects of error tolerance ϵ on <font style="font-variant: small-caps">OSP-T</font>: as ϵ increases, the <em>L</em>1 error increases while the running time decreases.</span>
          </div>
        </figure>
        <figure id="fig7">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186107/images/www2018-116-fig7.jpg" class="img-responsive" alt="Figure 7" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 7:</span> <span class="figure-title">Effects of size of <em>ΔG</em> on <font style="font-variant: small-caps">OSP-T</font>: as the size of <em>ΔG</em> becomes bigger, both computation time and <em>L</em>1 error increase.</span>
          </div>
        </figure>
        <figure id="fig8">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186107/images/www2018-116-fig8.jpg" class="img-responsive" alt="Figure 8" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 8:</span> <span class="figure-title">Effects of location of <em>ΔG</em>: when <em>ΔG</em> happens around high RWR score nodes, <font style="font-variant: small-caps">OSP-T</font> takes long running time. However, this rarely happens since there are only few nodes with high RWR score in a graph.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-27">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.5</span> Effects of <em>ΔG</em>, a graph modification</h3>
          </div>
        </header>
        <section id="sec-28">
          <header>
            <div class="title-info">
              <h4><span class="section-number">4.5.1</span> Size of <em>ΔG</em></h4>
            </div>
          </header>
          <p>In Figure&nbsp;<a class="fig" href="#fig7">7</a>, as the size of <em>ΔG</em> increases, the running time and <em>L</em>1 error of <font style="font-variant: small-caps">OSP-T</font> also increase. Larger size of <em>ΔG</em> leads to longer <em>L</em>1 length of the starting vector <strong>q</strong> <sub>offset</sub> with longer computation time. Likewise, longer <em>L</em>1 length of <strong>q</strong> <sub>offset</sub> leads to higher <em>L</em>1 error as discussed in Section&nbsp;<a class="sec" href="#sec-11">3.3</a>. Still, the whole <em>L</em>1 norm errors are under the error bound <em>O</em>(ϵ/<em>c</em>) where ϵ is the error tolerance and <em>c</em> is the restart probability.</p>
        </section>
        <section id="sec-29">
          <header>
            <div class="title-info">
              <h4><span class="section-number">4.5.2</span> Location of <em>ΔG</em></h4>
            </div>
          </header>
          <p>To show the effects of location of <em>ΔG</em> on the performance of <font style="font-variant: small-caps">OSP-T</font>, we estimate the running time varying the location of an edge to be deleted in a given graph. We first calculate RWR scores among nodes and divide nodes evenly into 100 groups in the order of RWR scores. Then, we randomly sample 10 nodes from each group. For each sampled node <em>u</em>, we estimate the running time of <font style="font-variant: small-caps">OSP-T</font> after deleting an edge (<em>u</em>, <em>v</em>). As shown in Figure&nbsp;<a class="fig" href="#fig8">8</a>, when a modification happens around nodes with high RWR scores, <font style="font-variant: small-caps">OSP-T</font> takes a long running time, but this rarely happens. Intuitively, when a modification happens around high RWR score nodes, the higher offset scores are propagated, then the more steps would be needed to satisfy the given error tolerance. This intuition is consistent with the theoretical result we showed in Section&nbsp;<a class="sec" href="#sec-11">3.3</a>. Sparse distribution around high RWR scores with long running time coincides with sporadic long running time observed by Ohsaka et al.&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>].</p>
        </section>
      </section>
    </section>
    <section id="sec-30">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Related Works</h2>
        </div>
      </header>
      <p>In this section, we review previous approaches to handle dynamic RWR problem. Chien et al.&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>] proposed the approximate aggregation/disaggregation method. The method takes a small subset <em>S</em> that contains the updated edge, and then renew RWR scores only in <em>S</em>. Bahmani et al.&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>] applied the Monte-Carlo method&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>] on the dynamic RWR problem. Their algorithm maintains R random-walk segments, and reconstructs any segments related to a graph modification. Recently, score propagation models TrackingPPR and LazyForward were proposed by Ohsaka&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>] and Zhang&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>], respectively: when a given graph is updated, scores that complement the changes are calculated at first, then propagated across the graph. Although sharing the same intuition, they differ in the initialization step and the propagation method. While TrackingPPR propagates the scores immediately to all neighboring nodes, LazyForward modifies RWR values of the updated nodes at first then propagates the scores. In <font style="font-variant: small-caps">OSP-T</font>, our proposed method, calculating offset seed vector <strong>q</strong> <sub>offset</sub> is at the initialization step. The propagation methods used in the two models are Gauss-Southwell algorithm and Forward Local Push algorithm, respectively. In each iteration, Gauss-Southwell algorithm and Forward Local Push algorithm propagate scores stored in a vertex which has the largest score, while <font style="font-variant: small-caps">OSP-T</font> propagates scores across whole vertices that could be reached in one hop. TrackingPPR and LazyForward succeed in outperforming the previous approaches&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>] in both computation time and accuracy&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>], and show the effectiveness of propagation model on dynamic graphs. However, none of them provide the guarantee of exactness or rigid analysis of error bound. Furthermore, Ohsaka et al. analyzed the running time only when edges are randomly and sequentially inserted, while Zhang et al. analyzed the running time only for undirected graphs. Note that we provide exactness of <font style="font-variant: small-caps">OSP</font>, and time complexity and error bound for <font style="font-variant: small-caps">OSP-T</font> in a generalized form. <font style="font-variant: small-caps">OSP-T</font> outperforms TrackingPPR and LazyForward in terms of speed and accuracy as shown in our experiments (Section&nbsp;<a class="sec" href="#sec-22">4.3</a>).</p>
    </section>
    <section id="sec-31">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Conclusion</h2>
        </div>
      </header>
      <p>We propose <font style="font-variant: small-caps">OSP</font>, a fast and accurate method for tracking RWR scores on a dynamic graph. When the graph is updated, <font style="font-variant: small-caps">OSP</font> first calculates offset scores around the modified edges, propagates the offset scores across the updated graph, and then merges them with the current RWR scores to get updated RWR scores. We also propose <font style="font-variant: small-caps">OSP-T</font>, a version of <font style="font-variant: small-caps">OSP</font> which regulates a trade-off between accuracy and computation time. Among numerous dynamic RWR models based on score propagation, <font style="font-variant: small-caps">OSP</font> is the first model with rigid analysis of accuracy and running time in a generalized form. Through intensive experiments, we show that <font style="font-variant: small-caps">OSP</font> and <font style="font-variant: small-caps">OSP-T</font> outperform other state-of-the-art methods in terms of accuracy and computation time.</p>
    </section>
    <section id="sec-32">
      <header>
        <div class="title-info">
          <h2>Acknowledgment</h2>
        </div>
      </header>
      <p>This work was supported by Institute for Information &amp; communications Technology Promotion(IITP) grant funded by the Korea government(MSIT) (No.R0190-15-2012, High Performance Big Data Analytics Platform Performance Acceleration Technologies Development). U Kang is the corresponding author.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Reid Andersen, Fan Chung, and Kevin Lang. 2006. Local graph partitioning using pagerank vectors. In <em><em>Foundations of Computer Science, 2006. FOCS’06. 47th Annual IEEE Symposium on</em></em> . IEEE, 475–486.</li>
        <li id="BibPLXBIB0002" label="[2]">I Antonellis, H Garcia-Molina, and C-C&nbsp;Simrank+ Chang. 2007. Query rewriting through link analysis of the click graph. <em><em>Proceedings of VLDB (Dec 2008)</em></em> (2007), 408–421.</li>
        <li id="BibPLXBIB0003" label="[3]">R Artusi, P Verderio, and E Marubini. 2002. Bravais-Pearson and Spearman correlation coefficients: meaning, test of hypothesis and confidence interval. <em><em>Int J Biol Markers</em></em> 17, 2 (2002), 148–151.</li>
        <li id="BibPLXBIB0004" label="[4]">Bahman Bahmani, Abdur Chowdhury, and Ashish Goel. 2010. Fast incremental and personalized pagerank. <em><em>Proceedings of the VLDB Endowment</em></em> 4, 3 (2010), 173–184.</li>
        <li id="BibPLXBIB0005" label="[5]">Soumen Chakrabarti, Amit Pathak, and Manish Gupta. 2011. Index design and query processing for graph conductance search. <em><em>The VLDB Journal</em></em> 20, 3 (2011), 445–470.</li>
        <li id="BibPLXBIB0006" label="[6]">Steve Chien, Cynthia Dwork, Ravi Kumar, Daniel&nbsp;R Simon, and D Sivakumar. 2004. Link evolution: Analysis and algorithms. <em><em>Internet mathematics</em></em> 1, 3 (2004), 277–304.</li>
        <li id="BibPLXBIB0007" label="[7]">Michalis Faloutsos, Petros Faloutsos, and Christos Faloutsos. 1999. On power-law relationships of the internet topology. In <em><em>ACM SIGCOMM computer communication review</em></em> , Vol.&nbsp;29. ACM, 251–262.</li>
        <li id="BibPLXBIB0008" label="[8]">Yasuhiro Fujiwara, Makoto Nakatsuji, Makoto Onizuka, and Masaru Kitsuregawa. 2012. Fast and exact top-k search for random walk with restart. <em><em>Proceedings of the VLDB Endowment</em></em> 5, 5 (2012), 442–453.</li>
        <li id="BibPLXBIB0009" label="[9]">Glen Jeh and Jennifer Widom. 2002. SimRank: a measure of structural-context similarity. In <em><em>Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining</em></em> . ACM, 538–543.</li>
        <li id="BibPLXBIB0010" label="[10]">Glen Jeh and Jennifer Widom. 2003. Scaling personalized web search. In <em><em>Proceedings of the 12th international conference on World Wide Web</em></em> . ACM, 271–279.</li>
        <li id="BibPLXBIB0011" label="[11]">Woojeong Jin, Jinhong Jung, and U Kang. 2017. Supervised and Extended Restart in Random Walks for Ranking and Link Prediction in Networks. <em><em>arXiv preprint arXiv:1710.06609</em></em> .</li>
        <li id="BibPLXBIB0012" label="[12]">Jinhong Jung, Woojeong Jin, Lee Sael, and U. Kang. 2016. Personalized Ranking in Signed Networks Using Signed Random Walk with Restart. In <em><em>IEEE 16th International Conference on Data Mining, ICDM 2016, December 12-15, 2016, Barcelona, Spain</em></em> . 973–978.</li>
        <li id="BibPLXBIB0013" label="[13]">Jinhong Jung, Namyong Park, Lee Sael, and U Kang. 2017. BePI: Fast and Memory-Efficient Method for Billion-Scale Random Walk with Restart. In <em><em>SIGMOD</em></em> .</li>
        <li id="BibPLXBIB0014" label="[14]">Jinhong Jung, Kijung Shin, Lee Sael, and U. Kang. 2016b. Random Walk with Restart on Large Graphs Using Block Elimination. <em><em>ACM Trans. Database Syst.</em></em> 41, 2 (2016), 12. https://doi.org/10.1145/2901736</li>
        <li id="BibPLXBIB0015" label="[15]">U Kang, Mikhail Bilenko, Dengyong Zhou, and Christos Faloutsos. 2012. Axiomatic Analysis of Co-occurrence Similarity Functions. <em><em>CMU-CS-12-102</em></em> (2012).</li>
        <li id="BibPLXBIB0016" label="[16]">Zhenjiang Lin, Michael&nbsp;R Lyu, and Irwin King. 2009. Matchsim: a novel neighbor-based similarity measure with maximum neighborhood matching. In <em><em>Proceedings of the 18th ACM conference on Information and knowledge management</em></em> . ACM, 1613–1616.</li>
        <li id="BibPLXBIB0017" label="[17]">Naoto Ohsaka, Takanori Maehara, and Ken-ichi Kawarabayashi. 2015. Efficient PageRank tracking in evolving networks. In <em><em>Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em></em> . ACM, 875–884.</li>
        <li id="BibPLXBIB0018" label="[18]">Jia-Yu Pan, Hyung-Jeong Yang, Christos Faloutsos, and Pinar Duygulu. 2004. Automatic multimedia cross-modal correlation discovery. In <em><em>Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</em></em> . ACM, 653–658.</li>
        <li id="BibPLXBIB0019" label="[19]">Haekyu Park, Jinhong Jung, and U. Kang. 2017. A comparative study of matrix factorization and random walk with restart in recommender systems. In <em><em>2017 IEEE International Conference on Big Data, BigData 2017, Boston, MA, USA, December 11-14, 2017</em></em> . 756–765.</li>
        <li id="BibPLXBIB0020" label="[20]">Kijung Shin, Jinhong Jung, Sael Lee, and U Kang. 2015. BEAR: Block Elimination Approach for Random Walk with Restart on Large Graphs. In <em><em>Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data</em></em> . ACM, 1571–1585.</li>
        <li id="BibPLXBIB0021" label="[21]">Jimeng Sun, Huiming Qu, Deepayan Chakrabarti, and Christos Faloutsos. 2005. Neighborhood formation and anomaly detection in bipartite graphs. In <em><em>Data Mining, Fifth IEEE International Conference on</em></em> . IEEE, 8–pp.</li>
        <li id="BibPLXBIB0022" label="[22]">Hanghang Tong and Christos Faloutsos. 2006. Center-piece subgraphs: problem definition and fast solutions. In <em><em>Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</em></em> . ACM, 404–413.</li>
        <li id="BibPLXBIB0023" label="[23]">Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan. 2006. Fast random walk with restart and its applications. (2006).</li>
        <li id="BibPLXBIB0024" label="[24]">Sibo Wang, Youze Tang, Xiaokui Xiao, Yin Yang, and Zengxiang Li. 2016. HubPPR: effective indexing for approximate personalized pagerank. <em><em>Proceedings of the VLDB Endowment</em></em> 10, 3 (2016), 205–216.</li>
        <li id="BibPLXBIB0025" label="[25]">Joyce&nbsp;Jiyoung Whang, David&nbsp;F Gleich, and Inderjit&nbsp;S Dhillon. 2013. Overlapping community detection using seed set expansion. In <em><em>Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management</em></em> . ACM, 2099–2108.</li>
        <li id="BibPLXBIB0026" label="[26]">Minji Yoon, Jinhong Jung, and U Kang. 2018. TPA: Fast, Scalable, and Accurate method for Approximate Random Walk with Restart on Billion Scale Graphs. In <em><em>IEEE 34th International Conference on Data Engineering, ICDE 2018, April 16-20, 2018, Paris, France</em></em> .</li>
        <li id="BibPLXBIB0027" label="[27]">Hongyang Zhang, Peter Lofgren, and Ashish Goel. 2016. Approximate Personalized PageRank on Dynamic Graphs. <em><em>arXiv preprint arXiv:1603.07796</em></em> (2016).</li>
        <li id="BibPLXBIB0028" label="[28]">Zeyuan&nbsp;Allen Zhu, Silvio Lattanzi, and Vahab&nbsp;S Mirrokni. 2013. A Local Algorithm for Finding Well-Connected Clusters.. In <em><em>ICML (3)</em></em> . 396–404.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>], the original time complexity is <span class="inline-equation"><span class="tex">$O(|\Delta E| + 1/\bar{\delta })$</span></span> where <span class="inline-equation"><span class="tex">$\bar{\delta }$</span></span> is a degree-normalized error tolerance per node such that <span class="inline-equation"><span class="tex">$|\mathbf {r}^{(i)}(t)|/d(t){\lt}\bar{\delta }$</span></span> for residuals <em>r</em> with any node <em>t</em> at <em>i</em>th iteration. To consider the effect of changes in degree, we present <em>δ</em> as <span class="inline-equation"><span class="tex">$\bar{d}\bar{\delta }$</span></span> with the average degree <span class="inline-equation"><span class="tex">$\bar{d}$</span></span> .</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&nbsp;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3178876.33186107">https://doi.org/10.1145/3178876.33186107</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
