<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>When Sheep Shop: Measuring Herding Effects in Product Ratings with Natural Experiments</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">When Sheep Shop: Measuring Herding Effects in Product Ratings with Natural Experiments</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Gael</span>      <span class="surName">Lederrey</span>,     EPFL, <a href="mailto:gael.lederrey@epfl.ch">gael.lederrey@epfl.ch</a>     </div>     <div class="author">     <a href="https://orcid.org/0000-0002-3984-1232" ref="author"><span class="givenName">Robert</span>      <span class="surName">West</span></a>,     EPFL, <a href="mailto:robert.west@epfl.ch">robert.west@epfl.ch</a>     </div>            </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3178876.3186160" target="_blank">https://doi.org/10.1145/3178876.3186160</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>As online shopping becomes ever more prevalent, customers rely increasingly on product rating websites for making purchase decisions. The reliability of online ratings, however, is potentially compromised by the so-called <em>herding effect:</em>when rating a product, customers may be biased to follow other customers&#x2019; previous ratings of the same product. This is problematic because it skews long-term customer perception through haphazard early ratings. The study of herding poses methodological challenges. In particular, observational studies are impeded by the lack of counterfactuals: simply correlating early with subsequent ratings is insufficient because we cannot know what the subsequent ratings would have looked like had the first ratings been different. The methodology introduced here exploits a setting that comes close to an experiment, although it is purely observational&#x2014;a <em>natural experiment</em>. Our key methodological device consists in studying the same product on two separate rating sites, focusing on products that received a high first rating on one site, and a low first rating on the other. This largely controls for confounds such as a product&#x0027;s inherent quality, advertising, and producer identity, and lets us isolate the effect of the first rating on subsequent ratings. In a case study, we focus on beers as products and jointly study two beer rating sites, but our method applies to any pair of sites across which products can be matched. We find clear evidence of herding in beer ratings. For instance, if a beer receives a very high first rating, its second rating is on average half a standard deviation higher, compared to a situation where the identical beer receives a very low first rating. Moreover, herding effects tend to last a long time and are noticeable even after 20 or more ratings. Our results have important implications for the design of better rating systems.</small>     </p>    </div>    <div class="classifications">     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Gael Lederrey and Robert West. 2018. When Sheep Shop: Measuring Herding Effects in Product Ratings with Natural Experiments. In <em>WWW 2018: The 2018 Web Conference,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France</em>. ACM, New York, NY, USA 10 pages. <a href="https://doi.org/10.1145/3178876.3186160" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3178876.3186160</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-3">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>With every purchase but one click away, online shopping is extremely convenient and is accounting for an ever larger share of the retail market. The downside of online shopping is that it provides a less direct experience than going to an offline, brickandmortar store, where customers can taste, smell, touch, and feel a product before deciding whether to buy it. Online, we must rely on ratings provided by previous customers instead.</p>    <p>Online rating systems, however, suffer from the known problem of social influence, also termed <strong>herding,</strong> which expresses the fact that raters tend to be biased by the opinions of previous raters [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>] and which can make online rating systems fickle and sensitive to small variations in early ratings: if the first few reviews of a product happen to swing a certain way (or are purposefully engineered that way in an act of review spamming [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>]), this can unduly skew subsequent reviews. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186160/images/www2018-169-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">       <em>Lost Rhino Ice Breaker IPA,</em> an example of a beer with low (high) ratings on BeerAdvocate (RateBeer) (scores standardized to be comparable across sites; <em>cf.</em> Sec.&#x00A0;<a class="sec" href="#sec-9">3.2</a>).</span>     </div>     </figure>    </p>    <p>This can have severe implications for both customers, who may end up with unsatisfying products, and producers, whose highquality products may end up being bought less than they deserve. Herding is therefore a behavior of great interest both sociologically as well as economically.</p>    <p>Studying the herding effect is difficult, however. Although <strong>randomized experiments</strong> have been successfully deployed to quantify social influence in rating behavior [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>], experiments can be risky from a business and ethical perspective, for either they wilfully subject products to random treatments with potentially harmful effects, or they are restricted to small laboratory settings [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>], which reduces the generality of findings. <strong>Observational studies</strong> of herding [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>], on the other hand, are less delicate in this regard than randomized experiments, but they are more delicate methodologically, as they require more care during the analysis.</p>    <p>To illustrate this point, consider a <strong>na&#x00EF;ve observational study of herding,</strong> which simply measures if products that receive high early ratings also tend to receive high later ratings, and if at the same time products that receive low early ratings tend to receive low later ratings. The problem, obviously, with this hypothetical study is that both early and later ratings might be caused by a hidden correlate&#x2014;the inherent quality of the product&#x2014;rather than one by the other. To credibly claim a causal relation, we would need to show that, <em>for a fixed product,</em> later ratings follow early ratings regardless of whether the first ratings were high or low. If, on the contrary, inherent quality were the real cause, then a good product would get good later ratings even if, for some reason, the first ratings were low. In other words, the na&#x00EF;ve observational study suffers from the lack of counterfactuals: we cannot tell whether there has been herding in the ratings for a product if we do not know what would have happened if the first ratings had been different.</p>    <p>We address this challenge by studying not a single product rating website, but two of them in parallel. In particular, we will observe how the same product is rated independently on the two sites; if the product happens to receive a vastly different firstrating on site 1, compared to site 2, we can measure how the firstrating affects subsequent ones.</p>    <p>To explain the basic idea behind our method, we start with an example. For the sake of concreteness, and to set the stage for our case study, consider the case of beers as products, rated on the two major beerrating websites, BeerAdvocate and RateBeer. Consider a beer <em>B</em> that has become available just recently. The RateBeer user to first rate beer <em>B</em> on RateBeer happens to love it, so she gives it a very high score. The BeerAdvocate user to first rate beer <em>B</em> on BeerAdvocate, on the contrary, happens to hate it, so he gives it a very low score. Of course, the inherent quality of beer <em>B</em> was exactly the same for both users, and each user was the first to rate beer <em>B</em> on the respective site, so they were not influenced by previous opinions. It is only due to chance that the first RateBeer rating was high, and the first BeerAdvocate rating low, instead of <em>vice versa.</em>    </p>    <p>More generally, whenever the same beer gets a high firstrating on one site, and a low firstrating on the other site, it seems likely that it is haphazard whether the high firstrating happens on RateBeer or on BeerAdvocate. Whether this is indeed true needs to be established, but if it can be established, this means that nature has created a situation akin to an experiment for us: she has flipped a coin to decide on which of the two sites beer <em>B</em> was to be exposed to the &#x201C;experimental&#x201D; condition <em>high firstrating,</em> and on which to the &#x201C;experimental&#x201D; condition <em>low firstrating</em>&#x2014;a so-called <strong>natural experiment</strong>. We may then analyze which effect the two conditions have on later ratings of beer <em>B</em>. In the presence of herding, later ratings on the site with the high firstrating should on average be higher than on the site with the low firstrating. Conversely, in the absence of herding, later ratings should on average be similar regardless of the firstrating.</p>    <p>Fig.&#x00A0;<a class="fig" href="#fig1">1</a> shows that beers such as the anonymous <em>B</em> really exist, in this case an India pale ale named <em>Lost Rhino Ice Breaker</em>. The time series of this beer&#x0027;s ratings is plotted in Fig.&#x00A0;<a class="fig" href="#fig1">1</a>(a), with the cumulative average displayed in Fig.&#x00A0;<a class="fig" href="#fig1">1</a>(b) . The curves show that <em>Lost Rhino Ice Breaker</em> received a much lower firstrating on BeerAdvocate than on RateBeer, and that it never managed to recover from its dismal start on BeerAdvocate, while it thrived on RateBeer&#x2014;a difference that may be due to herding. <a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> This example is but anecdotal, of course, and the goal of this paper is to move from such examples to reliable causal statements. Our main contributions are twofold: First, we introduce an observational methodology for quantifying how consistently early ratings influence later ones via the natural experiment sketched above (Sec.&#x00A0;<a class="sec" href="#sec-4">2</a>). Second, we apply our method to a real dataset of product ratings (Sec.&#x00A0;<a class="sec" href="#sec-7">3</a>), after carefully ruling out confounds and thus confirming that indeed we have identified a natural experiment (Sec.&#x00A0;<a class="sec" href="#sec-10">4</a>). Our results provide strong evidence of substantial herding effects (Sec.&#x00A0;<a class="sec" href="#sec-14">5</a>): the second rating for a product is on average half a standard deviation higher when a beer received a very high firstrating, compared to when it received a very low firstrating. Furthermore, herding effects are tenacious and can be noticed even after 20 or more reviews. We conclude the paper by discussing implications of our findings and prior as well as future work (Sec.&#x00A0;<a class="sec" href="#sec-15">6</a>).</p>   </section>   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Methodology: natural experiment</h2>     </div>    </header>    <figure id="fig2">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186160/images/www2018-169-fig2.jpg" class="img-responsive" alt="Figure 2"      longdesc=""/>     <div class="figure-caption">     <span class="figure-number">Figure 2:</span>     <span class="figure-title">Variable dependencies for different kinds of study (Sec.&#x00A0;<a class="sec" href="#sec-4">2</a>). <em>T</em>: treatment (firstrating); <em>O</em>: outcome (subsequent ratings); <em>P</em>: rated product; <em>S</em>: rating site. Only (a) and (c) allow us to draw conclusions about a causal link between <em>T</em> and <em>O</em>.</span>     </div>    </figure>    <p>To illustrate the difference between a proper randomized experiment and the na&#x00EF;ve observational study delineated in the introduction, we represent both scenarios as Bayesian networks in Fig.&#x00A0;<a class="fig" href="#fig2">2</a>(a&#x2013;b). The diagrams contain three random variables: product (<em>P</em>), treatment (<em>T</em>), and outcome (<em>O</em>). The treatment <em>T</em> captures whether the firstrating for product <em>P</em> is high or low; the outcome <em>O</em> captures whether subsequent ratings for <em>P</em> are high or low.</p>    <p>In a randomized experiment (Fig.&#x00A0;<a class="fig" href="#fig2">2</a>(a)), treatment assignment is decided by a coin flip, independent of any product properties, so different treatment groups are indistinguishable with respect to product properties and are therefore directly comparable. Hence, if we observe significantly different outcomes for different treatments, this difference is likely to be caused by the treatment.</p>    <p>In a na&#x00EF;ve observational study (Fig.&#x00A0;<a class="fig" href="#fig2">2</a>(b)), on the contrary, treatment assignment may depend on product properties, so the latter may influence both treatment and outcome. In this case, a correlation between treatment and outcome may not be causal, but both may instead be caused separately by a <em>confound,</em> a latent property of the product. As mentioned, an obvious confound could be the inherent quality of the product, as good products tend to be rated highly both by the first reviewer (treatment) and by subsequent reviewers (outcome), even in the absence of herding.</p>    <p>Our methodology circumvents the problem of productinduced confounds by studying not one single rating website (as would be done in a na&#x00EF;ve observational study), but rather two separate rating websites with overlapping sets of rated products. This still constitutes an observational study, but one that naturally controls for confounds and thus comes close to a randomized experiment in spirit&#x2014;a situation commonly known as a <em>natural experiment.</em>    </p>    <p>Let us call the two sites <em>S</em>     <sub>1</sub> and <em>S</em>     <sub>2</sub>, and consider a product <em>P</em> rated on both sites. If <em>P</em> received a high firstrating (<em>i.e.</em>, treatment) on <em>S</em>     <sub>1</sub> and a low firstrating on <em>S</em>     <sub>2</sub> (or <em>vice versa</em>), then&#x2014;under conditions to be discussed below (Sec.&#x00A0;<a class="sec" href="#sec-6">2.2</a>)&#x2014;this situation may be seen as emulating two &#x201C;parallel universes&#x201D;: we can observe what happens to the <em>same</em> product under each possible treatment. In other words, we now have counterfactuals, the lack of which is the major shortcoming of the na&#x00EF;ve, singlesite observational study.</p>    <section id="sec-5">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Step-by-step description</h3>     </div>     </header>     <p>We now describe our methodology in detail. It encompasses 5 steps.</p>     <p>     <strong>Step&#x00A0;1:</strong>      <strong>Match products</strong> across the two rating websites. The fundamental device exploited by our natural experiment consists in tracking the same product on two separate websites, so we work only with products that we can identify on both sites and discard all others. Sec.&#x00A0;<a class="sec" href="#sec-11">4.1</a> describes the matching algorithm we used on a pair of beer rating websites; it is based on string similarities between product names, and we believe it is general enough to be adapted to other datasets as well.</p>     <p>     <strong>Step&#x00A0;2:</strong>      <strong>Define the pairedtreatment groups.</strong> On each site, label each product as &#x201C;high&#x201D; (H), &#x201C;medium&#x201D; (M), or &#x201C;low&#x201D; (L), depending on the firstrating (treatment) it received on the site. A firstrating is defined as H if it is in the top <em>p</em> percent of the firstrating s on the respective site, as L if it is in the bottom <em>p</em> percent, and as M otherwise. (In our specific case study, we use <em>p</em> = 15.) After this step, each product falls into one of the nine <em>pairedtreatment groups</em> defined by the cross product {<em>T</em>     <sub>1</sub>     <em>T</em>     <sub>2</sub>: <em>T</em>     <sub>1</sub>, <em>T</em>     <sub>2</sub> &#x2208; {H, M, L}}, where the two letters capture the treatments the product received on sites <em>S</em>     <sub>1</sub> and <em>S</em>     <sub>2</sub> via the respective firstrating s; <em>e.g.</em>, HH means that the product received high firstrating s on both sites, HL that it received a high firstrating on <em>S</em>     <sub>1</sub> and a low one on <em>S</em>     <sub>2</sub>, LH that it received a low firstrating on <em>S</em>     <sub>1</sub> and a high firstrating on <em>S</em>     <sub>2</sub>, <em>etc.</em>     </p>     <p>     <strong>Step&#x00A0;3:</strong>      <strong>Balance the pairedtreatment groups,</strong> making sure that, for each (<em>T</em>     <sub>1</sub>, <em>T</em>     <sub>2</sub>) &#x2208; {H, M, L} &#x00D7; {H, M, L}, we have the same number of products in the pairedtreatment group <em>T</em>     <sub>1</sub>     <em>T</em>     <sub>2</sub> as in the group <em>T</em>     <sub>2</sub>     <em>T</em>     <sub>1</sub>. We may achieve this simply by randomly subsampling from the larger of the two groups. This step ensures that, for each site <em>S</em> and each pairedtreatment group <em>T</em>     <sub>1</sub>     <em>T</em>     <sub>2</sub> (with <em>T</em>     <sub>1</sub> &#x2260; <em>T</em>     <sub>2</sub>), the probabilities of the two treatments <em>T</em>     <sub>1</sub> and <em>T</em>     <sub>2</sub> are 50% each.</p>     <p>     <strong>Step&#x00A0;4:</strong>      <strong>Aggregate pairedtreatment groups</strong> containing the same set {<em>T</em>     <sub>1</sub>, <em>T</em>     <sub>2</sub>} of treatments. This reduces the number of pairedtreatment groups to six: HH, HM, HL, MM, ML, LL; <em>e.g.</em>, after aggregation, the group HL contains both products with H on <em>S</em>     <sub>1</sub> and L on <em>S</em>     <sub>2</sub> and products with L on <em>S</em>     <sub>1</sub> and H on <em>S</em>     <sub>2</sub>. This is done to have more data points per group, but we advise to also perform a separate analysis on the nonaggregated data as a sanity check.</p>     <p>     <strong>Step&#x00A0;5:</strong>      <strong>Compare the outcomes for different treatments</strong> within the same pairedtreatment group. We consider the groups HL, HM, and ML, where the same product received different firstrating s on the two sites. By comparing subsequent ratings across the two sites, we can estimate the treatment effect in isolation from any productrelated confounds (such as inherent quality), which are controlled for by fixing the product. In particular, for a given product <em>P</em> and a given rating index <em>i</em>, we compare <em>P</em>&#x2019;s <em>i</em>-th rating on the site where it received the higher firstrating with its <em>i</em>-th rating on the site where it received the lower firstrating. If the difference is positive, this supports the hypothesis of a causal link between treatment (firstrating) and outcome (<em>i</em>-th rating), <em>i.e.</em>, herding. Tracking the difference as a function of the rating index <em>i</em> also lets us study if, and how fast, herding attenuates with time.</p>     <p>The most interesting pairedtreatment group is HL, as it corresponds to the starkest difference in treatments. Since, however, it will generally occur less frequently in practice than the less extreme groups (HM and ML), we recommend to also study the latter. Finally, as a sanity check, it is also advisable to include the symmetric groups HH, MM, and LL in the analysis.</p>    </section>    <section id="sec-6">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Assumptions</h3>     </div>     </header>     <p>The above methodology allows us to estimate the causal effect of the firstrating (treatment) on subsequent ratings (outcome) if the two following assumptions hold.</p>     <p>The first and most crucial assumption, and in fact the defining property of a natural experiment, is that <strong>treatment assignment is haphazard:</strong> whether a given product <em>P</em> with different firstrating s receives its higher firstrating on <em>S</em>     <sub>1</sub> and its lower firstrating on <em>S</em>     <sub>2</sub> or <em>vice versa</em> must not depend on any properties of <em>P</em>, <em>S</em>     <sub>1</sub>, and <em>S</em>     <sub>2</sub>. In other words, the treatment assignment <em>T</em> must be independent of the product <em>P</em> and of the site <em>S</em> (Fig.&#x00A0;<a class="fig" href="#fig2">2</a>(c)). If this is the case, and if variations in <em>T</em> are correlated with variations in <em>O</em>, then the link between <em>T</em> and <em>O</em> is likely to be causal. Otherwise (Fig.&#x00A0;<a class="fig" href="#fig2">2</a>(d)), properties of the product or of the site, or a combination of the two, could explain both the treatment assignment and the outcome&#x2014;we might have mere correlation without causation, which would defeat the very purpose of considering a matched, rather than a na&#x00EF;ve, single-site observational study.</p>     <p>Note that, by construction, treatment assignment is independent of the product alone: each product is included twice in the matched dataset, once per site, on one of them with a higher, and on one with a lower, firstrating, such that we have a 50/50 distribution over the two possible treatments for a given product. Similarly, again by construction, treatment assignment is independent of the site alone: after balancing pairedtreatment group s (step&#x00A0;3 in Sec.&#x00A0;<a class="sec" href="#sec-5">2.1</a>), each site has as many products with a higher as with a lower firstrating, resulting in a 50/50 distribution over the two possible treatments in each pairedtreatment group for a given site.</p>     <p>This does not imply, though, that treatment assignment is independent of the combination of product and site; <a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>     <em>e.g.</em>, users on site <em>S</em>     <sub>1</sub> might like a certain kind of product more than users on site <em>S</em>     <sub>2</sub>, which could result in an increased probability of a higher firstrating (treatment) for that kind of product on <em>S</em>     <sub>1</sub>, compared to <em>S</em>     <sub>2</sub>.</p>     <p>In our setup, showing that treatment is indeed independent of the combination of product and site establishes the <em>internal validity</em> of the study. How to show that a specific study is internally valid depends on the datasets being used. (See Sec.&#x00A0;<a class="sec" href="#sec-13">4.3</a> for how we proceed in the case of beer ratings.) Although we cannot speak of a natural experiment if this independence does not immediately hold in the matched dataset, one might still achieve it by explicitly balancing the dataset, <em>e.g.</em>, via propensityscore matching [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>].</p>     <p>The second assumption is that the <strong>matched dataset accurately reflects the full dataset.</strong> In general, not all products are present on both rating sites, so matching will select a subset of all products. If the matched sample is biased, <em>i.e.</em>, systematically different from the full dataset before matching, this might preclude us from generalizing our findings from the natural experiment to the set of all products rated on the two sites. For instance, it is conceivable that particularly good products are more likely to be present on both sites, which would make our findings specific to good, rather than average, products. By showing that the matched sample is unbiased, we establish the so-called <em>external validity</em> of the study. (See Sec.&#x00A0;<a class="sec" href="#sec-13">4.3</a> for how we proceed in the case of beers as products.)</p>    </section>   </section>   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Data: two beer rating websites</h2>     </div>    </header>    <p>We apply our methodology to the specific scenario of beer ratings. This setting is well suited for several reasons: the market is dominated by two large websites dedicated to the rating and reviewing of beers&#x2014;BeerAdvocate and RateBeer&#x2014;, each with a long history reaching back nearly 20 years, with very similar site designs, and with a large overlap of rated products.</p>    <p>An older version of the data was made available by McAuley <em>et&#x00A0;al.</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>], but as that version was produced in 2012, we recrawled it; the data now extends from 2001 to August 2017. <a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>    </p>    <p>Although we focus on one case study, our method applies equally to other pairs of rating websites, as long as the intersection of the sets of rated products is large (<em>cf.</em> our discussion in Sec.&#x00A0;<a class="sec" href="#sec-15">6</a>).</p>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Description of beer rating websites</h3>     </div>     </header>     <p>BeerAdvocate and RateBeer are the two largest online beerrelated websites. Although they provide a general space for beer aficionados, with articles, discussion forums, and trading platforms, their main purpose is to collect and curate beer ratings provided by users. On both sites, beers are rated with respect to five aspects (look, smell/aroma, taste, feel/palate, overall), which are then combined via a weighted sum into a rating score between 1 and 5. The sites are also similar with respect to layout and visual appearance. They both prominently show the most recent ratings as well as the current cumulative average on the page of each beer (RateBeer also shows the rank of the beer among all beers), so we can assume that users about to rate a beer become aware of this information.</p>    </section>    <section id="sec-9">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Basic analysis of rating datasets</h3>     </div>     </header>     <p>Here we discuss some properties of the two beer rating datasets that are relevant for our study of herding.</p>     <p>We start by summarizing the size of the datasets in Table&#x00A0;<a class="tbl" href="#tab1">1</a>, which shows that each site contains ratings for hundreds of thousands of beers from tens of thousands of breweries, rated by tens of thousands of users, totaling millions of ratings.</p>     <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">Dataset size.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;"/>        <th style="text-align:right;">BeerAdvocate</th>        <th>RateBeer</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:left;">Breweries</td>        <td style="text-align:right;">16,758</td>        <td>24,189</td>       </tr>       <tr>        <td style="text-align:left;">Beers</td>        <td style="text-align:right;">280,823</td>        <td>442,081</td>       </tr>       <tr>        <td style="text-align:left;">Beers (&#x2265; 5 ratings)</td>        <td style="text-align:right;">96,156</td>        <td>166,043</td>       </tr>       <tr>        <td style="text-align:left;">Beers (&#x2265; 10 ratings)</td>        <td style="text-align:right;">61,193</td>        <td>104,062</td>       </tr>       <tr>        <td style="text-align:left;">Beers (&#x2265; 20 ratings)</td>        <td style="text-align:right;">38,533</td>        <td>60,451</td>       </tr>       <tr>        <td style="text-align:left;">Users</td>        <td style="text-align:right;">153,704</td>        <td>70,174</td>       </tr>       <tr>        <td style="text-align:left;">Users (&#x2265; 10 ratings)</td>        <td style="text-align:right;">48,595</td>        <td>17,744</td>       </tr>       <tr>        <td style="text-align:left;">Users (&#x2265; 100 ratings)</td>        <td style="text-align:right;">14,488</td>        <td>6,419</td>       </tr>       <tr>        <td style="text-align:left;">Ratings</td>        <td style="text-align:right;">8,393,032</td>        <td>7,122,074</td>       </tr>      </tbody>     </table>     </div>     <p>The two sites attract rather different user populations. In particular, BeerAdvocate is mostly frequented by users from the U.S. (74% of users), followed by Canada (2%), with less than 1% of users from any other single country. RateBeer&#x0027;s user base, though also predominantly from the U.S. (38%), is more balanced, with 5% of users from Canada, 4% from England, 2% Poland, 2% from Australia, <em>etc.</em>     </p>     <p>BeerAdvocate&#x0027;s more U.S.centric user base is also reflected in the breweries whose beers are rated on the sites: 44% of all breweries represented on BeerAdvocate are from the U.S., while the fraction is only 29% on RateBeer. Other countries have similar percentages across sites (<em>cf.</em> &#x201C;Unmatched&#x201D; in Table&#x00A0;<a class="tbl" href="#tab4">4</a>). These differences imply that selecting a matched sample of beers rated on both websites cannot possibly reflect the overall distribution of products on both sites equally well, an issue we address in Sec.&#x00A0;<a class="sec" href="#sec-13">4.3</a>.</p>     <p>Fig.&#x00A0;<a class="fig" href="#fig3">3</a>(a) plots the histograms of ratings for both websites. We clearly see that users on BeerAdvocate tend to give higher ratings than users on RateBeer. <a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a> As a side note, we also point out that the rating distributions of Fig.&#x00A0;<a class="fig" href="#fig3">3</a>(a) differ vastly from the bimodal distributions with mostly extremely high or extremely low values that have frequently been observed on other rating websites [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>] and that have been attributed to a &#x201C;brag-and-moan&#x201D; effect. On beer rating websites, ratings seem to be less affected by selection bias due to disappointment or positive surprise. <figure id="fig3">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186160/images/www2018-169-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 3:</span>       <span class="figure-title">Statistics of the two beerrating datasets. Error bars in (b&#x2013;c) capture 95% confidence intervals.</span>      </div>     </figure>     </p>     <p>The histograms of Fig.&#x00A0;<a class="fig" href="#fig3">3</a>(a) pool all ratings from 2001 through August 2017. Next, we group ratings by year and plot the annual mean (Fig.&#x00A0;<a class="fig" href="#fig3">3</a>(b)) and standard deviation (Fig.&#x00A0;<a class="fig" href="#fig3">3</a>(c)). We observe that neither quantity stays constant over time: the mean increases, while the standard deviation decreases, from year to year. Assuming that the inherent quality of beers being rated stays roughly constant, the rising mean may be interpreted as score inflation, while the sinking standard deviation could indicate a consolidating consensus about what should constitute the score of an average beer.</p>     <p>This implies that, in order to compare ratings across sites and time periods, we must account for biases stemming from site conventions (shifted rating histograms) and from a temporal drift in these conventions (rising means and sinking standard deviations). Instead of raw ratings, we therefore consider <em>standardized ratings</em> (also known as <em>z</em>-scores): for each site and each year, we compute the mean and standard deviation over all ratings. We then subtract the mean of year <em>t</em> from all ratings submitted in year <em>t</em> and divide them by the standard deviation of year <em>t</em>, such that each year&#x0027;s set of ratings has mean 0 and standard deviation 1.</p>    </section>   </section>   <section id="sec-10">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Matching products across websites</h2>     </div>    </header>    <p>Our method hinges on a set of products rated on two separate websites. An alignment of products across sites (<em>e.g.</em>, via consistent unique identifiers) is typically not given explicitly; rather, one usually needs to perform the matching oneself heuristically. In this section, we describe our algorithm for achieving a highquality alignment between beers from BeerAdvocate and RateBeer (Sec.&#x00A0;<a class="sec" href="#sec-11">4.1</a>), report basic statistics of the matched sample (Sec.&#x00A0;<a class="sec" href="#sec-12">4.2</a>), and discuss its external and internal validity (Sec.&#x00A0;<a class="sec" href="#sec-13">4.3</a>).</p>    <section id="sec-11">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Matching algorithm</h3>     </div>     </header>     <p>When matching products across websites, we should favor precision over recall: not matching all potentially matchable products simply decreases the sample size and is therefore acceptable (as long as it does not bias the dataset, <em>cf.</em> Sec.&#x00A0;<a class="sec" href="#sec-13">4.3</a>), whereas matching nonidentical products to each other introduces noise into the data. With this in mind, we designed a matching algorithm geared toward precision, potentially at the expense of recall.</p>     <p>We proceed in two phases. First, we align breweries across sites, then we align beers only within breweries; <em>i.e.</em>, we only consider pairs of beers as potential matches if their respective breweries were matched to each other before. The same basic procedure is used both for matching breweries and for matching beers, in each case operating on name strings.</p>     <p>The algorithm starts by representing names as TF-IDF vectors and computes all pairwise cosine similarities. Inverse document frequency (IDF) weighting serves to downweight common terms such as &#x201C;brewery&#x201D;, &#x201C;company&#x201D;, &#x201C;beer&#x201D;, &#x201C;ale&#x201D;, <em>etc.</em> When aligning names from two sets, the number of matches is upperbounded by the size of the smaller set, so we iterate over the smaller set and, for each name, find the optimal match in the larger set. We only keep a match if its cosine similarity is above a threshold <em>&#x03B8;</em> and if the best match has a much higher similarity than the second best match (to rule out ambiguities), by requiring a gap in similarities of at least <em>&#x03B4;</em>. If this greedy procedure pairs the same element from the larger set with more than one element from the smaller set, we discard all these pairs. <a class="fn" href="#fn5" id="foot-fn5"><sup>5</sup></a>     </p>     <p>As mentioned, we use the same procedure for matching breweries and then for matching beers within breweries. When matching breweries, we additionally require an exact match of locations (states for U.S. breweries, and countries for others). When matching beers, we additionally require an exact match in alcohol by volume; also, before computing cosine similarities, we first remove from each beer name all tokens that also appear in the brewery name, as sometimes the name of the beer contains the brewery name in one dataset, but not in the other (<em>e.g.</em>, &#x201C;Ingobr&#x00E4;u Meistersud&#x201D; <em>vs.</em> just &#x201C;Meistersud&#x201D;).</p>    </section>    <section id="sec-12">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Matched dataset</h3>     </div>     </header>     <p>The above algorithm has two parameters, <em>&#x03B8;</em> and <em>&#x03B4;</em>. We find <em>&#x03B8;</em> = 0.8 and <em>&#x03B4;</em> = 0.3 to work well in practice, as shown by an evaluation in which we inspected 500 matched brewery pairs and 500 matched beer pairs and, based on this ground truth, estimate precision as 99.6% for matched breweries (2 of the 500 inspected matches were wrong) and 100% for matched beers.</p>     <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Dataset size after matching.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;"/>        <th colspan="4" style="text-align:center;">Minimum number of ratings per beer</th>       </tr>       <tr>        <th style="text-align:left;"/>        <th style="text-align:right;">0</th>        <th style="text-align:right;">5</th>        <th style="text-align:right;">10</th>        <th>20</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:left;">Breweries</td>        <td style="text-align:right;">6,084</td>        <td style="text-align:right;">2,561</td>        <td style="text-align:right;">1,711</td>        <td>1,079</td>       </tr>       <tr>        <td style="text-align:left;">Beers</td>        <td style="text-align:right;">45,640</td>        <td style="text-align:right;">12,890</td>        <td style="text-align:right;">7,424</td>        <td>4,051</td>       </tr>       <tr>        <td style="text-align:left;">Ratings on BA</td>        <td style="text-align:right;">955,968</td>        <td style="text-align:right;">873,944</td>        <td style="text-align:right;">812,070</td>        <td>732,165</td>       </tr>       <tr>        <td style="text-align:left;">Ratings on RB</td>        <td style="text-align:right;">1,020,638</td>        <td style="text-align:right;">761,496</td>        <td style="text-align:right;">650,642</td>        <td>542,961</td>       </tr>      </tbody>     </table>     </div>     <p>The size of the matched dataset is summarized in Table&#x00A0;<a class="tbl" href="#tab2">2</a>. In our result analysis (Sec.&#x00A0;<a class="sec" href="#sec-14">5</a>), we restrict ourselves to beers with at least a minimum number of ratings, so the table lists sizes for various values of this threshold. Although matching reduces the dataset by a lot, we are still left with tens of thousands of beers from thousands of breweries, with close to a million ratings on each site.</p>     <p>Matching ensures that each remaining product has been rated on each of the two websites. As explained in Sec.&#x00A0;<a class="sec" href="#sec-5">2.1</a> (step&#x00A0;2), each beer falls into one of nine pairedtreatment group s (HH, HM, HL, MH, <em>etc.</em>). Table&#x00A0;<a class="tbl" href="#tab3">3</a> displays the size of all groups (for beers with at least five ratings on each site, as the bulk of our analysis will be conducted on this set). We observe that the groups are rather well balanced &#x201C;out of the box&#x201D; (<em>e.g.</em>, 1,210 beers in HM <em>vs.</em> 1,213 in MH, <em>etc.</em>), even before balancing them explicitly (step&#x00A0;3 of Sec.&#x00A0;<a class="sec" href="#sec-5">2.1</a>).</p>     <div class="table-responsive" id="tab3">     <div class="table-caption">      <span class="table-number">Table 3:</span>      <span class="table-title">Number of beers per pairedtreatment group (Sec. <a class="sec" href="#sec-5">2.1</a>, step 2) after matching, before balancing (Sec.&#x00A0;<a class="sec" href="#sec-5">2.1</a>, step 3).</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:center;"/>        <th style="text-align:center;"/>        <th colspan="3" style="text-align:center;">        <strong>BA</strong>        </th>       </tr>       <tr>        <th style="text-align:center;"/>        <th style="text-align:center;"/>        <th style="text-align:center;">H</th>        <th style="text-align:center;">M</th>        <th>L</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">H</td>        <td style="text-align:center;">585</td>        <td style="text-align:center;">1,213</td>        <td>116</td>       </tr>       <tr>        <td style="text-align:right;"><strong>RB</strong>        <td style="text-align:center;">M</td>        <td style="text-align:center;">1,210</td>        <td style="text-align:center;">6,593</td>        <td>1,242</td>       </tr>       <tr>        <td style="text-align:right;"/>        <td style="text-align:center;">L</td>        <td style="text-align:center;">138</td>        <td style="text-align:center;">1,225</td>        <td>568</td>       </tr>      </tbody>     </table>     </div>     <p>We recomputed and inspected the rating histograms (<em>cf.</em> Fig.&#x00A0;<a class="fig" href="#fig3">3</a>(a)) on the subset of beers in the matched sample only and found them essentially indistinguishable from the full sample shown in Fig.&#x00A0;<a class="fig" href="#fig3">3</a>(a) . This implies that the vastly different rating distributions of the two sites are not caused by users on one of the sites having a systematic preference for rating inherently better or worse beers (<em>e.g.</em>, certain rating sites might see themselves as &#x201C;bashing sites&#x201D;); rather, the difference must stem from different scoring standards.</p>     <p>To make scores comparable across sites, we thus standardize all ratings as described in Sec.&#x00A0;<a class="sec" href="#sec-9">3.2</a>, by subtracting the annual mean and dividing by the annual standard deviation. As seen in Fig.&#x00A0;<a class="fig" href="#fig4">4</a>(a), the two sites&#x2019; rating histograms are entirely overlapping after standardization, so ratings may now be compared across sites. <figure id="fig4">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186160/images/www2018-169-fig4.jpg" class="img-responsive" alt="Figure 4"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 4:</span>       <span class="figure-title">Standardized ratings after matching. Red cross in (b) marks example from Fig.&#x00A0;<a class="fig" href="#fig1">1</a>; gray tones capture number of beers per bin. Although overall rating distributions are identical, many individual beers are rated differently across sites.</span>      </div>     </figure>     </p>     <p>It is important to note that, whereas the distribution of standardized ratings is identical for the two sites (Fig.&#x00A0;<a class="fig" href="#fig4">4</a>(a)), there are numerous individual products with vastly different ratings on BeerAdvocate <em>vs.</em> RateBeer. To emphasize this point, Fig.&#x00A0;<a class="fig" href="#fig4">4</a>(b) contains a scatter plot of ratings on BeerAdvocate <em>vs.</em> ratings on RateBeer, where each beer is summarized by its average standardized rating on each site. The fact that the point cloud disperses widely off the diagonal clearly shows that many beers are perceived differently on the two sites. Viewed this way, the purpose of our natural experiment is to determine how beers such as <em>Lost Rhino Ice Breaker</em> from the introduction wind up in the fringe of the point cloud of Fig.&#x00A0;<a class="fig" href="#fig4">4</a>(b) (where <em>Lost Rhino Ice Breaker</em> is marked as a red cross)&#x2014;by virtue of herding or by sheer good or bad luck.</p>    </section>    <section id="sec-13">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Validity of matched sample</h3>     </div>     </header>     <p>Drawing correct conclusions from our observational study requires the assumptions laid out in Sec.&#x00A0;<a class="sec" href="#sec-6">2.2</a>. The purpose of this section is to show that these assumptions, in particular external and internal validity, are empirically met by the matched beer rating dataset. <strong>External validity.</strong>Favoring precision over recall when matching (Sec.&#x00A0;<a class="sec" href="#sec-11">4.1</a>) comes at the expense of losing many matches in which we are less confident, which may introduce selection bias and can potentially impair the external validity of our results: if the sample we study is fundamentally different from the overall population, our conclusions might not generalize from the former to the latter.</p>     <p>First recall from Sec.&#x00A0;<a class="sec" href="#sec-9">3.2</a> that there are some significant differences between the two sites: BeerAdvocate is more U.S.centric in terms of products and users, and it is also smaller in terms of the number of beers rated (Table&#x00A0;<a class="tbl" href="#tab1">1</a>). Since the number of matched beers is upperbounded by the number of beers in the smaller dataset, the best we could hope to do is match all beers in BeerAdvocate to their corresponding beers in RateBeer. This would preserve the original data distribution in BeerAdvocate and skew RateBeer&#x0027;s distribution to match it. <figure id="fig5">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186160/images/www2018-169-fig5.jpg" class="img-responsive" alt="Figure 5"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 5:</span>       <span class="figure-title">Comparison of three dataset properties before <em>vs.</em> after matching.</span>      </div>     </figure>     </p>     <p>Fig.&#x00A0;<a class="fig" href="#fig5">5</a> and Table&#x00A0;<a class="tbl" href="#tab4">4</a> show that, even though the smaller BeerAdvocate is not a subset of RateBeer, matching still produces a dataset very similar to BeerAdvocate. Fig.&#x00A0;<a class="fig" href="#fig5">5</a> inspects three exemplary properties (mean average beer rating, number of ratings per beer, and number of beers per brewery) of the data before (left box in each pair) <em>vs.</em> after matching (right box in each pair), for both BeerAdvocate (left panel in each figure) and RateBeer (right panel in each figure). We observe that matching does not noticeably alter BeerAdvocate&#x0027;s distributions, whereas RateBeer&#x0027;s do change.</p>     <p>Table&#x00A0;<a class="tbl" href="#tab4">4</a> lists the most common countries of origin for breweries present in each dataset before matching, as well as in the matched dataset. We make two observations. First, the distribution over countries is similar in both datasets even before matching, with the exception that BeerAdvocate contains a much larger fraction of U.S. breweries. Second, matching mimics the distribution of the smaller dataset, BeerAdvocate, more closely than that of RateBeer. We also compared the style distributions before and after matching, with the same result that the matched dataset mirrors BeerAdvocate&#x0027;s distribution closely (in decreasing order of frequency: American IPA 10.8% before, <em>vs.</em> 12.1% after, matching; American Pale Ale 6.2% <em>vs.</em> 6.8%; Saison/Farmhouse Ale 5.0% <em>vs.</em> 5.9%, <em>etc.</em>).</p>     <p>We conclude that our matched sample is unbiased with respect to BeerAdvocate (as explained above, the best we could hope for), such that the conclusions we draw can at the very least be generalized to all of BeerAdvocate. Note that this is a conservative statement; we have seen no explicit indications why our conclusions should not also hold on all of RateBeer.</p>     <div class="table-responsive" id="tab4">     <div class="table-caption">      <span class="table-number">Table 4:</span>      <span class="table-title">Brewery locations before and after matching (Sec. <a class="sec" href="#sec-5">2.1</a>, step 1), ordered by percentage after matching.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;"/>        <th colspan="2" style="text-align:center;">Unmatched</th>        <th>Matched</th>       </tr>       <tr>        <th style="text-align:left;"/>        <th style="text-align:center;">BA</th>        <th style="text-align:center;">RB</th>        <th/>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:left;">United States</td>        <td style="text-align:center;">44.4%</td>        <td style="text-align:center;">28.6%</td>        <td>47.8%</td>       </tr>       <tr>        <td style="text-align:left;">Germany</td>        <td style="text-align:center;">8.5%</td>        <td style="text-align:center;">8.3%</td>        <td>6.4%</td>       </tr>       <tr>        <td style="text-align:left;">England</td>        <td style="text-align:center;">6.1%</td>        <td style="text-align:center;">8.8%</td>        <td>5.8%</td>       </tr>       <tr>        <td style="text-align:left;">Canada</td>        <td style="text-align:center;">5.1%</td>        <td style="text-align:center;">3.7%</td>        <td>4.9%</td>       </tr>       <tr>        <td style="text-align:left;">Italy</td>        <td style="text-align:center;">2.2%</td>        <td style="text-align:center;">4.3%</td>        <td>2.7%</td>       </tr>       <tr>        <td style="text-align:left;">Belgium</td>        <td style="text-align:center;">2.0%</td>        <td style="text-align:center;">1.9%</td>        <td>2.5%</td>       </tr>       <tr>        <td style="text-align:left;">France</td>        <td style="text-align:center;">2.4%</td>        <td style="text-align:center;">3.5%</td>        <td>2.3%</td>       </tr>       <tr>        <td style="text-align:left;">Spain</td>        <td style="text-align:center;">1.9%</td>        <td style="text-align:center;">3.2%</td>        <td>2.3%</td>       </tr>       <tr>        <td style="text-align:left;">Australia</td>        <td style="text-align:center;">2.4%</td>        <td style="text-align:center;">2.3%</td>        <td>2.2%</td>       </tr>       <tr>        <td style="text-align:left;">Netherlands</td>        <td style="text-align:center;">1.5%</td>        <td style="text-align:center;">2.1%</td>        <td>2.1%</td>       </tr>      </tbody>     </table>     </div>     <p>     <strong>Internal validity.</strong>As argued in Sec.&#x00A0;<a class="sec" href="#sec-6">2.2</a>, we need to show that the treatment assignment <em>T</em> (the firstrating a beer receives) is independent of the rating site <em>S</em> and the rated product <em>P</em>. Although, as discussed there, we have <em>T</em>&#x22A5;&#x22A5;<em>S</em> and <em>T</em>&#x22A5;&#x22A5;<em>P</em> by construction, these do not automatically imply <em>T</em>&#x22A5;&#x22A5;(<em>S</em>, <em>P</em>). For instance, it is in principle possible (though not likely) that users on site <em>S</em>     <sub>1</sub> love all pale beers and hate all dark beers, while users on <em>S</em>     <sub>2</sub> love all dark beers and hate all pale beers. This would entail that all pale beers would see both a high treatment (firstrating) and a high outcome (subsequent reviews) on <em>S</em>     <sub>1</sub>; and that all dark beers would see both a high treatment and a high outcome on <em>S</em>     <sub>2</sub>. Here, a correlation between treatment and outcome would not be causal, but due to the confound of sitespecific preferences. We therefore need to check empirically that the distribution of treatment assignments (<em>i.e.</em>, the probability of receiving a higher firstrating) is approximately equal for all combinations of site and product properties. Notice that only properties available <em>before</em> treatment should be taken into account here, as all other properties might be consequences, rather than causes, of the treatment. This precludes us, <em>e.g.</em>, from considering ratings received by the respective beer.</p>     <p>Inspecting treatment probabilities for all beer properties on each site would be elusive, especially given our limited dataset size. But we argue that the most likely confounds would be captured by beer style and producer country: controlling for style also roughly fixes the most salient properties of a beer, such as bitterness, color, alcohol content, <em>etc.</em>; and controlling for producer country accounts for the fact that BeerAdvocate users are more likely American and might therefore be biased toward (or against) American beers.</p>     <p>The numbers are presented in Table&#x00A0;<a class="tbl" href="#tab5">5</a> for the most frequent styles and countries. There is one table per group of interest (HM, ML, HL). For each combination of beer property (style or country) and site, we list the number of beers with the higher treatment on that site and the implied probability of receiving the higher treatment. As there are two treatments in each group, perfect independence would yield probabilities of 50% everywhere.</p>     <p>While achieving such an exact balance is infeasible with our limited dataset, Table&#x00A0;<a class="tbl" href="#tab5">5</a> shows that we come rather close; in particular, we achieve treatment probabilities close to 50% for the most frequent styles and countries (which have the biggest impact).</p>     <p>These numbers mean that our cross-site product matching results in a treatment assignment that is (approximately) independent of site and product properties (<em>cf.</em> Fig.&#x00A0;<a class="fig" href="#fig2">2</a>(c)). Though not randomized by us as the researchers, treatment assignment is mostly haphazard, such that we may indeed speak of a natural experiment.</p>     <div class="table-responsive" id="tab5">     <div class="table-caption">      <span class="table-number">Table 5:</span>      <span class="table-title">Counts (#) and probabilities (Pr) of higher treatment for three pairedtreatment group s, both sites (BA, RB), and top beer styles and brewery countries. Most values being similar for BA and RB supports internal validity of our study (Sec.&#x00A0;<a class="sec" href="#sec-13">4.3</a>).</span>     </div>     <table class="table">      <thead>       <tr>        <th colspan="5" style="text-align:center;">        <strong>HM</strong>        <hr/>        </th>        <th style="text-align:left;"/>        <th colspan="5" style="text-align:center;">        <strong>ML</strong>        <hr/>        </th>        <th style="text-align:left;"/>        <th colspan="5" style="text-align:center;">        <strong>HM</strong>        <hr/>        </th>       </tr>       <tr>        <th style="text-align:left;"/>        <th colspan="2" style="text-align:center;">#(H)<hr/>        </th>        <th colspan="2" style="text-align:center;">Pr(H)<hr/>        </th>        <th style="text-align:left;"/>        <th colspan="2" style="text-align:center;">#(M)<hr/>        </th>        <th colspan="2" style="text-align:center;">Pr(M)<hr/>        </th>        <th style="text-align:center;"/>        <th colspan="2" style="text-align:center;">#(H)<hr/>        </th>        <th colspan="2" style="text-align:center;">Pr(H)<hr/>        </th>        <th/>        <th/>       </tr>       <tr>        <th style="text-align:left;">Style</th>        <th style="text-align:center;">BA</th>        <th style="text-align:center;">RB</th>        <th style="text-align:center;">BA</th>        <th style="text-align:center;">RB</th>        <th style="text-align:left;"/>        <th style="text-align:center;">Style</th>        <th style="text-align:center;">BA</th>        <th style="text-align:center;">RB</th>        <th style="text-align:center;">BA</th>        <th style="text-align:center;">RB</th>        <th style="text-align:left;"/>        <th style="text-align:center;">Style</th>        <th style="text-align:center;">BA</th>        <th style="text-align:center;">RB</th>        <th style="text-align:center;">BA</th>        <th>RB</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:left;">Amer. IPA</td>        <td style="text-align:center;">105</td>        <td style="text-align:center;">88</td>        <td style="text-align:center;">0.54</td>        <td style="text-align:center;">0.46</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. IPA</td>        <td style="text-align:center;">64</td>        <td style="text-align:center;">64</td>        <td style="text-align:center;">0.50</td>        <td style="text-align:center;">0.50</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. IPA</td>        <td style="text-align:center;">7</td>        <td style="text-align:center;">5</td>        <td style="text-align:center;">0.58</td>        <td>0.42</td>       </tr>       <tr>        <td style="text-align:left;">Amer. Double/Imp. IPA</td>        <td style="text-align:center;">100</td>        <td style="text-align:center;">81</td>        <td style="text-align:center;">0.55</td>        <td style="text-align:center;">0.45</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Pale Ale</td>        <td style="text-align:center;">36</td>        <td style="text-align:center;">44</td>        <td style="text-align:center;">0.45</td>        <td style="text-align:center;">0.55</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Double/Imp. IPA</td>        <td style="text-align:center;">8</td>        <td style="text-align:center;">2</td>        <td style="text-align:center;">0.80</td>        <td>0.20</td>       </tr>       <tr>        <td style="text-align:left;">Amer. Pale Ale</td>        <td style="text-align:center;">32</td>        <td style="text-align:center;">32</td>        <td style="text-align:center;">0.50</td>        <td style="text-align:center;">0.50</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Fruit/Vegetable Beer</td>        <td style="text-align:center;">30</td>        <td style="text-align:center;">25</td>        <td style="text-align:center;">0.55</td>        <td style="text-align:center;">0.45</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Pale Ale</td>        <td style="text-align:center;">3</td>        <td style="text-align:center;">3</td>        <td style="text-align:center;">0.50</td>        <td>0.50</td>       </tr>       <tr>        <td style="text-align:left;">Amer. Wild Ale</td>        <td style="text-align:center;">27</td>        <td style="text-align:center;">36</td>        <td style="text-align:center;">0.43</td>        <td style="text-align:center;">0.57</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Amber/Red Ale</td>        <td style="text-align:center;">32</td>        <td style="text-align:center;">20</td>        <td style="text-align:center;">0.61</td>        <td style="text-align:center;">0.39</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Russian Imperial Stout</td>        <td style="text-align:center;">0</td>        <td style="text-align:center;">5</td>        <td style="text-align:center;">0.00</td>        <td>1.00</td>       </tr>       <tr>        <td style="text-align:left;">Saison/Farmhouse Ale</td>        <td style="text-align:center;">33</td>        <td style="text-align:center;">30</td>        <td style="text-align:center;">0.52</td>        <td style="text-align:center;">0.48</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Double/Imp. IPA</td>        <td style="text-align:center;">28</td>        <td style="text-align:center;">18</td>        <td style="text-align:center;">0.61</td>        <td style="text-align:center;">0.39</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Amber/Red Ale</td>        <td style="text-align:center;">3</td>        <td style="text-align:center;">2</td>        <td style="text-align:center;">0.60</td>        <td>0.40</td>       </tr>       <tr>        <td style="text-align:left;">Amer. Double/Imp. Stout</td>        <td style="text-align:center;">22</td>        <td style="text-align:center;">36</td>        <td style="text-align:center;">0.38</td>        <td style="text-align:center;">0.62</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Saison/Farmhouse Ale</td>        <td style="text-align:center;">20</td>        <td style="text-align:center;">26</td>        <td style="text-align:center;">0.44</td>        <td style="text-align:center;">0.56</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Wild Ale</td>        <td style="text-align:center;">4</td>        <td style="text-align:center;">1</td>        <td style="text-align:center;">0.80</td>        <td>0.20</td>       </tr>       <tr>        <td style="text-align:left;">Amer. Black Ale</td>        <td style="text-align:center;">15</td>        <td style="text-align:center;">20</td>        <td style="text-align:center;">0.43</td>        <td style="text-align:center;">0.57</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Blonde Ale</td>        <td style="text-align:center;">28</td>        <td style="text-align:center;">13</td>        <td style="text-align:center;">0.68</td>        <td style="text-align:center;">0.32</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Barleywine</td>        <td style="text-align:center;">2</td>        <td style="text-align:center;">3</td>        <td style="text-align:center;">0.40</td>        <td>0.60</td>       </tr>       <tr>        <td style="text-align:left;">Amer. Porter</td>        <td style="text-align:center;">14</td>        <td style="text-align:center;">18</td>        <td style="text-align:center;">0.44</td>        <td style="text-align:center;">0.56</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Porter</td>        <td style="text-align:center;">14</td>        <td style="text-align:center;">24</td>        <td style="text-align:center;">0.37</td>        <td style="text-align:center;">0.63</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Blonde Ale</td>        <td style="text-align:center;">1</td>        <td style="text-align:center;">3</td>        <td style="text-align:center;">0.25</td>        <td>0.75</td>       </tr>       <tr>        <td style="text-align:left;">Russian Imperial Stout</td>        <td style="text-align:center;">13</td>        <td style="text-align:center;">13</td>        <td style="text-align:center;">0.50</td>        <td style="text-align:center;">0.50</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Pale Wheat Ale</td>        <td style="text-align:center;">18</td>        <td style="text-align:center;">19</td>        <td style="text-align:center;">0.49</td>        <td style="text-align:center;">0.51</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Porter</td>        <td style="text-align:center;">2</td>        <td style="text-align:center;">2</td>        <td style="text-align:center;">0.50</td>        <td>0.50</td>       </tr>       <tr>        <td style="text-align:left;">American Stout</td>        <td style="text-align:center;">10</td>        <td style="text-align:center;">14</td>        <td style="text-align:center;">0.42</td>        <td style="text-align:center;">0.58</td>        <td style="text-align:left;"/>        <td style="text-align:center;">German Pilsener</td>        <td style="text-align:center;">14</td>        <td style="text-align:center;">21</td>        <td style="text-align:center;">0.40</td>        <td style="text-align:center;">0.60</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Amer. Black Ale</td>        <td style="text-align:center;">0</td>        <td style="text-align:center;">4</td>        <td style="text-align:center;">0.00</td>        <td>1.00</td>       </tr>       <tr>        <td style="text-align:left;">Country</td>        <td style="text-align:center;">BA</td>        <td style="text-align:center;">RB</td>        <td style="text-align:center;">BA</td>        <td style="text-align:center;">RB</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Country</td>        <td style="text-align:center;">BA</td>        <td style="text-align:center;">RB</td>        <td style="text-align:center;">BA</td>        <td style="text-align:center;">RB</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Country</td>        <td style="text-align:center;">BA</td>        <td style="text-align:center;">RB</td>        <td style="text-align:center;">BA</td>        <td>RB</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:center;"/>        <td style="text-align:center;"/>        <td style="text-align:center;"/>        <td style="text-align:center;"/>        <td style="text-align:left;"/>        <td style="text-align:center;"/>        <td style="text-align:center;"/>        <td style="text-align:center;"/>        <td style="text-align:center;"/>        <td style="text-align:center;"/>        <td style="text-align:left;"/>        <td style="text-align:center;"/>        <td style="text-align:center;"/>        <td style="text-align:center;"/>        <td style="text-align:center;"/>        <td/>       </tr>       <tr>        <td style="text-align:left;">United States</td>        <td style="text-align:center;">544</td>        <td style="text-align:center;">493</td>        <td style="text-align:center;">0.52</td>        <td style="text-align:center;">0.48</td>        <td style="text-align:left;"/>        <td style="text-align:center;">United States</td>        <td style="text-align:center;">445</td>        <td style="text-align:center;">449</td>        <td style="text-align:center;">0.50</td>        <td style="text-align:center;">0.50</td>        <td style="text-align:left;"/>        <td style="text-align:center;">United States</td>        <td style="text-align:center;">46</td>        <td style="text-align:center;">38</td>        <td style="text-align:center;">0.55</td>        <td>0.45</td>       </tr>       <tr>        <td style="text-align:left;">Canada</td>        <td style="text-align:center;">24</td>        <td style="text-align:center;">37</td>        <td style="text-align:center;">0.39</td>        <td style="text-align:center;">0.61</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Canada</td>        <td style="text-align:center;">84</td>        <td style="text-align:center;">53</td>        <td style="text-align:center;">0.61</td>        <td style="text-align:center;">0.39</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Canada</td>        <td style="text-align:center;">7</td>        <td style="text-align:center;">7</td>        <td style="text-align:center;">0.50</td>        <td>0.50</td>       </tr>       <tr>        <td style="text-align:left;">Belgium</td>        <td style="text-align:center;">30</td>        <td style="text-align:center;">31</td>        <td style="text-align:center;">0.49</td>        <td style="text-align:center;">0.51</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Belgium</td>        <td style="text-align:center;">28</td>        <td style="text-align:center;">36</td>        <td style="text-align:center;">0.44</td>        <td style="text-align:center;">0.56</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Germany</td>        <td style="text-align:center;">3</td>        <td style="text-align:center;">6</td>        <td style="text-align:center;">0.33</td>        <td>0.67</td>       </tr>       <tr>        <td style="text-align:left;">England</td>        <td style="text-align:center;">7</td>        <td style="text-align:center;">13</td>        <td style="text-align:center;">0.35</td>        <td style="text-align:center;">0.65</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Germany</td>        <td style="text-align:center;">20</td>        <td style="text-align:center;">21</td>        <td style="text-align:center;">0.49</td>        <td style="text-align:center;">0.51</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Belgium</td>        <td style="text-align:center;">5</td>        <td style="text-align:center;">2</td>        <td style="text-align:center;">0.71</td>        <td>0.29</td>       </tr>       <tr>        <td style="text-align:left;">Australia</td>        <td style="text-align:center;">4</td>        <td style="text-align:center;">14</td>        <td style="text-align:center;">0.22</td>        <td style="text-align:center;">0.78</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Australia</td>        <td style="text-align:center;">20</td>        <td style="text-align:center;">19</td>        <td style="text-align:center;">0.51</td>        <td style="text-align:center;">0.49</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Australia</td>        <td style="text-align:center;">2</td>        <td style="text-align:center;">4</td>        <td style="text-align:center;">0.33</td>        <td>0.67</td>       </tr>       <tr>        <td style="text-align:left;">Germany</td>        <td style="text-align:center;">10</td>        <td style="text-align:center;">7</td>        <td style="text-align:center;">0.59</td>        <td style="text-align:center;">0.41</td>        <td style="text-align:left;"/>        <td style="text-align:center;">England</td>        <td style="text-align:center;">9</td>        <td style="text-align:center;">19</td>        <td style="text-align:center;">0.32</td>        <td style="text-align:center;">0.68</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Switzerland</td>        <td style="text-align:center;">1</td>        <td style="text-align:center;">2</td>        <td style="text-align:center;">0.33</td>        <td>0.67</td>       </tr>       <tr>        <td style="text-align:left;">Sweden</td>        <td style="text-align:center;">10</td>        <td style="text-align:center;">6</td>        <td style="text-align:center;">0.62</td>        <td style="text-align:center;">0.38</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Netherlands</td>        <td style="text-align:center;">7</td>        <td style="text-align:center;">12</td>        <td style="text-align:center;">0.37</td>        <td style="text-align:center;">0.63</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Denmark</td>        <td style="text-align:center;">0</td>        <td style="text-align:center;">2</td>        <td style="text-align:center;">0.00</td>        <td>1.00</td>       </tr>       <tr>        <td style="text-align:left;">Italy</td>        <td style="text-align:center;">3</td>        <td style="text-align:center;">8</td>        <td style="text-align:center;">0.27</td>        <td style="text-align:center;">0.73</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Italy</td>        <td style="text-align:center;">4</td>        <td style="text-align:center;">11</td>        <td style="text-align:center;">0.27</td>        <td style="text-align:center;">0.73</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Austria</td>        <td style="text-align:center;">1</td>        <td style="text-align:center;">1</td>        <td style="text-align:center;">0.50</td>        <td>0.50</td>       </tr>       <tr>        <td style="text-align:left;">Denmark</td>        <td style="text-align:center;">4</td>        <td style="text-align:center;">7</td>        <td style="text-align:center;">0.36</td>        <td style="text-align:center;">0.64</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Scotland</td>        <td style="text-align:center;">5</td>        <td style="text-align:center;">6</td>        <td style="text-align:center;">0.46</td>        <td style="text-align:center;">0.54</td>        <td style="text-align:left;"/>        <td style="text-align:center;">Netherlands</td>        <td style="text-align:center;">1</td>        <td style="text-align:center;">1</td>        <td style="text-align:center;">0.50</td>        <td>0.50</td>       </tr>       <tr>        <td style="text-align:left;">New Zealand</td>        <td style="text-align:center;">0</td>        <td style="text-align:center;">9</td>        <td style="text-align:center;">0.00</td>        <td style="text-align:center;">1.00</td>        <td style="text-align:left;"/>        <td style="text-align:center;">New Zealand</td>        <td style="text-align:center;">3</td>        <td style="text-align:center;">5</td>        <td style="text-align:center;">0.38</td>        <td style="text-align:center;">0.62</td>        <td style="text-align:left;"/>        <td style="text-align:center;">New Zealand</td>        <td style="text-align:center;">1</td>        <td style="text-align:center;">1</td>        <td style="text-align:center;">0.50</td>        <td>0.50</td>       </tr>      </tbody>     </table>     </div>    </section>   </section>   <section id="sec-14">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Results</h2>     </div>    </header>    <p>Now that we have introduced our matched dataset and established that correlations between first and later ratings are highly likely to be causal, we proceed to analyzing the dataset with respect to such correlations, to estimate the effect of first on later ratings.</p>    <p>After processing the data as described in Sec.&#x00A0;<a class="sec" href="#sec-5">2.1</a> (steps 1&#x2013;4), there are 3 pairedtreatment group s of interest: HL, HM, ML. We estimate the effect of a higher (H for HL/HM; M for ML) <em>vs.</em> a lower (L for HL/ML; M for HM) firstrating separately for each of them.</p>    <p>Recall that each group contains the same beer twice, once on BeerAdvocate, once on RateBeer; and once with a higher, once with a lower, firstrating. As established in Sec.&#x00A0;<a class="sec" href="#sec-13">4.3</a>, on which site a beer receives the higher firstrating is essentially haphazard. Therefore, in the presence of herding, a beer will on average receive higher subsequent ratings on the site on which it happened to receive the higher firstrating, and lower subsequent ratings on the other site. In the absence of herding, subsequent ratings will be indistinguishable between the two sites on average. In other words, we have herding if and only if first and subsequent ratings are correlated. <figure id="fig6">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186160/images/www2018-169-fig6.jpg" class="img-responsive" alt="Figure 6"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 6:</span>      <span class="figure-title">Herding effects in beer ratings; (a&#x2013;b) identical beer receives significantly higher (lower) subsequent ratings if firstrating was higher (lower); (c) herding effects last long: even after 20 or more ratings, product average ratings are significantly higher (lower) for beers with higher (lower) firstrating s. Ratings are standardized; error bars show 95% confidence intervals.</span>     </div>     </figure>    </p>    <p>In this light, Fig.&#x00A0;<a class="fig" href="#fig6">6</a>(a) provides a clear indication of herding. The dark curves in the center correspond to the pairedtreatment group HL. The dark red (green) curve summarizes ratings received on the site with a firstrating of H (L); the horizontal axis shows the rating index <em>i</em> = 1, &#x2026;, 5, and the vertical axis, the <em>i</em>-th standardized rating on the respective site, averaged over all beers in the HL group. The plot includes only beers with at least five ratings, so the same set of beers contributes to all indices <em>i</em>. We also emphasize that the dark red and green curves are computed on exactly the same set of beers, just with a different treatment per curve. Thus, we conclude from Fig.&#x00A0;<a class="fig" href="#fig6">6</a>(a) that the same beer&#x0027;s second rating is about half a standard deviation higher if the firstrating was H, <em>vs.</em> if it was L.</p>    <p>The same effect can be observed for the less extreme pairedtreatment group s (HM and ML; Fig.&#x00A0;<a class="fig" href="#fig6">6</a>(b)), but with less extreme differences, as expected: here, a different firstrating translates into a secondrating difference of about a quarter standard deviation. Fig.&#x00A0;<a class="fig" href="#fig6">6</a>(a&#x2013;b) also show that the impact of herding extends beyond the second rating; the effect size is roughly constant on any of the first five ratings. It is therefore interesting to ask whether the herding effect lingers indefinitely or is ultimately overridden by the inherent quality of the respective beer. To address this question, we consider only beers with a substantial number of ratings (at least 20) and compare their long-term averages (based on all ratings received up until the datasets were crawled) for different firstrating s. The results of this analysis, plotted in Fig.&#x00A0;<a class="fig" href="#fig6">6</a>(c), are clear: even after 20 or more ratings, a high firstrating (H for HL) entails a rating on average 0.28 standard deviations higher than what we would see after a low firstrating (L for HL). The effect is again less extreme for less extreme firstrating differences (HM, ML), but it is still noticeable (and with nonoverlapping 95% confidence intervals).</p>    <p>The plots of Fig.&#x00A0;<a class="fig" href="#fig6">6</a> were computed after aggregating symmetric pairedtreatment group s, such that, <em>e.g.</em>, beers that received H on BeerAdvocate and L on RateBeer were grouped together with beers that received L on BeerAdvocate and H on RateBeer (<em>cf.</em> step&#x00A0;4 in Sec.&#x00A0;<a class="sec" href="#sec-5">2.1</a>). As a sanity check, we also investigate treatment differences in the nonaggregated groups (Table&#x00A0;<a class="tbl" href="#tab6">6</a>), concluding that a higher firstrating entails higher subsequent ratings regardless of the site on which the higher firstrating occurred.</p>    <div class="table-responsive" id="tab6">     <div class="table-caption">     <span class="table-number">Table 6:</span>     <span class="table-title">Standardized 5th rating (with 95% confidence intervals) for disaggregated pairedtreatment group s, <em>i.e.</em>, without step&#x00A0;4 of Sec.&#x00A0;<a class="sec" href="#sec-5">2.1</a>; <em>e.g.</em>, cell (L, H on RB) contains mean 5th rating on site with firstrating L when firstrating H happened on RB.</span>     </div>     <table class="table">      <thead>      <tr>       <th style="text-align:center;"/>       <th style="text-align:center;">H on BA</th>       <th style="text-align:center;">H on RB</th>       <th style="text-align:center;"/>       <th style="text-align:center;"/>       <th style="text-align:center;">H on BA</th>       <th style="text-align:center;">H on RB</th>       <th style="text-align:center;"/>       <th style="text-align:center;"/>       <th style="text-align:center;">M on BA</th>       <th>M on RB</th>      </tr>      </thead>      <tbody>      <tr>       <td style="text-align:center;">H</td>       <td style="text-align:center;">-0.032 [-0.193, 0.123]</td>       <td style="text-align:center;">0.226 [0.045, 0.393]</td>       <td style="text-align:center;"/>       <td style="text-align:center;">H</td>       <td style="text-align:center;">0.270 [0.225, 0.314]</td>       <td style="text-align:center;">0.498 [0.460, 0.542]</td>       <td style="text-align:center;"/>       <td style="text-align:center;">M</td>       <td style="text-align:center;">0.057 [0.006, 0.107]</td>       <td>0.376 [0.334, 0.423]</td>      </tr>      <tr>       <td style="text-align:center;">L</td>       <td style="text-align:center;">-0.392 [-0.572, -0.231]</td>       <td style="text-align:center;">-0.066 [-0.220, 0.099]</td>       <td style="text-align:center;"/>       <td style="text-align:center;">M</td>       <td style="text-align:center;">-0.506 [-0.563, -0.450]</td>       <td style="text-align:center;">-0.229 [-0.279, -0.176]</td>       <td style="text-align:center;"/>       <td style="text-align:center;">L</td>       <td style="text-align:center;">-0.657 [-0.721, -0.596]</td>       <td>-0.414 [-0.467, -0.363]</td>      </tr>     </tbody>     </table>    </div>    <p>Fig.&#x00A0;<a class="fig" href="#fig6">6</a> and Table&#x00A0;<a class="tbl" href="#tab6">6</a> directly capture (standardized) rating scores. Plain scores are, however, not all that matters; rating sites tend to also rely heavily on rankings, <em>e.g.</em>, when making recommendations to users. Therefore, we also repeat our analysis by measuring outcomes in terms of ranks (normalized to lie between 0 and 1), rather than scores, as follows (we explain our setup for the HL group; it is analogous for the other groups). For each rating index <em>i</em> = 1, &#x2026;, 5, we rank all beers in the group by their <em>i</em>-th rating, resulting in one ranking for each of the two sites. Then, we compute, for each beer, its mean rank on the site where it received H as the firstrating, as well as on the site where it received L. Comparing the mean for H with the mean for L, we observe that normalized ranks with respect to second ratings are 61% on average on the H site, and only 43% on the L site. We consider this normalizedrank difference of 18% rather substantial. (Even when considering fifth, rather than second, ratings, we still measure a difference of 10%.)</p>   </section>   <section id="sec-15">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Discussion and related work</h2>     </div>    </header>    <p>     <strong>Summary of results.</strong>Our results show clear evidence of herding in the ratings collected by the two most prominent online beerrating platforms. We find that a very high firstrating leads to the following five ratings being about half a standard deviation higher, compared to a situation in which the exact same beer receives a very low firstrating (Fig.&#x00A0;<a class="fig" href="#fig6">6</a>(a&#x2013;b)). These differences in absolute scores also translate into large differences in ranking positions (18% for the second, 10% for the fifth, rating), which are essential for product recommendations. The problem would be mitigated if the platform managed to swiftly &#x201C;forget&#x201D; the first reviews and to converge to the true, inherent quality of the beer being rated, but we find that this is not the case, with the effects of firstrating s lingering until after the beer has received 20 or more reviews (Fig.&#x00A0;<a class="fig" href="#fig6">6</a>(c)).</p>    <p>Whether the first review is positive or negative might come down to random factors such as if the sun was shining when the first reviewer tasted the beer, if they had a bad stomach, or if they had been in a fight with their husband, which may then kick off a domino effect with potentially severe consequences: since many users rely on rating sites to decide what to buy, randomness among the first reviews can tangibly affect the business of producers. <strong>Implications for ratingsite design.</strong>A simple idea to address this problem would be to hide all reviews of a product as long as it has received less than a minimum number of ratings. If, <em>e.g.</em>, ratings are hidden until there are at least ten of them, this will mean that, effectively, the ten first ratings are independent of one another and not affected by herding. Once the eleventh reviewer arrives, they will see an average rating that reflects the inherent quality of the product much more closely than any one single review. As a consequence, even if the eleventh reviewer is biased by previous ratings, they will be biased by something much less haphazard. Future work should verify this hypothesis in an A/B test. <strong>Community overlap.</strong>We point out that our conclusions hold even when information flows between the two sites via users active on both sites (such users exist in practice): as we focus on products with divergent firstrating s, a surmised dependence between the two sites (with respect to the products we study) would have to be one of deliberate antiherding, which would be hard to explain. <strong>Prior work on herding.</strong>Early work on human herding behavior (primarily from marketing and economics) was inspired by work from biology on the behavior of animal herds [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>], which possibly explains why some of the earliest empirical studies of human herding considered farmers [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>] and investment bankers [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>].</p>    <p>Due to data scarcity, much early work was theoretical [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>], but with the rise of the Web, empirical studies have become more feasible. The strongest evidence, naturally, comes from experimental studies. Prominently, Muchnik <em>et al.</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>] inserted random firstrating s into a newsstory website and studied how users reacted to these treatments. Interestingly, while they found that both up- and down-votes skew later votes, the effects of down-votes were offset by social correction in their case, <em>i.e.</em>, by benign users overcompensating for down-votes with subsequent up-votes. In our case, even if social correction should occur, it certainly does not override the negative influence of haphazard early ratings (Fig.&#x00A0;<a class="fig" href="#fig6">6</a>). A followup experiment [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>] yielded evidence for herding on the social bookmarking site Reddit, but without evidence for social correction.</p>    <p>Experiments are powerful tools, but they are expensive to run and involve random manipulations that raise ethical challenges, which, <em>e.g.</em>, kept Muchnik <em>et al.</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>] from disclosing the site on which they had operated. Simulations [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>] and observational studies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>] can serve as an alternative, but circumventing the problems we have mentioned in the introduction tends to require complex modeling assumptions and ways to control for confounds.</p>    <p>We, on the contrary, propose a methodology based on natural experiments, which, although also observational, eliminates the need for explicitly controlling for confounds by leveraging a situation where treatment assignment is haphazard. Our approach is inspired by the method of <em>double pair comparison</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>], which was first applied to study the effectiveness of car safety belts (a concise summary of the study is given by Rosenbaum [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, Sec.&#x00A0;1.4]). <strong>Applicability of our method.</strong>Being cheap and not interfering with the systems being studied are clear advantages of observational studies, especially because different settings may be affected by herding in different ways (<em>cf.</em> the above case of social correction on news stories [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>] <em>vs.</em> Reddit posts [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>]), such that we should study a variety of cases. Luckily, our method applies very generally (Sec.&#x00A0;<a class="sec" href="#sec-4">2</a>). We simply require a set of products rated on two separate websites and alignable across the two sites. We emphasize again the importance of verifying the validity of each setting before analyzing results. In particular, we need to ascertain that the matched sample of products is unbiased with respect to the set of all samples (external validity), and that matching products across sites indeed results in firstrating s (treatment assignment) being independent of product and site properties (internal validity).</p>    <p>When assessing validity, we are limited to observed product features. In particular, we argued that the style and country of a beer are the primary potential confounds, as they capture most other conceivable confounds, observed or unobserved (Sec.&#x00A0;<a class="sec" href="#sec-13">4.3</a>). Despite this extrinsic argument, we stress that one can never fully rule out unobserved confounds, something researchers should be aware of when applying our method to other datasets. When one does not have overwhelming extrinsic arguments supporting the independence of treatment from product and site properties (internal validity), one may perform a sensitivity analysis [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>] to quantify how strongly the treatment would have to depend on such properties before we would alter our conclusions. <strong>Future work.</strong>We hope that researchers will adopt our method to study herding in further scenarios. We believe that product ratings on Amazon constitute a particularly interesting case, as Amazon has sites in multiple languages (<em>e.g.</em>, Amazon.com, Amazon.de, Amazon.fr), each with an independent rating system, yet covering overlapping subsets of a wide spectrum of products. Also, as each product has a unique Amazonwide identifier, matching is trivial.</p>    <p>Our results raise several interesting questions: Are certain users (<em>e.g.</em>, newcomers) more susceptible to herding than others? Can exposure to haphazard ratings lastingly alter a user&#x0027;s later behavior (rather than only a product&#x0027;s later ratings)? And finally, given ratings for the same product from several websites, can we develop models for combining them into a more truthful aggregate score? <strong>Acknowledgments.</strong>We thank Julian McAuley and Carlos Castillo for thoughtful discussions.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Abhijit&#x00A0;V Banerjee. 1992. A Simple Model of Herd Behavior. <em>      <em>The Quarterly Journal of Economics</em>     </em>107, 3 (1992), 797&#x2013;817.</li>     <li id="BibPLXBIB0002" label="[2]">Judith&#x00A0;A Chevalier and Dina Mayzlin. 2006. The Effect of Word of Mouth on Sales: Online Book Reviews. <em>      <em>Journal of Marketing Research</em>     </em>43, 3 (2006), 345&#x2013;354.</li>     <li id="BibPLXBIB0003" label="[3]">Wenjing Duan, Bin Gu, and Andrew&#x00A0;B Whinston. 2008. Do Online Reviews Matter? An Empirical Investigation of Panel Data. <em>      <em>Decision Support Systems</em>     </em>45, 4 (2008), 1007&#x2013;1016.</li>     <li id="BibPLXBIB0004" label="[4]">Leonard Evans. 1986. Double Pair Comparison: A New Method to Determine How Occupant Characteristics Affect Fatality Risk in Traffic Crashes. <em>      <em>Accident Analysis &#x0026; Prevention</em>     </em>18, 3 (1986), 217&#x2013;227.</li>     <li id="BibPLXBIB0005" label="[5]">Leonard Evans. 1986. The Effectiveness of Safety Belts in Preventing Fatalities. <em>      <em>Accident Analysis &#x0026; Prevention</em>     </em>18, 3 (1986), 229&#x2013;241.</li>     <li id="BibPLXBIB0006" label="[6]">Maria Glenski and Tim Weninger. 2017. Rating Effects on Social News Posts and Comments. <em>      <em>ACM Transactions on Intelligent Systems and Technology</em>     </em>8, 6(2017), 78.</li>     <li id="BibPLXBIB0007" label="[7]">William&#x00A0;D Hamilton. 1971. Geometry for the Selfish Herd. <em>      <em>Journal of Theoretical Biology</em>     </em>31, 2 (1971), 295&#x2013;311.</li>     <li id="BibPLXBIB0008" label="[8]">Nan Hu, Paul&#x00A0;A Pavlou, and Jennifer Zhang. 2006. Can Online Reviews Reveal a Product&#x0027;s True Quality? Empirical Findings and Analytical Modeling of Online Word-of-Mouth Communication. In <em>      <em>Proceedings of the 7th ACM Conference on Electronic Commerce</em>     </em>. 324&#x2013;330.</li>     <li id="BibPLXBIB0009" label="[9]">Nitin Jindal and Bing Liu. 2007. Analyzing and Detecting Review Spam. In <em>      <em>Proceedings of the 7th IEEE International Conference on Data Mining</em>     </em>. 547&#x2013;552.</li>     <li id="BibPLXBIB0010" label="[10]">Young-Jin Lee, Kartik Hosanagar, and Yong Tan. 2015. Do I Follow my Friends or the Crowd? Information Cascades in Online Movie Ratings. <em>      <em>Management Science</em>     </em>61, 9 (2015), 2241&#x2013;2258.</li>     <li id="BibPLXBIB0011" label="[11]">Jure Leskovec and Andrej Krevl. 2016. SNAP Datasets: Stanford Large Network Dataset Collection (2014). <em>      <em><a href="https://http://snap.stanford.edu/data">http://snap.stanford.edu/data</a></em>     </em>(2016).</li>     <li id="BibPLXBIB0012" label="[12]">Julian&#x00A0;J McAuley, Jure Leskovec, and Daniel Jurafsky. 2012. Learning Attitudes and Attributes from Multi-Aspect Reviews. <em>      <em>Proceedings of the 12th IEEE International Conference on Data Mining</em>     </em> (2012), 1020&#x2013;1025.</li>     <li id="BibPLXBIB0013" label="[13]">Lev Muchnik, Sinan Aral, and Sean&#x00A0;J Taylor. 2013. Social Influence Bias: A Randomized Experiment. <em>      <em>Science</em>     </em>341, 6146 (2013), 647&#x2013;651.</li>     <li id="BibPLXBIB0014" label="[14]">Andreas Roider and Andrea Voskort. 2016. Reputational Herding in Financial Markets: A Laboratory Experiment. <em>      <em>Journal of Behavioral Finance</em>     </em>17, 3 (2016), 244&#x2013;266.</li>     <li id="BibPLXBIB0015" label="[15]">Paul&#x00A0;R Rosenbaum. 2010. <em>      <em>Design of Observational Studies</em>     </em>. Springer.</li>     <li id="BibPLXBIB0016" label="[16]">David&#x00A0;S Scharfstein and Jeremy&#x00A0;C Stein. 1990. Herd Behavior and Investment. <em>      <em>The American Economic Review</em>     </em>80, 3 (1990), 465&#x2013;479.</li>     <li id="BibPLXBIB0017" label="[17]">Ting Wang and Dashun Wang. 2014. Why Amazon&#x0027;s Ratings Might Mislead You: The Story of Herding Effects. <em>      <em>Big Data</em>     </em>2, 4 (2014), 196&#x2013;204.</li>     <li id="BibPLXBIB0018" label="[18]">Kislev Yoav and Nira Shchori-Bachrach. 1973. The Process of an Innovation Cycle. <em>      <em>American Journal of Agricultural Economics</em>     </em>55, 1 (1973), 28&#x2013;37.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>The irony of illustrating herding with a lost rhino is incidental.</p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>While <em>X</em>&#x22A5;&#x22A5;(<em>Y</em>, <em>Z</em>) (&#x201C;<em>X</em> is independent of (<em>Y</em>, <em>Z</em>)&#x201D;) implies <em>X</em>&#x22A5;&#x22A5;<em>Y</em> and <em>X</em>&#x22A5;&#x22A5;<em>Z</em>, the statement does not hold in the opposite direction.</p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>Data available upon request. Code: <a class="link-inline force-break"     href="https://github.com/epfl-dlab/when_sheep_shop">https://github.com/epfl-dlab/when_sheep_shop</a>. </p>   <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>We found that the distinct spikes in BeerAdvocate&#x0027;s histogram are caused by reviews that gave the same score to all five aspects (<em>cf.</em> Sec.&#x00A0;<a class="sec" href="#sec-8">3.1</a>) and that tend to be very short or even empty, which seems to indicate that these reviews were entered in a hurry.</p>   <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>Alternatively, we could run a proper matching algorithm, such as the Hungarian algorithm, but as we aim to maximize precision, we opted for first being fully greedy and then generously discarding all potentially bad matches.</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License.<br/>ACM ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186160">https://doi.org/10.1145/3178876.3186160</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
