<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>&#x201C;You are no Jack Kennedy&#x201D;: On Media Selection of Highlights from Presidential Debates</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186142'>https://doi.org/10.1145/3178876.3186142</a> 
 Published in WWW2018 Proceedings Â© 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186142'>https://w3id.org/oa/10.1145/3178876.3186142</a>
</p></div>
<hr>

  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">&#x201C;You are no Jack Kennedy&#x201D;: On Media Selection of Highlights from Presidential Debates</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Chenhao</span>      <span class="surName">Tan</span>,     Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA, <a href="mailto:chenhao@chenhaot.com">chenhao@chenhaot.com</a>     </div>     <div class="author">     <span class="givenName">Hao</span>      <span class="surName">Peng</span>,     Paul G. Allen School of CS&#x0026;E, University of Washington, Seattle, WA, USA, <a href="mailto:hapeng@cs.washington.edu">hapeng@cs.washington.edu</a>     </div>     <div class="author">     <span class="givenName">Noah A.</span>      <span class="surName">Smith</span>,     Paul G. Allen School of CS&#x0026;E, University of Washington, Seattle, WA, USA, <a href="mailto:nasmith@cs.washington.edu">nasmith@cs.washington.edu</a>     </div>               </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3178876.3186142" target="_blank">https://doi.org/10.1145/3178876.3186142</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Political speeches and debates play an important role in shaping the images of politicians, and the public often relies on media outlets to select bits of political communication from a large pool of utterances. It is an important research question to understand what factors impact this selection process.</small>     </p>     <p>     <small>To quantitatively explore the selection process, we build a three-decade dataset of presidential debate transcripts and post-debate coverage. We first examine the effect of wording and propose a binary classification framework that controls for both the speaker and the debate situation. We find that crowdworkers can only achieve an accuracy of 60% in this task, indicating that media choices are not entirely obvious. Our classifiers outperform crowdworkers on average, mainly in primary debates. We also compare important factors from crowdworkers&#x2019; free-form explanations with those from data-driven methods and find interesting differences. Few crowdworkers mentioned that &#x201C;context matters&#x201D;, whereas our data show that well-quoted sentences are more distinct from the previous utterance by the same speaker than less-quoted sentences. Finally, we examine the aggregate effect of media preferences towards different wordings to understand the extent of fragmentation among media outlets. By analyzing a bipartite graph built from quoting behavior in our data, we observe a decreasing trend in bipartisan coverage.</small>     </p>    </div>    <div class="CCSconcepts">     <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Applied computing </strong>&#x2192; <strong>Law, social and behavioral sciences;</strong></small> </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>media bias</small>, </span>     <span class="keyword">      <small> presidential debates</small>, </span>     <span class="keyword">      <small> quotations</small>, </span>     <span class="keyword">      <small> wording</small>, </span>     <span class="keyword">      <small> conversations</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Chenhao Tan, Hao Peng, and Noah A. Smith. 2018. &#x201C;You are no Jack Kennedy&#x201D;: On Media Selection of Highlights from Presidential Debates. In <em>WWW 2018: The 2018 Web Conference,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 11 Pages. <a href="https://doi.org/10.1145/3178876.3186142" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3178876.3186142</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>Televised public debates have become a focal point of election campaigns [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>]. A famous example is from the 1988 U.S. vice presidential debate. After Dan Quayle compared himself to John F. Kennedy, Lloyd Bentsen dismissively replied, &#x201C;you are no Jack Kennedy&#x201D;. This moment received wide post-debate coverage, and even pervades later debates and popular parodies.<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> We refer to moments that are frequently quoted by media outlets as <em>highlights</em>. Media-selected highlights in post-debate coverage shape how the public interprets election debates, because these highlights may be the only debate content consumed by many voters [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>]. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186142/images/www2018-151-fig1.svg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Between the two bold sentences from Bernie Sanders from neighboring turns in the 2016 Democratic primary debates, the first sentence was quoted 23 times in newspapers within a week after the debate, while the second one was not quoted at all in our data. Yet in our experiments, 3 out of 5 humans thought the second one was quoted more.</span>     </div>     </figure>    </p>    <p>However, most highlights that media select are not as exceptional as &#x201C;you are no Jack Kennedy&#x201D;, and it remains unclear what factors determine media selection. Consider the example in Figure&#x00A0;<a class="fig" href="#fig1">1</a>. It was not obvious to participants in our experiments which of the two passages from Sanders was a highlight. Even knowing that the first one was highlighted, we can propose multiple plausible explanations for this choice of the media. It could be the catchiness of &#x201C;casino capitalist&#x201D;, or the parallel structure of &#x201C;so few have so much&#x201D; and &#x201C;so many have so little&#x201D;. It may also relate to the conversational dynamics (e.g., Clinton&#x0027;s agreement about inequality) or non-textual factors such as the media&#x0027;s political leanings.</p>    <p>Some qualitative studies have investigated the effect of language-related factors in how the media select highlights [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>]. For instance, to explain the popularity of &#x201C;you are no Jack Kennedy&#x201D;, Clayman [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>] suggests three important factors: 1) <em>narrative relevance</em> (how well a moment fits in a news story); 2) <em>conspicuousness</em> (how much a moment stands out in a debate); 3) <em>extractability</em> (how self-contained a moment is). However, it is nontrivial to computationally characterize these qualitative factors, and their predictive power remains unknown. What is also missing in the existing literature is an understanding of how consumers of news coverage, i.e., the public, interpret media outlets&#x2019; selection of highlights.</p>    <p>Moreover, media selection of highlights holds promise for understanding media bias and polarization. Existing studies have shown that non-textual factors such as the media&#x0027;s preferences and biases can affect the selection of highlights [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>]. In particular, Niculae et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>] demonstrate implicit structure in the media (e.g., international vs. domestic) by analyzing the patterns in quotes of President Barack Obama. Since televised presidential debates have been happening for decades, analysis of debate coverage can shed light on the evolution of media preferences over time.</p>    <p>To quantitatively investigate these questions, we collect American presidential debate transcripts, including both general debates (the debates between general election candidates after primary elections) and primary debates (the earlier, within-party debates in primary elections), and post-debate coverage in newspapers (details in &#x00A7;<a class="sec" href="#sec-5">2</a>). Our dataset spans more than three decades.</p>    <p>     <strong>The present work: the effect of wording on media choices (&#x00A7;<a class="sec" href="#sec-6">3</a>).</strong>The first thrust of this paper investigates the effect of wording on media choices and examines whether the public understands these choices. To do that, we propose a binary classification framework, where a well-quoted sentence (highlight) is paired with a sentence that is not a highlight, controlling for the speaker and the debate situation. The task is to identify which one was quoted more. Using this classification framework, we investigate how well humans and machine-learned classifiers can predict media choices and what the distinguishing textual factors are.</p>    <p>We find that media choices in the selection of highlights are not entirely obvious to humans. As a proxy for the general public, we request Mechanical Turk workers to perform the classification task and explain what factors they use in making predictions. Although they are able to identify some textual signals and outperform random chance (50%), they only achieve an average accuracy of 60%.</p>    <p>Meanwhile, there seem to exist more signals in the wording that are not salient to untrained humans. With carefully-designed features that build on past qualitative studies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>], our classifiers achieve an accuracy of 66%. This result indicates that textual factors can predict media choices to a greater extent than average human performance suggests. In fact, the main performance gap comes from primary debates. One possible explanation for the gap in human performance between general debates and primary debates is the amount of past exposure: primary debates receive less media coverage than general debates and humans may have weaker memories of primary debate highlights.</p>    <p>We also observe interesting similarities and differences when comparing distinguishing factors that humans mentioned with those identified by data-driven methods. For instance, negativity is considered important in both approaches. However, the two approaches view conversational context differently. Only 3% of human responses mention that context matters, while our models suggest that it is a significant factor: highlights tend to be more different from the speaker&#x0027;s previous utterance, and are more likely to be picked up in later utterances.</p>    <p>     <strong>The present work: quoting patterns over time (&#x00A7;<a class="sec" href="#sec-11">4</a>).</strong>The second thrust of this paper examines the media&#x0027;s own preferences and biases in selecting highlights over time. Instead of viewing all media outlets as a uniform body, we take advantage of the longitudinal nature of our data and study whether the news media have become more fragmented over time. Using a bag-of-sentences approach, we construct a bipartite graph over media outlets and the sentences they quoted. Consistent with existing studies on polarization [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>], we observe a decreasing trend in bipartisan coverage in general elections, where a clear two-party structure exists. When we investigate the similarity between media outlets without partisan assumptions, we find an increasing trend in the tightness of local clustering, but do not observe that media outlets are becoming less similar to each other over time on average. <figure id="fig2">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186142/images/www2018-151-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 2:</span>      <span class="figure-title">In Figure&#x00A0;2a, media outlets are sorted by total number of quotes, and there is a heavy tail. Figure&#x00A0;2b shows that an increasing fraction of sentences in the debates are (partially) quoted by the media over time. Figure&#x00A0;2c indicates that an increasing fraction of texts in news articles are direct quotes from the debates. Figure&#x00A0;2d shows that more quotes are from the beginning of a debate. Throughout the paper, error bars represent standard error, dashed lines show the best linear fit and * in a legend indicates that the linear coefficient is statistically significantly different from 0 with <em>p</em> < 0.05.</span>     </div>     </figure>    </p>   </section>   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> An Overview of the Dataset</h2>     </div>    </header>    <p>Our dataset consists of two parts: debate transcripts and post-debate news coverage. We extract transcripts from general debates since 1960 and primary debates since the 2000 presidential election from the <em>American Presidency Project</em>.<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a> Throughout this work, we define a <em>turn</em> as an uninterrupted utterance by a single speaker.</p>    <p>In order to collect post-debate news coverage, we use LexisNexis Academic<a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a> to search all newspapers within seven days after each debate. As LexisNexis indexes newspapers since 1980, we study media highlights of presidential debates from 1980 to 2016. To achieve high recall, we use debate type (&#x201C;presidential&#x201D;, &#x201C;vice&#x201D;, &#x201C;democratic&#x201D; and &#x201C;republican&#x201D;) and the word &#x201C;debate&#x201D; as the query. Although newspapers are a subset of news coverage, they comprise a long-standing and often-studied segment of the media and are highly amenable to replication studies. We leave exploration of additional media sources to future work.</p>    <p>Inspired by existing studies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0047">47</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0052">52</a>], we define &#x201C;highlights&#x201D; based on quotes in news articles that directly come from the debates. In this work, we differentiate quotes from quotations. We refer to any texts in news articles that are enclosed in quotation marks as <em>quotations</em>, and <em>quotes</em> are a subset of quotations that can be matched to a turn at a debate. We determine whether a quotation matches a turn in the presidential debate based on word overlap and fuzzy matching. The extraction process produces pairs of quotes and quoted sentences from the corresponding debate. We will present the formal definition of highlights in &#x00A7;<a class="sec" href="#sec-7">3.1</a>. Our dataset and supplementary material are available at <a class="link-inline force-break"     href="https://chenhaot.com/papers/debate-quotes.html">https://chenhaot.com/papers/debate-quotes.html</a>. </p>    <p>Table&#x00A0;<a class="tbl" href="#tab1">1</a> shows overall statistics of our dataset. We next discuss basic properties of our dataset. In particular, we observe an increasing trend of news media quoting presidential debate moments.</p>    <p>     <strong>A diverse set of newspapers (Figure&#x00A0;2a).</strong>It is important to point out that there are more newspapers over time in our dataset, partly because more media outlets began to quote presidential debates and partly because LexisNexis gradually improves their collection of newspapers. Only four newspapers quoted general debates in 1980; 334 newspapers did in 2016. There are around 700 unique newspapers in total and the top 10% of the newspapers in quoting debates account for 72% of all the quotes. The <em>New York Times</em> and <em>Washington Post</em> are consistently the top newspapers with the most quotes since 1980. We also have small newspapers (e.g., <em>Rhode Island Lawyers Weekly</em>) and international newspapers (e.g., <em>The Guardian</em>).</p>    <div class="table-responsive" id="tab1">     <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Dataset statistics. The last three columns show the average number of sentences, the average number of tokens, and the average number of quotes per debate, respectively.</span>     </div>     <table class="table">     <thead>      <tr>       <th style="text-align:left;">debate type</th>       <th style="text-align:right;">#debates</th>       <th style="text-align:left;">avg. #sent&#x0027;s</th>       <th style="text-align:left;">avg. #tokens</th>       <th style="text-align:left;">avg. #quotes</th>      </tr>      </thead> 					 <tbody> 					 <tr>       <td style="text-align:left;">general</td>       <td style="text-align:right;">26</td>       <td style="text-align:left;">1064.9</td>       <td style="text-align:left;">16278.0</td>       <td style="text-align:left;">944.2</td>      </tr>      <tr>       <td style="text-align:left;">vice</td>       <td style="text-align:right;">9</td>       <td style="text-align:left;">1018.2</td>       <td style="text-align:left;">15974.0</td>       <td style="text-align:left;">618.4</td>      </tr>      <tr>       <td style="text-align:left;">Democratic</td>       <td style="text-align:right;">38</td>       <td style="text-align:left;">1070.6</td>       <td style="text-align:left;">16028.3</td>       <td style="text-align:left;">330.7</td>      </tr>      <tr>       <td style="text-align:left;">Republican</td>       <td style="text-align:right;">59</td>       <td style="text-align:left;">1270.8</td>       <td style="text-align:left;">17781.1</td>       <td style="text-align:left;">369.1</td>      </tr>     </tbody>     </table>    </div>    <p>     <strong>An increasing trend of quoting (Figure&#x00A0;2b and Figure&#x00A0;2c).</strong>Since there are more media outlets over time, it is expected that an increasing fraction of sentences in the debates are quoted in the news media. In comparison, general debates are quoted much more than primary debates. But it is unexpected that the fraction of texts that are direct quotes in news articles is also growing over time, as we observe. This suggests that directly quoting the candidates is an increasingly common way to cover debates.</p>    <p>     <strong>More quotes are from the beginning of a debate (Figure&#x00A0;2d).</strong>Later turns in a debate are less likely to be quoted in the media. This decreasing likelihood is robust across different types of debates and echoes findings on movie quotes [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>].</p>   </section>   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> The Effect of Wording on Media Choices</h2>     </div>    </header>    <p>We study how textual factors associate with media selection of highlights from presidential debates for three reasons. First, media-selected highlights are the only debate content consumed by voters who do not watch the debate and hence rely on post-debate coverage. How well the public understands media selection of highlights is worth studying because the public uses this understanding to interpret news coverage. Second, debating candidates cannot control their popularity or the news media&#x0027;s political preferences, but they can always choose the wording when they seek to deliver a message. Understanding the effects of wording can thus inform political communication. Third, it is valuable to know the extent to which we are able to predict media choices using <em>only</em> textual information&#x2014;<em>although of course textual information alone may not fully predict media choices</em>.</p>    <p>To study the effect of wording on media choices, we propose an experimental framework that controls for the speaker and the debate situation and formulate a binary classification task (&#x00A7;<a class="sec" href="#sec-7">3.1</a>). We then study the public understanding of media choices by evaluating human performance on this task and analyzing free-form explanations in human surveys (&#x00A7;<a class="sec" href="#sec-8">3.2</a>). We further build on existing theories and develop quantitative features for data-driven classifiers (&#x00A7;<a class="sec" href="#sec-9">3.3</a>), and examine their prediction performance in &#x00A7;<a class="sec" href="#sec-10">3.4</a>.</p>    <section id="sec-7">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Experimental Framework</h3>     </div>     </header>     <p>To investigate how textual factors associate with media selection of highlights from presidential debates, we need to control for other confounding factors such as who the speaker is and what state the debate is in. Inspired by &#x201C;natural experiments&#x201D; and previous studies about the effect of wording on message sharing, memorability, and persuasion [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0054">54</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0055">55</a>], we propose a classification task that asks humans and machines to decide which sentence was quoted more in the news media between two &#x201C;similar&#x201D; sentences.</p>     <p>     <strong>Binary classification framework.</strong>To formally define highlights, we use a sentence as the basic unit of analysis. In our natural experiment framework, we find a matching &#x201C;negative&#x201D; sentence for each media-selected highlight and evaluate whether humans or machines can tell the highlighted one from the not-highlighted one in a pair. Because debating candidates have varying popularity and the debate progresses with different levels of importance (see Figure&#x00A0;2d), we match each highlight with a not-highlighted sentence of similar length within three turns by the same speaker.<a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a>     </p>     <p>We consider a sentence <em>highlighted</em> if it was among the most quoted <span class="inline-equation"><span class="tex">$t\%$</span>     </span> sentences from the corresponding debate. We opted for this instead of absolute-count thresholding because the number of quotes increases over time (see Figure&#x00A0;2b). We experiment with <em>t</em> = 1, 2, &#x2026;, 10. The results are robust across choices of <em>t</em>, and we thus report only the results for <em>t</em> = 10 (except for overall accuracy).</p>     <p>Following the above definition, we extract &#x223C; 14K pairs of sentences from all the debates. For a pair of sentences, we randomize the order and predict whether the first one was highlighted. A random guess gives an accuracy of 50%. We randomly select 80% of our data for training and hold out the other 20% for testing. To build machine learning classifiers in &#x00A7;<a class="sec" href="#sec-10">3.4</a>, we construct a vector representation of each pair by extracting features from each sentence and take the difference between them. We use logistic regression with &#x2113;<sub>2</sub>-regularization. This approach is equivalent to a linear framework for the ranking task within a pair [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>]. We grid search the best &#x2113;<sub>2</sub> coefficient based on five-fold cross-validated accuracy on the training set over <span class="inline-equation"><span class="tex">$\bigl \lbrace 2^x\bigr \rbrace$</span>     </span>, where <em>x</em> ranges over 20 values evenly spaced between &#x2013;8 and 1.</p>     <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Top factors in human surveys and the percentage of humans that mentioned them.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">category</th>        <th style="text-align:left;">% humans</th>       </tr>       <tr>        <th style="text-align:left;">circular (sound bite, newsworthy)</th>        <th style="text-align:left;">30.0</th>       </tr>       </thead> 					 <tbody> 						<tr>        <td style="text-align:left;">provocative, sensational</td>        <td style="text-align:left;">25.5</td>       </tr>       <tr>        <td style="text-align:left;">surprising, funny</td>        <td style="text-align:left;">17.0</td>       </tr>       <tr>        <td style="text-align:left;">issues, informative</td>        <td style="text-align:left;">16.0</td>       </tr>       <tr>        <td style="text-align:left;">controversial</td>        <td style="text-align:left;">15.0</td>       </tr>       <tr>        <td style="text-align:left;">memory, past exposure</td>        <td style="text-align:left;">12.0</td>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Human Interpretation of Media Choices</h3>     </div>     </header>     <p>Using the above classification framework, we first examine the public understanding of how the news media select highlights. We recruit 200 U.S.-based Mechanical Turk workers as a sample of untrained humans (the public) to perform the prediction task on randomly sampled pairs from the held-out set. In addition, we ask our participants to explain the important factors that they use to make predictions in free-form responses.</p>     <p>Specifically, we request each participant to label 25 pairs and finish an exit survey to explain what factors they used to make predictions as well as their experience of watching debates and their political ideology. For a pair, we show the highlighted sentence, the not-highlighted sentence, and a few surrounding sentences<a class="fn" href="#fn5" id="foot-fn5"><sup>5</sup></a> in the order they occurred in the debate and ask the participants to guess which one was quoted more in the news media. To make sure that they understand the task, we prepare three training pairs and require a comprehension quiz before they start. We also provide a bonus for each correct guess to incentivize participants to try their best. Further details of the human experiments are in the appendix.</p>     <p>     <strong>Media choices are not obvious to the public.</strong>The average human accuracy is 60% and Fleiss&#x2019; <em>&#x03BA;</em> between human labels is 0.2, indicating slight agreement.<a class="fn" href="#fn6" id="foot-fn6"><sup>6</sup></a>These observations suggest that media choices are not obvious to humans, at least based on textual content. One plausible explanation is that the textual information is insufficient to explain media choices: media choices are influenced by external factors such as statements made outside presidential debates and public opinion shifts. However, as we will show later, there seem to exist signals in the wording that are not salient to untrained humans. Another more pessimistic explanation is that humans have a limited understanding of how the news media select highlights.</p>     <p>     <strong>Important factors in human surveys.</strong> To examine the important factors from the perspective of humans, we categorize free-form explanations in human surveys and present the top factors in Table&#x00A0;<a class="tbl" href="#tab2">2</a>. The most common factors cited are circular; i.e., 30% of the participants mentioned that they made decisions based on which one is newsworthy or which one makes a good sound bite. This suggests that it is nontrivial for humans to reason about media selection of highlights.</p>     <p>Among the next five most frequently mentioned categories, participants mentioned <em>sensational</em> (emotional, negative, shocking, etc.) and <em>surprising or funny</em>. Most of these factors are difficult to operationalize computationally. Interestingly, <em>memory or past exposure</em> was explicitly mentioned by 12% of the participants, indicating that humans may predict media choices even less accurately without unavoidable media exposure.</p>     <p>These top factors do not directly align with existing qualitative studies. For instance, Clayman [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>], the most relevant work, points out three important factors: 1) <em>narrative relevance</em> (how well a moment fits in a news story); 2) <em>conspicuousness</em> (how much a moment stands out in a debate); 3) <em>extractability</em> (how self-contained a moment is). It is unclear how to map the factors that our participants mentioned to these three.</p>     <p>Notably, only 3% of the participants mentioned that context in which a sentence occurred matters, while an equal number of people brought up appealing to liberal voters as a criterion (none discussed the other direction). Extractability in Clayman [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>], or &#x201C;can be taken out of context&#x201D; was viewed important by 4% of the participants. However, &#x201C;potential to be twisted&#x201D;, a slightly different but more malicious interpretation, was explicitly mentioned by 6.5% of the participants. These observations indicate a negative attitude toward the news media, or at least some skepticism about their role in American politics.</p>     <div class="table-responsive" id="tab3">     <div class="table-caption">      <span class="table-number">Table 3:</span>      <span class="table-title">Testing results of sentence-alone features. Upward arrows indicate that highlighted sentences have larger scores in that feature, while downward arrows suggest the other way around (&#x2191;&#x2191;&#x2191;&#x2191;: <em>p</em> < 0.0001, &#x2191;&#x2191;&#x2191;: <em>p</em> < 0.001, &#x2191;&#x2191;: <em>p</em> < 0.01, &#x2191;: <em>p</em> < 0.05, the same for downward arrows; <em>p</em> refers to the <em>p</em>-value after the Bonferroni correction).</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">Feature set</th>        <th style="text-align:left;">Related theories/intuitions and brief description</th>        <th colspan="2" style="text-align:center;">Significance</th>       </tr> 						</thead> 						<tbody> 						<tr>        <td style="text-align:left;">Informative-ness</td>        <td style="text-align:left;">We use length as a proxy of informativeness. Longer sentences are more likely to be highlighted</td>        <td style="text-align:left;">length</td>        <td style="text-align:left;">&#x2191;&#x2191;&#x2191;&#x2191;</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">despite our control on length as discussed in &#x00A7;<a class="sec" href="#sec-7">3.1</a>. This echoes findings in Tan et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0054">54</a>], ,<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0055">55</a>].</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;">Emotions</td>        <td style="text-align:left;">We consider positive and negative words in Pennebaker et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0040">40</a>]. Highlighted sentences use</td>        <td style="text-align:left;">posemo</td>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">significantly more negative words, while there is no difference in positive words. This is consistent</td>        <td style="text-align:left;">negemo</td>        <td style="text-align:left;">&#x2191;&#x2191;&#x2191;&#x2191;</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">with negativity bias [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0044">44</a>] and the negativity found in the news media [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0018">18</a>].</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;">Contrast</td>        <td style="text-align:left;">We use negations and negative conjunctions (e.g., <em>not, but, although</em>) to capture contrast. Our result</td>        <td style="text-align:left;">negation</td>        <td style="text-align:left;">&#x2191;&#x2191;&#x2191;&#x2191;</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">echoes Atkinson [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0001">1</a>], which demonstrates the importance of contrast.</td>        <td style="text-align:left;">negative conj.</td>        <td style="text-align:left;">&#x2191;&#x2191;&#x2191;&#x2191;</td>       </tr>       <tr>        <td style="text-align:left;">Personal pronouns</td>        <td style="text-align:left;">In general, highlighted sentences use more personal pronouns except first person plural and third</td>        <td style="text-align:left;">i, you, she, he</td>        <td style="text-align:left;">&#x2191;&#x2191;&#x2191;&#x2191;</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">person plural. One explanation for the contrast between <em>I</em>and <em>we</em> is that media outlets prefer</td>        <td style="text-align:left;">they</td>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">statements about candidates themselves to unifying statements using <em>we</em>.</td>        <td style="text-align:left;">we</td>        <td style="text-align:left;">&#x2193;&#x2193;&#x2193;&#x2193;</td>       </tr>       <tr>        <td style="text-align:left;">Uncertainty/ subjectivity</td>        <td style="text-align:left;">Hedging is a common way to express uncertainty [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0030">30</a>] and we use a dictionary from</td>        <td style="text-align:left;">hedges</td>        <td style="text-align:left;">&#x2191;&#x2191;&#x2191;&#x2191;</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">Tan and Lee [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0053">53</a>]. In the debate context, hedges may also represent subjectivity.</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;">Strong emphasis</td>        <td style="text-align:left;">Superlatives represent the extreme form of an adjective or an adverb and can be used to put</td>        <td style="text-align:left;">superlatives</td>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">emphasis on a statement. Surprisingly, highlighted sentences do not use more superlatives.</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;">Generality</td>        <td style="text-align:left;">We count indefinite articles to measure generality. Our findings are consistent with</td>        <td style="text-align:left;">indef. articles</td>        <td style="text-align:left;">&#x2191;&#x2191;&#x2191;</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">Danescu-Niculescu-Mizil et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0013">13</a>], Shahaf et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0045">45</a>], Tan et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0054">54</a>].</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;">Language model</td>        <td style="text-align:left;">To capture surprise or conspicuousness, we compute language model scores based on NYT texts and</td>        <td style="text-align:left;">unigram</td>        <td style="text-align:left;">&#x2191;&#x2191;</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">part-of-speech (POS) tags in the WSJ portion of Penn Treebank. However, the only significant feature</td>        <td style="text-align:left;">bi-, trigram</td>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">is that highlighted sentences are more similar to NYT texts in unigram usage. This finding is</td>        <td style="text-align:left;">POS {1, 2, 3}-gram</td>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">consistent with message sharing [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0054">54</a>] but is different from memorable movie quotes [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0013">13</a>].</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;">Parallelism</td>        <td style="text-align:left;">Using parallel sentence structure is a rhetorical technique, e.g, the first sentence in Table&#x00A0;<a class="fig" href="#fig1">1</a> and &#x201C;I&#x0027;ve</td>        <td style="text-align:left;">parallelism</td>        <td style="text-align:left;">&#x2191;</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">never wilted in my life, and I&#x0027;ve never wavered in my life&#x201D;. We use average longest common</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">sequences between sub-sentences to measure it [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0048">48</a>].</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec-9">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> Quantitative Features</h3>     </div>     </header>     <p>Building on the above human intuitions and existing studies, we develop two sets of features: sentence-alone features, and conversation-flow features that attempt to capture conversational dynamics. In this section, we use training data to identify important features that distinguish highlights from non-highlights, and compare the signals from data-driven methods with the factors from humans&#x2019; free-form explanations.</p>     <p>In addition to these two sets of features, we will employ bag-of-words features as a strong baseline in &#x00A7;<a class="sec" href="#sec-10">3.4</a>, i.e., unigrams and bigrams that occur at least 5 times in the training set.</p>     <p>     <strong>Sentence-alone features.</strong>We first examine features that do not rely on any contextual information in the debates and can be extracted from a sentence alone. We evaluate whether highlighted sentences are significantly different from not-highlighted sentences in each feature. Specifically, for each feature, we compute the feature values for both highlighted and not-highlighted sentences and conduct one-sided paired <em>t</em>-tests with the Bonferroni correction [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>]. Table&#x00A0;<a class="tbl" href="#tab3">3</a> presents intuitions and theories for each feature set, including related work. We present the full computational details in the appendix.</p>     <p>By comparing results in Table&#x00A0;<a class="tbl" href="#tab3">3</a> with previously discussed factors from human surveys, we find that the top factors in human surveys also tend to be statistically significant signals from data-driven methods, such as length (informative), and negative emotions (sensational). But this is not always the case, e.g., positive emotions and strong emphasis were not statistically significant signals. Meanwhile, signals such as personal pronouns, hedges, and language model features arise from data-driven methods, but humans may not pay as much attention to them. A complete comparison between computational features and human factors would require operationalizing controversiality, sensationalism, humor, etc.; we leave this to future work.</p>     <p>     <strong>Conversation-flow features.</strong>Although only a handful of participants in our human experiment mentioned that context matters, conversational dynamics in the debates may contribute to the selection of highlights [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0058">58</a>]. We propose a novel set of conversation-flow features and indeed observe intriguing conversational dynamics around the highlights.</p>     <p>In order to capture the local context of a sentence (<em>s</em>), we compare the sentence with its neighboring turns. We use a window <em>w</em> and denote the content words in the next <em>w</em> turns by the same speaker as <span class="inline-equation"><span class="tex">$\operatorname{Words}^{\mathrm{post}}_{\mathrm{self}}(w)$</span>     </span>, the content words in the previous <em>w</em> turns by the same speaker as <span class="inline-equation"><span class="tex">$\operatorname{Words}^{\mathrm{prev}}_\mathrm{self}(w)$</span>     </span>. Similarly, we extract <span class="inline-equation"><span class="tex">$\operatorname{Words}^{\mathrm{post}}_\mathrm{other}(w)$</span>     </span> and <span class="inline-equation"><span class="tex">$\operatorname{Words}^{\mathrm{prev}}_\mathrm{other}(w)$</span>     </span> for other speakers. We compute Jaccard similarity between the sentence (<span class="inline-equation"><span class="tex">$\operatorname{Words}_s$</span>     </span>) and its neighboring turns. For instance, <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\[ \operatorname{Jaccard}^{\mathrm{post}}_{\mathrm{other}}(5)= \frac{\vert \operatorname{Words}_s \cap \operatorname{Words}^{\mathrm{post}}_{\mathrm{other}}(5) \vert }{\vert \operatorname{Words}_s \cup \operatorname{Words}^{\mathrm{post}}_{\mathrm{other}}(5) \vert } \] </span>       <br/>      </div>     </div> measures the similarity between the sentence and the 5 turns by other speakers after the sentence. <figure id="fig3">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186142/images/www2018-151-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 3:</span>       <span class="figure-title">Figure&#x00A0;3a and Figure&#x00A0;3b present conversation-flow features that are based on Jaccard similarity between a sentence and its neighboring turns (negative windows for previous turns, positive windows for later turns, error bars are tiny). In Figure&#x00A0;3a, a kink exists around 0 in similarity to turns by the same speaker, while in Figure&#x00A0;3b, highlighted sentences are consistently more similar to turns by other speakers.</span>      </div>     </figure>     </p>     <ul class="list-no-style">     <li id="list1" label="&#x2022;">A kink exists in similarity to turns by the same speaker (Figure&#x00A0;3a). Highlighted and not-highlighted sentences present the same level of similarity to turns by the same speaker until the last turn before the sentence. An interesting kink shows up around the sentence: highlighted sentences are less similar to the turn immediately before but are more similar to turns after. We take this as a sign that &#x201C;changepoints&#x201D; in a monologue, where the speaker shifts in topic or style, are more likely to be quoted.<br/></li>     <li id="list2" label="&#x2022;">Highlighted sentences are more similar to neighboring turns by other speakers (Figure&#x00A0;3b). Regarding the overall trend, both for highlighted and not-highlighted sentences, the similarity is smaller for the immediate neighboring turns (<em>w</em> is 1 or -1) than when more turns are included. This is because moderators often speak right before and right after candidates, and moderators speak distinctly from candidates, in terms of words (due to different communicative goals).<br/></li>     </ul>    </section>    <section id="sec-10">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.4</span> Prediction Performance</h3>     </div>     </header>     <p>Finally, we study to what extent media choices can be predicted only from textual factors by examining classification performance on the held-out set. We also investigate the difference between general debates and primary debates. <figure id="fig4">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186142/images/www2018-151-fig4.jpg" class="img-responsive" alt="Figure 4"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 4:</span>       <span class="figure-title">Classification accuracy. In Figure&#x00A0;4a, each point measures the accuracy of a feature set (indicated by the color) on the subset of held-out data where the quote count of the highlighted sentence in a pair is among the top <em>x</em>% quoted sentences in the debate. In other words, smaller <em>x</em> values correspond to &#x201C;easier&#x201D; pairs where the highlighted sentence is more prominent. <em>y</em> values for <em>x</em> = 10 give the accuracies on the full held-out data (all, 66.0% vs. human, 60.1%, <em>p</em> = 0.0008). Figure&#x00A0;4b illustrates the accuracy when we apply the classifier trained on a debate type to another debate type. Different colors represent the debate type of the training data, and the <em>x</em>-axis represents the debate type of the test data. Note that &#x201C;human&#x201D; reports the accuracy of human predictions on the corresponding debate type in the test data, and is not a function of the training set.</span>      </div>     </figure>      <strong>Overall prediction accuracy (Figure&#x00A0;4a).</strong>Using only textual factors, our classifier achieves an accuracy of 66% on the held-out set for <em>t</em> = 10. The accuracy of both machines and humans increases for &#x201C;easier&#x201D; pairs, the ones in which highlighted sentences were quoted more frequently. This trend confirms that meaningful signals exist in the wording. The accuracy of machines (&#x201C;all&#x201D;) is always above humans and the difference is statistically significant.</p>     <p>The bag-of-words (BOW) model already outperforms humans in this task. In comparison with the features that we propose in &#x00A7;<a class="sec" href="#sec-9">3.3</a> (&#x201C;all &#x2013; BOW&#x201D;), although &#x201C;all &#x2013; BOW&#x201D; has far fewer features, it yields a similar accuracy to BOW. &#x201C;all &#x2013; BOW&#x201D; works relatively well when highlighted sentences in a pair were quoted more frequently and when there are fewer training instances, while BOW has an advantage when the highlighted sentence is closer to the 10% threshold (right side of Figure&#x00A0;4a). Combining all features (including BOW; &#x201C;all&#x201D;) always leads to the best accuracy.</p>     <p>     <em>Note that the accuracies of machines and humans are not meant to be compared head-to-head, since machines rely on training data to identify the useful signals, while humans depend on their daily (potentially biased) media exposure.</em> Instead, we view this accuracy gap as evidence suggesting that some signals in the wording are hard for humans to identify. This also points to the potential to inform the public with the help of machines.</p>     <p>     <strong>Differences across debate types (Figure&#x00A0;4b).</strong>As primary debates have more candidates and receive less coverage than general debates, the news media may employ different criteria to select highlights. To explore the differences, we train classifiers on subsets of the training data from primary debates and test on different types of debate. Differences indeed exist in how wording affects media selection: the classifiers do not usually perform well when tested on other debate types, except from Republican primary debates to general debates. In fact, using all training instances does not improve over using the pairs only from the matching debate type, despite the latter&#x0027;s use of fewer training instances.<a class="fn" href="#fn7" id="foot-fn7"><sup>7</sup></a>     </p>     <p>     <strong>Machines outperform humans only in primary debates.</strong>Human accuracy is much better in general debates than in primary debates. In fact, the advantage of our classifiers (&#x201C;all&#x201D;) in Figure&#x00A0;4a mainly comes from primary debates. The reason may be that general debates receive more attention and more coverage, humans are thus more likely to remember what was selected as highlights; indeed, &#x201C;memory, past exposure&#x201D; was an important factor in the surveys. If this is the case, humans may have an even more limited understanding of media choices had there been no influence from previous exposure. We also observe that humans perform better in general debates after 2000 than in those before 2000.</p>    </section>   </section>   <section id="sec-11">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Media Preferences over Time</h2>     </div>    </header>    <p>Beyond the effect of wording, a media outlet&#x0027;s own preferences can potentially impact how highlights are selected. In fact, media polarization has attracted significant interest from both researchers and the public [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>]. We take advantage of the longitudinal nature of our dataset, and evaluate the extent of media fragmentation over time. Building on the intuition that outlets are similar if they quote the same sentences with similar sentiments, we employ two approaches to quantify the fragmentation level. We first consider the existing two-party structure in the U.S. and evaluate whether the media quote both parties &#x201C;evenly&#x201D;. Second, we borrow concepts from the clustering literature and examine the overall similarity between media outlets beyond the partisan assumption.</p>    <section id="sec-12">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Bipartisan Coverage</h3>     </div>     </header>     <figure id="fig5">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186142/images/www2018-151-fig5.jpg" class="img-responsive" alt="Figure 5"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 5:</span>      <span class="figure-title">Bipartite graph between media outlets and highlights from presidential debates. The edges are sampled from presidential debates in 2016.</span>     </div>     </figure>     <p>Because U.S. presidential elections typically involve two major parties, we first take advantage of this two-party structure and evaluate fragmentation by how much &#x201C;Democratic-leaning&#x201D; media outlets quote Republican candidates and vice versa.</p>     <p>     <strong>Bipartite graph representation.</strong>A natural representation of quoting patterns is a bipartite graph between outlets and sentences, where an edge between media outlet <em>i</em> and candidate sentence <em>j</em> indicates that <em>i</em> quotes <em>j</em> (e.g., Figure&#x00A0;<a class="fig" href="#fig5">5</a>). This graph can be represented using a media-sentence matrix <span class="inline-equation"><span class="tex">$\mathbf {D}\in \mathbb {R}^{M \times S}$</span>     </span>, where each row represents a media outlet (<em>M</em> is the number of outlets) and each column represents a sentence from a candidate (<em>S</em> is the number of sentences). To obtain <strong>D</strong>     <sub>      <em>ij</em>     </sub>, we use three methods to account for both the frequency and the sentiment of a media outlet quoting a candidate utterance: <em>a.&#x00A0;count</em> (<strong>D</strong>     <sub>      <em>ij</em>     </sub> is the number of times that sentence <em>j</em> was quoted in outlet <em>i</em>); <em>b.&#x00A0;positive context</em> (<strong>D</strong>     <sub>      <em>ij</em>     </sub> is the number of positive words in the 30 words around each quote of sentence <em>j</em> in outlet <em>i</em>); <em>c.&#x00A0;negative context</em> (similar to positive context but counting negative words). We normalize each row so that the &#x2113;<sub>2</sub>-norm is 1 and remove media outlets that used fewer than 10 quotes in an election. <figure id="fig6">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186142/images/www2018-151-fig6.jpg" class="img-responsive" alt="Figure 6"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 6:</span>       <span class="figure-title">Figure&#x00A0;6a estimates whether the outlets quote evenly across two parties and shows a declining trend over time. Figure&#x00A0;6b gives the global average pairwise similarity and there are no clear trends, while Figure&#x00A0;6c shows that &#x201C;local similarity&#x201D; (average similarity with top nearest neighbors) increases over time. There are not enough media outlets with at least 10 quotes to compute meaningful results in the 80s, so we exclude those years. In all figures, different colors represent different ways to represent media outlets with their quoting patterns.</span>      </div>     </figure>      <strong>Using min-cut to identify bipartisan coverage.</strong>We focus on news coverage of general debates, because there has always been one presidential candidate and one vice-presidential candidate from the Democratic party and the Republican party during the past three decades.<a class="fn" href="#fn8" id="foot-fn8"><sup>8</sup></a>We thus build matrices for the bipartite graphs based on general debates in each presidential election.</p>     <p>To the extent that outlets &#x201C;lean&#x201D; one way or the other, we expect them to quote one party or the other more (or to positively quote one party more, or to negatively quote one party more). In the extreme case, a subset of media outlets might only quote the Republican candidates and the rest only quote the Democratic candidates, in other words, there exists no bipartisan coverage. These intuitions align with the idea of using min-cut to identify bipartisan coverage. If we apply the min-cut algorithm to separate sentences from Democratic candidates and sentences from Republican candidates in the bipartite graph [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0049">49</a>], then the extreme case where no bipartisan coverage exists leads to a min-cut of 0. Conversely, the more costly the min-cut, the more entangled the two sides are.</p>     <p>     <strong>Decreasing bipartisan coverage (Figure&#x00A0;6a).</strong>We thus compute the fraction of weights in the min-cut and smaller values in this statistic indicate that media outlets quote largely from one of the two sides and little from the other.<a class="fn" href="#fn9" id="foot-fn9"><sup>9</sup></a>Figure&#x00A0;6a shows that cross-cutting coverage in the min-cut is declining over time, under all three definitions. It is worth noting that the fraction of weights in the min-cut is not small (about 40%, upper bounded by 50%) despite the declining trend, which suggests that media outlets tend to at least cover both sides. The fact that there exists less cross-cutting coverage in sentiment (both positive and negative) than in counts indicates that although media outlets quote both sides, the sentiment differs.<a class="fn" href="#fn10" id="foot-fn10"><sup>10</sup></a>     </p>    </section>    <section id="sec-13">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Beyond Partisan Assumptions</h3>     </div>     </header>     <p>An alternative way to estimate fragmentation is to study how well media outlets cluster together without partisan assumptions. We build matrices based on both primary debates and general debates in each presidential election. We use each row <strong>D</strong>     <sub>      <em>i</em>     </sub> to represent media outlet <em>i</em> and investigate the quality of clustering between media outlets.</p>     <p>Clustering purity is typically evaluated at two levels: in a pure clustering, inter-cluster distances are large and intra-cluster distances are small [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0043">43</a>]. When we use the Silhouette score (a measure of purity) to identify the optimal number of clusters in a <em>K</em>-means clustering of media representations in <strong>D</strong>, the optimal number is close to the total number of media outlets, <em>M</em>, which suggests that there are many isolated small clusters.</p>     <p>We thus examine fragmentation at the above two levels by considering each media outlet as a singleton: whether media outlets have become less similar to each other overall (analogous to inter-cluster distances); and whether media outlets have become more similar to their nearest neighbors (analogous to intra-cluster distances). We use cosine similarity to measure the similarity between a pair of media outlets.</p>     <p>     <strong>No clear trends in &#x201C;inter-cluster&#x201D; similarity (Figure&#x00A0;6b).</strong>To evaluate whether the news media become less similar to each other, we calculate the global mean of all pairwise similarities. A decreasing global mean would indicate fragmentation at the global level, but we do not observe consistent trends or any statistically significant correlation with time (Figure&#x00A0;6b). The similarity in positive context and negative context is always smaller than the similarity in usage frequency. This again suggests that, although different media outlets may quote the same sentences, they present different opinions around the quotes.</p>     <p>     <strong>Increasing &#x201C;intra-cluster&#x201D; similarity (Figure&#x00A0;6c).</strong>To capture &#x201C;local&#x201D; similarity that is analogous to intra-cluster distances, we propose a statistic that measures the average similarity between a media outlet and its <em>K</em> nearest neighbors. We refer to this as <em>local similarity</em>. A growing local similarity suggests increasing tightness at the local level. We observe consistent increasing trends across three definitions, and this observation is robust with choices of <em>K</em>. This observation is related to the fact that there are increasingly many media outlets over time and it is thus more likely for a media outlet to have a close nearest neighbor. However, this hypothesis is insufficient to explain our observations, because it also suggests that &#x201C;inter-cluster&#x201D; similarity should increase, which does not hold.</p>     <p>     <strong>Discussion.</strong>Our observations are derived from a three-decade dataset and are consistent with past work on polarization and partisan selective exposure [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0051">51</a>], but the reasons behind the decreasing bipartisan coverage and the increasing local similarity require further investigation.</p>     <p>Our results are certainly limited by the relatively short history of presidential debates. It is also important to note that our study does not take into account the influence among media outlets themselves [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>]. For instance, Golan [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>] shows a correlation between the morning <em>New York Times</em> and three evening television news programs. Further studies regarding the diffusion in media selection of highlights can shed more light on our observations.</p>    </section>   </section>   <section id="sec-14">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Related Work</h2>     </div>    </header>    <p>We have discussed the most relevant studies throughout the paper. Here we discuss three additional strands of related work.</p>    <p>     <strong>The effect of post-debate coverage on public opinion.</strong>Studies have shown that media choices about coverage can have serious consequences [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0056">56</a>]. For instance, Fridkin et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>] show that in the 2004 U.S. election, citizens who only read the news coverage rated Kerry more negatively compared to those who watched the debate firsthand, because media outlets highlighted the moment of Kerry outing Cheney&#x0027;s lesbian daughter, although this moment did not catch much attention from the live audience. Boydstun et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>] develop a mobile app to collect real-time feedback for presidential debates. Patterson [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>] discuss the media&#x0027;s critical tendency and its partisan consequences in the U.S.</p>    <p>     <strong>Influences between the media and politicians.</strong>Although our work focuses on media selection of highlights, politicians often behave based on their beliefs about media preferences, which suggests complex dynamics between the media and politicians [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>]. For instance, Blumler and Kavanagh [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] discuss politicians&#x2019; increasing adaptation to different news values and formats in the presence of media abundance. Also relevant is research on the influence of politicians on the media, including agenda-setting, rhetorical positioning, and framing [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0046">46</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0057">57</a>].</p>    <p>     <strong>Power dynamics in debates and other types of coverage.</strong>Studies have shown that language use and topic control in debates can reflect influence between candidates and indicate power dynamics [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>]. More recently, social media have also become an important channel to monitor public opinion on debates in real time [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>] and potentially change news media coverage.</p>   </section>   <section id="sec-15">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Conclusion</h2>     </div>    </header>    <p>In this paper, we conduct the first systematic study on media selection of highlights from presidential debates, using a three-decade dataset. We introduce a computational framework that controls for the speaker and the debate situation to study the effect of textual factors. First, we find that media choices are not obvious to Mechanical Turk workers, suggesting that the public may have a limited understanding of how the news media choose highlights in news coverage. Second, although machines and humans achieve similar accuracy in general debates, machines significantly outperform humans in predicting media-chosen highlights in primary debates. Our findings indicate that there exist signals in the textual information that untrained humans do not find salient. In particular, highlights are locally distinct from the speaker&#x0027;s previous turn, but are later echoed more by both the speaker and other participants. We further demonstrate a declining trend of bipartisan coverage using macro quoting patterns and analyze the quality of clustering between media outlets without partisan assumptions.</p>    <p>The news media play an important role in connecting the public and politicians. Our work indicates that the public may not understand what factors matter in media choices. Quantitative studies in this domain can complement qualitative theories to improve the understanding of political and media communication for both scholars and the public.</p>    <p>     <strong>Acknowledgments.</strong> We thank Yejin Choi, Aaron Jaech, Luke Zettlemoyer, anonymous reviewers, and all members of Noah&#x0027;s ARK for helpful comments and discussions. This research was made possible by a University of Washington Innovation Award.</p>   </section>  </section>  <section class="back-matter">   <Appendix>    <section id="sec-16">     <header>     <div class="title-info">      <h2>       <span class="section-number">A</span> Appendix</h2>     </div>     </header>     <section id="sec-17">     <header>      <div class="title-info">       <h3>        <span class="section-number">A.1</span> Amazon Mechanical Turk Labeling Details</h3>      </div>     </header>     <p>      <strong>Detailed task and filtering criteria.</strong>For each threshold <span class="inline-equation"><span class="tex">$t \in \lbrace 2, 4, 6, 8, 10\rbrace,$</span>      </span> we randomly sampled 200 pairs from the corresponding heldout set, in total 1,000 pairs. In our Amazon Mechanical Turk experiments, we required participants to be from the United States and have done at least 10 HITs with at least 97% acceptance rate. We requested each participant to label 25 pairs in an assignment (5 for each threshold) and each participant can only finish one assignment. We paid <font style="normal">&#x0024;</font>1.00 (<font style="normal">&#x0024;</font>0.04 a pair) for an assignment and gave <font style="normal">&#x0024;</font>0.02 bonus for each correct guess to incentivize participants to try their best. We removed participants who did not answer survey questions in good faith and spent too short time on the task. To compensate for such filtering, we added assignments on Amazon Mechanical Turk until we had 200 valid assignments. In the end, we gathered 5,000 labels in total (5 labels per pair).</p>     <p>      <strong>Survey questions.</strong>The following questions were asked after participants finished labeling:</p>     <ul class="list-no-style">      <li id="list3" label="&#x2022;">Some people follow presidential debates most of the time, while others aren&#x0027;t that interested. How often would you say you have watched presidential debates from 1980 to 2016? (Never, 1-5 times, 5-10 times, more than 10 times)<br/></li>      <li id="list4" label="&#x2022;">Generally speaking, when it comes to political parties in the U.S., how would you describe yourself? (Democrat, Independent close to Democrat, Independent (close to neither), Independent close to Republican, Republican, Other)<br/></li>      <li id="list5" label="&#x2022;">Explain what factors influence your decision on which sentence was quoted more, simple comments such as several adjectives or nouns (e.g., issues, surprise) can help our research. (free-form response)<br/></li>      <li id="list6" label="&#x2022;">If you have any comment about our task, please give us your feedback. (free-form response)<br/></li>     </ul>     <p>There are no clear trends in human performances regarding levels of experience or ideology. Most participants gave very positive feedback about our task, e.g., &#x201C;Very fun to read some of the old transcripts and think about those conversations&#x2013;thank you!&#x201D;.</p>     </section>     <section id="sec-18">     <header>      <div class="title-info">       <h3>        <span class="section-number">A.2</span> Sentence-alone Feature Definitions and Testing Results</h3>      </div>     </header>     <p>      <strong>Detailed definitions.</strong> The following list is aligned with features in Table 2.</p>     <ul class="list-no-style">      <li id="list7" label="&#x2022;">Length is measured by the number of words in a sentence.<br/></li>      <li id="list8" label="&#x2022;">The lexicons of positive words and negative words come from the corresponding category in LIWC [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0040">40</a>].<br/></li>      <li id="list9" label="&#x2022;">Negations and negative conjunctions. Negations include &#x201C;n&#x0027;t&#x201D;, &#x201C;not&#x201D;, &#x201C;no&#x201D;, &#x201C;cannot&#x201D;. Negative conjunctions include &#x201C;although&#x201D;, &#x201C;atho&#x201D;, &#x201C;but&#x201D;, &#x201C;nor&#x201D;, &#x201C;whereas&#x201D;, &#x201C;while&#x201D;, &#x201C;though&#x201D;, &#x201C;however&#x201D;, &#x201C;otherwise&#x201D;, &#x201C;tho&#x201D; and &#x201C;unless&#x2019;.&#x2019;<br/></li>      <li id="list10" label="&#x2022;">Personal pronouns. The list of definitions come from LIWC [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0040">40</a>].<br/></li>      <li id="list11" label="&#x2022;">Hedges. We use a list of regular expressions from Tan and Lee [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0053">53</a>].<br/></li>      <li id="list12" label="&#x2022;">Superlatives. We get a list of candidate lexicons by matching words with the regular expression &#x201C;[a-zA-Z]+est&#x201D;, and then manual filter false positives. We also include &#x201C;most&#x201D;, &#x201C;least&#x201D; and &#x201C;worst&#x201D;.<br/></li>      <li id="list13" label="&#x2022;">Indefinite articles. &#x201C;a&#x201D; and &#x201C;an&#x201D;.<br/></li>      <li id="list14" label="&#x2022;">Language model features. We use each sentence&#x0027;s likelihood w.r.t. both lexical level and part-of-speech level language models trained on newswire data. Specifically, we train 1, 2, and 3-gram lexical level language models on the NYT corpus<a class="fn" href="#fn11" id="foot-fn11"><sup>11</sup></a>, and we use the WSJ portion of Penn Treebank<a class="fn" href="#fn12" id="foot-fn12"><sup>12</sup></a> to train POS-level models. Our implementation is based on SRILM [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0050">50</a>].<br/></li>      <li id="list15" label="&#x2022;">Parallelism. We measure parallelism using the average length of the longest common sequences between sub-sentences following Song et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0048">48</a>]. The basic unit in the longest common sequence is a word. Sub-sentences are split by &#x201C;;&#x201D; or &#x201C;,&#x201D;.<br/></li>     </ul>     <p>      <strong>Feature testing procedure and results.</strong>For each feature, we use a one-sided paired <em>t</em>-test to test whether, on our training pairs, our scoring function for that feature is larger in the highlighted sentences than in the not-highlighted sentences. Given that we did 20 tests in total, there is a risk of obtaining false positives due to multiple testing. To account for this, we only report significant results after the Bonferroni correction [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0004">4</a>], i.e., we multiply each <em>p</em>-value by 20 and see whether it is smaller than (for example) 0.05.</p>     </section>    </section>   </Appendix>   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Max Atkinson. 1984. <em>      <em>Our Masters&#x2019; Voices: The Language and Body Language of Politics.</em></em> Psychology Press.</li>     <li id="BibPLXBIB0002" label="[2]">Matthew&#x00A0;A. Baum and Tim Groeling. 2008. New Media and the Polarization of American Political Discourse. <em>      <em>Political Communication</em>     </em>25, 4 (2008), 345&#x2013;365.</li>     <li id="BibPLXBIB0003" label="[3]">Jay&#x00A0;G. Blumler and Dennis Kavanagh. 1999. The Third Age of Political Communication: Influences and Features. <em>      <em>Political communication</em>     </em>16, 3 (1999), 209&#x2013;230.</li>     <li id="BibPLXBIB0004" label="[4]">Carlo&#x00A0;E. Bonferroni. 1936. <em>      <em>Teoria statistica delle classi e calcolo delle probabilita.</em></em> Libreria internazionale Seeber.</li>     <li id="BibPLXBIB0005" label="[5]">Amber&#x00A0;E. Boydstun, Rebecca&#x00A0;A. Glazier, Matthew&#x00A0;T. Pietryka, and Philip Resnik. 2014. Real-time Reactions to a 2012 Presidential Debate: A Method for Understanding Which Messages Matter. <em>      <em>Public Opinion Quarterly</em>     </em>78, S1 (2014), 330&#x2013;343.</li>     <li id="BibPLXBIB0006" label="[6]">Thomas&#x00A0;P. Boyle. 2001. Intermedia Agenda Setting in the 1996 Presidential Election. <em>      <em>Journalism &#x0026; Mass Communication Quarterly</em>     </em>78, 1 (2001), 26&#x2013;44.</li>     <li id="BibPLXBIB0007" label="[7]">Marcel Broersma and Todd Graham. 2012. Social Media as Beat: Tweets as a News Source During the 2010 British and Dutch elections. <em>      <em>Journalism Practice</em>     </em>6, 3 (2012), 403&#x2013;419.</li>     <li id="BibPLXBIB0008" label="[8]">Jennifer Brubaker and Gary Hanson. 2009. The Effect of Fox News and CNN&#x0027;s Postdebate Commentator Analysis on Viewers&#x2019; Perceptions of Presidential Candidate Performance. <em>      <em>Southern Communication Journal</em>     </em>74, 4 (2009), 339&#x2013;351.</li>     <li id="BibPLXBIB0009" label="[9]">Karen Callaghan and Frauke Schnell. 2010. Assessing the Democratic Debate: How the News Media Frame Elite Policy Discourse. <em>      <em>Political Communication</em>     </em>18, 2 (2010), 183&#x2013;213.</li>     <li id="BibPLXBIB0010" label="[10]">Dennis Chong and James&#x00A0;N. Druckman. 2007. A Theory of Framing and Opinion Formation in Competitive Elite Environments. <em>      <em>Journal of Communication</em>     </em>57, 1 (2007), 99&#x2013;118.</li>     <li id="BibPLXBIB0011" label="[11]">Steven&#x00A0;E. Clayman. 1995. Defining Moments, Presidential Debates, and the Dynamics of Quotability. <em>      <em>Journal of Communication</em>     </em>45, 3 (1995), 118&#x2013;147.</li>     <li id="BibPLXBIB0012" label="[12]">Steven&#x00A0;E. Clayman and John Heritage. 2002. <em>      <em>The news interview: Journalists and public figures on the air.</em></em> Cambridge University Press.</li>     <li id="BibPLXBIB0013" label="[13]">Cristian Danescu-Niculescu-Mizil, Justin Cheng, Jon Kleinberg, and Lillian Lee. 2012. You Had Me at Hello: How Phrasing Affects Memorability. In <em>      <em>Proceedings of ACL.</em></em></li>     <li id="BibPLXBIB0014" label="[14]">Nicholas&#x00A0;A. Diakopoulos and David&#x00A0;A. Shamma. 2010. Characterizing Debate Performance via Aggregated Twitter Sentiment. In <em>      <em>Proceedings of CHI.</em></em></li>     <li id="BibPLXBIB0015" label="[15]">John Dinardo. 2010. Natural Experiments and Quasi-Natural Experiments. In <em>      <em>Microeconometrics.</em></em> Palgrave Macmillan UK, 139&#x2013;153.</li>     <li id="BibPLXBIB0016" label="[16]">Robert&#x00A0;M. Entman. 1993. Framing: Toward Clarification of a Fractured Paradigm. <em>      <em>Journal of Communication</em>     </em>43, 4 (1993), 51&#x2013;58.</li>     <li id="BibPLXBIB0017" label="[17]">Kim&#x00A0;L. Fridkin, Patrick&#x00A0;J. Kenney, Sarah&#x00A0;Allen Gershon, and Gina Serignese&#x00A0;Woodall. 2008. Spinning Debates: The Impact of the News Media&#x0027;s Coverage of the Final 2004 Presidential Debate. <em>      <em>The International Journal of Press/Politics</em>     </em>13, 1 (2008), 29&#x2013;51.</li>     <li id="BibPLXBIB0018" label="[18]">John&#x00A0;G. Geer. 2012. The News Media and the Rise of Negativity in Presidential Campaigns. <em>      <em>PS: Political Science &#x0026; Politics</em>     </em>45, 03 (2012), 422&#x2013;427.</li>     <li id="BibPLXBIB0019" label="[19]">Elisabeth Gidengil and Joanna Everitt. 2003. Talking Tough: Gender and Reported Speech in Campaign News Coverage. <em>      <em>Political communication</em>     </em>20, 3 (2003), 209&#x2013;232.</li>     <li id="BibPLXBIB0020" label="[20]">Guy Golan. 2007. Inter-media Agenda Setting and Global News Coverage. <em>      <em>Journalism Studies</em>     </em>7, 2 (2007), 323&#x2013;333.</li>     <li id="BibPLXBIB0021" label="[21]">Noah Grand. 2015. <em>The Emergence of Newsworthiness: Inclusion, Exclusion and Inequality in Political News and Online Media</em>. Ph.D. Dissertation.</li>     <li id="BibPLXBIB0022" label="[22]">Tim Groseclose and Jeffrey Milyo. 2005. A Measure of Media Bias. <em>      <em>The Quarterly Journal of Economics</em>     </em>(2005), 1191&#x2013;1237.</li>     <li id="BibPLXBIB0023" label="[23]">Kimberly Gross, Ethan Porter, and Thomas Wood. 2017. Presidential Debates in the Age of Partisan Media: A Field Experiment. (2017). Available at SSRN.</li>     <li id="BibPLXBIB0024" label="[24]">Daniel&#x00A0;C. Hallin. 1992. Sound Bite News: Television Coverage of Elections, 1968&#x2013;1988. <em>      <em>Journal of communication</em>     </em>42, 2 (1992), 5&#x2013;24.</li>     <li id="BibPLXBIB0025" label="[25]">D.&#x00A0;Sunshine Hillygus and Simon Jackman. 2003. Voter Decision Making in Election 2000: Campaign Effects, Partisan Activation, and the Clinton Legacy. <em>      <em>American Journal of Political Science</em>     </em>47, 4 (2003), 583&#x2013;596.</li>     <li id="BibPLXBIB0026" label="[26]">Hyunseo Hwang, Melissa&#x00A0;R. Gotlieb, Seungahn Nah, and Douglas&#x00A0;M. McLeod. 2007. Applying a Cognitive-processing Model to Presidential Debate Effects: Postdebate News Analysis and Primed Reflection. <em>      <em>Journal of Communication</em>     </em>57, 1 (2007), 40&#x2013;59.</li>     <li id="BibPLXBIB0027" label="[27]">Shanto Iyengar and Kyu&#x00A0;S. Hahn. 2009. Red media, Blue media: Evidence of Ideological Selectivity in Media Use. <em>      <em>Journal of Communication</em>     </em>59, 1 (2009), 19&#x2013;39.</li>     <li id="BibPLXBIB0028" label="[28]">Thorsten Joachims. 2002. Optimizing Search Engines Using Clickthrough Data. In <em>      <em>Proceedings of KDD.</em></em></li>     <li id="BibPLXBIB0029" label="[29]">Kyungmo Kim and George&#x00A0;A. Barnett. 1996. The Determinants of International News Flow. <em>      <em>Communication Research</em>     </em>23, 3 (1996), 323&#x2013;352.</li>     <li id="BibPLXBIB0030" label="[30]">George Lakoff. 1975. Hedges: A Study in Meaning Criteria and the Logic of Fuzzy Concepts. <em>      <em>Journal of Philosophical Logic</em>     </em>2, 4 (1975), 458&#x2013;508.</li>     <li id="BibPLXBIB0031" label="[31]">Jure Leskovec, Lars Backstrom, and Jon Kleinberg. 2009. Meme-tracking and the Dynamics of the News Cycle. In <em>      <em>Proceedings of KDD.</em></em></li>     <li id="BibPLXBIB0032" label="[32]">Yu-Ru Lin, James&#x00A0;P. Bagrow, and David Lazer. 2011. More Voices Than Ever? Quantifying Media Bias in Networks. In <em>      <em>Proceedings of ICWSM.</em></em></li>     <li id="BibPLXBIB0033" label="[33]">Maxwell&#x00A0;E. McCombs and Donald&#x00A0;L. Shaw. 1972. The Agenda-setting Function of Mass Media. <em>      <em>Public Opinion Quarterly</em>     </em>36, 2 (1972), 176&#x2013;187.</li>     <li id="BibPLXBIB0034" label="[34]">Mitchell&#x00A0;S. McKinney and Diana&#x00A0;B. Carlin. 2004. Political Campaign Debates. In <em>      <em>Handbook of political communication research.</em></em> 203&#x2013;234.</li>     <li id="BibPLXBIB0035" label="[35]">Viet-An Nguyen, Jordan Boyd-Graber, and Philip Resnik. 2012. SITS: A Hierarchical Nonparametric Model Using Speaker Identity for Topic Segmentation in Multiparty Conversations. In <em>      <em>Proceedings of ACL.</em></em></li>     <li id="BibPLXBIB0036" label="[36]">Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik, Deborah&#x00A0;A. Cai, Jennifer&#x00A0;E. Midberry, and Yuanxin Wang. 2014. Modeling Topic Control to Detect Influence in Conversations Using Nonparametric Topic Models. <em>      <em>Machine Learning</em>     </em>95, 3 (2014), 381&#x2013;421.</li>     <li id="BibPLXBIB0037" label="[37]">Vlad Niculae, Caroline Suen, Justine Zhang, Cristian Danescu-Niculescu-Mizil, and Jure Leskovec. 2015. QUOTUS: The Structure of Political Media Coverage as Revealed by Quoting Patterns. In <em>      <em>Proceedings of WWW.</em></em></li>     <li id="BibPLXBIB0038" label="[38]">Thomas&#x00A0;E. Patterson. 2016. News Coverage of the 2016 General Election: How the Press Failed the Voters. (2016).</li>     <li id="BibPLXBIB0039" label="[39]">Thomas&#x00A0;E. Patterson. 2016. News Coverage of the 2016 Presidential Primaries: Horce Race Reporting Has Consequences. (2016).</li>     <li id="BibPLXBIB0040" label="[40]">James&#x00A0;W. Pennebaker, Martha&#x00A0;E. Francis, and Roger&#x00A0;J. Booth. 2007. <em>      <em>Linguistic Inquiry and Word Count: LIWC 2007.</em></em> Technical Report.</li>     <li id="BibPLXBIB0041" label="[41]">Vinodkumar Prabhakaran, Ashima Arora, and Owen Rambow. 2014. Staying on Topic: An Indicator of Power in Political Debates. In <em>      <em>Proceedings of EMNLP.</em></em></li>     <li id="BibPLXBIB0042" label="[42]">Andrea Prat and David Str&#x00F6;mberg. 2013. The Political Economy of Mass Media. In <em>      <em>Advances in Economics and Econometrics: Tenth World Congress.</em></em> Cambridge University Press.</li>     <li id="BibPLXBIB0043" label="[43]">Peter&#x00A0;J. Rousseeuw. 1987. Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis. <em>      <em>Journal of Computational and Applied Mathematics</em>     </em>20 (1987), 53&#x2013;65.</li>     <li id="BibPLXBIB0044" label="[44]">Paul Rozin and Edward&#x00A0;B. Royzman. 2001. Negativity Bias, Negativity Dominance, and Contagion. <em>      <em>Personality and Social Psychology Review</em>     </em>5, 4 (2001), 296&#x2013;320.</li>     <li id="BibPLXBIB0045" label="[45]">Dafna Shahaf, Eric Horvitz, and Robert Mankoff. 2015. Inside Jokes: Identifying Humorous Cartoon Captions. In <em>      <em>Proceedings of KDD.</em></em></li>     <li id="BibPLXBIB0046" label="[46]">Yanchuan Sim, Brice&#x00A0;D.L. Acree, Justin&#x00A0;H. Gross, and Noah&#x00A0;A. Smith. 2013. Measuring Ideological Proportions in Political Speeches. In <em>      <em>Proceedings of EMNLP.</em></em></li>     <li id="BibPLXBIB0047" label="[47]">Matthew&#x00A0;P. Simmons, Lada&#x00A0;A. Adamic, and Eytan Adar. 2011. Memes Online: Extracted, Subtracted, Injected, and Recollected. In <em>      <em>Proceedings of ICWSM.</em></em></li>     <li id="BibPLXBIB0048" label="[48]">Wei Song, Tong Liu, Ruiji Fu, Lizhen Liu, Hanshi Wang, and Ting Liu. 2016. Learning to Identify Sentence Parallelism in Student Essays. In <em>      <em>Proceedings of COLING.</em></em></li>     <li id="BibPLXBIB0049" label="[49]">Mechthild Stoer and Frank Wagner. 1997. A Simple Min-cut Algorithm. <em>      <em>Journal of the ACM</em>     </em>44, 4 (1997), 585&#x2013;591.</li>     <li id="BibPLXBIB0050" label="[50]">Andreas Stolcke, Jing Zheng, Wen Wang, and Victor Abrash. 2011. SRILM at Sixteen: Update and Outlook. In <em>      <em>Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop.</em></em></li>     <li id="BibPLXBIB0051" label="[51]">Natalie&#x00A0;J. Stroud. 2010. Polarization and Partisan Selective Exposure. <em>      <em>Journal of Communication</em>     </em>60, 3 (2010), 556&#x2013;576.</li>     <li id="BibPLXBIB0052" label="[52]">Chenhao Tan, Adrien Friggeri, and Lada&#x00A0;A. Adamic. 2016. Lost in Propagation? Unfolding News Cycles from the Source. In <em>      <em>Proceedings of ICWSM.</em></em></li>     <li id="BibPLXBIB0053" label="[53]">Chenhao Tan and Lillian Lee. 2016. Talk it up or Play it down? (Un)expected Correlations between (De-)emphasis and Recurrence of Discussion Points in Consequential U.S. Economic Policy Meetings. (2016). Presented in Text as Data.</li>     <li id="BibPLXBIB0054" label="[54]">Chenhao Tan, Lillian Lee, and Bo Pang. 2014. The Effect of Wording on Message Propagation: Topic- and Author-controlled Natural Experiments on Twitter. In <em>      <em>Proceedings of ACL.</em></em></li>     <li id="BibPLXBIB0055" label="[55]">Chenhao Tan, Vlad Niculae, Cristian Danescu-Niculescu-Mizil, and Lillian Lee. 2016. Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions. In <em>      <em>Proceedings of WWW.</em></em></li>     <li id="BibPLXBIB0056" label="[56]">Yariv Tsfati. 2003. Debating the Debate: The Impact of Exposure to Debate News Coverage and Its Interaction with Exposure to the Actual Debate. <em>      <em>The International Journal of Press/Politics</em>     </em>8, 3 (2003), 70&#x2013;86.</li>     <li id="BibPLXBIB0057" label="[57]">Chris Wells, Dhavan&#x00A0;V. Shah, Jon&#x00A0;C. Pevehouse, JungHwan Yang, Ayellet Pelled, Frederick Boehm, Josephine Lukito, Shreenita Ghosh, and Jessica&#x00A0;L Schmidt. 2016. How Trump Drove Coverage to the Nomination: Hybrid Media Campaigning. <em>      <em>Political Communication</em>     </em>(2016).</li>     <li id="BibPLXBIB0058" label="[58]">Justine Zhang, Ravi Kumar, Sujith Ravi, and Cristian Danescu-Niculescu-Mizil. 2016. Conversational Flow in Oxford-style Debates. In <em>      <em>Proceedings of NAACL (short papers).</em></em></li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class="link-inline force-break"     href="https://en.wikipedia.org/wiki/Senator,_you&#x0027;re_no_Jack_Kennedy#Legacy">https://en.wikipedia.org/wiki/Senator,_you&#x0027;re_no_Jack_Kennedy#Legacy</a>. </p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break"     href="http://www.presidency.ucsb.edu/debates.php">http://www.presidency.ucsb.edu/debates.php</a>. In fact, presidential debates are a relatively recent phenomenon, despite their prominence nowadays. After the first general debate between John F. Kennedy and Richard Nixon in 1960, there were no general debates until 1976. For more historical details, refer to <a class="link-inline force-break"     href="http://www.cnn.com/2012/09/30/opinion/greene-debates/">http://www.cnn.com/2012/09/30/opinion/greene-debates/</a>. </p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a><a class="link-inline force-break"     href="http://www.lexisnexis.com/hottopics/lnacademic/">http://www.lexisnexis.com/hottopics/lnacademic/</a>. </p>   <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>There exist alternate ways to account for topic shift, e.g., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>].</p>   <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>For both sentences in a pair, we include up to 3 sentences before it and 3 sentences after it to provide some context for the participants to understand the current state of the debate.</p>   <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a>Surprisingly, there is no clear relationship between an individual&#x0027;s prediction performance and their self-reported level of experience or political ideology.</p>   <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a>A more comparable setup is to subsample training instances to match the size in a particular debate type. Doing this, training only using the matching debate type (known as &#x201C;in-domain&#x201D;) always outperforms using all debate types.</p>   <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a>We ignore all independent candidates in this analysis.</p>   <p id="fn9"><a href="#foot-fn9"><sup>9</sup></a>Note that media outlets that preferentially quote Democratic candidates may not support the Democratic party, because a quote can be presented in a negative light. We thus also use sentiment information in the context of quotes to populate <strong>D</strong>.</p>   <p id="fn10"><a href="#foot-fn10"><sup>10</sup></a>In terms of the partition resulted from the min-cut, in most years, the majority of the media outlets are in the partition associated with Republican candidate sentences, at least consistent with a recent report in 2016 [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>]. This is especially true for big media outlets such as the <em>New York Times</em> and <em>Washington Post</em>. A notable exception is that the <em>Washington Post</em> is in the Democratic partition for positive contexts in 2008.</p>   <p id="fn11"><a href="#foot-fn11"><sup>11</sup></a>LDC number: LDC2008T19. <a class="link-inline force-break" href="https://catalog.ldc.upenn.edu/ldc2008t19">https://catalog.ldc.upenn.edu/ldc2008t19</a>   </p>   <p id="fn12"><a href="#foot-fn12"><sup>12</sup></a>LDC number: LDC99T42. <a class="link-inline force-break" href="https://catalog.ldc.upenn.edu/ldc99t42">https://catalog.ldc.upenn.edu/ldc99t42</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186142">https://doi.org/10.1145/3178876.3186142</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
