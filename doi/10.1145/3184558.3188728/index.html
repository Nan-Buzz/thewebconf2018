<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>Misleading or Falsification? Inferring Deceptive Strategies and Types in Online News and Social Media</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3188728'>https://doi.org/10.1145/3184558.3188728</a> 
 Published in WWW2018 Proceedings Â© 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3188728'>https://w3id.org/oa/10.1145/3184558.3188728</a>
</p></div>
<hr>

  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">Misleading or Falsification? Inferring Deceptive Strategies and Types in Online News and Social Media</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author">     <span class="givenName">Svitlana</span>     <span class="surName">Volkova</span>,     Pacific Northwest National Laboratory, Richland, Washington    </div>    <div class="author">     <span class="givenName">Jin Yea</span>     <span class="surName">Jang</span><a class="fn" href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>,     Pacific Northwest National Laboratory, Richland, 		 Washington, <a href="mailto:svitlana.volkova@pnnl.gov, jinyea.jang@keti.re.kr">svitlana.volkova@pnnl.gov, jinyea.jang@keti.re.kr</a>    </div>        </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3184558.3188728" target="_blank">https://doi.org/10.1145/3184558.3188728</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>Deceptive information in online news and social media has had dramatic effect on our society in recent years. This study is the first to gain deeper insights into writers&#x2019; intent behind digital misinformation by analyzing psycholinguistic signals: moral foundations and connotations extracted from different types of deceptive news ranging from strategic disinformation to propaganda and hoaxes. To ensure consistency of our findings and generalizability across domains, we experiment with data from: (1) confirmed cases of disinformation in news summaries, (2) propaganda, hoax, and disinformation news pages, and (3) social media news. We first contrast lexical markers of biased language, syntactic and stylistic signals, and connotations across deceptive news types including disinformation, propaganda, and hoaxes, and deceptive strategies including misleading or falsification. We then incorporate these insights to build machine learning and deep learning predictive models to infer deception strategies and deceptive news types. Our experimental results demonstrate that unlike earlier work on deception detection, content combined with biased language markers, moral foundations, and connotations leads to better predictive performance of deception strategies compared to syntactic and stylistic signals (as reported in earlier work on deceptive reviews). Falsification strategy is easier to identify than misleading strategy. Disinformation is more difficult to predict than to propaganda or hoaxes. Deceptive news types (disinformation, propaganda, and hoaxes), unlike deceptive strategies (falsification and misleading), are more salient, and thus easier to identify in tweets than in news reports. Finally, our novel connotation analysis across deception types provides deeper understanding of writers&#x2019; perspectives and therefore reveals the intentions behind digital misinformation.</small>    </p>    </div>    <div class="CCSconcepts">    <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Computing methodologies </strong>&#x2192; <strong>Natural language processing;</strong> <strong>Neural networks;</strong></small> </p>    </div>    <div class="classifications">    <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>natural language processing; machine learning; deep learning; misinformation; deception; social media analysis; connotation analysis</small>     </span>    </div>    <br/>    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Svitlana Volkova and Jin Yea Jang. 2018. Misleading or Falsification? Inferring Deceptive Strategies and Types in Online News and Social Media. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018 (WWW &#x2019;18 Companion),</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 9 Pages. <a href="https://doi.org/10.1145/3184558.3188728" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3184558.3188728</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-2">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>    </div>    </header>    <p>Information is power. Disinformation undermines this power. According to the World Economic Forum report&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>], massive digital disinformation is listed as one of the main risks of the modern society. Different types of false information have been actively shared on the web and through social media. Regardless of the false information&#x0027;s type and purpose &#x2013; misinterpretation by mistake or targeted propaganda campaigns&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>], the consequences it has on people&#x0027;s lives are harmful&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>] and sometimes even fatal&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0040">40</a>].</p>    <p>Sparse availability of data annotated with deceptive news types, credibility levels, or checked facts limited research on analyzing and identifying false information in online communications&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>]. The majority of earlier work on automatic deception detection relied on manually constructed small corpora to build predictive models to detect deceptive product reviews&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>]. Recent work has focused on annotated data from PolitiFact&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0050">50</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0062">62</a>], satirical news e.g., The Onion&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0054">54</a>], and news articles&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>], which typically targeted only one domain (generally politics), or focused on specific event types e.g., shooting events&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0056">56</a>], natural disasters&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0057">57</a>], or elections&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>]. These studies have resulted in important findings about the effect of misinformation spread&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>], influence campaigns&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>], and social bots&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>] within specific newsworthy events.</p>    <p>Only&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>] and&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0061">61</a>] explored Twitter data to evaluate linguistic realizations in mainstream vs. alternative news sources, and built models to predict information credibility and deceptive news types e.g., propaganda, hoaxes, and clickbait vs. trusted news, respectively. However, to the best of our knowledge, limited prior work focused on analyzing deception strategies e.g., misleading vs. falsification&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>], and analyzed linguistic realizations of disinformation. Thus, the unique source of public data that consists of confirmed cases of disinformation (https://euvsdisinfo.eu/, @EUvsDisinfo) annotated by the European Union&#x0027;s East Strategic Communications Task Force analyzed in this study, in addition to deceptive webpages and social media communications, will further advance understanding and improve predictive models for factuality assessment and information credibility online. We outline the main contributions of this study below.</p>    <p>First, we examine linguistic realizations across deceptive strategies: misleading vs. falsification, and types: disinformation, propaganda, and hoaxes across domains including disinformation reports, news pages, and social media posts. We report statistically significant differences in psycholinguistic cues, biased and subjective language, and moral foundations behind deceptive news content.</p>    <p>Second, we analyze connotations toward agents and targets of deceptive news across different types of deceptive content to provide deeper understanding of writers&#x2019; perspectives and intentions behind strategic disinformation, propaganda, and hoaxes.</p>    <p>Finally, we incorporate our findings on differences in linguistic realizations across deception types and strategies to build predictive models for deception detection. We contrast machine learning and deep learning model performance trained on content, stylistic, syntactic, and psycholinguistic signals across domains to ensure generalizability of our models.</p>    <section id="sec-3">    <header>     <div class="title-info">      <h3>Deception Types</h3>     </div>    </header>    <p>To study deception on a spectrum depending on writers intent, we focus on three popular types of deception&#x2013;strategic disinformation, propaganda and hoaxes, and two deception strategies&#x2013;misleading or falsification as shown in Figure&#x00A0;<a class="fig" href="#fig1">1</a>. The example tweets of deceptive news along with definitions for three deceptive news types are presented below. <figure id="fig1">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3188728/images/www18companion-236-fig1.svg" class="img-responsive" alt="Figure 1"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 1:</span>       <span class="figure-title">Deceptive news categorized based on deception type and strategy.</span>      </div>     </figure>    </p>    <ul class="list-no-style">     <li id="list1" label="&#x2022;"><strong>Hoax</strong> is a type of misinformation that aims to deliberately deceive the reader&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0030">30</a>]. The example hoax tweet: <em>BREAKING! Massive Volcano Eruption Only 32 Miles Away From MAJOR Nuclear Plant! &#x00A0; Consciously Enlightened.</em>      <br/></li>     <li id="list2" label="&#x2022;"><strong>Propaganda</strong> is a form of persuasion that attempts to influence the emotions, attitudes, opinions, and actions of specified target audiences for political, ideological, and religious purposes through the controlled transmission of deceptive, selectively omitting, and one-sided messages&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0035">35</a>]. The example propaganda tweet: <em>The UN Plans To Implement Universal Biometric Identification For All Of Humanity By 2030.</em>      <br/></li>     <li id="list3" label="&#x2022;"><strong>Disinformation</strong> denotes false facts that are conceived in order to deliberately deceive the audience&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0030">30</a>]. The example disinformation tweet: <em>Soren Kern: European Union Declares War on Internet Free Speech.</em>      <br/></li>    </ul>    </section>    <section id="sec-4">    <header>     <div class="title-info">      <h3>Deception Strategies</h3>     </div>    </header>    <p>One of the contributions of this work focuses on analyzing disinformation strategies &#x2013; misleading and falsification as defined below, and contrasting psycholinguistic realizations that distinguish them.</p>    <ul class="list-no-style">     <li id="list4" label="&#x2022;"><strong>Misleading</strong> strategy includes cases of topic changes, irrelevant information, and equivocations: <em>Austria and Slovenia are closing their borders with Serbia to stem the flow of refugees.</em><a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a>      <br/></li>     <li id="list5" label="&#x2022;"><strong>Falsification</strong> strategy deals with contradictions or distortions: <em>Ukrainian engineers made a mistake constructing AN-178 plane, they have to fly with ballast.</em><a class="fn" href="#fn3" id="foot-fn3"><sup>2</sup></a>      <br/></li>    </ul>    <p>Other types of deceptive strategies have been recently studied in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>], e.g., exaggeration and omission. We consider these strategies to be very specific cases of misleading strategies that require background knowledge to identify and exclude them from our analysis.</p>    <p>Unlike any previous work, we analyze and contrast moral foundations and connotations across deceptive news types, strategies, and data sources. We also incorporate our findings into predictive models that rely on machine learning and deep learning to automatically infer deception types and strategies across domains: summaries, webpages, and tweets. To evaluate model generalizability and consistency of our findings, we contrast our results across data sources (domains) and report the predictive power of different psycholinguistic signals extracted from news: content, syntax, style, connotations, and moral foundations behind deceptive content.</p>    </section>   </section>   <section id="sec-5">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> Background</h2>    </div>    </header>    <p>Previous work on deception detection primarily focused on spoken and written personal and criminal narratives and conference calls&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0063">63</a>]. Only recently researchers have proposed methods for deception detection in online communications: book and hotel reviews or essay data&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>]. The existing models primarily rely on shallow linguistic features e.g., n-grams, part-of-speech tags, readability, and syntactic complexity features combined with state-of-the-art machine learning models&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0046">46</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0053">53</a>]. Researchers found that textual clues to deception include self reference, negation statements, complaints, and generalizing items. More specifically, Linguistic Inquiry and Word Count (LIWC) features&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>] were used to show that deceptive stories compared to true stories had lower cognitive complexity e.g., <em>cause, know</em>; use fewer exclusive words e.g., <em>but, except</em>; more negative emotion words e.g., <em>hate, worthless, sad</em> and more motion verbs e.g., <em>walk, go, carry</em>; fewer self-references, fewer first-person singular pronouns e.g., <em>I, me, and my</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>]. Recent work focused on building predictive models to distinguish between fake and verified news&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0055">55</a>], infer deceptive news types&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0050">50</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0061">61</a>], and assess information credibility&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0062">62</a>].</p>    <p>Several papers analyzed the impact of false information spread on the web, focusing on hoaxes on encyclopedia&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>], satirical news&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0054">54</a>], and misinformation propagation in social networks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0058">58</a>]. Most of the work in this area has focused on engineered features, e.g., network structure and shallow semantic features&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0059">59</a>]. More recent work took into account deeper semantic understanding of language for fact-checking and defined a statistical model to detect all mentions of events in news and then assess the degree of uncertainty around whether each mentioned event happened&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>]. The focus of this work is not to study misinformation contagion in social networks. Instead, we analyze linguistic realizations of misinformation that lead to misleading or falsified statements, and incorporate these psycholinguistic signals into predictive models to automatically infer deception types and strategies across domains.</p>   </section>   <section id="sec-6">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> Deception Datasets</h2>    </div>    </header>    <p>This section presents three datasets used for our analysis: disinformation summaries, deceptive news pages and tweets, and data annotation and pre-processing details.</p>    <section id="sec-7">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Disinformation Summaries</h3>     </div>    </header>    <p>We rely on public data annotated with confirmed cases of disinformation (https://euvsdisinfo.eu/, @EUvsDisinfo) collected by the European Union&#x0027;s East Strategic Communications Task Force in 2015 &#x2013; 2016. The total number of confirmed disinformation cases is 1,992 with 36 cases reported per week on average.</p>    <p>We annotated disinformation summaries as falsification and misleading using crowdsourcing. We first marked summaries that contained substrings <em>unprovable, no evidence, no proof, no supporting evidence,</em> etc. in the disproof as falsification. We then showed five annotators the remaining disinformation summaries with the URLs. Measured pairwise inter-annotator agreement on all responses was 64% (when at least four annotators agree 66%), and the kappa score on all responses was 0.43 (when at least four annotators agree, the score is 0.22). In total, we ended up with 1,376 (69%) summaries annotated as falsification and 616 (31%) as misleading.</p>    <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">Dataset statistics: the number of news pages, tweets, and disinformation summaries annotated with deception types and strategies.</span>     </div>     <table class="table"> 		  <thead>       <tr bgcolor="gray">       <th style="text-align:center;" colspan="4"><SmallCap>Deception Types</SmallCap>       </th>       </tr>       <tr>       <th style="text-align:left;"/>       <th style="text-align:center;">Propaganda</th>       <th style="text-align:center;">Hoaxes</th>       <th style="text-align:center;">Disinfo</th>       </tr> 			</thead>      <tbody>       <tr>       <td style="text-align:left;">Webpages</td>       <td style="text-align:center;">17,872</td>       <td style="text-align:center;">5,297</td>       <td style="text-align:center;">166</td>       </tr>       <tr>       <td style="text-align:left;">Tweets</td>       <td style="text-align:center;">3,834</td>       <td style="text-align:center;">453</td>       <td style="text-align:center;">205</td>       </tr> 			<thead>       <tr bgcolor="gray">       <th style="text-align:center;" colspan="4"><SmallCap>Deception Strategies</SmallCap>       </th>       </tr>       <tr>       <th style="text-align:left;"/>       <th style="text-align:center;">Misleading</th>       <th colspan="2" 				 style="text-align:center;">Falsification</th>       </tr> 			</thead>       <tr>       <td style="text-align:left;">Summaries</td>       <td style="text-align:center;">616</td>       <td colspan="2" style="text-align:center;">1,376       </td>       </tr>       <tr>       <td style="text-align:left;">Webpages</td>       <td style="text-align:center;">81</td>       <td colspan="2" style="text-align:center;">85       </td>       </tr>       <tr>       <td style="text-align:left;">Tweets</td>       <td style="text-align:center;">96</td>       <td colspan="2" style="text-align:center;">109       </td>       </tr>      </tbody>     </table>    </div>    <p>We parsed all summaries, news pages, and tweets (described below) using the state-of-the-art dependency parser &#x2013; SyntaxNet<a class="fn" href="#fn4" id="foot-fn4"><sup>3</sup></a>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0047">47</a>]. We extracted grammar and syntax: subjects, verbs and objects, and the part-of-speech tags. This is an important step toward understanding agents and themes of deception and contrasting connotations across deception types.</p>    </section>    <section id="sec-8">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Deceptive News Pages</h3>     </div>    </header>    <p>We followed URLs in disinformation summaries to collect the original news pages. We propagated misleading and falsification labels from disinformation summaries to label the news pages. For our analysis we only focused on English webpages. In total we had 85 (51%) news pages in English marked as falsification and 81 (49%) as misleading. In addition, we downloaded 17,872 propaganda and 5,297 hoax news pages to contrast disinformation with other deceptive news types.</p>    </section>    <section id="sec-9">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> Deceptive Tweets</h3>     </div>    </header>    <p>We used subject, verb, and object tuples extracted from parsed disinformation summaries and the disinformation summary date field to query Twitter public API to extract disinformation tweets. We collected 7,969 disinformation tweets and retweets. After de-duplication (4,457 tweets) and removing @mentions, URLs, and RTs (985 tweets), we removed tweets with edit distance and TFIDF cosine similarity above 0.8 to avoid overfitting. We ended up with a clean sample of 205 disinformation tweets annotated as misleading vs. falsification. We also collected tweets produced by example propaganda and hoax accounts produced in 2016.</p>    <p>In addition to annotating tweets with deceptive strategies e.g., misleading vs. falsification we also asked annotators to define targeted topics of disinformation following the annotation strategy proposed in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>]. We report top targeted topics of disinformation in summaries and tweets. We found that the most popular targets of disinformation are politics, security, and economics. Moreover, tweets and summaries are framed to mislead rather than falsify information about politics and external affairs. More summaries about security are falsified rather than misleading, but more tweets about security are misleading rather than falsified.</p>    <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Top targeted topics of disinformation summaries and tweets.</span>     </div>     <table class="table"> 		  <thead>       <tr bgcolor="gray">       <th style="text-align:center;"/>       <th colspan="2" style="text-align:center;">        <SmallCap>Summaries</SmallCap>       </th>       <th colspan="2" style="text-align:center;">        <SmallCap>Tweets</SmallCap>       </tdh>       </tr>       <tr>       <th style="text-align:left;">Frame</th>       <th style="text-align:center;">Mislead</th>       <th style="text-align:center;">Falsify</th>       <th style="text-align:center;">Mislead</th>       <th style="text-align:center;">Falsify</th>       </tr> 			</thead>      <tbody>       <tr>       <td style="text-align:left;">Political</td>       <td style="text-align:center;">        <strong>46.7</strong>       </td>       <td style="text-align:center;">41.7</td>       <td style="text-align:center;">        <strong>55.9</strong>       </td>       <td style="text-align:center;">37.0</td>       </tr>       <tr>       <td style="text-align:left;">Security</td>       <td style="text-align:center;">23.0</td>       <td style="text-align:center;">        <strong>31.1</strong>       </td>       <td style="text-align:center;">        <strong>37.2</strong>       </td>       <td style="text-align:center;">33.3</td>       </tr>       <tr>       <td style="text-align:left;">Economic</td>       <td style="text-align:center;">        <strong>9.6</strong>       </td>       <td style="text-align:center;">3.5</td>       <td style="text-align:center;">3.5</td>       <td style="text-align:center;">        <strong>10.2</strong>       </td>       </tr>       <tr>       <td style="text-align:left;">Crime</td>       <td style="text-align:center;">5.8</td>       <td style="text-align:center;">        <strong>6.3</strong>       </td>       <td style="text-align:center;">&#x2013;</td>       <td style="text-align:center;">3.7</td>       </tr>       <tr>       <td style="text-align:left;">Cultural</td>       <td style="text-align:center;">2.7</td>       <td style="text-align:center;">        <strong>4.2</strong>       </td>       <td style="text-align:center;">&#x2013;</td>       <td style="text-align:center;">&#x2013;</td>       </tr>       <tr>       <td style="text-align:left;">Public</td>       <td style="text-align:center;">        <strong>2.7</strong>       </td>       <td style="text-align:center;">2.5</td>       <td style="text-align:center;">2.3</td>       <td style="text-align:center;">        <strong>2.8</strong>       </td>       </tr>       <tr>       <td style="text-align:left;">External</td>       <td style="text-align:center;">2.7</td>       <td style="text-align:center;">        <strong>3.9</strong>       </td>       <td style="text-align:center;">1.2</td>       <td style="text-align:center;">        <strong>9.3</strong>       </td>       </tr>      </tbody>     </table>    </div>    </section>   </section>   <section id="sec-10">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> Approach</h2>    </div>    </header>    <p>This section describes predictive models and different types of signals to infer deception types and strategies across domains.</p>    <section id="sec-11">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Predictive Models</h3>     </div>    </header>    <p>We use the state-of-the-art classifiers &#x2013; MaxEntropy and RandomForest implemented in scikit-learn&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0042">42</a>], Long Short-Term Memory (LSTM), and Convolutional Neural Network (CNN)-based models&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0061">61</a>] implemented in keras<a class="fn" href="#fn5" id="foot-fn5"><sup>4</sup></a> to predict deception types and strategies. We run experiments using 10-fold cross-validation and rely on the lexical, syntactic, stylistic, psycholinguistic, and connotation signals described below.</p>    <section id="sec-12">     <p><em>4.1.1 Content.</em> For machine learning models, we rely on TFIDF features extracted from webpages, summaries, and tweets. We take advantage of StandardScalar<a class="fn" href="#fn6" id="foot-fn6"><sup>5</sup></a> and dimensionality reduction<a class="fn" href="#fn7" id="foot-fn7"><sup>6</sup></a> to avoid overfitting. For neural network models, we initialize the embedding layer with pre-trained Glove embeddings&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0044">44</a>].</p>    </section>    <section id="sec-13">     <p><em>4.1.2 Style, complexity, and readability.</em> We rely on language complexity and readability features designed to measure how difficult the text is to understand e.g., Automated Readability Index (ARI), Flesch-Kincaid readability tests, Coleman-Liau index, and the Gunning fog index etc.<a class="fn" href="#fn8" id="foot-fn8"><sup>7</sup></a>     </p>    </section>    <section id="sec-14">     <p><em>4.1.3 Syntax.</em> We use syntactic signals demonstrated to be effective for deception detection in book and hotel reviews&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0036">36</a>]. To evaluate the predictive power of syntactic signals across domains, we rely on part-of-speech tags extracted by SyntaxNet&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0047">47</a>].</p>    </section>    <section id="sec-15">     <p><em>4.1.4 Biased language, moral foundations, and psycholinguistic signals.</em> Recent work demonstrated that biased lexicons&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0052">52</a>] and moral foundations&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0061">61</a>] are predictive of suspicious news in social media. We outline biased language lexicons used to form our analysis and predictive models below.</p>     <ul class="list-no-style">      <li id="list6" label="&#x2022;"><em>Factive verbs</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0029">29</a>]: presuppose the truth of their complement clause e.g., <em>realize, know, regret</em>.<br/></li>      <li id="list7" label="&#x2022;"><em>Assertive verbs</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0024">24</a>]: a complement clause requires a preposition; the level of certainty depends on the asserting verb e.g., <em>point out, claim</em>.<br/></li>      <li id="list8" label="&#x2022;"><em>Report verbs</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0052">52</a>]: include verbs e.g., <em>admit, blame, criticize</em>.<br/></li>      <li id="list9" label="&#x2022;"><em>Hedges</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0026">26</a>]: an expression of &#x201C;tentativeness and possibility&#x201D; or language corresponding to the &#x201C;writer withholding full commitments to statements&#x201D;&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0009">9</a>] e.g., <em>may, possibly, seems.</em>       <br/></li>      <li id="list10" label="&#x2022;"><em>Implicative verbs</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0028">28</a>]: imply the truth or untruth of their complement, depending on the polarity of the main predicate e.g., <em>decline, hesitate, avoid, neglect</em>.<br/></li>      <li id="list11" label="&#x2022;"><em>Intensifiers and dramatic adverbs</em>: include superlatives and comparatives e.g., <em>nicest, damper</em>; action, manner, modal adverbs e.g., <em>accidentally, freely, truly.</em>       <br/></li>      <li id="list12" label="&#x2022;"><em>Moral foundations</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0023">23</a>] Basic moral values emerge from cultural and evolutionary factors that people support &#x2013; <em>care and harm, fairness and cheating, loyalty and betrayal, authority and subversion, and purity and degradation.</em> People differ in the way they endorse these values; thus, writers of different types of deceptive news might appeal to specific moral foundations of their readers.<br/></li>      <li id="list13" label="&#x2022;"><em>Psycholinguistic cues</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0043">43</a>] Linguistic Inquiry Word Count (LIWC) cues include <em>imperative commands, personal pronouns, emotional language, quotations, and inclusions</em>.<br/></li>     </ul>     <figure id="fig2">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3188728/images/www18companion-236-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Example connotation frame.</span>      </div>     </figure>     <figure id="fig3">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3188728/images/www18companion-236-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 3:</span>       <span class="figure-title">Psycholinguistic markers of biased and subjective language and moral foundations in misleading vs. falsification statements across domains (% of summaries, % of sentences in news pages, % of tweets). Only statistically significant results are reported (<em>p</em> &#x2264; 0.05).</span>      </div>     </figure>    </section>    <section id="sec-16">     <p><em>4.1.5 Connotations.</em> Connotation frames allow the reader to estimate the author&#x0027;s perspective: positive, negative, or neutral toward the subject and object of the sentence, as well as the perspective of the subject toward the object&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0051">51</a>]. Connotations provide insights about feelings that a word invokes in addition to its literal or primary meaning. The example connotations for the disinformation summary <em>Great Britain</em>      <strong>threatens</strong>      <em>the Islamic state with a nuclear bomb</em> is shown in Figure&#x00A0;<a class="fig" href="#fig2">2</a> include writer <span class="inline-equation"><span class="tex">$\xrightarrow {\text{--}}$</span>      </span> Great Britain, writer <span class="inline-equation"><span class="tex">$\xrightarrow {\text{=}}$</span>      </span> Islamic state, Great Britain (subj) <span class="inline-equation"><span class="tex">$\xrightarrow {\text{--}}$</span>      </span> Islamic state (obj). <figure id="fig4">       <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3188728/images/www18companion-236-fig4.jpg" class="img-responsive" alt="Figure 4"        longdesc=""/>       <div class="figure-caption">       <span class="figure-number">Figure 4:</span>       <span class="figure-title">Connotation frame analysis in disinformation, propaganda, and hoax tweets and news headlines. We plot the writer&#x0027;s perspective (positive &#x2013; Y axis, negative &#x2013; X axis) toward agents and themes. Subjectivity (the opposite of neutrality or objectivity) of agents and themes are shown using color gradient &#x2013; the darker the color, the more subjective (less neutral) the perspective is.</span>       </div>      </figure>     </p>    </section>    </section>   </section>   <section id="sec-17">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Results</h2>    </div>    </header>    <section id="sec-18">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.1</span> Linguistic Analysis of Deceptive News</h3>     </div>    </header>    <p>Figures&#x00A0;<a class="fig" href="#fig3">3</a> presents differences in linguistic realizations between misleading and falsification statements across domains: tweets, news pages, and summaries. First, we observe that misleading vs. falsification deceptive strategies are realized in linguistically different ways across domains. The only shared linguistic signals are subjective language, harm, moral foundation, and negation.</p>    <p>Second, we found that subjective language and affect signals are the most represented in tweets, pronouns, and subjective language in news pages and prepositions and inclusion in summaries. Interestingly, differences in HarmVirtue and IngroupVirtue moral foundations are significant in tweets but HarmVice and FairnessVice in summaries. Finally, we estimated that language is more subjective in misleading statements than falsified content in summaries and news pages but not in tweets; there are more prepositions in summaries and fewer pronouns in news pages in falsified content than in misleading content.</p>    <div class="table-responsive" id="tab3">     <div class="table-caption">      <span class="table-number">Table 3:</span>      <span class="table-title">Results for predicting deception strategies &#x2013; misleading vs. falsification across domains (summaries, webpage, and tweets) using different signals &#x2013; content, syntactic, stylistic (readability and complexity), affect (connotations), and lexicon features. Baseline Random Forest (RF) and MaxEntropy (ME) models rely on individual signals. Neural network models LSTM and CNN combine content and individual signals. F1 stands for macro F1, F1:M &#x2013; misleading class, F1:F &#x2013; falsification. ROC and F1 for top predictive models across different signals and domains are highlighted in bold.</span>     </div>     <table class="table"> 		  <thead>       <tr>       <th style="text-align:left;"/>       <th style="text-align:right;"/>       <th colspan="4" style="text-align:center;">        <SmallCap>Summaries</SmallCap>        <hr/>       </th>       <th colspan="4" style="text-align:center;">        <SmallCap>News Pages</SmallCap>        <hr/>       </th>       <th colspan="4" style="text-align:center;">        <SmallCap>Tweets</SmallCap>        <hr/>       </th>       </tr>       <tr>       <th style="text-align:left;">        <strong>Signals</strong>       </th>       <th style="text-align:right;">        <strong>Model</strong>       </th>       <th style="text-align:right;">        <strong>ROC</strong>       </th>       <th style="text-align:right;">        <strong>F1</strong>       </th>       <th style="text-align:right;">        <strong>F1:M</strong>       </th>       <th style="text-align:right;">        <strong>F1:F</strong>       </th>       <th style="text-align:right;">        <strong>ROC</strong>       </th>       <th style="text-align:right;">        <strong>F1</strong>       </th>       <th style="text-align:right;">        <strong>F1:M</strong>       </th>       <th style="text-align:right;">        <strong>F1:F</strong>       </th>       <th style="text-align:right;">        <strong>ROC</strong>       </th>       <th style="text-align:right;">        <strong>F1</strong>       </th>       <th style="text-align:right;">        <strong>F1: M</strong>       </th>       <th>        <strong>F1:F</strong>       </th>       </tr> 			</thead>      <tbody>       <tr>       <td style="text-align:left;">Content</td>       <td style="text-align:right;">ME</td>       <td style="text-align:right;">0.60</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.58</strong>       </td>       <td style="text-align:right;">        <strong>0.49</strong>       </td>       <td style="text-align:right;">0.67</td>       <td style="text-align:right;">0.55</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.55</strong>       </td>       <td style="text-align:right;">        <strong>0.41</strong>       </td>       <td style="text-align:right;">0.69</td>       <td style="text-align:right;">0.81</td>       <td style="text-align:right;">0.81</td>       <td style="text-align:right;">0.80</td>       <td>0.81</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">RF</td>       <td style="text-align:right;">0.57</td>       <td style="text-align:right;">0.57</td>       <td style="text-align:right;">0.36</td>       <td style="text-align:right;">        <strong>0.78</strong>       </td>       <td style="text-align:right;">0.51</td>       <td style="text-align:right;">0.47</td>       <td style="text-align:right;">0.25</td>       <td style="text-align:right;">0.69</td>       <td style="text-align:right;">0.71</td>       <td style="text-align:right;">0.69</td>       <td style="text-align:right;">0.69</td>       <td>0.69</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">LSTM</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.61</strong>       </td>       <td style="text-align:right;">0.57</td>       <td style="text-align:right;">0.40</td>       <td style="text-align:right;">0.75</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.57</strong>       </td>       <td style="text-align:right;">0.52</td>       <td style="text-align:right;">0.34</td>       <td style="text-align:right;">0.70</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.92</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.81</strong>       </td>       <td style="text-align:right;">0.80</td>       <td>0.82</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">CNN</td>       <td style="text-align:right;">0.60</td>       <td style="text-align:right;">0.57</td>       <td style="text-align:right;">0.40</td>       <td style="text-align:right;">0.74</td>       <td style="text-align:right;">0.50</td>       <td style="text-align:right;">0.44</td>       <td style="text-align:right;">0.16</td>       <td style="text-align:right;">0.73</td>       <td style="text-align:right;">0.90</td>       <td style="text-align:right;">0.80</td>       <td style="text-align:right;">0.79</td>       <td>0.80</td>       </tr>       <tr>       <td style="text-align:left;">Syntax</td>       <td style="text-align:right;">ME</td>       <td style="text-align:right;">0.54</td>       <td style="text-align:right;">0.53</td>       <td style="text-align:right;">0.40</td>       <td style="text-align:right;">0.65</td>       <td style="text-align:right;">0.58</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.56</strong>       </td>       <td style="text-align:right;">0.39</td>       <td style="text-align:right;">0.73</td>       <td style="text-align:right;">0.78</td>       <td style="text-align:right;">0.76</td>       <td style="text-align:right;">0.74</td>       <td>0.77</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">RF</td>       <td style="text-align:right;">0.55</td>       <td style="text-align:right;">0.54</td>       <td style="text-align:right;">0.33</td>       <td style="text-align:right;">0.75</td>       <td style="text-align:right;">0.51</td>       <td style="text-align:right;">0.49</td>       <td style="text-align:right;">0.27</td>       <td style="text-align:right;">0.70</td>       <td style="text-align:right;">0.73</td>       <td style="text-align:right;">0.73</td>       <td style="text-align:right;">0.73</td>       <td>0.73</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">LSTM</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.61</strong>       </td>       <td style="text-align:right;">0.57</td>       <td style="text-align:right;">0.39</td>       <td style="text-align:right;">0.65</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.60</strong>       </td>       <td style="text-align:right;">0.46</td>       <td style="text-align:right;">0.20</td>       <td style="text-align:right;">0.72</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.93</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.82</strong>       </td>       <td style="text-align:right;">0.80</td>       <td>        <strong>0.84</strong>       </td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">CNN</td>       <td style="text-align:right;">0.59</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.62</strong>       </td>       <td style="text-align:right;">0.38</td>       <td style="text-align:right;">0.73</td>       <td style="text-align:right;">0.56</td>       <td style="text-align:right;">0.51</td>       <td style="text-align:right;">0.24</td>       <td style="text-align:right;">0.78</td>       <td style="text-align:right;">0.86</td>       <td style="text-align:right;">0.73</td>       <td style="text-align:right;">0.72</td>       <td>0.75</td>       </tr>       <tr>       <td style="text-align:left;">Style</td>       <td style="text-align:right;">ME</td>       <td style="text-align:right;">0.50</td>       <td style="text-align:right;">0.48</td>       <td style="text-align:right;">0.40</td>       <td style="text-align:right;">0.54</td>       <td style="text-align:right;">0.54</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.51</strong>       </td>       <td style="text-align:right;">0.37</td>       <td style="text-align:right;">0.65</td>       <td style="text-align:right;">0.61</td>       <td style="text-align:right;">0.58</td>       <td style="text-align:right;">0.58</td>       <td>0.59</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">RF</td>       <td style="text-align:right;">0.54</td>       <td style="text-align:right;">0.63</td>       <td style="text-align:right;">0.33</td>       <td style="text-align:right;">0.75</td>       <td style="text-align:right;">0.48</td>       <td style="text-align:right;">0.48</td>       <td style="text-align:right;">0.32</td>       <td style="text-align:right;">0.63</td>       <td style="text-align:right;">0.59</td>       <td style="text-align:right;">0.58</td>       <td style="text-align:right;">0.56</td>       <td>0.60</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">LSTM</td>       <td style="text-align:right;">0.56</td>       <td style="text-align:right;">0.48</td>       <td style="text-align:right;">0.19</td>       <td style="text-align:right;">0.76</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.56</strong>       </td>       <td style="text-align:right;">0.48</td>       <td style="text-align:right;">0.32</td>       <td style="text-align:right;">0.64</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.93</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.80</strong>       </td>       <td style="text-align:right;">0.80</td>       <td>0.81</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">CNN</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.61</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.64</strong>       </td>       <td style="text-align:right;">0.39</td>       <td style="text-align:right;">0.74</td>       <td style="text-align:right;">0.54</td>       <td style="text-align:right;">0.41</td>       <td style="text-align:right;">0.05</td>       <td style="text-align:right;">0.76</td>       <td style="text-align:right;">0.91</td>       <td style="text-align:right;">0.77</td>       <td style="text-align:right;">0.74</td>       <td>0.79</td>       </tr>       <tr>       <td style="text-align:left;">Connotations</td>       <td style="text-align:right;">ME</td>       <td style="text-align:right;">0.50</td>       <td style="text-align:right;">0.53</td>       <td style="text-align:right;">0.36</td>       <td style="text-align:right;">0.62</td>       <td style="text-align:right;">0.47</td>       <td style="text-align:right;">0.43</td>       <td style="text-align:right;">0.32</td>       <td style="text-align:right;">0.55</td>       <td style="text-align:right;">0.56</td>       <td style="text-align:right;">0.51</td>       <td style="text-align:right;">0.36</td>       <td>0.67</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">RF</td>       <td style="text-align:right;">0.52</td>       <td style="text-align:right;">0.61</td>       <td style="text-align:right;">0.31</td>       <td style="text-align:right;">0.72</td>       <td style="text-align:right;">0.48</td>       <td style="text-align:right;">0.47</td>       <td style="text-align:right;">0.28</td>       <td style="text-align:right;">0.66</td>       <td style="text-align:right;">0.58</td>       <td style="text-align:right;">0.53</td>       <td style="text-align:right;">0.37</td>       <td>0.70</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">LSTM</td>       <td style="text-align:right;">0.62</td>       <td style="text-align:right;">0.57</td>       <td style="text-align:right;">0.38</td>       <td style="text-align:right;">0.75</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.60</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.55</strong>       </td>       <td style="text-align:right;">0.38</td>       <td style="text-align:right;">0.72</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.93</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.82</strong>       </td>       <td style="text-align:right;">0.81</td>       <td>0.83</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">CNN</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.63</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.66</strong>       </td>       <td style="text-align:right;">0.42</td>       <td style="text-align:right;">0.76</td>       <td style="text-align:right;">0.53</td>       <td style="text-align:right;">0.41</td>       <td style="text-align:right;">0.04</td>       <td style="text-align:right;">0.78</td>       <td style="text-align:right;">0.90</td>       <td style="text-align:right;">0.77</td>       <td style="text-align:right;">0.74</td>       <td>0.80</td>       </tr>       <tr>       <td style="text-align:left;">Lexicons</td>       <td style="text-align:right;">ME</td>       <td style="text-align:right;">0.56</td>       <td style="text-align:right;">0.57</td>       <td style="text-align:right;">0.44</td>       <td style="text-align:right;">0.65</td>       <td style="text-align:right;">0.56</td>       <td style="text-align:right;">0.52</td>       <td style="text-align:right;">0.39</td>       <td style="text-align:right;">0.65</td>       <td style="text-align:right;">0.65</td>       <td style="text-align:right;">0.63</td>       <td style="text-align:right;">0.62</td>       <td>0.63</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">RF</td>       <td style="text-align:right;">0.54</td>       <td style="text-align:right;">0.65</td>       <td style="text-align:right;">0.32</td>       <td style="text-align:right;">0.76</td>       <td style="text-align:right;">0.54</td>       <td style="text-align:right;">0.53</td>       <td style="text-align:right;">0.34</td>       <td style="text-align:right;">0.71</td>       <td style="text-align:right;">0.65</td>       <td style="text-align:right;">0.63</td>       <td style="text-align:right;">0.63</td>       <td>0.63</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">LSTM</td>       <td style="text-align:right;">0.61</td>       <td style="text-align:right;">0.56</td>       <td style="text-align:right;">0.39</td>       <td style="text-align:right;">0.74</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.63</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.57</strong>       </td>       <td style="text-align:right;">0.43</td>       <td style="text-align:right;">0.72</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.92</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.81</strong>       </td>       <td style="text-align:right;">0.80</td>       <td>0.83</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">CNN</td>       <td style="text-align:right;">0.60</td>       <td style="text-align:right;">0.63</td>       <td style="text-align:right;">0.38</td>       <td style="text-align:right;">0.74</td>       <td style="text-align:right;">0.42</td>       <td style="text-align:right;">0.39</td>       <td style="text-align:right;">0.04</td>       <td style="text-align:right;">        <strong>0.78</strong>       </td>       <td style="text-align:right;">0.88</td>       <td style="text-align:right;">0.78</td>       <td style="text-align:right;">0.76</td>       <td>0.80</td>       </tr>       <tr>       <td style="text-align:left;">ALL</td>       <td style="text-align:right;">ME</td>       <td style="text-align:right;">0.58</td>       <td style="text-align:right;">0.64</td>       <td style="text-align:right;">0.43</td>       <td style="text-align:right;">0.74</td>       <td style="text-align:right;">0.46</td>       <td style="text-align:right;">0.42</td>       <td style="text-align:right;">0.24</td>       <td style="text-align:right;">0.61</td>       <td style="text-align:right;">0.83</td>       <td style="text-align:right;">0.82</td>       <td style="text-align:right;">0.80</td>       <td>0.83</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">RF</td>       <td style="text-align:right;">0.56</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.66</strong>       </td>       <td style="text-align:right;">0.35</td>       <td style="text-align:right;">0.77</td>       <td style="text-align:right;">0.45</td>       <td style="text-align:right;">0.44</td>       <td style="text-align:right;">0.23</td>       <td style="text-align:right;">0.64</td>       <td style="text-align:right;">0.71</td>       <td style="text-align:right;">0.69</td>       <td style="text-align:right;">0.67</td>       <td>0.70</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">LSTM</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.61</strong>       </td>       <td style="text-align:right;">0.57</td>       <td style="text-align:right;">0.38</td>       <td style="text-align:right;">0.75</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.54</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.48</strong>       </td>       <td style="text-align:right;">0.27</td>       <td style="text-align:right;">0.69</td>       <td style="text-align:right;" bgcolor="gray"><strong>0.92</strong>       </td>       <td style="text-align:right;" bgcolor="gray"><strong>0.82</strong>       </td>       <td style="text-align:right;">        <strong>0.82</strong>       </td>       <td>0.82</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:right;">CNN</td>       <td style="text-align:right;">0.60</td>       <td style="text-align:right;">0.65</td>       <td style="text-align:right;">0.39</td>       <td style="text-align:right;">0.75</td>       <td style="text-align:right;">0.50</td>       <td style="text-align:right;">0.44</td>       <td style="text-align:right;">0.19</td>       <td style="text-align:right;">0.69</td>       <td style="text-align:right;">0.89</td>       <td style="text-align:right;">0.77</td>       <td style="text-align:right;">0.75</td>       <td>0.79</td>       </tr>      </tbody>     </table>    </div>    <p>     <strong>Implications of Linguistic Analysis</strong>. Unlike&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0050">50</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0061">61</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0062">62</a>] that analyzed linguistic differences across disinformation types&#x2013;propaganda, hoaxes, clickbaits, and trusted news in web pages, PolitiFact statements and tweets, respectively&#x2013;we focused on differences in linguistic realizations between misleading and falsified statements. Interestingly, compared to earlier work, we found that only a small portion of linguistic signals is useful to distinguish between misleading and falsified statements. Our results not only show differences across different domains&#x2013;news pages, tweets, and summaries&#x2013;but also identified linguistic realizations useful to build predictive models for factuality assessment of the statement without relying on the external knowledge. Our findings will allow us to improve fact-checking systems by going beyond fake news classification&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0062">62</a>].</p>    </section>    <section id="sec-19">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.2</span> Connotation Analysis of Deceptive News</h3>     </div>    </header>    <p>The purpose of identifying perspectives toward agents and themes of deceptive content is to capture the hidden agenda behind strategic misinformation and disinformation. In Figure&#x00A0;<a class="fig" href="#fig4">4</a> we contrast connotations for top agents and themes across deception types: disinformation, propaganda, and hoaxes. We plot writers&#x2019; positive and negative perspectives about agents and themes and outline our key observations below.</p>    <div class="table-responsive" id="tab4">     <div class="table-caption">      <span class="table-number">Table 4:</span>      <span class="table-title">Results for predicting deception types: hoaxes, disinformation and propaganda across domains (webpage and tweets) using different signals: content, syntactic, stylistic (readability and complexity), connotations (targeted perspectives), and psycho-linguistic signals. Baseline Random Forest (RF) and MaxEntropy (ME) models rely on individual signals. Neural network models LSTM and CNN combine content and individual signals. F1 stands for macro F1, and individual F1:H for hoaxes class, F1:D &#x2013; disinformation, F1:P &#x2013; propaganda. F1 for top predictive models across different signals and domains are highlighted in bold. Confidence intervals obtained using 10-fold cross validation are omitted due to space constraints.</span>     </div>     <table class="table"> 		  <thead>      <tr>       <th style="text-align:left;"/>       <th style="text-align:center;"/>       <th colspan="4" style="text-align:center;">        <SmallCap>News Pages</SmallCap>        <hr/>       </th>       <th colspan="4" style="text-align:center;">        <SmallCap>Tweets</SmallCap>        <hr/>       </th>       </tr>       <tr>       <th style="text-align:left;">        <strong>Signals</strong>       </th>       <th style="text-align:center;">        <strong>Model</strong>       </th>       <th style="text-align:center;">        <strong>F1</strong>       </th>       <th style="text-align:center;">        <strong>F1:P</strong>       </th>       <th style="text-align:center;">        <strong>F1:H</strong>       </th>       <th style="text-align:center;">        <strong>F1:D</strong>       </th>       <th style="text-align:center;">        <strong>F1</strong>       </th>       <th style="text-align:center;">        <strong>F1:P</strong>       </th>       <th style="text-align:center;">        <strong>F1:H</strong>       </th>       <th>        <strong>F1:D</strong>       </th>       </tr> 			</thead>      <tbody>       <tr>       <td style="text-align:left;">Content</td>       <td style="text-align:center;">ME</td>       <td style="text-align:center;">0.48 &#x00B1; 0.02</td>       <td style="text-align:center;">0.54 &#x00B1; 0.06</td>       <td style="text-align:center;">0.56 &#x00B1; 0.03</td>       <td style="text-align:center;">0.34 &#x00B1; 0.08</td>       <td style="text-align:center;">0.65 &#x00B1; 0.04</td>       <td style="text-align:center;">0.52 &#x00B1; 0.08</td>       <td style="text-align:center;">0.70 &#x00B1; 0.06</td>       <td>0.73 &#x00B1; 0.05</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">RF</td>       <td style="text-align:center;">0.79 &#x00B1; 0.05</td>       <td style="text-align:center;">0.70 &#x00B1; 0.06</td>       <td style="text-align:center;">0.72 &#x00B1; 0.08</td>       <td style="text-align:center;">0.94 &#x00B1; 0.03</td>       <td style="text-align:center;">0.71 &#x00B1; 0.05</td>       <td style="text-align:center;">0.67 &#x00B1; 0.07</td>       <td style="text-align:center;">0.70 &#x00B1; 0.06</td>       <td>0.77 &#x00B1; 0.04</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">LSTM</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.82 &#x00B1; 0.01</strong>       </td>       <td style="text-align:center;">        <strong>0.76 &#x00B1; 0.04</strong>       </td>       <td style="text-align:center;">        <strong>0.76 &#x00B1; 0.02</strong>       </td>       <td style="text-align:center;">0.94 &#x00B1; 0.01</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.87 &#x00B1; 0.02</strong>       </td>       <td style="text-align:center;">        <strong>0.83 &#x00B1; 0.03</strong>       </td>       <td style="text-align:center;">        <strong>0.87 &#x00B1; 0.03</strong>       </td>       <td>0.92 &#x00B1; 0.02</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">CNN</td>       <td style="text-align:center;">0.78 &#x00B1; 0.05</td>       <td style="text-align:center;">0.71 &#x00B1; 0.10</td>       <td style="text-align:center;">0.75 &#x00B1; 0.06</td>       <td style="text-align:center;">0.88 &#x00B1; 0.02</td>       <td style="text-align:center;">0.80 &#x00B1; 0.02</td>       <td style="text-align:center;">0.75 &#x00B1; 0.03</td>       <td style="text-align:center;">0.78 &#x00B1; 0.05</td>       <td>0.88 &#x00B1; 0.03</td>       </tr>       <tr>       <td style="text-align:left;">Syntax</td>       <td style="text-align:center;">ME</td>       <td style="text-align:center;">0.70 &#x00B1; 0.04</td>       <td style="text-align:center;">0.68 &#x00B1; 0.03</td>       <td style="text-align:center;">0.68 &#x00B1; 0.07</td>       <td style="text-align:center;">0.73 &#x00B1; 0.04</td>       <td style="text-align:center;">0.58 &#x00B1; 0.04</td>       <td style="text-align:center;">0.55 &#x00B1; 0.06</td>       <td style="text-align:center;">0.59 &#x00B1; 0.05</td>       <td>0.60 &#x00B1; 0.04</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">RF</td>       <td style="text-align:center;">0.68 &#x00B1; 0.04</td>       <td style="text-align:center;">0.65 &#x00B1; 0.06</td>       <td style="text-align:center;">0.63 &#x00B1; 0.05</td>       <td style="text-align:center;">0.77 &#x00B1; 0.03</td>       <td style="text-align:center;">0.57 &#x00B1; 0.03</td>       <td style="text-align:center;">0.54 &#x00B1; 0.05</td>       <td style="text-align:center;">0.61 &#x00B1; 0.05</td>       <td>0.57 &#x00B1; 0.03</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">LSTM</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.75 &#x00B1; 0.04</strong>       </td>       <td style="text-align:center;">0.72 &#x00B1; 0.03</td>       <td style="text-align:center;">0.72 &#x00B1; 0.08</td>       <td style="text-align:center;">0.82 &#x00B1; 0.05</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.85 &#x00B1; 0.02</strong>       </td>       <td style="text-align:center;">0.79 &#x00B1; 0.04</td>       <td style="text-align:center;">0.86 &#x00B1; 0.03</td>       <td>0.89 &#x00B1; 0.02</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">CNN</td>       <td style="text-align:center;">0.72 &#x00B1; 0.04</td>       <td style="text-align:center;">0.70 &#x00B1; 0.06</td>       <td style="text-align:center;">0.69 &#x00B1; 0.10</td>       <td style="text-align:center;">0.78 &#x00B1; 0.02</td>       <td style="text-align:center;">0.77 &#x00B1; 0.02</td>       <td style="text-align:center;">0.69 &#x00B1; 0.03</td>       <td style="text-align:center;">0.76 &#x00B1; 0.02</td>       <td>0.87 &#x00B1; 0.02</td>       </tr>       <tr>       <td style="text-align:left;">Style</td>       <td style="text-align:center;">ME</td>       <td style="text-align:center;">0.50 &#x00B1; 0.09</td>       <td style="text-align:center;">0.35 &#x00B1; 0.15</td>       <td style="text-align:center;">0.63 &#x00B1; 0.02</td>       <td style="text-align:center;">0.51 &#x00B1; 0.16</td>       <td style="text-align:center;">0.57 &#x00B1; 0.04</td>       <td style="text-align:center;">0.44 &#x00B1; 0.08</td>       <td style="text-align:center;">0.62 &#x00B1; 0.04</td>       <td>0.64 &#x00B1; 0.02</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">RF</td>       <td style="text-align:center;">0.53 &#x00B1; 0.07</td>       <td style="text-align:center;">0.51 &#x00B1; 0.09</td>       <td style="text-align:center;">0.58 &#x00B1; 0.10</td>       <td style="text-align:center;">0.49 &#x00B1; 0.03</td>       <td style="text-align:center;">0.61 &#x00B1; 0.04</td>       <td style="text-align:center;">0.54 &#x00B1; 0.06</td>       <td style="text-align:center;">0.67 &#x00B1; 0.06</td>       <td>0.61 &#x00B1; 0.06</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">LSTM</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.66 &#x00B1; 0.06</strong>       </td>       <td style="text-align:center;">0.67 &#x00B1; 0.06</td>       <td style="text-align:center;">0.65 &#x00B1; 0.07</td>       <td style="text-align:center;">0.68 &#x00B1; 0.08</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.84 &#x00B1; 0.01</strong>       </td>       <td style="text-align:center;">0.78 &#x00B1; 0.03</td>       <td style="text-align:center;">0.84 &#x00B1; 0.02</td>       <td>0.89 &#x00B1; 0.02</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">CNN</td>       <td style="text-align:center;">0.54 &#x00B1; 0.06</td>       <td style="text-align:center;">0.48 &#x00B1; 0.10</td>       <td style="text-align:center;">0.63 &#x00B1; 0.05</td>       <td style="text-align:center;">0.52 &#x00B1; 0.06</td>       <td style="text-align:center;">0.74 &#x00B1; 0.05</td>       <td style="text-align:center;">0.66 &#x00B1; 0.08</td>       <td style="text-align:center;">0.74 &#x00B1; 0.04</td>       <td>0.83 &#x00B1; 0.05</td>       </tr>       <tr>       <td style="text-align:left;">Connotations</td>       <td style="text-align:center;">ME</td>       <td style="text-align:center;">0.43 &#x00B1; 0.03</td>       <td style="text-align:center;">0.36 &#x00B1; 0.08</td>       <td style="text-align:center;">0.44 &#x00B1; 0.07</td>       <td style="text-align:center;">0.49 &#x00B1; 0.04</td>       <td style="text-align:center;">0.39 &#x00B1; 0.04</td>       <td style="text-align:center;">0.57 &#x00B1; 0.05</td>       <td style="text-align:center;">0.11 &#x00B1; 0.12</td>       <td>0.49 &#x00B1; 0.03</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">RF</td>       <td style="text-align:center;">0.40 &#x00B1; 0.08</td>       <td style="text-align:center;">0.39 &#x00B1; 0.15</td>       <td style="text-align:center;">0.39 &#x00B1; 0.10</td>       <td style="text-align:center;">0.42 &#x00B1; 0.06</td>       <td style="text-align:center;">0.41 &#x00B1; 0.05</td>       <td style="text-align:center;">0.57 &#x00B1; 0.04</td>       <td style="text-align:center;">0.21 &#x00B1; 0.11</td>       <td>0.44 &#x00B1; 0.04</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">LSTM</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.67 &#x00B1; 0.03</strong>       </td>       <td style="text-align:center;">0.67 &#x00B1; 0.04</td>       <td style="text-align:center;">0.65 &#x00B1; 0.05</td>       <td style="text-align:center;">0.69 &#x00B1; 0.02</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.85 &#x00B1; 0.02</strong>       </td>       <td style="text-align:center;">0.79 &#x00B1; 0.03</td>       <td style="text-align:center;">0.85 &#x00B1; 0.03</td>       <td>0.90 &#x00B1; 0.03</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">CNN</td>       <td style="text-align:center;">0.61 &#x00B1; 0.02</td>       <td style="text-align:center;">0.57 &#x00B1; 0.05</td>       <td style="text-align:center;">0.57 &#x00B1; 0.05</td>       <td style="text-align:center;">0.70 &#x00B1; 0.06</td>       <td style="text-align:center;">0.75 &#x00B1; 0.04</td>       <td style="text-align:center;">0.66 &#x00B1; 0.06</td>       <td style="text-align:center;">0.74 &#x00B1; 0.08</td>       <td>0.85 &#x00B1; 0.01</td>       </tr>       <tr>       <td style="text-align:left;">Lexicons</td>       <td style="text-align:center;">ME</td>       <td style="text-align:center;">0.53 &#x00B1; 0.06</td>       <td style="text-align:center;">0.34 &#x00B1; 0.13</td>       <td style="text-align:center;">0.63 &#x00B1; 0.04</td>       <td style="text-align:center;">0.62 &#x00B1; 0.04</td>       <td style="text-align:center;">0.57 &#x00B1; 0.03</td>       <td style="text-align:center;">0.51 &#x00B1; 0.07</td>       <td style="text-align:center;">0.59 &#x00B1; 0.05</td>       <td>0.61 &#x00B1; 0.04</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">RF</td>       <td style="text-align:center;">0.58 &#x00B1; 0.03</td>       <td style="text-align:center;">0.54 &#x00B1; 0.04</td>       <td style="text-align:center;">0.62 &#x00B1; 0.02</td>       <td style="text-align:center;">0.59 &#x00B1; 0.06</td>       <td style="text-align:center;">0.63 &#x00B1; 0.04</td>       <td style="text-align:center;">0.58 &#x00B1; 0.06</td>       <td style="text-align:center;">0.65 &#x00B1; 0.06</td>       <td>0.66 &#x00B1; 0.05</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">LSTM</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.67 &#x00B1; 0.04</strong>       </td>       <td style="text-align:center;">0.66 &#x00B1; 0.04</td>       <td style="text-align:center;">0.66 &#x00B1; 0.05</td>       <td style="text-align:center;">0.70 &#x00B1; 0.03</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.85 &#x00B1; 0.04</strong>       </td>       <td style="text-align:center;">0.80 &#x00B1; 0.04</td>       <td style="text-align:center;">0.85 &#x00B1; 0.03</td>       <td>0.90 &#x00B1; 0.04</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">CNN</td>       <td style="text-align:center;">0.64 &#x00B1; 0.04</td>       <td style="text-align:center;">0.65 &#x00B1; 0.03</td>       <td style="text-align:center;">0.57 &#x00B1; 0.07</td>       <td style="text-align:center;">0.70 &#x00B1; 0.07</td>       <td style="text-align:center;">0.76 &#x00B1; 0.04</td>       <td style="text-align:center;">0.68 &#x00B1; 0.06</td>       <td style="text-align:center;">0.76 &#x00B1; 0.05</td>       <td>0.85 &#x00B1; 0.02</td>       </tr>       <tr>       <td style="text-align:left;">ALL</td>       <td style="text-align:center;">ME</td>       <td style="text-align:center;">0.57 &#x00B1; 0.01</td>       <td style="text-align:center;">0.64 &#x00B1; 0.04</td>       <td style="text-align:center;">0.67 &#x00B1; 0.03</td>       <td style="text-align:center;">0.40 &#x00B1; 0.04</td>       <td style="text-align:center;">0.72 &#x00B1; 0.04</td>       <td style="text-align:center;">0.62 &#x00B1; 0.07</td>       <td style="text-align:center;">0.76 &#x00B1; 0.05</td>       <td>0.79 &#x00B1; 0.03</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">RF</td>       <td style="text-align:center;" bgcolor="gray">0.81 &#x00B1; 0.03</td>       <td style="text-align:center;">0.74 &#x00B1; 0.06</td>       <td style="text-align:center;">0.73 &#x00B1; 0.04</td>       <td style="text-align:center;">        <strong>0.96 &#x00B1; 0.03</strong>       </td>       <td style="text-align:center;">0.74 &#x00B1; 0.04</td>       <td style="text-align:center;">0.68 &#x00B1; 0.05</td>       <td style="text-align:center;">0.74 &#x00B1; 0.06</td>       <td>0.80 &#x00B1; 0.03</td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">LSTM</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.81 &#x00B1; 0.05</strong>       </td>       <td style="text-align:center;">0.76 &#x00B1; 0.06</td>       <td style="text-align:center;">0.76 &#x00B1; 0.08</td>       <td style="text-align:center;">0.91 &#x00B1; 0.02</td>       <td style="text-align:center;" bgcolor="gray"><strong>0.86 &#x00B1; 0.03</strong>       </td>       <td style="text-align:center;">0.81 &#x00B1; 0.04</td>       <td style="text-align:center;">0.86 &#x00B1; 0.06</td>       <td>        <strong>0.92 &#x00B1; 0.01</strong>       </td>       </tr>       <tr>       <td style="text-align:left;"/>       <td style="text-align:center;">CNN</td>       <td style="text-align:center;">0.74 &#x00B1; 0.12</td>       <td style="text-align:center;">0.66 &#x00B1; 0.14</td>       <td style="text-align:center;">0.70 &#x00B1; 0.16</td>       <td style="text-align:center;">0.86 &#x00B1; 0.05</td>       <td style="text-align:center;">0.78 &#x00B1; 0.03</td>       <td style="text-align:center;">0.71 &#x00B1; 0.05</td>       <td style="text-align:center;">0.78 &#x00B1; 0.04</td>       <td>0.86 &#x00B1; 0.01</td>       </tr>      </tbody>     </table>    </div>    <p>     <strong>Writer &#x2192; Agent</strong>. Authors of disinformation express positive perspectives about <em>Europe, Ukraine</em>, and negative perspectives about <em>Obama and Clinton</em> agents; mixed perspectives (both positive and negative) are expressed toward <em>Russia, Washington,</em> and <em>West</em>. In contrast, writers of propaganda express positive connotations toward <em>military, Monsanto, bill</em> agents but negative perspectives toward <em>terrorists, Syria</em> and <em>CIA</em>; mixed perspectives expressed toward <em>government, Israel</em>. Writers of hoaxes express positive connotations toward <em>congress, court, authorities</em> agents, and negative perspectives toward <em>democrats, liberals, terrorists</em>.</p>    <p>     <strong>Writer &#x2192; Theme</strong>. Authors of disinformation express positive perspectives about <em>forces, power, law,</em> and <em>money</em> themes, and negative perspectives about <em>Turkey</em> and <em>strikes</em>; mixed perspectives are expressed about <em>terror, sanctions</em>. Writers of propaganda express positive perspectives about <em>truth, idea, power</em> themes, and negative connotations toward <em>Syria</em>. Finally, hoax writers express positive connotations toward <em>truth, police, order</em> themes, and negative connotations toward <em>government</em>.</p>    <p>     <strong>Implications of Connotation Analysis</strong>. Note, our connotation analysis combines quantitative and qualitative methods: first, we automatically parse tweets to extract agents, verbs, and themes; then we get a quantitative estimate of targeted perspectives (connotations) driven by the verb toward each agent and theme of deceptive statement; third, we qualitatively visualize positive vs. negative perspectives toward agents and themes across deception types. Such two-fold analysis allows us to demonstrate how agents and themes of strategic deception vary across deception types, and, as a result, qualitatively identify the hidden agenda of content from propaganda vs. disinformation vs. hoax tweets over the same time period. Such differences in hidden agenda may drive deeper insights about (a) intent behind deceptive content shared online and (b) targeted audiences influenced by such deceptive content.</p>    <p>Furthermore, our findings on connotations behind deceptive content online will contribute to research on misinformation propagation in social networks by identifying gatekeepers and persistent minorities, e.g., trolls and bots that potentially spread deceptive content&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0038">38</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0060">60</a>].</p>    </section>    <section id="sec-20">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.3</span> Prediction Results</h3>     </div>    </header>    <p>Tables&#x00A0;<a class="tbl" href="#tab3">3</a> and&#x00A0;<a class="tbl" href="#tab4">4</a> present prediction results for two disinformation strategies&#x2013;misleading vs. falsification&#x2013;and three deception types: propaganda, disinformation, and hoaxes, respectively. We report classification results obtained using the state-of-the-art models: MaxEntropy (ME), RandomForest (RF), Convolutional Neural Networks (CNN), and Long Short-Term Memory Networks (LSTM). We evaluate and contrast the predictive power of content, syntax, style, affect, and psycholinguistic signals across domains: summaries, webpages, and tweets. Content represents what is being discussed e.g., targeted topics, keywords; syntax and style represent how the content is being discussed; connotations and psycholinguistic signals represent how emotional the discussion is. We report model performance using the area under under the receiver operating characteristic (ROC) curve weighted, weighted F1 score, and F1 measures for each class.</p>    <p>Our best model for deception type prediction relies on content signals in combination with LSTM model yields F1 of .82 for webpages and F1 of .87 for tweets. Our best model for deception strategy detection relies on content combined with connotation signals incorporated into a CNN model yields F1 of .66 and ROC of .63 for summaries; content combined with lexicon signals incorporated into a LSTM model yields F1 of .57 and ROC of .63 for news pages; and content combined with either connotation or syntax signals incorporated into a LSTM model yields F1 of .82 and ROC of .93 for tweets. Our more detailed findings are shown below.</p>    <ul class="list-no-style">     <li id="list14" label="&#x2022;"><em>Psycholinguistic signals:</em> Unlike earlier work on deception detection in product reviews&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0036">36</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0039">39</a>], content combined with moral foundations and connotations are more predictive of deception strategies than syntactic and stylistic features. Interestingly, for predicting deception types (Table&#x00A0;<a class="tbl" href="#tab4">4</a>) content > syntax > connotations > style > lexicon signals. However, for predicting deception strategies (Table&#x00A0;<a class="tbl" href="#tab3">3</a>) connotations > lexicon > syntax > content > style.<br/></li>     <li id="list15" label="&#x2022;"><em>Predictive models:</em> As expected, neural network models e.g., CNNs and LSTMs achieve higher performance compared to baseline machine learning models.<br/></li>     <li id="list16" label="&#x2022;"><em>Deception types:</em> Disinformation (F1 is 0.96 for news pages, F1 is 0.92 for tweets) is less difficult to predict compared to propaganda (F1 is 0.76 for news pages, F1 is 0.83 for tweets) or hoaxes (F1 is 0.76 for news pages, F1 is 0.87 for tweets).<br/></li>     <li id="list17" label="&#x2022;"><em>Deception strategies:</em> As expected, deception strategies are more difficult to predict than deception types, even though it is a binary classification compared to 3-way classification. Falsification strategy is easier to infer than misleading strategy in news pages (F1 is 0.78 and 0.41, respectively) and disinformation summaries (F1 is 0.78 and 0.49, respectively). However, falsification strategy is as easy to classify as misleading strategy in tweets (F1 is 0.84 and 0.82, respectively). Syntax is more predictive in tweets, lexicons in news pages, and content in summaries. Content is the most predictive of misleading strategy across all domains.<br/></li>     <li id="list18" label="&#x2022;"><em>Domains:</em> Deception types, unlike deception strategies, are easier to identify in tweets (F1 is 0.87) than in news pages (F1 is 0.82).<br/></li>    </ul>    </section>   </section>   <section id="sec-21">    <header>    <div class="title-info">     <h2>      <span class="section-number">6</span> Summary and Discussion</h2>    </div>    </header>    <p>To the best of our knowledge, this is the first work that focused on building predictive models to infer deception types and strategies across multiple domains, regardless the topic or event in the deceptive message, by analyzing and incorporating psycholinguistic signals e.g., connotations and moral foundations behind deceptive news content into predictive models.</p>    <p>Recent work on fake news detection online and in social media has focused on developing models to distinguish between fake vs. verified content (binary classification)&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>], or estimating credibility level of the tweet or PolitiFact statement (regression)&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0050">50</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0062">62</a>]. These binary classification models achieve F1 between 78% for the news page domain&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>] and as high as 95% for social media&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0061">61</a>]. Regression models that predict the level of information credibility on Twitter&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>] achieve 68%, and models that predict credibility of PolitiFact statements achieve 65% and 27%, respectively&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0050">50</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0062">62</a>].</p>    <p>Only&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0061">61</a>] and&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0050">50</a>] analyzed language differences to build models for <em>classifying types of deceptive content</em>, e.g., propaganda, hoaxes, satire, and clickbaits. Our work not only goes beyond that by incorporating disinformation into multi-class models but also develops models for inferring whether the <em>statement is misleading or falsification</em>. Unlike <em>misinformation</em> e.g., hoaxes&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0058">58</a>], rumors&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>], and clickbaits that have been a target of recent research, <em>disinformation</em> is more difficult to capture and study even though it is more harmful and influential on our society. <em>Misinformation</em> is conveyed in the honest but mistaken belief that the relayed incorrect facts are true, <em>disinformation</em> denotes false facts that are conceived in order to deliberately deceive the audience. Finally, our study targets a very important issue of model generalizability that is often overlooked, and demonstrates how predictive models, linguistic and connotation analysis generalize across domains such as online news, disinformation statements, and social media.</p>    <p>In the future, we plan to extend our models to make predictions (a) across languages by relying on a multilingual connotation framework recently developed by&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0049">49</a>] and (b) across social media environments. Moreover, inspired by recent work&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>] that incorporates images from social media in addition to text to predict the clickbaitness (score between 0 and 1) of tweets, we plan to incorporate image signals into our approach.</p>   </section>   <section id="sec-22">    <header>    <div class="title-info">     <h2>Acknowledgments</h2>    </div>    </header>    <p>The research described in this paper was conducted under the Laboratory Directed Research and Development Program at Pacific Northwest National Laboratory, a multiprogram national laboratory operated by Battelle for the U.S. Department of Energy.</p>    <p>The authors would like to thank Hannah Rashkin from the University of Washington for her help with data collection and annotation, and anonymous reviewers for their helpful comments and suggestions.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">Darren&#x00A0;Scott Appling, Erica&#x00A0;J. Briscoe, and Clayton&#x00A0;J. Hutto. 2015. Discriminative Models for Predicting Deception Strategies. In <em>      <em>Proceedings of WWW</em>     </em>. 947&#x2013;952.</li>    <li id="BibPLXBIB0002" label="[2]">Eytan Bakshy, Jake&#x00A0;M Hofman, Winter&#x00A0;A Mason, and Duncan&#x00A0;J Watts. 2011. Everyone&#x0027;s an influencer: quantifying influence on twitter. In <em>      <em>Proceedings of WSDM</em>     </em>. 65&#x2013;74.</li>    <li id="BibPLXBIB0003" label="[3]">Erica&#x00A0;J Briscoe, D&#x00A0;Scott Appling, and Heather Hayes. 2014. Cues to deception in social media communications. In <em>      <em>International Conference on System Sciences</em>     </em>. 1435&#x2013;1443.</li>    <li id="BibPLXBIB0004" label="[4]">David&#x00A0;B Buller, Judee&#x00A0;K Burgoon, JA Daly, and JM Wiemann. 1994. Deception: Strategic and nonstrategic communication. <em>      <em>Strategic interpersonal communication</em>     </em>(1994), 191&#x2013;223.</li>    <li id="BibPLXBIB0005" label="[5]">Dallas Card, Amber&#x00A0;E Boydstun, Justin&#x00A0;H Gross, Philip Resnik, and Noah&#x00A0;A Smith. 2015. The media frames corpus: Annotations of frames across issues. In <em>      <em>Proceedings of ACL</em>     </em>. 438&#x2013;444.</li>    <li id="BibPLXBIB0006" label="[6]">Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information credibility on Twitter. In <em>      <em>Proceedings of WWW</em>     </em>. 675&#x2013;684.</li>    <li id="BibPLXBIB0007" label="[7]">Meeyoung Cha, Hamed Haddadi, Fabricio Benevenuto, and P&#x00A0;Krishna Gummadi. 2010. Measuring user influence in Twitter: The million follower fallacy.<em>      <em>Proceedings of ICWSM</em>     </em>10, 10-17 (2010), 30.</li>    <li id="BibPLXBIB0008" label="[8]">Justin Cheng, Cristian Danescu-Niculescu-Mizil, Jure Leskovec, and Michael Bernstein. 2017. Anyone Can Become a Troll. <em>      <em>American Scientist</em>     </em>105, 3 (2017), 152.</li>    <li id="BibPLXBIB0009" label="[9]">Eunsol Choi, Chenhao Tan, Lillian Lee, Cristian Danescu-Niculescu-Mizil, and Jennifer Spindel. 2012. Hedge detection as a lens on framing in the GMO debates: A position paper. In <em>      <em>Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics</em>     </em>. 70&#x2013;79.</li>    <li id="BibPLXBIB0010" label="[10]">Giovanni&#x00A0;Luca Ciampaglia, Prashant Shiralkar, Luis&#x00A0;M Rocha, Johan Bollen, Filippo Menczer, and Alessandro Flammini. 2015. Computational fact checking from knowledge networks. <em>      <em>PloS one</em>     </em>10, 6 (2015), e0128193.</li>    <li id="BibPLXBIB0011" label="[11]">Niall&#x00A0;J Conroy, Victoria&#x00A0;L Rubin, and Yimin Chen. 2015. Automatic deception detection: methods for finding fake news. <em>      <em>Proceedings of the Association for Information Science and Technology</em>     </em>52, 1(2015), 1&#x2013;4.</li>    <li id="BibPLXBIB0012" label="[12]">Bella&#x00A0;M DePaulo, James&#x00A0;J Lindsay, Brian&#x00A0;E Malone, Laura Muhlenbruck, Kelly Charlton, and Harris Cooper. 2003. Cues to deception.<em>      <em>Psychological bulletin</em>     </em>129, 1 (2003), 74.</li>    <li id="BibPLXBIB0013" label="[13]">Paul Ekman and Wallace&#x00A0;V Friesen. 1969. Nonverbal leakage and clues to deception. <em>      <em>Psychiatry</em>     </em>32, 1 (1969), 88&#x2013;106.</li>    <li id="BibPLXBIB0014" label="[14]">Song Feng, Ritwik Banerjee, and Yejin Choi. 2012. Syntactic stylometry for deception detection. In <em>      <em>Proceedings of ACL</em>     </em>. 171&#x2013;175.</li>    <li id="BibPLXBIB0015" label="[15]">Song Feng, Longfei Xing, Anupam Gogar, and Yejin Choi. 2012. Distributional Footprints of Deceptive Product Reviews. <em>      <em>Proceedings of ICWSM</em>     </em>12(2012), 98&#x2013;105.</li>    <li id="BibPLXBIB0016" label="[16]">Emilio Ferrara. 2017. Disinformation and social bot operations in the run up to the 2017 French presidential election. (2017).</li>    <li id="BibPLXBIB0017" label="[17]">Eileen Fitzpatrick and Joan Bachenko. 2012. Building a data collection for deception research. In <em>      <em>Proceedings of the Workshop on Computational Approaches to Deception Detection</em>     </em>. 31&#x2013;38.</li>    <li id="BibPLXBIB0018" label="[18]">Fortune. 2016. Fake Bloomberg news report drives Twitter stock up 8%. http://fortune.com/2015/07/14/fake-twitter-bloomberg-report/. (2016). Accessed: 2016-12-12.</li>    <li id="BibPLXBIB0019" label="[19]">Maria Glenski, Ellyn Ayton, Dustin Arendt, and Svitlana Volkova. 2017. Fishing for Clickbaits in Social Images and Texts with Linguistically-Infused Neural Network Models. <em>      <em>arXiv preprint arXiv:1710.06390</em>     </em>(2017).</li>    <li id="BibPLXBIB0020" label="[20]">Jesse Graham, Jonathan Haidt, and Brian&#x00A0;A Nosek. 2009. Liberals and conservatives rely on different sets of moral foundations.<em>      <em>Journal of Personality and Social Psychology</em>     </em>96, 5(2009), 1029.</li>    <li id="BibPLXBIB0021" label="[21]">Guardian. 2015. Woman dies after taking &#x201D;diet pills&#x201D; bought over internet. <a class="link-inline force-break"      href="https://www.theguardian.com/society/2015/apr/21/woman-dies-after-taking-diet-pills-bought-over-internet">https://www.theguardian.com/society/2015/apr/21/woman-dies-after-taking-diet-pills-bought-over-internet</a>. (2015).</li>    <li id="BibPLXBIB0022" label="[22]">Jonathan Haidt and Jesse Graham. 2007. When morality opposes justice: Conservatives have moral intuitions that liberals may not recognize. <em>      <em>Social Justice Research</em>     </em>20, 1 (2007), 98&#x2013;116.</li>    <li id="BibPLXBIB0023" label="[23]">Jonathan Haidt and Craig Joseph. 2004. Intuitive ethics: How innately prepared intuitions generate culturally variable virtues. <em>      <em>Daedalus</em>     </em>133, 4 (2004), 55&#x2013;66.</li>    <li id="BibPLXBIB0024" label="[24]">Joan&#x00A0;B. Hooper. 1975. On assertive predicates. In <em>      <em>Syntax and Semantics</em>     </em>, J.&#x00A0;Kimball (Ed.). Vol.&#x00A0;4. 91&#x2013;124.</li>    <li id="BibPLXBIB0025" label="[25]">Lee Howell. 2013. Digital wildfires in a hyperconnected world. <em>      <em>WEF Report</em>     </em> (2013).</li>    <li id="BibPLXBIB0026" label="[26]">Ken Hyland. 2005. <em>      <em>Metadiscourse</em>     </em>. Wiley Online Library.</li>    <li id="BibPLXBIB0027" label="[27]">Fang Jin, Wei Wang, Liang Zhao, Edward Dougherty, Yang Cao, Chang-Tien Lu, and Naren Ramakrishnan. 2014. Misinformation propagation in the age of Twitter. <em>      <em>Computer</em>     </em>47, 12 (2014), 90&#x2013;94.</li>    <li id="BibPLXBIB0028" label="[28]">Lauri Karttunen. 1971. Implicative verbs. <em>      <em>Language</em>     </em> (1971), 340&#x2013;358.</li>    <li id="BibPLXBIB0029" label="[29]">Paul Kiparsky and Carol Kiparsky. 1968. <em>      <em>Fact</em>     </em>. Indiana University.</li>    <li id="BibPLXBIB0030" label="[30]">Srijan Kumar, Robert West, and Jure Leskovec. 2016. Disinformation on the Web: Impact, Characteristics, and Detection of Wikipedia Hoaxes. In <em>      <em>Proceedings of WWW</em>     </em>. 591&#x2013;602.</li>    <li id="BibPLXBIB0031" label="[31]">Kenton Lee, Yoav Artzi, Yejin Choi, and Luke Zettlemoyer. 2015. Event Detection and Factuality Assessment with Non-Expert Supervision. <em>      <em>Proceedings of EMNLP</em>     </em>(2015).</li>    <li id="BibPLXBIB0032" label="[32]">Newton Lee. 2014. Misinformation and Disinformation. In <em>      <em>Facebook Nation</em>     </em>. Springer, 169&#x2013;188.</li>    <li id="BibPLXBIB0033" label="[33]">Kristina Lerman and Rumi Ghosh. 2010. Information contagion: An empirical study of the spread of news on Digg and Twitter social networks.<em>      <em>Proceedings of ICWSM</em>     </em>(2010), 90&#x2013;97.</li>    <li id="BibPLXBIB0034" label="[34]">Cristian Lumezanu, Nick Feamster, and Hans Klein. 2012. # bias: Measuring the tweeting behavior of propagandists. (2012).</li>    <li id="BibPLXBIB0035" label="[35]">Feamster Lumezanu and H Klein. 2012. Measuring the tweeting behavior of propagandists. In <em>      <em>Proceedings of ICWSM</em>     </em>.</li>    <li id="BibPLXBIB0036" label="[36]">Rada Mihalcea and Carlo Strapparava. 2009. The lie detector: Explorations in the automatic recognition of deceptive language. In <em>      <em>Proceedings of the ACL-IJCNLP</em>     </em>. 309&#x2013;312.</li>    <li id="BibPLXBIB0037" label="[37]">Tanushree Mitra, Graham&#x00A0;P Wright, and Eric Gilbert. 2017. A parsimonious language model of social media credibility across disparate events. In <em>      <em>Proceedings of CSCW</em>     </em>. 126&#x2013;145.</li>    <li id="BibPLXBIB0038" label="[38]">Bjarke M&#x00F8;nsted, Piotr Sapie&#x017C;y&#x0144;ski, Emilio Ferrara, and Sune Lehmann. 2017. Evidence of complex contagion of information in social media: An experiment using Twitter bots. <em>      <em>PLOS ONE</em>     </em>12, 9 (09 2017), 1&#x2013;12. <a class="link-inline force-break"      href="https://doi.org/10.1371/journal.pone.0184148"      target="_blank">https://doi.org/10.1371/journal.pone.0184148</a></li>    <li id="BibPLXBIB0039" label="[39]">Matthew&#x00A0;L Newman, James&#x00A0;W Pennebaker, Diane&#x00A0;S Berry, and Jane&#x00A0;M Richards. 2003. Lying words: Predicting deception from linguistic styles. <em>      <em>Personality and social psychology bulletin</em>     </em>29, 5 (2003), 665&#x2013;675.</li>    <li id="BibPLXBIB0040" label="[40]">NYTimes. 2016. Google and Facebook Take Aim at Fake News Sites. http://www.nytimes.com/2016/11/15/technology/google-will-ban-websites-that-host-fake-news-from-using-its-ad-service.html. (2016).</li>    <li id="BibPLXBIB0041" label="[41]">Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey&#x00A0;T Hancock. 2011. Finding deceptive opinion spam by any stretch of the imagination. In <em>      <em>Proceedings of ACL-HLT</em>     </em>. 309&#x2013;319.</li>    <li id="BibPLXBIB0042" label="[42]">F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. <em>      <em>Journal of Machine Learning Research</em>     </em>12 (2011), 2825&#x2013;2830.</li>    <li id="BibPLXBIB0043" label="[43]">James&#x00A0;W Pennebaker, Martha&#x00A0;E Francis, and Roger&#x00A0;J Booth. 2001. Linguistic inquiry and word count: LIWC 2001. <em>      <em>Mahway: Lawrence Erlbaum Associates</em>     </em>71 (2001), 2001.</li>    <li id="BibPLXBIB0044" label="[44]">Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word representation. In <em>      <em>Proceedings EMNLP</em>     </em>. 1532&#x2013;1543.</li>    <li id="BibPLXBIB0045" label="[45]">Ver&#x00F3;nica P&#x00E9;rez-Rosas, Bennett Kleinberg, Alexandra Lefevre, and Rada Mihalcea. 2017. Automatic Detection of Fake News. <em>      <em>arXiv preprint arXiv:1708.07104</em>     </em>(2017).</li>    <li id="BibPLXBIB0046" label="[46]">Ver&#x00F3;nica P&#x00E9;rez-Rosas and Rada Mihalcea. 2015. Experiments in Open Domain Deception Detection. <em>      <em>Proceedings of EMNLP</em>     </em>(2015), 1120&#x2013;1125.</li>    <li id="BibPLXBIB0047" label="[47]">Slav Petrov. 2016. Announcing SyntaxNet: The World&#x0027;s Most Accurate Parser Goes Open Source. <em>      <em>Google Research Blog, May</em>     </em>12 (2016), 2016.</li>    <li id="BibPLXBIB0048" label="[48]">Vahed Qazvinian, Emily Rosengren, Dragomir&#x00A0;R Radev, and Qiaozhu Mei. 2011. Rumor has it: Identifying misinformation in microblogs. In <em>      <em>Proceedings of EMNLP</em>     </em>. 1589&#x2013;1599.</li>    <li id="BibPLXBIB0049" label="[49]">Hannah Rashkin, Eric Bell, Yejin Choi, and Svitlana Volkova. 2017. Multilingual Connotation Frames: A Case Study on Social Media for Targeted Sentiment Analysis and Forecast. In <em>      <em>Proceedings of ACL</em>     </em>, Vol.&#x00A0;2. 459&#x2013;464.</li>    <li id="BibPLXBIB0050" label="[50]">Hannah Rashkin, Eunsol Choi, Jin&#x00A0;Yea Jang, Svitlana Volkova, and Yejin Choi. 2017. Truth of varying shades: Analyzing language in fake news and political fact-checking. In <em>      <em>Proceedings of EMNLP</em>     </em>. 2921&#x2013;2927.</li>    <li id="BibPLXBIB0051" label="[51]">Hannah Rashkin, Sameer Singh, and Yejin Choi. 2016. Connotation Frames: A Data-Driven Investigation. In <em>      <em>Proceedings of ACL</em>     </em>. 311&#x2013;321.</li>    <li id="BibPLXBIB0052" label="[52]">Marta Recasens, Cristian Danescu-Niculescu-Mizil, and Dan Jurafsky. 2013. Linguistic Models for Analyzing and Detecting Biased Language. In <em>      <em>Proceedings of ACL</em>     </em>. 1650&#x2013;1659.</li>    <li id="BibPLXBIB0053" label="[53]">Victoria&#x00A0;L Rubin. 2010. On deception and deception detection: Content analysis of computer-mediated stated beliefs. <em>      <em>Proceedings of the American Society for Information Science and Technology</em>     </em>47, 1 (2010), 1&#x2013;10.</li>    <li id="BibPLXBIB0054" label="[54]">Victoria&#x00A0;L Rubin, Yimin Chen, and Niall&#x00A0;J Conroy. 2015. Deception detection for news: three types of fakes. <em>      <em>Proceedings of the Association for Information Science and Technology</em>     </em>52, 1(2015), 1&#x2013;4.</li>    <li id="BibPLXBIB0055" label="[55]">Victoria&#x00A0;L Rubin, Niall&#x00A0;J Conroy, Yimin Chen, and Sarah Cornwell. 2016. Fake News or Truth? Using Satirical Cues to Detect Potentially Misleading News. In <em>      <em>Proceedings of NAACL-HLT</em>     </em>. 7&#x2013;17.</li>    <li id="BibPLXBIB0056" label="[56]">Kate Starbird. 2017. Examining the Alternative Media Ecosystem Through the Production of Alternative Narratives of Mass Shooting Events on Twitter. In <em>      <em>Proceedings of ICWSM</em>     </em>. 230&#x2013;239.</li>    <li id="BibPLXBIB0057" label="[57]">Bruno Takahashi, Edson&#x00A0;C Tandoc, and Christine Carmichael. 2015. Communicating on Twitter during a disaster: An analysis of tweets during Typhoon Haiyan in the Philippines. <em>      <em>Computers in Human Behavior</em>     </em>50 (2015), 392&#x2013;398.</li>    <li id="BibPLXBIB0058" label="[58]">Marcella Tambuscio, Giancarlo Ruffo, Alessandro Flammini, and Filippo Menczer. 2015. Fact-checking effect on viral hoaxes: A model of misinformation spread in social networks. In <em>      <em>Proceedings of WWW</em>     </em>. 977&#x2013;982.</li>    <li id="BibPLXBIB0059" label="[59]">Michail Tsikerdekis and Sherali Zeadally. 2014. Online deception in social media. <em>      <em>Commun. ACM</em>     </em>57, 9 (2014), 72&#x2013;80.</li>    <li id="BibPLXBIB0060" label="[60]">Onur Varol, Emilio Ferrara, Clayton&#x00A0;A Davis, Filippo Menczer, and Alessandro Flammini. 2017. Online human-bot interactions: Detection, estimation, and characterization. In <em>      <em>Proceedings of ICWSM</em>     </em>. 280&#x2013;289.</li>    <li id="BibPLXBIB0061" label="[61]">Svitlana Volkova, Kyle Shaffer, Jin&#x00A0;Yean Jang, and Nathan Hodas. 2017. Separating Facts from Fiction: Linguistic Models to Classify Suspicious and Trusted News Posts on Twitter. In <em>      <em>Proceedings of ACL</em>     </em>. 647&#x2013;653.</li>    <li id="BibPLXBIB0062" label="[62]">William&#x00A0;Yang Wang. 2017. &#x201D;Liar, Liar Pants on Fire&#x201D;: A New Benchmark Dataset for Fake News Detection. In <em>      <em>Proceedings of ACL</em>     </em>. 422&#x2013;426.</li>    <li id="BibPLXBIB0063" label="[63]">Miron Zuckerman, Richard Koestner, and Robert Driver. 1981. Beliefs about cues associated with deception. <em>      <em>Journal of Nonverbal Behavior</em>     </em>6, 2 (1981), 105&#x2013;114.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>now at Korea Electronics Technology Institute (KETI)</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a>Disproof: Austria and Slovenia don&#x0027;t have common borders with Serbia.</p>   <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a>No proofs given.</p>   <p id="fn4"><a href="#foot-fn4"><sup>3</sup></a><a class="link-inline force-break"      href="https://github.com/tensorflow/models/tree/master/syntaxnet">https://github.com/tensorflow/models/tree/master/syntaxnet</a></p>   <p id="fn5"><a href="#foot-fn5"><sup>4</sup></a><a class="link-inline force-break"      href="https://keras.io/">https://keras.io/</a></p>   <p id="fn6"><a href="#foot-fn6"><sup>5</sup></a><a class="link-inline force-break"      href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScalar.html">http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScalar.html</a></p>   <p id="fn7"><a href="#foot-fn7"><sup>6</sup></a><a class="link-inline force-break"      href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html">http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html</a></p>   <p id="fn8"><a href="#foot-fn8"><sup>7</sup></a><a class="link-inline force-break"      href="https://github.com/nltk/nltk_contrib/tree/master/nltk_contrib/readability">https://github.com/nltk/nltk_contrib/tree/master/nltk_contrib/readability</a></p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3188728">https://doi.org/10.1145/3184558.3188728</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
