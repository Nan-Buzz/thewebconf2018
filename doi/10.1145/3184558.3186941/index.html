<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Siamese Cookie Embedding Networks for Cross-Device User Matching</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Siamese Cookie Embedding Networks for Cross-Device User Matching</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Ugo</span>      <span class="surName">Tanielian</span>     Criteo Research, <a href="mailto:u.tanielian@criteo.com">u.tanielian@criteo.com</a>     </div>     <div class="author">     <span class="givenName">Anne-Marie</span>      <span class="surName">Tousch</span>     Criteo Research, <a href="mailto:am.tousch@criteo.com">am.tousch@criteo.com</a>     </div>     <div class="author">     <span class="givenName">Flavian</span>      <span class="surName">Vasile</span>     Criteo Research, <a href="mailto:f.vasile@criteo.com">f.vasile@criteo.com</a>     </div>                 </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3186941" target="_blank">https://doi.org/10.1145/3184558.3186941</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Over the last decade, the number of devices per person has increased substantially. This poses a challenge for cookie-based personalization applications, such as online search and advertising, as it narrows the personalization signal to a single device environment. A key task is to find which cookies belong to the same person to recover a complete cross-device user journey. Recent work on the topic has shown the benefits of using unsupervised embeddings learned on user event sequences. In this paper, we extend this approach to a supervised setting and introduce the <em>Siamese Cookie Embedding Network</em> (<em>SCEmNet</em>), a siamese convolutional architecture that leverages the multi-modal aspect of sequences, and show significant improvement over the state-of-the-art.</small>     </p>    </div>    <div class="classifications">     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Ugo Tanielian, Anne-Marie Tousch, and Flavian Vasile. 2018. Siamese Cookie Embedding Networks for Cross-Device User Matching. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 2 Pages. <a href="https://doi.org/10.1145/3184558.3186941" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3186941</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>The cross-device matching task has been addressed recently in the literature, most notably within the scope of the ICDM 2015<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> challenge and the CIKM Cup 2016<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>.</p>    <p>The winners of the CIKM Cup [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>] proposed using neural features to describe sequences of URL tokens. Their approach is based on a hierarchical <em>doc2vec</em> model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>]. However, in real world settings, <em>doc2vec</em> suffers from several drawbacks: first, <em>doc2vec</em> generates unsupervised sequence embeddings that are not specialized for the final task; secondly, <em>doc2vec</em> generates embeddings only for sequences available at training time.</p>    <p>In our approach, we propose to use the <em>TextCNN</em> structure as in Kim [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] in a siamese network to learn cookie similarities with different types of sequences. Using a supervised approach allows us to reach better performance than the state-of-the-art. Furthermore, our approach is able to match cookies unseen at training time.</p>    <p>Our main contribution is a new architecture for the problem of cookie matching, the <em>SCEmNet</em> structure, and its wide&#x0026;deep counterpart (<em>JSCEmNet</em>) that address the shortcomings of previous embedded-based works.</p>   </section>   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Our approach</h2>     </div>    </header>    <section id="sec-6">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Context</h3>     </div>     </header>     <p>We evaluate our approach on a cross-device matching data set that was released for the CIKM Cup in 2016. The description of the data set can be found in Phan et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>]. The data set is composed of about 339k cookies and more than 506k ground truth pairs in training. The task is to find the 215k true pairs linking the users in test. For each cookie, the data set contains a sequence of events, where an event is a pair (URL, timestamp). The evaluation metrics of the challenge are precision, recall, and F1-score.</p>     <p>For a given set of cookies, the aim is then to compute a list of pairs of matched users. Since evaluating all possible pairs between <em>n</em> cookies results in <em>O</em>(<em>n</em>     <sup>2</sup>) operations, a classical 2-step approach is to have a candidate pair generation followed by pairwise ranking trained on ground truth data.</p>     <p>In the first step, we use a cookie representation similar to&#x00A0;Phan et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>] with k-nearest-neighbors to generate the candidate pairs. For the ranking step, we first implemented a baseline ranking algorithm. For each of the candidate pairs, we generate a set of <em>Baseline features</em>: some features are based on URL sequences such as TF, TF-IDF similarities, term-matching features and <em>doc2vec</em> embedding similarities, while other features are time-related features. For better results, we introduce our supervised <em>SCEmNet</em> architecture.</p>    </section>    <section id="sec-7">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span>       <em>SCEmNet</em> Architecture</h3>     </div>     </header>     <p>Our similarity learning architecture is based on convolutional networks and is illustrated in Figure&#x00A0;<a class="fig" href="#fig1">1</a>. We rely on the assumption that each cookie <strong>c</strong> is associated with <em>M</em> sequences (<strong>s<sub>1</sub>(c), ..., s<sub>M</sub>(c)</strong>) of fixed size. For a given token modality, the sequence of tokens is first processed through a <em>SeqCNN</em> module, similar to the <em>TextCNN</em> architecture introduced in&#x00A0;Kim [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>]: given an input sequence of embedded tokens, a convolutional network with one convolution, max-pooling and dropout layer outputs a <em>cookie embedding</em>. We use this module in a siamese network with a pairwise fusion layer to transform the two cookie embeddings into a single <em>pair embedding</em>. Therefore, each one of the <em>M</em> modalities yields a distinct pair embedding. The <em>M</em> pair embeddings are combined in the multi-modal fusion layer. Finally, an output layer is learned to link the multi-modal pair embedding to the final similarity score. <figure id="fig1">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186941/images/www18companion-181-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 1:</span>       <span class="figure-title">        <em>SCEmNet</em> architecture: fusionning several pair embeddings to get a richer one.</span>      </div>     </figure>     </p>     <p>The <em>SCEmNet</em> structure can therefore be trained independently to output a likelihood that a given pair is a true pair and then be used as a feature in addition to the other pre-computed <em>Baseline features</em> in a logistic regression. Or, similarly to the Wide &#x0026; Deep architecture used in Cheng et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>], we propose to learn <em>SCEmNet</em> jointly with the logistic regression weights of the <em>Baseline features</em>: we call this the <em>JSCEmNet</em> structure.</p>    </section>   </section>   <section id="sec-8">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Experiments and Results</h2>     </div>    </header>    <p>For the <em>SCEmNet</em> implementation, we fixed the different filter sizes to be (2, 3, 4, 5, 6, 10) and the number of filters per size at 40. The dropout probability was set at 0.5 for training and 0 for test. Negative pairs were sampled from the set of candidate pairs not present in the list of ground truth pairs. Training a multi-modal <em>SCEmNet</em>, where <em>M</em> = 4 with sequences generated from URLs at different depths, resulted in learning richer pair embeddings. Regarding the merging of cookie embeddings, we found that using element wise multiplication for the fusion layer and concatenation for the multi-modal layer improved the results.</p>    <div class="table-responsive" id="tab1">     <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Note that these results are computed using only 50% of the correct pairs as in the CIKM cup setup. Training the <em>SCEmNet</em> structure jointly with other features is the most efficient method. Here, Baseline refers to the Baseline features defined previously.</span>     </div>     <table class="table">     <tbody>      <tr>       <td style="text-align:left;">Method</td>       <td style="text-align:center;">Precision</td>       <td style="text-align:center;">Recall</td>       <td>F1</td>      </tr>      <tr>       <td style="text-align:left;">Baseline</td>       <td style="text-align:center;">40.01</td>       <td style="text-align:center;">42.12</td>       <td>41.04 &#x00B1; 0.04</td>      </tr>      <tr>       <td style="text-align:left;">Baseline + <em>SCEmNet</em>       </td>       <td style="text-align:center;">41.20</td>       <td style="text-align:center;">44.01</td>       <td>42.56 &#x00B1; 0.05</td>      </tr>      <tr>       <td style="text-align:left;">        <em>JSCEmNet</em>       </td>       <td style="text-align:center;">44.81</td>       <td style="text-align:center;">47.86</td>       <td>        <em>46.28</em>        <strong>&#x00B1; 0.03</strong>       </td>      </tr>      <tr>       <td style="text-align:left;">Baseline + <em>SCEmNet</em> + XGB</td>       <td style="text-align:center;">43.85</td>       <td style="text-align:center;">46.85</td>       <td>45.30 &#x00B1; 0.05</td>      </tr>      <tr>       <td style="text-align:left;">        <em>JSCEmNet</em> with XGB</td>       <td style="text-align:center;">44.83</td>       <td style="text-align:center;">47.89</td>       <td>        <em>46.79</em>        <strong>&#x00B1; 0.03</strong>       </td>      </tr>      <tr>       <td style="text-align:left;">Phan et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0005">5</a>]</td>       <td style="text-align:center;">39.30</td>       <td style="text-align:center;">55.10</td>       <td>45.90</td>      </tr>     </tbody>     </table>    </div>    <p>We compare the performance of the <em>SCEmNet</em> feature with <em>JSCEmNet</em> using only 50% of the test pairs, following the CIKM challenge setup. We report confidence intervals on the F1 score obtained by doing 50 random splits of the test pairs. Note that this is different to how Phan et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>] reported their results, as they evaluated on the full test set.</p>    <p>Our main results are presented in Table&#x00A0;<a class="tbl" href="#tab1">1</a>. We show that using all features in joint training is the most efficient method: <em>JSCEmNet</em> is doing better than the baseline features combined with <em>SCEmNet</em>. Our best score was obtained when adding a gradient boosted feature (XGB), which was obtained by training an XGBoost model on the baseline features and using its prediction as a feature. We improved the state-of-the-art results of Phan et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>] by 1.9%.</p>   </section>   <section id="sec-9">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Conclusion</h2>     </div>    </header>    <p>This paper adds to the literature showing that applying Natural Language Processing techniques to sequences can be very efficient, especially in the field of similarity learning. We introduced the <em>SCEmNet</em> structure showing that siamese CNNs can be applied successfully to learn sequence similarity on non textual data. Furthermore, with the <em>JSCEmNet</em> architecture, we showed that learning the <em>SCEmNet</em> representation jointly with other features brings additional value and beats state-of-the-art results.</p>    <p>These promising results were obtained while keeping to state-of-the-art methods for candidate generation. Besides, when working on online users, training a sequence representation such as <em>doc2vec</em> for all cookies might not be realistic (e.g. billions of sequences). In that case it could be helpful to use a <em>SCEmNet</em>-like structure to infer sequence embeddings and perform approximate kNN search. Future work should also better integrate the temporal information (time gaps, daily and weekly patterns,...) in our cookie/pair representation. A possibility could be to integrate the time-gaps in <em>doc2vec</em> as additional information as in Vasile et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>], or to use RNNs as proposed by Smirnova and Vasile [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>]. Further work should investigate the use of RNNs for the task of similarity learning.</p>    <p>More generally, this structure developed for cookie matching can be generalized to any kind of sequence similarity task. For example, we plan to test our similarity learning structure on textual data for the SemEval-2018 workshop on Semantic Evaluation <a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, and others. 2016. Wide &#x0026; deep learning for recommender systems. In <em>      <em>Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</em>     </em>. ACM, 7&#x2013;10.</li>     <li id="BibPLXBIB0002" label="[2]">Andrew&#x00A0;M. Dai, Christopher Olah, and Quoc&#x00A0;V. Le. 2015. Document Embedding with Paragraph Vectors. <em>      <em>CoRR</em>     </em>abs/1507.07998(2015). <a class="link-inline force-break" href="http://arxiv.org/abs/1507.07998"      target="_blank">http://arxiv.org/abs/1507.07998</a></li>     <li id="BibPLXBIB0003" label="[3]">Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification. <em>      <em>arXiv preprint arXiv:1408.5882</em>     </em>(2014). arxiv:arXiv:1408.5882v2</li>     <li id="BibPLXBIB0004" label="[4]">Cong-Minh Phan, Yin Tay, and Tuan-Anh Nguyen&#x00A0;Pham. 2016. Cross Device Matching for Online Advertising with Neural Feature Ensembles : First Place Solution at CIKM Cup 2016. In <em>      <em>CIKM 2016</em>     </em>.</li>     <li id="BibPLXBIB0005" label="[5]">Min h&#x00A0;C. Phan, Aixin Sun, and Yi Tay. 2017. Cross-Device User Linking : URL, Session, Visiting Time, and Device-log Embedding. In <em>      <em>SIGIR</em>     </em>. 933&#x2013;936.</li>     <li id="BibPLXBIB0006" label="[6]">Elena Smirnova and Flavian Vasile. 2017. Contextual Sequence Modeling for Recommendation with Recurrent Neural Networks. In <em>      <em>WDLRS</em>     </em>. arxiv:1706.07684v1</li>     <li id="BibPLXBIB0007" label="[7]">Flavian Vasile, Elena Smirnova, and Alexis Conneau. 2016. Meta-Prod2Vec - Product Embeddings Using Side-Information for Recommendation. <em>      <em>RecSys</em>     </em> (2016), 0&#x2013;7. arxiv:1607.07326</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>ICDM 2015:&#x00A0;<a class="link-inline force-break"     href="https://www.kaggle.com/c/icdm-2015-drawbridge-cross-device-connections">https://www.kaggle.com/c/icdm-2015-drawbridge-cross-device-connections</a>   </p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>CIKM 2016:&#x00A0;<a class="link-inline force-break" href="http://cikm2016.cs.iupui.edu/cikm-cup/">http://cikm2016.cs.iupui.edu/cikm-cup/</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>SemEval-2018:&#x00A0;<a class="link-inline force-break" href="http://alt.qcri.org/semeval2018/">http://alt.qcri.org/semeval2018/</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186941">https://doi.org/10.1145/3184558.3186941</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
