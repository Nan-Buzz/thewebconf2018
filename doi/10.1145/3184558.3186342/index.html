<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>How to Improve the Answering Effectiveness in
  Pay-for-Knowledge Community: An Exploratory Application of
  Intelligent QA System</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3186342'>https://doi.org/10.1145/3184558.3186342</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3186342'>https://w3id.org/oa/10.1145/3184558.3186342</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">How to Improve the Answering
          Effectiveness in Pay-for-Knowledge Community: An
          Exploratory Application of Intelligent QA
          System</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Yihang</span> <span class=
          "surName">Cheng</span>, Tianjin University, <a href=
          "mailto:chengyihang@tju.edu.cn">chengyihang@tju.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Xi</span> <span class=
          "surName">Zhang</span>, Tianjin University, <a href=
          "mailto:jackyzhang@tju.edu.cn">jackyzhang@tju.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Hao</span> <span class=
          "surName">Wang</span>, 360 Search Lab, <a href=
          "mailto:cashenry@126.com">cashenry@126.com</a>
        </div>
        <div class="author">
          <span class="givenName">Shang</span> <span class=
          "surName">Jiang</span>, Tianjin University, <a href=
          "mailto:shanjiangtju@tju.edu.cn">shanjiangtju@tju.edu.cn</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186342"
        target=
        "_blank">https://doi.org/10.1145/3184558.3186342</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Community Question Answering (CQA) has emerged
        recently and it becomes popular among people. During the
        process of the communication, different knowledge can be
        merged. Recently, several vendors use the business model of
        paying for knowledge to make these knowledge to the
        monetary benefits, then the Pay-for-Knowledge Communities
        (PKC) have been applied. Even PKC has interesting business
        model, there are several problems to be solved, and one of
        the most salient problem is that questioners may takes too
        long time to choose the most valuable answers, leading to
        questioners not able to pay for suitable answerers. There
        are several previous research has focused on this problem
        but still have not found satisfactory solutions as
        questions and answers become more and more complex in the
        platforms. With the development of cognitive computing
        techniques, applying an intelligent QA system in PKC to
        improve the answering effectiveness may be possible. In
        this paper, we tried to investigate how to apply the
        intelligent QA system into PKC platform to improve the
        answering effectiveness. For solving the problems of
        matching complex questions and answers, we present a Four
        Module QA Model based on the normal intelligent QA System.
        Compared to normal intelligent QA System, our model uses
        categories to classify the questions with traditional
        machine learning methods. We use answers in each category
        of corresponding questions as one dataset, answers in each
        entity of corresponding question as the other dataset,
        finally, these two datasets make up the document database.
        Then we got the best answer among past answers through
        comparing the TF-IDF weighted bag-of word vectors of two
        datasetsor the new answer including key words through Long
        Short-Term Memory (LSTM) algorithm with PKC's features
        composed of centrality and money. Exploratory experiments
        were developed on a dataset with 1222 users’ QA sites
        collected from a QA community. The model we proposed is
        expected to increase QA's effectiveness and improve the
        business model of Pay-for-Knowledge
        Communities.</small></p>
      </div>
      <div class="classifications">
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Yihang Cheng, Xi Zhang, Hao Wang and Shang Jiang. 2018.
          How to Improve the Answering Effectiveness in
          Pay-for-Knowledge Community: An Exploratory Application
          of Intelligent QA System . In <em>Proceedings of The 2018
          Web Conference Companion (WWW'2018 Companion). ACM, New
          York, NY, USA, 9 pages.</em> <a href=
          "https://doi.org/10.1145/3184558.3186342" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3186342</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec1">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          INTRODUCTION</h2>
        </div>
      </header>
      <p>Recently, Community Question Answering (CQA) has become a
      trend in knowledge and learning applications [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#bib1">1</a>]. In Yahoo! Answer, more than 80
      million questions have been resolved by the community [2].
      Similarly, there are Baidu Knows, 360 QA and some other CQA
      platforms in the world.</p>
      <p>There are several reasons for the CQA's success: 1) The
      exact and personalized answer: If people can get the answer
      only fits them, they will be happy to use this way again. 2)
      The social needs: CQA platforms have likes and comment
      functions, which can provide the chance of developing social
      connections among users. 3) The knowledge creation: The CQA
      platform provides a communication environment for talents in
      different fields to create new interdisciplinary
      knowledge.</p>
      <p>Considering the success of the early CQA platforms,
      practitioners then applied the business model of pay for
      knowledge into platform. There are two ways in the process of
      paying for knowledge: 1) The first is user paying for experts
      who may answer users’ questions correctly, called the
      systematic pay for knowledge community (PKC) such as
      <em>Fenda</em> and <em>Ximalaya</em>; 2) The second way is
      user paying for the answerers, whose answer is best whatever
      who they are, called the reward-function PKC, such as
      <em>Zhihu</em> or <em>Baidu Knows</em>, which processes are
      illustrated at Figure 1. The biggest difference of them is
      whether users know the answers in advance, the first one is
      yes, and the second is on the contrary.</p>
      <p>Even numerous studies have focused on PKC, a fundamental
      question has not been well answered: 1) Do users get what
      they really want? 2) If not, what are reasons and what can we
      do to improve the users' satisfaction effectively? As for the
      first question, in the process of the Question Answering (QA)
      in platform, it is likely that they cannot get answer because
      of the topic, question length or the degree of clarity of
      explanation to the question [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#bib2">2</a>]. As for the second question, there are many
      people asking some fundamental questions [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#bib3">3</a>], such as “Who is the US
      president?”, which are too easy to appeal attention. These
      problems may cause the low answering ratio</p>
      <p>of these platforms.</p>
      <p>Previous work uses different approaches to solve these
      problems, but most of work can not satisfy the users as
      giving correct and personalized answers in time. With the
      development of the intelligent QA system, the application of
      machine intelligence in PKC platform may be an effective way.
      But there are also challenges, the most critical one is how
      to combine the machine intelligence and PKC platform in a
      suitable way.</p>
      <p>This paper mainly considers the intelligent QA system as
      the manifestations of machine intelligence, combining the
      intelligent QA and PKC platforms. Our work mainly uses the
      category to classify the questions users post and Long
      Short-Term Memory (LSTM) with PKC platform features to train
      the answers in each category and each entity of corresponding
      question based on the fundamental QA System. Then, we can
      answer the question users propose using the key words our
      training model gets.</p>
    </section>
    <section id="sec2">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> RELATED
          WORK</h2>
        </div>
      </header>
      <section id="sec2Z1">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Previous
            work on Pay-for-Knowledge Communities</h3>
          </div>
        </header>
        <p>The Pay-for-Knowledge Communities (PKC) is a new
        application. Generally, PKC are developed from normal CQA
        platform, but are more specific and advanced. As rare
        studies have focused on this specific platform, we will
        discuss the literature from CQA.</p>
        <p>Within CQA, information seekers can get answers by
        posting questions to other participants and letting them
        answer. However, CQA is not always effective: in some
        cases, the user can get the perfect answer in a few
        minutes, hours or even days [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#bib4">4</a>]. Prior works mainly aimed to find reasons
        for no-answered questions. Yang et al [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#bib2">2</a>] found the reasons for no-answered
        questions are depends on the content features, heuristic
        features such as length and time. There are also some
        previous works aiming at matching answerers with questions.
        Li and King [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#bib5">5</a>] proposed a framework called Question Routing
        (QR) to route questions to answerers who are top ranking
        according to their performance in previous days.</p>
        <figure id="fig1The">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186342/images/image1.jpg"
          class="img-responsive" alt="Figure 1:The" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span>
            <span class="figure-title">The process of the PKC
            platform.</span>
          </div>
        </figure>
        <p>As for the problems about finding suitable experts in
        PKC, Riahi et al [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#bib6">6</a>] used Latent Dirichlet Allocation model and
        Segmented Topic Model to route questions correctly to
        experts which showed that statistical topic models help get
        better expertise recommendation. Zhang [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#bib7">7</a>] modeled the QA community into an
        expertise graph, and proposed an Expertise Ranking
        algorithm. Yang et al [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#bib8">8</a>] proposed Topic Expertise Model (TEM) to
        model topics and expertise together by integrating textual
        content model and link structure analysis. These ways
        indeed improve the quality of answers and the answers, but
        the effectiveness of them decreases fast as the questions
        and answers are becoming more and more complex.</p>
      </section>
      <section id="sec2Z2">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Intelligent
            QA System</h3>
          </div>
        </header>
        <p>Previous works mainly focus to improve the answering
        effectiveness in the existing QA environment. If the
        questions and answers become more complex, the waiting time
        may be longer. With the development of the cognitive
        computing (i.e., a method for computing simulating the
        mechanisms of the brain [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#bib9">9</a>]), intelligent QA systems were presented, by
        which intelligently QA can decrease the waiting time and
        improve the effectiveness. Combination of intelligent QA
        system and the PKC platform are the implement of cognitive
        computing. The researches about intelligent QA system are
        mainly aiming to increase the precision of answering.</p>
        <p>Chen et al [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#bib10">10</a>] use the TF-IDF in retrievers and the RNN
        in readers to successfully make machine answer the
        open-domain questions in exact-match 69.5% and F1-score
        78.8% for the Stanford Question Answering Dataset (SQuAD).
        These ratios reflect the machine can answer our fundamental
        questions. To improve the effectiveness of answering
        questions, Eunsol et al [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#bib11">11</a>] also used the summary of documents in
        reader so that long documents can be used effectiveness. As
        for the improvement of the quality of answers, He et al
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#bib12">12</a>] proposed an
        end-to-end QA system. As for the improvement of questions
        dealing with, based on the normal QA system, Cui et al
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#bib3">3</a>] propose KBQA model
        which uses category and template to classify the questions.
        Hao et al <a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href="#bib13">[13</a>]
        propose a new representation of question combining the
        knowledge bases (KBs).</p>
        <p>Even more and more researchers pay attentions on
        intelligent QA systems, rare studies focus on integrating
        the PKC platform and intelligent QA system. In this paper,
        we tries to apply the intelligent QA system into PKC
        platform. Our work may have some potential contributions in
        the field of PKC as follows:</p>
        <p>1. We propose the four modules model to describe the
        intelligent QA system in PKC, which are Question Module,
        Document Module, Learning Module and Matching
        Module.Especially, the Learning Module has the features
        composed of centrality and money in PKC platform and
        Matching Module is the quite new module in our model
        compared with normal intelligent QA system.</p>
        <p>2. We add PKC's features composed of the number of likes
        and commentsinto intelligent QA system so that our model
        can suit the real environment of PKC platform.</p>
      </section>
    </section>
    <section id="sec3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> PROBLEM
          FORMULATION</h2>
        </div>
      </header>
      <p>In this section, we propose our research problem in
      technical ways. Table <a class="tbl" href="#tb1">1</a>
      displays all definition and notations.</p>
      <div class="table-responsive" id="tb1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">Notations of the definitions.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:center;">DFINITION</th>
              <th style="text-align:center;">SYMBOL</th>
              <th style="text-align:center;">DESCRIPTION</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:center;" rowspan="4">
              Answer</td>
              <td style="text-align:center;"><span class=
              "inline-equation"><span class=
              "tex">$\;{C_a}$</span></span></td>
              <td style="text-align:center;">Contents of the
              answer</td>
            </tr>
            <tr>
              <td style="text-align:center;"><span class=
              "inline-equation"><span class=
              "tex">${{\rm{T}}_a}$</span></span></td>
              <td style="text-align:center;">The time that question
              is answered</td>
            </tr>
            <tr>
              <td style="text-align:center;"><span class=
              "inline-equation"><span class=
              "tex">${\rm{T}}{{\rm{P}}_a}$</span></span></td>
              <td style="text-align:center;">The topic of the
              question answer corresponding</td>
            </tr>
            <tr>
              <td style="text-align:center;"><span class=
              "inline-equation"><span class=
              "tex">${{\rm{A}}_a}$</span></span></td>
              <td style="text-align:center;">The person proposing
              this answer</td>
            </tr>
            <tr>
              <td style="text-align:center;" rowspan="5">
              Question</td>
              <td style="text-align:center;"><span class=
              "inline-equation"><span class=
              "tex">${C_q}$</span></span></td>
              <td style="text-align:center;">Contents of the
              question</td>
            </tr>
            <tr>
              <td style="text-align:center;"><span class=
              "inline-equation"><span class=
              "tex">${T_q}$</span></span></td>
              <td style="text-align:center;">The time that question
              is posted</td>
            </tr>
            <tr>
              <td style="text-align:center;"><span class=
              "inline-equation"><span class=
              "tex">$T{P_q}$</span></span></td>
              <td style="text-align:center;">The topic of the
              question</td>
            </tr>
            <tr>
              <td style="text-align:center;"><span class=
              "inline-equation"><span class=
              "tex">${A_q}$</span></span></td>
              <td style="text-align:center;">The person posting
              this question</td>
            </tr>
            <tr>
              <td style="text-align:center;"><span class=
              "inline-equation"><span class=
              "tex">$C{G_q}$</span></span></td>
              <td style="text-align:center;">The category under
              some topic</td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>Definition 1: Answer. Answer refers to the process of
      answering the question. The text or voice answered by experts
      or someone who knows is called contents represented by
      <span class="inline-equation"><span class=
      "tex">${C_a}$</span></span> , the time from posting a
      question to be answered is represented by <span class=
      "inline-equation"><span class=
      "tex">${{\rm{T}}_a}$</span></span> , the topic of the
      correspond question is represented by <span class=
      "inline-equation"><span class=
      "tex">${\rm{T}}{{\rm{P}}_a}$</span></span> , the person
      proposing this answer is called answerer, which is
      represented by <span class="inline-equation"><span class=
      "tex">${{\rm{A}}_a}$</span></span> . Each answer has these
      four features, so it is displayed as a four tuple
      <span class="inline-equation"><span class="tex">$(
      {{C_a},{T_a},T{P_a},{A_a}} )$</span></span> . All the Answers
      makes up a dataset called <span class=
      "inline-equation"><span class="tex">${\rm{A}}$</span></span>
      .</p>
      <p><span class="inline-equation"><span class="tex">${\rm{A}}
      = \{ {Answer|{\rm{\;}}( {{C_a},{\rm{\;}}{T_a},T{P_a},{A_a}}
      ){C_a},T{P_a},{A_a} \in String{T_a} \in Int}
      \}$</span></span> .</p>
      <p>Definition 2: Question. Question refers to the process of
      posting the question, also including many features. The
      contents are represented by <span class=
      "inline-equation"><span class="tex">${C_q}$</span></span> ,
      the time that question is posted is represented by
      <span class="inline-equation"><span class=
      "tex">${T_q}$</span></span> , the topic of the correspond
      question is represented by <span class=
      "inline-equation"><span class="tex">$T{P_q}$</span></span> ,
      the person posted this question is called asker, which is
      represented by <span class="inline-equation"><span class=
      "tex">${A_q}$</span></span> . The different feature with
      Answer is the category, which means the specific
      classification under topic, such as friendship in emotion, is
      represented by <span class="inline-equation"><span class=
      "tex">$C{G_q}$</span></span> .Similarly, it is displayed as a
      five tuple <span class="inline-equation"><span class="tex">$(
      {{C_q},{T_q},T{P_q},{A_q},C{G_q}} )$</span></span> . All the
      Questions makes up a dataset called <span class=
      "inline-equation"><span class="tex">${\rm{Q}}$</span></span>
      ,</p>
      <p><span class="inline-equation"><span class="tex">${\rm{Q}}
      = \{ {Question|{\rm{\;}}(
      {{C_q},{\rm{\;}}{T_q},T{P_q},{A_q},C{G_q}}
      ){C_q},{\rm{\;}}T{P_q},{A_q},C{G_q} \in String{T_q} \in Int}
      \}$</span></span> .</p>
      <p>After describing the definition and notations, we can
      describe the problem in the process. We formulate the problem
      in the unified ways as follows.</p>
      <p>Problem (Question Answering): When a new Question appears
      in the PKC platform, we can use the model to provide an
      Answer, the <span class="inline-equation"><span class=
      "tex">${C_a}$</span></span> of this Answer is some key words.
      The results of this problem can be evaluated by the
      comparison of the existing Answer and the Answer machine
      provides.</p>
    </section>
    <section id="sec4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> OUR MODEL</h2>
        </div>
      </header>
      <section id="sec4Z1">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Fundamental
            Framework</h3>
          </div>
        </header>
        <p>Intelligent QA system mainly has two parts: retriever
        and reader [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#bib10">10</a>]. Based on the fundamental intelligent QA
        system, we can develop a new and complex model including 4
        modules: Question module, Document module, Learning module,
        and Matching module (Figure <a class="fig" href=
        "#fig2">2</a>). Question module is to build the mapping of
        the category and the template of questions with clustering
        algorithm and Bayesian probability; document module is to
        construct training set including answers of different
        categories and different entities among questions; learning
        module will learn the dataset's feature of document module
        by LSTM algorithm; finally, matching module is the process
        to match suitable words of training results of each
        category and training results of each entity in question,
        then, the prediction with key words can be got. The
        combination of these four modules and matching two results
        of different training datasets are the biggest contribution
        of our work. The principle of each module is explained in
        Section <a class="sec" href="#sec4Z2">4.2</a>.</p>
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186342/images/image2.jpg"
          class="img-responsive" alt="Figure 2:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">Overview of our fundamental
            framework.</span>
          </div>
        </figure>
      </section>
      <section id="sec4Z2">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> The
            principle of our model</h3>
          </div>
        </header>
        <p>In this part, we mainly explain the principle of four
        modules, and construct the complete process of the
        lifecycle of a new question in our model in the end.</p>
        <p><strong><em>1. The Question Module:</em></strong></p>
        <p>Cui et al [3] proposed a KBQA to deal with the question,
        they use the maximal probability and the category to
        classify questions. The category and template are given new
        definitions.</p>
        <p>In our model, <span class="inline-equation"><span class=
        "tex">$C{G_q}$</span></span> is the classification for
        topic, for example, emotion, friendship, love and so on. In
        the same time, we can extract the entity of every question
        to get the template of this question. For example, the
        question “I have a problem about computer, how to open the
        MAC and how to get the factory code of this computer?”
        Through the extraction, the templates of this question are
        “how to open the <font style="normal">$</font>entity?” and
        “how to get <font style="normal">$</font>entity?”</p>
        <p>Then we can use the K-means clustering to cluster the
        category, and we can get all categories under the
        corresponding topic. In the end, we use Bayesian
        probability to estimate the category of the template,
        specific formula is as follows.</p>
        <p><span class="inline-equation"><span class=
        "tex">${\rm{P}}( {y = C{G_q}|template} ) = \frac{{\mathop
        \prod \nolimits_{i = 1}^m P( {templat{e^i}|y = C{G_q}} )P(
        {y = C{G_q}} )}}{{\mathop \sum \nolimits_Q P( {y = C{G_q}}
        )\mathop \prod \nolimits_{i = 1}^m P( {templat{e^i}|y =
        C{G_q}} )}}$</span></span></p>
        <p><span class="inline-equation"><span class=
        "tex">${\rm{P}} = {\rm{max}}( {\begin{array}{@{}*{1}{c}@{}}
        {P( {y = C{G_{q1}}|template} ),}\\ {P( {y =
        C{G_{q2}}|template} ) \ldots P( {y = C{G_{qQ}}|template} )}
        \end{array}} )$</span></span></p>
        <p><span class="inline-equation"><span class=
        "tex">${\rm{P\;}}$</span></span> is the maximum
        probability, and corresponding category is which the
        template belongs. In this formula, <span class=
        "inline-equation"><span class="tex">$P( {y = C{G_q}}
        )$</span></span> and <span class=
        "inline-equation"><span class="tex">$P( {templat{e^i}|y =
        C{G_q}} )$</span></span> can be learned by the existing
        dataset. Until now, each question has its own <span class=
        "inline-equation"><span class="tex">$T{P_q}$</span></span>
        and <span class="inline-equation"><span class=
        "tex">$C{G_q}$</span></span> besides <span class=
        "inline-equation"><span class="tex">${C_q}$</span></span>
        .</p>
        <p><strong><em>2. Document Module and Learning
        Module:</em></strong></p>
        <p>Because the Learning Module is to learn the results of
        Document Module, explaining these two modules together can
        be explained logically and understood easily. We add PKC's
        features composed of centrality and money into LSTM
        algorithm and take two trainings according to different
        categories and different entities.</p>
        <p>As for the questions in PKC, there are usually two
        kinds: one is that question has already answered in past,
        the other is that question has not answered which means
        it's new.</p>
        <p><strong>(1) The question has already
        answered:</strong></p>
        <p>The first one can be solved by similarity between the
        questions have already answered and the question proposing
        now. Our model use TF-IDF algorithm to make words into
        vectors, specific formula is as follows [14].</p>
        <p><span class="inline-equation"><span class=
        "tex">${\rm{T}}{{\rm{F}}_{i,j}} =
        \frac{{{n_{i,j}}}}{{\mathop \sum \nolimits_k
        {n_{k,j}}}}$</span></span></p>
        <p><span class="inline-equation"><span class=
        "tex">${\rm{ID}}{{\rm{F}}_i} = \log ( {\frac{{| D |}}{{|
        {\{ {j:{t_i} \in {d_j}} \}} |}}} )$</span></span></p>
        <p>In the formula, <span class=
        "inline-equation"><span class=
        "tex">${\rm{i\;and\;j\;}}$</span></span> are the words in
        the questions, so we can use the product of <span class=
        "inline-equation"><span class=
        "tex">${\rm{TF\;and\;IDF\;}}$</span></span> to present the
        words in one question. Finally, we can get similarity of
        the new question and each question has already
        answered.</p>
        <p><strong>(2) The new question:</strong></p>
        <p>We display the TOP-five answers to users, if users
        choose one of these answers, the answering is end. If not,
        the answering transform to the second way, which is
        answering new questions. The normal intelligent QA system
        only contains the first part, however, there are new
        question entering the PKC platform continuously, so there
        should be some means to react this problem in the
        intelligent QA system of PKC platform. In the consequence,
        this part is the important contribution of our work.</p>
        <p>In the process of answering new questions, we use the
        LSTM to predict the contents of the answers. The recurrent
        neural network language model (RNNLM) has shown significant
        promise for statistical language modeling [15]. Shi et al
        [16] also applied the LSTM whichadds doors in RNN to
        improve the accuracy of prediction. We use the LSTM with
        some features PKC platform has such as centrality and
        money. The content can be transformed into a words’ vector
        <span class="inline-equation"><span class="tex">$(
        {w1,w2,w3 \ldots wn} )$</span></span> , so the problem is
        to predict the vector. The complete ways to get the vector
        is as follows:</p>
        <p><span class="inline-equation"><span class="tex">$(
        {w1,w2,w3 \ldots wn} ) = LSTM(
        {w{1^{\rm{'}}},w{2^{\rm{'}}},w{3^{\rm{'}}} \ldots
        w{n^{\rm{'}}}} )$</span></span></p>
        <p>The <span class="inline-equation"><span class=
        "tex">$w{i^{\rm{'}}}( {i \in 1,2,3 \ldots n}
        ){\rm{\;}}$</span></span> is vector of <span class=
        "inline-equation"><span class="tex">$wi$</span></span> ,
        which represent the word in the answer. <span class=
        "inline-equation"><span class=
        "tex">$w{i^{\rm{'}}}$</span></span> consists of several
        elements. These elements are explained as follows:</p>
        <p>Word features:</p>
        <p><span class="inline-equation"><span class=
        "tex">${f_{word - feature}}( {wi} ) = ( {entity( {wi} ),TF(
        {wi} ),previousword( {wi} )} )$</span></span> .</p>
        <p>The <span class="inline-equation"><span class=
        "tex">$entity\;( {wi} )$</span></span> represents the
        entity of <span class="inline-equation"><span class=
        "tex">$wi$</span></span> . If <span class=
        "inline-equation"><span class="tex">$wi$</span></span> is
        entity, then the value is 1, if not, the value is 0. The
        <span class="inline-equation"><span class="tex">$TF( {wi}
        )$</span></span> represents the word frequency in this
        answer. The <span class="inline-equation"><span class=
        "tex">$previousword( {wi} )$</span></span> represents the
        previous word of <span class="inline-equation"><span class=
        "tex">$wi$</span></span> .</p>
        <p>Word embedding:<span class=
        "inline-equation"><span class="tex">${f_{word -
        embeddings}}( {wi} ) = {\rm{E}}( {wi} )$</span></span>
        .</p>
        <p>We can train the common words in advanced such as
        “hello”, personal pronouns and so on because these words
        can influence the results of training on other words
        because of the word frequency.</p>
        <p>Word experts’ features: <span class=
        "inline-equation"><span class="tex">${f_{word - expert}}(
        {wi} ) = ( {amountoflistening( {wi} ),money( {wi} )}
        )$</span></span> .</p>
        <p>The different aspects of PKC platform with the normal QA
        is the amount of listening and the money of the answers.
        The more amount of listening and much money mean that word
        is usually said by experts, so this word can be the
        probably answer for these questions.</p>
        <p>Similarly, we can train the answers of each entity of
        corresponding questions as the methods above. However, the
        different of them is the word features in LSTM algorithm.
        There is <span class="inline-equation"><span class=
        "tex">$entity( {wi} ){\rm{\;}}$</span></span> in word
        features of the process above but there is not in the
        learning process of the answers of each entity because the
        training set has the same entity in this learning process.
        The complete process of learning is displayed in Figure
        <a class="fig" href="#fig3">3.</a></p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186342/images/image3.jpg"
          class="img-responsive" alt="Figure 3:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">The learning process in our
            model.</span>
          </div>
        </figure>
        <p><strong><em>3. Matching Module:</em></strong></p>
        <p>We get the model trained through the Learning Module, in
        the module, we use the model to predict two kinds of
        results: one is the result of the learning process of
        answers of each category, the other is the result of the
        learning process of answers of each entity corresponding
        with the question. When we get these two kinds of results,
        we can get the all of words of them and remove the words
        irrelevant with questions, finally, the results are these
        suitable key words. The matching process of our model is
        displayed in Figure <a class="fig" href="#fig3">3.</a></p>
      </section>
    </section>
    <section id="sec5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span>
          EXPERIMENTS</h2>
        </div>
      </header>
      <section id="sec5Z1">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.1</span> Data</h3>
          </div>
        </header>
        <p>In recent researches, the evaluation dataset is the
        mostly standard dataset such as SQuAD [17], CNN/Daily Mail
        [18]. Because the particularity of the PKC platform, we use
        the dataset of PKC platform.</p>
        <p>We have collected the 1222 QA sites range from big data
        to movies and so on from a Chinese community. There are six
        topics in the dataset, every topic can be about all kinds
        of themes such as life, Internet and so on. The community
        is one of the best communities of persons who have
        professional knowledge, the questions where are normal, but
        the answers are logic and evidential in China. In the same
        time, in the community, there are many topics in this
        platform such as emotion, health, employment and so on. So,
        our data is comprehensive in topic and practical meaning in
        PKC market.</p>
      </section>
      <section id="sec5Z2">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.2</span> Results and
            discussion</h3>
          </div>
        </header>
        <p>We can design three indexes to evaluation our model,
        named Precision, Recall and F1-score [19]. The first one is
        exact matching of these key words predicted by our model,
        which means ratio of the number of key words completely
        appearing in the existing answer people have accepted
        widely and the number of words predictive answer has, we
        can define which as the Precision of our model. The second
        one is ratio of the number of key words completely
        appearing in the existing answer people have accepted
        widely and the number of words predictive answer has, we
        can define which as the Recall of our model. F1-score is
        the harmonic average of them. The detail formula is
        illustrated as follow.</p>
        <p><span class="inline-equation"><span class=
        "tex">${\bf{Precision}} =
        \frac{{the\;number\;of\;exact\;match{\rm{\;}}words}}{{t{\rm{he\;}}number\;of\;words\;predictive\;answer{\rm{\;}}has}}$</span></span></p>
        <p><span class="inline-equation"><span class=
        "tex">${\bf{Recall}} =
        \frac{{the\;number\;of\;exact\;match{\rm{\;}}words}}{{t{\rm{he\;}}number\;of\;words\;best\;answer{\rm{\;}}has}}$</span></span></p>
        <p><span class="inline-equation"><span class=
        "tex">${\bf{F}}1 - {\bf{score}} =
        \frac{{2{\rm{*}}Precision{\rm{*}}Recall}}{{Precision +
        Recall}}$</span></span></p>
        <p>Considering the contents of PKC platform are developing
        with time, we choose the Question: “How to choose the
        cheapest commodities and are them really cheap in ‘Double
        Eleven’ (11st, Nov)?” as our experiment question. We use
        clustering method to define this question as the category
        of Internet. Because the question is new, so our model
        should answer this question by itself. Then the entity of
        this question is ‘Double Eleven’, and the training dataset
        is the QA sites of Internet category and the ‘Double
        Eleven’ entity. At the same time, to evaluate the accuracy
        of our model, we calculate the Precision, Recall and
        F1-scoreof the answer our model gets and make some
        comparisons.</p>
        <p>To evaluate whether our model may fit the PKC platform
        more suitably, we choose the normal RNN algorithm as the
        compared model to our model. We can get the Precision,
        Recall and F1-score of these two models in different number
        of keywords, which includes 5, 10 and 20 keywords
        respectively. The detail results are displayed as Figure
        <a class="fig" href="#fig4">4.</a></p>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186342/images/image4.jpg"
          class="img-responsive" alt="Figure 4:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">Comparison of normal RNN and
            Our model.</span>
          </div>
        </figure>
        <p>According to the results of comparison of normal RNN
        algorithm and our model, we find our model is better than
        normal RNN algorithm in the PKC platform. At the same time,
        we can find the Recall and the F1-score is decreasing as
        the number of key words increases, while the Precision
        remains stable as the number of key words increases. In the
        consequence, the high weight word is predicted more
        precisely in the experiment.</p>
        <p>Then, we can compare the different results of different
        iterations of our model, the results are illustrated at
        Figure <a class="fig" href="#fig5">5</a>. We can find the
        results of 10000 iterations are best of them, although the
        Precision and F1-score of 40000 iterations are better in
        small number of key words, the integral prediction of which
        are less than another two ways. In the consequence, the
        more iterations may not lead to better results as the local
        optimum exists.</p>
        <figure id="fig5">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186342/images/image5.jpg"
          class="img-responsive" alt="Figure 5:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span>
            <span class="figure-title">Comparison of different
            iterations of Our model.</span>
          </div>
        </figure>
      </section>
      <section id="sec5Z3">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.3</span> Improvement
            directions</h3>
          </div>
        </header>
        <p>In this paper, we just use experiments of two aspects to
        evaluate our model. And we just use one question as our
        evaluation question, which we can improve in the future
        studies.</p>
        <p>First, we will try to answer more questions by our
        model, which means our model can train more data, these
        changes will improve the effectiveness of our model.
        Second, we may delete some information irrelevant with the
        question and some have much subjective meaning. Third,
        machine comprehension can be added into the implement of
        the Learning module, which may improve the results of
        learning and effectiveness of answering. Finally, the
        learning ratio of our Learning module can be changed to
        find the most suitable ratio, as according to the findings
        of this study, the relationship between indexes and
        iterations are still not obvious.</p>
      </section>
    </section>
    <section id="sec6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6:</span>
          CONCLUSION</h2>
        </div>
      </header>
      <p>This paper aims to investigate how to apply the
      intelligent QA system into the PKC environment. Based on the
      results, we mainly have two findings: 1) The precision of our
      model in Question Answering can reach the level of normal
      answering in other CQA fields and our model is better than
      the normal RNN algorithm in the PKC platform. 2) The
      answering effectiveness can be improved by our model.</p>
      <p>Our work also has some business implications: 1) Our work
      aims to improve the answering effectiveness of PKC platform,
      which is one of the most salient problems in the PKC
      platform. 2) We try to integrate intelligent QA systems and
      PKC platforms, and propose four modules of intelligent QA,
      which can be adopted by platform. 3) From cognitive computing
      aspects by combing machine learning and user behavioral
      theory, we investigates how to solve the QA problem, which
      may be adopted by researchers and practitioners to improve
      users’ satisfaction from integrated and interdisciplinary
      perspectives.</p>
      <p>The future works may focus on these aspects: 1) Take more
      experiments on the larger and real datasets. 2) Collect data
      from other PKC platforms to train the model so that we can
      compare the advantages and disadvantages of them. 3)
      Investigate how to input questions can have a more correct
      answer and what other features in the PKC platform we can
      use. 4) Explore whether this work can really enhance the
      business value of PKC, in other word and whether this work
      can improve the users’ satisfaction or the benefits for
      company.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="bib-sec-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="bib1" label="[1]">Liu, Y., Bian, J. and Agichtein,
        E. Predicting information seeker satisfaction in community
        question answering. <em>International ACM SIGIR Conference
        on Research and Development in Information Retrieval</em>
        (2008), 483-490.</li>
        <li id="bib2" label="[2]">Yang, L., Bao, S., Lin, Q., Wu,
        X., Han, D., Su, Z. and Yu, Y. Analyzing and predicting
        not-answered questions in community-based question
        answering services. <em>AAAI Conference on Artificial
        Intelligence</em> (2011), 1273-1278.</li>
        <li id="bib3" label="[3]">Cui, W., Wang, H., Wang, H.,
        Song, Y., Hwang, S. W. and Wang, W. KBQA: learning question
        answering over QA corpora and knowledge bases.
        <em>Proceedings of the Vldb Endowment</em>, 10, 5 (2017),
        565-576.</li>
        <li id="bib4" label="[4]">Agichtein, E., Liu, Y., &amp;
        Bian, J. Modeling information-seeker satisfaction in
        community question answering. <em>Acm Transactions on
        Knowledge Discovery from Data</em>, 3, 2 (2009), 1-27.</li>
        <li id="bib5" label="[5]">Li, B. and King, I. Routing
        questions to appropriate answerers in community question
        answering services. <em>ACM International Conference on
        Information and Knowledge Management</em> (2010),
        1585-1588.</li>
        <li id="bib6" label="[6]">Riahi, F., Zolaktaf, Z., Shafiei,
        M. and Milios, E. Finding expert users in community
        question answering. <em>Proceedings of the 21st
        International Conference on World Wide Web</em> (April 16 -
        20, 2012 2012), 791-798.</li>
        <li id="bib7" label="[7]">Zhang, J., Ackerman, M. S. and
        Adamic, L. Expertise networks in online
        communities:structure and algorithms. <em>International
        Conference on World Wide Web</em> (2007), 221-230.</li>
        <li id="bib8" label="[8]">Yang, L., Qiu, M., Gottipati, S.,
        Zhu, F., Jiang, J., Sun, H. and Chen, Z. CQArank: jointly
        model topics and expertise in community question answering.
        <em>ACM International Conference on Information &amp;
        Knowledge Management</em> (2013), 99-108.</li>
        <li id="bib9" label="[9]">Wang, Y. On Cognitive Computing.
        <em>International Journal of Software Science &amp;
        Computational Intelligence</em>, 1, 3 (2012), 1-15.</li>
        <li id="bib10" label="[10]">Chen, D., Fisch, A., Weston, J.
        and Bordes, A. Reading Wikipedia to Answer Open-Domain
        Questions. <em>Proceedings of the 55th Annual Meeting of
        the Association for Computational Linguistics</em> (July 30
        - August 4, 2017 2017).</li>
        <li id="bib11" label="[11]">Choi E, H. D., Uszkoreit J,
        <em>et al.</em> Coarse-to-fine question answering for long
        documents. <em>Proceedings of the 55th Annual Meeting of
        the Association for Computational Linguistics</em> 1, 1
        (2017), 209-220.</li>
        <li id="bib12" label="[12]">He, S., Liu, C., Liu, K., Zhao,
        J., He, S., Liu, C., Liu, K. and Zhao, J. Generating
        Natural Answers by Incorporating Copying and Retrieving
        Mechanisms in Sequence-to-Sequence Learning. <em>Meeting of
        the Association for Computational Linguistics</em> (2017),
        199-208.</li>
        <li id="bib13" label="[13]">Hao, Y., Zhang, Y., Liu, K.,
        He, S., Liu, Z., Wu, H., Zhao, J., Hao, Y., Zhang, Y. and
        Liu, K. An End-to-End Model for Question Answering over
        Knowledge Base with Cross-Attention Combining Global
        Knowledge. <em>Meeting of the Association for Computational
        Linguistics</em> (2017), 221-231.</li>
        <li id="bib14" label="[14]">Wu, H. C., Luk, R. W. P., Wong,
        K. F. and Kwok, K. L. Interpreting TF-IDF term weights as
        making relevance decisions. <em>Acm Transactions on
        Information Systems</em>, 26, 3 (2008), 55-59.</li>
        <li id="bib15" label="[15]">Shi, Y., Zhang, W. Q., Liu, J.
        and Johnson, M. T. RNN language model with word clustering
        and class-based output layer. <em>Eurasip Journal on Audio
        Speech &amp; Music Processing</em>, 2013, 1 (2013),
        22.</li>
        <li id="bib16" label="[16]">Shi, Z., Shi, M. and Li, C. The
        prediction of character based on recurrent neural network
        language model. <em>Ieee/acis International Conference on
        Computer and Information Science</em> (2017).</li>
        <li id="bib17" label="[17]">Rajpurkar, P., Zhang, J.,
        Lopyrev, K. and Liang, P. SQuAD: 100,000+ Questions for
        Machine Comprehension of Text. <em>Proceedings of the 2016
        Conference on Empirical Methods in Natural Language
        Processing</em> (November 1-5, 2016 2016).</li>
        <li id="bib18" label="[18]">Chen, D., Bolton, J. and
        Manning, C. D. A Thorough Examination of the CNN/Daily Mail
        Reading Comprehension Task. <em>Proceedings of the 54th
        Annual Meeting of the Association for Computational
        Linguistics</em> (August 7-12, 2016 2016).</li>
        <li id="bib19" label="[19]">Hao, W., Yanmei, F., Qinyong,
        W., Hongzhi, Y., Changying, D. and Xiong, H. A
        Location-Sentiment-Aware Recommender System for Both
        Home-Town and Out-of-Town Users. <em>Proceedings of the
        23rd ACM SIGKDD International Conference on Knowledge
        Discovery and Data Mining</em> ( August 13 - 17, 2017
        2017), 1135-1143.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY 4.0) license. Authors
      reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018 IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC BY 4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3186342">https://doi.org/10.1145/3184558.3186342</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
