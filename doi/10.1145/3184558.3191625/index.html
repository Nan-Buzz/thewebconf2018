<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Emerging Product Topics Prediction in Social Media without
  Social Structure Information</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3191625'>https://doi.org/10.1145/3184558.3191625</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3191625'>https://w3id.org/oa/10.1145/3184558.3191625</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Emerging Product Topics
          Prediction in Social Media<br />
          without Social Structure Information</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Sinya</span> <span class=
          "surName">Peng</span>, National Chiao Tung University,
          Taiwan, <a href=
          "mailto:sinyaya99.cs04g@nctu.edu.tw">sinyaya99.cs04g@nctu.edu.tw</a>
        </div>
        <div class="author">
          <span class="givenName">Vincent S.</span> <span class=
          "surName">Tseng</span>, National Chiao Tung University,
          Taiwan, <a href=
          "mailto:vtseng@cs.nctu.edu.tw">vtseng@cs.nctu.edu.tw</a>
        </div>
        <div class="author">
          <span class="givenName">Che-Wei</span> <span class=
          "surName">Liang</span>, Industrial Technology Research
          Institute, Taiwan, <a href=
          "mailto:jared@itri.org.tw">jared@itri.org.tw</a>
        </div>
        <div class="author">
          <span class="givenName">Man-Kwan</span> <span class=
          "surName">Shan</span>, National Chengchi University,
          Taiwan, <a href=
          "mailto:mkshan@nccu.edu.tw">mkshan@nccu.edu.tw</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191625"
        target=
        "_blank">https://doi.org/10.1145/3184558.3191625</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Social media provides a vast continuous supply of
        dynamic and diverse information contents from the crowd,
        which serves as useful resources for predictive analytical
        applications. Although there exist already a number of
        studies on emerging topics detection, they focused on
        modelling of textual contents and emerging detection
        mechanism over topic popularity. To meet the real-life
        demands, prediction of emerging product topic, rather than
        detection, in the early stage is required. Besides, despite
        that some relevant studies considered social structure
        information, they suffer from the assumption that the
        complete network is available and the diffusion process
        only depends on social influence among members of networks.
        Moreover, not all social media sites provide the
        functionality to facilitate the development of online
        social networks. In this paper, we tackle the problem of
        emerging product topics prediction in social network with
        implicit networks. Two tasks, one for long-term forecast in
        pre-production stage and the other for short-term forecast
        in post-release stage, are investigated. We present a novel
        framework named Emerging Topics Predictor (ETP). Two novel
        features, namely author diversity and competition features,
        are also proposed to accommodate the diffusion process with
        implicit networks based on the rationale of product
        marketing. Through empirical evaluation on movie reviews
        from two real social media sites, ETP is shown to provide
        effective and efficient performance in predicting the
        emerging topics as early as possible. In particular, the
        experiment results show the promising effect of author
        diversity in emerging prediction. To the best of our
        knowledge, this work is among the very first studies on
        emerging product topic prediction in social media with
        considerations of implicit networks.</small></p>
      </div>
      <div class="classifications">
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Sinya Peng, Vincent S. Tseng, Che-Wei Liang and Man-Kwan
          Shan. 2018. Emerging Product Topics Prediction in Social
          Media without Social Structure Information. In
          <em>Proceedings of The 2018 Web Conference Companion (WWW
          '18 Companion)</em>. ACM, New York, NY, USA, 13 pages.
          <a href="https://doi.org/10.1145/3184558.3191625" target=
          "_blank">https://doi.org/10.1145/3184558.3191625</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec1">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          INTRODUCTION</h2>
        </div>
      </header>
      <p>With the rapid growth of social media sites, large amounts
      of customer reviews on products are authored, posted, spread
      and propagated over online social networks. The
      instantaneity, accessibility, and popularity of social media
      provide the opportunity for collection of customer opinions,
      estimation of product sales, and prediction of products’
      future trends by discovering patterns from customer
      reviews.</p>
      <p>An increasing number of studies have investigated the
      dynamics of online word-of-mouth. A positive relationship
      between online customer reviews and product sales was found
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#bib10">10</a>]. In parallel,
      other researches also show that the volume of reviews has a
      significant effect on new product sales in the early period
      and such effect decreases over time [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#bib16">16</a>].</p>
      <p>Numerous recent studies have been devoted to tackling the
      problem on detection of emerging topics from social media
      data, specifically, opinions/items that have the potential
      for high popularity due to increased public interests while
      they are not popular currently. Existing researches on
      emerging topic detection focused on the dynamic modeling of
      textual contents and the emerging detection mechanism over
      topic popularity. These works are constrained in the
      detection of emerging topics. To meet the realistic demand of
      providing useful insight by predicting emerging product
      topics in the early stage or before they are materialized,
      prediction (rather than detection) of emerging product topics
      as early as possible is needed.</p>
      <p>Some other research has devoted to the prediction of spike
      time of information cascades over social media. An
      information cascade occurs as information propagates through
      friends. Most research reported that temporal and social
      structure features are key indicators for prediction
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#bib3">3</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#bib8">8</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#bib11">11</a>]. These problems have been solved in the
      aspect of spike prediction on information cascades, but
      remain widely open on the emerging topic prediction with
      implicit network which is shortfall of network structural
      properties. Furthermore, not all social media sites provide
      the functionality to facilitate the development of online
      social networks. The social network over which diffusion
      takes place is unknown. These social news aggregation and
      discussion sites without explicit social network have
      tremendous customer reviews on products. One example is
      Reddit, which had 542 million monthly visitors, ranking as
      the 4th most visited website in U.S. and the 8th in the
      world, as of 2017. Reddit is composed of thousands of user
      created and moderated subreddits, which are discussion boards
      covering a variety of topics including news, movies, music,
      science, and so on.</p>
      <p>Based on the observations as above, in this paper, we
      tackle the problem of emerging product topic prediction in
      social network with implicit networks. Here, an emerging
      product topic indicates a topic of products that gathers a
      significantly growing number of reviews over social media
      (more detailed definition will be given in Section III). Two
      prediction tasks are investigated as follows:</p>
      <p><strong>Task 1:</strong> Given a set of product review
      streams in social media site, which product topics will
      become emerging in the future? How can we predict it
      accurately and as early as possible?</p>
      <p><strong>Task 2:</strong> Given a set of product review
      streams in social media site, which product topics will
      become emerging in the next predicting time interval? How can
      we predict it accurately and as early as possible?</p>
      <p>Task 1 is designed for long-term prediction during the
      early stage of product development. For example, the
      production of a movie is an expensive, risky endeavor. While
      movie fans tend to paid attention to relevant news early in
      the pre-production stage, pre-production analysis and
      prediction from movie discussions authored by fans are
      helpful for decision makers of the film industry. In
      contrast, Task 2 focuses primarily upon short-term prediction
      in the stages of product life cycle. For example, in the
      third week after a movie is released, along with the
      information of simultaneous released movies, the decision
      maker would like to make the prediction for the fourth
      week.</p>
      <p>To tackle the problem of these two tasks over social media
      with implicit network, a novel framework named <em>Emerging
      Topics Predictor</em> (<em>ETP</em>) is proposed. In
      particular, we proposed a new type of features, author
      diversity, to deal with the diffusion process with implicit
      network. Moreover, Products, which perform the same function,
      compete against each other. However, to the best of our
      knowledge, no work has incorporated the competition features
      into the prediction model for emerging topic detection or
      cascade spike prediction. In this paper, another new type of
      feature, namely competition, is proposed for task 2.</p>
      <p>We conducted empirical evaluations on two sets of online
      movie reviews from two real social media sites. While our
      proposed ETP framework can be applied to most types of
      products, we take the task of predicting emerging topics for
      movies as the example to demonstrate and evaluate our
      proposed approach. The idea of taking the movie as the
      primary example comes from the studies from the electronic
      commerce community, which indicates that popularity of
      customer reviews has a greater impact on sales of experience
      products (like movies) than on those of search products (like
      commodities). The experimental results show that ETP delivers
      effective and efficient performance in predicting the
      emerging product topics from social media data.</p>
      <p>The remaining of this paper is organized as follows:
      Section <a class="sec" href="#sec2">2</a> introduces the
      background of emerging topic prediction. Section <a class=
      "sec" href="#sec3">3</a> gives the details of our ETP
      predictor. Experimental evaluation is discussed in Section
      <a class="sec" href="#sec4">4</a>. The last Section presents
      our conclusion.</p>
    </section>
    <section id="sec2">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> RELATED
          WORK</h2>
        </div>
      </header>
      <p>Two primary areas related to our work are emerging topic
      detection, and cascades prediction over social media.</p>
      <p>In the category of emerging topic detection, the existing
      works focused on topic representation and emerging detection
      mechanism. Most research represents a topic as a collection
      of words or hashtags [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#bib2">2</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#bib6">6</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#bib17">17</a>]. For example, Cataldi et al. [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#bib2">2</a>] presented the work that used aging
      theory to mimic the life cycle of each term and define
      emerging topics as sets of terms using a co-occurrence based
      metric. Emerging topics are detected by constructing
      keyword-based topic graph which connects the emerging terms
      with their co-occurrent ones under user-specified time
      constraints. The other approach for topic representation is
      developed based on topic modeling algorithms [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#bib1">1</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#bib5">5</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#bib14">14</a>]. AlSumait et al. [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#bib1">1</a>] proposed Online Latent Dirichlet
      Allocation to incrementally builds an up-to-date model when a
      new document appears. Saha et al. [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#bib14">14</a>] proposed a dynamic non-negative
      matrix factorization framework with a complex temporal
      regularization. Hayashi [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#bib5">5</a>] proposed a new method based on real-time
      streaming non-negative matrix factorization to detect top
      topic in twitter, and filter unrelated advertising tweets.
      These works are constrained in the detection of emerging
      topics, rather than prediction product topics in the early
      stage or before they are materialized.</p>
      <p>In the category of cascade prediction over social media,
      an information cascade such as a photo, a hashtag, is
      considered to occur as information propagates through
      friends. Most work focused on predicting the popularity of
      the cascades [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#bib3">3</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#bib8">8</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#bib11">11</a>]. Ma et al. [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#bib11">11</a>] transformed the hashtag popularity range
      prediction problem into five-class classification problem.
      Content and social context features are investigated. The
      experimental results showed that social context feature are
      more effective than content feature. Kong et al. transform
      the hashtag popularity prediction problem into regression
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#bib8">8</a>]. Among seven types
      of features, social structure is the 3<sup>rd</sup> effective
      feature, which is inferior to temporal and prototype feature.
      Given a cascade, Cheng et al. [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#bib3">3</a>] developed a framework in predicting whether
      the cascade will continue to grow and double the cascade size
      in the future. They reported that structural and temporal and
      features are key predictors of cascade size. In particular,
      initially, breadth, rather than depth in a cascade is a
      better indicator of larger cascades. Wang et al. [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#bib16">16</a>] investigated the
      burst (global spike) time prediction, rather than popularity
      prediction. They proposed a scale-independent
      classification-based approach. Experiments showed that
      fluctuation features are most important while social relation
      features and user profile features, which are Pagerank and
      HITS score of social network, are helpful. All the cascade
      prediction research assumes that the complete network
      information is available. In particular, the experiments
      showed the effectiveness and superiority of social structure
      features. These problems have been solved in the aspect of
      range popularity or spike prediction on information cascades,
      but remain widely open on the emerging topic prediction with
      implicit network, which is shortfall of network structural
      information.</p>
    </section>
    <section id="sec3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> PROPOSED
          METHOD</h2>
        </div>
      </header>
      <section id="sec3Z1">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Problem
            Statements</h3>
          </div>
        </header>
        <p>Briefly, the targeted research problem in this paper is
        early prediction of emerging products topics with implicit
        network. We will start with the definitions of topic,
        popularity and emerging.</p>
        <p><strong>Definition 1 (Time Window)</strong> <em>Time
        window</em> is the minimum time unit to measure popularity
        and features. It should be given before model learning and
        prediction. For example, the time window for emerging
        prediction of movie topic is one day.</p>
        <p><strong>Definition 2 (Topic Popularity)</strong> The
        <em>topic popularity tp</em>(<em>t, c</em>) of product
        topic <em>t</em> in the <em>c</em>-th time window, is the
        number of posts (product reviews) relevant to product topic
        <em>t</em> in the <em>c</em>-th time window.</p>
        <p>Business people do not only look at the topic popularity
        of products, but also the novelty (significance) of
        popularity trends. There exist various definitions of
        emerging topic in the current literature due to different
        research goals. To assess the novelty of a popularity
        trend, we refer to the emerging score defined in [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#bib15">15</a>].</p>
        <p><strong>Definition 3 (Emerging Score)</strong>
        <em>Emerging Score ES</em>(<em>t, c</em>) of a topic
        <em>t</em> in the <em>c-th</em> time window is the
        measurement of the intensity of variation between two
        successive time windows,</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation*}ES\left( {t,c}
            \right) = \frac{{tp\left( {t,\;\;{\rm{c}}} \right) -
            EWMA\left( {tp\left( {t,1} \right),{\rm{\;}}tp\left(
            {t,2} \right),{\rm{\;}} \ldots ,tp\left( {t,{\rm{c}} -
            1} \right)} \right)}}{{1 + EWMStd\left( {tp\left( {t,1}
            \right),{\rm{\;}}tp\left( {t,2} \right),{\rm{\;}}
            \ldots ,p\left( {t,{\rm{\;c}} - 1} \right)}
            \right)}}\end{equation*}</span><br />
          </div>
        </div>where <em>EWMA</em> is exponentially weighted moving
        average, <em>EWMStd</em> is exponentially weighted moving
        standard deviation.
        <p></p>
        <p><strong>Definition 4 (Emerging Product Topic)</strong>
        Product topic <em>t</em> is emerging in the <em>c</em>-th
        time window, if <em>ES</em>(<em>t, c</em>) is larger than a
        specified threshold.</p>
        <p><strong>Definition 5 (Problem Statement of Task
        1)</strong> Given a set of product review streams in social
        media site, the objective of task 1 is to predict which
        product topic <em>t</em> will emerge after current time
        window.</p>
        <p>Task 1 is designed for long-term prediction in the
        pre-production stage. As illustrated in Figure <a class=
        "fig" href="#fig1">1</a>, the <strong><em>observed time
        interval</em></strong> is the blue-shaded period where the
        solid curve is the current observed data while the dashed
        curve is the future data. Typically, the observed time
        interval of a product topic <em>t</em> for task 1 starts
        from the first time window of product topic <em>t</em>.</p>
        <figure id="fig1">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image1.png"
          class="img-responsive" alt="Figure 1:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span>
            <span class="figure-title">The Illustration of Two
            Prediction Tasks.</span>
          </div>
        </figure>
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image2.PNG"
          class="img-responsive" alt="Figure 2:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">The Illustration of Emerging
            Product Topic.</span>
          </div>
        </figure>
        <p><strong>Definition 6 (Problem Statement of Task
        2)</strong> Given a set of product review streams in social
        media site, the objective of task 2 is to predict which
        product topic <em>t</em> will emerge in the next
        <strong><em>predicted time interval</em></strong> .</p>
        <p>Task 2 is designed for short-term prediction after a
        product is launched. The <em>granularity</em> of the
        predicted time interval depends on the characteristics of a
        product. For example, in general, movies are released on
        Friday and the box office sales of movies are measured in
        terms of week. Therefore, the predicted time interval of
        task 2 for movies is set to the next week. Note that the
        observed time interval of task 2 is not the same as that of
        task 1 either. It is specified by the user. For example,
        film companies typically pay attention to the critical
        period which starts from two weeks before the movie is
        leased to four weeks after release. Therefore, as
        illustrated in Figure <a class="fig" href="#fig1">1</a>, on
        Monday of week 3 after release, a film company wishes to
        predict whether the movie will emerge in week 4. In this
        case, the observed time interval is the blue-shaded period
        while the predicted time interval is the 4<sup>th</sup>
        week after release.</p>
      </section>
      <section id="sec3Z2">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Framework
            of ETP (Emerging Topic Prediction)</h3>
          </div>
        </header>
        <p>The ETP predictor we proposed is shown in Figure
        <a class="fig" href="#fig3">3</a>. In offline phase,
        <em>Prediction Models</em> are constructed from the
        training data. First, <em>Product Topic Identification</em>
        module identifies the product topic of each post by
        named-entity extraction techniques. We assume that a
        dictionary of product names is available. For example, it
        is easy to get the movie titles and associated information
        from IMDB (http://www.imdb.com). Even with the dictionary
        of product names, it is not trivial to identify the product
        topic. Most movie names have alias. For example, the
        aliases appearing in reviews on the movie “The Fast and the
        Furious 6” includes of “Fast &amp; Furious 6”, “f&amp;f6”,
        “FAF6”, “ff6”, and so on. Besides, some reviews comment on
        multiple movies for comparison. The basic approach is to
        determine the product topic based on the frequencies of
        product names appearing in the post using the dictionary
        along with alias list.</p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image3.PNG"
          class="img-responsive" alt="Figure 3:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">The proposed ETP
            Framework.</span>
          </div>
        </figure>
        <p>Having identified the product topic of each training
        post, the <em>Emerging Product Topic Detection</em> module
        collects the stream of posts for each topic <em>t</em>, and
        for each time window <em>c</em>, assesses the emerging
        score <em>ES</em>(<em>t, c</em>) and determine whether
        product topic <em>t</em> is emerging in the <em>c</em>-th
        time window.</p>
        <p><em>Model Learning</em> module consists of a set of
        binary classification algorithms and constructs different
        prediction models for different length of observed time
        interval. For a long-term prediction model
        <em>LM<sub>l</sub></em> of task 1, each stream of product
        <em>t</em> in the observed time interval [<span class=
        "inline-equation"><span class=
        "tex">$tw_1^t,\;tw_l^t$</span></span> ] is regarded as a
        training sample where <span class=
        "inline-equation"><span class="tex">$tw_i^t$</span></span>
        is the <em>i-</em>th time window of product topic
        <em>t</em>. Those emerge after time window <em>l</em> are
        positive while others are negative samples. For a
        short-term prediction model <em>SM<sub>l</sub></em> of task
        2, each product stream in the designated observed time
        interval of length <em>l</em> is a training sample. Those
        emerge in the predicted time interval are positive while
        others are negative samples. As shown in Figure <a class=
        "fig" href="#fig1">1</a>, the solid curves in the
        blue-shaded interval are the samples of observed length
        <em>l</em>. For each sample, <em>Feature Construction</em>
        module extracts four and five types of features for task 1
        and task 2 respectively in terms of time window, which are
        described in the following sections.</p>
        <p>Given incoming stream of product reviews, after
        <em>Product Topic Identification</em> and <em>Feature
        Construction</em>, for products in the pre-production stage
        with observed length <em>l</em>, long-term prediction model
        <em>LM<sub>l</sub></em> is employed to perform task 1 while
        for products in the opening weeks after launch, short-term
        prediction model <em>SM<sub>l</sub></em> is employed to
        perform task 2.</p>
      </section>
      <section id="sec3Z3">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span> Author
            Diversity Feature</h3>
          </div>
        </header>
        <p>Social structure feature is widely utilized in most
        existing research on spike prediction of information
        cascades over social media [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#bib3">3</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#bib8">8</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#bib11">11</a>]. Structure information of users and
        patterns of spreading paths to measure the broadness and
        depth of diffusion process are helpful for prediction of
        future trend. The rational behind social structure lies in
        that high viral cascades tend to spread across communities.
        For example, in [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#bib3">3</a>], the density of the first-<em>k</em>
        re-share cascade is utilized to measure the tendency
        whether the diffusion is spreading across communities.</p>
        <p>To predict emerging product topic in social media
        without social structure information, we proposed the
        author diversity features to assess the spreading tendency
        across different categories of users. The idea of the
        author diversity comes from the market segmentation in
        business. Market segmentation is the process of grouping
        consumers in the market into categories (known as
        segmentation) based on some types of shared
        characteristics. We categorize authors by preference,
        influence, engagement, and adoption respectively, and
        proposed four types of author diversities as follows. Note
        that the preference, influence, engagement, and adoption of
        an author are derived from the posting information of the
        author up to the current time window and are updated
        dynamically over time.</p>
        <p><strong>Definition 7 (Author's Preference)</strong>
        Given the number of posts <span class=
        "inline-equation"><span class="tex">$n{p_i}( x
        )$</span></span> of genre <em>i</em> authored by
        <em>x</em>, the preference <span class=
        "inline-equation"><span class="tex">$pr{f_i}( x
        )$</span></span> of author <em>x</em> for genre <em>i</em>
        is set to <span class="inline-equation"><span class=
        "tex">$n{p_i}( x )$</span></span> in numerical mode, while
        in binary mode, <span class="inline-equation"><span class=
        "tex">$pr{f_i}( x )$</span></span> is set to one if
        <span class="inline-equation"><span class="tex">$n{p_i}( x
        )$</span></span> is maximum among all genres and zero
        otherwise.</p>
        <ul class="list-no-style">
          <li>preference of author x for genre i (binary mode)
            <div class="table-responsive">
              <div class="display-equation">
                <span class=
                "tex mytex">\begin{equation*}pr{f_i}\left( x
                \right) = \left\{ {\begin{array}{@{}*{1}{c}@{}}
                {1\;\;\;if\;i = arg\mathop {\max }\limits_j \left(
                {n{p_j}\left( x \right)} \right)}\\
                {0\;\;\;otherwise\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;}
                \end{array}} \right.\end{equation*}</span><br />
              </div>
            </div><br />
          </li>
          <li>preference of author <em>x</em> for genre <em>i</em>
          (numerical mode)
            <div class="table-responsive">
              <div class="display-equation">
                <span class=
                "tex mytex">\begin{equation*}pr{f_i}\left( x
                \right) = n{p_i}\left( x
                \right)\end{equation*}</span><br />
              </div>
            </div><br />
          </li>
        </ul>
        <p></p>
        <p><strong>Definition 8 (Preference Diversity)</strong> The
        authors’ preferences <span class=
        "inline-equation"><span class="tex">${q_i}( c
        )$</span></span> for genre <em>i</em> in time window
        <em>c</em> is the summation of the preference <span class=
        "inline-equation"><span class="tex">$pr{f_i}( x
        )$</span></span> for all authors <em>x</em> who have
        published posts during the time interval [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#bib1">1</a>, <em>c</em>]. The preference
        diversity <em>PD</em>(<em>c</em>) in time window <em>c</em>
        is measured by entropy to quantify the impurity of authors
        in terms of preference of genres. <em>PD</em>(<em>c</em>)
        is defined as</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray*}&amp;&amp;
            PD\left( c \right) = - \mathop \sum \limits_{{\rm{i}} =
            1}^n {p_i}\left( c
            \right){\rm{lo}}{{\rm{g}}_2}{p_i}\left( c \right),\\
            &amp;&amp;{\rm where}\; p_i(c) =
            {}^{\displaystyle{q_i(c)}}\!\!\bigg{/}\!\!{}_{\displaystyle\sum\nolimits^n_{i=1}q_i(c)'}\\
            &amp;&amp;{q_i}\left( c \right) = \mathop \sum
            \limits_{t = 1}^{\rm{c}} \mathop \sum \limits_{x =
            1}^{{m_t}} pr{f_{\rm{i}}}\left( {\rm{x}} \right),
            \end{eqnarray*}</span>
          </div><em>c</em> is the index of current time window,
          <em>m<sub>t</sub></em> is total number of authors in time
          window <em>t</em>, and <em>n</em> is total number of
          genres.
          <p></p>
          <p><strong>Definition 9 (Author's Influence)</strong>
          Given total number of responses <span class=
          "inline-equation"><span class="tex">$n{r_i}( x
          )$</span></span> with respect to all posts of genre
          <em>i</em> authored by <em>x</em>, the influence
          <span class="inline-equation"><span class="tex">$in{f_i}(
          x )$</span></span> of author <em>x</em> on genre
          <em>i</em> is set to <span class=
          "inline-equation"><span class="tex">$n{r_i}( x
          )$</span></span> in numerical mode, while in binary mode,
          <span class="inline-equation"><span class="tex">$in{f_i}(
          x )$</span></span> is set to one if <span class=
          "inline-equation"><span class="tex">$n{r_i}( x
          )$</span></span> is maximum among all genres and zero
          otherwise.</p>
          <ul class="list-no-style">
            <li>• influence of author <em>x</em> on genre
            <em>i</em> (binary mode)<br /></li>
          </ul>
          <p></p>
          <p><span class="inline-equation"><span class=
          "tex">$in{f_i}( x ) = \{ {\begin{array}{@{}*{1}{c}@{}}
          {1\;if\;i = arg\mathop {\max }\limits_j ( {n{r_j}( x )}
          )}\\
          {0\;\;else\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;}
          \end{array}} $</span></span></p>
          <ul class="list-no-style">
            <li>• influence of author <em>x</em> on genre
            <em>i</em> (numerical mode)<br /></li>
          </ul>
          <p></p>
          <p><span class="inline-equation"><span class=
          "tex">$in{f_i}( x ) = n{r_i}( x )$</span></span></p>
          <p><strong>Definition 10 (Influence Diversity)</strong>
          The cumulative authors’ influence <span class=
          "inline-equation"><span class="tex">${q_i}( c
          )$</span></span> on genre <em>i</em> up to the current
          time window <em>c</em> is the summation of the influence
          <span class="inline-equation"><span class="tex">$in{f_i}(
          x )$</span></span> for all authors <em>x</em> who have
          published posts during the time interval [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#bib1">1</a>, <em>c</em>]. The
          influence diversity <em>ID</em>(<em>c</em>) in time
          window <em>c</em> is measured by entropy in the following
          to quantify the impurity of authors in terms of influence
          of genres. <em>ID</em>(<em>c</em>) is defined as</p>
          <p><span class="inline-equation"><span class="tex">$ID(
          {\rm{c}} ) = - \mathop \sum \limits_{{\rm{i}} = 1}^n
          {p_i}( c ){\rm{lo}}{{\rm{g}}_2}{p_i}$</span></span>
          ,<br />
          where <span class="inline-equation"><span class=
          "tex">${q_i}( c ) = \mathop \sum \limits_{t = 1}^{\rm{c}}
          \mathop \sum \limits_{x = 1}^{{m_t}} in{f_i}( x
          ),$</span></span><br />
          <span class="inline-equation"><span class="tex">$p_i(c) =
          {}^{\displaystyle{q_i(c)}}\!\!\bigg{/}\!\!{}_{\displaystyle\sum\nolimits^n_{i=1}q_i(c)'}$</span></span></p>
          <p>and definitions of <em>c, m<sub>t</sub></em> and
          <em>n</em>, are the same as those in Definition 5.</p>
          <p><strong>Definition 11 (Author's Engagement)</strong>
          The engagement of an author is measured by the gap (time
          interval) between two successive posts. In this paper,
          all the gaps are discretized into <em>el</em> levels.
          Given the number of posts <span class=
          "inline-equation"><span class="tex">$n{r_i}( x
          )$</span></span> with engagement level <em>i</em>
          authored by <em>x</em>, the engagement <span class=
          "inline-equation"><span class="tex">$en{g_i}( x
          )$</span></span> of author <em>x</em> for level
          <em>i</em> is set to <span class=
          "inline-equation"><span class="tex">$n{r_i}( x
          )$</span></span> in numerical mode, while in binary mode,
          <span class="inline-equation"><span class="tex">$en{g_i}(
          x )$</span></span> is set to one if <span class=
          "inline-equation"><span class="tex">$n{r_i}( x
          )$</span></span> is maximum among all levels and zero
          otherwise.</p>
          <ul class="list-no-style">
            <li>engagement of author <em>x</em> at level <em>i</em>
            (binary mode)<br /></li>
          </ul><span class="inline-equation"><span class=
          "tex">$en{g_i}( x ) = \{ {\begin{array}{@{}*{1}{c}@{}}
          {1\;if\;i = arg\mathop {\max }\limits_j ( {n{r_j}( x )}
          )}\\
          {0\;\;else\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;}
          \end{array}} $</span></span>
          <ul class="list-no-style">
            <li>engagement of author <em>x</em> at level <em>i</em>
            (numerical mode)<br /></li>
          </ul><span class="inline-equation"><span class=
          "tex">$en{g_i}( x ) = n{r_i}( x )$</span></span>
          <p></p>
          <p><strong>Definition 12 (Engagement Diversity)</strong>
          The cumulative authors’ engagement <span class=
          "inline-equation"><span class="tex">${q_i}( c
          )$</span></span> on level <em>i</em> up to the current
          time window <em>c</em> is the summation of the engagement
          <span class="inline-equation"><span class="tex">$en{g_i}(
          x )$</span></span> for all authors <em>x</em> who have
          published posts during the time interval [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#bib1">1</a>, <em>c</em>]. The
          engagement diversity <em>ED</em>(<em>c</em>) in time
          window <em>c</em> is measured by entropy in the following
          to quantify the impurity of authors in terms of
          engagement levels. <em>ED</em>(<em>c</em>) is defined
          as</p>
          <p><span class="inline-equation"><span class="tex">$ED(
          {\rm{c}} ) = - \mathop \sum \limits_{{\rm{i}} = 1}^{el}
          {p_i}( c ){\rm{lo}}{{\rm{g}}_2}{p_i}( c
          )$</span></span><br />
          where <span class="inline-equation"><span class=
          "tex">${q_i}( c ) = \mathop \sum \limits_{t = 1}^c
          \mathop \sum \limits_{x = 1}^{{m_t}} en{g_{\rm{i}}}( x
          )$</span></span> ,<br />
          <span class="inline-equation"><span class="tex">$p_i(c) =
          {}^{\displaystyle{q_i(c)}}\!\!\bigg{/}\!\!{}_{\displaystyle\sum\nolimits^n_{i=1}q_i(c)'}$</span></span></p>
          <p>and definitions of parameters are of the same as those
          in Definition 5 except that <em>el</em> is number of
          engagement levels.</p>
          <p>According to Diffusion of Innovation Theory [<a class=
          "bib" data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#bib13">13</a>], originated in
          communication studies to explain the diffusion process of
          an idea or a product over time through a social system,
          some individuals are more apt to adopt the innovation
          (new product, or new idea) than others. There are five
          categories of adopters, innovators, early adopters, early
          majority, late majority and laggards (<a class="fig"
          href="#fig4">Fig. 4</a>). Based on the posting order of a
          post in the corresponding topic stream <em>t</em>, it is
          easy to determine the category (adoption level) of the
          author in <em>t</em>.</p>
          <figure id="fig4">
            <img src=
            "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image4.png"
            class="img-responsive" alt="Figure 4:" longdesc="" />
            <div class="figure-caption">
              <span class="figure-number">Figure 4:</span>
              <span class="figure-title">Adopters in Diffusion of
              Innovation<sup>3.</sup></span>
            </div>
          </figure>
          <p><strong>Definition 13 (Author's Adoption)</strong>
          Given total number of posts <span class=
          "inline-equation"><span class="tex">$np{a_i}( x
          )$</span></span> for all posts of adoption level
          <em>i</em> authored by <em>x</em>, the adoption
          <span class="inline-equation"><span class="tex">$ad{p_i}(
          x )$</span></span> of author <em>x</em> on genre
          <em>i</em> is set to <span class=
          "inline-equation"><span class="tex">$np{a_i}( x
          )$</span></span> in numerical mode, while in binary mode,
          <span class="inline-equation"><span class="tex">$ad{p_i}(
          x )$</span></span> is set to one if <span class=
          "inline-equation"><span class="tex">$np{a_i}( x
          )$</span></span> is maximum among all genres and zero
          otherwise.</p>
          <ul class="list-no-style">
            <li>• adoption of author <em>x</em> at level <em>i</em>
            (binary mode)<br /></li>
          </ul><span class="inline-equation"><span class=
          "tex">$ad{p_i}( x ) = \{ {\begin{array}{@{}*{1}{c}@{}}
          {1\;if\;i = arg\mathop {\max }\limits_j ( {np{a_j}( x )}
          )}\\
          {0\;\;else\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;}
          \end{array}} $</span></span>
          <ul class="list-no-style">
            <li>• influence of author x at category i (numerical
            mode)<br /></li>
          </ul><span class="inline-equation"><span class=
          "tex">$ad{p_i}( x ) = np{a_i}( x )$</span></span>
          <p></p>
          <p><strong>Definition 14 (Adoption Diversity)</strong>
          The cumulative authors’ adoption <span class=
          "inline-equation"><span class="tex">${q_i}( c
          )$</span></span> on level <em>i</em> up to the current
          time window <em>c</em> is the summation of the engagement
          <span class="inline-equation"><span class="tex">$ad{p_i}(
          x )$</span></span> for all authors <em>x</em> who have
          published posts during the time interval [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#bib1">1</a>, <em>c</em>]. The
          adoption diversity <em>AD</em>(<em>c</em>) in time window
          <em>c</em> is measured by entropy in the following to
          quantify the impurity of authors in terms of adoption
          levels. <em>AD</em>(<em>c</em>) is defined as</p>
          <p><span class="inline-equation"><span class="tex">$AD(
          {\rm{c}} ) = - \mathop \sum \limits_{i = 1}^{al} {p_i}( c
          ){\rm{lo}}{{\rm{g}}_2}{p_i}( c )$</span></span><br />
          where <span class="inline-equation"><span class=
          "tex">${q_i}( c ) = \mathop \sum \limits_{t = 1}^c
          \mathop \sum \limits_{x = 1}^{{m_t}} ad{p_i}( x
          )$</span></span><br />
          <span class="inline-equation"><span class="tex">$p_i(c) =
          {}^{\displaystyle{q_i(c)}}\!\!\bigg{/}\!\!{}_{\displaystyle\sum\nolimits^n_{i=1}q_i(c)}$</span></span></p>
          <p>and the definitions of parameters are of the same as
          those in Definition 5 except that <em>al</em> is number
          of adoption levels.</p>
        </div>
      </section>
      <section id="sec3Z4">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.4</span> Competition
            Feature</h3>
          </div>
        </header>
        <p>Competition is a major principle of market economies.
        Competition occurs naturally among products in the same
        market. Products, which perform the same function, compete
        against each other under the budget constraints. For
        example, <a class="fig" href="#fig5">Fig. 5</a> shows the
        interplay of review popularities among three concurrent
        movies, Interstellar, Ghostbusters and Deadpool. It is
        therefore essential to take the competition nature into
        consideration for task 2. Recent studies have considered
        the competition effect for modeling of diffusion process.
        However, to the best of our knowledge, no work has
        incorporated the competition features into the prediction
        model for emerging topic or spike cascade prediction.</p>
        <figure id="fig5">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image5.png"
          class="img-responsive" alt="Figure 5:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span>
            <span class="figure-title">Popularity Interaction among
            Products.</span>
          </div>
        </figure>
        <p>In this paper, we take the status of concurrent products
        into consideration. For a given target product, concurrent
        products are those whose launch periods up to now are
        overlapping with that of the target product (Sometimes, we
        may also shift the overlapping earlier to the pre-launch
        stage for promotion). We derive the following competition
        features.</p>
        <ul class="list-no-style">
          <li>• Number of concurrent products<br /></li>
          <li>• Number of concurrent products in terms of
          genre<br /></li>
          <li>• Number of emerging concurrent products up to now in
          terms of genre<br /></li>
          <li>• Number of emerging concurrent products over last
          week in terms of genre<br /></li>
          <li>• Correlation of review popularity between concurrent
          product and target product in terms of genre<br /></li>
          <li>• Number of time windows since the latest emerging
          event of concurrent product<br /></li>
        </ul>
        <p></p>
        <p>Note that the correlation of popularity for a genre is
        the maximal Pearson Correlation among all concurrent
        products belonging to this genre.</p>
      </section>
      <section id="sec3Z5">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.5</span> Temporal,
            Content, and User Features</h3>
          </div>
        </header>
        <p>In addition to the proposed author diversity and
        competition features, we also derive three typical types of
        features as follows. All the following features are
        extracted in the unit of time window except that the
        product start time is a global feature.</p>
        <p>Temporal features</p>
        <ul class="list-no-style">
          <li>• Total number of posts/responses till now<br /></li>
          <li>• Number of posts/responses in the last time
          window<br /></li>
          <li>• Average velocity of popularity<br /></li>
          <li>• Average acceleration of popularity<br /></li>
          <li>• Longest active time interval till now in terms of
          time window<br /></li>
          <li>• Longest inactive time interval till now in terms of
          time window<br /></li>
          <li>• Statistics of time interval between two
          posts/responses<br /></li>
          <li>• Number of emerging ones till now<br /></li>
          <li>• Number of time windows since the latest emerging
          event<br /></li>
          <li>• Start time of this product topic
          (Global)<br /></li>
          <li>• Latest time of this product topic<br /></li>
          <li>• Average popular time during a day<br /></li>
          <li>• Most popular day during a week<br /></li>
          <li>• Most popular month during a season<br /></li>
          <li>• Piecewise aggregate approximation of time between
          posts<br /></li>
          <li>• Statistics of 33.3% percentile of time between
          posts<br /></li>
        </ul>
        <p></p>
        <p>Content features</p>
        <ul class="list-no-style">
          <li>• Average number of lines per post<br /></li>
          <li>• Average number of words per post<br /></li>
          <li>• Average sentiment score of a post<br /></li>
        </ul>
        <p></p>
        <p>User features</p>
        <ul class="list-no-style">
          <li>• Total number of distinct authors till
          now<br /></li>
          <li>• Statistics of number of responses received by a
          author/responser<br /></li>
        </ul>
        <p></p>
      </section>
    </section>
    <section id="sec-004">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> EXPERIMENTAL
          EVALUATION</h2>
        </div>
      </header>
      <section id="sec4Z1">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Datasets
            and Experiment Setting</h3>
          </div>
        </header>
        <p>To evaluate the performance of our proposed approaches,
        we have performed experiments on real movie review data
        from Reddit (https://www.reddit.com) and PTT
        (https:/www.ptt.cc).</p>
        <p>Reddit is the 4<sup>th</sup> most visit sites in U.S.
        According to Alexa Traffic Rank over the past 3 months,
        Reddit is ranked 7th in the world and 5th in U.S. As of
        Dec. 2017, Reddit has 234 million registered users, 50,000
        active sub-reddits, 5 millions comments every day while the
        movies subreddit has more than 16 million subscribers. The
        Reddit dataset comes from the Datasets subreddit. We
        extract the posts along with comments in the Movie
        subreddit from January 2013 to December 2016. There are
        867,468 posts, 15,442,009 comments, 1,205,248 users
        (including authors and responders). Posts containing
        <em>url</em> only are filtered out first. In the end, 711
        movies are identified, after product topic identification
        with the movie dictionary crawled from IMDB.</p>
        <p>PTT is the largest bulletin board system in Taiwan.
        According to Alexa Traffic Rank over the past 3 months, PTT
        is ranked 15th in Taiwan. PTT has 1.5 million registered
        users, over 20,000 boards, 20,000 articles and 0.5 million
        comments every day. The PTT dataset is collected from our
        developed crawler. There are 117,328 posts, 3,554,029
        comments, 154,307 users and 486 movies are identified. The
        movie dictionary, which contains Chinese movie names and
        release dates in Taiwan, is crawled from TrueMovie
        (http://www.truemovie.com).</p>
        <p>We use five-fold cross-validation to evaluate on
        accuracy, precision, and recall for emerging topic
        prediction. Experiments are performed to evaluate the
        prediction performance versus observed length,
        classification algorithm, and features.</p>
      </section>
      <section id="sec4Z2">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Performance
            for Task 1</h3>
          </div>
        </header>
        <p>Figure <a class="fig" href="#fig6">6</a> shows the
        accuracy as a function of observed length for comparison of
        various classification algorithms, Random Forest (RF),
        Logistic Regression (LR), Support Vector Machines (SVM) and
        Gradient Boosting Decision Tree (GBDT), on Reddit. Random
        Forest performs best with accuracy over 90% except the
        first time window. The accuracy of all algorithms is better
        than 85% in spite of the observed length. It is no surprise
        that the performance improves approximately with increasing
        observed length except some time intervals.</p>
        <figure id="fig6">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image6.PNG"
          class="img-responsive" alt="Figure 6:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 6:</span>
            <span class="figure-title">Accuracy versus Observed
            Length of Different Algorithms of Task 1 in
            Reddit.</span>
          </div>
        </figure>
        <p>To explore the prediction performance more in depth,
        Table <a class="tbl" href="#tb1">1</a> lists the earliness,
        accuracy, precision, and recall for various observed length
        on Reddit using Random Forest.</p>
        <div class="table-responsive" id="tb1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Earliness, Precision and Recall versus
            Observed Length using Random Forest of Task 1 in
            Reddit.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;" rowspan="2">
                <strong>Length</strong></th>
                <th style="text-align:center;" rowspan="2">
                <strong>Earliness (Days)</strong></th>
                <th style="text-align:center;" rowspan="2">
                <strong>Accuracy</strong></th>
                <th style="text-align:center;" colspan="2">
                <strong>Emerging</strong></th>
                <th style="text-align:center;" colspan="2">
                <strong>Non-Emerging</strong></th>
              </tr>
              <tr>
                <th style="text-align:center;">
                <strong>Precision</strong></th>
                <th style="text-align:center;">
                <strong>Recall</strong></th>
                <th style="text-align:center;">
                <strong>Precision</strong></th>
                <th style="text-align:center;">
                <strong>Recall</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">
                <strong>1</strong></td>
                <td style="text-align:center;">293.532</td>
                <td style="text-align:center;">0.888886</td>
                <td style="text-align:center;">0.799</td>
                <td style="text-align:center;">0.367</td>
                <td style="text-align:center;">0.896</td>
                <td style="text-align:center;">0.983</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>3</strong></td>
                <td style="text-align:center;">291.532</td>
                <td style="text-align:center;">0.905022</td>
                <td style="text-align:center;">0.868</td>
                <td style="text-align:center;">0.412</td>
                <td style="text-align:center;">0.909</td>
                <td style="text-align:center;">0.988</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>5</strong></td>
                <td style="text-align:center;">289.532</td>
                <td style="text-align:center;">0.912066</td>
                <td style="text-align:center;">0.893</td>
                <td style="text-align:center;">0.437</td>
                <td style="text-align:center;">0.914</td>
                <td style="text-align:center;">0.991</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>7</strong></td>
                <td style="text-align:center;">287.532</td>
                <td style="text-align:center;">0.907235</td>
                <td style="text-align:center;">0.850</td>
                <td style="text-align:center;">0.427</td>
                <td style="text-align:center;">0.913</td>
                <td style="text-align:center;">0.987</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>9</strong></td>
                <td style="text-align:center;">285.532</td>
                <td style="text-align:center;">0.912942</td>
                <td style="text-align:center;">0.899</td>
                <td style="text-align:center;">0.446</td>
                <td style="text-align:center;">0.915</td>
                <td style="text-align:center;">0.991</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>11</strong></td>
                <td style="text-align:center;">283.532</td>
                <td style="text-align:center;">0.913653</td>
                <td style="text-align:center;">0.912</td>
                <td style="text-align:center;">0.420</td>
                <td style="text-align:center;">0.915</td>
                <td style="text-align:center;">0.993</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>13</strong></td>
                <td style="text-align:center;">281.532</td>
                <td style="text-align:center;">0.912306</td>
                <td style="text-align:center;">0.904</td>
                <td style="text-align:center;">0.409</td>
                <td style="text-align:center;">0.915</td>
                <td style="text-align:center;">0.991</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>15</strong></td>
                <td style="text-align:center;">279.532</td>
                <td style="text-align:center;">0.917842</td>
                <td style="text-align:center;">0.914</td>
                <td style="text-align:center;">0.431</td>
                <td style="text-align:center;">0.920</td>
                <td style="text-align:center;">0.992</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>17</strong></td>
                <td style="text-align:center;">277.532</td>
                <td style="text-align:center;">0.915921</td>
                <td style="text-align:center;">0.921</td>
                <td style="text-align:center;">0.401</td>
                <td style="text-align:center;">0.916</td>
                <td style="text-align:center;">0.994</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>19</strong></td>
                <td style="text-align:center;">275.532</td>
                <td style="text-align:center;">0.917961</td>
                <td style="text-align:center;">0.897</td>
                <td style="text-align:center;">0.421</td>
                <td style="text-align:center;">0.920</td>
                <td style="text-align:center;">0.993</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>21</strong></td>
                <td style="text-align:center;">273.532</td>
                <td style="text-align:center;">0.920382</td>
                <td style="text-align:center;">0.918</td>
                <td style="text-align:center;">0.419</td>
                <td style="text-align:center;">0.921</td>
                <td style="text-align:center;">0.994</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>23</strong></td>
                <td style="text-align:center;">271.532</td>
                <td style="text-align:center;">0.923339</td>
                <td style="text-align:center;">0.926</td>
                <td style="text-align:center;">0.434</td>
                <td style="text-align:center;">0.924</td>
                <td style="text-align:center;">0.994</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>25</strong></td>
                <td style="text-align:center;">269.532</td>
                <td style="text-align:center;">0.923020</td>
                <td style="text-align:center;">0.907</td>
                <td style="text-align:center;">0.436</td>
                <td style="text-align:center;">0.924</td>
                <td style="text-align:center;">0.994</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>27</strong></td>
                <td style="text-align:center;">267.532</td>
                <td style="text-align:center;">0.925717</td>
                <td style="text-align:center;">0.913</td>
                <td style="text-align:center;">0.439</td>
                <td style="text-align:center;">0.927</td>
                <td style="text-align:center;">0.994</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>29</strong></td>
                <td style="text-align:center;">265.532</td>
                <td style="text-align:center;">0.924268</td>
                <td style="text-align:center;">0.931</td>
                <td style="text-align:center;">0.402</td>
                <td style="text-align:center;">0.924</td>
                <td style="text-align:center;">0.996</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>31</strong></td>
                <td style="text-align:center;">263.532</td>
                <td style="text-align:center;">0.925810</td>
                <td style="text-align:center;">0.902</td>
                <td style="text-align:center;">0.433</td>
                <td style="text-align:center;">0.928</td>
                <td style="text-align:center;">0.993</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p><strong>Definition 15 (Earliness for Task 1)</strong>
        The earliness <span class="inline-equation"><span class=
        "tex">$k_l^t$</span></span> of a long-term prediction model
        <em>LM<sub>l</sub></em> with respect to a product topic
        <em>t</em> is the number of time windows from time window
        <em>l</em> to the first emerging time window.</p>
        <p>Earliness depends on the observed length and the
        emerging time (Figure <a class="fig" href="#fig1">1</a>).
        Intuitively, the longer the observed length, the better the
        prediction accuracy, but the shorter the earliness. From
        Table <a class="tbl" href="#tb1">1</a>, it can be seen that
        the proposed prediction model for task 1 achieves promising
        accuracy of at least 91% as early as 285 days in average
        before the first emerging event. Moreover, the accuracy
        could be improved by improving the recall of emerging
        topics.</p>
        <p>As most research on prediction over social media
        reported that temporal and social structure-related types
        of features are key indicators [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#bib3">3</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#bib8">8</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#bib11">11</a>], Figure <a class="fig" href="#fig7">7</a>
        examines the effect of proposed author diversity features
        against other types of features. The proposed diversity
        features surprisingly perform not only better than other
        features but also near the full set of features. This
        implies that the proposed author diversity is a
        well-performed predictor for prediction with implicit
        network.</p>
        <figure id="fig7">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image7.PNG"
          class="img-responsive" alt="Figure 7:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 7:</span>
            <span class="figure-title">Accuracy versus Observed
            Length of Different Features using Random Forest of
            Task 1 in Reddit.</span>
          </div>
        </figure>
        <p>Figure <a class="fig" href="#fig8">8</a>, Table
        <a class="tbl" href="#tb2">2</a> and Figure <a class="fig"
        href="#fig9">9</a> show the results of the same experiments
        on PTT. Again, Random Forest performs best, but the
        prediction accuracy is better than that on Reddit. By
        observing Table <a class="tbl" href="#tb2">2</a> where
        <em>ETP</em> on PTT achieves 95% accuracy as early as 104
        days before the first emerging event, the reason may come
        from shorter earliness of PTT comparing to that of Reddit.
        Shorter earliness tends to predict better. Users of PTT
        from Taiwan are less apt to access movie news in the early
        stage of pre-production from Hollywood than those in
        Reddit. Moreover, Figure <a class="fig" href="#fig9">9</a>
        also reveals that the proposed author diversity is a good
        predictor. But the superiority is not as promising as that
        on Reddit. This can be explained by inspecting the author
        diversities between Reddit and PTT. In average, authors of
        Reddit are more diverse than those of PTT.</p>
        <figure id="fig8">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image8.PNG"
          class="img-responsive" alt="Figure 8:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 8:</span>
            <span class="figure-title">Accuracy versus Observed
            Length of Different Algorithms of Task 1 in PTT.</span>
          </div>
        </figure>
        <div class="table-responsive" id="tb2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Earliness, Precision and Recall versus
            Observed Length using Random Forest of Task 1 in
            PTT.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;" rowspan="2">
                <strong>Length</strong></th>
                <th style="text-align:center;" rowspan="2">
                <strong>Earliness (Days)</strong></th>
                <th style="text-align:center;" rowspan="2">
                <strong>Accuracy</strong></th>
                <th style="text-align:center;" colspan="2">
                <strong>Emerging</strong></th>
                <th style="text-align:center;" colspan="2">
                <strong>Non-Emerging</strong></th>
              </tr>
              <tr>
                <th style="text-align:center;">
                <strong>Precision</strong></th>
                <th style="text-align:center;">
                <strong>Recall</strong></th>
                <th style="text-align:center;">
                <strong>Precision</strong></th>
                <th style="text-align:center;">
                <strong>Recall</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">
                <strong>1</strong></td>
                <td style="text-align:center;">110.257</td>
                <td style="text-align:center;">0.927874</td>
                <td style="text-align:center;">0.852</td>
                <td style="text-align:center;">0.844</td>
                <td style="text-align:center;">0.953</td>
                <td style="text-align:center;">0.953</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>3</strong></td>
                <td style="text-align:center;">108.257</td>
                <td style="text-align:center;">0.927226</td>
                <td style="text-align:center;">0.840</td>
                <td style="text-align:center;">0.839</td>
                <td style="text-align:center;">0.955</td>
                <td style="text-align:center;">0.952</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>5</strong></td>
                <td style="text-align:center;">106.257</td>
                <td style="text-align:center;">0.938029</td>
                <td style="text-align:center;">0.858</td>
                <td style="text-align:center;">0.856</td>
                <td style="text-align:center;">0.962</td>
                <td style="text-align:center;">0.960</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>7</strong></td>
                <td style="text-align:center;">104.257</td>
                <td style="text-align:center;">0.951381</td>
                <td style="text-align:center;">0.895</td>
                <td style="text-align:center;">0.873</td>
                <td style="text-align:center;">0.968</td>
                <td style="text-align:center;">0.972</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>9</strong></td>
                <td style="text-align:center;">102.257</td>
                <td style="text-align:center;">0.955442</td>
                <td style="text-align:center;">0.908</td>
                <td style="text-align:center;">0.868</td>
                <td style="text-align:center;">0.968</td>
                <td style="text-align:center;">0.977</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>11</strong></td>
                <td style="text-align:center;">100.257</td>
                <td style="text-align:center;">0.960944</td>
                <td style="text-align:center;">0.927</td>
                <td style="text-align:center;">0.869</td>
                <td style="text-align:center;">0.970</td>
                <td style="text-align:center;">0.983</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>13</strong></td>
                <td style="text-align:center;">98.257</td>
                <td style="text-align:center;">0.961348</td>
                <td style="text-align:center;">0.920</td>
                <td style="text-align:center;">0.878</td>
                <td style="text-align:center;">0.972</td>
                <td style="text-align:center;">0.981</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>15</strong></td>
                <td style="text-align:center;">96.257</td>
                <td style="text-align:center;">0.960863</td>
                <td style="text-align:center;">0.914</td>
                <td style="text-align:center;">0.878</td>
                <td style="text-align:center;">0.972</td>
                <td style="text-align:center;">0.980</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>17</strong></td>
                <td style="text-align:center;">94.257</td>
                <td style="text-align:center;">0.958883</td>
                <td style="text-align:center;">0.920</td>
                <td style="text-align:center;">0.858</td>
                <td style="text-align:center;">0.969</td>
                <td style="text-align:center;">0.982</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>19</strong></td>
                <td style="text-align:center;">92.257</td>
                <td style="text-align:center;">0.962407</td>
                <td style="text-align:center;">0.933</td>
                <td style="text-align:center;">0.858</td>
                <td style="text-align:center;">0.970</td>
                <td style="text-align:center;">0.985</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>21</strong></td>
                <td style="text-align:center;">90.257</td>
                <td style="text-align:center;">0.962707</td>
                <td style="text-align:center;">0.931</td>
                <td style="text-align:center;">0.857</td>
                <td style="text-align:center;">0.970</td>
                <td style="text-align:center;">0.986</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>23</strong></td>
                <td style="text-align:center;">88.257</td>
                <td style="text-align:center;">0.961898</td>
                <td style="text-align:center;">0.930</td>
                <td style="text-align:center;">0.851</td>
                <td style="text-align:center;">0.969</td>
                <td style="text-align:center;">0.986</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>25</strong></td>
                <td style="text-align:center;">86.257</td>
                <td style="text-align:center;">0.967294</td>
                <td style="text-align:center;">0.942</td>
                <td style="text-align:center;">0.858</td>
                <td style="text-align:center;">0.973</td>
                <td style="text-align:center;">0.989</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>27</strong></td>
                <td style="text-align:center;">84.257</td>
                <td style="text-align:center;">0.965555</td>
                <td style="text-align:center;">0.934</td>
                <td style="text-align:center;">0.853</td>
                <td style="text-align:center;">0.972</td>
                <td style="text-align:center;">0.987</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>29</strong></td>
                <td style="text-align:center;">82.257</td>
                <td style="text-align:center;">0.966328</td>
                <td style="text-align:center;">0.941</td>
                <td style="text-align:center;">0.850</td>
                <td style="text-align:center;">0.972</td>
                <td style="text-align:center;">0.989</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>31</strong></td>
                <td style="text-align:center;">80.257</td>
                <td style="text-align:center;">0.968735</td>
                <td style="text-align:center;">0.949</td>
                <td style="text-align:center;">0.857</td>
                <td style="text-align:center;">0.973</td>
                <td style="text-align:center;">0.990</td>
              </tr>
            </tbody>
          </table>
        </div>
        <figure id="fig9">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image9.PNG"
          class="img-responsive" alt="Figure 9:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 9:</span>
            <span class="figure-title">Accuracy versus Observed
            Length of Different Features using Random Forest of
            Task 1 in PTT.</span>
          </div>
        </figure>
      </section>
      <section id="sec4Z3">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Performance
            for Task 2</h3>
          </div>
        </header>
        <p>While Task 2 is designed for short-term emerging
        prediction on next predicted time interval, in our
        experiment, the granularity of predicted time interval is
        set as one week while the observed time interval is
        designated as the period starting from two weeks before a
        movie is released till current time window (Figure
        <a class="fig" href="#fig1">1</a>). Figure <a class="fig"
        href="#fig10">10</a> shows the prediction accuracy as a
        function of observed length for comparison of various
        classification algorithms on Reddit. Note that x-axis
        denotes the observed length and leads to the predicted time
        interval implicitly. For example, the observed length 24
        indicates that, on the 3<sup>rd</sup> day of week 2 after
        movie release, the user wishes to predict whether the movie
        will emerge in week 3. In Figure <a class="fig" href=
        "#fig10">10</a>, Random Forest still performs best with
        accuracy over 96% except the prediction on opening week
        with accuracy around 92%. This may due to the promotional
        campaigns prior to the opening week.</p>
        <figure id="fig10">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image10.PNG"
          class="img-responsive" alt="Figure 10:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 10:</span>
            <span class="figure-title">Accuracy versus Observed
            Length of Different Algorithms of Task 2 in
            Reddit.</span>
          </div>
        </figure>
        <p>Table <a class="tbl" href="#tb3">3</a> lists the
        precision, and recall versus difference earliness for the
        prediction on the first three opening weeks using Random
        Forest on Reddit.</p>
        <div class="table-responsive" id="tb3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class=
            "table-title">Earliness, Precision and Recall versus
            Earliness for the First Three Opening Weeks using
            Random Forest of Task 2 in Reddit.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;" rowspan="3">
                <strong><em>k</em></strong></th>
                <th style="text-align:center;" colspan="4">
                <strong>Predict Week 1</strong></th>
                <th style="text-align:center;" colspan="4">
                <strong>Predict Week 2</strong></th>
                <th style="text-align:center;" colspan="4">
                <strong>Predict Week 3</strong></th>
              </tr>
              <tr>
                <th style="text-align:center;" colspan="2">
                Emerging</th>
                <th style="text-align:center;" colspan="2">
                Non-emerg</th>
                <th style="text-align:center;" colspan="2">
                Emerging</th>
                <th style="text-align:center;" colspan="2">
                Non-emerg</th>
                <th style="text-align:center;" colspan="2">
                Emerging</th>
                <th style="text-align:center;" colspan="2">
                Non-emerg</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td></td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>7</strong></td>
                <td style="text-align:center;">.632</td>
                <td style="text-align:center;">.224</td>
                <td style="text-align:center;">.923</td>
                <td style="text-align:center;">.986</td>
                <td style="text-align:center;">.673</td>
                <td style="text-align:center;">.242</td>
                <td style="text-align:center;">.974</td>
                <td style="text-align:center;">.997</td>
                <td style="text-align:center;">.340</td>
                <td style="text-align:center;">.120</td>
                <td style="text-align:center;">.981</td>
                <td style="text-align:center;">.999</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>6</strong></td>
                <td style="text-align:center;">.678</td>
                <td style="text-align:center;">.242</td>
                <td style="text-align:center;">.925</td>
                <td style="text-align:center;">.987</td>
                <td style="text-align:center;">.633</td>
                <td style="text-align:center;">.224</td>
                <td style="text-align:center;">.972</td>
                <td style="text-align:center;">.997</td>
                <td style="text-align:center;">.520</td>
                <td style="text-align:center;">.200</td>
                <td style="text-align:center;">.984</td>
                <td style="text-align:center;">.999</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>5</strong></td>
                <td style="text-align:center;">.670</td>
                <td style="text-align:center;">.209</td>
                <td style="text-align:center;">.924</td>
                <td style="text-align:center;">.989</td>
                <td style="text-align:center;">.620</td>
                <td style="text-align:center;">.240</td>
                <td style="text-align:center;">.974</td>
                <td style="text-align:center;">.996</td>
                <td style="text-align:center;">.300</td>
                <td style="text-align:center;">.147</td>
                <td style="text-align:center;">.985</td>
                <td style="text-align:center;">.999</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>4</strong></td>
                <td style="text-align:center;">.632</td>
                <td style="text-align:center;">.209</td>
                <td style="text-align:center;">.924</td>
                <td style="text-align:center;">.987</td>
                <td style="text-align:center;">.657</td>
                <td style="text-align:center;">.248</td>
                <td style="text-align:center;">.975</td>
                <td style="text-align:center;">.997</td>
                <td style="text-align:center;">.160</td>
                <td style="text-align:center;">.060</td>
                <td style="text-align:center;">.984</td>
                <td style="text-align:center;">.999</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>3</strong></td>
                <td style="text-align:center;">.647</td>
                <td style="text-align:center;">.206</td>
                <td style="text-align:center;">.924</td>
                <td style="text-align:center;">.985</td>
                <td style="text-align:center;">.707</td>
                <td style="text-align:center;">.256</td>
                <td style="text-align:center;">.975</td>
                <td style="text-align:center;">.997</td>
                <td style="text-align:center;">.180</td>
                <td style="text-align:center;">.087</td>
                <td style="text-align:center;">.984</td>
                <td style="text-align:center;">.998</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>2</strong></td>
                <td style="text-align:center;">.606</td>
                <td style="text-align:center;">.197</td>
                <td style="text-align:center;">.922</td>
                <td style="text-align:center;">.985</td>
                <td style="text-align:center;">.643</td>
                <td style="text-align:center;">.276</td>
                <td style="text-align:center;">.977</td>
                <td style="text-align:center;">.997</td>
                <td style="text-align:center;">.160</td>
                <td style="text-align:center;">.067</td>
                <td style="text-align:center;">.984</td>
                <td style="text-align:center;">.999</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>1</strong></td>
                <td style="text-align:center;">.590</td>
                <td style="text-align:center;">.190</td>
                <td style="text-align:center;">.921</td>
                <td style="text-align:center;">.985</td>
                <td style="text-align:center;">.746</td>
                <td style="text-align:center;">.296</td>
                <td style="text-align:center;">.977</td>
                <td style="text-align:center;">.996</td>
                <td style="text-align:center;">.180</td>
                <td style="text-align:center;">.080</td>
                <td style="text-align:center;">.984</td>
                <td style="text-align:center;">.999</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p><strong>Definition 16 (Earliness for Task 2)</strong>
        The earliness <span class="inline-equation"><span class=
        "tex">$k_l^t$</span></span> of a short-term prediction
        model <em>SM<sub>l</sub></em> with respect to a product
        topic <em>t</em> is the number of time windows from the
        last time window of observed time interval to the first
        time window of predicted time interval.</p>
        <p>For example, if the observed length is 24, the earliness
        is 4 days before next Friday (Recall that most movies
        released on Friday). From Table <a class="tbl" href=
        "#tb3">3</a>, it can be observed that the performance can
        be improved by improving the recall of emerging ones.</p>
        <p>Figure <a class="fig" href="#fig11">11</a> examines the
        effect of competition feature on Reddit using Random
        Forest. Once again, the performance of the proposed
        competition feature alone is no less inferior to the full
        set of features. This indicates that competition feature is
        a good predictor for Task 2 on Reddit.</p>
        <figure id="fig11">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image11.PNG"
          class="img-responsive" alt="Figure 11:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 11:</span>
            <span class="figure-title">Accuracy versus Observed
            Length of Different Features using Random Forest of
            Task 2 in Reddit.</span>
          </div>
        </figure>
        <p>Figure <a class="fig" href="#fig12">12</a>, Table
        <a class="tbl" href="#tb4">4</a> and Figure <a class="fig"
        href="#fig13">13</a> show the results of the same
        experiments on PTT. Again, Random Forest performs best, but
        the prediction accuracy of the first open week is inferior
        to that on Reddit while the 2<sup>nd</sup> and
        3<sup>rd</sup> opening week are superior. It can be
        observed that the proposed approach on PTT achieves more
        than 95% accuracy as early as one week before for emerging
        prediction on next week except the first opening week.
        Figure <a class="fig" href="#fig13">13</a> examines the
        effect of competition features on PTT. The competition
        feature alone on PTT is slightly worse than the full set
        feature. Though the performance of competition feature is
        not as good as that on Reddit, it is helpful to raise the
        accuracy on PTT.</p>
        <figure id="fig12">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image12.PNG"
          class="img-responsive" alt="Figure 12:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 12:</span>
            <span class="figure-title">Accuracy versus Observed
            Length of Different Algorithms of Task 2 in PTT.</span>
          </div>
        </figure>
        <div class="table-responsive" id="tb4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class=
            "table-title">Earliness, Precision and Recall versus
            Earliness for the First Three Opening Weeks using
            Random Forest of Task 2 in PTT.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;" rowspan="3">
                <strong><em>k</em></strong></th>
                <th style="text-align:center;" colspan="4">
                <strong>Predict Week 1</strong></th>
                <th style="text-align:center;" colspan="4">
                <strong>Predict Week 2</strong></th>
                <th style="text-align:center;" colspan="4">
                <strong>Predict Week 3</strong></th>
              </tr>
              <tr>
                <th style="text-align:center;" colspan="2">
                Emerging</th>
                <th style="text-align:center;" colspan="2">
                Non-emerg</th>
                <th style="text-align:center;" colspan="2">
                Emerging</th>
                <th style="text-align:center;" colspan="2">
                Non-emerg</th>
                <th style="text-align:center;" colspan="2">
                Emerging</th>
                <th style="text-align:center;" colspan="2">
                Non-emerg</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td></td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
                <td style="text-align:center;">Prec.</td>
                <td style="text-align:center;">Rec.</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>7</strong></td>
                <td style="text-align:center;">.788</td>
                <td style="text-align:center;">.454</td>
                <td style="text-align:center;">.876</td>
                <td style="text-align:center;">.967</td>
                <td style="text-align:center;">.905</td>
                <td style="text-align:center;">.536</td>
                <td style="text-align:center;">.962</td>
                <td style="text-align:center;">.995</td>
                <td style="text-align:center;">.733</td>
                <td style="text-align:center;">.453</td>
                <td style="text-align:center;">.983</td>
                <td style="text-align:center;">.998</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>6</strong></td>
                <td style="text-align:center;">.806</td>
                <td style="text-align:center;">.436</td>
                <td style="text-align:center;">.873</td>
                <td style="text-align:center;">.971</td>
                <td style="text-align:center;">.842</td>
                <td style="text-align:center;">.484</td>
                <td style="text-align:center;">.958</td>
                <td style="text-align:center;">.993</td>
                <td style="text-align:center;">.743</td>
                <td style="text-align:center;">.440</td>
                <td style="text-align:center;">.983</td>
                <td style="text-align:center;">.998</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>5</strong></td>
                <td style="text-align:center;">.711</td>
                <td style="text-align:center;">.387</td>
                <td style="text-align:center;">.862</td>
                <td style="text-align:center;">.959</td>
                <td style="text-align:center;">.858</td>
                <td style="text-align:center;">.461</td>
                <td style="text-align:center;">.955</td>
                <td style="text-align:center;">.992</td>
                <td style="text-align:center;">.827</td>
                <td style="text-align:center;">.433</td>
                <td style="text-align:center;">.983</td>
                <td style="text-align:center;">.998</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>4</strong></td>
                <td style="text-align:center;">.721</td>
                <td style="text-align:center;">.361</td>
                <td style="text-align:center;">.859</td>
                <td style="text-align:center;">.965</td>
                <td style="text-align:center;">.850</td>
                <td style="text-align:center;">.437</td>
                <td style="text-align:center;">.952</td>
                <td style="text-align:center;">.991</td>
                <td style="text-align:center;">.767</td>
                <td style="text-align:center;">.427</td>
                <td style="text-align:center;">.983</td>
                <td style="text-align:center;">.998</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>3</strong></td>
                <td style="text-align:center;">.687</td>
                <td style="text-align:center;">.380</td>
                <td style="text-align:center;">.858</td>
                <td style="text-align:center;">.954</td>
                <td style="text-align:center;">.812</td>
                <td style="text-align:center;">.370</td>
                <td style="text-align:center;">.946</td>
                <td style="text-align:center;">.992</td>
                <td style="text-align:center;">.720</td>
                <td style="text-align:center;">.420</td>
                <td style="text-align:center;">.983</td>
                <td style="text-align:center;">.998</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>2</strong></td>
                <td style="text-align:center;">.674</td>
                <td style="text-align:center;">.350</td>
                <td style="text-align:center;">.856</td>
                <td style="text-align:center;">.955</td>
                <td style="text-align:center;">.800</td>
                <td style="text-align:center;">.331</td>
                <td style="text-align:center;">.925</td>
                <td style="text-align:center;">.989</td>
                <td style="text-align:center;">.828</td>
                <td style="text-align:center;">.450</td>
                <td style="text-align:center;">.976</td>
                <td style="text-align:center;">.995</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <strong>1</strong></td>
                <td style="text-align:center;">.697</td>
                <td style="text-align:center;">.302</td>
                <td style="text-align:center;">.859</td>
                <td style="text-align:center;">.970</td>
                <td style="text-align:center;">.801</td>
                <td style="text-align:center;">.385</td>
                <td style="text-align:center;">.912</td>
                <td style="text-align:center;">.984</td>
                <td style="text-align:center;">.775</td>
                <td style="text-align:center;">.564</td>
                <td style="text-align:center;">.977</td>
                <td style="text-align:center;">.991</td>
              </tr>
            </tbody>
          </table>
        </div>
        <figure id="fig13">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191625/images/image13.PNG"
          class="img-responsive" alt="Figure 13:" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 13:</span>
            <span class="figure-title">Accuracy versus Observed
            Length of Different Features using Random Forest of
            Task 2 in PTT.</span>
          </div>
        </figure>
      </section>
    </section>
    <section id="sec4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span>
          CONCLUSIONS</h2>
        </div>
      </header>
      <p>In this paper, we have addressed the problem of emerging
      product topic prediction over social media with implicit
      networks. Two prediction tasks are investigated. One is the
      long-term prediction in the pre-production stage to predict
      which products topics will emerge in the future while the
      other is the short-term prediction after product launch to
      predict which products topics will emerge in the next
      predicted time interval. A novel framework named <em>ETP</em>
      is developed to deal with the two targeted tasks. Moreover,
      two novel features named author diversity and competition,
      are proposed to deal with the diffusion process without
      social structure information and the short-term prediction
      task, respectively. Experiments performed on two real movie
      reviews datasets from Reddit and PTT show that for long-term
      prediction on Reddit, ETP achieves promising accuracy of at
      least 91% as early as 285 days before the first emerging
      event while 95% accuracy as early as 104 days before the
      first emerging on PTT. In particular, the proposed author
      diversity features surprisingly perform not only better than
      other features but also near the performance of full set of
      features. For short-term prediction, ETP performs well with
      accuracy over 96% for prediction on the 2<sup>nd</sup> and
      3<sup>rd</sup> opening week while 92% on the first opening
      week. Moreover, the performance of the proposed competition
      feature alone is no less inferior to the full set of
      features. In summary, the proposed ETP framework along with
      the novel author diversity and completion features are shown
      to constitute a novel predictor for emerging product topic
      prediction over social media with implicit networks.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ack-001">
      <header>
        <div class="title-info">
          <h2>ACKNOWLEDGEMENT</h2>
        </div>
      </header>
      <p><strong>This research was partially supported by Ministry
      of Science and Technology, Taiwan, under grant number
      106-3114-E-009-008.</strong></p>
    </section>
    <section id="bib-sec-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="bib1" label="[1]">L. Alsumait, D. Barbará, and C.
        Domeniconi, On-line LDA: adaptive topic models for mining
        text streams with applications to topic detection and
        tracking, 8th IEEE International Conference on Data Mining,
        2008.</li>
        <li id="bib2" label="[2]">M. Cataldi, L. D. Caro, and C.
        Schifanella, Emerging topic detection on Twitter based on
        temporal and social terms evaluation, Proceedings of the
        10th International Workshop on Multimedia Data Mining,
        2011.</li>
        <li id="bib3" label="[3]">J. Cheng, L. Adamic, P. A. Dow,
        J. M. Kleinberg, and J. Leskovec, Can cascades be
        predicted?, Proceedings of the 23rd International
        Conference on World Wide Web, 2014.</li>
        <li id="bib4" label="[4]">W. Duan, B. Gu, and A. B.
        Whinston, The dynamics of online word-of-mouth and product
        sales: An empirical investigation of the movie industry,
        Journal of Retailing, Vol. 84, No. 2, 2008.</li>
        <li id="bib5" label="[5]">K. Hayashi, T. Maehara, M.
        Toyoda, and K.-I. Kawarabayashi, Real-time Top-R topic
        detection on Twitter with topic Hijack filtering,”
        Proceedings of the 21th ACM SIGKDD International Conference
        on Knowledge Discovery and Data Mining, 2015.</li>
        <li id="bib6" label="[6]">S. Huang, Y. Yang, H. Li, and G.
        Sun, Topic detection from microblog based on text
        clustering and topic model analysis, Asia-Pacific Services
        Computing Conference, 2014.</li>
        <li id="bib7" label="[7]">J. Hurtado, S. Huang, and X. Zhu,
        Topic discovery and future trend prediction using
        association analysis and ensemble forecasting, IEEE
        International Conference on Information Reuse and
        Integration, 2015.</li>
        <li id="bib8" label="[8]">S. Kong, Q. Mei, L. Feng, F. Ye,
        and Z. Zhao, Predicting bursts and popularity of hashtags
        in real-time, Proceedings of the 37th international ACM
        SIGIR Conference on Research &amp; Development in
        Information Retrieval, 2014.</li>
        <li id="bib9" label="[9]">J. Li, G. Dong, and K.
        Ramamohanarao, Making use of the most expressive jumping
        emerging patterns for classification, Knowledge Discovery
        and Data Mining. Current Issues and New Applications
        Lecture Notes in Computer Science, pp. 220–232, 2001.</li>
        <li id="bib10" label="[10]">Y. Liu, Word of mouth for
        movies: Its dynamics and impact on box office revenue,
        Journal of Marketing, Vol. 70, No. 3, 2006.</li>
        <li id="bib11" label="[11]">Z. Ma, A. Sun, and G. Cong, On
        predicting the popularity of newly emerging hashtags in
        Twitter, Journal of the American Society for Information
        Science and Technology, Vol. 64, No. 7, pp. 1399–1410,
        2013.</li>
        <li id="bib12" label="[12]">S. Rill, D. Reinel, J. Scheidt,
        and R. V. Zicari, PoliTwi: Early detection of emerging
        political topics on twitter and the impact on concept-level
        sentiment analysis, Knowledge-Based Systems, Vol. 69, pp.
        24–33, 2014.</li>
        <li id="bib13" label="[13]">E. M. Rogers, Diffusion of
        innovations. London: Simon &amp; Schuster, 2003.</li>
        <li id="bib14" label="[14]">A. Saha and V. Sindhwani,
        Learning evolving and emerging topics in social media,
        Proceedings of the fifth ACM international conference on
        Web Search and Data Mining, 2012.</li>
        <li id="bib15" label="[15]">E. Schubert, M. Weiler, and
        H.-P. Kriegel, SigniTrend, Proceedings of the 20th ACM
        SIGKDD International Conference on Knowledge Discovery and
        Data Mining, 2014.</li>
        <li id="bib16" label="[16]">S. Wang, Z. Yan, X. Hu, P. S.
        Yu, Z. Li, and B. Wang, CPB: a classification-based
        approach for burst time prediction in cascades, Knowledge
        and Information Systems, Vol. 49, Issue. 1, 2016.</li>
        <li id="bib17" label="[17]">S.-H. Yang, A. Kolcz, A.
        Schlaikjer, and P. Gupta, Large-scale high-precision topic
        modeling on twitter, Proceedings of the 20th ACM SIGKDD
        International Conference on Knowledge Discovery and Data
        Mining, 2014.</li>
        <li id="bib18" label="[18]">R. Zafarani, M. A. Abbasi, and
        H. Liu, Social media mining: an introduction. New York:
        Cambridge University Press, 2014.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY 4.0) license. Authors
      reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18 Companion, April 23-27 2018, Lyon,
      France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY 4.0
      License.<br />
      ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3191625">https://doi.org/10.1145/3184558.3191625</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
