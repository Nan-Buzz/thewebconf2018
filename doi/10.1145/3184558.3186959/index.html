<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>An Effective Joint Framework for Document
  Summarization</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3186959'>https://doi.org/10.1145/3184558.3186959</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3186959'>https://w3id.org/oa/10.1145/3184558.3186959</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">An Effective Joint Framework for
          Document Summarization</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Min</span> <span class=
          "surName">Gui*</span> CCCE, Nankai University, China
        </div>
        <div class="author">
          <span class="givenName">Zhengkun</span> <span class=
          "surName">Zhang</span> CCCE, Nankai University, China
        </div>
        <div class="author">
          <span class="givenName">Zhenglu</span> <span class=
          "surName">Yang*</span> CCCE, Nankai University, China,
          <a href=
          "mailto:nk_guimin,%20zzk446501998@mail.nankai.edu.cn,">nk_guimin,
          zzk446501998@mail.nankai.edu.cn,</a>, <a href=
          "mailto:yangzl@nankai.edu.cn">yangzl@nankai.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Yanhui</span> <span class=
          "surName">Gu</span> School of CS and Technology,, Nanjing
          Normal University, China, <a href=
          "mailto:gu@njnu.edu.cn">gu@njnu.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Guandong</span> <span class=
          "surName">Xu</span> Advanced Analytics Institute,,
          University of Technology Sydney, Australia, <a href=
          "mailto:Guandong.xu@uts.edu.au">Guandong.xu@uts.edu.au</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186959"
        target=
        "_blank">https://doi.org/10.1145/3184558.3186959</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Document summarization is an important research
        issue and has attracted much attention from the academe.
        The approaches for document summarization can be classified
        as <em>extractive</em> and <em>abstractive</em>. In this
        work, we introduce an effective joint framework that
        integrates extractive and abstractive summarization models,
        which is much closer to the way human write summaries
        (first underlining important information). Preliminary
        experiments on real benchmark dataset demonstrate that our
        model is competitive with the state-of-the-art
        methods.</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Abstractive Summarization;
          Extractive summarization; Sequence-to-Sequence
          Framework</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Min Gui*, Zhengkun Zhang, Zhenglu Yang*, Yanhui Gu, and
          Guandong Xu. 2018. An Effective Joint Framework for
          Document Summarization. In <em>WWW '18 Companion: The
          2018 Web Conference Companion,</em> <em>April 23â€“27,
          2018,</em> <em>Lyon, France. ACM, New York, NY, USA</em>
          2 Pages. <a href=
          "https://doi.org/10.1145/3184558.3186959" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3186959</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Document summarization, a task to compress a document into
      a condensed but informative summary, has been extensively
      investigated to alleviate information overload. Studies on
      document summarization task have used either extractive or
      abstractive methods. A vast amount of previous work in
      summarization task has been extractive [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0002">2</a>] due to the immaturity of
      text generation technologies and the simplicity of extractive
      methods, which generally identify key sentences or important
      phrases of an input document and reproduce them as a summary.
      However, extractive methods face incoherence problem and is
      different from the way human writes. Abstractive
      summarization attempts to produce a condensed representation,
      aspects of which may not appear as parts of the original
      input text. With the emergence of deep learning techniques as
      a viable alternative for Natural Language Process (NLP)
      tasks, researchers have begun applying modern neural networks
      to abstractive summarization [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>], which is much closer to the way
      humans write summaries. Although abstractive methods have
      achieved remarkable success, they still remain challenging.
      Encoding and decoding a long sequence of multiple sentences
      fail to achieve satisfactory performance. The neural Seq2Seq
      framework for summarization tends to generate trivial and
      generic summaries with limited grammaticality and readability
      and is trained to predict the next word with previous
      ground-truth words as the input by using the maximum
      likelihood estimation (MLE) objective function [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0005">5</a>].</p>
      <p>To address these challenges, we introduce a joint
      framework which utilizes the advantages of extractive and
      abstractive summarization to improve the performance.
      According to the experiments and discussions in [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0004">4</a>], using only
      the first 400 tokens of an article can yield significantly
      higher ROUGE scores than those obtained by using the first
      800 tokens. This result may be explained by the nature of
      articles that most of articles especially news ones tend to
      be structured with the most important information at the
      start or in some sentences. Inspired by this observation, we
      use extractive summarization methods to select <em>k</em>
      most important sentences before implementing abstractive
      methods. This process is similar to how human always underlie
      salient sentences first before they summarize an article.</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186959/images/www18companion-199-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">Overview of the proposed model</span>
        </div>
      </figure>
      <p></p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Our Model</h2>
        </div>
      </header>
      <p>In this section, we introduce our proposed model. The
      widely-used sequence-to-sequence framework is adopted to
      encode an article with multiple sentences and decode it as a
      short condensed summary. Our baseline model is similar to
      that of See et&nbsp;al. [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>], and is illustrated in
      Figure.&nbsp;<a class="fig" href="#fig1">1</a>. The main
      distinction of our work is that we introduce an extractive
      layer which highlights salient sentences to improve the
      efficiency of decoder when attending to different parts of
      input document. In the following sections, we will first
      introduce the extractive layer, and then describe the
      combination of extractive and abstractive methods.</p>
      <section id="sec-6">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Extractive
            Layer</h3>
          </div>
        </header>
        <p>A document <em>d</em> is a sequence of sentences
        <em>d</em> = <em>S</em> <sub>1</sub>, <em>S</em>
        <sub>2</sub>, â‹…â‹…â‹…, <em>S<sub>n</sub></em> , and a sentence
        <em>S<sub>i</sub></em> is a sequence of words
        <em>S<sub>i</sub></em> = <em>w</em> <sub><em>i</em>1</sub>,
        <em>w</em> <sub><em>i</em>2</sub>, â‹…â‹…â‹…,
        <em>w<sub>ik</sub></em> , where <em>w<sub>ik</sub></em> is
        the <em>k</em>-th word from the <em>i</em>-th sentence.
        Words are fed one-by-one into a single-layer bidirectional
        LSTM encoder. The encoder produces a sequence of encoder
        hidden state <span class="inline-equation"><span class=
        "tex">$h_i^e$</span></span> and the decoder has its state
        at time step <em>t</em>, denoted as <span class=
        "inline-equation"><span class="tex">$h_t^d$</span></span> .
        Mimicking the way humans write summaries, we implement an
        extractive layer by using extractive summarization methods
        to highlight salient and informative sentences, whose
        content is more likely to be attended to by the decoder.
        Although many extractive methods can be utilized to select
        salient sentences, we simplify this process and follow
        Lead-3 model, which achieves outstanding performance and is
        surpassed by the best extractive system by only a small
        margin [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href="#BibPLXBIB0002">2</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0004">4</a>]. It
        selects only the first <em>k</em> sentences of each article
        as the basis of abstractive summary generation.</p>
      </section>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Neural
            Attentional Model</h3>
          </div>
        </header>
        <p>The attention mechanism [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0001">1</a>] is usually introduced to alleviate
        the burden of remembering the whole input sequence and
        different parts of input document at different time step.
        In our work, the attention distribution
        <em>a<sup>t</sup></em> are calculated as as in See
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0004">4</a>]:</p>
        <div class="table-responsive" id="Xeq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} a^t =
            softmax(v^Ttanh(W_hh^e_i + W_sh^d_t + b_{attn}))
            \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>where<em>v</em>, <em>W<sub>h</sub></em> ,
        <em>W<sub>s</sub></em> and <em>b<sub>attn</sub></em> are
        learnable parameters. The context vector <span class=
        "inline-equation"><span class="tex">$h^*_t$</span></span> ,
        which is a weighted sum of the encoder hidden states, is
        set to be different at different time step, namely,
        <span class="inline-equation"><span class="tex">$h^*_t =
        \sum _ia_i^th^e_i$</span></span> .
        <p></p>
        <p>Then the decoder hidden state is concatenated with the
        context vector and fed through two linear layers to produce
        the vocabulary distribution:</p>
        <div class="table-responsive" id="Xeq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} P_{vocab} =
            softmax(V^*(V([h_t^d, h_t^*])+b)+b^*)
            \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>where <em>V</em> <sup>*</sup>, <em>V</em>,
        <em>b</em>, and <em>b</em> <sup>*</sup> are learnable
        parameters. Similar to See et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0004">4</a>] and Nallapati
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0003">3</a>], we introduce a pointer mechanism
        that allows both copying words via pointing and generating
        words from the vocabulary, to approach the
        out-of-vocabulary words. We define <em>u</em> as a binary
        value, <em>u</em> = 1 means the pointer mechanism working,
        0 otherwise. The final distribution is:
        <div class="table-responsive" id="Xeq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} P(y_t) = p(u_t
            = 1)p(y_t | u_t = 1) + p(u_t = 0)p_{vocab}(y_t)
            \end{equation}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>where <em>p</em>(<em>y<sub>t</sub></em> =
        <em>x<sub>i</sub></em> |<em>u<sub>t</sub></em> = 1) is
        equal to the attention weight of input token
        <em>x<sub>i</sub></em> , which is copied from source
        document.
        <p></p>
        <p>, then output of time step <em>t</em> is denoted as
        <em>y<sub>t</sub></em> ,</p>
        <p>The loss function <em>L</em> of the model is the
        negative log likelihood of generating summaries. We define
        the ground-truth output sequence as <span class=
        "inline-equation"><span class="tex">$y^* = {y_1^*, y_2^*,
        \cdots , y_n^*}$</span></span> for a given input
        <em>d</em>, during training, the loss is calculated as
        <span class="inline-equation"><span class="tex">$L = -\sum
        _{t = 1}^nlogp(y_t^* | y_1^*, \cdots , y_{t-1}^*,
        x)$</span></span> .</p>
      </section>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Experiment</h2>
        </div>
      </header>
      <p>We conduct experiments on <em>CNN/Daily Mail</em> corpus,
      which is widely used in abstractive document summarization
      and comprises news stories with multi-sentence human
      generated summaries. The corpus contains 287,226 training
      pairs, 13,368 validation pairs, and 11,490 test pairs. The
      value of <em>k</em>, which denotes the number of sentences
      being selected as the basis of abstractive summarization
      process, is set to 5.</p>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">Performance Comparison on ROUGE-N</span>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <td style="text-align:center;">Models</td>
              <td style="text-align:center;">GBA</td>
              <td style="text-align:center;">PGN</td>
              <td>Ours</td>
            </tr>
            <tr>
              <td style="text-align:center;">ROUGE-1</td>
              <td style="text-align:center;">38.10</td>
              <td style="text-align:center;">36.09</td>
              <td>36.38</td>
            </tr>
            <tr>
              <td style="text-align:center;">ROUGE-2</td>
              <td style="text-align:center;">13.90</td>
              <td style="text-align:center;">15.10</td>
              <td><strong>16.35</strong></td>
            </tr>
            <tr>
              <td style="text-align:center;">ROUGE-L</td>
              <td style="text-align:center;">34.00</td>
              <td style="text-align:center;">32.78</td>
              <td>33.35</td>
            </tr>
            <tr>
              <td style="text-align:center;">Human</td>
              <td style="text-align:center;">3.14</td>
              <td style="text-align:center;">3.89</td>
              <td><strong>3.91</strong></td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>We compare our model with two state-of-the-art approaches,
      i.e., graph-based attention model (GBA)&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0006">6</a>] and pointer-generator
      network (PGN, without coverage mechanism)&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0004">4</a>]. We have
      conducted preliminary experiments on the proposed model with
      the extractive layer due to limited experimental condition.
      As illustrated in Table&nbsp;<a class="tbl" href=
      "#tab1">1</a>, our model can improve about 2.45 point in
      terms of ROUGE-2. Furthermore, we trained our model for 30000
      iterations, which is much fewer than the 600,000 iterations
      required by PGN&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>], while we have achieved better
      performance than PGN.</p>
      <p>We also perform human evaluation to evaluate output
      summaries. We randomly select 30 articles from the dataset,
      three evaluators are asked to score summaries generated by
      typical models from 1 point to 5 point, where 1 indicated the
      lowest readability and 5 indicates the highest level. From
      Table&nbsp;<a class="tbl" href="#tab1">1</a>, we can see that
      the proposed method can improve the readability of
      summaries.</p>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Conclusion</h2>
        </div>
      </header>
      <p>In this paper, we proposed a joint framework of extractive
      and abstractive summarization methods. Experimental results
      demonstrated that our model improves the performance on
      baseline dataset and can generate more readable and natural
      summaries.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2>ACKNOWLEDGMENTS</h2>
        </div>
      </header>
      <p>This work was supported in part by the National Natural
      Science Foundation of China under Grant No.U1636116,
      11431006, 41571382, the Research Fund for International Young
      Scientists under Grant No. 61650110510 and 61750110530, and
      Jiangsu Higher Education Institutions of China under Grant
      No. 15KJA420001.</p>
    </section>
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Dzmitry Bahdanau,
        Kyunghyun Cho, and Yoshua Bengio. 2014. Neural Machine
        Translation by Jointly Learning to Align and Translate.
        <em><em>CoRR</em></em> (2014).</li>
        <li id="BibPLXBIB0002" label="[2]">Ramesh Nallapati, Feifei
        Zhai, and Bowen Zhou. 2017. SummaRuNNer: A Recurrent Neural
        Network Based Sequence Model for Extractive Summarization
        of Documents. In <em><em>AAAI</em></em> .</li>
        <li id="BibPLXBIB0003" label="[3]">Ramesh Nallapati, Bowen
        Zhou, Cicero dos Santos, Caglar Gulcehre, and Bing Xiang.
        2016. Abstractive Text Summarization using
        Sequence-to-sequence RNNs and Beyond. In
        <em><em>SIGNLL</em></em> .</li>
        <li id="BibPLXBIB0004" label="[4]">Abigail See,
        Peter&nbsp;J. Liu, and Christopher&nbsp;D. Manning. 2017.
        Get To The Point: Summarization with Pointer-Generator
        Networks. In <em><em>ACL</em></em> .</li>
        <li id="BibPLXBIB0005" label="[5]">Ilya Sutskever, Oriol
        Vinyals, and Quoc&nbsp;V. Le. 2014. Sequence to Sequence
        Learning with Neural Networks. In <em><em>NIPS</em></em>
        .</li>
        <li id="BibPLXBIB0006" label="[6]">Jiwei Tan, Xiaojun Wan,
        and Jianguo Xiao. 2017. Abstractive Document Summarization
        with a Graph-Based Attentional Neural Model. In
        <em><em>ACL</em></em> .</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>Â© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3186959">https://doi.org/10.1145/3184558.3186959</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
