<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Predicting Document Creation Times in News Citation
  Networks</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3191633'>https://doi.org/10.1145/3184558.3191633</a> 
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3191633'>https://w3id.org/oa/10.1145/3184558.3191633</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Predicting Document Creation
          Times in News Citation Networks</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Andreas</span> <span class=
          "surName">Spitz</span> Heidelberg University, Im
          Neuenheimer Feld 205 69120Heidelberg, Germany, <a href=
          "mailto:spitz@informatik.uni-heidelberg.de">spitz@informatik.uni-heidelberg.de</a>
        </div>
        <div class="author">
          <span class="givenName">Jannik</span> <span class=
          "surName">Strötgen</span> Max-Planck-Institute for
          Informatics, Campus E1 4 66123Saarbrücken, Germany,
          <a href=
          "mailto:jannik.stroetgen@mpi-inf.mpg.de">jannik.stroetgen@mpi-inf.mpg.de</a>
        </div>
        <div class="author">
          <span class="givenName">Michael</span> <span class=
          "surName">Gertz</span> Heidelberg University, Im
          Neuenheimer Feld 205 69120Heidelberg, Germany, <a href=
          "mailto:gertz@informatik.uni-heidelberg.de">gertz@informatik.uni-heidelberg.de</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191633"
        target=
        "_blank">https://doi.org/10.1145/3184558.3191633</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>For the temporal analysis of news articles or the
        extraction of temporal expressions from such documents,
        accurate document creation times are indispensable. While
        document creation times are available as time stamps or
        HTML metadata in many cases, depending on the document
        collection in question, this data can be inaccurate or
        incomplete in others. Especially in digitally published
        online news articles, publication times are often missing
        from the article or inaccurate due to (partial) updates of
        the content at a later time. In this paper, we investigate
        the prediction of document creation times for articles in
        citation networks of digitally published news articles,
        which provide a network structure of knowledge flows
        between individual articles in addition to the contained
        temporal expressions. We explore the evolution of such
        networks to motivate the extraction of suitable features,
        which we utilize in a subsequent prediction of document
        creation times, framed as a regression task. Based on our
        evaluation of several established machine learning
        regressors on a large network of English news articles, we
        show that the combination of temporal and local structural
        features allows for the estimation of document creation
        times from the network.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS
        Concepts:</span> • <strong>Information systems</strong> →
        <em>Web mining;</em> • <strong>Computing
        methodologies</strong> → <em>Supervised learning by
        regression;</em></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>news</small>,</span>
          <span class="keyword"><small>citation
          network</small>,</span> <span class=
          "keyword"><small>temporal evolution</small>,</span>
          <span class="keyword"><small>document
          dating</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Andreas Spitz, Jannik Strötgen, and Michael Gertz. 2018.
          Predicting Document Creation Times in News Citation
          Networks. In <em>WWW '18 Companion: The 2018 Web
          Conference Companion,</em> <em>April 23–27, 2018,</em>
          <em>Lyon, France. ACM, New York, NY, USA</em> 6 Pages.
          <a href="https://doi.org/10.1145/3184558.3191633" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3191633</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>The question <em>When was this published?</em> does not
      only come to mind when browsing news websites that
      inconveniently neglect to include or update a publication
      timestamp, but is also a central aspect in the automated
      processing of news documents. For many news analysis tasks
      that rely on temporal information such as event detection or
      timeline generation, the extraction of temporal expressions
      is a key component. In the news domain, such an extraction
      relies heavily on the availability of accurate document
      creation times (DCT) since the majority of temporal
      expressions are given in relation to the reference time of
      the document&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0024">24</a>]. Thus, knowledge of the DCT is a
      necessary precursor for subsequent temporal analyses.</p>
      <p>Depending on the source of the document, the DCT may be
      difficult to obtain. While it is a simple task for articles
      obtained from RSS feeds, it is more challenging when articles
      are obtained via social media links or web crawls. In these
      cases, the creation time may be available from a variety of
      metadata fields, in the text of the article itself, or
      missing entirely. As a result, a number of methods have been
      developed to estimate the DCT of documents on the Web from
      metadata, available versions of the document, external web
      archives, and links to other documents (see,
      e.g.,&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0021">21</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0025">25</a>]).</p>
      <p>Due to the constantly changing structure of the Web, such
      metadata may not always be available. Even worse, the content
      of the news articles may change over time, often including an
      update of the timestamp to the last-modified date that
      discards the original date. Simply storing the data to
      circumvent this problem is often not possible due to the
      proprietary nature of news articles. As a result, estimating
      the DCT of news articles is a difficult problem even when the
      entire content and metadata is available, and becomes
      continuously more challenging as time progresses.</p>
      <p>In this paper, we explore the premise that news citation
      networks, which encode the flow of knowledge between
      individual news articles, may be helpful tools in estimating
      the DCT of articles with unknown publication times based on
      their neighbourhood in the network. Since such networks
      encode the relational structure between articles but not
      their content, they are safe to store. Similar to scientific
      citation networks, news citation networks can be extracted
      from the references that are contained within digitally
      published news articles&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0022">22</a>]. In contrast to scientific
      citations, however, the resulting networks of news citations
      are more sparse and thus pose a greater challenge for
      predictive tasks since very little adjacency information is
      available for each individual article.</p>
      <p><strong>Contributions.</strong> We construct a large news
      citation network from international English news articles and
      investigate its utility for the prediction of news article
      DCTs. We explore the structure and temporal evolution of such
      a network as well as the extraction of suitable machine
      learning features, before evaluating the prediction of DCTs
      as a regression task for six regression approaches.</p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related
          Work</h2>
        </div>
      </header>
      <p>Our work relates to the areas of document creation time
      estimation and news citation networks, which we survey in the
      following.</p>
      <p><strong>Estimating document creation times.</strong> The
      most straightforward way to estimate a document's last update
      time is to use HTTP header fields&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0001">1</a>]. Since these are often
      either unavailable or unreliable, Toyoda and Kitsuregawa
      propose a novelty measure for identifying new documents in a
      series of unstable web snapshots by scoring incoming links
      from other web pages&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0026">26</a>]. Similarly, Nunes et&nbsp;al.
      exploit neighboring pages of web documents by using incoming
      links, outgoing links, and HTML source attributes to discern
      the last-modified date of web documents&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0017">17</a>]. For online resources,
      the DCTFinder combines supervised learning and rules to
      detect the DCT of web pages by identifying the title and
      selecting the oldest date among the possible
      candidates&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0025">25</a>]. In contrast,
      CarbonDate&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0021">21</a>] exploits a variety of web features
      to determine the DCT of web pages, e.g., the first time the
      URI was shortened or tweeted, and the first time it appeared
      in a web archive. Again, the document creation time is
      estimated to be the oldest available date.</p>
      <p>Furthermore, the textual content of documents is exploited
      in several approaches for document dating, where the goal is
      to assign the most likely creation time to an undated piece
      of text. Typically, such approaches focus on historic
      documents and thus work at the coarse temporal granularity of
      years. Often, temporal language models are exploited for this
      task&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0007">7</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0010">10</a>]. In
      contrast, Chambers infers document creation times based on
      the temporal expressions occurring in the documents, while Ge
      et&nbsp;al. propose an event-based model&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0008">8</a>]. Based on the observation
      that parts of documents may have differing creation times,
      Zhao and Hauff address the estimation of creation times for
      sub-documents on blog pages&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0028">28</a>].</p>
      <p>In contrast to the above approaches, we focus exclusively
      on the estimation of document creation times in citation
      networks of news articles, whose texts contain references and
      temporal expressions, but no further external metadata. Since
      multiple versions or mentions of articles are not available
      in this setting, the prediction task is best approached as a
      pure regression problem.</p>
      <p><strong>News citation networks.</strong> News citation
      networks are conceptually similar to scientific citation
      networks (for an overview, see&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0018">18</a>]). While scientific
      citation networks are well researched models of knowledge
      dynamics, news citation networks have so far received little
      attention. Based on various web document types such as news
      articles, blogs, and social media posts, Kim et&nbsp;al.
      analyze the structure of user citation
      networks&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0011">11</a>]. Similarly, with a focus on online
      news, Spitz and Gertz investigate the evolution of citations
      in a network of German news articles&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0022">22</a>]. In contrast, we focus
      exclusively on news citations and on a much larger network
      extracted from international English speaking news
      outlets.</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Data Extraction
          and Exploration</h2>
        </div>
      </header>
      <p>Before we proceed to the prediction of DCTs from news
      citations, we investigate the underlying network
      structure.</p>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">Overview of news outlets, with number of
          days <em>d</em> the outlet has been included, average
          number of articles per day ⟨<em>a</em>⟩, average number
          of temporal expressions per article ⟨<em>t</em>⟩, and
          percentage of incoming citations <em>e<sub>in</sub></em>
          and outgoing citations <em>e<sub>out</sub></em> that
          connect to a different news outlet.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:left;">short</th>
              <th style="text-align:left;">news outlet</th>
              <th style="text-align:right;"><em>d</em></th>
              <th style="text-align:right;">⟨<em>a</em>⟩</th>
              <th style="text-align:right;">⟨<em>t</em>⟩</th>
              <th style="text-align:right;">
              <em>e<sub>in</sub></em></th>
              <th style="text-align:right;">
              <em>e<sub>out</sub></em></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:left;">AJ</td>
              <td style="text-align:left;">Al Jazeera</td>
              <td style="text-align:right;">334</td>
              <td style="text-align:right;">14.0</td>
              <td style="text-align:right;">7.4</td>
              <td style="text-align:right;">7.9</td>
              <td style="text-align:right;">1.4</td>
            </tr>
            <tr>
              <td style="text-align:left;">AP</td>
              <td style="text-align:left;">Associated Press</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">0.6</td>
              <td style="text-align:right;">7.6</td>
              <td style="text-align:right;">0.0</td>
              <td style="text-align:right;">0.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">AT</td>
              <td style="text-align:left;">The Atlantic</td>
              <td style="text-align:right;">334</td>
              <td style="text-align:right;">7.2</td>
              <td style="text-align:right;">10.5</td>
              <td style="text-align:right;">16.7</td>
              <td style="text-align:right;">50.6</td>
            </tr>
            <tr>
              <td style="text-align:left;">BBC</td>
              <td style="text-align:left;">British Bc. Corp.</td>
              <td style="text-align:right;">730</td>
              <td style="text-align:right;">8.1</td>
              <td style="text-align:right;">6.5</td>
              <td style="text-align:right;">19.1</td>
              <td style="text-align:right;">8.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">CBC</td>
              <td style="text-align:left;">Canadian Bc. Corp.</td>
              <td style="text-align:right;">334</td>
              <td style="text-align:right;">12.2</td>
              <td style="text-align:right;">7.4</td>
              <td style="text-align:right;">6.6</td>
              <td style="text-align:right;">3.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">CBS</td>
              <td style="text-align:left;">Columbia Bc. System</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">31.9</td>
              <td style="text-align:right;">6.7</td>
              <td style="text-align:right;">5.3</td>
              <td style="text-align:right;">1.1</td>
            </tr>
            <tr>
              <td style="text-align:left;">CDT</td>
              <td style="text-align:left;">China Digital Times</td>
              <td style="text-align:right;">244</td>
              <td style="text-align:right;">1.2</td>
              <td style="text-align:right;">10.3</td>
              <td style="text-align:right;">0.5</td>
              <td style="text-align:right;">28.2</td>
            </tr>
            <tr>
              <td style="text-align:left;">CNN</td>
              <td style="text-align:left;">Cable News Network</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">2.8</td>
              <td style="text-align:right;">8.8</td>
              <td style="text-align:right;">3.3</td>
              <td style="text-align:right;">61.1</td>
            </tr>
            <tr>
              <td style="text-align:left;">DM</td>
              <td style="text-align:left;">Daily Mail</td>
              <td style="text-align:right;">244</td>
              <td style="text-align:right;">7.4</td>
              <td style="text-align:right;">8.3</td>
              <td style="text-align:right;">0.0</td>
              <td style="text-align:right;">0.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">DT</td>
              <td style="text-align:left;">Daily Telegraph
              (AU)</td>
              <td style="text-align:right;">213</td>
              <td style="text-align:right;">3.0</td>
              <td style="text-align:right;">5.4</td>
              <td style="text-align:right;">9.9</td>
              <td style="text-align:right;">43.5</td>
            </tr>
            <tr>
              <td style="text-align:left;">DW</td>
              <td style="text-align:left;">Deutsche Welle</td>
              <td style="text-align:right;">334</td>
              <td style="text-align:right;">1.2</td>
              <td style="text-align:right;">6.1</td>
              <td style="text-align:right;">48.1</td>
              <td style="text-align:right;">5.9</td>
            </tr>
            <tr>
              <td style="text-align:left;">FOX</td>
              <td style="text-align:left;">Fox News</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">2.7</td>
              <td style="text-align:right;">9.8</td>
              <td style="text-align:right;">0.0</td>
              <td style="text-align:right;">0.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">TG</td>
              <td style="text-align:left;">The Guardian</td>
              <td style="text-align:right;">730</td>
              <td style="text-align:right;">40.7</td>
              <td style="text-align:right;">7.6</td>
              <td style="text-align:right;">4.7</td>
              <td style="text-align:right;">3.8</td>
            </tr>
            <tr>
              <td style="text-align:left;">TH</td>
              <td style="text-align:left;">The Herald</td>
              <td style="text-align:right;">244</td>
              <td style="text-align:right;">0.7</td>
              <td style="text-align:right;">7.3</td>
              <td style="text-align:right;">0.6</td>
              <td style="text-align:right;">0.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">HK</td>
              <td style="text-align:left;">Huffington Post
              (UK)</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">4.9</td>
              <td style="text-align:right;">4.7</td>
              <td style="text-align:right;">1.6</td>
              <td style="text-align:right;">42.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">HU</td>
              <td style="text-align:left;">Huffington Post
              (US)</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">6.8</td>
              <td style="text-align:right;">8.1</td>
              <td style="text-align:right;">9.5</td>
              <td style="text-align:right;">86.3</td>
            </tr>
            <tr>
              <td style="text-align:left;">IBT</td>
              <td style="text-align:left;">Int. Business Times</td>
              <td style="text-align:right;">669</td>
              <td style="text-align:right;">29.3</td>
              <td style="text-align:right;">6.4</td>
              <td style="text-align:right;">0.4</td>
              <td style="text-align:right;">15.2</td>
            </tr>
            <tr>
              <td style="text-align:left;">TI</td>
              <td style="text-align:left;">The Independent</td>
              <td style="text-align:right;">730</td>
              <td style="text-align:right;">35.4</td>
              <td style="text-align:right;">5.7</td>
              <td style="text-align:right;">6.1</td>
              <td style="text-align:right;">5.5</td>
            </tr>
            <tr>
              <td style="text-align:left;">LAT</td>
              <td style="text-align:left;">LA Times</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">31.6</td>
              <td style="text-align:right;">8.2</td>
              <td style="text-align:right;">2.9</td>
              <td style="text-align:right;">4.1</td>
            </tr>
            <tr>
              <td style="text-align:left;">NPR</td>
              <td style="text-align:left;">National Public
              Radio</td>
              <td style="text-align:right;">334</td>
              <td style="text-align:right;">0.4</td>
              <td style="text-align:right;">8.4</td>
              <td style="text-align:right;">63.6</td>
              <td style="text-align:right;">58.5</td>
            </tr>
            <tr>
              <td style="text-align:left;">NY</td>
              <td style="text-align:left;">The New Yorker</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">3.0</td>
              <td style="text-align:right;">13.2</td>
              <td style="text-align:right;">33.5</td>
              <td style="text-align:right;">30.6</td>
            </tr>
            <tr>
              <td style="text-align:left;">NYT</td>
              <td style="text-align:left;">New York Times</td>
              <td style="text-align:right;">669</td>
              <td style="text-align:right;">23.8</td>
              <td style="text-align:right;">10.7</td>
              <td style="text-align:right;">26.8</td>
              <td style="text-align:right;">4.7</td>
            </tr>
            <tr>
              <td style="text-align:left;">OBS</td>
              <td style="text-align:left;">The Observer</td>
              <td style="text-align:right;">213</td>
              <td style="text-align:right;">18.8</td>
              <td style="text-align:right;">5.9</td>
              <td style="text-align:right;">0.2</td>
              <td style="text-align:right;">9.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">CMP</td>
              <td style="text-align:left;">S. China Morn. Post</td>
              <td style="text-align:right;">122</td>
              <td style="text-align:right;">19.2</td>
              <td style="text-align:right;">7.8</td>
              <td style="text-align:right;">4.5</td>
              <td style="text-align:right;">0.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">SC</td>
              <td style="text-align:left;">The Scotsman</td>
              <td style="text-align:right;">244</td>
              <td style="text-align:right;">2.0</td>
              <td style="text-align:right;">5.3</td>
              <td style="text-align:right;">5.8</td>
              <td style="text-align:right;">3.6</td>
            </tr>
            <tr>
              <td style="text-align:left;">SKY</td>
              <td style="text-align:left;">Sky News</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">13.0</td>
              <td style="text-align:right;">5.0</td>
              <td style="text-align:right;">6.5</td>
              <td style="text-align:right;">0.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">SMH</td>
              <td style="text-align:left;">Sydney Morn. Herald</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">2.3</td>
              <td style="text-align:right;">7.0</td>
              <td style="text-align:right;">3.0</td>
              <td style="text-align:right;">51.9</td>
            </tr>
            <tr>
              <td style="text-align:left;">TEL</td>
              <td style="text-align:left;">The Telegraph</td>
              <td style="text-align:right;">730</td>
              <td style="text-align:right;">28.9</td>
              <td style="text-align:right;">6.5</td>
              <td style="text-align:right;">7.1</td>
              <td style="text-align:right;">2.4</td>
            </tr>
            <tr>
              <td style="text-align:left;">EX</td>
              <td style="text-align:left;">The Express</td>
              <td style="text-align:right;">244</td>
              <td style="text-align:right;">6.7</td>
              <td style="text-align:right;">5.7</td>
              <td style="text-align:right;">1.0</td>
              <td style="text-align:right;">3.2</td>
            </tr>
            <tr>
              <td style="text-align:left;">TS</td>
              <td style="text-align:left;">Toronto Star</td>
              <td style="text-align:right;">334</td>
              <td style="text-align:right;">25.3</td>
              <td style="text-align:right;">7.8</td>
              <td style="text-align:right;">1.0</td>
              <td style="text-align:right;">1.5</td>
            </tr>
            <tr>
              <td style="text-align:left;">UPI</td>
              <td style="text-align:left;">United Press Int.</td>
              <td style="text-align:right;">334</td>
              <td style="text-align:right;">15.1</td>
              <td style="text-align:right;">6.9</td>
              <td style="text-align:right;">1.6</td>
              <td style="text-align:right;">32.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">USA</td>
              <td style="text-align:left;">USA Today</td>
              <td style="text-align:right;">669</td>
              <td style="text-align:right;">1.3</td>
              <td style="text-align:right;">9.2</td>
              <td style="text-align:right;">0.0</td>
              <td style="text-align:right;">0.0</td>
            </tr>
            <tr>
              <td style="text-align:left;">VS</td>
              <td style="text-align:left;">Vancouver Sun</td>
              <td style="text-align:right;">334</td>
              <td style="text-align:right;">0.4</td>
              <td style="text-align:right;">6.4</td>
              <td style="text-align:right;">5.6</td>
              <td style="text-align:right;">38.7</td>
            </tr>
            <tr>
              <td style="text-align:left;">WP</td>
              <td style="text-align:left;">Washington Post</td>
              <td style="text-align:right;">548</td>
              <td style="text-align:right;">62.7</td>
              <td style="text-align:right;">9.4</td>
              <td style="text-align:right;">13.7</td>
              <td style="text-align:right;">5.1</td>
            </tr>
          </tbody>
        </table>
      </div>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> News
            Citation Networks</h3>
          </div>
        </header>
        <p>Intuitively, a news citation network represents
        citations between news articles, much like a citation
        network between scientific publications. However, an
        important aspect is the limitation to <em>internal</em>
        references, i.e., the focus on references that are anchored
        in the article text and the exclusion of advertisements or
        navigational links. Formally, let <em>V</em> be a set of
        news articles. With <em>E</em>⊆<em>V</em> × <em>V</em>, we
        denote the set of edges between these articles such that
        for two articles <em>v</em> and <em>w</em>, we have
        (<em>v</em>, <em>w</em>) ∈ <em>E</em> iff the text of
        <em>v</em> contains a reference to <em>w</em>. The directed
        graph <em>G</em> = (<em>V</em>, <em>E</em>) then represents
        the network of news citations. Each article <em>v</em> ∈
        <em>V</em> can be attributed further, for example, with a
        publication time, a text, or temporal expressions. For a
        more in-depth introduction to news citation networks,
        see&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0022">22</a>].</p>
      </section>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Sources,
            Extraction, and Annotation</h3>
          </div>
        </header>
        <p>We use a network of citations between English news
        articles. As described above, only the content of the news
        articles is considered for the extraction of text-anchored
        links to other news articles. The network is constructed
        from news articles that were collected between November 1,
        2015 and October 31, 2017. Some outlets were added after
        2015 and are thus present for a shorter period of time.
        Articles that do not give or receive citations are not
        included. In total, the network consists of 244,631
        articles (nodes) that are connected through 367,225
        citations (edges), and can be downloaded from our
        website<a class="fn" href="#fn1" id=
        "foot-fn1"><sup>1</sup></a>. The total number of 34 news
        outlets includes outlets from the UK, the US, Canada,
        Australia, Qatar, Germany, and China. To extract the
        contained temporal expressions, we tag all articles with
        HeidelTime in the news domain setting&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0023">23</a>]. The articles contain a
        total of 1,748,813 temporal expressions of the type
        <em>date</em>: 41.5% have the granularity day, 19.7% the
        granularity month, and 38.8% the granularity year. In
        Table&nbsp;<a class="tbl" href="#tab1">1</a>, we show an
        overview of the data set. The percentages of incoming and
        outgoing citations that refer to (or from) a different news
        outlet give an indication of the citation policy of the
        individual news outlets with respect to the
        competition.</p>
      </section>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span> Temporal
            Correlations</h3>
          </div>
        </header>
        <p>To obtain an impression of the temporal expressions
        contained in the articles, we consider the correlation of
        temporal expressions with day granularity to the
        publication dates. When comparing the temporal expressions
        of an article with the publication date of the article
        itself, we obtain a Pearson correlation of
        <em>ρ<sub>self</sub></em> = 0.440. If we compare the
        temporal expressions in an article with the publication
        dates of citing articles (i.e., along incoming edges in the
        network), this drops to <em>ρ<sub>in</sub></em> = 0.400,
        while the correlation with publication dates of articles at
        the end of outgoing edges is <em>ρ<sub>out</sub></em> =
        0.473. We take this as an indication that using the
        correlation between temporal expressions and the dates of
        articles along outgoing edges is more beneficial, which
        conforms with the expectation that articles tend to contain
        temporal expressions that match the relevant dates of
        referenced articles. However, when compared to the much
        higher correlation between publication dates of articles
        along edges <em>ρ<sub>pub</sub></em> = 0.934, we expect the
        temporal information contained in the publication dates to
        be more useful for DCT prediction.</p>
      </section>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.4</span> Evolution
            of Network Metrics</h3>
          </div>
        </header>
        <p>An interesting characteristic of evolving networks is
        the change in their metrics as nodes and edges are added.
        For many naturally occurring networks, typical
        characteristics are a long-tailed degree distribution,
        leading to a shrinking diameter&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0012">12</a>] (i.e., a decreasing
        length of the longest shortest path) and an increased
        clustering coefficient&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0002">2</a>] (i.e., a densification of the local
        neighbourhood) as the network evolves. In contrast, a news
        citation network for four German news outlets was observed
        to maintain constant clustering coefficient and constant
        diameter over a period of 300 days&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0022">22</a>].</p>
        <figure id="fig1">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191633/images/www18companion-372-fig1.jpg"
          class="img-responsive" alt="Figure 1" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span>
            <span class="figure-title">Evolution of network metrics
            for the entire network as well as the politics and
            business subnetworks.</span>
          </div>
        </figure>
        <p></p>
        <p>Since the sparsity of the data and the network's
        structure are of interest to our subsequent prediction
        task, we show the results of a similar analysis on the
        larger international news network in Figure&nbsp;<a class=
        "fig" href="#fig1">1</a>. We observe that the findings hold
        for the larger network. While there are some spikes in the
        diameter, it is largely constant, as are the clustering
        coefficient and the average path lengths for the entire
        network. The politics subnetwork is similar and dominates
        the combined network, while the business subnetwork is
        smaller and less regular. Overall, we observe long chains
        of article citations that lend themselves to the
        exploration of evolving news stories.</p>
      </section>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.5</span> Exploration
            of Citation Chains</h3>
          </div>
        </header>
        <p>The low density and the high diameter of the network
        suggest the emergence of long citation chains as the
        network evolves. Naturally, such citation chains are not
        only of interest for estimating article publication times,
        but also for investigating the spread of information in the
        network. While an in-depth analysis of such information
        propagation is beyond the scope of this paper, we show an
        example of a medium-length citation chain in
        Figure&nbsp;<a class="fig" href="#fig2">2</a>. As the
        article headlines indicate, there is a propagation of
        information as the story evolves over more than a year.
        Note that the figure shows only a single citation chain,
        which overlaps and intersects with other chains in the
        entire network. In the following, we use this network
        structure to derive topological and temporal network
        features as an aid in the prediction of publication
        dates.</p>
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191633/images/www18companion-372-fig2.jpg"
          class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">Example of a news citation
            chain concerning Russian involvement in the 2016 U.S.
            presidential election.</span>
          </div>
        </figure>
        <p></p>
      </section>
    </section>
    <section id="sec-12">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Publication
          Time Prediction</h2>
        </div>
      </header>
      <p>We next describe our approach used to predict article
      publication times by exploiting the temporal citation
      network.</p>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Feature
            Extraction</h3>
          </div>
        </header>
        <p>To train the regressors, we use a set <em>F</em> of 27
        features, which can be grouped into three categories:
        features derived from the topology of the citation network,
        features derived from the publication times of adjacent
        articles in the network, and features derived from temporal
        expressions in adjacent articles. The 28th variable is the
        publication time of the article itself, which we denote
        with <em>T</em> and use as response variable in the
        subsequent experiments. To encode all temporal features, we
        use an integer value representing POSIX time.</p>
        <p><strong>Network topology features.</strong> To utilize
        the structure of the news citation network, we extract
        purely topological features. That is, we rely on the
        connectivity information of the network. For definitions
        and derivations of the network metrics, see&nbsp;[<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0016">16</a>], for
        example. The degree captures the most basic connectivity
        information, namely the number of adjacent edges. Since the
        network is directed, we include the outgoing degree
        <em>deg<sub>out</sub></em> , the incoming degree
        <em>deg<sub>in</sub></em> , and the undirected (total)
        degree <em>deg<sub>all</sub></em> as features for each
        node. As a description of the neighbourhood of a node, we
        utilize the undirected local clustering coefficient
        <em>cc</em> as a feature, which captures the degree to
        which the neighbours of a given node are interconnected.
        Finally, we include a number of centrality measures, namely
        the betweenness centrality <em>c<sub>btw</sub></em> , the
        page rank centrality <em>c<sub>pr</sub></em> , and the
        incoming and outgoing closeness centralities <em>c</em>
        <sub><em>cl</em>, <em>in</em></sub> and <em>c</em>
        <sub><em>cl</em>, <em>out</em></sub> . For the computation
        of these network features, we use the <tt>igraph</tt>
        package&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0006">6</a>] in R with default parameter
        settings.</p>
        <p><strong>Temporal network features.</strong> Moving
        beyond mere topological information, we combine the network
        connectivity with the publication times of adjacent
        articles. To this end, let <em>T<sub>in</sub></em> denoted
        the set of publication dates of articles that reference a
        given article <em>v</em>, and let <em>T<sub>out</sub></em>
        denote the publication times of articles that <em>v</em>
        references. Then, we derive a set of features from the
        relations between those outgoing and incoming dates.
        Specifically, we use the maximum and minimum publication
        date of articles that are referenced by article <em>v</em>
        and denote them with <em>max</em>(<em>T<sub>out</sub></em>
        ) and <em>min</em>(<em>T<sub>out</sub></em> ). We also
        compute the mean <em>μ</em>(<em>T<sub>out</sub></em> ) and
        standard deviation <em>σ</em>(<em>T<sub>out</sub></em> ) of
        these publication times, along with the time span
        <em>span</em>(<em>T<sub>out</sub></em> ) =
        <em>max</em>(<em>T<sub>out</sub></em> ) −
        <em>min</em>(<em>T<sub>out</sub></em> ) between them.
        Similarly, for articles that include references to
        <em>v</em>, we compute <em>max</em>(<em>T<sub>in</sub></em>
        ), <em>min</em>(<em>T<sub>in</sub></em> ),
        <em>μ</em>(<em>T<sub>in</sub></em> ),
        <em>σ</em>(<em>T<sub>in</sub></em> ),
        <em>span</em>(<em>T<sub>in</sub></em> ) from the set of
        their publication dates <em>T<sub>in</sub></em> .
        Intuitively, the publication date of an article should be
        located in the interval of referenced and referencing
        articles. Therefore, we also construct the set of pairwise
        distances between the incoming and outgoing adjacent
        articles as</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\[ Dist=\bigcup
            _{{{\scriptstyle {\begin{array}{*10c}t_i\in
            T_{in}\\t_o\in T_{out}\end{array}}}}} t_i - t_o
            \]</span><br />
          </div>
        </div>and derive from them the minimum distance
        <em>min</em>(<em>Dist</em>), the maximum distance
        <em>max</em>(<em>Dist</em>), as well as the average
        distance <em>μ</em>(<em>Dist</em>) and the standard
        deviation of the distance <em>σ</em>(<em>Dist</em>). For a
        conceptual visualization of these 14 features, see
        Figure&nbsp;<a class="fig" href="#fig3">3</a>.
        <p></p>
        <p><strong>Temporal expression features.</strong> Similar
        to the extraction of features from publication times, we
        can also consider the temporal expressions contained in
        adjacent articles (recall that temporal expressions within
        the article itself are useless prior to estimating the
        DCT). In the following, temporal expressions with a
        granularity of months or years are represented by the mean
        value of the interval. Based on our findings in
        Section&nbsp;<a class="sec" href="#sec-9">3.3</a>, we
        conjecture that the temporal expressions in referenced
        articles are less useful for determining the DCT of the
        referencing article. However, the temporal expressions that
        are located within the text of referencing articles are
        likely related to the publication time of the referenced
        article. Thus, we denote with <em>X<sub>in</sub></em> the
        set of all temporal expressions in articles that reference
        a given article <em>v</em>. Based on this set, we derive
        the same types of features as we obtained for the
        publication times, namely the maximum and minimum of
        incoming temporal expressions
        <em>max</em>(<em>X<sub>in</sub></em> ) and
        <em>min</em>(<em>X<sub>in</sub></em> ), as well as their
        mean <em>μ</em>(<em>X<sub>in</sub></em> ), standard
        deviation <em>σ</em>(<em>X<sub>in</sub></em> ), and time
        span <em>span</em>(<em>X<sub>in</sub></em> ).</p>
        <p><strong>Feature imputation.</strong> Due to the
        sparseness of the network, many articles are lacking
        incoming or outgoing edges, which means that not all
        features can be computed for all articles. As a result,
        30.8% of feature values are missing, which is quite
        substantial. Furthermore, 89.6% of the articles have at
        least one missing feature value. Therefore, discarding
        articles with incomplete feature values is not viable and
        we have to impute missing values. In the following, we
        impute values by the mean of a given feature. More involved
        imputation approaches are available that could potentially
        further improve the results, such as multiple imputation by
        chained equation&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0027">27</a>]. However, given the already
        promising results for imputation by mean (see
        Section&nbsp;<a class="sec" href="#sec-15">4.3</a>), we do
        not explore these here.</p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191633/images/www18companion-372-fig3.jpg"
          class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">Conceptual overview of the
            temporal features.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Regression
            Methods</h3>
          </div>
        </header>
        <p>Using the above set of 27 features, we train six
        different regression methods along with a baseline. In the
        following, we briefly introduce the methods and discuss
        their relevant parameters. Where necessary or beneficial,
        the features are standardized (i.e., shifted by their mean
        and normalized by their standard deviation). We use the R
        software environment for all implementations.</p>
        <p><strong>Baseline (BASE).</strong> As baseline, we
        include a predictor that averages the publication times of
        adjacent articles on incoming edges and outgoing edges.
        That is, we compute <em>T<sub>base</sub></em> =
        0.5[<em>μ</em>(<em>T<sub>in</sub></em> ) +
        <em>μ</em>(<em>T<sub>out</sub></em> )] such that the mean
        publication times of articles along all incoming and all
        outgoing edges are averaged with equal weight.</p>
        <p><strong>Linear regression (LR).</strong> As a first
        regression approach, we utilize multiple linear regression
        on all available features. That is, we fit a linear
        regression model for regression coefficients
        <em>β<sub>i</sub></em> as</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\[ T \sim \beta _0 \sum
            _{i=1}^{|F|} \beta _i F_i + \varepsilon \]</span><br />
          </div>
        </div>where ɛ denotes the error terms. We obtain a fit
        through QR factorization using the default <tt>lm</tt>
        implementation in R.
        <p></p>
        <p><strong>Bayesian regression (BAY).</strong> To compare
        the traditional linear regression to a more advanced
        method, we also include Bayesian regression as implemented
        in the <tt>bayesreg</tt> package based on methods by
        Makalic and Schmidt&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0014">14</a>]. Specifically, we use Bayesian
        ridge regression with a Laplace model since the Gaussian
        and Student-t models yield identical results to traditional
        linear regression.</p>
        <p><strong>Random forest (RF).</strong> As a representative
        of decision tree learning, we train a random forest as
        implemented in the <tt>randomForest</tt>
        package&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0013">13</a>], which is based on the
        implementation by Breiman and Cutler&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0003">3</a>]. We set the forest size
        to 500 trees.</p>
        <p><strong>Gradient boosting (GB).</strong> As a second
        tree-based learner, we use gradient boosting on decision
        trees from the <tt>gbm</tt> package&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0019">19</a>]. Here, since our loss
        function is the mean absolute error, the Laplace
        distribution works best. We set the number of trees to
        <em>n</em> = 20, 000, the shrinkage to <em>λ</em> = 0.001
        and the tree depth to <em>K</em> = 5.</p>
        <p><strong>Support vector machine (SVM).</strong> For
        support vector machines, we utilize the package
        <tt>e1071</tt>&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0015">15</a>], which serves as an interface to
        the <tt>libsvm</tt> library&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0005">5</a>]. The radial kernel
        performs best, so we exclude the results for the linear and
        polynomial kernels. For training the SVM, we use
        ϵ-regression with a threshold of ϵ = 0.1.</p>
        <p><strong>Neural network (NN).</strong> Given the
        construction of features, recurrent neural networks are not
        particularly applicable to the given problem (while dates
        along edge sequences could be exploited, the sparseness of
        the network is too pronounced for the extraction of
        sufficient training data). Thus, we use a classic
        feedforward neural network from the <tt>neuralnet</tt>
        package&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0009">9</a>]. We use one node with linear output
        to obtain a regression model, and a single hidden layer
        with 14 nodes (i.e., mean number of nodes in the input and
        output layer). We rely on resilient
        backpropagation&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0020">20</a>] for training the network with one
        repetition and a convergence threshold of 1.0. We increase
        the number of steps to 10<sup>7</sup> to obtain
        convergence.</p>
      </section>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Evaluation
            Results</h3>
          </div>
        </header>
        <p>We perform 10-fold cross validation for all regression
        methods. We use the mean absolute error (MAE) as evaluation
        metric instead of the commonly used root mean square error,
        since (1) giving more weight to larger errors to penalize
        outliers does not seem sensible, and (2) MAE is easier to
        interpret for temporal distances (in days).</p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Mean absolute error in days for
            predictions by the six regressors and the baseline.
            Shown are the values for all articles (all), articles
            with only incoming edges (in) or outgoing edges (out),
            and articles with both (in+out).</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:right;"></th>
                <th style="text-align:left;">BASE</th>
                <th style="text-align:right;">LR</th>
                <th style="text-align:right;">BAY</th>
                <th style="text-align:right;">NN</th>
                <th style="text-align:right;">RF</th>
                <th style="text-align:right;">GB</th>
                <th style="text-align:right;">SVM</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:right;">all</td>
                <td style="text-align:left;">66.72</td>
                <td style="text-align:right;">60.46</td>
                <td style="text-align:right;">59.61</td>
                <td style="text-align:right;">26.88</td>
                <td style="text-align:right;">24.98</td>
                <td style="text-align:right;">
                <strong>22.66</strong></td>
                <td style="text-align:right;">26.19</td>
              </tr>
              <tr>
                <td style="text-align:right;">in</td>
                <td style="text-align:left;">88.88</td>
                <td style="text-align:right;">66.48</td>
                <td style="text-align:right;">87.55</td>
                <td style="text-align:right;">34.03</td>
                <td style="text-align:right;">32.25</td>
                <td style="text-align:right;">
                <strong>27.49</strong></td>
                <td style="text-align:right;">32.29</td>
              </tr>
              <tr>
                <td style="text-align:right;">out</td>
                <td style="text-align:left;">87.32</td>
                <td style="text-align:right;">59.54</td>
                <td style="text-align:right;">40.24</td>
                <td style="text-align:right;">32.52</td>
                <td style="text-align:right;">30.10</td>
                <td style="text-align:right;">
                <strong>26.68</strong></td>
                <td style="text-align:right;">30.77</td>
              </tr>
              <tr>
                <td style="text-align:right;">in+out</td>
                <td style="text-align:left;">18.68</td>
                <td style="text-align:right;">55.45</td>
                <td style="text-align:right;">54.95</td>
                <td style="text-align:right;">12.62</td>
                <td style="text-align:right;">
                <strong>11.23</strong></td>
                <td style="text-align:right;">12.76</td>
                <td style="text-align:right;">14.31</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>In Table&nbsp;<a class="tbl" href="#tab2">2</a>, we show
        the resulting MAE scores for all six methods on the entire
        data set (denoted by <em>all</em>). To analyze the impact
        of missing data, we also show results for subsets of the
        data. Specifically, we give the results for articles that
        only receive (<em>in</em>) or give references
        (<em>out</em>), and the subset of articles that both
        receive and give references (<em>in+out</em>). The three
        sets have roughly equal size in our data (<span class=
        "inline-equation"><span class="tex">$\sim
        30\%$</span></span> ). Note that all articles have at least
        one incident edge or they would not be part of the network.
        For the entire data, the baseline performs worst with an
        average prediction error of two months. Linear regression
        and Bayesian regression are only slightly better, while the
        error of the neural network, SVM, and random forest
        regressors are less than one month. Gradient boosing
        performs slightly worse on the <em>in+out</em> set but best
        overall. All methods perform better on the smallest subset
        of articles that have both incoming and outgoing
        references, although the baseline is so good in this
        special case that linear regression and Bayesian regression
        do not outperform it. For the much harder cases of articles
        that only have incoming or outgoing edges, all methods
        outperform the baseline. Furthermore, the performances of
        all methods on the <em>in</em> set are slightly worse than
        on the <em>out</em> set, indicating that the direction of
        references does not play a major role. Bayesian regression
        is the only exception and benefits more from outgoing edges
        than from incoming edges. Overall, GB has the best
        performance.</p>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191633/images/www18companion-372-fig4.jpg"
          class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">Results for the five
            regressors and the baseline, for all articles (all),
            those with only incoming edges (in) or outgoing edges
            (out), and both (in+out); left: distribution of the
            absolute error in days; right: recall for sliding
            absolute error.</span>
          </div>
        </figure>
        <p></p>
        <p>To analyze the overall spread of the prediction quality,
        we show the distributions of the absolute error in
        Figure&nbsp;<a class="fig" href="#fig4">4</a>&nbsp;(left).
        We find that the mean values in Table&nbsp;<a class="tbl"
        href="#tab2">2</a> correlate well with the median values
        and the overall distribution. The results of the SVM have a
        small spread but a higher median value than the RF and GB
        results, leading to a worse overall performance. In
        Figure&nbsp;<a class="fig" href="#fig4">4</a>&nbsp;(right),
        we show the recall by increasing absolute error. We find
        that the SVM initially performs worse than GB, but peaks at
        an error of three weeks, where over 80% of the results are
        included, and then performs slightly better than gradient
        boosting.</p>
      </section>
      <section id="sec-16">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.4</span> Feature
            Importance</h3>
          </div>
        </header>
        <p>For an analysis of the importance of individual
        features, we rely on the tree-based methods, which provide
        the total sum of residuals that are computed in each split
        during the training process and allow us to measure the
        gain in node purity for splits on any given feature. In
        Figure&nbsp;<a class="fig" href="#fig5">5</a>, we show this
        feature importance obtained from the 10-fold cross
        validation as relative values. For RF, it is clear that
        most features play a minor role and that six features
        account for the majority of selected splits, all of which
        are temporal network features. Two temporal expression
        features are the next most important, while topological
        features play a minor role. For GB, just two temporal
        network features account for the bulk of splits, which are
        the same as the top two features for RF. Overall, temporal
        expression features are less important for GB, while
        topological features have a higher importance, especially
        those that are degree-based. We see this distribution of
        feature importances as an indication that the temporal
        information contained in the local neighbourhood of
        articles is most valuable for DCT prediction.</p>
        <figure id="fig5">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191633/images/www18companion-372-fig5.jpg"
          class="img-responsive" alt="Figure 5" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span>
            <span class="figure-title">Relative importance for
            feature types: network topology (yellow), temporal
            expression (green), and temporal network (purple).
            Error bars are one standard deviation.</span>
          </div>
        </figure>
        <p></p>
      </section>
    </section>
    <section id="sec-17">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Summary and
          Outlook</h2>
        </div>
      </header>
      <p>In this paper, we created and analyzed a large-scale
      network of citations between English news articles covering
      two years. We investigated the task of predicting the
      document creation time of news articles from the network
      structure and the publication times of adjacent articles in
      the network as a regression problem. Despite the sparseness
      of the network, we found that document publication times in
      such a setting can be predicted reliably with an average
      error of slightly over three weeks. Overall, we observed the
      most challenging aspect to be the sparseness of the data
      since the predictive performance increased strongly for
      articles that both contain and receive references. As a
      result, we conjecture that denser news citation networks
      constructed from more news outlets stand to support better
      predictions. Finally, an analysis of feature importance for
      the two best-performing regressors showed that features
      derived from the network structure with the publication times
      of adjacent articles have the largest impact, indicating that
      the knowledge of the topological structure and the
      publication times is sufficient for obtaining high-quality
      predictions.</p>
      <p><strong>Future work.</strong> Given the individual
      performance profiles of the regressors, the construction of
      an ensemble classifier warrants further investigation.
      Similarly, the application of convolutional neural networks
      on citation chain features stands to further improve the
      predictive performance of the proposed approach.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Einat Amitay, David
        Carmel, Michael Herscovici, Ronny Lempel, and Aya Soffer.
        2004. Trend Detection Through Temporal Link Analysis. <em>
          <em>J. Am. Soc. Inf. Sci. Technol.</em></em> 55, 14 (Dec.
          2004), 1270–1281. <a class="link-inline force-break"
          href="https://doi.org/10.1002/asi.20082" target=
          "_blank">https://doi.org/10.1002/asi.20082</a>
        </li>
        <li id="BibPLXBIB0002" label="[2]">Béla Bollobás and
        Oliver&nbsp;M Riordan. 2003. Mathematical Results on
        Scale-free Random Graphs. <em><em>Handbook of Graphs and
        Networks: from the Genome to the Internet</em></em> (2003),
        1–34.</li>
        <li id="BibPLXBIB0003" label="[3]">Leo Breiman. 2001.
        Random Forests. <em><em>Machine Learning</em></em> 45, 1
        (2001), 5–32. <a class="link-inline force-break" href=
        "https://doi.org/10.1023/A:1010933404324" target="_blank">
          https://doi.org/10.1023/A:1010933404324</a>
        </li>
        <li id="BibPLXBIB0004" label="[4]">Nathanael Chambers.
        2012. Labeling Documents with Timestamps: Learning from
        Their Time Expressions. In <em><em>ACL</em></em> .
          <a class="link-inline force-break" href=
          "http://dl.acm.org/citation.cfm?id=2390524.2390539"
          target=
          "_blank">http://dl.acm.org/citation.cfm?id=2390524.2390539</a>
        </li>
        <li id="BibPLXBIB0005" label="[5]">Chih-Chung Chang and
        Chih-Jen Lin. 2011. LIBSVM: A Library for Support Vector
        Machines. <em><em>ACM TIST</em></em> 2, 3 (2011),
        27:1–27:27. <a class="link-inline force-break" href=
        "https://doi.org/10.1145/1961189.1961199" target="_blank">
          https://doi.org/10.1145/1961189.1961199</a>
        </li>
        <li id="BibPLXBIB0006" label="[6]">Gabor Csardi and Tamas
        Nepusz. 2006. The igraph Software Package for Complex
        Network Research. <em><em>InterJournal, Complex
        Systems</em></em> 1695, 5 (2006), 1–9.</li>
        <li id="BibPLXBIB0007" label="[7]">Franciska M.G. de Jong,
        Henning Rode, and Djoerd Hiemstra. 2005. Temporal Language
        Models for the Disclosure of Historical Text. In
        <em><em>AHC</em></em> .</li>
        <li id="BibPLXBIB0008" label="[8]">Tao Ge, Baobao Chang,
        Sujian Li, and Zhifang Sui. 2013. Event-Based Time Label
        Propagation for Automatic Dating of News Articles. In <em>
          <em>EMNLP</em></em> . <a class="link-inline force-break"
          href="http://www.aclweb.org/anthology/D13-1001" target=
          "_blank">http://www.aclweb.org/anthology/D13-1001</a>
        </li>
        <li id="BibPLXBIB0009" label="[9]">Frauke Günther and
        Stefan Fritsch. 2010. neuralnet: Training of Neural
        Networks. <em><em>The R Journal</em></em> 2, 1 (2010),
        30–38. <a class="link-inline force-break" href=
        "https://journal.r-project.org/archive/2010/RJ-2010-006/index.html"
          target=
          "_blank">https://journal.r-project.org/archive/2010/RJ-2010-006/index.html</a>
        </li>
        <li id="BibPLXBIB0010" label="[10]">Nattiya Kanhabua and
        Kjetil Nørvåg. 2009. Using Temporal Language Models for
        Document Dating. In <em><em>ECML PKDD</em></em> .
          <a class="link-inline force-break" href=
          "https://doi.org/10.1007/978-3-642-04174-7_53" target=
          "_blank">https://doi.org/10.1007/978-3-642-04174-7_53</a>
        </li>
        <li id="BibPLXBIB0011" label="[11]">Minkyoung Kim, Lexing
        Xie, and Peter Christen. 2012. Event Diffusion Patterns in
        Social Media. In <em><em>ICWSM</em></em> . <a class=
        "link-inline force-break" href=
        "http://www.aaai.org/ocs/index.php/ICWSM/ICWSM12/paper/view/4595"
          target=
          "_blank">http://www.aaai.org/ocs/index.php/ICWSM/ICWSM12/paper/view/4595</a>
        </li>
        <li id="BibPLXBIB0012" label="[12]">Jure Leskovec,
        Jon&nbsp;M. Kleinberg, and Christos Faloutsos. 2005. Graphs
        Over Time: Densification Laws, Shrinking Diameters and
        Possible Explanations. In <em><em>KDD</em></em> .
          <a class="link-inline force-break" href=
          "https://doi.org/10.1145/1081870.1081893" target=
          "_blank">https://doi.org/10.1145/1081870.1081893</a>
        </li>
        <li id="BibPLXBIB0013" label="[13]">Andy Liaw and Matthew
        Wiener. 2002. Classification and Regression by
        randomForest. <em><em>R News</em></em> 2, 3 (2002), 18–22.
        <a class="link-inline force-break" href=
        "http://CRAN.R-project.org/doc/Rnews/" target=
        "_blank">http://CRAN.R-project.org/doc/Rnews/</a>
        </li>
        <li id="BibPLXBIB0014" label="[14]">Enes Makalic and
        Daniel&nbsp;F Schmidt. 2016. High-Dimensional Bayesian
        Regularised Regression with the BayesReg Package. <em><em>
          arXiv preprint</em></em> (2016). <a class=
          "link-inline force-break" href=
          "https://arxiv.org/abs/1611.06649" target=
          "_blank">https://arxiv.org/abs/1611.06649</a>
        </li>
        <li id="BibPLXBIB0015" label="[15]">David Meyer, Evgenia
        Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich
        Leisch. 2017. <em><em>e1071: Misc Functions of the
        Department of Statistics, Probability Theory
        Group</em></em> . <a class="link-inline force-break"
          href="https://CRAN.R-project.org/package=e1071" target=
          "_blank">https://CRAN.R-project.org/package=e1071</a>
        </li>
        <li id="BibPLXBIB0016" label="[16]">Mark Newman. 2010.
        <em><em>Networks: An Introduction</em></em> . Oxford
        University Press.</li>
        <li id="BibPLXBIB0017" label="[17]">Sérgio Nunes, Cristina
        Ribeiro, and Gabriel David. 2007. Using Neighbors to Date
        Web Documents. In <em><em>WIDM</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/1316902.1316924" target="_blank">
          https://doi.org/10.1145/1316902.1316924</a>
        </li>
        <li id="BibPLXBIB0018" label="[18]">Filippo Radicchi, Santo
        Fortunato, and Alessandro Vespignani. 2012. Citation
        Networks. In <em><em>Models of Science Dynamics: Encounters
        Between Complexity Theory and Information
        Sciences</em></em> , Andrea Scharnhorst, Katy Börner, and
        Peter van&nbsp;den Besselaar (Eds.). Springer. <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1007/978-3-642-23068-4_7" target=
        "_blank">https://doi.org/10.1007/978-3-642-23068-4_7</a>
        </li>
        <li id="BibPLXBIB0019" label="[19]">Greg Ridgeway. 2006.
        <em><em>gbm: Generalized Boosted Regression
        Models</em></em> . <a class="link-inline force-break"
          href="https://cran.r-project.org/package=gbm" target=
          "_blank">https://cran.r-project.org/package=gbm</a>
        </li>
        <li id="BibPLXBIB0020" label="[20]">Martin Riedmiller.
        1994. Advanced Supervised Learning in Multi-layer
        Perceptrons–From Backpropagation to Adaptive Learning
        Algorithms. <em><em>Comput Stand Interfaces</em></em> 16, 3
        (1994), 265–278. <a class="link-inline force-break" href=
        "https://doi.org/10.1016/0920-5489(94)90017-5" target=
        "_blank">https://doi.org/10.1016/0920-5489(94)90017-5</a>
        </li>
        <li id="BibPLXBIB0021" label="[21]">Hany&nbsp;M.
        SalahEldeen and Michael&nbsp;L. Nelson. 2013. Carbon Dating
        the Web: Estimating the Age of Web Resources. In
        <em><em>WWW Companion</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/2487788.2488121" target="_blank">
          https://doi.org/10.1145/2487788.2488121</a>
        </li>
        <li id="BibPLXBIB0022" label="[22]">Andreas Spitz and
        Michael Gertz. 2015. Breaking the News: Extracting the
        Sparse Citation Network Backbone of Online News Articles.
        In <em><em>ASONAM</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/2808797.2809380" target="_blank">
          https://doi.org/10.1145/2808797.2809380</a>
        </li>
        <li id="BibPLXBIB0023" label="[23]">Jannik Strötgen and
        Michael Gertz. 2013. Multilingual and Cross-domain Temporal
        Tagging. <em><em>Language Resources and
        Evaluation</em></em> 47, 2 (2013), 269–298. <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1007/s10579-012-9179-y" target=
        "_blank">https://doi.org/10.1007/s10579-012-9179-y</a>
        </li>
        <li id="BibPLXBIB0024" label="[24]">Jannik Strötgen and
        Michael Gertz. 2016. <em><em>Domain-Sensitive Temporal
        Tagging</em></em> . Morgan &amp; Claypool.</li>
        <li id="BibPLXBIB0025" label="[25]">Xavier Tannier. 2014.
        Extracting News Web Page Creation Time with DCTFinder. In
        <em><em>LREC</em></em> . <a class="link-inline force-break"
          href=
          "http://www.lrec-conf.org/proceedings/lrec2014/summaries/3.html"
          target=
          "_blank">http://www.lrec-conf.org/proceedings/lrec2014/summaries/3.html</a>
        </li>
        <li id="BibPLXBIB0026" label="[26]">Masashi Toyoda and
        Masaru Kitsuregawa. 2006. What's Really New on the Web?:
        Identifying New Pages from a Series of Unstable Web
        Snapshots. In <em><em>WWW</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/1135777.1135815" target="_blank">
          https://doi.org/10.1145/1135777.1135815</a>
        </li>
        <li id="BibPLXBIB0027" label="[27]">Stef Van&nbsp;Buuren,
        Jaap&nbsp;PL Brand, Catharina&nbsp;GM Groothuis-Oudshoorn,
        and Donald&nbsp;B Rubin. 2006. Fully Conditional
        Specification in Multivariate Imputation. <em><em>J Stat
        Comput Simul</em></em> 76, 12 (2006), 1049–1064.
          <a class="link-inline force-break" href=
          "https://doi.org/10.1080/10629360600810434" target=
          "_blank">https://doi.org/10.1080/10629360600810434</a>
        </li>
        <li id="BibPLXBIB0028" label="[28]">Yue Zhao and Claudia
        Hauff. 2015. Sub-document Timestamping of Web Documents. In
        <em><em>SIGIR</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/2766462.2767803" target="_blank">
          https://doi.org/10.1145/2766462.2767803</a>
        </li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>All data and
    code is available at <a class="link-inline force-break" href=
    "https://dbs.ifi.uni-heidelberg.de/resources/data/">https://dbs.ifi.uni-heidelberg.de/resources/data/</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3191633">https://doi.org/10.1145/3184558.3191633</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
