<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Customer Sentiment in Web-Based Service Interactions:
  Automated Analyses and New Insights</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3191628'>https://doi.org/10.1145/3184558.3191628</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3191628'>https://w3id.org/oa/10.1145/3184558.3191628</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Customer Sentiment in Web-Based
          Service Interactions: Automated Analyses and New
          Insights</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <a href="https://orcid.org/0000-0003-0295-7968" ref=
          "author"><span class="givenName">Galit B.</span>
          <span class="surName">Yom-Tov</span></a> Technion—Israel
          Institute of Technology, Haifa, Israel, <a href=
          "mailto:gality@technion.ac.il">gality@technion.ac.il</a>
        </div>
        <div class="author">
          <span class="givenName">Shelly</span> <span class=
          "surName">Ashtar</span> Technion—Israel Institute of
          Technology, Haifa, Israel, <a href=
          "mailto:shellya@campus.technion.ac.il">shellya@campus.technion.ac.il</a>
        </div>
        <div class="author">
          <span class="givenName">Daniel</span> <span class=
          "surName">Altman</span> Technion—Israel Institute of
          Technology, Haifa, Israel, <a href=
          "mailto:altmand@campus.technion.ac.il">altmand@campus.technion.ac.il</a>
        </div>
        <div class="author">
          <span class="givenName">Michael</span> <span class=
          "surName">Natapov</span> LivePerson Inc., Tel-Aviv,
          Israel, <a href=
          "mailto:michaelna@liveperson.com">michaelna@liveperson.com</a>
        </div>
        <div class="author">
          <span class="givenName">Neta</span> <span class=
          "surName">Barkay</span> LivePerson Inc., Tel-Aviv,
          Israel, <a href=
          "mailto:netabarkay@gmail.com">netabarkay@gmail.com</a>
        </div>
        <div class="author">
          <span class="givenName">Monika</span> <span class=
          "surName">Westphal</span> Technion—Israel Institute of
          Technology, Haifa, Israel, <a href=
          "mailto:westphal@campus.technion.ac.il">westphal@campus.technion.ac.il</a>
        </div>
        <div class="author">
          <span class="givenName">Anat</span> <span class=
          "surName">Rafaeli</span> Technion—Israel Institute of
          Technology, Haifa, Israel, <a href=
          "mailto:anatr@technion.ac.il">anatr@technion.ac.il</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191628"
        target=
        "_blank">https://doi.org/10.1145/3184558.3191628</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>We adjust sentiment analysis techniques to
        automatically detect customer emotion in on-line service
        interactions of multiple business domains. Then we use the
        adjusted sentiment analysis tool to report insights into
        the dynamics of emotion in on-line service chats, using a
        large dataset of telecommunications customer service
        interactions. Our analyses show customer emotions start out
        negative and evolve into positive feelings, as the
        interaction unfolds. Also, we identify a close relationship
        between customer emotion dynamics <em>during</em> the
        service interaction and the concepts of service failure and
        recovery. This connection manifests itself in customer
        service quality evaluations <em>after</em> the interaction
        ends. Our study highlights the connection between customer
        emotion and service quality as service interactions unfold,
        and suggests the use of sentiment analysis tools for
        real-time monitoring and control of web-based service
        quality.</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Customer service; sentiment
          analysis; customer satisfaction</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Galit B. Yom-Tov, Shelly Ashtar, Daniel Altman, Michael
          Natapov, Neta Barkay, Monika Westphal, and Anat Rafaeli.
          2018. Customer Sentiment in Web-Based Service
          Interactions: Automated Analyses and New Insights. In
          <em>WWW '18 Companion: The 2018 Web Conference
          Companion,</em> <em>April 23–27, 2018 (WWW ’18
          Companion),</em> <em>Lyon, France. ACM, New York, NY,
          USA</em> 9 Pages. <a href=
          "https://doi.org/10.1145/3184558.3191628" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3191628</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>The service industry is undergoing a digital revolution.
      Services become more and more automatic and easy to use, and
      service companies become more accessible through new service
      channels and social media (e.g. Twitter or Facebook),
      corporate websites, or messaging applications (e.g.
      WhatsApp). Still, people find service very frustrating and
      emotionally demanding. Available theory clearly indicates
      that customer service interactions envelop multiple
      manifestations of emotions (cf., Affective Events Theory
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0032">32</a>]), and that
      emotion dynamics are important to recognize because they
      reflect service quality [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0018">18</a>]. In addition, providing service
      through digital interfaces opens new opportunities to explore
      human behavior in service systems that were not available in
      the past [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0023">23</a>].
      Therefore, understanding the effects and dynamics of emotions
      that customers express, is critical.</p>
      <p>In this study, we focus on a large on-line
      telecommunications company whose customers seek service
      through textual platforms. We aim to understand the effect of
      changes in communicated sentiment through the service
      interaction. We leverage automated sentiment analysis to
      analyze emotions in the service chats of this company; but
      instead of examining emotion in an entire interaction (as
      done in analyses of customer reviews), we examine changes of
      sentiment from a longitudinal standpoint. (Such use of
      sentiment analysis was done for example, in the context of
      health-care informatics [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0034">34</a>] to detect progression of patient
      emotions.) We seek to answer the following three research
      questions: (1) how does customer sentiment change within a
      service interaction; (2) is there a connection between such
      changes and service quality measures; and (3) does emotion in
      different stages of an interaction connect to different
      stages in a service process, such as service failure and
      recovery?</p>
      <p>We find that available sentiment analysis tools have
      limited accuracy when applied to detecting emotion in
      customer service interactions. Research acknowledged that
      sentiment tools should be adjusted to the context studies
      (e.g. [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href=
      "#BibPLXBIB0034">34</a>]). We therefore began our study by
      building a sentiment analysis tool adjusted to the context of
      customer service and validating it using a dataset of chat
      services of multiple domains. This includes three
      adjustments: (1) adjustments to the domain of customer
      service; (2) adjustments to specific features of specific
      brands; (3) adjustments to specific language features used by
      service customers. We then use the tool to test theoretically
      derived hypotheses about the dynamics of customer emotion in
      service interactions. Our findings offer new insights into
      how emotions that customers express relate to the
      effectiveness and quality of the service interaction.</p>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">1.1</span> Nature of
            Chat-Based Service Interactions</h3>
          </div>
        </header>
        <p>Customer-service chat interactions comprise a sequence
        of interdependent messages between customers and service
        employees (see Figure <a class="fig" href="#fig1">1</a>).
        Chat service interactions can be viewed on two levels: (i)
        the atomic level of individual messages, implying
        identification of the emotion in each individual customer
        message; (ii) the cumulative level of full interactions,
        implying identification of emotion of a complete
        interaction. Identifying emotion at the individual message
        level enables real-time detection of a customer's emotional
        state at the specific point in time of this particular
        message; an emotion score at the full interaction level
        provides far less granularity, but is the current industry
        norm, and considered an indication of overall service
        quality. We suggest here that analyses at the individual
        message level is the right way to obtain real-time
        assessments of overall service quality. A look limited to
        the full service interaction level misses meaningful
        distinctions between the (initial) service failure stage
        and potential progression toward service recovery.</p>
        <p>Another characteristic of customer chat texts is their
        spontaneous and unedited language; they typically comprise
        short sentences, do not necessarily maintain coherence or
        grammatical structure, and often include shortcuts, slang,
        typos and spelling mistakes. Text-based interactions can
        also contain obscenities and extensive use of punctuation,
        symbols, emoticons and capitalization; these may relate to
        emotions of the writer. This is different from product
        reviews—commonly used for developing and testing sentiment
        analysis engines—that typically go through substantial
        editing, and include well thought out and socially polite
        text. Recent research on sentiment in Twitter takes some of
        these features into account (see for example [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0001">1</a>]) but, to
        our knowledge, previous work only examined specific parts
        of an interaction and did not examine emotion dynamics that
        occur throughout whole customer service interactions
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0012">12</a>]. Thus,
        our paper suggests that available models for automated
        emotion detection need to be adjusted to the context of
        spontaneous, real-life, text-based customer service
        interactions. We fill this gap by by providing a tool with
        specific features that fit the bill, and show insights into
        emotions expressed by customers interacting through chat
        with service employees.</p>
        <figure id="fig1">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191628/images/www18companion-367-fig1.jpg"
          class="img-responsive" alt="Figure 1" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span>
            <span class="figure-title">An example of a service
            interaction between employee and customer through
            chat</span>
          </div>
        </figure>
        <p></p>
      </section>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Background and
          Hypotheses Development</h2>
        </div>
      </header>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Customer
            Emotion Dynamics within Service Interactions</h3>
          </div>
        </header>
        <p>We claim that customer emotion during service
        interactions is <em>dynamic</em> (rather than stable or
        constant). Following the logic of customers approaching a
        service provider because of a “service failure” [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0018">18</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0019">19</a>], we
        expect customer emotions when an interaction starts to be
        relatively negative or neutral; customers request service
        when they have a problem, which brings about negative
        emotions [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0011">11</a>]. Customers may also express
        negative emotions because they believe it will get them
        better results [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0024">24</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0030">30</a>], and/or decrease service time
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0020">20</a>].
        Negative emotions early in the interaction may also occur
        just because people have to spend time and effort on
        something they feel should not have happened (i.e., a
        service failure). Customer negative emotions will be
        evident in customer expressions such as (e.g. “I need to
        cancel my cellular plan”) or a problem (e.g. “My phone
        connection doesn't work!”). The implicit logic is something
        like: “It is the company's fault that I need to waste my
        time for this service”. The psychology theory of Cognitive
        Appraisal [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href="#BibPLXBIB0009">9</a>]
        suggests that such perceptions of the need to turn to a
        service agent damage people's sense of well-being, and
        evoke negative emotions [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0008">8</a>]. The role of service delivery
        agents, in turn, is to resolve problems that customers
        raise, and promote “service recovery” [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0018">18</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0019">19</a>]. Service recovery in an
        interaction may be more or less effective, depending on
        multiple factors [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0008">8</a>]. Regardless of these factors,
        however, the effectiveness of the service recovery is
        likely to manifest in the change of the emotions that
        customers feel and express. Thus, we propose that customer
        emotion is not a stable state throughout service
        interactions; rather customer emotions are dynamic, and
        evolve during the interactions depending on the degree to
        which their needs are addressed and their problem is
        solved. This is the first unique analysis that our approach
        allows, and our first prediction:</p>
        <div class="hypothesis" id="enc1">
          <label>Hypothesis 1.</label>
          <p>&nbsp; Customer emotions during service interactions
          are dynamic, evolving from initial relatively negative
          (based on a service failure logic), into more positive
          emotions at the end of the interaction (based on a
          service recovery logic).</p>
        </div>
        <p>To test Hypothesis <a class="enc" href="#enc1">1</a>, we
        will assess customer emotion in different parts of a large
        sample of service interactions. Our analysis depicts the
        emotions that customers express as they progress through a
        service interaction. Obviously, different customers bring
        different needs, problems, and expectations, so emotion in
        individual interactions are likely to vary. We will depict
        typical emotion expressions, by reporting the average
        sentiment expressed in similar points in time of different
        interactions.</p>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Relating
            Customer Emotion to Service Quality</h3>
          </div>
        </header>
        <p>Hypothesis <a class="enc" href="#enc1">1</a> refers to
        two important parts of service interactions: the beginning
        and the end. Our next hypothesis regards the meaning of the
        dynamics between these two points. We specifically suggest
        that the difference in emotions between them connects to
        customers’ overall assessment of the complete service
        interaction, and of the extent to which the interaction
        effectively resolved their problem. If the initial
        (relatively negative) emotion does not change during the
        interaction, this means the customer issue has not been
        resolved, and subsequently customers are <em>less
        likely</em> to rate the interaction as satisfying and
        effective, than if the change in emotion during the
        interaction is substantial. Thus, we predict that
        differences in customer emotions dynamics in successful vs.
        unsuccessful service interactions are meaningful indicators
        of service quality:</p>
        <div class="hypothesis" id="enc2">
          <label>Hypothesis 2.</label>
          <p>&nbsp; The magnitude of change in customer emotion
          during a service interaction from negative (in the start)
          to positive (at the end) reflects the quality of the
          service a customer received.</p>
        </div>
        <p>Hypothesis <a class="enc" href="#enc2">2</a> can refer
        to two aspects of customer assessments of service quality:
        The extent to which the customer problem was resolved in
        the interaction, and the extent to which a customer was
        satisfied with the interaction. This hypothesis is
        important because it suggests that customer perceptions of
        service quality can be assessed <em>during a service
        interaction</em>, rather than <em>after the service</em>,
        as typically done today. It also suggests that one should
        not simply bundle the emotions throughout the interaction
        together, as the emotions at the beginning of an
        interaction should serve as a base-line for the level of
        service failure the customer started with, while the
        trajectory within the service interaction should serve as a
        measure for success in service recovery. Our analyses
        specifically show that quantifying and dynamically
        assessing customer emotion <em>within</em> service
        interactions can predict, and potentially replace, measures
        of service performance <em>after</em> the interaction. We
        test and support the hypothesis with two popular measures
        of service performance, both currently collected from
        customers after their service interactions ended: (i)
        Problem resolution (known in the service industry as
        <em>FCR</em>, which stands for <em>First Contact
        Resolution</em>), (ii) Customer satisfaction (known in the
        service industry as <em>CSAT</em>). Thus, we suggest a
        novel way to assess service quality, using objective,
        unobtrusive analyses of customer expressions during an
        interaction.</p>
      </section>
    </section>
    <section id="sec-13">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Methods</h2>
        </div>
      </header>
      <p>Our paper has two methods parts: Part 1 presents the
      sentiment analysis tool for service interactions we call
      <em>CustSent</em>, and its validation. Part 2 describes
      insights about customer emotions and tests hypotheses using
      this tool.</p>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Part 1:
            CustSent—A Sentiment Analysis Tool Adjusted for Service
            Interactions</h3>
          </div>
        </header>
        <p>We developed a lexicon-based model, because this
        approach allowed us to adapt CustSent to different service
        domains and brands; airline, telecommunications, or
        financial services share a focus on service, but may vary
        in specific lexicon. The alternative, machine learning
        approach would require training a separate model for each
        service domain, which would imply an extremely demanding
        annotation cost with each new context. See [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0027">27</a>] for more discussion on
        lexicon based vs. machine learning approaches.</p>
        <p>The model assigns an emotion score to each customer
        message by applying a set of rules. The score is assigned
        at the semantic level of a sentence. Each rule assigns a
        numeric integer score to words or nonverbal elements of the
        sentence. Each sentence is scored by multiple rules, and
        the set of scores is aggregated into an overall emotion
        score assigned to each sentence. If a message contains more
        than one sentence the emotion scores of the sentences are
        added up. A total message score above zero means total
        emotion of the message is <em>positive</em>; scores below
        zero indicate total emotion of the message is
        <em>negative</em>. A score of zero indicates <em>no
        emotion</em><a class="fn" href="#fn1" id=
        "foot-fn1"><sup>1</sup></a>.</p>
        <p>Two types of rules determine the sentence emotion score:
        Lexicon rules assign a <em>base score</em> to emotionally
        charged words (<em>anchors</em>); anchors are manually
        annotated words that compose lexicons of different base
        polarity and intensity; e.g., positive words: <em>excellent
        (+2), great (+1), like (0)</em>, and negative words:
        <em>horrible (-2), confused (-1)</em>. The lexicons were
        derived inductively by looking through a large collection
        of customer interaction data. These lexicons are of
        different sizes and overall comprise a few thousands of
        anchors. Comparing to the available sentiment word lists
        (e.g. the well known Bing Liu sentiment corpus) they
        contain adjustments of three types:</p>
        <ul class="list-no-style">
          <li id="list1" label="•"><strong>Service-domain related
          adjustments:</strong>We exclude or add to the sentiment
          lexicons words due to their special use in the service
          domain context. E.g., exclude words like <em>support,
          confirm, approve</em>; include words like <em>cancel,
          legal, waiting, elsewhere</em>.<br />
          I'll take a <em>legal</em> action<br />
          I gonna look <em>elsewhere</em> (if you don't suit me
          here)<br />
          Some words even changed polarities: <em>promises</em>
          which seems positive, has negative connotation in
          service:<br />
          I'm tired of your <em>promises.</em><br /></li>
          <li id="list2" label="•"><strong>Business-domain related
          adjustments:</strong>We exclude or add words to the
          sentiment lexicons due to their special use in a specific
          brand context, or general business context. E.g., exclude
          words like <em>gold, advanced, enhanced, premium, free,
          secure, solid, unlimited; miss, missed, limited, complex,
          blind, fall, dark, split, cold</em>.<br />
          <em>Premium</em> account, <em>Advanced</em>
          Program<br /></li>
          <li id="list3" label="•"><strong>Customer language
          adjustments:</strong>Exclude words like <em>well, right,
          ok</em>. Include common misspellings of emotionally
          charged words, slang and obscenities in the corresponding
          lexicons.<br /></li>
        </ul>
        <p>Beyond the lexicons, the rules account for the
        <em>context</em> of the anchor, which is defined as the
        presence of negation and/or intensification words in three
        words preceding an anchor<a class="fn" href="#fn2" id=
        "foot-fn2"><sup>2</sup></a>. An anchor that appears without
        negation and/or intensification is considered as
        <em>without a context</em>, and its base score remains
        unaltered. The model sums up all the context-defined scores
        of anchors in each sentence, creating the preliminary
        emotion score of the sentence.</p>
        <p>The second set of rules updates the preliminary score of
        the sentence, based on features which do not change their
        meaning in presence of intensification and/or negation, but
        project an emotional charge of the whole sentence. These
        features also reflect the customer service and brand
        related context and include non-verbal (exclamation or
        question marks and emoticons), and verbal terms (e.g.
        <em>sorry</em>, <em>thanks</em>, or <em>lol</em>—an acronym
        for <em>laughing out loud</em>).</p>
        <section id="sec-15">
          <p><em>3.1.1 Lexicon Based Rules.</em> We use five
          lexicons with different levels of base sentiment
          polarity: <em>negative</em> (base score -1), <em>very
          negative</em> (-2), <em>positive</em> (+1), <em>very
          positive</em> (+2) and <em>tentative positive</em> (base
          score 0, and becomes negative if negated).</p>
          <p>For each lexicon context, the adjustment rule shifts
          the base score in cases of intensification and negation.
          The first four lexicons—negative, very negative,
          positive, very positive—follow similar adjustment
          rules:</p>
          <ul class="list-no-style">
            <li id="list4" label="•"><em>Intensification</em> words
            amplify the base score of an anchor by 1 point:<br />
            <em>pleased</em> (+1) → <em>very pleased</em>
            (+2)<br />
            <em>disappointed</em> (-2) → <em>extremely
            disappointed</em> (-3)<br /></li>
            <li id="list5" label="•">
              <em>Negation</em> words shift the base polarity of an
              anchor by 2 points in the direction of the opposite
              polarity (cf. [<a class="bib" data-trigger="hover"
              data-toggle="popover" data-placement="top" href=
              "#BibPLXBIB0027">27</a>]):<br />
              <em>pleased</em> (+1) → <em>not pleased</em>
              (-1)<br />
              <em>disappointed</em> (-2) → <em>not
              disappointed</em> (0)<br />
            </li>
            <li id="list6" label="•">These two rules are applied in
            the same manner when combined:<br />
            <em>not pleased</em> (-1) → <em>very not pleased</em>
            (-2)<br />
            <em>extremely disappointed</em> (-3) → <em>not
            extremely disappointed</em> (-1)<br /></li>
          </ul>
          <p>The tentative positive lexicon is different from the
          other four. It comprises words (e.g. <em>enough, like,
          support, efficient, good</em>) which may convey positive
          emotion in certain cases, but in customer service
          interactions are used differently. Consider for example
          the word <em>like</em>. Most (&gt; 90%) of the
          appearances of the word <em>like</em> without a context
          have no positive connotation: most common use of the
          no-context <em>like</em> is neutral <em>“I would like
          to...”</em>. In contrast, negation of the word
          <em>like</em> (as in <em>“I don't like”</em>) almost
          always has a negative connotation. To account for such
          behavior we include terms such as <em>like</em> in the
          tentative positive category, i.e. model it as neutral
          without context, and negative with negation:</p>
          <p><em>like</em> (0) → <em>don't like</em> (-1) →
          <em>really don't like</em> (-2)</p>
        </section>
        <section id="sec-16">
          <header>
            <div class="title-info">
              <h4><span class="section-number">3.1.2</span>
              Sentence Level Rules</h4>
            </div>
          </header>
          <ul class="list-no-style">
            <li id="list7" label="•">
              <strong>Question rule</strong>: A question structure
              has a different emotional load than a declarative
              sentence with the same wording [<a class="bib"
              data-trigger="hover" data-toggle="popover"
              data-placement="top" href="#BibPLXBIB0013">13</a>,
              <a class="bib" data-trigger="hover" data-toggle=
              "popover" data-placement="top" href=
              "#BibPLXBIB0014">14</a>, <a class="bib" data-trigger=
              "hover" data-toggle="popover" data-placement="top"
              href="#BibPLXBIB0033">33</a>], because questions
              reduce the intensity of the emotion that an anchor
              term expresses. For example, compare the following
              sentences:<br />
              I want to return it because <em>I don't like it</em>.
              (-1)<br />
              <em>What</em> is the return policy in case <em>I
              don't like it</em>? (0)<br />
            </li>
            <li id="list8" label="•"><strong>Politeness and
            Condition rules</strong>: Specific verbal features,
            like polite words (e.g. <em>sorry, apologize</em>) or
            condition words (e.g. <em>if, maybe</em>), do not have
            a polarity score on their own, but serve as modifiers
            of the emotion a sentence conveys. Specifically, the
            model reduces the intensity of the emotion score of a
            sentence when politeness and/or conditioning are
            present:<br />
            I am <em>confused</em>... (-1) → <em>Sorry</em>, I am
            <em>confused</em>... (0)<br /></li>
            <li id="list9" label="•"><strong>Positive
            slang</strong>: Phrases such as <em>yes</em>,
            <em>lol!</em>, and <em>no, lol!</em>, indicate
            emotionally similar (very positive in our model)
            reactions to an employee suggestion. A sentence
            sentiment score is increased in presence of such slang
            words.<br /></li>
            <li id="list10" label="•"><strong>Emoticons</strong>: A
            check of frequencies showed that emoticons used were
            almost solely smilies, e.g. <em>:-)</em> and frownies,
            e.g. <em>:(</em>, and we consider them as non verbal
            indicators of emotions. They add to or subtract from
            the sentence score, respectively.<br /></li>
            <li id="list11" label="•"><strong>Negative
            idioms</strong>: Some stable phrases and
            idioms—<em>been waiting</em>, <em>fed up</em>, or
            <em>your fault</em>—implicitly convey emotion because
            of the associations they insinuate. Such phrases
            subtract from the sentence sentiment score:<br />
            I've <em>been waiting</em> on line for over an hour now
            (-2)<br /></li>
            <li id="list12" label="•"><strong>Thank-you
            phrases</strong>: Phrases conveying customer thanks add
            a positive factor to the sentiment score of a sentence
            in which they appear. The positive factor depends on
            the degree of the conveyed <em>thanks</em>, e.g.:<br />
            <em>no, thanks</em> (+1)<br />
            <em>thank you sooo much for your help!</em>
            (+3)<br /></li>
            <li id="list13" label="•"><strong>Multiple
            punctuation</strong>: A common expression that appears
            in customer messages is multiple exclamation and/or
            question marks. Inductive analysis led us to model
            several patterns for such expressions. A preliminary
            sentiment score may be increased or decreased by
            multiple punctuation, e.g.:<br />
            <em>great</em> (+1) → <em>great!!!</em> (+2)<br />
            <em>hello</em> (0) → <em>hello???</em> (-2)<br /></li>
          </ul>
          <p>More sentence level rules, e.g. special attention to
          CAPITALIZATION patterns, were tested and rejected as not
          improving the model accuracy.</p>
        </section>
      </section>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Assessing
            the Accuracy of the CustSent Model</h3>
          </div>
        </header>
        <p>A sample of 600 customer messages was manually annotated
        by three annotators (see below). To ensure coherency, we
        provided guidelines and examples to the annotators. We
        discussed dilemmas about coding, until there was agreement
        about the emotion in a text (ICC =.89); thus, coding was
        done by multiple judges, supported by consensus resolution
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0003">3</a>, <a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0007">7</a>, <a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0015">15</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0021">21</a>].</p>
        <p>An initial, pilot-phase of coding (of a different sample
        of 200 messages) showed a majority (∼ 70%) of messages as
        containing no emotion, with CustSent detecting even less
        emotion. Therefore, we used a stratified approach of
        sampling customer messages for the validation corpora. This
        sample is not merely a random set of messages, as this
        would generate a large subset of no-emotion messages. The
        sample includes a lower proportion of no-emotion messages
        than a random sample. Specifically, we considered customer
        messages from service chats conducted in two service brands
        (telecommunications and retail) during the first week in
        March 2016. We divided the messages into three emotion
        polarity groups detected by CustSent (negative, positive,
        no emotion), to which we refer as <em>negative</em>,
        <em>positive</em> and <em>neutral stratum</em>,
        respectively. Then we sampled an equal number of messages
        from each stratum. We aimed for a sample of 600 messages –
        200 from each stratum. Due to technical issues, the human
        coders coded an effective sample comprising 597 customer
        messages.</p>
        <p>Use of a sample (as opposed to a predefined Golden
        Standard) requires an adjustment of formulas for the
        accuracy metrics. We now show how the precision and recall
        of a sentiment analysis tool on negative emotion class is
        evaluated. Precision and recall for positive emotion are
        similarly adjusted. To measure precision and recall of
        negative emotion class, one compares the number of messages
        detected as negative by a sentiment detection tool to the
        number of messages coded as negative by human judges.
        <em>Precision</em> is the proportion of correct detections,
        and <em>recall</em> is the proportion of real negative
        emotions that are detected [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0016">16</a>]. Formally, we denote
        <em>α<sub>neg</sub></em> the number of messages detected as
        negative by the sentiment analysis tool,
        <em>β<sub>neg</sub></em> the number of messages coded as
        negative by human judges, and <em>γ<sub>neg</sub></em> the
        number of messages detected as negative by the tool and
        coded as negative by human judges. Then</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            Precision(negative) = \frac{\gamma _{neg}}{\alpha
            _{neg}} \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            Recall(negative) = \frac{\gamma _{neg}}{\beta _{neg}}
            \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>
        <p></p>
        <p>Now, we adjust Formulas (<a class="eqn" href=
        "#eq1">1</a>) and (<a class="eqn" href="#eq2">2</a>) by
        assigning to each message a weight, which is equal to the
        proportion of the stratum in the population it represents.
        Formally, let <em>N</em> <sub>1</sub>, <em>N</em>
        <sub>2</sub>, and <em>N</em> <sub>3</sub> denote the size
        of the negative, positive and neutral stratum,
        respectively. Then, a message from the <em>i</em>-th
        stratum has the weight <em>w<sub>i</sub></em> =
        <em>N<sub>i</sub></em> /(<em>N</em> <sub>1</sub> +
        <em>N</em> <sub>2</sub> + <em>N</em> <sub>3</sub>). Each
        message coded as negative by the human judges contributes
        its weight to the precision and recall formulas. Denote
        <span class="inline-equation"><span class="tex">$\alpha
        _i^M$</span></span> as the number of messages detected as
        negative by model M in stratum <em>i</em>,
        <em>β<sub>i</sub></em> as the number of messages coded as
        negative by human judges in stratum <em>i</em>, and
        <span class="inline-equation"><span class="tex">$\gamma
        _i^M$</span></span> as the number of messages detected as
        negative by model M and coded as negative by human judges
        in stratum <em>i</em>. Hence, the precision and recall of
        identifying negative emotion by the model M is now:</p>
        <div class="table-responsive" id="eq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            Precision_M(negative) = \frac{\sum \limits
            _{i=1}^{3}\gamma _i^M \times w_i}{\sum \limits
            _{i=1}^{3} \alpha _i^M \times w_i}
            \end{equation}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>
        <div class="table-responsive" id="Xeq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            Recall_M(negative) = \frac{\sum \limits
            _{i=1}^{3}\gamma _i^M \times w_i}{\sum \limits
            _{i=1}^{3} \beta _i \times w_i}
            \end{equation}</span><br />
            <span class="equation-number">(4)</span>
          </div>
        </div>
        <p></p>
        <p>Note, that since all the messages detected as negative
        by CustSent belong to the first stratum, Formula (<a class=
        "eqn" href="#eq3">3</a>) for
        <em>Precision<sub>CustSent</sub></em> is the same as
        Formula (<a class="eqn" href="#eq1">1</a>).</p>
        <p>In addition to precision and recall, we also report
        <strong>F<sub>1</sub></strong> —the harmonic average of
        precision and recall—a standard way to aggregate these two
        into one metric.</p>
        <p>Also, we would like to promote the use of sentiment
        tools for real-time assessment of customer sentiment. Such
        use must minimize false alarms (inaccurate alerts of
        negative emotion) and avoid overoptimistic inaccurate
        reports of positive emotion. We therefore put more emphasis
        on precision, especially that of negative emotion, as one
        of the key accuracy metric for our assessment of customer
        sentiment. To this end we deploy the
        <strong>F<sub>0.5</sub></strong> metric, a variation of
        <em>F</em> <sub>1</sub>, in which precision is weighed
        twice as important as recall [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0016">16</a>].</p>
        <p>All these metrics—precision, recall, <em>F</em>
        <sub>1</sub>, <em>F</em> <sub>0.5</sub>—are calculated
        separately for the negative and positive emotion classes
        for CustSent, Stanford Sentiment Analysis RNTN model
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0026">26</a>],
        SentiStrength [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0029">29</a>], and LIWC [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0028">28</a>], as summarized in
        Tables <a class="tbl" href="#tab1">1</a> and <a class="tbl"
        href="#tab2">2</a>.<a class="fn" href="#fn3" id=
        "foot-fn3"><sup>3</sup></a></p>
        <p>CustSent outperforms previously available automatic
        detection models in the precision of detecting negative
        emotion; its precision level is significantly higher than
        the other models (Table <a class="tbl" href="#tab1">1</a>;
        <em>p</em> &lt; 0.001<a class="fn" href="#fn4" id=
        "foot-fn4"><sup>4</sup></a>). In recall CustSent falls
        behind the Stanford engine, but the precision of the latter
        is extremely low, and thus the <em>F</em> <sub>0.5</sub>
        value of CustSent is the highest among the compared
        detection models.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Comparing four models in detecting
            negative emotion in customer messages.</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:left;"></td>
                <td colspan="4" style="text-align:center;">
                  <strong>Negative emotion class</strong>
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>Model</em></td>
                <td style="text-align:right;">
                <em>Precision</em></td>
                <td style="text-align:right;"><em>Recall</em></td>
                <td style="text-align:right;"><em>F</em>
                <sub>1</sub></td>
                <td style="text-align:right;"><em>F</em>
                <sub>0.5</sub></td>
              </tr>
              <tr>
                <td style="text-align:left;">CustSent</td>
                <td style="text-align:right;">
                <strong>0.719</strong></td>
                <td style="text-align:right;">0.236</td>
                <td style="text-align:right;">0.355</td>
                <td style="text-align:right;">
                <strong>0.51</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">Stanford</td>
                <td style="text-align:right;">0.335</td>
                <td style="text-align:right;">
                <strong>0.509</strong></td>
                <td style="text-align:right;">
                <strong>0.404</strong></td>
                <td style="text-align:right;">0.36</td>
              </tr>
              <tr>
                <td style="text-align:left;">LIWC</td>
                <td style="text-align:right;">0.479</td>
                <td style="text-align:right;">0.115</td>
                <td style="text-align:right;">0.186</td>
                <td style="text-align:right;">0.294</td>
              </tr>
              <tr>
                <td style="text-align:left;">SentiStrength</td>
                <td style="text-align:right;">0.494</td>
                <td style="text-align:right;">0.216</td>
                <td style="text-align:right;">0.3</td>
                <td style="text-align:right;">0.393</td>
              </tr>
            </tbody>
            <tfoot>
              <tr>
                <td>&nbsp;</td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
              </tr>
            </tfoot>
          </table>
        </div>
        <p>In assessments of positive emotions, CustSent has better
        precision than other models, though comparable to
        SentiStrength (<em>p</em> = 0.149). In recall, CustSent
        falls behind other engines (<em>p</em> &lt; 0.03), and the
        <em>F</em> <sub>0.5</sub> of CustSent is similar to
        SentiStrength (Table <a class="tbl" href="#tab2">2</a>).
        All in all, we show that CustSent provides the most valid
        customer emotion detection in service interactions, and its
        performance is superior to that of the other models.</p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Comparing four models in detecting
            positive emotion in customer messages.</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:left;"></td>
                <td colspan="4" style="text-align:center;">
                  <strong>Positive emotion class</strong>
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>Model</em></td>
                <td style="text-align:right;">
                <em>Precision</em></td>
                <td style="text-align:right;"><em>Recall</em></td>
                <td style="text-align:right;"><em>F</em>
                <sub>1</sub></td>
                <td style="text-align:right;"><em>F</em>
                <sub>0.5</sub></td>
              </tr>
              <tr>
                <td style="text-align:left;">CustSent</td>
                <td style="text-align:right;">
                <strong>0.866</strong></td>
                <td style="text-align:right;">0.569</td>
                <td style="text-align:right;">0.687</td>
                <td style="text-align:right;">
                <strong>0.784</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">Stanford</td>
                <td style="text-align:right;">0.546</td>
                <td style="text-align:right;">0.339</td>
                <td style="text-align:right;">0.418</td>
                <td style="text-align:right;">0.486</td>
              </tr>
              <tr>
                <td style="text-align:left;">LIWC</td>
                <td style="text-align:right;">0.491</td>
                <td style="text-align:right;">
                <strong>0.717</strong></td>
                <td style="text-align:right;">0.583</td>
                <td style="text-align:right;">0.524</td>
              </tr>
              <tr>
                <td style="text-align:left;">SentiStrength</td>
                <td style="text-align:right;">0.813</td>
                <td style="text-align:right;">0.677</td>
                <td style="text-align:right;">
                <strong>0.739</strong></td>
                <td style="text-align:right;">0.781</td>
              </tr>
            </tbody>
            <tfoot>
              <tr>
                <td>&nbsp;</td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
              </tr>
            </tfoot>
          </table>
        </div>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span> Part 2:
            Data—Using an Automated Engine to Assess Customer
            Emotion in Service Chats</h3>
          </div>
        </header>
        <p>&nbsp; We used CustSent to analyze customer emotions in
        service chats of companies in several domains. Results are
        robust across domains. For lack of space we report here
        only the results of a telecommunications company. The full
        data include 677,936 full interactions (conducted between
        October and December 2016), with 10,035,328 individual
        messages. Full interactions include between two and several
        hundred messages; messages can be customer generated,
        employee generated, or automatically generated by the
        service platform (e.g., <em>“Thank you for your patience.
        One of our agents will be with you shortly”</em>). We
        analyze here only customer messages (mean number of
        customer messages in an interaction is 12.75, <em>SD</em> =
        13.33).</p>
        <p>For testing Hypothesis 2, we added service quality data
        collected separately by the company. This included customer
        assessments of problem resolution and self reported
        satisfaction with the service. Approximately 50% of the
        customers were sent a post-service survey (73% of all
        customers) responded, an acceptable response rate in
        customer surveys. <strong>Problem resolution</strong> was
        assessed with a measure known in the service industry as
        FCR, based on responses to the question “Was your service
        need resolved in this interaction?” (Yes/No).
        <strong>Customer Satisfaction (CSAT)</strong> was assessed
        with the question: “Please rate your satisfaction with the
        service you received” (responses rated 1-Very unsatisfied
        to 5-Very Satisfied).</p>
      </section>
    </section>
    <section id="sec-19">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Findings</h2>
        </div>
      </header>
      <section id="sec-20">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Customer
            Emotion Dynamics within Service Interactions</h3>
          </div>
        </header>
        <p>To examine and compare emotion dynamics in different
        interactions, we standardized length of interactions to 10
        sections (or 10 deciles). We then averaged the sentiment of
        all customer messages in each section, obtaining 10 scores
        that depict the customer emotion in the section. We used
        these 10 emotion scores to depict the evolution of emotion
        in the interaction, and to compare emotions expressed in
        the first sections to emotions expressed at the end of the
        interaction. We conducted this comparison for the full
        dataset, and for a subset of 390,438 interactions that
        include 10 or more customer messages. For lack of space we
        report only the latter<a class="fn" href="#fn5" id=
        "foot-fn5"><sup>5</sup></a>.</p>
        <p>Hypothesis <a class="enc" href="#enc1">1</a>, which
        predicted that service interactions begin with negative
        emotion and end with positive emotion, was supported.
        Figure <a class="fig" href="#fig2">2</a> presents the
        sentiment flow in sections of interactions. In support of
        Hypothesis <a class="enc" href="#enc1">1</a>, a
        paired-samples t-test confirmed customer emotions at the
        beginning (the first section) and the end (last section) of
        interaction as significantly different
        (<em>M<sub>difference</sub></em> = 0.63, <em>t</em>(390437)
        = 450.52, <em>p</em> &lt; 0.001). For robustness we also
        compared the first and last two sections, and obtained
        similar results. The prediction that customer emotions are
        negative at the start and positive at the end of the
        interaction, is supported by a single-sample t-test: across
        multiple interactions, there is more negative customer
        emotions at the beginning (<em>t</em>(390437) = −138.72,
        <em>p</em> &lt; 0.001), and more positive emotions at the
        end of the interaction (<em>t</em>(390437) = 458.5,
        <em>p</em> &lt; 0.001).</p>
        <p>To support the claim that emotions in the beginning of a
        chat convey service failure while emotions at the end
        reflect problem resolution, we examined the CustSent engine
        rules activated in each part. We find the following rules
        (terms) prevalent in early sections: <em>error, problem(s),
        issue(s), wrong, lost, confused, missing, unable, invalid,
        trouble, cancel, mistake, incorrect</em>. These terms
        clearly indicate service failure. For example:
        <em>”Something is wrong with my account,” or ”I have a
        problem receiving calls.”</em> In contrast, terms that
        appear more towards the end of service include:
        <em>thank(s), good, help, great, works/working, fine,
        correct, appreciate, nice, happy, best</em>. These terms
        more likely indicate service resolution. For example,
        <em>“I really appreciate your help,” or “That sounds fine.
        Thanks.”</em>.</p>
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191628/images/www18companion-367-fig2.jpg"
          class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">Sentiment flow of service
            interactions, divided into 10 sections [<em>n</em> =
            390, 438]</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-21">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Relating
            Customer Emotion to Service Quality</h3>
          </div>
        </header>
        <p>We report the following analyses for the subset of
        286,671 interactions that include 10 or more customer
        messages, and whose customers responded to a post-service
        survey. Hypothesis <a class="enc" href="#enc2">2</a>
        predicted that the change in customer emotion during a
        service interaction from negative to positive reflects
        service quality. To test this hypothesis, we will run a
        logistic (ordinal) regression to predict FCR (CSAT) from
        the sentiment score in each section of the interaction.</p>
        <p><strong>Resolution of Customer Needs</strong> Hypothesis
        <a class="enc" href="#enc2">2</a> predicted that the
        evolution of emotion for customers whose issue was resolved
        is different from the evolution of emotion for customers
        whose issue was not resolved. To test this hypothesis, we
        used the section number (a within-subject factor) and the
        FCR response (as a between-subject factor) in a
        mixed-effects model as predictors of customer emotion. The
        interaction between the two factors in this model indicates
        whether the evolution in emotion scores differs for
        different FCR customer groups. We found a significant
        interaction between section number and customer FCR
        (<em>F</em>(9, 1271502) = 2229.12, <em>p</em> &lt; 0.001),
        which supports that emotions develop differently for
        customers with different FCR values<a class="fn" href=
        "#fn6" id="foot-fn6"><sup>6</sup></a>. Customers who say
        their issue was resolved have a steeper climb from initial
        negative emotion, and end with higher levels of positive
        emotions. Customers who report their issue was not resolved
        had significantly lower emotion scores at the end of the
        service (Figure <a class="fig" href="#fig3">3</a>). In
        addition, we support these results with a logistic
        regression that predicts customer FCR values by customer
        sentiment scores in each section of the interaction
        (<em>χ</em> <sup>2</sup>(10) = 28481.386, <em>p</em> &lt;
        0.001). The model explained 26.1% (Nagelkerke
        <em>R<sup>2</sup></em> ) of the variance in FCR and
        correctly classified 77.4% of cases. The effect of the
        sentiment scores in the latter sections was significantly
        higher than the effect of the early sentiment scores
        (Beta=.83 and .97 of sections 9–10 vs. Beta=.27 and .07 of
        sections 1 and 2), which further demonstrate the dependency
        between emotion dynamics and service outcomes.</p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191628/images/www18companion-367-fig3.jpg"
          class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">Sentiment in different
            sections by FCR response [<em>n</em> = 286, 671]</span>
          </div>
        </figure>
        <p></p>
        <p><strong>Customer Satisfaction</strong> Hypothesis
        <a class="enc" href="#enc2">2</a> also predicted that the
        evolution of emotion in a service interaction differs
        between satisfied vs. unsatisfied customers. We test this
        prediction in a similar analysis, using customer CSAT
        response as the between-subject factor<a class="fn" href=
        "#fn7" id="foot-fn7"><sup>7</sup></a>. A significant
        interaction between satisfaction and section number
        (<em>F</em>(9, 891990) = 3386.85, <em>p</em> &lt; 0.001)
        again confirmed that emotions evolve differently for
        customers who end up reporting different levels of
        satisfaction. Interactions where customers reported a
        higher satisfaction score had a significantly steeper
        change in customer emotion during the interaction; the
        change from the initial negative emotion to the positive at
        the end was significantly larger (Figure <a class="fig"
        href="#fig4">4</a>).</p>
        <p>Here as well, an ordinal regression supported the
        results, showing that customer sentiment scores in each
        section of the interaction predicts customer satisfaction
        scores (<em>χ</em> <sup>2</sup>(10) = 44725.318, <em>p</em>
        &lt; .001). This model explained 28.9% (Nagelkerke
        <em>R<sup>2</sup></em> ) of the variance in customer
        satisfaction. Importantly, the effect of the sentiment
        scores in the <em>latter</em> sections of customers who
        reach higher level of satisfaction are significantly larger
        than the effects of early sections (Beta=.895 and 1.10 of
        sections 9 and 10, vs. Beta=-1.71 and -1.27 of sections 1
        and 2). This again supports the claimed relationship
        between emotion evolution and satisfaction.</p>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191628/images/www18companion-367-fig4.jpg"
          class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">Sentiment in different
            sections by customer satisfaction (CSAT) response
            [<em>n</em> = 286, 671]</span>
          </div>
        </figure>
        <p></p>
        <p>Figures <a class="fig" href="#fig3">3</a> and <a class=
        "fig" href="#fig4">4</a> illustrate the findings of
        Hypothesis <a class="enc" href="#enc2">2</a>, showing
        patterns of relationships between customer emotions during
        service and customer evaluations (FCR, CSAT) after the
        service interaction. The figures also summarize our key
        theme, showing that interactions that start with negative
        emotions (because of a service failure), can evolve into
        (good) service resolution, evident in more positive
        emotions at the end of the interaction. Our analyses show
        less influence of initial emotions (early in the
        interaction), further supporting our interpretation that
        initial emotions reflect pre-chat service failure. Both
        figures suggests the existence of a “tipping point” around
        the middle of the interaction, from which positive customer
        emotions begin to emerge. We suggest the problem
        resolution, that may have started around that stage, is
        connected to this phenomenon. Identifying the exact events
        that led to such an emergence of customer emotion, and the
        exact dynamic around it are beyond the scope of our
        analyses. In short, automated, real time assessments of
        customer emotion <em>during</em> an interaction may
        essentially replace (more costly and late) evaluations of
        service quality. Emotion dynamics during the interaction
        reflect customer satisfaction.</p>
      </section>
    </section>
    <section id="sec-22">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Discussion</h2>
        </div>
      </header>
      <p>&nbsp; We introduce a new approach to studying customer
      emotions in service interactions, and to assessing service
      quality (service failure and service recovery) in a service
      interaction. The approach offers a new model for automatic
      assessment of customer emotions in the service domain, and
      our analyses provide evidence of the validity of these
      assessments in identifying customer emotions, and their
      utility for identifying resolution of customer needs and
      customer satisfaction. The model allows real-time assessments
      of customer emotion in spontaneous and real-life service
      interactions. This new approach has substantial benefits in
      providing objective, unobtrusive assessments of customer
      service, that build directly on customers’ actual expressions
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0031">31</a>], and in
      assessing customer emotion in far greater granularity than
      prevailing methods (of customer surveys) can depict. Current
      practices typically aggregate reports of customers into bins
      of “satisfied” and “not satisfied”. Our approach offers a
      more complete picture, of the changes in customer emotion
      during an interaction, showing the relation of these changes
      to service quality evaluations. This approach can be used to
      detect service delivery issues in real time, allowing
      interventions as a problem occurs, rather than after it
      occurs, which is currently the common practice. To this end,
      the CustSent model is applied in the LivePerson chat service
      platform, and monitors real-time customer emotion development
      in many different brands.</p>
      <section id="sec-23">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.1</span>
            Contributions</h3>
          </div>
        </header>
        <p>Our paper makes three core contributions: (a)
        methodologically, it proposes automated sentiment analysis
        as a useful tool for both service delivery and service
        research ; (b) theoretically, it documents the meaning of
        trends and changes in emotions that occur within an
        individual interaction; (c) managerially, it suggests a new
        way to leverage sentiment analysis to improve service
        operations. Our approach suggests a wide range of ideas
        that can promote research and management of service
        delivery [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0022">22</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0023">23</a>], operations [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0010">10</a>], and human resource
        management [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0017">17</a>].</p>
        <p>Our results show that the level of positive emotions
        that customers reach (compared to where they start)
        reflects the quality of the service interaction. Better
        service quality is evident in the (positive) emotions
        customers express in the latter part of their interactions.
        Thus, automated emotion assessment, conducted in real-time
        during service interactions, can be used to evaluate
        service quality, and to intervene toward better service
        recovery [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0006">6</a>]. Identifying customers whose
        emotions do not improve towards the end of the interaction
        can help managers intervene before a service situation
        escalates. A system of alerts, for example, when customer
        sentiment stays negative, can be used as notification that
        something is wrong. In addition, our prediction model can
        be used for developing measurements to replace customer
        surveys, using an automated objective tool, rather than
        post-hoc subjective assessments.</p>
      </section>
      <section id="sec-24">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.2</span> Limitations
            and Future Research</h3>
          </div>
        </header>
        <p>A natural step for future research is assessing when and
        what emotion alerts should be activated, and what their
        impact may be. There are also limitations to our work that
        call for more research. First, our analyses currently
        detect customer emotion, only; a desirable extension for a
        complete picture of service interactions would be
        monitoring expressions of agents. Employees must regulate
        the emotions they express toward customers, performing what
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0025">25</a>]
        described as “emotional labor”. A separate emotion
        detection tool is therefore needed for analyzing employee
        emotion. Second, the approach we suggest can help
        investigations of effects of customer emotion on employee
        performance. Some recent research, for example, shows that
        customer sentiment influences employee response time and
        employee tendency to take unscheduled breaks [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0002">2</a>, <a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0004">4</a>]. Dynamic
        planning of time allotted to a given service interaction,
        or of employee breaks based on identified customer
        emotions, can build on these analyses, and help reduce
        employee burnout. Third, we analyzed only customer textual
        expressions toward detecting customer emotions. Sentiment
        analysis tools may be improved with integration of
        additional aspects of customer behavior, like key strokes,
        or engagement history (cf. <a class=
        "link-inline force-break" href=
        "https://www.clicktale.com/">https://www.clicktale.com/</a>).
        Such integration can potentially improve predictions of
        service evaluations. Lastly, combining sentiment analysis
        with aspect analysis (e.g. [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0005">5</a>]), in the context of service
        delivery, can further distinguish the emotions resulting
        from service failure and recovery; in addition this may
        also provide the business some guidance into optimizing
        service recovery strategies. This opens up numerous
        opportunities for research.</p>
      </section>
    </section>
    <section id="sec-25">
      <header>
        <div class="title-info">
          <h2>Acknowledgement</h2>
        </div>
      </header>
      <p>We thank Naama Tepper and Shlomo Lahav for initiating the
      collaboration between the Technion and LivePerson, Ella
      Nadjharov, Igor Gavako and Dr. Valery Trofimov (the SEELab
      team at the Technion), and the following students for helping
      CustSent testing and evaluation: Galia Bar, David Spivak,
      Gabby Mayer, Cassidy Laidlaw, Laura Blumenfeld, Beaux
      Ballard.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Apoorv Agarwal, Boyi
        Xie, Ilia Vovsha, Owen Rambow, and Rebecca Passonneau.
        2011. Sentiment analysis of twitter data. In
        <em><em>Proceedings of the workshop on languages in social
        media</em></em> . Portland, Oregon, 30–38.</li>
        <li id="BibPLXBIB0002" label="[2]">Daniel Altman. 2017.
        <em>Modeling employee behavioral reactions to emotions
        expressed by customers</em>. Master's thesis.
        Technion—Israel Institute of Technology.</li>
        <li id="BibPLXBIB0003" label="[3]">Teresa&nbsp;M Amabile,
        Elisabeth&nbsp;A. Schatzel, Giovanni&nbsp;B Moneta, and
        Steven&nbsp;J Kramer. 2004. Leader behaviors and the work
        environment for creativitity. <em><em>The Leadership
        Quarterly</em></em> 15, 1 (2004), 5–32.</li>
        <li id="BibPLXBIB0004" label="[4]">Shelly Ashtar. 2017.
        <em>The effect of customer emotion and work demands on
        employee unscheduled breaks</em>. Master's thesis.
        Technion—Israel Institute of Technology.</li>
        <li id="BibPLXBIB0005" label="[5]">Samuel Brody and Noemie
        Elhadad. 2010. An unsupervised aspect-sentiment model for
        online reviews. In <em><em>Human Language Technologies: The
        2010 Annual Conference of the North American Chapter of the
        Association for Computational Linguistics</em></em> .
        Association for Computational Linguistics, 804–812.</li>
        <li id="BibPLXBIB0006" label="[6]">Riza Casidy and Hyunju
        Shin. 2015. The effects of harm directions and service
        recovery strategies on customer forgiveness and negative
        word-of-mouth intentions. <em><em>Journal of Retailing and
        Consumer Services</em></em> 27 (2015), 103–112.</li>
        <li id="BibPLXBIB0007" label="[7]">Marie&nbsp;T.
        Dasborough. 2003. Cognitive Asymetry in employee affective
        reactions to leadership behaviors. <em><em>Leadership
        Quarterly</em></em> 17, 2 (2003), 1–32.</li>
        <li id="BibPLXBIB0008" label="[8]">Tom DeWitt, Doan&nbsp;T.
        Nguyen, and Roger Marshall. 2008. Exploring customer
        loyalty following service recovery: The mediating effects
        of trust and emotions. <em><em>Journal of Service
        Research</em></em> 10, 3 (2008), 269–281.</li>
        <li id="BibPLXBIB0009" label="[9]">Susan Folkman,
        Richard&nbsp;S. Lazarus, Christine Dunkel-Schetter, Anita
        DeLongis, and Rand&nbsp;J. Gruen. 1986. Dynamics of a
        stressful encounter. <em><em>Journal of Personality and
        Social Psychology</em></em> 50, 5(1986), 992.</li>
        <li id="BibPLXBIB0010" label="[10]">Gerard George,
        Ernst&nbsp;C Osinga, Dovev Lavie, and Brent&nbsp;A Scott.
        2016. Big Data and Data Science methods for management
        research. <em><em>Academy of Management Journal</em></em>
        59, 5 (2016), 1493–1507.</li>
        <li id="BibPLXBIB0011" label="[11]">Markus Groth and
        Alicia&nbsp;A Grandey. 2012. From bad to worse: Negative
        exchange spirals in employee-customer service interactions.
        <em><em>Organizational Psychology Review</em></em> 2, 3
        (2012), 208–233.</li>
        <li id="BibPLXBIB0012" label="[12]">Jonathan Herzig, Guy
        Feigenblat, Michal Shmueli-Scheuer, David Konopnicki, and
        Anat Rafaeli. 2016. Predicting customer satisfaction in
        customer support conversations in social media using
        affective features. <em><em>Proceedings of UMAP
        ’16</em></em> (2016), 115–119.</li>
        <li id="BibPLXBIB0013" label="[13]">George Lakoff. 1984.
        Performative subordinate clauses. In <em><em>Proceedings of
        the Annual Meeting of the Berkeley Linguistics
        Society</em></em> , Vol.&nbsp;10. 472–480.</li>
        <li id="BibPLXBIB0014" label="[14]">Robin Lakoff. 1976.
        Language in context. <em><em>Language</em></em> 48, 4
        (1976), 907–927.</li>
        <li id="BibPLXBIB0015" label="[15]">Rikard Larsson. 1993.
        Case survey methodology: Quantitative analysis of patterns
        across case studies. <em><em>Academy of
        Management</em></em> 36, 6 (1993), 1515–1546.</li>
        <li id="BibPLXBIB0016" label="[16]">Christopher Manning,
        Raghavan Prabhakar, and Schütze Hinrich. 2009. Introduction
        to information retrieval. (2009).</li>
        <li id="BibPLXBIB0017" label="[17]">Samuel&nbsp;T McAbee,
        Ronald&nbsp;S Landis, and Maura&nbsp;I Burke. 2017.
        Inductive reasoning: The promise of Big Data. <em><em>Human
        Resource Management Review</em></em> 27, 2 (2017),
        277–290.</li>
        <li id="BibPLXBIB0018" label="[18]">Janet&nbsp;R
        McColl-Kennedy and Amy&nbsp;K Smith. 2006. Customer
        emotions in service failure and recovery encounters. In
        <em><em>Research on emotion in organizations</em></em> ,
        W.J. Zerbe, N.M. Ashkanasy, and E.E.J. Haertel (Eds.).
        Vol.&nbsp;2. Emerald Group Publishing Ltd, Bingley, UK,
        Chapter&nbsp;10, 237–268.</li>
        <li id="BibPLXBIB0019" label="[19]">Janet&nbsp;R
        McColl-Kennedy, Beverley&nbsp;A Sparks, By
        Beverley&nbsp;Sparks, and Janet McColl-Kennedy. 2003.
        Application of Fairness Theory to Service Failures and
        Service Recovery. <em><em>Journal of Service
        Research</em></em> 5, 3 (2003), 251–266.</li>
        <li id="BibPLXBIB0020" label="[20]">Ella Miron-Spektor,
        Dorit Efrat-Treister, Anat Rafaeli, and Orit Schwarz-Cohen.
        2011. Others’ anger makes people work harder not smarter.
        <em><em>Journal of Applied Psychology</em></em> 96, 5
        (2011), 1065–1075.</li>
        <li id="BibPLXBIB0021" label="[21]">Lakshmi Narayanan,
        Shanker Menon, and Paul&nbsp;E Spector. 1999. Stress in the
        workplace: A comparison of gender and occupations.
        <em><em>Journal of Organizational Behavior</em></em> 20, 1
        (1999), 63.</li>
        <li id="BibPLXBIB0022" label="[22]">
        Francisco&nbsp;Villarroel Ordenes, Stephan Ludwig, Ko
        De&nbsp;Ruyter, Dhruv Grewal, and Martin Wetzels. 2017.
        Unveiling what is written in the stars. <em><em>Journal of
        Consumer Research</em></em> 43, 6 (2017), 875–894.</li>
        <li id="BibPLXBIB0023" label="[23]">Anat Rafaeli, Daniel
        Altman, Dwayne&nbsp;D Gremler, Ming-Hui Huang, Dhruv
        Grewal, Bala Iyer, A. Parasuraman, and Ko de Ruyter. 2017.
        The future of frontline research: Invited Commentaries.
        <em><em>Journal of Service Research</em></em> 20, 1 (2017),
        91–99.</li>
        <li id="BibPLXBIB0024" label="[24]">Anat Rafaeli, Amir
        Erez, Shy Ravid, Rellie Derfler-Rozin, Dorit&nbsp;Efrat
        Treister, and Ravit Scheyer. 2012. When customers exhibit
        verbal aggression, employees pay cognitive costs.
        <em><em>Journal of Applied Psychology</em></em> 97, 5
        (2012), 931–950.</li>
        <li id="BibPLXBIB0025" label="[25]">Anat Rafaeli and
        Robert&nbsp;I Sutton. 1987. Expression of emotion as part
        of the work role. <em><em>Academy of Management
        Review</em></em> 12, 1 (1987), 23–37.</li>
        <li id="BibPLXBIB0026" label="[26]">Richard Socher, Alex
        Perelygin, Jean Wu, Jason Chuang, Christopher&nbsp;D
        Manning, Andrew Ng, and Christopher Potts. 2013. Recursive
        deep models for semantic compositionality over a sentiment
        treebank. In <em><em>Proceedings of the 2013 conference on
        empirical methods in natural language processing</em></em>
        . 1631–1642.</li>
        <li id="BibPLXBIB0027" label="[27]">Maite Taboada, Julian
        Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede.
        2011. Lexicon-based methods for sentiment analysis.
        <em><em>Computational Linguistics</em></em> 37, 2 (2011),
        267–307.</li>
        <li id="BibPLXBIB0028" label="[28]">Yla&nbsp;R Tausczik and
        James&nbsp;W Pennebaker. 2010. The psychological meaning of
        words: LIWC and computerized text analysis methods.
        <em><em>Journal of Language and Social Psychology</em></em>
        29, 1 (2010), 24–54.</li>
        <li id="BibPLXBIB0029" label="[29]">Mike Thelwall, Kevan
        Buckley, Georgios Paltoglou, and Di Cai. 2010. Sentiment
        strength detection in short informal text. <em><em>The
        American Society for Informational science and
        technology</em></em> 61, 12 (12 2010), 2544–2558.</li>
        <li id="BibPLXBIB0030" label="[30]">Gerben&nbsp;A van
        Kleef, Carsten K&nbsp;W De&nbsp;Dreu, and Antony S&nbsp;R
        Manstead. 2004. The interpersonal effects of anger and
        happiness in negotiations. <em><em>Journal of Personality
        and Social Psychology</em></em> 86, 1(2004), 57–76.</li>
        <li id="BibPLXBIB0031" label="[31]">Eugene&nbsp;J Webb,
        Donald&nbsp;T Campbell, Richard&nbsp;D Schwartz, and Lee
        Sechrest. 1966. <em><em>Unobstrusive measures: Nonreactive
        research in the social sciences</em></em> . Vol.&nbsp;111.
        Rand Mc Nally, Chicago.</li>
        <li id="BibPLXBIB0032" label="[32]">Howard&nbsp;M Weiss and
        Russell Cropanzano. 1996. Affective Events Theory.
        <em><em>Research in Organizational Behavior</em></em> 18, 1
        (1996), 1–74.</li>
        <li id="BibPLXBIB0033" label="[33]">Renxian Zhang, Dehong
        Gao, and Wenjie Li. 2011. What are tweeters doing:
        Recognizing speech acts in Twitter. <em><em>Analyzing
        Microtext</em></em> (2011), 86–91.</li>
        <li id="BibPLXBIB0034" label="[34]">Shaodian Zhang, Erin
        Bantum, Jason Owen, and Noémie Elhadad. 2014. Does
        sustained participation in an online health community
        affect sentiment?. In <em><em>AMIA Annual Symposium
        Proceedings</em></em> . American Medical Informatics
        Association.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>A value of zero
    may also indicate an equal amount of positive and negative
    emotion in the same message, but our data show this occurs in a
    negligible number of messages.</p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>We compared a
    model with 2, 3, 4 and 5 preceding words and found 3 words to
    be optimal in identifying emotion in interactions conducted in
    English.</p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>We first
    calculated the metrics separately for messages from the
    different firms. The results were not substantially different.
    For lack of space, we present the metrics of the combined
    sample of 597 messages, where the weight of each message
    corresponds to its proportion in the population.</p>
    <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>P-values
    reported in this section refer to a comparison of CustSent to
    the best result in the same category.</p>
    <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>To conduct this
    analysis on all interactions in the data, including shorter
    interactions, as a robustness check, we stretched interactions
    with less than 10 customer messages, by duplicating missing
    quantiles. For example, for an interaction with length 5:
    1,2,3,4,5, the 10 points were 1,1,2,2,3,3,4,4,5,5. The results
    of this “stretched” analysis were similar, and support the
    robustness of our test.</p>
    <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a>We also found a
    significant effect of the section number variable
    (<em>F</em>(9, 1271502) = 16409.76, <em>p</em> &lt; 0.001),
    fully supporting Hypothesis <a class="enc" href=
    "#enc1">1</a>.</p>
    <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a>We conducted
    two analyses, one defined responses of five (5) and one (1) as
    satisfied and unsatisfied customers, respectively, a second
    analysis defined responses 1–3 as unsatisfied, and 4–5 as
    satisfied. The results were identical.</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution-NonCommercial-NoDerivs 4.0 International
      (CC-BY-NC-ND&nbsp;4.0) license. Authors reserve their rights
      to disseminate the work on their personal and corporate Web
      sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons
      CC-BY-NC-ND&nbsp;4.0 License. ACM ISBN
      978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3191628">https://doi.org/10.1145/3184558.3191628</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
