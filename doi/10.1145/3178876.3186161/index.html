<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Modeling Interdependent and Periodic Real-World Action
  Sequences</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186161'>https://doi.org/10.1145/3178876.3186161</a> 
 Published in WWW2018 Proceedings Â© 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186161'>https://w3id.org/oa/10.1145/3178876.3186161</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Modeling Interdependent and
          Periodic Real-World Action Sequences</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Takeshi</span> <span class=
          "surName">Kurashima</span>, NTT Corp. &amp; Stanford
          University, <a href=
          "mailto:kurashima.takeshi@lab.ntt.co.jp">kurashima.takeshi@lab.ntt.co.jp</a>
        </div>
        <div class="author">
          <span class="givenName">Tim</span> <span class=
          "surName">Althoff</span>, Stanford University, <a href=
          "mailto:althoff@cs.stanford.edu">althoff@cs.stanford.edu</a>
        </div>
        <div class="author">
          <span class="givenName">Jure</span> <span class=
          "surName">Leskovec</span>, Stanford University, <a href=
          "mailto:jure@cs.stanford.edu">jure@cs.stanford.edu</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.3186161"
        target=
        "_blank">https://doi.org/10.1145/3178876.3186161</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Mobile health applications, including those that
        track activities such as exercise, sleep, and diet, are
        becoming widely used. Accurately predicting human actions
        in the real world is essential for targeted recommendations
        that could improve our health and for personalization of
        these applications. However, making such predictions is
        extremely difficult due to the complexities of human
        behavior, which consists of a large number of potential
        actions that vary over time, depend on each other, and are
        periodic. Previous work has not jointly modeled these
        dynamics and has largely focused on item consumption
        patterns instead of broader types of behaviors such as
        eating, commuting or exercising.</small></p>
        <p><small>In this work, we develop a novel statistical
        model, called <em>TIPAS</em>, for Time-varying,
        Interdependent, and Periodic Action Sequences. Our approach
        is based on personalized, multivariate temporal point
        processes that model time-varying action propensities
        through a mixture of Gaussian intensities. Our model
        captures short-term and long-term periodic
        interdependencies between actions through Hawkes
        process-based self-excitations. We evaluate our approach on
        two activity logging datasets comprising 12 million
        real-world actions (<em>e.g.</em>, eating, sleep, and
        exercise) taken by 20 thousand users over 17 months. We
        demonstrate that our approach allows us to make successful
        predictions of future user actions and their timing.
        Specifically, TIPAS improves predictions of actions, and
        their timing, over existing methods across multiple
        datasets by up to 156%, and up to 37%, respectively.
        Performance improvements are particularly large for
        relatively rare and periodic actions such as walking and
        biking, improving over baselines by up to 256%. This
        demonstrates that explicit modeling of dependencies and
        periodicities in real-world behavior enables successful
        predictions of future actions, with implications for
        modeling human behavior, app personalization, and targeting
        of health interventions.</small></p>
      </div>
      <div class="classifications">
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Takeshi Kurashima, Tim Althoff, and Jure Leskovec. 2018.
          Modeling Interdependent and Periodic Real-World Action
          Sequences. In <em>Proceedings of The 2018 Web Conference
          (WWW 2018).</em> ACM, New York, NY, USA 11 Pages.
          <a href="https://doi.org/10.1145/3178876.3186161" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3178876.3186161</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Activity tracking applications for mobile health have
      become an important part of people's daily lives. A
      US-nationwide study in 2013 found that 69% of adults keep
      track of a health indicator, and 21% among them used an app
      or device to do so&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0024">24</a>]. In activity logging applications
      such as Fitbit, Under Armour Record, and Argus, users might
      take one of many possible actions from a large and diverse
      space of potential actions at any point in time. Users
      continuously track many actions of their lives including
      exercise, diet, sleep, and commuting behavior with the goal
      of improving self-knowledge and personal
      well-being&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0045">45</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0046">46</a>]. User modeling is critical to making
      activity logging applications more useful by providing users
      with personalized experiences matching their specific
      objectives&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0054">54</a>]. This has the potential to
      significantly improve people's health, for instance by
      preventing negative health outcomes and promoting the
      adoption and maintenance of healthy behaviors&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0004">4</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0025">25</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0042">42</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0049">49</a>]. However,
      successful personalization of systems rests on the ability to
      predict the user's next actions and when they will
      occur&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0017">17</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0021">21</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0054">54</a>].</p>
      <p>Predicting actions is important because these predictions
      facilitate personalization of the user interface and user
      experience in order to provide users with what they need,
      without them asking for it explicitly&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0041">41</a>]. For example, in activity
      logging applications we can predict when the user will eat
      dinner and their future location in order to provide relevant
      recommendations&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0052">52</a>]. Accurate and contextualized
      predictions could further help users to realize their
      personal goals by reminding them to measure their weight or
      notifying them about the exercise the next
      morning&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0046">46</a>]. Besides predicting the action
      itself, it is also critical to predict its timing, so that
      recommendations and reminders can be made at the right time.
      For instance, diet reminders ideally are delivered just
      <em>before</em> meal choices are made&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0026">26</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0042">42</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0049">49</a>]. More generally,
      predicting user actions also enables digital personal
      assistants that support users with relevant information
      including local recommendations, traffic, weather, events,
      and news&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0019">19</a>].</p>
      <p>However, human behavior is extremely complex, which makes
      accurate predictions very challenging. In particular, human
      behavior is (1) <em>time-varying</em>, (2)
      <em>interdependent</em>, and (3) <em>periodic.</em> First,
      real-world actions <em>vary over time</em>, for example based
      on time of day (<em>e.g.</em>, spending time with friends in
      the evenings) and day of week (<em>e.g.</em>, going hiking on
      weekends)&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0035">35</a>]. Second, actions are also
      <em>interdependent</em> in the short-term and the long-term
      (<em>e.g.</em>, brushing teeth before going to bed, or
      drinking water after workouts). Third, humans are creatures
      of habit&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0017">17</a>] and exhibit <em>periodic</em>
      behaviors&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0018">18</a>], such as brushing teeth every
      morning and evening.</p>
      <p>Current user modeling techniques
      (<em>e.g.</em>,&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0035">35</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0037">37</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0050">50</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0055">55</a>]) do not jointly model all these key
      aspects (time variation, interdependence, periodicity) of
      real-world action sequences. However, failing to account for
      any of them results in decreased predictive performance. For
      example, consider the task of predicting the time of a user's
      next meal. When not accounting for periodicity, one would
      miss the fact that the user's early lunch might lead to an
      earlier dinner as well. However, this could be a critical
      mistake if the user relies on timely diet reminders.</p>
      <p>While great advances have been made in modeling specific
      aspects of behavior in narrow application domains, in
      particular in the space of recommender
      systems&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0035">35</a>] or information
      retrieval&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0048">48</a>], these lines of work have largely
      focused on consumption of items such as specific videos,
      songs, or websites&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0035">35</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0050">50</a>]. In all these cases, users repeat
      the <em>same</em> high-level actions such as watching one
      video after another. In contrast, we consider predicting
      <em>which</em> higher-level action, out of many, the user
      will take next; for example, whether they will watch a movie
      or go for a run (not which specific movie or run).
      Furthermore, previous work has often focused on predicting
      short-term actions such as the next unix
      command&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0017">17</a>], web page request&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0055">55</a>], or TV
      episode watched&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0050">50</a>]. Instead, we are interested in
      predicting longer-term actions such as a commute in the
      evening or a run the next morning.</p>
      <p><strong>This work.</strong>We present a new model for the
      task of predicting future user actions and their timing.
      First, we empirically demonstrate that action sequences
      exhibit time-varying, interdependent, and periodic patterns
      and that modeling them is critical to accurate predictions of
      user actions. Our model extends prior work on multivariate
      temporal point processes and is the first model to account
      for all three key properties. The model addresses
      (1)&nbsp;time-varying propensities of actions through mixture
      of Gaussians, (2)&nbsp;short-term dependencies between
      actions through a Hawkes process, and (3)&nbsp;long-term
      periodicity with time-dependent Weibull distributions. We
      call this model <em>TIPAS</em> referring to Time-varying
      Interdependent Periodic Action Sequences. TIPAS is
      personalized to each user through learning user-specific
      action preferences. We further develop an EM-based algorithm
      to fit this model using maximum likelihood estimation.</p>
      <p>We demonstrate that TIPAS can scale to real-world datasets
      from Argus and Under Armour activity logging applications
      that capture 12 million actions taken by 20 thousand users
      over 17 months. We evaluate our model on these two activity
      logging datasets capturing ten different real-world actions,
      and demonstrate that we can predict the user's next logged
      activity (<em>e.g.</em>, run, eat, or sleep) and the timing
      of that activity (continuous, non-discretized timestamp)
      based on the user's previous actions and their timing.</p>
      <p>Further, we show that TIPAS accurately captures all three
      fundamental behavioral patterns in real-world data. Using
      several domains of real-world actions, we demonstrate that
      our model outperforms eleven existing approaches on tasks of
      predicting actions by up to 156% as well as predicting when
      they will occur by up to 37%. Further, we show that
      performance improvements over baselines are particularly
      large for rare actions, increasing prediction accuracy over
      baselines by up to 256%. We find that these performance
      improvements are crucially enabled by modeling time-varying
      propensities of actions and their dependencies, and by
      modeling long-term periodicities of actions. Empirically,
      modeling time-varying propensities of actions yields 53% and
      40% accuracy on the two activity logging datasets. Modeling
      short-term dependencies between actions improves this to 59%
      and 49%, respectively. Also capturing long-term periodicities
      of actions further improves this to 61% and 51%,
      respectively. Thus, capturing these three properties is
      essential to predicting periodic and interdependent human
      action sequences.</p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related
          Work</h2>
        </div>
      </header>
      <p><strong>Predicting the next action.</strong>Much work has
      focused on predictions of next actions, including unix
      commands &nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0017">17</a>], user interface actions to enable
      interface adaption&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0027">27</a>], web page requests allowing for
      prefetching and latency reduction&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0055">55</a>], clicks on web
      search&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0003">3</a>],
      user behavior anomalies&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0037">37</a>], product item preferences [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0035">35</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0044">44</a>], online
      purchases&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0034">34</a>], mobile apps used&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0010">10</a>], and
      future location-based checkins&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0009">9</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0013">13</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0038">38</a>]. Many of these works
      (<em>e.g.</em>,&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0037">37</a>]) have formulated the problem as a
      discrete-time sequence prediction task and used Markov
      models. However, Markov models assume unit time steps and are
      further unable to capture long-range dependencies since the
      overall state-space will grow exponentially in the number of
      time steps considered&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0019">19</a>]. Other works have used LSTM
      models&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0030">30</a>],
      which also assume discrete time steps and are limited in
      their interpretability.</p>
      <p>In contrast, we also model and predict <em>when</em> the
      next action will occur, which is critical to surface
      recommendations and reminders at the right time. In addition,
      instead of specific web queries or item consumption, we
      consider a broader set of higher-level actions such as
      watching a movie, going for a run, or going to sleep.</p>
      <p><strong>Patterns of repeat consumption.</strong>Another
      line of work has studied repeated actions, in particular in
      the space of item consumption, including video binge
      watching&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0050">50</a>], music listening&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0032">32</a>], web page
      revisitation patterns&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>], and repeated web search
      queries&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0048">48</a>]. More recent work has focused on
      modeling these behaviors and proposed models based on
      patterns of boredom&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0032">32</a>] and recency&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0008">8</a>].</p>
      <p>Importantly, patterns of human actions in the real world,
      which are modeled in this work, are fundamentally different
      from patterns of item consumption due to their higher-level
      notion (<em>e.g.</em>, watching a movie, not which specific
      one). For example, patterns of boredom&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0011">11</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0032">32</a>] suggest that the
      probability of repeating an action within a short amount of
      time is unlikely. In contrast, we empirically observe the
      opposite in some cases, such as users commuting one way being
      extremely likely to commute back in the near future. More
      generally, real-world actions are characterized by more
      complex dynamics including time-varying behavior,
      interdependence, and periodicity of actions.</p>
      <p><strong>Temporal point processes.</strong>Recent work has
      considered temporal point processes&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0015">15</a>] including Poisson and
      Hawkes&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0028">28</a>]
      process-based models to predict the timing of future actions.
      Temporal point processes have been used to predict
      continuously time-varying item preferences&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0021">21</a>], and to
      model user influence in a social network&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0031">31</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0047">47</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0053">53</a>], the co-evolution of
      information and network structure&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0022">22</a>], competition between
      products&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0051">51</a>], mobility patterns in space and
      time&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0019">19</a>],
      user return times&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0033">33</a>], and temporal document
      clustering&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0040">40</a>]. Perhaps the closest works to ours
      are by Du et al.&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0021">21</a>], which also attempt to predict both
      future user actions <em>and</em> their timing.</p>
      <p>We extend this line of work by explicitly modeling
      time-varying action propensities as well as developing a
      novel combination of Exponential and Weibull kernels to model
      short-term and long-term periodic dependencies between
      actions. Further, we demonstrate that these aspects are
      critical when predicting real-world user actions and their
      timing across two real-world activity logging datasets.</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Task
          Description</h2>
        </div>
      </header>
      <p>The task considered in this work is, given a user and her
      history, a timestamped sequence of her actions in the past,
      to predict the user's future actions and the timing of these
      actions.</p>
      <p>Formally, let <em>U</em> be a set of users. Each user
      <em>u</em> â <em>U</em> has an action sequence, which we
      represent as a user history <span class=
      "inline-equation"><span class="tex">$H_{u} = \lbrace
      (a_{un},t_{un})\rbrace _{n=1}^{N_{u}}$</span></span> with a
      total of <em>N<sub>u</sub></em> events. Each element in
      <em>H<sub>u</sub></em> is an event consisting of an action
      and timestamp representing that user <em>u</em> takes action
      <em>a<sub>un</sub></em> â <em>A</em> at time <span class=
      "inline-equation"><span class="tex">$t_{un} \in \mathbb
      {R}^+$</span></span> (0 â¤ <em>t<sub>un</sub></em> â¤
      <em>T</em>). <em>T</em> denotes the end of our observation
      period. For example, <em>a<sub>un</sub></em> could correspond
      to watching a movie or going for a run (but not which
      specific movie or run). We assume that events are sorted by
      their timestamps, <span class="inline-equation"><span class=
      "tex">$t_{un} \le t_{un^{\prime }}$</span></span> for
      <em>n</em> &lt; <em>n</em>â². We denote the set of events
      before time <em>t</em> in user history <em>H<sub>u</sub></em>
      as <em>H<sub>ut</sub></em> = {(<em>a</em>â²,
      <em>t</em>â²)|(<em>a</em>â², <em>t</em>â²) â
      <em>H<sub>u</sub></em> and <em>t</em>â² &lt; <em>t</em>}.</p>
      <p>The task of predicting future user actions and when they
      will occur can now be formalized as follows. Given user
      history <em>H<sub>ut</sub></em> up until time <em>t</em>,
      predict the next <em>K</em> actions the user will take and
      their timing <span class="inline-equation"><span class=
      "tex">$\lbrace (a_k,t^{\prime }_k)\rbrace
      _{k=1}^K$</span></span> , where <span class=
      "inline-equation"><span class="tex">$t^{\prime }_k {\gt}
      t$</span></span> (<em>i.e.</em>, these are the actions with
      the smallest <span class="inline-equation"><span class=
      "tex">$t^{\prime }_k {\gt} t$</span></span> among all
      possible future user actions).</p>
      <p>Here, we propose a novel multivariate temporal point
      process model for this prediction task and focus on the case
      of <em>K</em> = 1.</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Empirical
          Observations</h2>
        </div>
      </header>
      <p>Next we make a series of empirical observations about
      important properties of real-world action sequences that will
      provide the basis for our statistical model TIPAS
      (Section&nbsp;<a class="sec" href="#sec-10">5</a>).
      Accounting for these observations will lead to superior
      predictive models (Section&nbsp;<a class="sec" href=
      "#sec-14">6</a>).</p>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Dataset
            Description</h3>
          </div>
        </header>
        <p>To illustrate critical properties of real-world actions
        we use a dataset of logged activities from a mobile
        activity logging application, Argus by Azumio, used in
        previous work on activity logging&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0006">6</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0007">7</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0045">45</a>]. This smartphone app
        allows users to track their various daily activities
        including drink, sleep, heart rate, running, weight, food,
        walking, biking, workout, and stretching actions. For
        example, the drink action is logged to keep track of the
        user's daily fluid intake and the workout action is used to
        log various indoor exercises such as weightlifting or
        indoor-cycling. This dataset includes over four thousand
        active users taking 1.2 million actions over the course of
        seven months (all users logged at least two unique actions
        per day on average). Due to the popularity of the app, this
        set of users is very diverse in terms of age, gender,
        health status, country of origin, and other
        features&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0007">7</a>]. We note that the following
        properties of real-world actions also hold in other
        datasets including Under Armour activity logging app data
        (Section&nbsp;<a class="sec" href="#sec-15">6.1</a>).</p>
      </section>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Properties
            of Real-World Action Sequences</h3>
          </div>
        </header>
        <p>Next, we describe three important properties of
        real-world action sequences and present empirical
        justification for each. TIPAS will explicitly address all
        three properties (Section&nbsp;<a class="sec" href=
        "#sec-10">5</a>).</p>
        <figure id="fig1">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186161/images/www2018-170-fig1.jpg"
          class="img-responsive" alt="Figure 1" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span>
            <span class="figure-title">Fraction of events within
            each time-of-day window. Notice that action propensity
            is clearly non-uniform and sometimes
            multi-modal.</span>
          </div>
        </figure><strong>Time-varying propensities of
        actions.</strong>Human real-world actions vary over time,
        for example based on time of day (<em>e.g.</em>, having
        meals in the morning, at mid-day, and in the evening) and
        day of week (<em>e.g.</em>, working out on the weekends).
        This dynamic is evident in real-world data of human
        activities as illustrated in Figure&nbsp;<a class="fig"
        href="#fig1">1</a>. The figure shows the distribution of
        the timing of three types of actions throughout the day:
        wake-up (from sleep), food, and bike. First, we observe
        that all three distributions are clearly non-uniform over
        time. For example, wake-up actions are clustered at around
        07:00 hours (7 am). Second, we observe significant
        differences in the propensities to take different actions.
        While for sleep we observe a uni-modal distribution
        concentrated in the early morning, we observe a bi-modal
        distribution for biking. The two modes in the morning and
        evening likely correspond to commute activity where users
        log their rides to and from work. We also observe two clear
        modes for food during lunch and dinner times. However,
        breakfast times seem to vary more widely across users and
        are more dispersed. Summarizing, we observe non-uniform,
        temporal distributions with varying number of modes that
        vary across actions.
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186161/images/www2018-170-fig2.png"
          class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">Fraction of interarrival
            times at each time window (log scale). Figure shows
            drink, weight, and heart rate measurement actions taken
            after run (left) and wake-up (right) actions. Notice
            that the likelihood of drink, weight, and heart-rate
            actions declines quickly after both run and wake-up
            actions. However, note that fraction of heart-rate
            actions decreases much quicker after wake-up than after
            runs.</span>
          </div>
        </figure><strong>Short-term dependencies between
        actions.</strong>Certain actions make it more likely that
        some other actions will follow shortly. For example, people
        might drink water right after exercising or stretch right
        before running. In order to examine the short-term
        correlations between actions, we extract interarrival times
        between pairs of actions (<em>i.e.</em>, the elapsed time
        between the two actions) from a set of action histories.
        Figure&nbsp;<a class="fig" href="#fig2">2</a> shows the
        distribution of interarrival times for several pairs of
        user actions after run actions (left) and sleep actions
        (right). We make two important observations. First, the
        monotonically decreasing curves show that the likelihood of
        other actions is largest right after an action has
        happened. After this, the likelihood declines very quickly
        in a monotonic manner (note the log scale of the Y-axis).
        This points to a self-excitation dynamic of logged human
        actions. For example, users are very likely to follow up on
        runs or waking up from sleep with drinking water or
        measuring their heart rate or weight. Specifically, about
        50% of the weight measurements which happen within 6 hours
        of waking up occur right within the first 30 minutes.
        Second, we find that the action dependency patterns vary
        across actions. For example, drinking is more common after
        runs than after waking up and heart rate measurements fall
        off more sharply right after waking up than after runs. In
        summary, human actions in the real world often trigger
        other actions within a short period but these patterns are
        different across actions. We can leverage these
        correlations among actions when predicting future events.
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186161/images/www2018-170-fig3.jpg"
          class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">Density describing when the
            next biking action will occur (interarrival time) given
            that the prior bike action occurred between 6-12h
            (solid black line) or between 12-18h (red dashed line)
            after midnight (timing, not duration). Notice the
            multiple and different modes of the two distributions
            indicating that biking actions recur periodically but
            that the period timing depends on the time of
            day.</span>
          </div>
        </figure><strong>Long-term periodic effects.</strong>Humans
        exhibit periodic behaviors such as waking up at about the
        same time every morning or commuting back home after about
        8 hours of work. Therefore, logged real-world actions
        likely follow periodic recurrence patterns in which the
        same action tends to recur at certain, regular intervals.
        While some of these periodic behaviors are rooted in
        intrinsic biological rhythms such as sleep&nbsp;[<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0005">5</a>], others
        are dictated by extrinsic factors (<em>e.g.</em>, when does
        one have to be in the office in the morning), or based on
        personal habits&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0017">17</a>] (<em>e.g.</em>, measuring one's
        weight before breakfast). We illustrate these dynamics
        using interarrival times between bike events in real-world
        data. Figure&nbsp;<a class="fig" href="#fig3">3</a> shows
        the distribution of interarrival times up to a maximum of
        30h, where the two curves represent observed dynamics when
        the first of the two bike actions occurred during specific
        times of day (6-12h in solid black and 12-18h in dashed red
        line; note that these correspond to the timing and not the
        duration of the bike action).
        <p></p>
        <p>We make two important observations. Previously, we had
        observed that short-term dependencies between actions
        exhibit monotonic decay. Here, we observe that this strong
        monotonic decay only holds within the first few hours and
        that we observe multiple additional peaks for both
        distributions after this initial phase. Second, we observe
        that these peaks occur at different times based on when the
        first action occurred. In the case of the distribution for
        bike actions following a 6-12h bike ride, we observe peaks
        at around 9 and 24 hours (interarrival times), and peaks at
        around 14 and 24 hours for bike actions following a 12-18h
        bike ride. This behavior is not unexpected. When biking in
        the morning (6-12h), the next bike ride will likely be a
        commute back around 9h later. However, if the bike ride
        happens in the evening (12-18h), the next bike ride is
        likely not during the middle of the night, but after 14
        hours or at around 8:00h in the morning. In addition, both
        curves exhibit a daily, 24h, periodicity. Modeling these
        periodicities allows us to capture user-specific timing of,
        for example, a late evening commute signaling a later start
        the next morning. In conclusion, two important dynamics
        could help predicting future real-world actions: actions
        display periodic recurrence and the time of recurrence can
        depend on the time of day.</p>
      </section>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Proposed
          Model</h2>
        </div>
      </header>
      <p>In this section, we operationalize the insights gained
      from empirical observations (Section&nbsp;<a class="sec"
      href="#sec-7">4</a>) in a probabilistic model based on
      temporal point processes, called TIPAS.</p>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.1</span> Background
            on Temporal Point Processes</h3>
          </div>
        </header>
        <p>A temporal point process is a random process whose
        realization consists of a list of discrete events localized
        in time, <span class="inline-equation"><span class=
        "tex">$\lbrace t_n\rbrace _{n \in \mathbb
        {N}}$</span></span> with <span class=
        "inline-equation"><span class="tex">$t_n \in \mathbb
        {R}^+$</span></span> . We introduce univariate temporal
        point processes for ease of exposition, though we will be
        using multivariate point processes to model the joint
        occurrence dynamics of multiple different actions
        (description inspired by&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0022">22</a>]; more background
        in&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0001">1</a>]). Let <em>H<sub>t</sub></em> be the
        history of events before time <em>t</em>. Temporal point
        processes can be characterized via the conditional
        intensity function representing a stochastic model for the
        time of the next event given all the times of previous
        events. Formally, the conditional intensity function
        <em>Î»</em>(<em>t</em>) is the conditional probability of
        observing an event in a small window [<em>t</em>,
        <em>t</em> + <em>dt</em>) given the history
        <em>H<sub>t</sub></em> ; that is, <span class=
        "inline-equation"><span class="tex">$\lambda (t)dt =
        \mathbb {P}\lbrace \text{event in} [t, t + dt)|H_t\rbrace
        .$</span></span> The conditional probability that no event
        happens during [<em>t</em>, <em>t</em>â²) is <span class=
        "inline-equation"><span class="tex">$S(t^{\prime }) = \exp
        (-\int _t^{t^{\prime }}\lambda (\tau)d\tau)$</span></span>
        and the conditional density that an event occurs at time
        <em>t</em>â² is <em>f</em>(<em>t</em>â²) =
        <em>Î»</em>(<em>t</em>â²)<em>S</em>(<em>t</em>â²)&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0001">1</a>]. Thus, the
        log-likelihood of a list of events <em>t</em> <sub>1</sub>,
        <em>t</em> <sub>2</sub>, â¦, <em>t<sub>n</sub></em> in an
        observation window [0, <em>T</em>), where <em>T</em> &gt;
        <em>t<sub>n</sub></em> , can be expressed as</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \mathcal {L}(t_1,
            t_2, \dots , t_n) = \sum _{i=1}^n {\log \lambda (t_i)}
            - \int _0^{T}\lambda (\tau)d\tau \, .
            \end{align}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>The intensity <em>Î»</em> can take various functional
        forms leading to a homogeneous Poisson process if
        <em>Î»</em>(<em>t</em>) is constant, to an inhomogeneous
        Poisson process if <em>Î»</em>(<em>t</em>) is time-varying
        but independent of the event history <em>H<sub>t</sub></em>
        , or to a Hawkes process if the intensity models mutual
        self-excitations between events&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0001">1</a>]. Our TIPAS model is
        based on multivariate Hawkes processes&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0028">28</a>].
        <p></p>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.2</span> Model
            Definition</h3>
          </div>
        </header>
        <p>We model user actions as a multivariate temporal point
        process with a time-varying intensity based on three
        factors based on our empirical observations
        (Section&nbsp;<a class="sec" href="#sec-7">4</a>). The
        following intensity function models the rate that action
        <em>a</em> occurs at time <em>t</em> in user history
        <em>u</em>,</p>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \lambda
            _{u}(t,a)\!=\!\alpha _{ua}\!\!+\!\!\mathit
            {Time}_{u}(t,a)\!\!+\!\!\mathit
            {ShortTerm}_{u}(t,a)\!\!+\!\!\mathit
            {LongTerm}_{u}(t,a). \!\! \end{align}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>Here, we use an additive decomposition of the
        intensity instead of modeling more complex interaction
        effects, because this approach is simple yet powerful and
        has been proven empirically successful as
        well&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0022">22</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0031">31</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0047">47</a>]. This model is conceptually
        visualized in Figure&nbsp;<a class="fig" href=
        "#fig4">4</a>. The figure shows how the overall intensity
        function <em>Î»<sub>u</sub></em> (<em>t</em>, <em>a</em>)
        (blue; here, <em>a</em> = food) is the sum of the
        time-varying propensity <em>Time<sub>u</sub></em>
        (<em>t</em>, <em>a</em>) (black), short-term dependencies
        between actions <em>ShortTerm<sub>u</sub></em> (<em>t</em>,
        <em>a</em>) (green), and long-term periodic effects
        <em>LongTerm<sub>u</sub></em> (<em>t</em>, <em>a</em>)
        (red) between actions (for simplicity, we assume no
        personalization, <em>i.e.</em>&nbsp;<em>Î±<sub>ua</sub></em>
        = 0). Note that our model does account for randomness, in
        the sense that not all actions may strictly conform to
        short-term and long-term patterns, through the personalized
        and time-varying baserates. In fact, learning model
        parameters from real data tries to account for all actions
        and will adapt distributional parameters to best explain
        all occurring actions. Next, we formally define each of the
        four factors in turn.
        <p></p>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186161/images/www2018-170-fig4.jpg"
          class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">Conceptual model overview.
            Intensity function of âfoodâ for user u is modeled by
            the sum of three types of influences; time-varying
            background intensity (A; black), short-term
            dependencies (B; green), and long-term periodic effects
            (C; red). (A) Time-varying background intensity models
            typical times for food (<em>e.g.</em>, having lunch
            around 12:00h). (B) Events of âwalkingâ and âwaterâ
            might trigger âfoodâ action within a short period of
            time. (C) Due to the early breakfast (6:00h), we might
            expect an earlier lunch.</span>
          </div>
        </figure>
        <p><strong>Personalized action preferences:
        <em>Î±<sub>ua</sub></em> .</strong>We include personalized
        user preferences for specific actions through a constant
        additive factor <em>Î±<sub>ua</sub></em> â¥ 0 for each action
        and user. Note that one could also model user preferences
        to be time-varying instead. However, this would lead to a
        very large number of parameters and we show in
        Section&nbsp;<a class="sec" href="#sec-14">6</a> that this
        simple model works well in practice.</p>
        <p><strong>Time-varying propensities of actions:
        <em>Time<sub>u</sub></em> (<em>t</em>,
        <em>a</em>).</strong>Events can occur without influence
        from preceding events according to the background intensity
        function <em>Time<sub>u</sub></em> (<em>t</em>,
        <em>a</em>). Having observed that the propensity of actions
        varies across time of day (Section&nbsp;<a class="sec"
        href="#sec-9">4.2</a>), we model the background intensity
        of action <em>a</em> as a function of time-of-day through a
        Gaussian mixture model. We define:</p>
        <div class="table-responsive" id="eq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray} \mathit
            {Time}_{u}(t,a) = \sum _{z \in Z} \frac{\beta
            _{az}}{\sqrt {2\pi \sigma _{az}^{2}}}\exp \Bigl (-
            \frac{\bigl (l_{t}-\mu _{az}\bigr)^{2}}{2\sigma
            _{az}^{2}}\Bigr)\;\;, \end{eqnarray}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>where <em>z</em> â Z represents the latent class of
        Gaussian mixture model (the number of mixtures can be
        determined through cross-validation). For each action
        <em>a</em> and latent mixture class <em>z</em>,
        <em>Î¼<sub>az</sub></em> &gt; 0 and <em>Ï<sub>az</sub></em>
        &gt; 0 denote the mean and standard deviation of the
        Gaussian distribution. The importance of that mixture on
        the overall intensity function <em>Time<sub>u</sub></em>
        (<em>t</em>, <em>a</em>) is captured by
        <em>Î²<sub>az</sub></em> â¥ 0. <em>l<sub>t</sub></em>
        corresponds to the time of day of timestamp <em>t</em>
        (<em>i.e.</em>, elapsed time since midnight). We show in
        Section&nbsp;<a class="sec" href="#sec-17">6.3</a> that
        Gaussian mixtures fit temporal variation in real-world data
        well.
        <p></p>
        <p><strong>Short-term dependencies between actions:
        <em>ShortTerm<sub>u</sub></em> (<em>t</em>,
        <em>a</em>).</strong>To model short-term dependencies
        between actions, we consider how the rate at which action
        <em>a</em> occurs at time <em>t</em> (Equation <a class=
        "eqn" href="#eq2">2</a>) is influenced by actions
        <em>a</em>â² which occurred at previous time <em>t</em>â²
        &lt; <em>t</em>. We model these influences as a Hawkes
        process exhibiting self-excitations using Exponential decay
        functions starting at the time of previous actions. As
        demonstrated in Section&nbsp;<a class="sec" href=
        "#sec-9">4.2</a>, the short-term influence of previous
        actions diminishes quickly and monotonically, making the
        Exponential distribution a natural choice for the decay
        function. We define:</p>
        <div class="table-responsive" id="eq4">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \mathit
            {ShortTerm}_{u}(t,a) = \sum _{(t^{\prime },a^{\prime })
            \in H_{ut} } \theta _{a^{\prime }a}\omega _{a^{\prime
            }a}\exp (-\omega _{a^{\prime }a}\Delta _{t^{\prime }t})
            \;\;, \end{align}</span><br />
            <span class="equation-number">(4)</span>
          </div>
        </div>where <em>H<sub>ut</sub></em> = {(<em>t</em>â²,
        <em>a</em>â²)|(<em>t</em>â², <em>a</em>â²) â
        <em>H<sub>u</sub></em> and <em>t</em>â² &lt; <em>t</em>} is
        the set of events before time <em>t</em> in history
        <em>u</em>, and <span class="inline-equation"><span class=
        "tex">$\Delta _{t^{\prime }t} = t - t^{\prime
        }$</span></span> is the time difference between time
        <em>t</em>â² and time <em>t</em> &gt; <em>t</em>â². Further,
        <span class="inline-equation"><span class="tex">$\omega
        _{a^{\prime }a} \ge 0$</span></span> determines how quickly
        action <em>a</em>â² triggers action <em>a</em> (shape of
        Exponential distribution), and <span class=
        "inline-equation"><span class="tex">$\theta _{a^{\prime }a}
        \ge 0$</span></span> determines how likely action
        <em>a</em>â² triggers action <em>a</em> (scaling of
        distribution). We estimate these parameters for each pair
        of actions (<em>a</em>â², <em>a</em>). Therefore, this
        component of the model captures the interdependencies
        between different actions (<em>e.g.</em>, drinking after
        running), as well as the self-exciting effects of actions
        (<em>e.g.</em>, running after running). We show in
        Section&nbsp;<a class="sec" href="#sec-17">6.3</a> that a
        Hawkes process with Exponential decay function fits
        short-term action dependencies in real-world data well.
        <p></p>
        <p><strong>Long-term periodic effects:
        <em>LongTerm<sub>u</sub></em> (<em>t</em>,
        <em>a</em>).</strong>We model the long-term periodic
        effects between identical actions (<em>e.g.</em>, run to
        run) using Weibull distributions. The Weibull distribution
        is a continuous distribution with positive support
        (<em>i.e.</em>, for <span class=
        "inline-equation"><span class="tex">$\Delta _{t^{\prime
        }t}{\gt}0$</span></span> ) that is well suited to model
        long-term effect patterns at different points in time and
        with different variance around its mean. We model the rate
        at which action <em>a</em> occurs at time <em>t</em>
        influenced by a previous event of action <em>a</em> at time
        <em>t</em>â² as follows:</p>
        <div class="table-responsive" id="eq5">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \mathit
            {LongTerm}_{u}(t,a) = \sum _{(t^{\prime },a^{\prime })
            \in H_{ut}^a} \phi _{c_{t^{\prime }}a} \gamma
            _{c_{t^{\prime }}a} \kappa _{c_{t^{\prime }}a} \Delta
            _{t^{\prime }t}^{\kappa _{c_{t^{\prime }}a}-1} \! \exp
            (- \gamma _{c_{t^{\prime }}a} \Delta _{t^{\prime
            }t}^{\kappa _{c_{t^{\prime }}a}})
            \end{align}</span><br />
            <span class="equation-number">(5)</span>
          </div>
        </div>where <span class="inline-equation"><span class=
        "tex">$H_{ut}^a = \lbrace (t^{\prime },a^{\prime
        })|(t^{\prime },a^{\prime }) \in H_{u}$</span></span> and
        <em>t</em>â² &lt; <em>t</em> and <em>a</em>â² = <em>a</em>}
        is the set of events of action <em>a</em> before time
        <em>t</em> in history <em>u</em>, and <span class=
        "inline-equation"><span class="tex">$\Delta _{t^{\prime }t}
        = t - t^{\prime }$</span></span> is again the time
        difference between time <em>t</em>â² and time <em>t</em>
        &gt; <em>t</em>â². As shown in Section&nbsp;<a class="sec"
        href="#sec-9">4.2</a>, long-term effects vary based on the
        time of day of action <em>a</em>â². This is captured through
        the parameter <span class="inline-equation"><span class=
        "tex">$c_{t^{\prime }}\in C$</span></span> that represents
        discretized time-of-day windows (<em>e.g.</em>, using four
        classes as 0-6h, 6-12h, 12-18h, and 18-24h). This allows us
        to learn time-of-day-dependent distributions modeling
        different periodicities. Parametrized by this time-of-day
        category <span class="inline-equation"><span class=
        "tex">$c_{t^{\prime }}$</span></span> and by action
        <em>a</em>, <span class="inline-equation"><span class=
        "tex">$\gamma _{c_{t^{\prime }}a} \ge 0$</span></span> ,
        <span class="inline-equation"><span class="tex">$\phi
        _{c_{t^{\prime }}a} \ge 0$</span></span> determine how
        quickly and how likely (influence) action <em>a</em>â²
        (which occurred in time-of-day window <span class=
        "inline-equation"><span class="tex">$c_{t^{\prime
        }}$</span></span> ) triggered its following event of action
        <em>a</em>. <span class="inline-equation"><span class=
        "tex">$\kappa _{c_{t^{\prime }}a} \ge 0$</span></span>
        determines the shape of the Weibull distribution. In
        Section&nbsp;<a class="sec" href="#sec-17">6.3</a>, we
        demonstrate that the Weibull distribution closely match
        periodic dynamics in real-world data.
        <p></p>
      </section>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.3</span> Model
            Inference</h3>
          </div>
        </header>
        <p>We use maximum likelihood estimation to infer the
        parameters of our proposed model (Equation&nbsp;<a class=
        "eqn" href="#eq2">2</a>). The unknown parameters are Î± =
        {{<em>Î±<sub>ua</sub></em> } <sub><em>u</em> â
        <em>U</em></sub> } <sub><em>a</em> â <em>A</em></sub> , Î² =
        {{<em>Î²<sub>az</sub></em> } <sub><em>a</em> â
        <em>A</em></sub> } <sub><em>z</em> â Z</sub>, Î¼ =
        {{<em>Î¼<sub>az</sub></em> } <sub><em>a</em> â
        <em>A</em></sub> } <sub><em>z</em> â Z</sub>, Ï =
        {{<em>Ï<sub>az</sub></em> } <sub><em>a</em> â
        <em>A</em></sub> } <sub><em>z</em> â Z</sub>, <span class=
        "inline-equation"><span class="tex">$\Theta = \lbrace
        \lbrace \theta _{a^{\prime }a}\rbrace _{a \in A}\rbrace
        _{a^{\prime } \in A}$</span></span> , <span class=
        "inline-equation"><span class="tex">$\Omega = \lbrace
        \lbrace \omega _{a^{\prime }a}\rbrace _{a \in A}\rbrace
        _{a^{\prime } \in A}$</span></span> , Î¦ =
        {{<em>Ï<sub>ca</sub></em> } <sub><em>c</em> â
        <em>C</em></sub> } <sub><em>a</em> â <em>A</em></sub> , Î =
        {{<em>Î³<sub>ca</sub></em> } <sub><em>c</em> â
        <em>C</em></sub> } <sub><em>a</em> â <em>A</em></sub> , and
        K = {{<em>Îº<sub>ca</sub></em> } <sub><em>c</em> â
        <em>C</em></sub> } <sub><em>a</em> â <em>A</em></sub> . The
        set of all parameters is denoted by Î¨ = {Î±, Î², Î¼, Ï, Î, Î©,
        Î¦, Î, K}.</p>
        <p>The log-likelihood function (Equation&nbsp;<a class=
        "eqn" href="#eq1">1</a>), given a set of user histories
        <span class="inline-equation"><span class="tex">$\mathcal
        {H} = \lbrace H_u\rbrace _{u \in U}$</span></span> , can be
        expressed as:</p>
        <div class="table-responsive" id="eq6">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \mathcal {L}(\Psi
            |\mathcal {H}) = \sum _{u \in U}\sum _{n=1}^{N_{u}}
            \log \lambda _{u}(t_{un},a_{un}) - \sum _{u \in U} \int
            _{0}^{T} \sum _{a \in A} \lambda _{u}(t,a)dt \;\;,
            \end{align}</span><br />
            <span class="equation-number">(6)</span>
          </div>
        </div>where the last term, the expectation function,
        represents the expected number of events in the time period
        from 0 to <em>T</em>. Combining Equations (<a class="eqn"
        href="#eq2">2</a>)-(<a class="eqn" href="#eq6">6</a>), the
        log-likelihood can be written as follows:
        <div class="table-responsive" id="eq7">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \mathcal {L}(\Psi
            |\mathcal {H}) = \nonumber \\ {} &amp; \sum _{u \in U}
            \sum _{n=1}^{N_{u}} \log \Biggl \lbrace \alpha
            _{ua_{un}} + \sum _{z \in Z} \frac{\beta
            _{a_{un}z}}{\sqrt {2\pi \sigma _{a_{un}z}^{2}}}\exp
            \Bigl (- \frac{\bigl (l_{t_{un}}-\mu
            _{a_{un}z}\bigr)^{2}}{2\sigma _{a_{un}z}^{2}}\Bigr)
            \nonumber \\ {} &amp; + \sum _{m=1}^{n-1} \theta
            _{a_{um}a_{un}} \omega _{a_{um}a_{un}} \exp (-\omega
            _{a_{um}a_{un}} \Delta _{t_{um}t_{un}})\nonumber \\ {}
            &amp; + \sum _{l=1}^{n-1} \Bigl (I(a_{ul}=a_{un}) \phi
            _{c_{ul}a_{un}} \gamma _{c_{ul}a_{un}} \kappa
            _{c_{ul}a_{un}} \Delta _{t_{ul}t_{un}}^{\kappa
            _{c_{ul}a_{un}}-1} \nonumber \\ {} &amp; \times \exp
            (-\gamma _{c_{ul}a_{un}} \Delta _{t_{ul}t_{un}}^{\kappa
            _{c_{ul}a_{un}}}) \Bigr) \Biggr \rbrace - \sum _{u \in
            U} \int _{0}^{T} \sum _{a \in A} \lambda _{u}(t,a)dt
            \;\;, \end{align}</span><br />
            <span class="equation-number">(7)</span>
          </div>
        </div>where <em>c<sub>ul</sub></em> â <em>C</em> represents
        time-of-day category of <em>l</em>-th event of <em>u</em>,
        and <em>I</em>(Â·) is the indicator function. The integral
        in Equation&nbsp;<a class="eqn" href="#eq7">7</a> can be
        analytically calculated.
        <p></p>
        <p>Inspired by previous work&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0022">22</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0053">53</a>], we develop an
        efficient inference algorithm to maximize the
        log-likelihood based on the EM algorithm. By iterating the
        E-step and the M-step until convergence, we obtain a local
        optimum solution for Î¨.</p>
        <p><strong>E-step.</strong>Conceptually, we introduce
        latent variables p, q, r to capture why each event was
        triggered either through user preference, time-varying
        background intensity, short-term action interdependencies,
        or long-term periodic effects. Let <em>p</em> <sub>0,
        <em>un</em></sub> be the probability that the <em>n</em>-th
        event of user <em>u</em> was triggered by user preference,
        <em>p</em> <sub><em>z</em>, <em>un</em></sub> be the
        probability that the <em>n</em>-th event of user <em>u</em>
        was triggered by the time-varying background intensity
        function of latent class <em>z</em>, <em>q</em>
        <sub><em>um</em>, <em>un</em></sub> be the probability that
        the <em>n</em>-th event of user <em>u</em> was triggered by
        the short-term effect of the <em>m</em>-th event of user
        <em>u</em>, and <em>r</em> <sub><em>ul</em>,
        <em>un</em></sub> be the probability that the <em>n</em>-th
        event of user <em>u</em> was triggered by the long-term
        effect of the <em>l</em>-th event of user <em>u</em>.</p>
        <p>In E-step, <em>k</em>-th estimate of <span class=
        "inline-equation"><span class=
        "tex">$p^{k}_{0,un}$</span></span> , <span class=
        "inline-equation"><span class=
        "tex">$p_{z,un}^{k}$</span></span> , <span class=
        "inline-equation"><span class=
        "tex">$q^{k}_{um,un}$</span></span> , and <span class=
        "inline-equation"><span class=
        "tex">$r^{k}_{ul,un}$</span></span> are calculated by:</p>
        <div class="table-responsive" id="eq8">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} p^{k}_{0,un} =
            \frac{\alpha ^{k}_{ua_{un}}}{R_{un}} \;\;,
            \end{align}</span><br />
            <span class="equation-number">(8)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq9">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} p_{z,un}^{k} =
            \frac{1}{R_{un}} \frac{\beta _{a_{un}z}^{k}}{\sqrt
            {2\pi (\sigma _{a_{un}z}^{k})^{2}}}\exp \Bigl (-
            \frac{\bigl (l_{t_{un}}-\mu
            ^{k}_{a_{un}z}\bigr)^{2}}{2(\sigma
            ^{k}_{a_{un}z})^{2}}\Bigr) \;\;,
            \end{align}</span><br />
            <span class="equation-number">(9)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq10">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} q^{k}_{um,un} =
            \frac{1}{R_{un}} \theta ^{k}_{a_{um}a_{un}} \omega
            ^{k}_{a_{um}a_{un}} \exp (-\omega ^{k}_{a_{um}a_{un}}
            \Delta _{t_{um}t_{un}}) \;\;, \end{align}</span><br />
            <span class="equation-number">(10)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq11">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} r^{k}_{ul,un} =
            \Biggl \lbrace \frac{1}{R_{un}} \phi
            ^{k}_{c_{ul}a_{un}} \gamma ^{k}_{c_{ul}a_{un}} \kappa
            ^{k}_{c_{ul}a_{un}} {} &amp; \times \Delta
            _{t_{ul}t_{un}}^{\kappa ^{k}_{c_{ul}a_{un}} - 1} \exp
            (- \gamma ^{k}_{c_{ul}a_{un}} \Delta
            _{t_{ul}t_{un}}^{\kappa ^{k}_{c_{ul}a_{un}}}) \Biggr
            \rbrace \;\;, \end{align}</span><br />
            <span class="equation-number">(11)</span>
          </div>
        </div>where Î¨ <sup><em>k</em></sup> = {Î±
        <sup><em>k</em></sup> , Î² <sup><em>k</em></sup> , Î¼
        <sup><em>k</em></sup> , Ï <sup><em>k</em></sup> , Î
        <sup><em>k</em></sup> , Î© <sup><em>k</em></sup> , Î¦
        <sup><em>k</em></sup> , Î <sup><em>k</em></sup> , K
        <sup><em>k</em></sup> } is the <em>k</em>-th estimate of
        parameters in the EM procedure, and <em>R<sub>un</sub></em>
        is the normalization factor in order to satisfy
        <span class="inline-equation"><span class=
        "tex">$p^{k}_{0,un} + \sum _{z \in Z} p^{k}_{z,un} + \sum
        _{m=1}^{n-1} q^{k}_{um,un} + \sum _{l=1}^{n-1}
        r^{k}_{ul,un} = 1$</span></span> .
        <p></p>
        <p><strong>M-step.</strong>We use Jensen's inequality to
        provide a lower bound for the log-likelihood
        (Equation&nbsp;<a class="eqn" href="#eq7">7</a>); this
        lower bound is often called the <em>Q</em> function. We
        obtain the next estimate of the parameters by taking the
        derivative of the <em>Q</em> function with respect to each
        parameter and setting them to zero:</p>
        <div class="table-responsive" id="eq12">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \alpha
            _{ua}^{k+1} = \frac{\sum
            _{n=1}^{N_{u}}I(a_{un}=a)p_{0,un}^{k}}{T} \;\;,
            \end{align}</span><br />
            <span class="equation-number">(12)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq13">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \beta _{az}^{k+1}
            = \frac{2 \mathcal {T}}{|U| T} \times \frac{\sum _{u
            \in U} \sum _{n=1}^{N_{u}} I(a_{un}=a) p_{z,un}^{k}}{
            \mathit {erf}(\frac{\mu _{az}^{k}}{\sqrt {2}\sigma
            _{az}^{k}}) + \mathit {erf}(\frac{\mathcal {T} - \mu
            _{az}^{k}}{\sqrt {2}\sigma _{az}^{k}}) } \;\;,
            \end{align}</span><br />
            <span class="equation-number">(13)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq14">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \theta
            _{a^{\prime }a}^{k+1} = \frac{\sum _{u \in U} \sum
            _{n=1}^{N_{u}} \sum _{m=1}^{n-1} I(a_{um}=a^{\prime
            },a_{un}=a) q^{k}_{um,un}}{\sum _{u \in U} \sum
            _{n=1}^{N_{u}} I(a_{un}=a^{\prime }) \Bigl (1 - \exp
            \bigl (- \omega _{a^{\prime }a}^{k} (T-t_{un}) \bigr)
            \Bigr)} \;\;, \end{align}</span><br />
            <span class="equation-number">(14)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq15">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \phi _{ca}^{k+1}
            = \frac{\sum _{u \in U} \sum _{n=1}^{N_{u}} \sum
            _{l=1}^{n-1} I(a_{ul}=a,a_{un}=a,c_{ul}=c)
            r^{k}_{ul,un}}{\sum _{u \in U} \sum _{n=1}^{N_{u}}
            I(a_{un}=a,c_{un}=c) \Bigl (1 - \exp \bigl (-\gamma
            _{ca}^{k}(T-t_{un})^{\kappa _{ca}^{k}} \bigr) \Bigr)}
            \;\;, \end{align}</span><br />
            <span class="equation-number">(15)</span>
          </div>
        </div>where <span class="inline-equation"><span class=
        "tex">$\mathcal {T}$</span></span> is the time period of a
        day (<em>i.e.</em>, 24 hours), <span class=
        "inline-equation"><span class="tex">$\frac{T}{\mathcal
        {T}}$</span></span> is the number of days representation of
        the observed period <em>T</em>, and where <em>erf</em>
        denotes the Gauss error function <span class=
        "inline-equation"><span class="tex">$\mathit {erf}(x) =
        \frac{1}{\sqrt \pi }\int _{-x}^x e^{-t^2}
        \,\mathrm{d}t$</span></span> . Because of the exponentials
        (expâ and <em>erf</em>) within the expectation function
        (Equation&nbsp;<a class="eqn" href="#eq7">7</a>),
        <span class="inline-equation"><span class="tex">$\omega
        _{a^{\prime }a}^{k+1}$</span></span> , <span class=
        "inline-equation"><span class="tex">$\gamma
        _{ca}^{k+1}$</span></span> , <span class=
        "inline-equation"><span class="tex">$\kappa
        _{ca}^{k+1}$</span></span> , <span class=
        "inline-equation"><span class="tex">$\mu
        ^{k+1}_{az}$</span></span> , and <span class=
        "inline-equation"><span class="tex">$\sigma
        ^{k+1}_{az}$</span></span> cannot be solved in closed form.
        However, by further considering a lower bound for these
        exponentials <span class="inline-equation"><span class=
        "tex">$\omega _{a^{\prime }a}^{k+1}$</span></span> and
        <span class="inline-equation"><span class="tex">$\gamma
        _{ca}^{k+1}$</span></span> can be solved in closed form.
        Their update rules are as follows:
        <div class="table-responsive" id="eq16">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} { \omega
            _{a^{\prime }a}^{k+1} = \Biggl \lbrace \sum _{u \in U}
            \sum _{n=1}^{N_{u}} \sum _{m=1}^{n-1}
            I(a_{um}=a^{\prime },a_{un}=a) q^{k}_{um,un} \Biggr
            \rbrace } \nonumber \\ {} / \Biggl \lbrace \sum _{u \in
            U} \sum _{n=1}^{N_{u}} \sum _{m=1}^{n-1}
            I(a_{um}=a^{\prime },a_{un}=a) q^{k}_{um,un} \Delta
            _{t_{um}t_{un}} \nonumber \\ {} \quad\quad\quad + \sum
            _{u \in U} \sum _{n=1}^{N_{u}} I(a_{un}=a^{\prime })
            \theta _{a^{\prime }a}^{k} (T-t_{un})\exp \bigl
            (-\omega _{a^{\prime }a}^{k}(T-t_{un})\bigr) \Biggr
            \rbrace \;\;, \end{align}</span><br />
            <span class="equation-number">(16)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq17">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} { \gamma
            _{ca}^{k+1} = \Biggl \lbrace \sum _{u \in U} \sum
            _{n=1}^{N_{u}} \sum _{l=1}^{n-1}
            I(a_{ul}=a,a_{un}=a,c_{ul}=c) r^{k}_{ul,un} \Biggr
            \rbrace } \nonumber \\ {} / \Biggl \lbrace \sum _{u \in
            U} \sum _{n=1}^{N_{u}} \sum _{l=1}^{n-1}
            I(a_{ul}=a,a_{un}=a,c_{ul}=c) r^{k}_{ul,un} \Delta
            _{t_{ul}t_{un}}^{\kappa ^{k}_{ca}} \nonumber \\ {} +
            \sum _{u \in U} \sum _{n=1}^{N_{u}} I(a_{un}=a,
            c_{un}=c) \phi ^{k}_{ca} (T - t_{un})^{\kappa
            ^{k}_{ca}} \exp \bigl (- \gamma _{ca}^{k}
            (T-t_{un})^{\kappa ^{k}_{ca}}\bigr) \Biggr \rbrace \;.
            \end{align}</span><br />
            <span class="equation-number">(17)</span>
          </div>
        </div>The other three parameters, <span class=
        "inline-equation"><span class="tex">$\kappa
        _{ca}^{k+1}$</span></span> , <span class=
        "inline-equation"><span class="tex">$\mu
        ^{k+1}_{az}$</span></span> and <span class=
        "inline-equation"><span class="tex">$\sigma
        ^{k+1}_{az}$</span></span> , are estimated by maximizing
        the <em>Q</em> function through the use of a gradient-based
        numerical optimization method; we used the Newton method.
        For more details on model inference see the Online
        Appendix&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0036">36</a>].
        <p></p>
      </section>
    </section>
    <section id="sec-14">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span>
          Experiments</h2>
        </div>
      </header>
      <p>This section evaluates the predictive performance of our
      proposed model on two real-world datasets on predicting the
      next user action and when it will occur. We compare against
      eleven different baselines on each dataset. However, since
      many baseline models are unable to make joint predictions of
      action and timing, we evaluate these two tasks separately.
      Importantly, this process allows us to identify the
      individual sources of error that would impact joint
      predictions. Our implementation is available at <a class=
      "link-inline force-break" href=
      "http://snap.stanford.edu/tipas">snap.stanford.edu/tipas</a>.</p>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.1</span>
            Datasets</h3>
          </div>
        </header>
        <p>Our experiments use two real-world activity logging
        datasets. In total, these datasets comprise 12 millions
        real-world actions taken by 20 thousand users over 17
        months.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Basic dataset statistics.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;">Dataset
                Statistics</th>
                <th style="text-align:right;">Argus</th>
                <th style="text-align:right;">Under Armour</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Observation
                period</td>
                <td style="text-align:right;">7 months</td>
                <td style="text-align:right;">10 months</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:right;">Jan-July â15</td>
                <td style="text-align:right;">Jan-Oct â16</td>
              </tr>
              <tr>
                <td style="text-align:left;"># unique actions</td>
                <td style="text-align:right;">10</td>
                <td style="text-align:right;">8</td>
              </tr>
              <tr>
                <td style="text-align:left;"># total users</td>
                <td style="text-align:right;">4,708</td>
                <td style="text-align:right;">15,221</td>
              </tr>
              <tr>
                <td style="text-align:left;"># total actions</td>
                <td style="text-align:right;">2,140,757</td>
                <td style="text-align:right;">9,733,645</td>
              </tr>
              <tr>
                <td style="text-align:left;">Avg. # actions per
                user</td>
                <td style="text-align:right;">454.7</td>
                <td style="text-align:right;">639.5</td>
              </tr>
              <tr>
                <td style="text-align:left;">Avg. # unique actions
                per user</td>
                <td style="text-align:right;">6.3</td>
                <td style="text-align:right;">6.8</td>
              </tr>
              <tr>
                <td style="text-align:left;">Avg. # unique actions
                per user day</td>
                <td style="text-align:right;">2.7</td>
                <td style="text-align:right;">4.4</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p><strong>Argus dataset.</strong>We use the activity
        logging data from the Argus mobile app described in
        Section&nbsp;<a class="sec" href="#sec-8">4.1</a>. Users in
        this dataset can log 10 different actions (drink, sleep,
        heart rate, running, weight, food, walking, biking,
        workout, and stretching) and our goal is to predict which
        of these 10 actions a user will take next (and when). Our
        analyses include users who logged at least two unique
        actions per day on average (other users might only use the
        app to for example track their sleep making predictions of
        actions and their timing almost trivial; we find that our
        results are robust to different choices of this threshold).
        We consider 7 months of data from the app in a rolling
        window evaluation, where we use one month for training and
        the next for testing (<em>i.e.</em>, making out-of-sample
        predictions; without retraining). As shown in
        Table&nbsp;<a class="tbl" href="#tab1">1</a>, the dataset
        includes 2.1 million actions by over 4 thousand users
        within the 7 month observation period.</p>
        <p><strong>Under Armour dataset (UA).</strong>We also use
        activity logging data from Under Armour mobile apps
        (<em>i.e.</em>, MapMyFitness and MyFitnessPal; focusing on
        users that are active in both apps). Users in this dataset
        can log 8 different types of actions (running, walking,
        biking, workout, breakfast, lunch, dinner, and snacks). Our
        analyses include users who logged at least four unique
        actions per day on average, leading to a similar number of
        unique actions per user on average compared to the Argus
        dataset (again, our results are robust to different choices
        of this threshold). We consider 10 months of data from the
        app and again perform a rolling window evaluation where we
        train on one month and test on the next. In total, this
        dataset comprises 15 thousand users taking 9.8 million
        actions (Table&nbsp;<a class="tbl" href="#tab1">1</a>).</p>
      </section>
      <section id="sec-16">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.2</span> Model
            Learning</h3>
          </div>
        </header>
        <p>Note that our model has few core model parameters. In
        the context of the datasets described above, we have about
        500 core model parameters (Î², Î¼, Ï, Î, Î©, Î¦, Î, K) and
        about 25 thousand personalization parameters (Î±). This
        small, non-redundant set of parameters allows us to train
        the model efficiently and robustly, and explain model
        predictions through inspection and visualization of model
        parameters (Section&nbsp;<a class="sec" href=
        "#sec-20">6.6</a>), while performing competitively
        (Section&nbsp;<a class="sec" href="#sec-18">6.4</a>).
        However, during training time (but not test time) we also
        have latent variables (p, q, r) that allow us to learn the
        core model parameters. These latent variables represent
        which actions trigger which other actions, leading to
        <span class="inline-equation"><span class="tex">$\mathcal
        {O}(|U| (max_{u \in U} N_u)^2)$</span></span> variables in
        the worst case. On both datasets, inference of both core
        model and latent parameters involves solving an
        optimization problem with over 200 million total variables
        (Section&nbsp;<a class="sec" href="#sec-13">5.3</a>; we
        randomly initialize all parameters). Using our EM-based
        inference procedure we can robustly infer these parameters
        in less than ten hours using a single-threaded C++
        implementation on a single machine. We find that one month
        of training data is enough to reliably train our model.</p>
      </section>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.3</span> Validating
            Parametric Assumptions</h3>
          </div>
        </header>
        <figure id="fig5">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186161/images/www2018-170-fig5.jpg"
          class="img-responsive" alt="Figure 5" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span>
            <span class="figure-title">Validation of parametric
            modeling assumptions (Section&nbsp;<a class="sec" href=
            "#sec-12">5.2</a>). (a) Mixture of Gaussian closely
            fits observed time-varying action propensity (here, for
            bike action). (b) Exponential and Weibull distributions
            collectively well-approximate short-term dependencies
            and long-term periodic effects of previous bike
            actions.</span>
          </div>
        </figure>
        <p>In Section&nbsp;<a class="sec" href="#sec-12">5.2</a> we
        developed a model consisting of three parts: time variation
        modeled using a mixture of Gaussians (Time
        <sub><em>u</em></sub> (<em>t</em>, <em>a</em>)), short-term
        dependencies between actions modeled by a Hawkes process
        with Exponential decay function (ShortTerm
        <sub><em>u</em></sub> (<em>t</em>, <em>a</em>)), and
        long-term periodicity modeled through Weibull distributions
        (LongTerm <sub><em>u</em></sub> (<em>t</em>, <em>a</em>)).
        Here, we test empirically whether these parametric
        assumptions hold true in real data. Using the Argus
        dataset, we inferred appropriate parameters for these
        distributions.</p>
        <p>We demonstrate qualitatively in Figure&nbsp;<a class=
        "fig" href="#fig5">5</a> that the chosen distributions fit
        real-world dynamics well. Figure&nbsp;<a class="fig" href=
        "#fig5">5</a> (a) shows the time-varying propensity with
        superimposed mixture of Gaussian fit and (b) shows that,
        collectively, Exponential and Weibull distribution closely
        approximate the influence of previous actions (example data
        is for bike action as seen in Figure&nbsp;<a class="fig"
        href="#fig1">1</a>).</p>
        <p>We have further quantitatively evaluated our parametric
        assumptions and compared our choices to alternative
        distributions (<em>e.g.</em>, Rayleigh and Power-law)
        through goodness-of-fit tests which have shown that the
        suggested distributions best fit real-world data.</p>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.4</span> Predicting
            the Next Action</h3>
          </div>
        </header>
        <p>First, we evaluate our proposed model in terms of its
        accuracy in predicting actions at a given time. The task is
        to predict the <em>n</em> + 1-st action <em>a</em>
        <sub><em>un</em> + 1</sub> of user <em>u</em>, given time
        <em>t</em> <sub><em>un</em> + 1</sub> and past user history
        H <sub><em>u</em></sub> = {(<em>a</em>
        <sub><em>u</em>1</sub>, <em>t</em> <sub><em>u</em>1</sub>),
        âââ, (<em>a<sub>un</sub></em> , <em>t<sub>un</sub></em> )}.
        For each two month period in both datasets, we use the
        first month for training and the second month for testing
        and perform a rolling window evaluation, where we predict
        each test set event given all events that happened before
        it (without retraining). We use accuracy, the percentage of
        correct predictions, over all test events as our evaluation
        measure (the most common measure to evaluate recommender
        systems&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0029">29</a>]). We also report macro-averaged
        recall&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0039">39</a>] corresponding to averaging
        prediction accuracy equally weighted across all action
        types. This measure highlights differences in predictive
        performance on rare actions that do not affect the standard
        accuracy measure very much. We find very similar results
        using other classification metrics (<em>e.g.</em>, ROC AUC,
        F1). The number of mixtures for the time-varying action
        propensity (Equation&nbsp;<a class="eqn" href="#eq3">3</a>)
        is set via cross-validation. We compare our proposed model
        against the following seven baseline models, which have
        proven competitive across a wide variety of prediction
        tasks and recommender systems:</p>
        <ul class="list-no-style">
          <li id="list1" label="â¢">
            <strong>Copy Model:</strong> Simply repeats the user's
            last action. Several repeat consumption models are
            variants of this copy model
            (<em>e.g.</em>,&nbsp;[<a class="bib" data-trigger=
            "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0008">8</a>, <a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href=
            "#BibPLXBIB0011">11</a>]).<br />
          </li>
          <li id="list2" label="â¢">
            <strong>Markov Model:</strong> Predicts the next action
            based on the most recent actions of the user. We report
            first to fifth-order Markov models (sixth-order models
            did not significantly improve performance). Markov
            models have been used widely to predict next actions
            (<em>e.g.</em>,&nbsp;[<a class="bib" data-trigger=
            "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0009">9</a>, <a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href=
            "#BibPLXBIB0032">32</a>]).<br />
          </li>
          <li id="list3" label="â¢">
            <strong>Hidden Markov Model (HMM):</strong> This is a
            Markov model with hidden (unobserved) states. It
            predicts the next action based on the current, inferred
            state of the action sequence [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href=
            "#BibPLXBIB0037">37</a>].<br />
          </li>
          <li id="list4" label="â¢">
            <strong>Factorizing Personalized Markov Chains
            (FPMC):</strong> This is based on underlying Markov
            chains where the transitions matrices are
            user-specific. Matrix factorization models are used to
            address sparsity issues of these user-specific Markov
            chains&nbsp;[<a class="bib" data-trigger="hover"
            data-toggle="popover" data-placement="top" href=
            "#BibPLXBIB0044">44</a>].<br />
          </li>
          <li id="list5" label="â¢"><strong>Recurrent Neural Network
          (RNN):</strong> Feedforward neural network structure
          using outputs from the hidden units at the prior time
          step as the inputs as the current time step. Assumes
          discrete time steps and no ready-to-use generalizations
          to continuous time domain exist.<br /></li>
          <li id="list6" label="â¢"><strong>PP-Global:</strong> A
          global Poisson process model. The intensity function is
          constant over time and defined by <em>Î»<sub>u</sub></em>
          (<em>t</em>, <em>a</em>) = <em>Î±<sub>a</sub></em>
          .<br /></li>
          <li id="list7" label="â¢"><strong>PP-User:</strong> A
          user-specific Poisson process model. The intensity
          function is constant over time and defined by
          <em>Î»<sub>u</sub></em> (<em>t</em>, <em>a</em>) =
          <em>Î±<sub>ua</sub></em> .<br /></li>
        </ul>
        <p>Note that Hawkes process models
        (<em>e.g.</em>,&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0020">20</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0022">22</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0028">28</a>]) are closely related to the
        ShortTerm <sub><em>u</em></sub> (<em>t</em>, <em>a</em>)
        component of our model (Equation&nbsp;<a class="eqn" href=
        "#eq4">4</a>). Our proposed model <strong>TIPAS</strong>
        uses the intensity function of Eq.&nbsp;<a class="eqn"
        href="#eq2">2</a>. We predict the most likely user action
        as <span class="inline-equation"><span class="tex">$\hat{a}
        = {\rm argmax}_a \lambda _{u}(t_{u n+1},a)$</span></span> .
        We also compare the individual model components in an
        ablation study below.</p>
        <figure id="fig6">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186161/images/www2018-170-fig6.jpg"
          class="img-responsive" alt="Figure 6" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 6:</span>
            <span class="figure-title">Accuracy when predicting
            actions. Higher is better. Comparing proposed TIPAS
            model (red) to baselines (gray). Error bars in all
            plots correspond to standard errors.</span>
          </div>
        </figure><strong>Results: Comparison to baseline
        models.</strong>Figure&nbsp;<a class="fig" href=
        "#fig6">6</a> compares accuracy of next action prediction.
        We observe that the eleven baselines achieve accuracies of
        36-57% on the Argus dataset and 20-46% on the Under Armour
        dataset with the RNN baseline performing best in both
        datasets. The limited predictive performance of these
        competitive baselines shows that this prediction task is
        non-trivial. TIPAS outperforms all baselines on both Argus
        (60.9%; 6-69% rel. improvement) and Under Armour datasets
        (50.9%; 11-156% rel. improvement). The small standard error
        across multiple dataset splits in the rolling window
        evaluation (Figure&nbsp;<a class="fig" href="#fig6">6</a>)
        demonstrates that our training procedure is robust and
        consistently shows good performance. We note that TIPAS
        performs particularly well on rare actions leading to
        9-256% relative improvement in macro-averaged recall over
        baseline models (Online Appendix&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0036">36</a>]).
        <p></p>
        <p><strong>Results: Comparison of individual model
        components.</strong>Note that TIPAS has three components
        (Equation&nbsp;<a class="eqn" href="#eq2">2</a>):
        time-varying action propensities (Time), short-term
        interdependencies between actions (Short), and long-term
        periodic effects (Long). Here, we evaluate the performance
        of each of these components in an ablation study by
        comparing Time, Time+Short, and the full TIPAS model
        combining Time+Short+Long (Figure&nbsp;<a class="fig" href=
        "#fig7">7</a>; all models include user personalized
        preferences <em>Î±<sub>ua</sub></em> ). We find that
        modeling time-varying action propensities achieves an
        accuracy of 53% and 40% on the two datasets, respectively.
        Further, modeling short-term dependencies between actions
        improves this to 59% and 49%, and capturing long-term
        periodicities of actions further improves this to 61% and
        51%, respectively. This demonstrates that capturing all
        three properties is essential to predicting actions in both
        datasets of human real-world action sequences. Further, we
        observe a bigger difference between the full
        Time+Short+Long model and the Time+Short model in terms of
        macro-averaged recall (7% and 5% relative MAR improvements
        compared to 3% and 4% in terms of accuracy on the Argus and
        Under Armour datasets, respectively). This indicates that
        modeling long-term periodicities is especially important
        for more rare actions such as walking and biking. In
        addition, we find that modeling long-term periodic effects
        discretized by time of day (0-6h, 6-12h, 12-18h, 18-24h)
        performs significantly better than not discretizing by time
        of day on both datasets. For example, actions such as
        biking and walking are periodic but vary based on time of
        day (Figure&nbsp;<a class="fig" href="#fig3">3</a>). Our
        full model captures these time-of-day dependent long-term
        effects and relatively improves macro-averaged recall of
        predicting biking and walking actions by 491-556% over Time
        model and 2-4% over Time+Short model.</p>
        <figure id="fig7">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186161/images/www2018-170-fig7.jpg"
          class="img-responsive" alt="Figure 7" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 7:</span>
            <span class="figure-title">Ablation study comparing
            different model components on accuracy when predicting
            actions. Higher is better.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-19">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.5</span> Predicting
            the Time of the Next Action</h3>
          </div>
        </header>
        <p>We now focus on the second aspect of modeling real-world
        actions: Predicting the time of the next action.
        Specifically, the task is the predict the <em>n</em> + 1-th
        timestamp <em>t</em> <sub><em>un</em> + 1</sub> in history
        <em>u</em>, given past events <em>H<sub>u</sub></em> =
        {(<em>a</em> <sub><em>u</em>1</sub>, <em>t</em>
        <sub><em>u</em>1</sub>), ..., (<em>a<sub>un</sub></em> ,
        <em>t<sub>un</sub></em> )} (we do not assume that the next
        action <em>a</em> <sub><em>un</em> + 1</sub> is given).
        Mean absolute error (MAE) is used as the evaluation metric.
        We use the same train/test paradigm as before (rolling
        window evaluation training one month and testing on the
        next). We restrict predictions to only events that will
        occur within the next 12 hours (<em>i.e.</em>, the time
        interval <em>t</em> <sub><em>un</em> + 1</sub> â
        <em>t<sub>un</sub></em> â¤ 12 hours) because these are the
        most important and actionable inferences (<em>e.g.</em>,
        predicting a sleep time many days from now may have large
        error, but it is also less relevant). In order to make time
        predictions based on TIPAS, we simulate the multivariate
        temporal point process using Ogata's modified thinning
        algorithm&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0043">43</a>]. We simulate 100 samples and
        return the average time.</p>
        <p>We compare our model to the following five baseline
        methods:</p>
        <ul class="list-no-style">
          <li id="list8" label="â¢"><strong>Time Copy
          Model:</strong> Predicts the next time, <em>t</em>
          <sub><em>un</em> + 1</sub>, based on the most recent
          time-interval of user <em>u</em> (<em>t</em>
          <sub><em>un</em> + 1</sub> = <em>t<sub>un</sub></em> +
          (<em>t<sub>un</sub></em> â <em>t</em> <sub><em>un</em> â
          1</sub>)).<br /></li>
          <li id="list9" label="â¢"><strong>Average Time
          Interval:</strong> Predicts the next time <em>t</em>
          <sub><em>un</em> + 1</sub> using the global average of
          time-intervals.<br /></li>
          <li id="list10" label="â¢"><strong>User Average Time
          Interval:</strong> Predicts the next time <em>t</em>
          <sub><em>un</em> + 1</sub> using the average of
          time-intervals for user <em>u</em>.<br /></li>
          <li id="list11" label="â¢"><strong>PP-Global:</strong> A
          global Poisson process model. The intensity function is
          constant over time and defined by <em>Î»<sub>u</sub></em>
          (<em>t</em>, <em>a</em>) = <em>Î±<sub>a</sub></em>
          .<br /></li>
          <li id="list12" label="â¢"><strong>PP-User:</strong> A
          user-specific Poisson process model. The intensity
          function is constant over time: <em>Î»<sub>u</sub></em>
          (<em>t</em>, <em>a</em>) = <em>Î±<sub>ua</sub></em>
          .<br /></li>
        </ul>
        <p>We note that the other baselines (Markov models, HMM,
        FPMC, and RNN) used in Section&nbsp;<a class="sec" href=
        "#sec-18">6.4</a> are unable to make any time
        predictions.</p>
        <figure id="fig8">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186161/images/www2018-170-fig8.jpg"
          class="img-responsive" alt="Figure 8" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 8:</span>
            <span class="figure-title">Mean absolute error (MAE)
            when predicting time of next actions. Lower is better.
            Comparison to baselines.</span>
          </div>
        </figure><strong>Results.</strong>Experimental results are
        shown in Figure&nbsp;<a class="fig" href="#fig8">8</a>. We
        observe that all baselines perform similarly except the
        Time Copy model which performs significantly worse on both
        datasets. TIPAS significantly outperforms all baselines
        across both datasets by 22-35% in the Argus dataset and
        11-37% in the Under Armour dataset (relative improvement).
        Restricting predictions to events within the next 6 hours
        (instead of 12h as before), TIPAS outperforms the baselines
        even more significantly, improving upon them by 44-58% and
        37-41% on the two datasets. TIPAS is able to make better
        timing predictions because it is able to leverage three key
        components. First, it is aware that certain actions only
        happen during certain parts of the day. For example, it
        will predict longer delays in the middle of the night when
        actions are unlikely to occur. Second, the model can
        exploit dependencies between actions. For instance, it
        might predict a very short time after a run because many
        users will drink water or check their heart rate soon
        after. Third, TIPAS is able to exploit periodicities in the
        data. For example, it might predict an evening time commute
        because it observed a commute in the morning. In summary,
        modeling these three key aspects of human behavior allows
        us to make better predictions of actions and their timing.
        <figure id="fig9">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186161/images/www2018-170-fig9.jpg"
          class="img-responsive" alt="Figure 9" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 9:</span>
            <span class="figure-title">Visualization of inferred
            TIPAS model parameters for (a) periodicity of food
            actions and (b) interdependent actions following food
            actions. The learned dependencies allow to explain why
            specific actions are being predicted.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-20">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.6</span> Model
            Explainability</h3>
          </div>
        </header>
        <p>TIPAS also allows for visualization of model parameters,
        which enables explanations of why certain predictions are
        made. This is especially important in the mobile health
        context, where model predictions may impact usersâ
        real-world health behaviors and therefore need to be
        explained and monitored.</p>
        <p>The inferred model parameters for
        Equation&nbsp;<a class="eqn" href="#eq5">5</a> are shown in
        Figure&nbsp;<a class="fig" href="#fig9">9</a> a
        (specifically, <span class="inline-equation"><span class=
        "tex">$f(\Delta _{t^{\prime }t})=\gamma _{c_{t^{\prime }}a}
        \kappa _{c_{t^{\prime }}a} \Delta _{t^{\prime }t}^{\kappa
        _{c_{t^{\prime }}a}-1} \! \exp (- \gamma _{c_{t^{\prime
        }}a} \Delta _{t^{\prime }t}^{\kappa _{c_{t^{\prime
        }}a}})$</span></span> for <em>a</em> = food). These
        distributions correspond to when food events likely trigger
        other food events. The distributions show that meals are
        extremely periodic and that meals sharply determine the
        timing of the next meal, except for dinners after 18:00h,
        which do not precisely determine the timing of the next
        meal (18-24h, green). The periodicities vary between 5h
        after breakfast (6-12h) and 6h after lunch (12-18h). This
        is consistent with a typical schedule of meals at 7:00h,
        12:00h, and 18:00h. Importantly, this enables us to
        correctly predict that earlier lunches may lead to earlier
        dinners. Such predictions are critical for correctly timed
        interventions, for instance making sure that diet reminders
        do not come to late.</p>
        <p>Furthermore, TIPAS allows us to explain why an activity
        was predicted, based on the relative contributions of model
        components to the overall intensity function
        (Section&nbsp;<a class="sec" href="#sec-12">5.2</a>). For
        example, after food actions users are likely to log other
        foods and drinks (Figure&nbsp;<a class="fig" href=
        "#fig9">9</a> b; showing <span class=
        "inline-equation"><span class="tex">$f(\Delta _{t^{\prime
        }t})=\omega _{a^{\prime }a}\exp (-\omega _{a^{\prime
        }a}\Delta _{t^{\prime }t})$</span></span> for <em>a</em>â² =
        food). This makes sense as typical meals include both food
        and drinks, and users may choose to log parts of each meal
        separately. Interestingly, users also often log their
        weight right after food, indicating that they might be
        conscious of how their meal might have impacted their
        weight. Lastly, we observe walking actions right after
        meals. Users may walk back from a restaurant, or they might
        attempt to walk off some of their meal's calories.</p>
        <p>While these results and examples are specific to mobile
        activity logging applications, the utility of our model may
        generalize other domains where behaviors are time-varying,
        interdependent, or periodic. Distributional choices for the
        individual may vary across domains but can easily be
        adapted in our model.</p>
      </section>
    </section>
    <section id="sec-21">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span> Conclusion</h2>
        </div>
      </header>
      <p>Accurately predicting the user's future actions is
      essential for personalization, user modeling, and timely
      interventions in mobile health applications. In this paper we
      demonstrated that real-world user behavior exhibits several
      complexities including a large number of potential actions,
      time-varying action propensities, dependencies between
      actions, and periodic behaviors. We proposed a novel
      statistical model based on multivariate temporal point
      processes that jointly models all these complexities of human
      behaviors. Empirically, we demonstrate that our model
      successfully captures these dynamics in two real-world
      datasets and that it significantly outperforms nine baselines
      on tasks of predicting the next user action and when this
      action will occur. Our model can serve as a foundation to
      predict more fine-gained attributes of real-world actions
      such as their duration, intensity, or exact location. Our
      results further have implications for modeling human
      behavior, app personalization, and targeting of health
      interventions.</p>
    </section>
    <section id="sec-22">
      <header>
        <div class="title-info">
          <h2>Acknowledgments</h2>
        </div>
      </header>
      <p>This research has been supported in part by NIH BD2K,
      DARPA NGS2, ARO MURI, IARPA HFC, Stanford Data Science
      Initiative, and Chan Zuckerberg Biohub.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">O.&nbsp;Aalen,
        O.&nbsp;Borgan, and H.&nbsp;Gjessing. <em>Survival and
        event history analysis: A process point of view</em>.
        2008.</li>
        <li id="BibPLXBIB0002" label="[2]">E.&nbsp;Adar,
        J.&nbsp;Teevan, and S.&nbsp;T. Dumais. Large scale analysis
        of web revisitation patterns. In <em>SIGCHI</em>,
        2008.</li>
        <li id="BibPLXBIB0003" label="[3]">E.&nbsp;Agichtein,
        E.&nbsp;Brill, and S.&nbsp;Dumais. Improving web search
        ranking by incorporating user behavior information. In
        <em>SIGIR</em>, 2006.</li>
        <li id="BibPLXBIB0004" label="[4]">T.&nbsp;Althoff.
        Population-scale pervasive health. <em>IEEE Pervasive
        Computing</em>, 16(4):75â79, 2017.</li>
        <li id="BibPLXBIB0005" label="[5]">T.&nbsp;Althoff,
        E.&nbsp;Horvitz, R.&nbsp;W. White, and J.&nbsp;Zeitzer.
        Harnessing the web for population-scale physiological
        sensing: A case study of sleep and performance. In
        <em>WWW</em>, 2017.</li>
        <li id="BibPLXBIB0006" label="[6]">T.&nbsp;Althoff,
        P.&nbsp;Jindal, and J.&nbsp;Leskovec. Online actions with
        offline impact: How online social networks influence online
        and offline user behavior. In <em>WSDM</em>, 2017.</li>
        <li id="BibPLXBIB0007" label="[7]">T.&nbsp;Althoff,
        R.&nbsp;Sosic, J.&nbsp;L. Hicks, A.&nbsp;C. King,
        S.&nbsp;L. Delp, and J.&nbsp;Leskovec. Large-scale physical
        activity data reveal worldwide activity inequality.
        <em>Nature</em>, 2017.</li>
        <li id="BibPLXBIB0008" label="[8]">A.&nbsp;Anderson,
        R.&nbsp;Kumar, A.&nbsp;Tomkins, and S.&nbsp;Vassilvitskii.
        The dynamics of repeat consumption. In <em>WWW</em>,
        2014.</li>
        <li id="BibPLXBIB0009" label="[9]">D.&nbsp;Ashbrook and
        T.&nbsp;Starner. Using GPS to learn significant locations
        and predict movement across multiple users. <em>Personal
        and Ubiquitous computing</em>, 2003.</li>
        <li id="BibPLXBIB0010" label="[10]">R.&nbsp;Baeza-Yates,
        D.&nbsp;Jiang, F.&nbsp;Silvestri, and B.&nbsp;Harrison.
        Predicting the next app that you are going to use. In
        <em>WSDM</em>, 2015.</li>
        <li id="BibPLXBIB0011" label="[11]">A.&nbsp;R. Benson,
        R.&nbsp;Kumar, and A.&nbsp;Tomkins. Modeling user
        consumption sequences. In <em>WWW</em>, 2016.</li>
        <li id="BibPLXBIB0012" label="[12]">S.&nbsp;Berkovsky,
        T.&nbsp;Kuflik, and F.&nbsp;Ricci. Mediation of user models
        for enhanced personalization in recommender systems.
        <em>User Modeling and User-Adapted Interaction</em>,
        2008.</li>
        <li id="BibPLXBIB0013" label="[13]">F.&nbsp;Bohnert,
        I.&nbsp;Zukerman, S.&nbsp;Berkovsky, T.&nbsp;Baldwin, and
        L.&nbsp;Sonenberg. Using interest and transition models to
        predict visitor locations in museums. <em>AI
        Communications</em>, 2008.</li>
        <li id="BibPLXBIB0014" label="[14]">J.&nbsp;Cheng,
        M.&nbsp;Bernstein, C.&nbsp;Danescu-Niculescu-Mizil, and
        J.&nbsp;Leskovec. Anyone can become a troll: Causes of
        trolling behavior in online discussions. In <em>CSCW</em>,
        2017.</li>
        <li id="BibPLXBIB0015" label="[15]">D.&nbsp;R. Cox and
        V.&nbsp;Isham. <em>Point processes</em>. 1980.</li>
        <li id="BibPLXBIB0016" label="[16]">A.&nbsp;Das&nbsp;Sarma,
        S.&nbsp;Gollapudi, R.&nbsp;Panigrahy, and
        L.&nbsp;Zhajtabar, Yang. Understanding cyclic trends in
        social choices. In <em>WSDM</em>, 2012.</li>
        <li id="BibPLXBIB0017" label="[17]">B.&nbsp;D. Davison and
        H.&nbsp;Hirsh. Predicting sequences of user actions. In
        <em>AAAI/ICML WS on Predicting the Future</em>, 1998.</li>
        <li id="BibPLXBIB0018" label="[18]">A.&nbsp;Drutsa,
        G.&nbsp;Gusev, and P.&nbsp;Serdyukov. Periodicity in user
        engagement with a search engine and its application to
        online controlled experiments. <em>ACM TWEB</em>,
        2017.</li>
        <li id="BibPLXBIB0019" label="[19]">N.&nbsp;Du,
        H.&nbsp;Dai, R.&nbsp;Trivedi, U.&nbsp;Upadhyay,
        M.&nbsp;Gomez-Rodriguez, and L.&nbsp;Song. Recurrent marked
        temporal point processes: Embedding event history to
        vector. In <em>KDD</em>, 2016.</li>
        <li id="BibPLXBIB0020" label="[20]">N.&nbsp;Du,
        M.&nbsp;Farajtabar, A.&nbsp;Ahmed, A.&nbsp;J. Smola, and
        L.&nbsp;Song. Dirichlet-hawkes processes with applications
        to clustering continuous-time document streams. In
        <em>KDD</em>, 2015.</li>
        <li id="BibPLXBIB0021" label="[21]">N.&nbsp;Du,
        Y.&nbsp;Wang, N.&nbsp;He, J.&nbsp;Sun, and L.&nbsp;Song.
        Time-sensitive recommendation from recurrent user
        activities. In <em>NIPS</em>, 2015.</li>
        <li id="BibPLXBIB0022" label="[22]">M.&nbsp;Farajtabar,
        Y.&nbsp;Wang, M.&nbsp;G. Rodriguez, S.&nbsp;Li,
        H.&nbsp;Zha, and L.&nbsp;Song. Coevolve: A joint point
        process model for information diffusion and network
        co-evolution. In <em>NIPS</em>, 2015.</li>
        <li id="BibPLXBIB0023" label="[23]">G.&nbsp;Fischer. User
        modeling in humanâcomputer interaction. <em>UMUAI</em>,
        2001.</li>
        <li id="BibPLXBIB0024" label="[24]">S.&nbsp;Fox and
        M.&nbsp;Duggan. <em>Tracking for health</em>. Pew Research
        Center's Internet &amp; American Life Project, 2013.</li>
        <li id="BibPLXBIB0025" label="[25]">J.&nbsp;Freyne and
        S.&nbsp;Berkovsky. Intelligent food planning: personalized
        recipe recommendation. In <em>IUI</em>, 2010.</li>
        <li id="BibPLXBIB0026" label="[26]">J.&nbsp;Freyne,
        J.&nbsp;Yin, E.&nbsp;Brindal, G.&nbsp;A. Hendrie,
        S.&nbsp;Berkovsky, and M.&nbsp;Noakes. Push notifications
        in diet apps: Influencing engagement times and tasks.
        <em>Int J of HumanâComputer Interaction</em>, 2017.</li>
        <li id="BibPLXBIB0027" label="[27]">P.&nbsp;Gorniak and
        D.&nbsp;Poole. Predicting future user actions by observing
        unmodified applications. In <em>AAAI</em>, 2000.</li>
        <li id="BibPLXBIB0028" label="[28]">A.&nbsp;G. Hawkes.
        Spectra of some self-exciting and mutually exciting point
        processes. <em>Biometrika</em>, 1971.</li>
        <li id="BibPLXBIB0029" label="[29]">J.&nbsp;L. Herlocker,
        J.&nbsp;A. Konstan, L.&nbsp;G. Terveen, and J.&nbsp;T.
        Riedl. Evaluating collaborative filtering recommender
        systems. <em>TOIS</em>, 2004.</li>
        <li id="BibPLXBIB0030" label="[30]">S.&nbsp;Hochreiter and
        J.&nbsp;Schmidhuber. Long short-term memory. <em>Neural
        Computation</em>, 1997.</li>
        <li id="BibPLXBIB0031" label="[31]">T.&nbsp;Iwata,
        A.&nbsp;Shah, and Z.&nbsp;Ghahramani. Discovering latent
        influence in online social activities via shared cascade
        poisson processes. In <em>KDD</em>, 2013.</li>
        <li id="BibPLXBIB0032" label="[32]">K.&nbsp;Kapoor,
        K.&nbsp;Subbian, J.&nbsp;Srivastava, and P.&nbsp;Schrater.
        Just in time recommendations: Modeling the dynamics of
        boredom in activity streams. In <em>WSDM</em>, 2015.</li>
        <li id="BibPLXBIB0033" label="[33]">K.&nbsp;Kapoor,
        M.&nbsp;Sun, J.&nbsp;Srivastava, and T.&nbsp;Ye. A hazard
        based approach to user return time prediction. In
        <em>KDD</em>, 2014.</li>
        <li id="BibPLXBIB0034" label="[34]">F.&nbsp;Kooti,
        K.&nbsp;Lerman, L.&nbsp;M. Aiello, M.&nbsp;Grbovic,
        N.&nbsp;Djuric, and V.&nbsp;Radosavljevic. Portrait of an
        online shopper: Understanding and predicting consumer
        behavior. In <em>WSDM</em>, 2016.</li>
        <li id="BibPLXBIB0035" label="[35]">Y.&nbsp;Koren.
        Collaborative filtering with temporal dynamics. In
        <em>KDD</em>, 2009.</li>
        <li id="BibPLXBIB0036" label="[36]">T.&nbsp;Kurashima,
        T.&nbsp;Althoff, and J.&nbsp;Leskovec. Modeling
        Interdependent and Periodic Real-World Action Sequences.
        2018. Online Appendix. <a href="http://bit.ly/2stjpB4"
        target="_blank">http://bit.ly/2stjpB4</a>.
        </li>
        <li id="BibPLXBIB0037" label="[37]">T.&nbsp;Lane. Hidden
        markov models for human/computer interface modeling. In
        <em>Proc. IJCAI WS on Learning about Users</em>, 1999.</li>
        <li id="BibPLXBIB0038" label="[38]">Q.&nbsp;Liu,
        S.&nbsp;Wu, L.&nbsp;Wang, and T.&nbsp;Tan. Predicting the
        next location: A recurrent model with spatial and temporal
        contexts. In <em>AAAI</em>, 2016.</li>
        <li id="BibPLXBIB0039" label="[39]">C.&nbsp;D. Manning,
        P.&nbsp;Raghavan, and H.&nbsp;SchÃ¼tze. <em>Introduction to
        information retrieval</em>. 2008.</li>
        <li id="BibPLXBIB0040" label="[40]">C.&nbsp;Mavroforakis,
        I.&nbsp;Valera, and M.&nbsp;G. Rodriguez. Modeling the
        dynamics of online learning activity. In <em>WWW</em>,
        2017.</li>
        <li id="BibPLXBIB0041" label="[41]">M.&nbsp;D. Mulvenna,
        S.&nbsp;S. Anand, and A.&nbsp;G. BÃ¼chner. Personalization
        on the net using web mining: Introduction. <em>CACM</em>,
        43(8):122â125, 2000.</li>
        <li id="BibPLXBIB0042" label="[42]">I.&nbsp;Nahum-Shani,
        S.&nbsp;N. Smith, B.&nbsp;J. Spring, L.&nbsp;M. Collins,
        K.&nbsp;Witkiewitz, A.&nbsp;Tewari, and S.&nbsp;A. Murphy.
        Just-in-time adaptive interventions (JITAIs) in mobile
        health: key components and design principles for ongoing
        health behavior support. <em>Ann Behav Med</em>, 2016.</li>
        <li id="BibPLXBIB0043" label="[43]">Y.&nbsp;Ogata. On
        Lewisâ simulation method for point processes. <em>IEEE
        Transactions on Information Theory</em>, 1981.</li>
        <li id="BibPLXBIB0044" label="[44]">S.&nbsp;Rendle,
        C.&nbsp;Freudenthaler, and L.&nbsp;Schmidt-Thieme.
        Factorizing personalized markov chains for next-basket
        recommendation. In <em>WWW</em>, 2010.</li>
        <li id="BibPLXBIB0045" label="[45]">A.&nbsp;Shameli,
        T.&nbsp;Althoff, A.&nbsp;Saberi, and J.&nbsp;Leskovec. How
        gamification affects physical activity: Large-scale
        analysis of walking challenges in a mobile application. In
        <em>WWW</em>, 2017.</li>
        <li id="BibPLXBIB0046" label="[46]">M.&nbsp;Swan. The
        quantified self: Fundamental disruption in big data science
        and biological discovery. <em>Big Data</em>, 1(2):85â99,
        2013.</li>
        <li id="BibPLXBIB0047" label="[47]">Y.&nbsp;Tanaka,
        T.&nbsp;Kurashima, Y.&nbsp;Fujiwara, T.&nbsp;Iwata, and
        H.&nbsp;Sawada. Inferring latent triggers of purchases with
        consideration of social effects and media advertisements.
        In <em>WSDM</em>, 2016.</li>
        <li id="BibPLXBIB0048" label="[48]">J.&nbsp;Teevan,
        E.&nbsp;Adar, R.&nbsp;Jones, and M.&nbsp;Potts. History
        repeats itself: Repeat queries in Yahoo's logs. In
        <em>SIGIR</em>, 2006.</li>
        <li id="BibPLXBIB0049" label="[49]">J.&nbsp;G. Thomas and
        D.&nbsp;S. Bond. Behavioral response to a just-in-time
        adaptive intervention (JITAI) to reduce sedentary behavior
        in obese adults: Implications for JITAI optimization.
        <em>Health Psychology</em>, 2015.</li>
        <li id="BibPLXBIB0050" label="[50]">W.&nbsp;Trouleau,
        A.&nbsp;Ashkan, W.&nbsp;Ding, and B.&nbsp;Eriksson. Just
        one more: Modeling binge watching behavior. In
        <em>KDD</em>, 2016.</li>
        <li id="BibPLXBIB0051" label="[51]">I.&nbsp;Valera and
        M.&nbsp;Gomez-Rodriguez. Modeling adoption and usage of
        competing products. In <em>ICDM</em>, 2015.</li>
        <li id="BibPLXBIB0052" label="[52]">R.&nbsp;Yu,
        A.&nbsp;Gelfand, S.&nbsp;Rajan, C.&nbsp;Shahabi, and
        Y.&nbsp;Liu. Geographic segmentation via latent poisson
        factor model. In <em>WSDM</em>, 2016.</li>
        <li id="BibPLXBIB0053" label="[53]">K.&nbsp;Zhou,
        H.&nbsp;Zha, and L.&nbsp;Song. Learning triggering kernels
        for multi-dimensional hawkes processes. In <em>ICML</em>,
        pages 1301â1309, 2013.</li>
        <li id="BibPLXBIB0054" label="[54]">I.&nbsp;Zukerman and
        D.&nbsp;W. Albrecht. Predictive statistical models for user
        modeling. <em>User Modeling and User-Adapted
        Interaction</em>, 2001.</li>
        <li id="BibPLXBIB0055" label="[55]">I.&nbsp;Zukerman,
        D.&nbsp;W. Albrecht, and A.&nbsp;E. Nicholson. Predicting
        usersâ requests on the WWW. In <em>UM</em>. 1999.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>Â© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License.<br />
      ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3178876.3186161">https://doi.org/10.1145/3178876.3186161</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
