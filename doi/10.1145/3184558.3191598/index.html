<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Cultural Heritage Resources Profiling: Ontology-based Approach</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Cultural Heritage Resources Profiling: Ontology-based Approach</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Mohamed BEN</span>      <span class="surName">ELLEFI</span>,     Aix Marseille University, CNRS, ENSAM, University of Toulon, LIS UMR 7020, 13397 Marseille, France     </div>     <div class="author">     <span class="givenName">Odile</span>      <span class="surName">PAPINI</span>,     Aix Marseille University, CNRS, ENSAM, University of Toulon, LIS UMR 7020, 13397 Marseille, France     </div>     <div class="author">     <span class="givenName">Djamal</span>      <span class="surName">MERAD</span>,     Aix Marseille University, CNRS, ENSAM, University of Toulon, LIS UMR 7020, 13397 Marseille, France     </div>     <div class="author">     <span class="givenName">Jean-Marc</span>      <span class="surName">BOI</span>,     Aix Marseille University, CNRS, ENSAM, University of Toulon, LIS UMR 7020, 13397 Marseille, France     </div>     <div class="author">     <span class="givenName">Jean-Philip</span>      <span class="surName">ROYER</span>,     Aix Marseille University, CNRS, ENSAM, University of Toulon, LIS UMR 7020, 13397 Marseille, France     </div>     <div class="author">     <span class="givenName">J&#x00E9;r&#x00F4;me</span>      <span class="surName">PASQUET</span>,     Aix Marseille University, CNRS, ENSAM, University of Toulon, LIS UMR 7020, 13397 Marseille, France     </div>     <div class="author">     <span class="givenName">Jean-Christophe</span>      <span class="surName">SOURISSEAU</span>,     Aix Marseille University, CNRS, Minist&#x00E8;re de la Culture et de la Communication, CCJ UMR 7299, 13094 Aix En Provence, France     </div>     <div class="author">     <span class="givenName">Filipe</span>      <span class="surName">CASTRO</span>,     Ship Reconstruction Laboratory 4352 TAMU, Texas A-M University, College Station, Texas 77843, USA     </div>     <div class="author">     <span class="givenName">Mohammad Motasem</span>      <span class="surName">NAWAF</span>,     Aix Marseille University, CNRS, ENSAM, University of Toulon, LIS UMR 7020, 13397 Marseille, France     </div>     <div class="author">     <span class="givenName">Pierre</span>      <span class="surName">DRAP</span>,     Aix Marseille University, CNRS, ENSAM, University of Toulon, LIS UMR 7020, 13397 Marseille, France     </div>                                              </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3191598" target="_blank">https://doi.org/10.1145/3184558.3191598</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Cultural heritage (CH) resources are very heterogeneous since the information was collected from vast diversity of cultural sites and digitally recorded in different formats. With the progress of 3D technologies, photogrammetry techniques become the adopted solution for representing CH artifacts by turning photos from small finds, to entire landscapes, into accurate 3D models. To meet knowledge representation with cultural heritage photogrammetry, this paper proposes an ontology-profiling method for modeling a real case of archaeological amphorae. The ontological profile consists of all needed information to represent a CH resource including typology attributes, geo-spatial information and photogrammetry process. An example illustrating the applicability of this profiling method to the problem of CH resources conceptualization is presented. We also outline our perspectives for using ontologies in data-driven science, in particular on modeling a complete pipeline that manages both the photogrammetric process and the archaeological knowledge.</small>     </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Ontology</small>, </span>     <span class="keyword">      <small> Profiling</small>, </span>     <span class="keyword">      <small> Modeling</small>, </span>     <span class="keyword">      <small> Cultural Heritage</small>, </span>     <span class="keyword">      <small> Photogrammetry</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Mohamed BEN ELLEFI, Odile PAPINI, Djamal MERAD, Jean-Marc BOI, Jean-Philip ROYER, J&#x00E9;r&#x00F4;me PASQUET, Jean-Christophe SOURISSEAU, Filipe CASTRO, Mohammad Motasem NAWAF, and Pierre DRAP. 2018. Cultural Heritage Resources Profiling: Ontology-based Approach. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em>, 8 Pages. <a href="https://doi.org/10.1145/3184558.3191598" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3191598</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-11">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>In philosophy the term &#x201D;ontology&#x201D; refers to the &#x201D;whatness&#x201D; question, or in other words &#x201D;what kinds of things are there?&#x201D;<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>. In Semantic Web field, the term &#x201D;ontology&#x201D; can be used to describe and represent an area of knowledge, according to the W3C vision<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>. In the remainder of this paper, we adopt the computational meaning of ontologies that reflects a structured system of fundamental concepts and relationships and of an agreed epistemology, i.e. clearly defined rules of evidence and reasoning, which do not privilege individual experiences or beliefs that cannot be argued against, and which at the same time include clear evaluation mechanisms for the credibility of research conclusions [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>].</p>    <p>In recent years, an increasing number of works have shown interest in the development of ontology-based approaches, technologies and tools for supporting cultural heritage applications, opening the door for many interesting perspectives. Doerr <em>et. al</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>] has argued that ontologies for cultural heritage have a tendency to exhibit a focus on the material and physical aspects of the past. The intention behind the use of ontology-based approaches is to allow the integration, use and re-use of the same set of data from different perspectives, especially when considering the high level of fragmentation of cultural heritage datasets. Beyond a real scientific interest demonstrated by scientists, the use of ontology-based approaches become a major concern in order to push local institution to use this approach, as the case for MIBACT &#x2014; the Italian Ministry of cultural heritage and Activities and Tourism [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>].</p>    <p>Bing <em>et al.</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>] present an ontology-based approach for modeling cultural heritage websites where they introduced Lalouver ontology to model <a class="link-inline force-break" href="http://Lalouver.com">Lalouver.com</a> website which mainly focuses on presenting painting and sculptures website into semantic web.</p>    <p>CIDOC-CRM as the abbreviation for the international Committee for Documentation (&#x201D;CIDOC&#x201D;) Conceptual Reference Model (&#x201D;CRM&#x201D;), is so far the most commonly used ontology for cultural heritage modeling [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>]. The primary role of the CIDOC-CRM is to enable information exchange and integration between heterogeneous sources of cultural heritage information. In simple term, we can see the overall scope of the CIDOC-CRM as the curated knowledge of museums. Furthermore, CIDOC-CRM is now well adopted by cultural heritage actors and a lot of developments are now aligned on this ontology [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>].</p>    <p>In the CH community, ontologies are mainly adopted for developing Geographic Information Systems (GIS) allowing to visualize, query, analyze, and comprehend geographic data in order to extract knowledges and assist users in their researches. The cultural heritage data that we are dealing with is collected from photographs taken directly from the CH studied site. These photographs are transformed then into 3D orthophoto through a photogrammetric process. Recent works related to GIS approaches [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>] and for recent spatial approaches based on CIDOC CRM, we cite [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>]. None of these approaches provide a model that described CH artifacts and in the same time the corresponding phtogrammetric process performed in the 3D transformation. Hence, in this paper we present a modeling approach that allows to profile the studied artifacts in term of their typology, spatial information and 3D transformation.</p>    <p>The profiling approach that we propose consists of an ontology model that describes cultural heritage resources with an orientation towards 3D photogrammetry representations and spatial measuring. In this way, CH Resources are represented from the measurement point of view and have access to all the photogrammetric data that contributed to their measurement in space. This modeling work consists of an extension of previous studies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>] in the context of underwater archeology, where the model started from the premise that the collections of measured items are marred by a lack of precision concerning their measurement, assumptions about their reconstruction, their age, and origin. It was therefore important to ensure the coherence of the measured artifact and potentially propose a possible revision. Following linked data best practices [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>], we linked our ontology to the CIDOC-CRM, which provides an upper level of conceptualization for our model. A simple mapping would not be sufficient, hence, we extended CIDOC-CRM with hierarchical relationships. This alignment is an extension of a previous study [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>] where we proposed a model for the Montreal Castle in Shawbak, Jordan. Finally, we introduce a new vision of cultural heritage profiling to fill the bridge between ontology modeling and cultural heritage survey where we distinguish between three different dimensions of profiles, typological, photogrammetrical process and spatial information.</p>    <p>The rest of the paper is organized as follow. First, Section. <a class="sec" href="#sec-12">2</a> will describe the process that we adopted for data gathering from photogrammetry to pattern recognition. Section. <a class="sec" href="#sec-15">3</a> will present our definition of CH resource profiling where we detail its different dimensions in the following sections: typological (see Section. <a class="sec" href="#sec-16">4</a>), photogrammetrical (see Section. <a class="sec" href="#sec-17">5</a>), and spatial (see Section. <a class="sec" href="#sec-18">6</a>). An example of the modeled CH data is presented in Section. <a class="sec" href="#sec-19">7</a>. Then, Section. <a class="sec" href="#sec-20">8</a> depicts a discussion about the different scenarios for linking our CH data. Finally, we conclude and give some future direction in the last section.</p>   </section>   <section id="sec-12">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Data Gathering and Photogrammetric Process: Xlendi Wreck</h2>     </div>    </header>    <p>This section describes our process of data gathering that was involved to characterize the Phoenician shipwreck of Xlendi (Malta). We recall here briefly the outline of the process, which lies at a depth of 110m, using modern photogrammetric approaches. The wreck was discovered in 2008, thanks to a systematic sonar survey of the coasts around Malta and Gozo. This study was supervised by the Superintendence of Cultural Heritage in order to uncover all the underwater archaeological remains lying in the Malta&#x0027;s territorial waters.</p>    <p>The process applied for the photogrammetric study was done in collaboration with COMEX<a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>, a society mainly devolved to underwater exploration missions. They designed a submarine of 2 people, the Remora 2000, on which the acquisition system was integrated. With a maximum depth of 610m and five hours of autonomy, it is perfectly suited to lead the acquisition. This work has been published in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>].</p>    <section id="sec-13">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Real Time Visual Odometry</h3>     </div>     </header>     <p>Being a non-invasive technology, the photogrammetry allows to study all visible part of the area and have a global comprehension. In this process, we start by briefly detailing different steps allowing to find the orientation of a set of photographs results. The first step consists of detecting all the interest points or features present on the images. While traditional detection approaches are limited to the detection of corners and sensitive changes between images (light, rotation...), we cite here more recent developments like [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>] that enable to find hundreds of features in each image, while being robust to changes concerning the scale, rotation or variations of luminosity. The next step consists of matching similar 2D points on different images. Descriptor based algorithms like SIFT (Scale Invariant Feature Transform) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0019">19</a>] enables to match feature by computing a distance between the descriptor and comparing it to a threshold. Depending on the calibration was already done or not, various approaches can be used to compute the relative orientations based on the set of matching points. A famous one is the five points algorithm [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>]. Due to some assumptions and knowledges like the distance between the stereo cameras, the global algorithm is a bit simplified and the proposed odometry method was adapted from two papers; S&#x00FC;nderhauf and <em>al.</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>] developed a method working with a subset of consecutive images, instead of all the set, lowering the computation time. Xue and Su [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0033">33</a>] took advantage of the knowledge of the relative orientation of the cameras to improve the bundle adjustment procedure. Combining and improving both works, the following algorithm was implemented to compute the orientation of the stereo images acquired by the submarine:</p>     <ul class="list-no-style">     <li id="list1" label="&#x2022;">Starting with image <em>I<sub>i</sub>      </em>, we look for the closest image <em>I</em>      <sub>       <em>i</em> + <em>k</em>      </sub> so that the distance between <em>I<sub>i</sub>      </em> and <em>I</em>      <sub>       <em>i</em> + <em>k</em>      </sub> exceeds a given threshold.<br/></li>     <li id="list2" label="&#x2022;">Add the new image <em>I</em>      <sub>       <em>i</em> + <em>k</em>      </sub> to the current considerer window.<br/></li>     <li id="list3" label="&#x2022;">i becomes i + k. Repeat first step in order to have three stereo image pairs in the window.<br/></li>     <li id="list4" label="&#x2022;">Apply the bundle adjustment method. The bundle adjustment is a refinement of the previously found parameters, relying on a minimization procedure: <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{align*} \mathsf {min} ||\sum _{i, j} \mathbf {M}_j \mathbf {X}_i - \mathbf {x_{ij}}||^2_F\end{align*} </span>        <br/>       </div>      </div> , where <strong>M</strong>      <sub>       <em>j</em>      </sub> is the set of projection matrices of the cameras, <strong>X</strong>      <sub>       <em>i</em>      </sub> is the set of computed 3D points and <strong>x<sub>ij</sub>      </strong> the corresponding 2D observations on the photographs.<br/></li>     <li id="list5" label="&#x2022;">Now, shift the current window using the next image and repeat the algorithm as long as all the images are not processed.<br/></li>     </ul>    </section>    <section id="sec-14">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> 3D&#x2014;2D Transformation</h3>     </div>     </header>     <p>After the visual odometry phase, which insures a perfect coverage of the site and produces a set of oriented photographs with a correct scale we need to exploit these data in order to produce documents for archaeological study. These documents can be 3D or 2D according to the archaeological needs. The scale is done using stereo calibration of the visual odometry system, a scale-bar constraint is inserted for each stereo pair coming from the visual odometry system.</p>     <p>We developed a set of tools to bridge our visual odometry software to commercial software as Photoscan from Agisoft<a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a> in order to use the densification capabilities. After this first step we obtain a dense cloud of points and a set of oriented high resolution photographs describing accurately the entire site. This is enough to produce high resolution orthophoto of the site (1 pixel/mm) and accurate 3D models. Example of high resolution orthophoto in <a class="link-inline force-break"      href="http://www.lsis.org/groplan/article/link/link2XlendiOrthophoto.html">http://www.lsis.org/groplan/article/link/link2XlendiOrthophoto.html</a>. </p>     <p>We remind the reader that our main intention is to develop tools which would meet the needs of archaeologists in their studies of the cargo and the artifacts. After collecting photographs of the wreck, the major challenge that we face consists of extracting known objects for these data, i.e. defining the right amphorae typology and the correspondent theoretical 3D models. This recognition process is composed by two different phase: the first one consists of the artifacts detections, and the second phase involves the pose estimation of each artifact in order to compute the exact dimension and spatial localization in the wreck. Our current approach starts by detecting 2D artifacts using the full orthophoto. Then makes use of Pasquet <em>et al.</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0025">25</a>] deep learning method which is based on pixel prediction to detect cultural heritage resources in a large image, i.e. this method can detect around 90% of amphorae in Xlendi wreck orthophoto. Then, we use a 3D matching approach to compute the position, orientation and dimension of the known artifact. The next section will introduce our profiling method that will propose an ontology for modeling the detected amphorae.</p>    </section>   </section>   <section id="sec-15">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Ontology Conceptualization For CH Profiling</h2>     </div>    </header>    <p>Data profiling has a wide definition in different communities, i.e. the definition in wikipedia<a class="fn" href="#fn5" id="foot-fn5"><sup>5</sup></a> of data profiling is the process of examining the data available in an existing data source (e.g. a database, photo of object, etc) and collecting statistics and information about that data. In archeology dictionary wordsmith<a class="fn" href="#fn6" id="foot-fn6"><sup>6</sup></a>, the term profile refers to vertical wall, section, or face of an excavation pit that exposes the lateral relationships, archaeological features, structures, stratigraphy &#x2013; and their relationships. By extension, a profile is a record or graphic representation of these, including color, soil type, and content. Soil profiles consist of a number of layers, or horizons, which result from soil-forming processes. The profiling is the use of profile gauge, i.e., a tool for recording the cross-sectional shape of a surface.</p>    <p>On the other hand, in semantic web community, a dataset profile can be seen as the formal representation of a set of features that describe a dataset and allow the comparison of different datasets with regard to their characteristics [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>].</p>    <p>To meet the semantic web profile definition with the archaeological one, we provide the following profile definition:</p>    <p>     <div class="definition" id="enc1">     <Label>Definition 3.1.</Label>     <p>      <strong>(CH Resource Profile) .</strong> Let <em>R</em> be a cultural heritage resource and <em>F</em> be a all comprehensive features that describes <em>R</em>. <em>S</em> is a profile for <em>R</em> where <em>S</em>&#x2282;<em>F</em> if <em>S</em> is a set of commonly investigated features that describes <em>R</em> with respect to a given application scenario.</p>     </div>    </p>    <p>This set of features allows to profile the CH resource in different application scenarios, i.e. to identify the typology of the resource, to produce a dimensional analysis, to perform a typology clustering and other statistical computations with regard to the represented profile dimension. In our ontology model we identify three profiling dimensions:</p>    <ul class="list-no-style">     <li id="list6" label="&#x2022;">Typological (height, maximum diameter, volume, ...)<br/></li>     <li id="list7" label="&#x2022;">Photogrammetrical process (bundle model, camera, photographs, ...)<br/></li>     <li id="list8" label="&#x2022;">Spatial (position, convex envelope, ...)<br/></li>    </ul>    <p>In order to produce a CH resource profile following the definition above, we need at first to provide a conceptual model that characterizes the different features for the CH resource. However CH data is very heterogeneous and can have different ambiguous descriptions. Hence, the most challenging problem for metadata designers and cultural heritage experts is to provide a common conceptualization of a such data. The conceptual representation of objects from different fields allows us to give expression to objects, or at least a portion of our knowledge of the object, from one field to another. To develop transversal data mining techniques and adapted systems, conceptualization must provide an intelligible description to experts in different fields. The challenge then is to bridge the conceptual framework in order to produce a formal representation. In this light, ontologies can be used to cover different terminologies and to represent a clear specification of the different meanings. Hence, having an associated ontology where each term has a corresponding construct in the conceptual framework allows to maintain this distinction within the conceptual model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>].</p>    <p>One of the main advantage behind developing such ontology is to offer the community a common unambiguous representation of modeling cultural heritage resources. Furthermore, this representation can guide the design of the knowledge bases to offer a storage model of the various experimental data as well as the measurement process in a knowledge manner. Moreover, the use of ontologies will help in maintaining a strict distinction between data and the interpretation based on the data. A particular conceptual framework along with the associated ontology is the optimal way to create a formal representation fit for different abstraction level.</p>    <p>Finally Ontologies provide a common way of representing knowledge about some domain and a way to share a common understanding of information structure. Once we have common understanding, we can try to reason/query over this information, i.e. inference, consistency checking, etc. We serialized our ontology with the Web Ontology Language OWL2, as a W3C recommendation<a class="fn" href="#fn7" id="foot-fn7"><sup>7</sup></a>. The developed ontology for cultural heritage profiling is made available on <a class="link-inline force-break"     href="http://www.arpenteur.org/ontology/Arpenteur.owl">http://www.arpenteur.org/ontology/Arpenteur.owl</a>. </p>   </section>   <section id="sec-16">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Typological Profiling</h2>     </div>    </header>    <p>In cultural heritage, we note that the differentiating criterion between different typologies is not the existence of certain attributes, but rather their values, or even the relationship between these values. For example, the differentiating criterion in an archaeological amphorae scenario is, the relationship between the height and the maximum diameter, or the height (Z side) where the amphora&#x0027;s maximum diameter is located. Note also that for archaeological reasons, awarding new amphorae typologies can not be performed automatically because the critical criteria are completely linked to the field of study and their integration is incompatible with the hierarchical relationships that we use. Hence, the identification of amphorae typologies have to be performed by archaeologists experts as can be stated in a previous work [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>].    </p>    <p>This<a class="fn" href="#fn8" id="foot-fn8"><sup>8</sup></a> section proposes a profiling approach for CH resources in term of their typology features. The typological profile can be defined as the set of features in the ontology that characterizes a given cultural heritage typology. The main intuition here is that for a given CH resource, we should identify the corresponding CH typology based on a this set of profile attributes/features. Figure. <a class="fig" href="#fig1">1</a> depicts the different dimensions that are measured from the amphora during the photogrammetry process, as detailed in section. <a class="sec" href="#sec-12">2</a>. In order to profile these typological dimensions, we define a set of morphological attributes, as depicted in Figure. <a class="fig" href="#fig2">2</a>:</p>    <ul class="list-no-style">     <li id="list9" label="&#x2022;"><strong>hasBellyDiameter</strong>, i.e. the diameter of the belly; a numerical value; unit of measurement is meter.<br/></li>     <li id="list10" label="&#x2022;"><strong>hasDiameterNeck</strong>, i.e. the diameter of the neck; a numerical value; unit of measurement is meter.<br/></li>     <li id="list11" label="&#x2022;"><strong>hasDiameterSupport</strong>, i.e. the diameter of the support; a numerical value; unit of measurement is meter.<br/></li>     <li id="list12" label="&#x2022;"><strong>hasDistanceHandles</strong>, i.e. the diameter of the support; a numerical value; unit of measurement is meter.<br/></li>     <li id="list13" label="&#x2022;"><strong>hasHandlesWidth</strong>, i.e. the diameter of the Handles; a numerical value; unit of measurement is meter.<br/></li>     <li id="list14" label="&#x2022;"><strong>hasHeightLips</strong>, i.e. the diameter of the lips; a numerical value; unit of measurement is meter.<br/></li>     <li id="list15" label="&#x2022;"><strong>hasMaxDiameter</strong>, i.e. the maximum diameter of the amphora; a numerical value; unit measurement is meter.<br/></li>     <li id="list16" label="&#x2022;"><strong>hasNormalizedDiamMaxPos</strong>, i.e. a normalized value on the max of all diameters in the amphora.<br/></li>     <li id="list17" label="&#x2022;"><strong>hasRatioDiamHeight</strong>, i.e. the ratio between the height and the max diameter.<br/></li>     <li id="list18" label="&#x2022;"><strong>hasWidthBetweenUpperHandles</strong>, i.e. for more accuracy we take width between upper handles in addition to the diameter which is between down handles.<br/></li>     <li id="list19" label="&#x2022;"><strong>hasWidhtLips</strong>, i.e. the width of the amphora lips; a numerical value; unit measurement is meter.<br/></li>     <li id="list20" label="&#x2022;"><strong>percentOfMeasured</strong>, i.e. sometimes, an amphora is not complete and missing pieces, this attribute depicts the measured percentage of the amphora.<br/></li>    </ul>    <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191598/images/www18companion-337-fig1.jpg" class="img-responsive" alt="Figure 1"      longdesc=""/>     <div class="figure-caption">     <span class="figure-number">Figure 1:</span>     <span class="figure-title">Amphora Dimensions.</span>     </div>    </figure> <figure id="fig2">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191598/images/www18companion-337-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 2:</span>      <span class="figure-title">An Amphora typological profile visualized via webvowl.</span>     </div>     </figure>    <p>An amphorae is a man-made large storage-jar used as transport recipient over history making it one of most important archaeological artifact for cultural heritage interest. An amphorae can be seen as a measurable item that do not have a reference to a property unit but towards a photogrammetrical model containing a set of images in which this item was seen and measured. In fact all concepts that can be measured are a sub-concept of the root Measurable. We can then organize the concepts taxonomy from a measurement point of view by defining a set of relationships linked to their morphology and based on the information obtained during the measurement process. This taxonomy representation is modeled in the ontology by the hierarchical relationships as depicted in Listing. <a class="fig" href="#unfig1">1</a> .</p>     <figure id="unfig1">     <div class="figure-caption">      <span class="figure-number">Listing 1:</span>      <span class="figure-title">Amphora taxonomy</span>     </div>     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191598/images/www18companion-337-img1.jpg" class="img-responsive" alt=""      longdesc=""/>    </figure>    <p>Inheriting in ontologies means something different that it means in object oriented languages, i.e. if a subclass inherits a property from its superclass, it only means that this property can also be applied to this sub-class. It is not a requirement. Hence, the typological profile is enriched by all measurement attributes inherited from the different super-classes that can assist archaeologists to define the typology of a given CH resource. The list of inherited attributes is shown in Listing. <a class="fig" href="#unfig2">2</a> .</p>     <figure id="unfig2">     <div class="figure-caption">      <span class="figure-number">Listing 2:</span>      <span class="figure-title">RecipientTransport, Artifact, SpatialObject and IdentifiedObject attributes</span>     </div>     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191598/images/www18companion-337-img2.jpg" class="img-responsive" alt=""      longdesc=""/>    </figure>    <p>Note that the morphological attributes {hasDiameterNeck, hasBellyDiameter, hasDiameterSupport, hasDistanceHandles, hasHandlesWidth, hasHeightLips, hasInternalVolume, hasNormalizedDialmMaxPos, hasRatioDiamHeight, hasWidthBetweenUpperHandles, hasWidthLips, percentOfMeasured} are linked to the CIDOC-CRM model as sub-properties of the <span class="inline-equation"><span class="tex">$E54\_Dimension$</span>     </span><a class="fn" href="#fn9" id="foot-fn9"><sup>9</sup></a>. This CIDOC-CRM class defines quantifiable properties that can be measured by some calibrated means and can be approximated by values, i.e. points or regions in a mathematical or conceptual space, such as natural or real numbers, RGB values etc.</p>    <p>The hub triples that connect the different profiles of CH resources are depicted in Listing. <a class="fig" href="#unfig3">3</a> . These hub triples describe the amphora super-classes, SpatialObject and SpatialLocalization that connect respectively the BoundingBox and Transformation3D concepts. These triples represent respectively the connection to the photogrammetrical profile and to the spatial profile as detailed in the following sections.</p>     <figure id="unfig3">     <div class="figure-caption">      <span class="figure-number">Listing 3:</span>      <span class="figure-title">The hub triples around spatial objects</span>     </div>     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191598/images/www18companion-337-img3.jpg" class="img-responsive" alt=""      longdesc=""/>    </figure>   </section>   <section id="sec-17">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Photogrammetrical Profiling</h2>     </div>    </header>    <p>Graphical representations of archaeological areas such as drawings, sketches, photographs, topographic renditions, artist impressions and photogrammetric studies are all essential phases on archaeological surveys. Each photogrammetrical components has a crucial impact on the 3D resulted model. Hence, we need a detailed model in our ontology for all involved components, i.e. the quality of the camera calibration has a direct impact on the quality of photographs resolutions and the resultant 3D model(s).</p>    <p>The photogrammetrical profile for a given CH resource can be defined as the model (i.e. set of concepts, relations, attributes) that describes all the involved components in the photogrammetrical process. This profile is structured around the concept Photogrammetry which is the root of four direct sub-classes: Photograph, Camera, Model and IcoloredPoint. In fact, the concept Photograph represents the photograph(s) that will be measured to create 3D models for CH resources.</p>    <p>Photogrammetry is based on the principle that while a single photograph can only yield 2D coordinates (height and width), a two overlapping images of the same scene, taken slightly apart from each other, can allow the third dimension (depth) to be calculated. In order to reflect this relation, we modeled the concept PhotoManager that connect a set of photograph through the relation haveSetOfPhotograph. In the other hand, we have isPhotographOf relation that links a Photograph resource to a PhotoManager resource. Furthermore, a Photograph is related to the concept Transformation3D that locates the position of its optical center in the 3D world space, as well as its orientation. In this way, our photogrammetrical profile keeps tracks of links between photograph(s) and the 3D model(s). A Photograph is connected to the corresponding Camera(s) through the relation hasCamera.</p>    <p>The camera features is the main measurement instrument as it bridges the scales from the 3D space to the 2D space [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>], i.e. computing a camera calibrations consists in estimating the matrix of the intrinsic parameters (see [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>] for more calibration details). We modeled the concept Camera by common three attributes: hasFocalLength, hasPPX and hasPPY, representing respectively the focal length of the camera and the deviation along the axis X and Y of the real principal point compared to the theoretical one (that is located at the center of the image plane). The concept Camera has two sub-classes representing the two major techniques in phtogrammetry: DigitalCamera and FilmBasedCamera, as can be seen in Figure. <a class="fig" href="#fig3">3</a>. Each technique represent a specific parameters like fiducial marks and sensor width, etc. We modeled a further specific information about distortion via the concept RadialDecenteringDistortion that allow to model the radial distortion (i.e. hasCoef_K1, hasCoef_K2, hasCoef_K3) and the decentering distortion (i.e. hasCoef_P1, hasCoef_P2), due to lens alignement.</p> <figure id="fig3">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191598/images/www18companion-337-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 3:</span>      <span class="figure-title">Partial view of the photogrammetry profile visualized via Webvowl.</span>     </div>     </figure>    <p>As detailed in section <a class="sec" href="#sec-12">2</a>, the overall sparse 3D model is obtained thanks to a triangulation process applied to the set of matched features. The external orientation is then refined using a global bundle adjustment applied to all the high-resolution images. The photogrammetrical model concept contains a set of oriented photographs and a set of 3D points which are at least visible on two oriented photographs. The correspondence with the photograph(s) and the measured 3D points are managed respectively by the concepts PhotoManager and MeasuredPointManger. On the other hand, we modeled a CameraManager concept to ensure the connection between a model and its corresponding camera(s). Each photograph is also in relation with its related camera. These different manager connections are modeled by a set of objectProperties relations that are asymmetric and irreflexive (following the definition in OWL2)</p>    <p>The concept IColoredPoint is the root concept in the hierarchy of points. This concept represents the RGB color values of the respective 2D or 3D points through three attributes of color: hasColor_R, hasColor_G and hasColor_B. On a down level of the hierarchy, the concept IPoint2D models 2D points via the two attributes hasX and hasY representing respectively the (X,Y) coordinates of a point in 2D space. On the next level down in the hierarchy, we defined two sub-classes ImagePoint and IPoint3D. The ImagePoint concept represents a 2D point that is related to the corresponding photograph through the relation isObservationOf. An observation corresponds to a point of interest on a given photograph. IPoint3D provides Z dimension of a point in 3D space via the attribute hasZ. Note here that 3D and 2D points information relate to the spatial profiles which will be described in the following. Finally, Point_3D inherits from IPoint3D to represent in a practical way the photogrammetric 3D point. This concept is related to a set of ImagePoint(s) (the so-called observations) corresponding to the projection of this point on each photograph through the property hasImagePointManager.    </p>   </section>   <section id="sec-18">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Spatial Profiling</h2>     </div>    </header>    <p>As stated in the previous section, the photogrammetric profile is the description of that allow the production of the 3D model. A spatial profile is the set of features that provide information about the orientation and the location of a given CH resource in a specific geographical area.</p>    <p>Spatial profiling in our model provides two major descriptions, the localization and the shape of the object. The model of this profiling is structured around the concept SpatialObject which is connected to the Transformation3D concept through the concept SpatialLocalization, as can be seen in Listing. <a class="fig" href="#unfig3">3</a> . The Transformation3D concept is considered as the hub for the localization description (as well for the photograph 3D transformations), as it allows to connect the resource to their spatial descriptions in term of rotation and 3D space points. The RotationMatrix concept is used to describe the rotation of the resource along the 3 axis in a 3D Euclidean space, using a 3x3 matrix. The hasTranslation relation provides a connection to the 3D translation with respect to its own coordinate system. The IPoint3D concept locates a resource in a given 3D space, while the Point_3D concept provides information about the photogrammetric point such as, accuracy information (residual) on the computed point, and the list of 2D points that represents the projection of the point on the various corresponding photographs. The IPoint3D is connected to a set of 3D points that, taken together, constitute the shape of the profiled resource. In this way, the spatial profile model for a given cultural heritage resources can be represented through a set of points in a given 3D space.</p>    <p>In computational geometry, a bounding volume for an objects is a closed volume that completely contains the object which is assumed to be non-empty and bounded (finite). For simplicity reasons, what is probably the most used bounding volume is the bounding box (BB). Other analytical shape are often used, like bounding spheres or cylinders. In a 3D space, a BB is displayed in form of a cuboid containing the object, respectively a rectangle in 2D space. we are interested in the problem of estimating the 3D location and orientation of the objects present in the scene. For even more simplicity reasons, the computed bounding box in computer science is generally the axis-aligned box and it is also the case here. Indeed, this will allow to model the BoundingBox concept by six attributes that correspond to the box coordinates: hasXMax, hasXMin, hasYMax, hasYMin, hasZMax, hasZMin. Computing such a bounding box is really easy, as we only need to determine the extremum values of the point cloud to be wrapped.</p>   </section>   <section id="sec-19">    <header>     <div class="title-info">     <h2>      <span class="section-number">7</span> Xlendi Amphorae Sample Dataset</h2>     </div>    </header>    <p>For better understanding of our profiling approach, we made available a dataset on the datahub &#x2014; XlendiAmphorae<a class="fn" href="#fn10" id="foot-fn10"><sup>10</sup></a>, which contains a sample of instances describing Amphore_A15 and Amphore_A03 from the Xlendi Wreck in the RDF file &#x201D;XlendiAmphoraeSample&#x201D;. The typological profile is presented through different morphological attributes that, when collected together, can specify the corresponding typology, i.e. Ramon-T2111-69 for Amphore_A15 and Pithecusse_343 for Amphore_A03. In order to investigate the spatial profiles, we go through the hasTransformation3D relation that point to the instance of the Transformation3D, i.e. Transfo-1953670366 for Amphore_A15. This latter instance provides connections to instances corresponding to the RotationMatrix and the IPoint3D, i.e. respectively Mat1220813917 and IPoint3D1039759545 that together provide information about the spatial location and rotation of Amphore_A15. Regarding the photogrammetry profile, we draw the reader intention to the RDF file &#x201D;PhotographSample&#x201D; in XlendiAmphorae dataset which depicts an example of a photograph instance Photograph_13 which is connected to a camera and a 3D transformation. The camera instance is described by a set of camera properties and enriched by a distortion specifications via the relation hasDistortion. The spatial profile is related to a single 3D point called POS (position and orientation system), the photogrammetrical profile describes the photograph with a set of 3D points and a set of rotation matrix that are related trough a single 3D transformation instance.</p>   </section>   <section id="sec-20">    <header>     <div class="title-info">     <h2>      <span class="section-number">8</span> Data Linking</h2>     </div>    </header>    <p>During the last years, the increasing adoption of Linked Open Data principles by Web practitioners around the world has led to a growing interconnected web-scale data network, LOD cloud<a class="fn" href="#fn11" id="foot-fn11"><sup>11</sup></a>. Behind this growth, there is a huge effort of data providers not only to publish their data but also to model and describe them following the LOD best practices. However, to ensure the interoperability of this large scale web of data, we would like to point out to the recommendation of building on, instead of replicating, existing ontologies.</p>    <p>Following these best practices, We linked our ontology to the CIDOC-CRM ontology in order to provide more integrity between cultural heritage datasets and to allow more flexibility for federated queries cross different datasets using these ontologies. The current version of this extension relates only to the TBox part of the ontologies by the use of the properties rdfs:subClassOf and rdfs:subPropertyOf to extend CIDOC&#x2013;CRM schema. As stated in Section. <a class="sec" href="#sec-16">4</a>, the morphological attributes of the typology profile are aligned to the CDOC-CRM concept E54_Dimension. As a spatial representation, the CIDOC-CRM provides the triple <E18_Physical _Thing, P53_has_former_or_current_location, E53_Place> as a description of an instance of E53_Place which is the former or current location of an instance of E18_Physical_Thing. We connected our spatial profiling model, which is structured around SpatialObject concept, to this latter CIDOC-CRM triple, as depicted in Listing. <a class="fig" href="#unfig4">4</a> . We note here that we limited our alignment to the extension relationships since the CIDOC-CRM provides very generic terminology that can not cover 3D GIS modeling, i.e. CIDOC-CRM does not provide description about 3D points positions and rotations details. In the same context, we cite another ontology GeoSPARQL<a class="fn" href="#fn12" id="foot-fn12"><sup>12</sup></a> that provides a description of spatial objects and geometries. This ontology does not provide any specific 3D spatial description of objects, neither geometry bounding boxes. We opted for the skos:closeMatch<a class="fn" href="#fn13" id="foot-fn13"><sup>13</sup></a> to describe the link of our ontology to GeoSPARQL, i.e. we linked our ontology to the concepts SpatialObject and Point. In addition to datasets interchangeability, a further motivation behind the connection to GeoSPARQL is to allow an enrichment of the spatial profile in our ontology by the spatial relations in GeoSPARQL, i.e. sfCrosses, ehMeet.</p>     <figure id="unfig4">     <div class="figure-caption">      <span class="figure-number">Listing 4:</span>      <span class="figure-title">The alignment between &#x003C;SpatialObject, hasTransformation3D, transformation3D&#x003E; triple and the corresponding triple in CIDOC-CRM</span>     </div>     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191598/images/www18companion-337-img4.jpg" class="img-responsive" alt=""      longdesc=""/>    </figure>    <p>To the best of our knowledge and according to the LOV<a class="fn" href="#fn14" id="foot-fn14"><sup>14</sup></a> repository, there is no other ontology that provides a model describing the photogrammetry process. Yet, only a few ontologies provide a description for photographic process from which we cite: SIO (semantic science integrated ontology) via the concept &#x201D;Photograph&#x201D;<a class="fn" href="#fn15" id="foot-fn15"><sup>15</sup></a> and DBpedia that provides a description of the concepts<a class="fn" href="#fn16" id="foot-fn16"><sup>16</sup></a>.</p>    <p>On the other hand, since we provide the only available data that represents amphorae in the Xlendi wreck with semantic web formats, there is no other available dataset describing this wreck and may contain similar resources to be linked to. Hence, in order to join the LOD cloud <a class="fn" href="#fn17" id="foot-fn17"><sup>17</sup></a>, we looked into multi-domain datasets such as DBpedia, where we looked to the widely used concept Camera<a class="fn" href="#fn18" id="foot-fn18"><sup>18</sup></a>. Let us take the example of the Nikon D100 camera that was used in our photogrammetric process, as depicted in the file &#x201D;PhotographSample&#x201D; in XlendiAmphorae dataset, and the same camera reference in DBpedia Nikon_D100<a class="fn" href="#fn19" id="foot-fn19"><sup>19</sup></a>. In our dataset, the calibration, as described in the instance &#x201D;Distortion1642610353&#x201D;, is the distinguishing criterion between different instances referring to a camera Nikon D100. However, in DBpedia there is only one D100 instance and no calibration differentiation. Hence, we realized that it is not possible to perform the identity link &#x201D;owl:sameAs&#x201D; in this case, according to [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>]. Since the identity link is not able to be adopted, properties such as rdfs:seeAlso<a class="fn" href="#fn20" id="foot-fn20"><sup>20</sup></a> or skos:broadMatch might be semantically more appropriate since they indicate a broader matching links.</p>    <p>As an application of our model in underwater CH scenario as Xlendi shipwreck, archaeologists draw a particular intention to the spatial data mining over amphorae which can be particularly helpful to understand the context of the site, i.e. amphora geo-spatial distribution based on their typologies can help to have an idea of the shape of the ship before it flows, the nature and the origin of the cargo. For this purpose, we cite the Drap <em>et al.</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>] tool, which is based on SWRL rules to perform queries over the profiled amphorae within the presented model. This GUI tool allows to produce a 3D representation of CH resources and to observe graphically the computational capabilities over it. Finally, we note that our ontology has been integrated in the linked open vocabularies and is made available for terms reuse on URL<a class="fn" href="#fn21" id="foot-fn21"><sup>21</sup></a>.</p>   </section>   <section id="sec-21">    <header>     <div class="title-info">     <h2>      <span class="section-number">9</span> Conclusion</h2>     </div>    </header>    <p>In this paper we introduce an ontology-based approach for cultural heritage profiling. The approach consists of modeling cultural heritage resources through three different dimensions: (i) typological &#x2014; the set of features representing a typology class of a resource, (ii) photogrammetrical &#x2014; the set of component involved in the photogrammetry process of the resource; and (iii) spatial &#x2014; the set of features that indicate the location of the resource on a 3D space.</p>    <p>We propose an ontology model that provides a set of conceptualizations for ontology terms reuse within the cultural heritage communities, as well as for other communities that are touching the photogrammetrical or spatial 3D field. For better visibility, we published our ontology into the linked open vocabulary repository. Further, we intend to officially publish our archaeological datasets (Xlendi, Shawback, etc) in the datahub repository as a linked open dataset. The next step will be to integrate the LOD cloud by linking our data to other existing datasets, allowing the CH community to perform sophisticated queries in different datasets, i.e. enriching our data by connecting to further amphora typologies from Archaeology Data Service (ADS)<a class="fn" href="#fn22" id="foot-fn22"><sup>22</sup></a>.</p>   </section>  </section>  <section class="back-matter">   <section id="sec-22">    <header>     <div class="title-info">     <h2>ACKNOWLEDGMENTS</h2>     </div>    </header>    <p>The authors would like to thank the iMareCulture project for partially funding this work, URL: <a class="link-inline force-break" href="http://imareculture.weebly.com">http://imareculture.weebly.com</a>. </p>   </section>   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Cristiana Araujo, Ricardo&#x00A0;G. Martini, Pedro&#x00A0;Rangel Henriques, and Jose&#x00A0;Joao Almeida. 2018. <em>      <em>Annotated Documents and Expanded CIDOC-CRM Ontology in the Automatic Construction of a Virtual Museum</em>     </em>. 91&#x2013;110.</li>     <li id="BibPLXBIB0002" label="[2]">Herbert Bay, Andreas Ess, Tinne Tuytelaars, and Luc Van&#x00A0;Gool. 2008. Speeded-Up Robust Features (SURF). <em>      <em>Comput. Vis. Image Underst.</em>     </em>110, 3 (June 2008), 346&#x2013;359.</li>     <li id="BibPLXBIB0003" label="[3]">Mohamed Ben&#x00A0;Ellefi, Zohra Bellahsene, J Breslin, Elena Demidova, Stefan Dietze, Julian Szymanski, and Konstantin Todorov. 2018. Rdf dataset profiling-a survey of features, methods, vocabularies and applications. <em>      <em>Semantic Web</em>     </em> (2018).</li>     <li id="BibPLXBIB0004" label="[4]">L. Bing, K.&#x00A0;C.&#x00A0;C. Chan, and L. Carr. 2014. Using Aligned Ontology Model to Convert Cultural Heritage Resources into Semantic Web. In <em>      <em>2014 IEEE ICSC</em>     </em>. 120&#x2013;123.</li>     <li id="BibPLXBIB0005" label="[5]">Christian Bizer, Tom Heath, and Tim Berners-Lee. 2009. Linked data-the story so far. <em>      <em>Semantic services, interoperability and web applications: emerging concepts</em>     </em> (2009), 205&#x2013;227.</li>     <li id="BibPLXBIB0006" label="[6]">Olivier Cure, Mariette S&#x00E9;rayet, Odile Papini, and Pierre Drap. [n. d.]. Toward a novel application of CIDOC CRM to underwater archaeological surveys. In <em>      <em>ICSC, 2010, IEEE</em>     </em>. 519&#x2013;524.</li>     <li id="BibPLXBIB0007" label="[7]">Martin Doerr. 2003. The CIDOC conceptual reference module: an ontological approach to semantic interoperability of metadata. <em>      <em>AI magazine</em>     </em>24, 3 (2003), 75.</li>     <li id="BibPLXBIB0008" label="[8]">Martin Doerr. 2009. Ontologies for cultural heritage. In <em>      <em>Handbook on Ontologies</em>     </em>. 463&#x2013;486.</li>     <li id="BibPLXBIB0009" label="[9]">Pierre Drap, Djamal Merad, Bilal Hijazi, Lamia Gaoua, Mohamad&#x00A0;Motasem Nawaf, Mauro Saccone, Bertrand Chemisky, Julien Seinturier, Jean-Christophe Sourisseau, Timmy Gambin, <em>et al.</em> 2015. Underwater photogrammetry and object modeling: a case study of Xlendi Wreck in Malta. <em>      <em>Sensors</em>     </em>15, 12 (2015), 30351&#x2013;30384.</li>     <li id="BibPLXBIB0010" label="[10]">Pierre Drap, Odile Papini, Elisa Pruno, Micchele Nucciotti, and Guido Vannini. 2017. Ontology-Based Photogrammetry Survey for Medieval Archaeology: Toward a 3D Geographic Information System (GIS). <em>      <em>Geosciences</em>     </em>7, 4 (2017).</li>     <li id="BibPLXBIB0011" label="[11]">Pierre Drap, Odile Papini, Jean-Chrisophe Sourisseau, and Timmy Gambin. 2017. Ontology-Based Photogrammetric Survey in Underwater Archaeology. In <em>      <em>ESWC</em>     </em>.</li>     <li id="BibPLXBIB0012" label="[12]">Panorea Gaitanou, Manolis Gergatsoulis, Dimitrios Spanoudakis, Lina Bountouri, and Christos Papatheodorou. [n. d.]. <em>      <em>Mapping the Hierarchy of EAD to VRA Core4.0 Through CIDOC CRM</em>     </em>. 193&#x2013;204.</li>     <li id="BibPLXBIB0013" label="[13]">Nicola Guarino, Daniel Oberle, and Steffen Staab. 2009. What is an Ontology?In <em>      <em>Handbook on ontologies</em>     </em>. Springer, 1&#x2013;17.</li>     <li id="BibPLXBIB0014" label="[14]">Harry Halpin and Patrick&#x00A0;J Hayes. 2010. When owl: sameAs isn&#x0027;t the Same: An Analysis of Identity Links on the Semantic Web.. In <em>      <em>LDOW</em>     </em>.</li>     <li id="BibPLXBIB0015" label="[15]">Gerald Hiebel, Martin Doerr, and &#x00D8;yvind Eide. 2016. CRMgeo: A spatiotemporal extension of CIDOC-CRM. <em>      <em>Int. J. Digit. Libr.</em>     </em>(2016).</li>     <li id="BibPLXBIB0016" label="[16]">Gerald Hiebel, Martin Doerr, Klaus Hanke, and Anja Masur. 2014. How to put archaeological geometric data into context? Representing mining history research with CIDOC CRM and extensions. <em>      <em>Int. J. Digit. Libr.</em>     </em>3, 3 (2014), 557&#x2013;578.</li>     <li id="BibPLXBIB0017" label="[17]">Gerald Hiebel, Klaus Hanke, and Ingrid Hayek. 2010. Methodology for CIDOC CRM Based Data Integration with Spatial Data. In <em>      <em>CAA</em>     </em>. Melero, F.J., Cano, P., Revelles, J., Granada.</li>     <li id="BibPLXBIB0018" label="[18]">Giorgia Lodi, Luigi Asprino, Andrea&#x00A0;Giovanni Nuzzolese, Valentina Presutti, Aldo Gangemi, Diego&#x00A0;Reforgiato Recupero, Chiara Veninata, and Annarita Orsini. 2017. <em>      <em>Semantic Web for Cultural Heritage Valorisation</em>     </em>. Cham, 3&#x2013;37.</li>     <li id="BibPLXBIB0019" label="[19]">David&#x00A0;G Lowe. 1999. Object recognition from local scale-invariant features. In <em>      <em>ICCV, 1999. IEEE</em>     </em>, Vol.&#x00A0;2. 1150&#x2013;1157.</li>     <li id="BibPLXBIB0020" label="[20]">David&#x00A0;G. Lowe. 2004. Distinctive Image Features from Scale-Invariant Keypoints. <em>      <em>Int. J. Comput. Vision</em>     </em>60, 2 (Nov. 2004), 91&#x2013;110.</li>     <li id="BibPLXBIB0021" label="[21]">Cheikh Niang, Claudia Marinica, Beatrice Markhoff, Elise Leboucher, Olivier Malavergne, Luc Bouiller, Claude Darrieumerlou, and Francois Laissus. 2017. Supporting Semantic Interoperability in Conservation-Restoration Domain: The PARCOURS Project. <em>      <em>J. Comput. Cult. Herit.</em>     </em>10, 3, Article 16 (July 2017), 20&#x00A0;pages.</li>     <li id="BibPLXBIB0022" label="[22]">Franco Niccolucci and Sorin Hermon. 2016. Expressing reliability with CIDOC CRM. <em>      <em>Int. Journal on Digital Libraries</em>     </em>(2016).</li>     <li id="BibPLXBIB0023" label="[23]">David Nist&#x00E9;r. 2004. An Efficient Solution to the Five-Point Relative Pose Problem. <em>      <em>IEEE Trans. Pattern Anal. Mach. Intell.</em>     </em>26, 6 (June 2004), 756&#x2013;777.</li>     <li id="BibPLXBIB0024" label="[24]">Francesca Noardo. 2017. <em>      <em>A Spatial Ontology for Architectural Heritage Information</em>     </em>. Cham, 143&#x2013;163.</li>     <li id="BibPLXBIB0025" label="[25]">J&#x00E9;r&#x00F4;me Pasquet, Stella Demesticha, Dimitrios Skarlatos, Djamal Merad, and Pierre Drap. 2017. Amphora Detection Based on a Gradient Weighted Error in a Convolution Neuronal Network. <em>      <em>IMEKO</em>     </em> (2017).</li>     <li id="BibPLXBIB0026" label="[26]">Anne-Sophie Poulin-Girard, Simon Thibault, and Denis Laurendeau. 2016. Influence of camera calibration conditions on the accuracy of 3D reconstruction. <em>      <em>Optics express</em>     </em>24, 3 (2016), 2678&#x2013;2686.</li>     <li id="BibPLXBIB0027" label="[27]">Paola Ronzino, Franco Niccolucci, Achille Felicetti, and Martin Doerr. 2016. CRMba a CRM extension for the documentation of standing buildings. <em>      <em>Int. J. Digit. Libr.</em>     </em>17, 1 (2016), 71&#x2013;78.</li>     <li id="BibPLXBIB0028" label="[28]">Mariette Serayet. 2010. <em>Raisonnement &#x00E0; partir d&#x0027;informations structur&#x00E9;es et hi&#x00E9;rarchis&#x00E9;es: application &#x00E0; l&#x0027;information arch&#x00E9;ologique</em>. Ph.D. Dissertation. Aix-Marseille.</li>     <li id="BibPLXBIB0029" label="[29]">Mariette S&#x00E9;rayet, Pierre Drap, and Odile Papini. 2009. Encoding the Revision of Partially Preordered Information in Answer Set Programming.. In <em>      <em>ECSQARU</em>     </em>. Springer, 421&#x2013;433.</li>     <li id="BibPLXBIB0030" label="[30]">Nigam Shah and Mark Musen. 2009. Ontologies for formal representation of biological systems. In <em>      <em>Handbook on Ontologies</em>     </em>. 445&#x2013;461.</li>     <li id="BibPLXBIB0031" label="[31]">Steffen Staab and Rudi Studer. 2010. <em>      <em>Handbook on ontologies</em>     </em>.</li>     <li id="BibPLXBIB0032" label="[32]">N. Sunderhauf, Kurt Konolige, S. Lacroix, and P. Protzel. 2005. <em>      <em>Visual Odometry using Sparse Bundle Adjustment on an Autonomous Outdoor Vehicle</em>     </em>.</li>     <li id="BibPLXBIB0033" label="[33]">Junpeng Xue and Xianyu Su. 2012. A new approach for the bundle adjustment problem with fixed constraints in stereo vision. <em>      <em>Optik - Int. J. for Light and Electron Optics</em>     </em>123, 21 (2012), 1923 &#x2013; 1927.</li>     <li id="BibPLXBIB0034" label="[34]">Junjie Yu, Changhe Zhou, Yancong Lu, Jun Wu, Linwei Zhu, and Wei Jia. 2015. Square lattices of quasi-perfect optical vortices generated by two-dimensional encoding continuous-phase gratings. <em>      <em>Optics letters</em>     </em>40, 11 (2015), 2513&#x2013;2516.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1a">This is the corresponding author email: <a class="link-inline force-break" href="mailto:mohammed.ben-ellefi@lis-lab.fr">mohammed.ben-ellefi@lis-lab.fr</a></p>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class="link-inline force-break" href="https://en.wikipedia.org/wiki/Ontology">https://en.wikipedia.org/wiki/Ontology</a>   </p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break" href="https://www.w3.org/TR/webont-req/">https://www.w3.org/TR/webont-req/</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a><a class="link-inline force-break" href="http://comex.fr">http://comex.fr</a>   </p>   <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a><a class="link-inline force-break" href="http://www.agisoft.com/">http://www.agisoft.com/</a>   </p>   <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a><a class="link-inline force-break"     href="https://en.wikipedia.org/wiki/Data_profiling">https://en.wikipedia.org/wiki/Data_profiling</a>   </p>   <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a><a class="link-inline force-break"     href="https://archaeologywordsmith.com/lookup.php?category=&#x0026;where=headwordterms=profile">https://archaeologywordsmith.com/lookup.php?category=&#x0026;where=headwordterms=profile</a>   </p>   <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a><a class="link-inline force-break" href="https://www.w3.org/TR/owl2-overview/">https://www.w3.org/TR/owl2-overview/</a>   </p>   <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a>degree of collapsing=0 in <a class="link-inline force-break" href="http://visualdataweb.de/webvowl">http://visualdataweb.de/webvowl</a>   </p>   <p id="fn9"><a href="#foot-fn9"><sup>9</sup></a><a class="link-inline force-break"     href="http://erlangen-crm.org/current/E54_Dimension">http://erlangen-crm.org/current/E54_Dimension</a>   </p>   <p id="fn10"><a href="#foot-fn10"><sup>10</sup></a><a class="link-inline force-break"     href="https://datahub.ckan.io/dataset/xlendiamphorae">https://datahub.ckan.io/dataset/xlendiamphorae</a>   </p>   <p id="fn11"><a href="#foot-fn11"><sup>11</sup></a><a class="link-inline force-break" href="http://lod-cloud.net/">http://lod-cloud.net/</a>   </p>   <p id="fn12"><a href="#foot-fn12"><sup>12</sup></a><a class="link-inline force-break"     href="http://www.opengeospatial.org/standards/geosparql">http://www.opengeospatial.org/standards/geosparql</a>   </p>   <p id="fn13"><a href="#foot-fn13"><sup>13</sup></a><a class="link-inline force-break" href="http://www.w3.org/2008/05/skos">http://www.w3.org/2008/05/skos</a>   </p>   <p id="fn14"><a href="#foot-fn14"><sup>14</sup></a>Searching the term &#x201D;photogrammetry&#x201D; in LOV: <a class="link-inline force-break"     href="http://lov.okfn.org/dataset/lov/terms?q=photogrammetry">http://lov.okfn.org/dataset/lov/terms?q=photogrammetry</a>   </p>   <p id="fn15"><a href="#foot-fn15"><sup>15</sup></a><a class="link-inline force-break"     href="http://semanticscience.org/resource/SIO_000082.rdf">http://semanticscience.org/resource/SIO_000082.rdf</a>   </p>   <p id="fn16"><a href="#foot-fn16"><sup>16</sup></a><a class="link-inline force-break" href="http://dbpedia.org/ontology/Camera">http://dbpedia.org/ontology/Camera</a>   </p>   <p id="fn17"><a href="#foot-fn17"><sup>17</sup></a><a class="link-inline force-break" href="http://lod-cloud.net/">http://lod-cloud.net/</a>   </p>   <p id="fn18"><a href="#foot-fn18"><sup>18</sup></a><a class="link-inline force-break"     href="http://dbpedia.org/class/yago/Camera102942699">http://dbpedia.org/class/yago/Camera102942699</a>   </p>   <p id="fn19"><a href="#foot-fn19"><sup>19</sup></a><a class="link-inline force-break" href="http://dbpedia.org/page/Nikon_D100">http://dbpedia.org/page/Nikon_D100</a>   </p>   <p id="fn20"><a href="#foot-fn20"><sup>20</sup></a><a class="link-inline force-break" href="https://www.w3.org/TR/rdf-schema">https://www.w3.org/TR/rdf-schema</a>   </p>   <p id="fn21"><a href="#foot-fn21"><sup>21</sup></a><a class="link-inline force-break"     href="http://lov.okfn.org/dataset/lov/vocabs/arp">http://lov.okfn.org/dataset/lov/vocabs/arp</a>   </p>   <p id="fn22"><a href="#foot-fn22"><sup>22</sup></a><a class="link-inline force-break"     href="http://data.archaeologydataservice.ac.uk/">http://data.archaeologydataservice.ac.uk/</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, Companion, April 23&#x2013;27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3191598">https://doi.org/10.1145/3184558.3191598</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
