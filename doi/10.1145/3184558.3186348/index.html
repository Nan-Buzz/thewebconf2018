<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Pain Prediction in Humans Using Human Brain Activity Data</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a HTML copy of <a href='https://doi.org/10.1145/3184558.3186348'>https://doi.org/10.1145/3184558.3186348</a> 
originally published by ACM, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML accessability, compatibility, 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3186348'>https://w3id.org/oa/10.1145/3184558.3186348</a>
</p></div>
<hr>

  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Pain Prediction in Humans Using Human Brain Activity Data</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Zara</span>      <span class="surName">Mansoor</span>,     Department of Software Engineering, University of Engineering and Technology, Taxila, Pakistan, <a href="mailto:mustansar.ali@uettaxila.edu.pk">mustansar.ali@uettaxila.edu.pk</a>         </div>         <div class="author">     <span class="givenName">Mustansar Ali</span>      <span class="surName">Ghazanfar</span>,     Department of Software Engineering, University of Engineering and Technology, Taxila, Pakistan, <a href="mailto:mustansar.ali@uettaxila.edu.pk">mustansar.ali@uettaxila.edu.pk</a>         </div>         <div class="author">     <span class="givenName">Syed Muhammad</span>      <span class="surName">Anwar</span>,     Department of Software Engineering, University of Engineering and Technology, Taxila, Pakistan, <a href="mailto:s.anwar@uettaxila.edu.pk">s.anwar@uettaxila.edu.pk</a>         </div>         <div class="author">     <span class="givenName">Ahmed S.</span>      <span class="surName">Alfakeeh</span>,     Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia, <a href="mailto:asalfakeeh@kau.edu.sa">asalfakeeh@kau.edu.sa</a>         </div>         <div class="author">     <span class="givenName">Khaled H.</span>      <span class="surName">Alyoubi</span>,     Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia, <a href="mailto:kalyoubi@kau.edu.sa">kalyoubi@kau.edu.sa</a>         </div>        </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3186348" target="_blank">https://doi.org/10.1145/3184558.3186348</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>This research article focuses on the analysis of electroencephalography (EEG) signals of the brain during pain perception. The proposed system is based on the hypothesis that a noticeable change occurs in mental conditions while experiencing pain. When the human body is injured, sensory receptors in the brain enter a stimulated state. The injury may be the result of attention or an accident. Pain warnings are natural in humans and protect the body from further negative effects. In this article, an innovative and robust system based on prominent features extracted from the brain activity recorded using EEG, is proposed to predict the state of pain perception. The brain signals of subjects are observed using two low-cost EEG headsets including neurosky mindwave mobile and emotiv insight. Time and frequency domain features are selected to represent the observed signals. The results show that a combination of time and frequency domain features is the most informative approach for pain prediction using the observed brain activity.</small>     </p>    </div>    <div class="classifications">     <div class="keyword">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>EEG analysis</small>, </span>     <span class="keyword">      <small>Pain prediction</small>, </span>     <span class="keyword">      <small>KNN</small>, </span>     <span class="keyword">      <small>SVM</small>, </span>     <span class="keyword">      <small>Time domain</small>, </span>     <span class="keyword">      <small>Frequency domain</small>, </span>     <span class="keyword">      <small>Classification</small>, </span>     <span class="keyword">      <small>Accuracy</small>, </span>     <span class="keyword">      <small>Prediction</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>Zara Mansoor, Mustansar Ali Ghazanfar, Syed Muhammad Anwar, Ahmed S. Alfakeeh and Khaled H. Alyoubi. 2018. Pain Prediction in Humans Using Human Brain Activity Data <em>. In Proceedings of The 2018 Web Conference Companion (WWW'2018 Companion)</em>. ACM, New York, NY, USA, 9 pages. <a href="https://doi.org/10.1145/3184558.3186348" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3186348</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-001">    <header>     <div class="title-info">     <h2>Introduction</h2>     </div>    </header>    <p>Brain cells communicate with each other via electrical impulses and remain active during sleep. Electroencephalography (EEG) is an important tool in the field of neurophysiology due to its capability to capture normal and abnormal activities of the brain. EEG activities in the brain can be used to determine different mental states. Examples of such mental states include stress and pain level while a patient in comas or for neonates, who are unable to communicate verbally [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib1">1</a>,<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib2">2</a>]. There are several factors of critical care that can alter verbal communication with patients, such as consciousness level changes, machine-driven ventilation and the administration of tranquilizing agents. Physiological and behavioral aspects are observable indicators of pain and can be used by medical professionals to assess the level of pain.</p>    <p>Pain is a distributed process that occurs in different brain areas, which makes observing pain a complex and challenging task. Subjective pain cannot be accessed from any individual area. This causes challenges for practitioner because it is difficult to determine how different areas and their interactions contribute to pain processing. Patrick et al. used the UNBC-McMaster database to predict and detect pain at a frame-by-frame level based on action units (AUs) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib3">3</a>]. In automatic detection systems, active appearance models are used to extract visual features and track the face [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib3">3</a>]. Philipp Werner et al. studied facial expressions related to pain and its intensities [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib5">5</a>]. They employed a linear intensity model trained using a comparative learning technique for labeling along with Support Vector Machine (SVM) classifier. They evaluated their concept using the Hi4D-ADSIP database [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib4">4</a>,<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib5">5</a>]. Maryam Vatankhah et al. differentiated between three levels of pain namely no pain, pain, and intolerant pain [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib6">6</a>]. Their research showed that the brain patterns change significantly under chronic pain conditions. Maria et al. showed that multivariate pattern analysis decoding captures the multivariate nature of brain processing, which has a reverberation with concepts of pain processing. Meenakshi et al. utilised EEG recordings for the prediction of pain experienced by epilepsy patients by considering three states of patients, i.e. normal, pre-ictal and seizures [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib7">7</a>]. Yiheng Tu et al. employed a multivariate pattern analysis in the time frequency domain for the prediction of pain from laser-evoked EEG oscillatory activities. The MVPA approach was used to study the relationship between pain intensity and time frequency EEG data, after that features were selected for the prediction of pain [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib8">8</a>]. Gan Huang et al. developed a novel approach based on a multiple linear regression (MLR) and common spatial pattern (CSP) for the detection of pain-related laser-evolved potentials (LEPs) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib9">9</a>]. Yiheng Tu et al. proposed a Principal Component Analysis and Sliced Inverse Regression for analysing EEG data for subjective pain prediction [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib10">10</a>]. Rony-Reuven et al. experimentally observed that the alpha-1 power as a direction and objective measure of tonic pain. The EEG signals were recorded using a 32Ag/Agcl electrode cap. The study revealed that the alpha power is sensitive to cognitive tasks, decreasing with object recognition, decision-making, reading sentences and arithmetic tasks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib11">11</a>].</p>    <p>This study aims to design an EEG-based system for the assessment of pain in patients. The most important issue related to EEGs is the cost of output channels. Many channels have been used in experimental setups using an EEG headset [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib8">8</a>,<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib12">12</a>]. The implementation of a large amount of data and experimental setup makes classification complex and costly. The brain signals of subjects were captured using a neurosky mindwave mobile headset and an emotiv insight headset. Pain perception was predicted for pain evoked from hot and cold sensing states. The proposed study confirmed the hypothesis that brain patterns are mapped by an EEG under the mental pain task, and thus the brain patterns identified by the EEG are reliable for detecting, measuring, and diagnosing pain in humans.</p>   </section>   <section id="sec-002">    <header>     <div class="title-info">     <h2>Methodology</h2>     </div>    </header>    <p>The steps followed during the proposed methodology are shown in <a class="fig" href="#fig1">Fig. 1</a>. Detail methodology is presented in the following subsections.</p>    <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186348/images/image1.jpg" class="img-responsive" alt="Figure 1:" longdesc=""/>     <div class="figure-caption">     <span class="figure-number">Figure 1:</span>     <span class="figure-title">Methodology of the proposed system.</span>     </div>    </figure>    <section id="sec2Z1">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Preprocessing</h3>     </div>     </header>     <p>There could be many reasons for noisy signals, such as eye blinking, scalp contamination, body movement and electrode noise. There are several types of noisy signals, such as DC offset, baseline movement and other external noises [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#bib12">12</a>]. All types of noise were removed to filter the signal of interest. While recording the EEG signal, noise is added to the original signal due to muscle movement, eye blinking and other external factors. The amplitude of the original signal slowly drifted. To address this problem, mean subtracted data were obtained. The arbitrary number obtained was the mean value of each channel that was added to the absolute channel signal and was then subtracted. The data recorded using emotiv insight required no noise removal procedures, as the device was built in the CMS/DRL noise dissolution configuration to produce clean and robust signals.</p>    </section>    <section id="sec2Z2">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Feature Extraction and Selection</h3>     </div>     </header>     <p>Twelve important features were selected. These features were the most common for each set of data. Different mental states are associated with different frequency rhythms of EEGs. Gamma, theta, beta, and delta rhythms depict stress, anxiety, high arousal, and hyperactivity [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#bib13">13</a>]. The noticeable features of all bands were selected to collect information about the subject&#x0027;s mental state during tonic hot and cold conditions. These features included the statistical, time domain and frequency domain features of EEGs as shown in Table <a class="tbl" href="#tb1">1</a>. Detailed mathematical information for these features is presented in Appendix A.</p>     <div class="table-responsive" id="tb1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">Selected features for pain prediction.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:center;">        <strong>Sr. No</strong>        </th>        <th style="text-align:center;">        <strong>Extracted Features</strong>        </th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">1</td>        <td style="text-align:center;">Maximum Amplitude</td>       </tr>       <tr>        <td style="text-align:center;">2</td>        <td style="text-align:center;">Minimum Amplitude</td>       </tr>       <tr>        <td style="text-align:center;">3</td>        <td style="text-align:center;">Peak to Peak Amplitude</td>       </tr>       <tr>        <td style="text-align:center;">4</td>        <td style="text-align:center;">Peak to Peak time</td>       </tr>       <tr>        <td style="text-align:center;">5</td>        <td style="text-align:center;">Variance of Signal</td>       </tr>       <tr>        <td style="text-align:center;">6</td>        <td style="text-align:center;">Energy of Signal</td>       </tr>       <tr>        <td style="text-align:center;">7</td>        <td style="text-align:center;">Power of Signal</td>       </tr>       <tr>        <td style="text-align:center;">8</td>        <td style="text-align:center;">Mean of Signal</td>       </tr>       <tr>        <td style="text-align:center;">9-10</td>        <td style="text-align:center;">Hjorths&#x2019; Parameters</td>       </tr>       <tr>        <td style="text-align:center;">11</td>        <td style="text-align:center;">Mean Frequency</td>       </tr>       <tr>        <td style="text-align:center;">12</td>        <td style="text-align:center;">Variance in Frequency</td>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec2Z3">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.3</span> Classification</h3>     </div>     </header>     <p>For classification, cross validation was applied to the data to make the system robust against overfitting. The data samples were randomly divided into 70% training and 30% test sets. To classify the data, SVM and K-Nearest Neighbors (KNN) were applied to the two sets of data, one from the neurosky mindwave and the other from the emotiv insight. They are used to observe the results and to compare the accuracy of the proposed system. The details of these classification algorithms are presented in the following subsections.</p>     <section id="sec2Z3Z1">     <p><em>2.3.1 K-Nearest Neighbors (KNN).</em> KNN is a supervised non-parametric learning classifier. It is a simple method used to classify new observations based on nearest neighbors. The testing point distance is calculated from all training instances. Based on the minimum sample distance, k training samples are considered and labeled. The majority class is assigned to the test sample. Various methods can be used to calculate the distance between two samples, such as Euclidean distance, Manhattan and City block. Euclidean distance was used for the proposed system.</p>     </section>     <section id="sec2Z3Z2">     <p><em>2.3.2 Support Vector Machines (SVM).</em> Support vector machines minimize the upper limit of generalization errors via maximizing the margin that separates the hyperplane and data. Basically, SVMs learn a linear decision rule, <em>h</em>(<em>x</em>) = <em>sign</em> {<em>wx</em> + <em>b</em>}, where &#x2018;w&#x2019; is a weight vector, and &#x2018;b&#x2019; is the threshold. It takes n examples from the training set as input: <div class="table-responsive" id="eqn1">       <div class="display-equation">        <span class="tex mytex">\begin{equation}Sn = {\rm{ }}\left( {\left( {x1,y1} \right),{\rm{ }}...{\rm{ }},\left( {xn,yn} \right)} \right),xi \in RN,yi \in \left\{ { - 1, + 1} \right\}\end{equation} </span>        <br/>        <span class="equation-number">(1)</span>       </div>      </div>     </p>     <p>For a linearly separable input set <em>Sn</em>, the SVM searches for an optimal margin hyperplane that separates the closest training examples with a maximum Euclidian distance and solves the optimization problem. By introducing the soft margin hyperplane, SVM constructs the hyperplane with a maximum margin with some training errors, and a penalty term is added to the minimization problem. For a multi-class classification problem, SVM treats it as a collection of various binary classification problems. The linear SVM was used in this study.</p>     </section>    </section>   </section>   <section id="sec-003">    <header>     <div class="title-info">     <h2>Experimental Setup</h2>     </div>    </header>    <p>The experimental setup is shown in Figure <a class="fig" href="#fig2">2</a>. Thirty right-handed healthy volunteers with a mean age of 22&#x00B1;5 years old participated in this study. Each subject was placed at 1 mm from a computer display, placed on a white cross with a black background and seated on an upright chair in a controlled temperature (24-26 &#x00B0;C) under hazy illumination conditions to avoid any visual annoyance. The eyes remained open in a pain incentive condition. The experimental trial was initiated by placing a 0.51-inch plastic bottle on a table to minimalize inconsistencies in the subjects&#x2019; command strength. The subjects were asked to hold the bottle with iced cold water (-1 &#x00B0;C &#x00B1; 0.5 &#x00B0;C) with his/her dominant hand while simultaneously clicking the computer mouse (click0) with his/her non-dominant hand to initiate the experiment. At the instant the subject felt slightly uncomfortable, they clicked the mouse (click1) to indicate the end of a relaxed state and the beginning of the pain state. Then, the subjects continued to hold the bottle until the pain became intolerable, and they could release the bottle at will. During the second step, the subjects were asked to hold a cup of warm water (50-90 &#x00B0;C) with their dominant hand. This was done to lessen the inconsistencies in arousal, vigilance and attention between and within subjects as well as to control the innocuous pressure sensation associated with holding a warm water cup with their hands [14]. The temperature of the beaker was checked using a temperature sensor. Each trial&#x0027;s total duration was a maximum of three minutes.</p>    <figure id="fig2">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186348/images/image3.jpg" class="img-responsive" alt="Figure 2:" longdesc=""/>     <div class="figure-caption">     <span class="figure-number">Figure 2:</span>     <span class="figure-title">The experimental setup used to record EEG signals.</span>     </div>    </figure>    <p>The EEG recordings were conducted using the emotiv EPOC 5-channel EEG wireless recording headset (Emotiv Systems Inc., San Francisco, CA, USA) and a neurosky mindwave mobile headset. The electrode system was placed according to the international 10-20 system referenced to the ear lobe. EEG data acquired using the 5-channel were at an internal sampling frequency of 128 samples per second per channel with a high pass filter. Later, the data acquired using the neurosky mindwave mobile headset was set at an internal sampling frequency of one sample per second. Special care was taken in recording observations, as no EEG cap was used for the headsets to be adjusted in a suitable manner to each subject&#x0027;s head. To reduce the occipital and muscular artefacts, all subjects were instructed to remain as immobile as possible and to concentrate on the cross shown on the display.</p>   </section>   <section id="sec4">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span>      <SmallCap/>Results and Discussion</h2>     </div>    </header>    <section id="sec4Z1">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Signal Acquisition</h3>     </div>     </header>     <p>A puzzle box synapse provides eight frequency bands in which the level of attention and mediation are additional factors. The obtained frequency bands are transformed into a time domain. Emotiv insight captures signals using five channels, AF3, AF4, T7, T8 and Pz, with two reference electrodes. Using the bandpass butter worth filter of order 2, five EEG bands were extracted. After acquiring the signals, the attention and mediation values were discarded, as the main focus was the bands of signals.</p>    </section>    <section id="sec4Z2">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Analysis of Selected Features</h3>     </div>     </header>     <p>The selected features were divided into three subsets, as shown in Table <a class="tbl" href="#tb2">2</a>. Further experiments were performed on them separately. The performance of each classifier was evaluated using the Receiver Operating Characteristics (ROC) curve, accuracy, sensitivity and specificity metrics [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#bib15">15</a>]. Set 1 contained all features for both the time and frequency domains, Set 2 contained features of the time domain and Set 3 consisted of features of the frequency domain.</p>     <div class="table-responsive" id="tb2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Subsets of the selected features.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:center;">        <strong>Set 1All Features</strong>        </th>        <th style="text-align:center;">        <strong>Set 2Time Domain Features</strong>        </th>        <th style="text-align:center;">        <strong>Set 3Frequency Domain Features</strong>        </th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">Mean<br/>Variance<br/>Power<br/>Energy<br/>Maximum amplitude<br/>Minimum amplitude<br/>Peak to peak time<br/>Peak to peak value<br/>Hjorth&#x0027;s parameters<br/>Mean fft<br/>Variance fft<br/>        </td>        <td style="text-align:center;">Mean<br/>Variance<br/>Power<br/>Energy<br/>Maximum amplitude<br/>Minimum amplitude<br/>Peak to peak time<br/>Peak to peak value<br/>Hjorth&#x0027;s parameters</td>        <td style="text-align:center;">Mean fft<br/>Variance fft<br/>        </td>       </tr>      </tbody>     </table>     </div>     <p>The features were explored in both domains to analyze their impact on pain prediction. For the time domain, mean frequency, power spectrum and changes in frequency were represented by Hjorth parameters. In the first set, these parameters were removed to determine their effects on both types of signals. The results showed that the signals captured using neurosky had no effect, while the accuracy decreased to 88.88% in the signals captured using emotiv insight. SVM and KNN algorithms were applied to the three subsets separately. We used these classifiers as they have been widely used in literature [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#bib20">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#bib21">21</a>].</p>     <p>For the single channel neurosky mindwave (Tables <a class="tbl" href="#tb5">5</a> and 6), the sensitivity was higher relative to specificity for KNN, while for SVM, the specificity was higher relative to sensitivity. For emotiv insight (Tables <a class="tbl" href="#tb3">3</a> and <a class="tbl" href="#tb4">4</a> ), KNN showed a high specificity relative to sensitivity, while SVM showed a high sensitivity relative to specificity.</p>     <div class="table-responsive" id="tb3">     <div class="table-caption">      <span class="table-number">Table 3:</span>      <span class="table-title">Sensitivity of each classifier for emotiv insight.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">Features\Classifier</th>        <th style="text-align:center;">SVM</th>        <th style="text-align:center;">KNN</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">Set 1</td>        <td style="text-align:center;">        <strong>100%</strong>        </td>        <td style="text-align:center;">40%</td>       </tr>       <tr>        <td style="text-align:center;">Set 2</td>        <td style="text-align:center;">90%</td>        <td style="text-align:center;">        <strong>60%</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Set 3</td>        <td style="text-align:center;">100%</td>        <td style="text-align:center;">40%</td>       </tr>      </tbody>     </table>     </div>     <div class="table-responsive" id="tb4">     <div class="table-caption">      <span class="table-number">Table 4:</span>      <span class="table-title">Specificity of each classifier for emotiv insight.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">Features\Classifier</th>        <th style="text-align:center;">SVM</th>        <th style="text-align:center;">KNN</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">Set 1</td>        <td style="text-align:center;">        <strong>100%</strong>        </td>        <td style="text-align:center;">        <strong>100%</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Set 2</td>        <td style="text-align:center;">80%</td>        <td style="text-align:center;">100%</td>       </tr>       <tr>        <td style="text-align:center;">Set 3</td>        <td style="text-align:center;">75%</td>        <td style="text-align:center;">100%</td>       </tr>      </tbody>     </table>     </div>     <div class="table-responsive" id="tb5">     <div class="table-caption">      <span class="table-number">Table 5:</span>      <span class="table-title">Sensitivity of each classifier for neurosky mind wave.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">Features\Classifier</th>        <th style="text-align:center;">SVM</th>        <th style="text-align:center;">KNN</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">Set 1</td>        <td style="text-align:center;">        <strong>100%</strong>        </td>        <td style="text-align:center;">        <strong>100%</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Set 2</td>        <td style="text-align:center;">100%</td>        <td style="text-align:center;">70%</td>       </tr>       <tr>        <td style="text-align:center;">Set 3</td>        <td style="text-align:center;">50%</td>        <td style="text-align:center;">60%</td>       </tr>      </tbody>     </table>     </div>     <div class="table-responsive" id="Utb6">     <div class="table-caption">      <span class="table-number">Table 6</span>      <span class="table-title">: Specificity of each classifier for neurosky mindwave.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">Features\Classifier</th>        <th style="text-align:center;">SVM</th>        <th style="text-align:center;">KNN</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">Set 1</td>        <td style="text-align:center;">        <strong>100%</strong>        </td>        <td style="text-align:center;">80%</td>       </tr>       <tr>        <td style="text-align:center;">Set 2</td>        <td style="text-align:center;">80%</td>        <td style="text-align:center;">        <strong>90%</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Set 3</td>        <td style="text-align:center;">100%</td>        <td style="text-align:center;">50%</td>       </tr>      </tbody>     </table>     </div>     <p>Tables <a class="tbl" href="#tb7">7</a> and <a class="tbl" href="#tb8">8</a> evaluate the classifiers in a more specific manner. Accuracy (classification rates) was used to identify the best feature set for the original data.</p>     <div class="table-responsive" id="tb7">     <div class="table-caption">      <span class="table-number">Table 7:</span>      <span class="table-title">Percentage Accuracy of classifiers for all sets of features for neuro sky mind wave. Data represented by Set 1 are more accurately classified by both classifiers.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">Features\Classifiers</th>        <th style="text-align:center;">SVM</th>        <th style="text-align:center;">KNN</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">Set 1</td>        <td style="text-align:center;">        <strong>100%</strong>        </td>        <td style="text-align:center;">        <strong>100%</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Set 2</td>        <td style="text-align:center;">85%</td>        <td style="text-align:center;">99.99%</td>       </tr>       <tr>        <td style="text-align:center;">Set 3</td>        <td style="text-align:center;">85%</td>        <td style="text-align:center;">88.88%</td>       </tr>      </tbody>     </table>     </div>     <div class="table-responsive" id="tb8">     <div class="table-caption">      <span class="table-number">Table 8:</span>      <span class="table-title">Percentage Accuracy of classifiers for all sets of features for emotiv insight. Data represented by Set 1 are more accurately classified by both classifiers.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">Features\Classifiers</th>        <th style="text-align:center;">SVM</th>        <th style="text-align:center;">KNN</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">Set 1</td>        <td style="text-align:center;">        <strong>99%</strong>        </td>        <td style="text-align:center;">66.66%</td>       </tr>       <tr>        <td style="text-align:center;">Set 2</td>        <td style="text-align:center;">99.9%</td>        <td style="text-align:center;">        <strong>77.77%</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Set 3</td>        <td style="text-align:center;">88.88%</td>        <td style="text-align:center;">77.77%</td>       </tr>      </tbody>     </table>     </div>     <p>In set 1, both time and frequency domain features were kept and classified. SVM yielded a high accuracy for both headsets, and KNN, which yielded the same high accuracy for the neurosky mindwave but not for the emotiv insight. For set 2 (time domain features), SVM showed a high accuracy for the emotiv, and KNN showed a high accuracy for time domain statistical features for the neurosky mindwave headset. For set 3 (frequency domain features), KNN indicated a high accuracy for the neurosky mindwave headset, while the accuracy of SVM was good for both headsets but lower than that of the former.</p>     <p>After the comparison of the two classifiers for all three feature sets, it was concluded that the features in set 1 were the best features for the proposed model. SVM yielded the best results for set 1 for both headsets. KNN showed good results for the neurosky mindwave but not for the emotiv of set 1. For Set 2, SVM showed a high accuracy for the emotiv insight, while KNN showed a good accuracy for the neurosky mindwave headset. For Set 3, KNN indicated a high accuracy for the neurosky mind wave headset, and SVM yielded good results for both headsets, although lower than that for the former feature sets. The reason for sets 1 and 2 yielding the best results is that time domain statistical features, especially the Hjorth parameters, were vigorous against non-stationaries and overfitting. A comparison of the proposed method in terms of accuracy and devices used for EEG recording is presented in Table <a class="tbl" href="#tb9">9.</a>     </p>     <div class="table-responsive" id="tb9">     <div class="table-caption">      <span class="table-number">Table 9:</span>      <span class="table-title">A comparison of the proposed method with other state-of-the-art methods.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:center;">        <strong>Method</strong>        </th>        <th style="text-align:center;">        <strong>Year</strong>        </th>        <th style="text-align:center;">        <strong>Device</strong>        </th>        <th style="text-align:center;">        <strong>Accuracy</strong>        </th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">        <strong>Proposed</strong>        <br/>        </td>        <td style="text-align:center;">        <strong>2016</strong>        </td>        <td style="text-align:center;">        <strong>Neurosky mindwave and</strong>         <br/>        <strong>Emotiv Insight (5-channel)</strong>        <br/>        </td>        <td style="text-align:center;">        <strong>99% and 99.7%</strong>        <br/>        </td>       </tr>       <tr>        <td style="text-align:center;">[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#bib16">16</a>]</td>        <td style="text-align:center;">2012</td>        <td style="text-align:center;">Electrode cap based on 64 electrodes<br/>        </td>        <td style="text-align:center;">83%</td>       </tr>       <tr>        <td style="text-align:center;">[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#bib17">17</a>]</td>        <td style="text-align:center;">2013</td>        <td style="text-align:center;">32 channel Biosemi EEG amplifier device<br/>        </td>        <td style="text-align:center;">96.97%<br/>        </td>       </tr>       <tr>        <td style="text-align:center;">[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#bib18">18</a>]</td>        <td style="text-align:center;">2015</td>        <td style="text-align:center;">Emotiv EPOC 14-channel EEG wireless<br/>recording headset<br/>        </td>        <td style="text-align:center;">84%<br/>        </td>       </tr>      </tbody>     </table>     </div>    </section>   </section>   <section id="sec5">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span>      <SmallCap/>Conclusion and Future Work</h2>     </div>    </header>    <p>The analysis of an EEG-based pain detection system has been explored in this article. EEG signals were recorded with the help of a simple and low-cost single channel neurosky mindwave mobile headset and a 5-channel emotiv insight. The time and frequency domain features of the preprocessed signals were selected. The features were divided into three sets. The first set consisted of both time and frequency domain features. The second set was a combination of Hjorth parameters and other statistical time domain features. The third set consisted of mean and variance in the frequency domain. Classification algorithms were applied to each feature set for pain prediction. Set 1 produced the best results of EEG signals used to classify pain and no pain signals. For the neurosky mindwave mobile headset, the average accuracy achieved was 100% for set 1, while the emotiv insight yielded an average accuracy of 83% for set 1 for the aforementioned classification algorithms.</p>    <p>The proposed work and results are encouraging for the medical field, as both headsets are easily available and inexpensive. For future research, the results of the proposed methodology can be improved using a multi-channel device, such as the emotiv EPOC headset and EEG caps. Feature selection algorithms, such as the Principal Component Analysis (PCA), can be exploited to select the best features for prediction. The developed algorithm can be used to detect the mental states of patients in hospitals and at home if embedded in a system for pain prediction. Experiments are also being conducted to analyse pain correlations among multiple patients and to find out novel techniques to build recommender system by incorporating expertise of a doctor in the system [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib19">19</a>-<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#bib20">20</a>].</p>   </section>  </section>  <section class="back-matter">   <Appendix>    <section id="app1">     <header>     <div class="title-info">      <h2>Appendix</h2>     </div>     </header>     <section id="appA1">     <header>      <div class="title-info">       <h3>        <span class="section-number">A.1</span> Time domain features</h3>      </div>     </header>     <p>      <strong>a)	<em>Maximum Amplitude</em>:</strong>      <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{equation} {\rm{maxv}} = {\rm{ma}}{{\rm{x}}_{{\rm{n}} = 1,2,3, \ldots \ldots .,{\rm{N}}}}\left( {{{\rm{x}}_{\rm{i}}}\left[ {\rm{n}} \right]} \right)\end{equation}</span>        <br/>        <span class="equation-number">(2)</span>       </div>      </div>     </p>     <p>      <strong>       <em>b)	Minimum Amplitude:</em>      </strong>      <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{equation} {\rm{minv}} = {\rm{mi}}{{\rm{n}}_{{\rm{n}} = 1,2,3, \ldots \ldots .,{\rm{N}}}}\left( {{{\rm{x}}_{\rm{i}}}\left[ {\rm{n}} \right]} \right)\end{equation}</span>        <br/>        <span class="equation-number">(3)</span>       </div>      </div>     </p>     <p>      <strong>c)	<em>Mean</em>      </strong>: <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{equation} {\rm{\;}}\end{equation}</span>        <br/>        <span class="equation-number">(4)</span>       </div>      </div>     </p>     <p>      <strong>d)	<em>Variance</em>      </strong>: <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{equation} {\rm{var}}\left( {\rm{x}} \right) = 1/{\rm{N}}\mathop \sum \limits_{{\rm{n}} = 1}^{\rm{N}} {\left( {{{\rm{x}}_{\rm{i}}}\left[ {\rm{n}} \right] - {\rm{\bar x}}} \right)^2}\end{equation}</span>        <br/>        <span class="equation-number">(5)</span>       </div>      </div>     </p>     <p>      <strong>       <em>e)	Peak to Peak Value:</em>      </strong>      <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{equation} {{\rm{p}}_2}{\rm{p}} = {\rm{maxv}} - {\rm{minv}}\end{equation}</span>        <br/>        <span class="equation-number">(6)</span>       </div>      </div>     </p>     <p>      <strong>       <em>f)	Peak to Peak time:</em>      </strong>      <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{equation} {{\rm{p}}_2}{\rm{p}}{{\rm{\;}}^{{\rm{time}}}} = {{\rm{T}}_{{\rm{maxv}}}} - {{\rm{T}}_{{\rm{minv\;}}}}\end{equation}</span>        <br/>        <span class="equation-number">(7)</span>       </div>      </div>     </p>     <p>      <strong>       <em>g)	Energy of Signal:</em>      </strong>      <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{equation} {\rm{E}}\left[ {\rm{n}} \right] = \mathop {\lim }\limits_{{\rm{N}} \to \infty } \mathop \sum \limits_{{\rm{n}} = 1}^{\rm{N}} {{\rm{x}}_{\rm{i}}}{\left[ {\rm{n}} \right]^2}\end{equation}</span>        <br/>        <span class="equation-number">(8)</span>       </div>      </div>     </p>     <p>      <strong>       <em>h)	Power of Signal:</em>      </strong>      <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{equation} {\rm{p}}\left[ {\rm{n}} \right] = \mathop {\lim }\limits_{{\rm{N}} \to \infty } 1/\left( {2{\rm{N}} + 1} \right)\mathop \sum \limits_{{\rm{n}} = 1}^{\rm{N}} {{\rm{x}}_{\rm{i}}}{\left[ {\rm{n}} \right]^2}\end{equation}</span>        <br/>        <span class="equation-number">(9)</span>       </div>      </div>     </p>     <p>      <strong>i)	Hjorths&#x2019; Parameters:</strong>     </p>     <p>Hjorths&#x2019; parameters represent the statistical properties of signals. Bo Hjorth discovered these parameters, which provide a maximum divisibility at a low computation. These parameters include activity, mobility and complexity. In fact, these time domain features are related to signal frequency. Activity represents the measure of mean power, mobility represents the mean frequency and complexity represents the frequency bands. <ul class="list-no-style">       <li><strong>        <em>Activity</em>        </strong>: Activity is taken in terms of variance. This feature has already been calculated, so this parameter is discarded.<div class="table-responsive">        <div class="display-equation">         <span class="tex mytex">\begin{equation}{\rm{Activity}} = {\rm{var}}\left( {{\rm{y}}\left( {\rm{t}} \right)} \right)\end{equation}</span>         <br/>         <span class="equation-number">(10)</span>        </div>        </div>        <br/></li>       <li><strong>        <em>Mobility</em>        </strong>: Mobility is computed by taking the square root of the ratio of the original signal&#x0027;s first derivative activity to the activity of the original signal.<div class="table-responsive">        <div class="display-equation">         <span class="tex mytex">\begin{equation}{\rm{Mobility}} = \sqrt {\begin{array}{@{}*{1}{c}@{}} {\frac{{{\rm{var}}\left( {\frac{{{\rm{y}}\left( {\rm{t}} \right){\rm{dy}}}}{{{\rm{\;\;\;\;\;\;\;dt}}}}} \right)}}{{{\rm{var}}\left( {{\rm{y}}\left( {\rm{t}} \right)} \right)}}}\\ {\;\;} \end{array}} \end{equation}</span>         <br/>         <span class="equation-number">(11)</span>        </div>        </div>        <br/></li>       <li><strong>        <em>Complexity</em>        </strong>: Mobility&#x0027;s modified form. It is the ratio of the mobility of the original signal&#x0027;s first derivative to the mobility of the original signal.<div class="table-responsive">        <div class="display-equation">         <span class="tex mytex">\begin{equation}{\rm{Complexity}} = \frac{{{\rm{mobility}}\left( {\frac{{{\rm{y}}\left( {\rm{t}} \right){\rm{dy}}}}{{{\rm{dt}}}}} \right)}}{{{\rm{mobility}}\left( {{\rm{y}}\left( {\rm{t}} \right)} \right)}}\end{equation}</span>         <br/>         <span class="equation-number">(12)</span>        </div>        </div>        <br/></li>      </ul>     </p>     <section id="appA2">      <p><em>A.2 Frequency Domain features</em> A statistical analysis of the captured EEG signals has also taken in frequency domain. First, the fast Fourier transform of the observed signals was taken, and then the following features were extracted.</p>      <p>       <strong>        <em>a)	Mean</em>       </strong>       <div class="table-responsive">        <div class="display-equation">        <span class="tex mytex">\begin{equation} {\rm{mea}}{{\rm{n}}_{{\rm{f}} = }}\mathop \smallint \limits_0^\infty {\rm{f}}.{\rm{A}}\left( {\rm{f}} \right){\rm{df}}/\mathop \smallint \limits_0^\infty {\rm{A}}\left( {\rm{f}} \right){\rm{df\;}}\end{equation}</span>        <br/>        <span class="equation-number">(13)</span>        </div>       </div>      </p>      <p>Where f is the frequency of the signal, and A(f) is the amplitude of the signal in the frequency domain.</p>      <p>       <strong>        <em>b)	Variance</em>       </strong>      </p>      <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{equation} {\rm{va}}{{\rm{r}}_{\rm{f}}} = \frac{{\mathop \smallint \nolimits_0^\infty {\rm{A}}\left( {\rm{f}} \right){{\rm{A}}^{\rm{*}}}\left( {\rm{f}} \right){{\left( {{\rm{f}} - {{\rm{f}}_{\rm{o}}}} \right)}^2}{\rm{df}}}}{{\mathop \smallint \nolimits_0^\infty {\rm{A}}\left( {\rm{f}} \right){{\rm{A}}^{\rm{*}}}\left( {\rm{f}} \right){\rm{df}}}}\end{equation}</span>        <br/>        <span class="equation-number">(14)</span>       </div>      </div>     </section>     </section>    </section>   </Appendix>   <section id="bib-sec-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">References</h2>     </div>    </header>    <ul class="bibUl">     <li id="bib1" label="[1]">Anwar, S.M., Saeed, S.M.U., Majid, M., Usman, S., Mehmood, C.A. and Liu, W., 2017. A Game Player Expertise Level Classification System Using Electroencephalography (EEG). <em>Applied Sciences</em>, <em>8</em>(1), p.18.</li>     <li id="bib2" label="[2]">Saeed, S.M.U., Anwar, S.M., Majid, M. and Bhatti, A.M., 2015, December. Psychological stress measurement using low cost single channel EEG headset. In <em>Signal Processing and Information Technology (ISSPIT), 2015 IEEE International Symposium on</em> (pp. 581-585). IEEE.</li>     <li id="bib3" label="[3]">P. Lucey, J. F. Cohn, I. Matthews, S. Lucey, S. Sridharan, J. Howlett, <em>et al.</em>, "Automatically detecting pain in video through facial action units," <em>Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on,</em> vol. 41, pp. 664-674, 2011.</li>     <li id="bib4" label="[4]">B. J. Matuszewski, W. Quan, and L.-K. Shark, "High-resolution comprehensive 3-D dynamic database for facial articulation analysis," in <em>Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on</em>, 2011, pp. 2128-2135.</li>     <li id="bib5" label="[5]">P. Werner, A. Al-Hamadi, and R. Niese, "Pain recognition and intensity rating based on comparative learning," in <em>Image Processing (ICIP), 2012 19th IEEE International Conference on</em>, 2012, pp. 2313-2316.</li>     <li id="bib6" label="[6]">M. Vatankhah and A. Toliyat, "Pain Level Measurement Using Discrete Wavelet Transform," <em>International Journal of Engineering and Technology,</em> vol. 8, p. 380, 2016.</li>     <li id="bib7" label="[7]">M. Sood, V. Kumar, and S. V. Bhooshan, "Review of State of Art in Electrooculogram Artifact Removal from Electroencephalogram Signals," <em>International Journal of Enhanced Research in Science Technology &amp; Engineering,</em> vol. 2, pp. 32-41, 2013.</li>     <li id="bib8" label="[8]">Y. Tu, Y. S. Hung, Z. Zhang, and L. Hu, "Prediction of pain perception using multivariate pattern analysis of laser-evoked EEG oscillations," in <em>Control Automation Robotics &amp; Vision (ICARCV), 2014 13th International Conference on</em>, 2014, pp. 13-16.</li>     <li id="bib9" label="[9]">Huang, G., Xiao, P., Hung, Y.S., Iannetti, G.D., Zhang, Z.G. and Hu, L., 2013. A novel approach to predict subjective pain perception from single-trial laser-evoked potentials. <em>Neuroimage</em>, <em>81</em>, pp.283-293.</li>     <li id="bib10" label="[10]">Y. Tu, Y. S. Hung, L. Hu, and Z. Zhang, "PCA-SIR: A new nonlinear supervised dimension reduction method with application to pain prediction from EEG," in <em>Neural Engineering (NER), 2015 7th International IEEE/EMBS Conference on</em>, 2015, pp. 1004-1007.</li>     <li id="bib11" label="[11]">R.-R. Nir, A. Sinai, R. Moont, E. Harari, and D. Yarnitsky, "Tonic pain and continuous EEG: prediction of subjective pain perception by alpha-1 power during stimulation and at rest," <em>Clinical Neurophysiology,</em> vol. 123, pp. 605-612, 2012.</li>     <li id="bib12" label="[12]">Bhatti, A.M., Majid, M., Anwar, S.M. and Khan, B., 2016. Human emotion recognition and analysis in response to audio music using brain signals. <em>Computers in Human Behavior</em>, <em>65</em>, pp.267-275.</li>     <li id="bib13" label="[13]">SAEED, S.M.U., ANWAR, S.M. and Majid, M., 2017. Quantification of Human Stress Using Commercially Available Single Channel EEG Headset. <em>IEICE Transactions on Information and Systems</em>, <em>100</em>(9), pp.2241-2244.</li>     <li id="bib14" label="[14]">L. J. Hadjileontiadis, "EEG-Based Tonic Cold Pain Characterization Using Wavelet Higher Order Spectral Features," <em>Biomedical Engineering, IEEE Transactions on,</em> vol. 62, pp. 1981-1991, 2015.</li>     <li id="bib15" label="[15]">Zhu, W., Zeng, N. and Wang, N., 2010. Sensitivity, specificity, accuracy, associated confidence interval and ROC analysis with practical SAS implementations. <em>NESUG proceedings: health care and life sciences, Baltimore, Maryland</em>, <em>19</em>.</li>     <li id="bib16" label="[16]">E. Schulz, A. Zherdin, L. Tiemann, C. Plant, and M. Ploner, "Decoding an individual&#x0027;s sensitivity to pain from the multivariate analysis of EEG data," <em>Cerebral Cortex,</em> vol. 22, pp. 1118-1123, 2012.</li>     <li id="bib17" label="[17]">P. Panavaranan and Y. Wongsawat, "EEG-based pain estimation via fuzzy logic and polynomial kernel support vector machine," in <em>Biomedical Engineering International Conference (BMEiCON), 2013 6th</em>, 2013, pp. 1-4.</li>     <li id="bib18" label="[18]">A. V. Apkarian, J. A. Hashmi, and M. N. Baliki, "Pain and the brain: specificity and plasticity of the brain in clinical chronic pain," <em>Pain,</em> vol. 152, p. S49, 2011.</li>     <li id="bib19" label="[19]">A Sattar, MA Ghazanfar, M Iqbal , "Building Accurate and Practical Recommender System Algorithms Using Machine Learning Classifier and Collaborative Filtering", Arabian Journal for Science and Engineering, 1-19, 2017</li>     <li id="bib20" label="[20]">Mustaqeem, A., Anwar, S.M., Khan, A.R. and Majid, M., 2017. A statistical analysis based recommender model for heart disease patients. <em>International Journal of Medical Informatics</em>, <em>108</em>, pp.134-145.</li>     <li id="bib21" label="[21]">Mustansar Ali Ghazanfar, Adam Pr&#x00FC;gel-Bennett, "Leveraging clustering approaches to solve the gray-sheep users problem in recommender systems", 41(7), 3261-3275, 2014</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY 4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC BY 4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186348">https://doi.org/10.1145/3184558.3186348</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
