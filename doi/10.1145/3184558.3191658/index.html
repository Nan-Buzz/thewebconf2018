<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Learning Large Scale Ordinal Ranking Model via
  Divide-and-Conquer Technique</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3191658'>https://doi.org/10.1145/3184558.3191658</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3191658'>https://w3id.org/oa/10.1145/3184558.3191658</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Learning Large Scale Ordinal
          Ranking Model via Divide-and-Conquer
          Technique</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Lu</span> <span class=
          "surName">Tang</span> University of Michigan, Ann Arbor,
          Michigan, <a href=
          "mailto:lutang@umich.edu">lutang@umich.edu</a>
        </div>
        <div class="author">
          <span class="givenName">Sougata</span> <span class=
          "surName">Chaudhuri</span> A9.com, Inc., Palo Alto,
          California, <a href=
          "mailto:sougata@a9.com">sougata@a9.com</a>
        </div>
        <div class="author">
          <span class="givenName">Abraham</span> <span class=
          "surName">Bagherjeiran</span> A9.com, Inc., Palo Alto,
          California, <a href=
          "mailto:abagher@a9.com">abagher@a9.com</a>
        </div>
        <div class="author">
          <span class="givenName">Ling</span> <span class=
          "surName">Zhou</span> University of Michigan, Ann Arbor,
          Michigan, <a href=
          "mailto:zholing@umich.edu">zholing@umich.edu</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191658"
        target=
        "_blank">https://doi.org/10.1145/3184558.3191658</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Structured prediction, where outcomes have a
        precedence order, lies at the heart of machine learning for
        information retrieval, movie recommendation, product review
        prediction, and digital advertising. Ordinal ranking, in
        particular, assumes that the structured response has a
        linear ranked order. Due to the extensive applicability of
        these models, substantial research has been devoted to
        understanding them, as well as developing efficient
        training techniques. One popular and widely cited technique
        of training ordinal ranking models is to exploit the linear
        precedence order and systematically reduce it to a binary
        classification problem. This facilitates the usage of
        readily available, powerful binary classifiers, but
        <em>necessitates</em> an expansion of the original training
        data, where the training data increases by <em>K</em> − 1
        times of its original size, with <em>K</em> being the
        number of ordinal classes. Due to prevalent nature of
        problems with large number of ordered classes, the
        reduction leads to datasets which are too large to train on
        single machines. While approximation methods like
        stochastic gradient descent are typically applied here, we
        investigate exact optimization solutions that can scale. In
        this paper, we present a divide-and-conquer (DC) algorithm,
        which divides large scale binary classification data into a
        cluster of machines and trains logistic models in parallel,
        and combines them at the end of the training phase to
        create a single binary classifier, which can then be used
        as an ordinal ranker. It requires no synchronization
        between the parallel learning algorithms during the
        training period, which makes training on large datasets
        feasible and efficient. We prove consistency and asymptotic
        normality property of the learned models using our proposed
        algorithm. We provide empirical evidence, on various
        ordinal datasets, of improved estimation and prediction
        performance of the model learnt using our algorithm, over
        several standard divide-and-conquer algorithms.</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Binary
          Classification</small>,</span> <span class=
          "keyword"><small>Ordinal Ranking</small>,</span>
          <span class="keyword"><small>Big Data</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Lu Tang, Sougata Chaudhuri, Abraham Bagherjeiran, and
          Ling Zhou. 2018. Learning Large Scale Ordinal Ranking
          Model via Divide-and-Conquer Technique. In <em>WWW '18
          Companion: The 2018 Web Conference Companion,</em>
          <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New
          York, NY, USA</em> 9 Pages. <a href=
          "https://doi.org/10.1145/3184558.3191658" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3191658</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Structured prediction involves predicting structured
      objects, rather than scalar discrete or real values. One of
      the earliest structured prediction problem consists of
      ordinal labeled data, that is, scalar outcomes which have a
      ranked order. Learning to rank ordinal outcomes has proven
      effective in search-based advertising, web search, ratings,
      and other applications where outcomes are both categorical
      and ordered in nature [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0022">22</a>].</p>
      <p>Recognizing that nearly all ordinal regression algorithms
      are built upon binary classification algorithm, we seek an
      efficient ordinal approach to use as a black box for our
      proposed binary classification algorithm [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0002">2</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0006">6</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0007">7</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0012">12</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0019">19</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0023">23</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0026">26</a>]. We use the technique
      discussed in [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0015">15</a>] in which the authors reduce ordinal
      regression to multiple binary classification problems and
      then solve them jointly as a single binary classifier. A
      simple step is then used to convert the binary outputs to an
      ordinal rank, which also leads to an immediate generalization
      analysis. The main advantages of the proposed scheme is that
      reduction technique is efficient and only one binary
      classifier needs to be trained on the expanded classification
      data; see for example, applications in online advertising
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0001">1</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0003">3</a>].</p>
      <p>This well-known reduction technique introduces a
      scalability challenge. Reducing ordinal regression to binary
      classification expands the instance space by <em>K</em> − 1
      times of its original size, where <em>K</em> is the number of
      ordinal outcomes. In the modern era of extreme class
      problems, where large number of ordered classes is prevalent,
      the reduction leads to datasets which are too large to train
      on single machines. Applying this reduction to large-scale
      modeling problems such as search-based advertising or web
      search, makes training binary classification models harder.
      This motivates us to investigate large scale binary
      classification training algorithms.</p>
      <p>The problems outlined above for ordinal regression falls
      under the “Big Data” regime. Big Data has led to
      approximation algorithms to cope with data so “big” in
      dimensions or, as in our case, training instances, that it
      cannot fit into main memory on a single machine. Algorithms
      handle big data by relying on distributed hardware
      architectures and approximate optimization methods [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0009">9</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0021">21</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0024">24</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0025">25</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0030">30</a>]. By
      distributing computation across a large cluster of machines
      with increasingly cheap SSD storage and mini-batch
      computation frameworks such as GPUs, they are able to run
      multiple passes over the data to eventually arrive at an
      appoximately close-enough solution. Since these are
      approximations, they are not guaranteed to solve for the
      ordinal regression problem. We observe anecdotally that
      down-sampling, applying the reduction in [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0015">15</a>], and then training with a
      good in-memory batch method such as [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0011">11</a>] leads to better and more
      consistent performance despite the fact that there may be
      information loss and weak theoretical results.</p>
      <p>We seek a large scale exact solver for the convex binary
      classification optimization problem to use in ordinal
      regression. We propose a divide-and-conquer strategy called
      the robust inverse variance weighted average
      (<strong>RIVWA</strong>) that is ideally suited to ordinal
      regression and, we believe other structured prediction
      problems. It provides an exact solution to the binary
      classification problem, scales to large problems, and
      involves only a single pass over the data. Solving the
      problem exactly means that we can obtain ordinal regression
      models using the reduction described in [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0015">15</a>].</p>
      <p>We list our contributions below:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">We first outline the reduction
        step to convert ordinal data to binary data, and the
        conversion of the trained binary classifier into an ordinal
        ranker. We then propose a method to divide large binary
        classification dataset into chunks, train individual
        regularized logistic classifiers on the blocks of data, and
        combine the classifiers in an efficient way to get single
        binary classifier. Our method requires no synchronization
        between learning algorithms on the data blocks and thus,
        the learning algorithms can run in parallel, on distributed
        data frameworks like Hadoop. Moreover, our method is a
        single pass method, that is, the division step and
        combinations step are executed only once, and do not need
        to be repeated. We note that once the data is divided, the
        actual training of classifiers on individual blocks can
        mimic any feature of training on the full dataset (assuming
        feasibility). Thus, the blocks can be loaded from fast
        SSDs, trained on CPU or fast GPU and use standard
        optimization algorithms, neural networks etc.<br /></li>
        <li id="list2" label="•">We prove that the model
        coefficients from our method is consistent with the true
        underlying parameter and asymptotically normally
        distributed.<br /></li>
        <li id="list3" label="•">We compare our model on multiple
        datasets (public and proprietary), and show improvement in
        estimation and prediction performance, as well as reduction
        in training time in some cases, over several competing
        divide and conquer methods.<br /></li>
      </ul>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related
          Work</h2>
        </div>
      </header>
      <p>Here, we give an overview of related work in
      divide-and-conquer paradigm for fitting logistic
      classification models. DC algorithms for logistic
      classification mainly refer to methods of partitioning the
      full dataset into <em>M</em> separate parts
      (<em>splitting</em>), obtaining coefficient estimates from
      each part, and combining the <em>M</em> sets of estimates to
      get the final result (<em>merging</em>). A DC algorithm is
      more efficient if no synchronization is required between
      individual learning algorithms, leading to true parallel
      learning. Although there are many relevant work that studies
      DC algorithms from various perspectives, we specifically
      emphasize the estimation consistency and asymptotic normality
      properties of a DC estimator . Thus, we only include variance
      dependent methods that we are aware of in the literature.</p>
      <p>The most straightforward DC method is to take the simple
      average (<strong>SA</strong>) of the estimates as:</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation*} \textstyle
          \text{SA:}\ \ \ \hat{\theta } = \frac{1}{M} \sum
          _{m=1}^{M} \hat{\theta }_m\end{equation*}</span><br />
        </div>
      </div>where <span class="inline-equation"><span class=
      "tex">$\hat{\theta }_m$</span></span> is the logistic
      classifier coefficient estimate from the <em>m</em>-th data
      partition. This method has been studied by others and shown
      to produce high variance in the combined estimator [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0018">18</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0030">30</a>].
      <p></p>
      <p>Another popular DC method that has been studied
      extensively under the topic of meta-analysis [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0027">27</a>] is to take the inverse
      variance weighted average (<strong>IVWA</strong>) of the
      separate estimates as</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation*} \textstyle
          \text{IVWA:}\ \ \ \hat{\theta } = (\sum _{m=1}^{M}
          \hat{\Sigma }_m^{-1})^{-1} \sum _{m=1}^{M} \hat{\Sigma
          }_m^{-1} \hat{\theta }_m\end{equation*}</span><br />
        </div>
      </div>where <span class="inline-equation"><span class=
      "tex">$\hat{\Sigma }_m$</span></span> is the estimated
      variance-covariance matrix of <span class=
      "inline-equation"><span class="tex">$\hat{\theta
      }_m$</span></span> . For logistic regression, <span class=
      "inline-equation"><span class="tex">$\hat{\Sigma }_m =
      \lbrace X_m^{\top } V_m(\hat{\theta }_m) X_m\rbrace
      ^{-1}$</span></span> , where <em>X<sub>m</sub></em> is the
      <em>m</em>-th block feature matrix, and
      <em>V<sub>m</sub></em> (<em>θ</em>) is a diagonal matrix with
      diagonal element <span class="inline-equation"><span class=
      "tex">$\nu _m(\theta)_{i, i} = \sigma ((X_m^{\top }
      \theta)_i) \lbrace 1 - \sigma ((X_m^{\top }
      \theta)_i)\rbrace$</span></span> , where
      <em>σ</em>(<em>x</em>) = 1/(1 + <em>e</em> <sup>−
      <em>x</em></sup> ) is the sigmoid function. This estimator
      guarantees theoretical efficiency in the sense that the DC
      estimator can achieve the smallest variance possible, which
      is the variance achieved by the benchmark of directly
      training on the full data. However, because of overfitting
      issue, due to lack of regularization, the empirical results
      usually show larger variance (and hence worse performance)
      than the benchmark. Although for ordinal regression there are
      many established methods (for example [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0016">16</a>]) that can be used as
      baseline, we specifically choose to compare with the full
      data maximum likelihood estimator since we are interested in
      not only the prediction, but also the efficiency for
      inference.
      <p></p>
      <p>To enforce sparsity, a majority voting
      (<strong>MV</strong>) method was proposed to select the most
      frequently identified features from lasso regressions across
      all data divisions [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>]. This method returns nonzero weights
      only for features that are identified by lasso regression
      across a majority of data parts, and lets the rest be zero.
      The combination step takes the form</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation*} \textstyle
          \text{MV:}\ \ \ \hat{\theta } = A (\sum _{m=1}^{M}
          A^{\top } \hat{\Sigma }_m^{-1} A)^{-1} \sum _{m=1}^{M}
          A^{\top }\hat{\Sigma }_m^{-1}A A^{\top } \hat{\theta
          }_m\end{equation*}</span><br />
        </div>
      </div>where <em>A</em> is a column-wise slicing of an
      identify matrix <em>I<sub>D</sub></em> , selecting columns
      <span class="inline-equation"><span class="tex">$\lbrace j :
      \sum _{m=1}^{M} 1[ \hat{\theta }_{m,j} \ne 0 ] {\gt} v
      \rbrace$</span></span> for some voting threshold <em>v</em>
      (<em>D</em> is the feature dimension). Here, <span class=
      "inline-equation"><span class="tex">$\hat{\theta
      }_m$</span></span> are lasso regularized estimates obtained
      from each data block <em>m</em>, unlike in
      <strong>SA</strong> and <strong>IVWA</strong> methods, where
      the estimates are not regularized. Due to the sparseness of
      <span class="inline-equation"><span class="tex">$\hat{\theta
      }_m$</span></span> , this method is numerically robust.
      However, it requires tuning of two parameters, the lasso
      regularization parameter and the voting threshold <em>v</em>.
      Additionally, the combined estimator <span class=
      "inline-equation"><span class="tex">$\hat{\theta
      }$</span></span> is biased due to the biasedness of
      <span class="inline-equation"><span class="tex">$\hat{\theta
      }_m$</span></span> , <em>m</em> = 1, …, <em>M</em>.
      <p></p>
      <p>As aforementioned, a major challenge for regularized
      estimators is that they are biased. Thus the combined
      estimate often lack theoretical guarantees in terms of
      consistency. Previous work has been done using the bootstrap
      subsampling idea [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0010">10</a>] to estimate and correct the bias of
      DC estimators [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0030">30</a>]. However, in this paper, we derive
      the closed-form expression of the bias of ℓ<sub>1</sub>
      regularized logistic regression, and directly correct the
      bias within each data part before combining the results. The
      importance of correcting for bias will be highlighted in the
      section discussing the theoretical merits of our method.</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Ordinal to
          Binary Classification Reduction</h2>
        </div>
      </header>
      <p>We outline the critical points of the method of reduction
      from ordinal ranking to binary classification given by a
      previous work [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0015">15</a>]. Ordinal outcomes naturally inspire
      a binary classification approach for training models. As an
      example, consider the satisfaction level of a user for a
      product, with five possible levels. By asking the question
      “is the satisfaction level for the user greater than level
      <em>k</em>”, one can get a binary classification problem for
      a fixed <em>k</em>, since the answer would be <em>yes</em> or
      <em>no</em> (1 or 0). By varying <em>k</em> = 1, 2, 3, 4, for
      each user, one can get 4 different binary classification
      problems. The approach then reduces to a question of how the
      classification models be trained and combined to obtain an
      ordinal ranking model. The main advantage of reducing ordinal
      ranking problem into binary classification problem is that it
      facilitates the usage of well-tuned binary classifiers
      available with standard libraries. We focus on logistic loss
      as the classification objective function since our
      theoretical results are derived for the same.</p>
      <p>For a binary logistic regression, with instance
      <span class="inline-equation"><span class="tex">$x \in
      \mathbb {R}^D$</span></span> and label <em>y</em> ∈ {0, 1},
      the binary classifier <em>f</em>(<em>x</em>) to be learnt is
      parameterized by <span class="inline-equation"><span class=
      "tex">$\beta \in \mathbb {R}^D$</span></span> , i.e.,
      <em>f</em>(<em>x</em>) = <em>x</em> <sup>⊤</sup> <em>β</em>.
      The loss (or the negative log likelihood) function of a
      training dataset is</p>
      <div class="table-responsive" id="eq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \textstyle \sum
          _{i=1}^{N} \left\lbrace \log \left(1 + e^{f(x_i)}\right)
          - y_i f(x_i) \right\rbrace \end{equation}</span><br />
          <span class="equation-number">(1)</span>
        </div>
      </div>where <em>N</em> is the training sample size, and the
      estimated coefficient vector <span class=
      "inline-equation"><span class="tex">$\hat{\beta
      }$</span></span> is the minimizer to (<a class="eqn" href=
      "#eq1">1</a>).
      <p></p>
      <p>A <em>K</em> class ordinal ranking problem is defined by
      an instance <span class="inline-equation"><span class=
      "tex">$x \in \mathcal {X} \subseteq \mathbb
      {R}^D$</span></span> and label <span class=
      "inline-equation"><span class="tex">$y \in \mathcal {Y} =
      \lbrace 1,2,\ldots , K\rbrace$</span></span> , where 1 ≤ 2 ≤
      … ≤ <em>K</em>. The objective is to learn a ranking rule
      <span class="inline-equation"><span class="tex">$r : \mathcal
      {X} \mapsto \mathcal {Y}$</span></span> , which will minimize
      a weighted point-wise loss function with weights defined by
      some cost <em>C</em> <sub><em>y</em>,
      <em>r</em>(<em>x</em>)</sub>. Each instance and label pair
      (<em>x<sub>i</sub></em> , <em>y<sub>i</sub></em> ) is reduced
      to a binary classification pair (along with introduction of a
      weight) by the following technique:</p>
      <div class="table-responsive" id="eq2">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \begin{split}
          x_i^k = &amp; (x_i^{\top }, e_k^{\top })^{\top } \in
          \mathbb {R}^{D+K-1},\\ y_i^k = &amp;1 [k {\lt} y], \\
          w_i^k = &amp; | C_{y_i, k} - C_{y_i, k+1} |, \end{split}
          \end{equation}</span><br />
          <span class="equation-number">(2)</span>
        </div>
      </div>for <em>k</em> = 1, …, <em>K</em> − 1, where <em>C</em>
      <sub><em>y</em>, <em>k</em></sub> is the cost for assigning
      an outcome of <em>k</em> when the actually value is
      <em>y</em>, and <em>e<sub>k</sub></em> is the standard basis
      vector in dimension <em>K</em> − 1. <em>As a result, the
      original sample size expands from <em>N</em> to (<em>K</em> −
      1)<em>N</em></em> . Then, a logistic classifier <em>f</em>(·)
      can be trained on the expanded training set by minimizing the
      new loss function
      <div class="table-responsive" id="eq3">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \textstyle \sum
          _{i=1}^{N} \sum _{k=1}^{K-1} w_i^k \left\lbrace \log
          \left(1 + e^{f({x_i^k})} \right) - y_i^k f({x_i^k})
          \right\rbrace . \end{equation}</span><br />
          <span class="equation-number">(3)</span>
        </div>
      </div>This can be viewed as the loss (negative log
      likelihood) of a training data with sample size <span class=
      "inline-equation"><span class="tex">$\tilde{N} =
      (K-1)N$</span></span> , feature dimension <span class=
      "inline-equation"><span class="tex">$\tilde{D} = D + K -
      1$</span></span> , and sample weights specified by
      <span class="inline-equation"><span class=
      "tex">$w_i^k$</span></span> . The solution to (<a class="eqn"
      href="#eq3">3</a>) would lead to a classifier <em>f</em>(·)
      of the form <em>f</em>(·) = (<em>g</em>(·), <em>b</em>
      <sub>1</sub>, <em>b</em> <sub>2</sub>, …, <em>b</em>
      <sub><em>K</em> − 1</sub>), where <em>g</em> is defined by a
      parameter vector <span class="inline-equation"><span class=
      "tex">$\beta \in \mathbb {R}^D$</span></span> (<span class=
      "inline-equation"><span class="tex">$g(x) = x^{\top } \beta
      \mapsto \mathbb {R}$</span></span> ) and {<em>b</em>
      <sub>1</sub>, …, <em>b</em> <sub><em>K</em> − 1</sub>} are
      bias terms. Thus, <em>f</em>(·) can be represented as a
      linear function with parameter <span class=
      "inline-equation"><span class="tex">$\theta \in \mathbb
      {R}^{\tilde{D}}$</span></span> as <em>θ</em> = [<em>β</em>,
      <em>b</em> <sub>1</sub>, …, <em>b</em> <sub><em>K</em> −
      1</sub>]<sup>⊤</sup>, with <em>f</em>(<em>x<sup>k</sup></em>
      ) = <em>x</em> <sup><em>k</em>⊤</sup> <em>θ</em> = <em>x</em>
      <sup>⊤</sup> <em>β</em> + <em>b<sub>k</sub></em> . The
      authors guaranteed (Thm.2, [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0015">15</a>]) when <em>C</em> <sub><em>y</em>,
      <em>r</em>(<em>x</em>)</sub> is convex, the bias terms are
      <em>rank monotone</em> such that <em>b</em> <sub>1</sub> ≥
      <em>b</em> <sub>2</sub> ≥ … ≥ <em>b</em> <sub><em>K</em> −
      1</sub>, therefore <em>f</em>(<em>x</em> <sup>1</sup>) ≥
      <em>f</em>(<em>x</em> <sup>2</sup>) ≥ … ≥
      <em>f</em>(<em>x</em> <sup><em>K</em> − 1</sup>). This
      justifies the ranking rule of predicting the ordinal class of
      a new instance <span class="inline-equation"><span class=
      "tex">$x_* \in \mathbb {R}^D$</span></span> by
      <div class="table-responsive" id="Xeq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \textstyle
          r(x_*) = 1 + \sum _{k=1}^{K-1} 1 [ f(x_*^k) {\gt} 0 ].
          \end{equation}</span><br />
          <span class="equation-number">(4)</span>
        </div>
      </div>
      <p></p>
      <p>In this paper, we consider the convex absolute loss
      <em>C</em> <sub><em>y</em>, <em>r</em>(<em>x</em>)</sub> =
      |<em>y</em> − <em>r</em>(<em>x</em>)| in the reduction to
      binary classification to ensure the biases to be rank
      monotone as described by the authors. As a result,
      <span class="inline-equation"><span class="tex">$w_i^k =
      1$</span></span> for all <em>i</em>, <em>k</em>.</p>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Divide and
          Conquer Algorithm for Large Scale Logistic
          Classification</h2>
        </div>
      </header>
      <p>The critical part of the reduction technique is the
      expansion of the training set, as evidenced in (<a class=
      "eqn" href="#eq2">2</a>). The training set increases by
      <em>K</em> − 1 times its original size. Even for moderately
      large datasets, such expansions can lead to greater
      computational burden. It might become impossible to store the
      expanded dataset in a single machine, or at least, load it
      into the main memory, which would lead to substantial
      increase in training time.A natural technique might be to
      partition the full training dataset and learn a classifier
      coefficient on the individual parts and somehow combine the
      coefficients to get a final, global coefficient. However,
      each part may have insufficient sample size to yield a stable
      coefficient estimate due to overfitting. Additionally,
      regularized methods that prevent overfitting usually give
      biased estimates such that the combined estimate is also
      biased. In this section, we propose the robust inverse
      variance weighted average (<strong>RIVWA</strong>) method to
      address these challenges.</p>
      <p>First, we divide the full ordinal data into <em>M</em>
      parts. For ease of exposition, we assume data is divided
      equally, with each part containing <em>n</em> =
      <em>N</em>/<em>M</em> of the original training set (Note that
      the algorithm can handle data parts that are not equally
      sized; smaller parts will have smaller inverse variance
      weights; thus smaller contribution to the final result. The
      equal division is for technical convenience). We assume that
      the feature dimension <em>D</em> is fixed so that coefficient
      estimates from separate parts can be combined. We advise to
      choose <em>M</em> not too large to ensure <em>n</em> &gt;
      <em>D</em>, and <em>M</em> not too small to ensure benefiting
      from DC.</p>
      <p>Let (<em>Y<sub>m</sub></em> , <em>X<sub>m</sub></em> )
      denote the <em>m</em>-th part after the expansion by
      (<a class="eqn" href="#eq2">2</a>), with instance space
      dimension being <span class="inline-equation"><span class=
      "tex">$\tilde{n} = (K-1)n$</span></span> and feature space
      dimension being <span class="inline-equation"><span class=
      "tex">$\tilde{D} = D + K - 1$</span></span> . Thus
      <em>X<sub>m</sub></em> is an <span class=
      "inline-equation"><span class="tex">$\tilde{n} \times
      \tilde{D}$</span></span> matrix where each row is an expanded
      instance <span class="inline-equation"><span class=
      "tex">$x_i^k$</span></span> , i.e., <span class=
      "inline-equation"><span class="tex">$X_m = [ x_{m,1}^1, \dots
      , x_{m,1}^{K-1}, \dots , x_{m,n}^1, \dots , x_{m,n}^{K-1}
      ]^{\top }$</span></span> , and <em>Y<sub>m</sub></em> is a
      vector of length <span class="inline-equation"><span class=
      "tex">$\tilde{n}$</span></span> , i.e., <span class=
      "inline-equation"><span class="tex">$Y_m = [ y_{m,1}^1, \dots
      , y_{m,1}^{K-1}, \dots , y_{m,n}^1, \dots , y_{m,n}^{K-1}
      ]^{\top }$</span></span> .</p>
      <p>For convenience of representation, we use iterator
      <span class="inline-equation"><span class="tex">$l = 1, \dots
      , \tilde{n}$</span></span> to iterate through
      <em>X<sub>m</sub></em> and <em>Y<sub>m</sub></em> . For each
      of the data block, we consider the ℓ<sub>1</sub> regularized
      logistic regression [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0029">29</a>] which employs the lasso penalty on
      the loss function to learn the coefficient vector
      <em>θ</em>:</p>
      <div class="table-responsive" id="eq4">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \textstyle
          \hat{\theta }_m = \text{argmin}_{\theta \in \mathbb
          {R}^{\tilde{D}}} \left\lbrace \frac{1}{\tilde{n}} \sum
          _{l=1}^{\tilde{n}} \left\lbrace \log \left(1 +
          e^{{x_{m,l}}^{\top } \theta }\right) - y_{m,l}
          {x_{m,l}}^{\top } \theta \right\rbrace + \lambda ||\theta
          ||_1 \right\rbrace , \end{equation}</span><br />
          <span class="equation-number">(5)</span>
        </div>
      </div>where || · ||<sub>1</sub> is the ℓ<sub>1</sub> norm and
      <em>λ</em> is the penalty factor. From (<a class="eqn" href=
      "#eq4">5</a>), we get a sparse estimate of regression
      coefficients <span class="inline-equation"><span class=
      "tex">$\hat{\theta }_m$</span></span> for the <em>m</em>-th
      block. In our experiments, we use the Python library
      <tt>sklearn</tt> with the <tt>liblinear</tt> solver to obtain
      <span class="inline-equation"><span class="tex">$\hat{\theta
      }_m$</span></span> [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0011">11</a>].
      <p></p>
      <p>Next, we obtain the robust inverse variance by</p>
      <div class="table-responsive" id="eq5">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \hat{\Sigma
          }_m^{-1}(\hat{\theta }_m) = X_m^{\top } V_m(\hat{\theta
          }_m) X_m, \end{equation}</span><br />
          <span class="equation-number">(6)</span>
        </div>
      </div>where <span class="inline-equation"><span class=
      "tex">$V_m(\hat{\theta }_m)$</span></span> is an <span class=
      "inline-equation"><span class="tex">$\tilde{n} \times
      \tilde{n}$</span></span> diagonal matrix with diagonal
      elements <span class="inline-equation"><span class=
      "tex">$v_{l,l} = \sigma (x_{m,l}^{\top }\hat{\theta }_m) (1 -
      \sigma (x_{m,l}^{\top }\hat{\theta }_m))$</span></span> ,
      <span class="inline-equation"><span class="tex">$l=1,\dots
      ,\tilde{n}$</span></span> .
      <p></p>
      <p>The de-biased coefficient vector is obtained by</p>
      <div class="table-responsive" id="eq6">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \hat{\theta
          }_m^c = \hat{\theta }_m + \hat{\Sigma }_m(\hat{\theta
          }_m) X_m^{\top }(Y_m - \hat{Y}_m),
          \end{equation}</span><br />
          <span class="equation-number">(7)</span>
        </div>
      </div>where <span class="inline-equation"><span class=
      "tex">$\hat{Y}_m = [ \hat{y}_{m,1}, \dots ,
      \hat{y}_{m,\tilde{n}} ]^{\top }$</span></span> with
      <span class="inline-equation"><span class=
      "tex">$\hat{y}_{m,l} = \sigma (x_{m,l}^{\top } \hat{\theta
      }_m)$</span></span> , <span class=
      "inline-equation"><span class="tex">$l=1,\dots
      ,\tilde{n}$</span></span> . The de-biased coefficient vector
      <span class="inline-equation"><span class="tex">$\hat{\theta
      }_m^c$</span></span> is an approximation to the coefficient
      estimated when <em>λ</em> = 0. Eq. (<a class="eqn" href=
      "#eq6">7</a>) provides a convenient way to quickly compute
      <span class="inline-equation"><span class="tex">$\hat{\theta
      }_m^c$</span></span> instead of solving (<a class="eqn" href=
      "#eq4">5</a>) again at <em>λ</em> = 0. We obtain <span class=
      "inline-equation"><span class="tex">$\hat{\theta
      }_m^c$</span></span> and <span class=
      "inline-equation"><span class="tex">$\hat{\Sigma
      }_m^{-1}(\hat{\theta }_m)$</span></span> for each of the data
      part, <em>m</em> = 1, …, <em>M</em>, in parallel. Finally, we
      get the combined RIVWA estimate:
      <div class="table-responsive" id="eq7">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \textstyle
          \hat{\theta } = \left\lbrace \sum _{m=1}^{M} \hat{\Sigma
          }_m^{-1}(\hat{\theta }_m) \right\rbrace ^{-1}
          \left\lbrace \sum _{m=1}^{M} \hat{\Sigma
          }_m^{-1}(\hat{\theta }_m) \hat{\theta }_m^c \right\rbrace
          . \end{equation}</span><br />
          <span class="equation-number">(8)</span>
        </div>
      </div>
      <p></p>
      <p>Note that when estimating the inverse variance weights, we
      plug in the sparse regularized estimates <span class=
      "inline-equation"><span class="tex">$\hat{\theta
      }_m$</span></span> to avoid overfitting and ensure numerical
      robustness of <span class="inline-equation"><span class=
      "tex">$\lbrace \hat{\Sigma }_m\rbrace _{m=1}^M$</span></span>
      . The computation of <span class=
      "inline-equation"><span class="tex">$\hat{\theta
      }_m$</span></span> is mainly for the purpose of stabilizing
      the robust inverse variances. However, the average is taken
      across the de-biased estimates <span class=
      "inline-equation"><span class="tex">$\lbrace \hat{\theta
      }_m^c\rbrace _{m=1}^M$</span></span> to ensure unbiasedness
      and consistency of <span class="inline-equation"><span class=
      "tex">$\hat{\theta }$</span></span> . Eq. (<a class="eqn"
      href="#eq6">7</a>) gives a direct and simple way to use the
      penalized <span class="inline-equation"><span class=
      "tex">$\hat{\theta }_m$</span></span> to compute the
      unpenalized counterpart <span class=
      "inline-equation"><span class="tex">$\hat{\theta
      }_m^c$</span></span> when <em>λ</em> = 0.</p>
      <p>In contrast, the classic inverse variance weighted average
      (IVWA) (see related work section) uses the unregularized
      coefficient estimates in calculation of the inverse variance
      weights, which often leads to overfitting in individual data
      parts, resulting in predicted class probabilities being very
      close to the boundary (i.e., 0 or 1).</p>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Theoretical
          Results</h2>
        </div>
      </header>
      <p>In this section, we provide the consistency and asymptotic
      normality properties of the RIVWA estimator <span class=
      "inline-equation"><span class="tex">$\hat{\theta
      }$</span></span> in (<a class="eqn" href="#eq7">8</a>).
      First, we establish the asymptotic properties of the
      de-biased estimators <span class=
      "inline-equation"><span class="tex">$\lbrace \hat{\theta
      }_m^c\rbrace _{m=1}^M$</span></span> from individual parts to
      show that the bias correction recovers the loss of asymptotic
      due to regularization. Then, we show that the combined
      estimator <span class="inline-equation"><span class=
      "tex">$\hat{\theta }$</span></span> achieves asymptotic
      normality with the most efficient variance. Let <em>θ</em>
      <sub>0</sub> be the unknown true underlying coefficient,
      which is the limiting value of the benchmark coefficient
      <span class="inline-equation"><span class="tex">$\hat{\theta
      }_{BM}$</span></span> (obtained from training on the entire,
      undivided dataset), as <span class=
      "inline-equation"><span class="tex">$\tilde{N} \rightarrow
      \infty$</span></span> .</p>
      <p></p>
      <div class="theorem" id="enc1">
        <label>Theorem 5.1.</label>
        <p>Under conditions listed in the Appendix, for the
        <em>m</em>-th block, <span class=
        "inline-equation"><span class="tex">$\hat{\theta
        }_m^c$</span></span> in (<a class="eqn" href="#eq6">7</a>)
        is consistent, i.e., <span class=
        "inline-equation"><span class="tex">$\hat{\theta }_m^c
        \overset{p}{\rightarrow } \theta _0$</span></span> , and
        asymptotically normally distributed, i.e., <span class=
        "inline-equation"><span class="tex">$\sqrt {\tilde{n}}
        (\hat{\theta }_m^c - \theta _{0}) \overset{d}{\rightarrow }
        \mathcal {N} (0, \Sigma _m(\theta _0))$</span></span> ,
        where <span class="inline-equation"><span class=
        "tex">$\Sigma _m^{-1}(\theta _0) = X_m^{\top } V_m(\theta
        _0) X_m$</span></span> .</p>
      </div>
      <p></p>
      <p></p>
      <div class="theorem" id="enc2">
        <label>Theorem 5.2.</label>
        <p>Under the same conditions in Theorem <a class="enc"
        href="#enc1">5.1</a>, the combined estimator <span class=
        "inline-equation"><span class="tex">$\hat{\theta
        }$</span></span> in (<a class="eqn" href="#eq7">8</a>) has
        the same consistentency and asymptotically normality
        property as <span class="inline-equation"><span class=
        "tex">$\hat{\theta }_{BM}$</span></span> , i.e.,
        <span class="inline-equation"><span class=
        "tex">$\hat{\theta } \overset{p}{\rightarrow } \theta
        _0$</span></span> and <span class=
        "inline-equation"><span class="tex">$\sqrt {\tilde{N}}
        (\hat{\theta } - \theta _{0}) \overset{d}{\rightarrow }
        \mathcal {N} (0, \Sigma (\theta _0))$</span></span> , with
        <span class="inline-equation"><span class="tex">$\Sigma
        ^{-1}(\theta _0) = \sum _{m=1}^{M} \Sigma _m^{-1}(\theta
        _0)$</span></span> .</p>
      </div>
      <p></p>
      <p>Theorem <a class="enc" href="#enc1">5.1</a> states that
      the de-biased estimator (<a class="eqn" href="#eq6">7</a>)
      regains the asymptotic normality lost due to regularization
      of the likelihood. Theorem <a class="enc" href=
      "#enc2">5.2</a> establishes that the loss of efficiency due
      to lack of communication between data parts is ignorable in
      an asymptotic sense. The proofs we provide are motivated from
      a recent work on divide-and-conquer in generalized linear
      models [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0028">28</a>].
      Here we specifically focus on the logistic model, and also
      show that the parameters due to data expansion enjoy the same
      properties, which is crucial to outcome prediction and other
      applications in ordinal ranking. In addition, using results
      from Theorem&nbsp;<a class="enc" href="#enc2">5.2</a>, we can
      conduct statistical tests on the bias terms <em>b</em>1, …,
      <em>b</em> <sub><em>K</em> − 1</sub> to compare the mean
      expected probabilities of different outcome levels.</p>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Empirical
          Results</h2>
        </div>
      </header>
      <p>In this section, we present results of extensive
      experiments on public and a proprietary ordinal dataset and a
      public classification dataset. The datasets span the domain
      of insurance industry, digital advertising, e-commerce and
      movie rating. Specifically, we compare our method with the
      benchmark and state-of-the-art DC methods.</p>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.1</span> Summary of
            Methods</h3>
          </div>
        </header>
        <p>We compare the following methods (citations, wherever
        required, are provided in related work section):</p>
        <ul class="list-no-style">
          <li id="list4" label="•">Single memory training on full
          data with batch gradient descent method (benchmark method
          - BM)- the benchmark method trains a logistic classifier
          on the full dataset, by solving Eq.&nbsp;<a class="eqn"
          href="#eq1">1</a>, [<a class="bib" data-trigger="hover"
          data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0011">11</a>].<br />
          </li>
          <li id="list5" label="•">Single memory training on
          sub-sampled data with batch gradient descent method
          (50<span class="inline-equation"><span class=
          "tex">$\%$</span></span> subsampling- BM 50<span class=
          "inline-equation"><span class="tex">$\%$</span></span> )-
          this is same as the benchmark method, except that
          50<span class="inline-equation"><span class=
          "tex">$\%$</span></span> of the data is randomly
          subsampled<br /></li>
          <li id="list6" label="•">Single memory training on
          sub-sampled data with batch gradient descent method
          (20<span class="inline-equation"><span class=
          "tex">$\%$</span></span> subsampling- BM 20<span class=
          "inline-equation"><span class="tex">$\%$</span></span> )-
          same as above, with even more aggressive
          subsampling<br /></li>
          <li id="list7" label="•">Single memory training on full
          data with follow-the-regularized-leader method (FTRL)
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0020">20</a>];<br />
          </li>
          <li id="list8" label="•">Single memory training with
          mini-batch gradient descent method (MBGD);<br /></li>
          <li id="list9" label="•">DC with simple average (SA)
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0018">18</a>, <a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0030">30</a>];<br />
          </li>
          <li id="list10" label="•">DC with inverse variance
          weighted average (IVWA) [<a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0027">27</a>];<br />
          </li>
          <li id="list11" label="•">DC with majority voting (MV)
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0005">5</a>];<br />
          </li>
          <li id="list12" label="•">DC with robust inverse variance
          weighted average and bias correction (RIVWA), our
          proposed method.<br /></li>
        </ul>
        <p><em>Important points about the competing methods</em>:
        BM (full and subsampled versions) and FTRL requires
        in-memory access to the full training data. MBGD, while
        ideally suited when we have in-memory access to full data,
        can be executed by reading mini-batches from secondary
        storage (as we have done). FTRL and MBGD are stochastic
        methods, that requires synchronization and data access at
        every iteration; thus they cannot be parallelized without
        paying extensive overhead charge. For FTRL, we iterate
        through all instances; for MBGD, we let the mini-batches to
        be 1/100 of the full training data. BM does not involve
        regularization, as it will not have the limiting
        distribution as shown in Theorem <a class="enc" href=
        "#enc2">5.2</a>. Moreover, FTRL represents the regularized
        version of single memory, non-divided training method. All
        our experiments were conducted on machines with SSD for
        fast data reading and writing, but we did not involve GPUs
        due to facility limitation.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Result on Prudential insurance dataset.
            Number of divisions <em>M</em> = 100 for DC methods.
            <em>d</em> <sub>1</sub>: absolute differences between
            coefficient estimates of other methods and the
            benchmark; <em>d</em> <sub>2</sub>: squared differences
            between coefficient estimates of other methods and the
            benchmark; change in <span class=
            "inline-equation"><span class=
            "tex">$\operatorname{abs\_loss}$</span></span> with
            respect to benchmark (%): the relative percentage
            change in absolute prediction loss with respect to
            benchmark (the smaller the better); time: computation
            time in seconds. Results are averaged across 10
            repeated experiments and reported as mean ± sd. Best
            results are highlighted in bold.</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">Change in
                <span class="inline-equation"><span class=
                "tex">$\operatorname{abs\_loss}$</span></span></td>
                <td style="text-align:center;">Time</td>
              </tr>
              <tr>
                <td style="text-align:left;">Methods</td>
                <td style="text-align:center;"><span class=
                "inline-equation"><span class=
                "tex">$d_1(\hat{\theta }, \hat{\theta
                }_{BM})$</span></span></td>
                <td style="text-align:center;"><span class=
                "inline-equation"><span class=
                "tex">$d_2(\hat{\theta }, \hat{\theta
                }_{BM})$</span></span></td>
                <td style="text-align:center;">w.r.t BM (%)</td>
                <td style="text-align:center;">(sec)</td>
              </tr>
              <tr>
                <td style="text-align:left;">Single memory</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
              </tr>
              <tr>
                <td style="text-align:left;">BM</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">63.3 ± 1.9</td>
              </tr>
              <tr>
                <td style="text-align:left;">BM 50%</td>
                <td style="text-align:center;">2.68 ± 0.37</td>
                <td style="text-align:center;">0.16 ± 0.07</td>
                <td style="text-align:center;">0.49 ± 0.21</td>
                <td style="text-align:center;">22.7 ± 0.6</td>
              </tr>
              <tr>
                <td style="text-align:left;">BM 20%</td>
                <td style="text-align:center;">5.82 ± 1.00</td>
                <td style="text-align:center;">0.79 ± 0.66</td>
                <td style="text-align:center;">2.14 ± 0.64</td>
                <td style="text-align:center;">6.4 ± 0.3</td>
              </tr>
              <tr>
                <td style="text-align:left;">FTRL</td>
                <td style="text-align:center;">5.56 ± 0.21</td>
                <td style="text-align:center;">0.51 ± 0.03</td>
                <td style="text-align:center;">1.72 ± 0.40</td>
                <td style="text-align:center;">109.8 ± 1.0</td>
              </tr>
              <tr>
                <td style="text-align:left;">MBGD</td>
                <td style="text-align:center;">4.63 ± 0.29</td>
                <td style="text-align:center;">0.32 ± 0.04</td>
                <td style="text-align:center;">0.64 ± 0.18</td>
                <td style="text-align:center;">117.3 ± 20.2</td>
              </tr>
              <tr>
                <td style="text-align:left;">DC with <em>M</em> =
                100</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
              </tr>
              <tr>
                <td style="text-align:left;">SA</td>
                <td style="text-align:center;">11.45 ± 0.78</td>
                <td style="text-align:center;">2.09 ± 0.29</td>
                <td style="text-align:center;">1.23 ± 0.51</td>
                <td style="text-align:center;">1.0 ± 0.1</td>
              </tr>
              <tr>
                <td style="text-align:left;">IVWA</td>
                <td style="text-align:center;">4.24 ± 0.19</td>
                <td style="text-align:center;">0.33 ± 0.02</td>
                <td style="text-align:center;">0.88 ± 0.15</td>
                <td style="text-align:center;">1.0 ± 0.1</td>
              </tr>
              <tr>
                <td style="text-align:left;">MV</td>
                <td style="text-align:center;">4.23 ± 0.15</td>
                <td style="text-align:center;">0.38 ± 0.01</td>
                <td style="text-align:center;">0.72 ± 0.18</td>
                <td style="text-align:center;">1.7 ± 0.4</td>
              </tr>
              <tr>
                <td style="text-align:left;">RIVWA</td>
                <td style="text-align:center;">
                <strong>1.60</strong> ± 0.06</td>
                <td style="text-align:center;">
                <strong>0.05</strong> ± 0.002</td>
                <td style="text-align:center;">
                <strong>0.29</strong> ± 0.14</td>
                <td style="text-align:center;"><strong>0.4</strong>
                ± 0.1</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.2</span> Performance
            Evaluation</h3>
          </div>
        </header>
        <p>For performance evaluation, we report the following
        metrics: 1) absolute difference <em>d</em> <sub>1</sub> of
        an estimated coefficient <span class=
        "inline-equation"><span class="tex">$\hat{\theta
        }$</span></span> to that of the benchmark <span class=
        "inline-equation"><span class="tex">$\hat{\theta
        }_{BM}$</span></span> :</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation*}
            d_1(\hat{\theta }, \hat{\theta }_{BM}) = ||\hat{\theta
            } -\hat{\theta }_{BM} ||_1\end{equation*}</span><br />
          </div>
        </div>2) squared difference <em>d</em> <sub>2</sub> of an
        estimated coefficient <span class=
        "inline-equation"><span class="tex">$\hat{\theta
        }$</span></span> to that of the benchmark <span class=
        "inline-equation"><span class="tex">$\hat{\theta
        }_{BM}$</span></span> :
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation*}
            d_2(\hat{\theta }, \hat{\theta }_{BM}) = ||\hat{\theta
            } -\hat{\theta }_{BM}
            ||_2^2\end{equation*}</span><br />
          </div>
        </div>3) absolute prediction loss of an estimated
        <span class="inline-equation"><span class=
        "tex">$\hat{\theta }$</span></span> evaluated on the
        testing set, defined by
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\[
            \operatorname{abs\_loss}(Y_{test}, \hat{\theta }) =
            \frac{1}{n} \sum _{i=1}^{n} C_{y_i, \hat{y}_i
            (\hat{\theta })} = \frac{1}{n} \sum _{i=1}^{n} |y_i -
            \hat{y}_i (\hat{\theta })|, \]</span><br />
          </div>
        </div>where <em>y<sub>i</sub></em> is the true ordinal
        label of the <em>i</em>-th instance in
        <em>Y<sub>test</sub></em> and <span class=
        "inline-equation"><span class="tex">$\hat{y}_i (\hat{\theta
        }) = 1 + \sum _{k=1}^{K-1} 1 [ x_i^{k\top } \hat{\theta }
        {\gt} 0 ]$</span></span> is its predicted label given
        <span class="inline-equation"><span class=
        "tex">$\hat{\theta }$</span></span> (this boils down to 0 −
        1 loss for binary classification) and
        <p></p>
        <p>4) computation time in seconds, including the time used
        to read data from divided parts. Time of DC methods is
        calculated by the maximum time across all parallel
        procedures plus time used to combine the results. We also
        compare the above metrics at different choices of
        <em>M</em>.</p>
        <p>Tuning parameters are selected to maximize the absolute
        prediction loss on the validation set such that for tuning
        parameter(s) <span class="inline-equation"><span class=
        "tex">$\lambda \in \mathcal {L}$</span></span> , we select
        <em>λ</em> <sup>*</sup> such that</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\[ {\lambda ^*} =
            \underset{\lambda \in \mathcal {L}}{\arg \min }
            \operatorname{abs\_loss}(Y_{valid}, \hat{\theta
            }_{\lambda }) \]</span><br />
          </div>
        </div>where <span class="inline-equation"><span class=
        "tex">$\hat{\theta }_{\lambda }$</span></span> is the
        coefficient vector obtained at tuning value <em>λ</em>. We
        use a grid search for <em>λ</em> ∈ {10<sup>− 4</sup>,
        10<sup>− 3</sup>, …, 10<sup>3</sup>}.
        <p></p>
      </section>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.3</span> Prudential
            Life Insurance Data</h3>
          </div>
        </header>
        <p>The Prudential dataset <a class="fn" href="#fn1" id=
        "foot-fn1"><sup>1</sup></a> is publicly available with an
        8-level ordinal outcome of interest related to some
        undisclosed decision associated with an application in
        Prudential Financial, Inc. The dataset contains 59,381
        labeled instances and has 144 features. We randomly split
        the dataset into 60% for training, 10% for validation, and
        30% for testing.</p>
        <figure id="fig1">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191658/images/www18companion-397-fig1.jpg"
          class="img-responsive" alt="Figure 1" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span>
            <span class="figure-title">Performance of different
            methods on the Prudential insurance dataset at
            <em>M</em> = 20, 40, 60, 80, 100 for DC methods.
            Results are averaged across 10 repeated experiments.
            Metrics <em>d</em> <sub>1</sub>, <em>d</em>
            <sub>2</sub> and <span class=
            "inline-equation"><span class=
            "tex">$\operatorname{abs\_loss}$</span></span> of BM is
            not affected by the choice of <em>M</em>. Computation
            time for BM is not displayed because it is much larger
            in scale as shown in Table&nbsp;<a class="tbl" href=
            "#tab1">1</a>.</span>
          </div>
        </figure>
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191658/images/www18companion-397-fig2.jpg"
          class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">Area under curves results of
            Criteo dataset across multiple DC methods in comparison
            to BM.</span>
          </div>
        </figure>
        <p></p>
        <p>Table <a class="tbl" href="#tab1">1</a> shows extensive
        experiment results comparing different methods. Results are
        averaged from 10 repetitions of the experiment. Our
        proposed RIVWA method produces the closest coefficient
        estimates to the benchmark in terms of <em>d</em>
        <sub>1</sub> and <em>d</em> <sub>2</sub>, and achieves good
        prediction performance in terms of <span class=
        "inline-equation"><span class=
        "tex">$\operatorname{abs\_loss}(Y_{test}, \hat{\theta
        })$</span></span> . Additionally, our computational time is
        less than 1/100 that of BM, and similar to other DC
        methods. Figure <a class="fig" href="#fig1">1</a> shows the
        change in <em>d</em> <sub>1</sub>, <em>d</em> <sub>2</sub>,
        <span class="inline-equation"><span class=
        "tex">$\operatorname{abs\_loss}$</span></span> and time at
        different values of <em>M</em>. We can see that performance
        of RIVWA remains stable against different choices of
        <em>M</em> whereas other DC methods show worse performance
        as <em>M</em> increases, especially for SA and IVWA. The
        computation time for batch and stochastic methods usually
        don't scale well for large data, thus is not shown in
        Figure&nbsp;fig:time . DC methods only require one pass of
        the entire data, thus are much faster than the iterative
        methods. The time of DC methods usually depends on the
        number of parallel jobs. In this case, given <em>N</em>
        fixed, the computation time in general has a decreasing
        trend as <em>M</em> increases, assuming <em>M</em> parallel
        jobs can be executed all at once. It is also interesting to
        note that when <em>M</em> is small, the performance of
        different DC methods are very similar, because the sample
        size in each data division is large enough to provide good
        estimates. An extreme case is when <em>M</em> = 1, where
        all DC methods perform as similar as BM.</p>
      </section>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.4</span> Additional
            Data Experiments</h3>
          </div>
        </header>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Result on the MovieLens movie rating
            dataset, Criteo conversion dataset, and an E-commerce
            advertising funnel dataset. Smaller the <span class=
            "inline-equation"><span class="tex">$d_1(\hat{\theta },
            \hat{\theta }_{BM})$</span></span> , <span class=
            "inline-equation"><span class="tex">$d_2(\hat{\theta },
            \hat{\theta }_{BM})$</span></span> and percentage
            change in <span class="inline-equation"><span class=
            "tex">$\operatorname{abs\_loss}$</span></span> , the
            better. Larger the AUC, the better. AUC is only
            available for the Criteo dataset because it has binary
            (two level) outcomes. Best results are highlighted in
            bold.</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">Change in
                <span class="inline-equation"><span class=
                "tex">$\operatorname{abs\_loss}$</span></span></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">Time</td>
              </tr>
              <tr>
                <td style="text-align:left;">Methods</td>
                <td style="text-align:center;"><span class=
                "inline-equation"><span class=
                "tex">$d_1(\hat{\theta }, \hat{\theta
                }_{BM})$</span></span></td>
                <td style="text-align:center;"><span class=
                "inline-equation"><span class=
                "tex">$d_2(\hat{\theta }, \hat{\theta
                }_{BM})$</span></span></td>
                <td style="text-align:center;">w.r.t. BM (%)</td>
                <td style="text-align:center;">AUC</td>
                <td style="text-align:center;">(sec)</td>
              </tr>
              <tr>
                <td style="text-align:left;">MovieLens</td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td style="text-align:left;">BM</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">953.2</td>
              </tr>
              <tr>
                <td style="text-align:left;">DC with <em>M</em> =
                1000</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
              </tr>
              <tr>
                <td style="text-align:left;">SA</td>
                <td style="text-align:center;">976.5</td>
                <td style="text-align:center;">3245.64</td>
                <td style="text-align:center;">7.21</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">11.1</td>
              </tr>
              <tr>
                <td style="text-align:left;">IVWA</td>
                <td style="text-align:center;">89.22</td>
                <td style="text-align:center;">22.17</td>
                <td style="text-align:center;">3.12</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">11.6</td>
              </tr>
              <tr>
                <td style="text-align:left;">MV</td>
                <td style="text-align:center;">79.59</td>
                <td style="text-align:center;">17.07</td>
                <td style="text-align:center;">
                <strong>-0.02</strong></td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">0.8</td>
              </tr>
              <tr>
                <td style="text-align:left;">RIVWA</td>
                <td style="text-align:center;">
                <strong>8.40</strong></td>
                <td style="text-align:center;">
                <strong>0.47</strong></td>
                <td style="text-align:center;">0.04</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">1.7</td>
              </tr>
              <tr>
                <td style="text-align:left;">Criteo</td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td style="text-align:left;">BM</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.81</td>
                <td style="text-align:center;">71.1</td>
              </tr>
              <tr>
                <td style="text-align:left;">DC with <em>M</em> =
                200</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
              </tr>
              <tr>
                <td style="text-align:left;">SA</td>
                <td style="text-align:center;">61.00</td>
                <td style="text-align:center;">8.40</td>
                <td style="text-align:center;">0.31</td>
                <td style="text-align:center;">0.81</td>
                <td style="text-align:center;">0.7</td>
              </tr>
              <tr>
                <td style="text-align:left;">IVWA</td>
                <td style="text-align:center;">40.30</td>
                <td style="text-align:center;">3.13</td>
                <td style="text-align:center;">0.19</td>
                <td style="text-align:center;">0.81</td>
                <td style="text-align:center;">1.0</td>
              </tr>
              <tr>
                <td style="text-align:left;">MV</td>
                <td style="text-align:center;">36.34</td>
                <td style="text-align:center;">2.61</td>
                <td style="text-align:center;">0.19</td>
                <td style="text-align:center;">0.81</td>
                <td style="text-align:center;">3.6</td>
              </tr>
              <tr>
                <td style="text-align:left;">RIVWA</td>
                <td style="text-align:center;">
                <strong>19.60</strong></td>
                <td style="text-align:center;">
                <strong>0.72</strong></td>
                <td style="text-align:center;">
                <strong>0.14</strong></td>
                <td style="text-align:center;">0.81</td>
                <td style="text-align:center;">2.4</td>
              </tr>
              <tr>
                <td style="text-align:left;">DC with <em>M</em> =
                1000</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
              </tr>
              <tr>
                <td style="text-align:left;">SA</td>
                <td style="text-align:center;">2850.43</td>
                <td style="text-align:center;">15755.89</td>
                <td style="text-align:center;">0.95</td>
                <td style="text-align:center;">0.80</td>
                <td style="text-align:center;">0.6</td>
              </tr>
              <tr>
                <td style="text-align:left;">IVWA</td>
                <td style="text-align:center;">172.53</td>
                <td style="text-align:center;">53.08</td>
                <td style="text-align:center;">35.55</td>
                <td style="text-align:center;">0.70</td>
                <td style="text-align:center;">1.1</td>
              </tr>
              <tr>
                <td style="text-align:left;">MV</td>
                <td style="text-align:center;">180.84</td>
                <td style="text-align:center;">61.38</td>
                <td style="text-align:center;">25.42</td>
                <td style="text-align:center;">0.71</td>
                <td style="text-align:center;">0.1</td>
              </tr>
              <tr>
                <td style="text-align:left;">RIVWA</td>
                <td style="text-align:center;">
                <strong>46.30</strong></td>
                <td style="text-align:center;">
                <strong>4.76</strong></td>
                <td style="text-align:center;">
                <strong>-0.15</strong></td>
                <td style="text-align:center;">
                <strong>0.81</strong></td>
                <td style="text-align:center;">1.2</td>
              </tr>
              <tr>
                <td style="text-align:left;">E-commerce</td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td style="text-align:left;">BM</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">635.4</td>
              </tr>
              <tr>
                <td style="text-align:left;">DC with <em>M</em> =
                1000</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td></td>
              </tr>
              <tr>
                <td style="text-align:left;">SA</td>
                <td style="text-align:center;">746.08</td>
                <td style="text-align:center;">1979.43</td>
                <td style="text-align:center;">-12.44</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">1.3</td>
              </tr>
              <tr>
                <td style="text-align:left;">IVWA</td>
                <td style="text-align:center;">
                <strong>73.71</strong></td>
                <td style="text-align:center;">36.18</td>
                <td style="text-align:center;">199.76</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">1.8</td>
              </tr>
              <tr>
                <td style="text-align:left;">MV</td>
                <td style="text-align:center;">108.11</td>
                <td style="text-align:center;">
                <strong>29.01</strong></td>
                <td style="text-align:center;">-18.96</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">1.0</td>
              </tr>
              <tr>
                <td style="text-align:left;">RIVWA</td>
                <td style="text-align:center;">79.09</td>
                <td style="text-align:center;">29.75</td>
                <td style="text-align:center;">
                <strong>-27.47</strong></td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">1.4</td>
              </tr>
              <tr>
                <td style="text-align:left;">SkillCraft</td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td style="text-align:left;">BM</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">0.00</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">3.5</td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>M</em>=10</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td></td>
              </tr>
              <tr>
                <td style="text-align:left;">SA</td>
                <td style="text-align:center;">4530.56</td>
                <td style="text-align:center;">220837.20</td>
                <td style="text-align:center;">50.75</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">7.6</td>
              </tr>
              <tr>
                <td style="text-align:left;">IVWA</td>
                <td style="text-align:center;">90.75</td>
                <td style="text-align:center;">91.35</td>
                <td style="text-align:center;">38.56</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">7.1</td>
              </tr>
              <tr>
                <td style="text-align:left;">MV</td>
                <td style="text-align:center;">69.36</td>
                <td style="text-align:center;">60.41</td>
                <td style="text-align:center;">-3.61</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">0.1</td>
              </tr>
              <tr>
                <td style="text-align:left;">RIVWA</td>
                <td style="text-align:center;">
                <strong>20.66</strong></td>
                <td style="text-align:center;">
                <strong>5.01</strong></td>
                <td style="text-align:center;">
                <strong>-0.75</strong></td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">0.2</td>
              </tr>
            </tbody>
          </table>
        </div>
        <section id="sec-15">
          <p><em>6.4.1 MovieLens Data.</em> This is a popular
          public movie rating dataset <a class="fn" href="#fn2" id=
          "foot-fn2"><sup>2</sup></a> containing 20,000,263 movie
          ratings by 138,493 users of 27,278 movies from 1995 –
          2015. We use the following features for modeling: user
          Id, movie Id, rate year, movie year, genre categories,
          user tags and genome tags with relevance above 0.8.</p>
          <p>Different from the Prudential dataset where the
          feature space dimension is fixed and small; the total
          number of features in this example is much larger than
          <em>N</em> and highly sparse. In order to estimate the
          variance of coefficients, we apply the hashing trick so
          that the features are reduced to a space of fixed
          dimension, which we fix at 2<sup>10</sup> = 1, 024. Note
          that having a fixed feature space with lower dimension is
          critical for all types of inverse variance weighted
          methods, i.e., IVWA, MV and RIVWA, because they need to
          store the inverse variance matrix from each data
          division, which is a <span class=
          "inline-equation"><span class="tex">$\tilde{D}\times
          \tilde{D}$</span></span> matrix. If <span class=
          "inline-equation"><span class=
          "tex">$\tilde{D}$</span></span> grows with <span class=
          "inline-equation"><span class=
          "tex">$\tilde{N}$</span></span> , the challenge in
          storing <span class="inline-equation"><span class=
          "tex">$\tilde{D} \times \tilde{D}$</span></span>
          weighting matrices compromises the scalability of these
          DC methods. There are DC methods that avoid using inverse
          variance weighting, however, they cannot achieve the
          asymptotic properties as presented in our theorems.</p>
          <p>Each movie has a score from 0.5 to 5.0 with 0.5
          increments (10 ordinal levels). We use a subsample of
          around 1 million instances for our experiments, which
          expands to 9 million binary instances. Similarly, we
          split the data as training, validation and testing set,
          with 60% for training, 10% for validation, and 30% for
          testing. We divide the training data into <em>M</em> =
          1000 parts. Results are shown in Table&nbsp;<a class=
          "tbl" href="#tab2">2</a> where we report similar
          performance metrics as before and compare between the
          different types of DC methods and the benchmark. We do
          not show other single memory methods besides BM because
          they require much longer training time and generally do
          not provide better performance than BM. From
          Table&nbsp;<a class="tbl" href="#tab2">2</a>, we can see
          that both RIVWA and MV have predictions very close to BM,
          and RIVWA has the closest coefficient estimate to BM.</p>
        </section>
        <section id="sec-16">
          <p><em>6.4.2 Criteo Advertisement Data.</em> While our
          paper is motivated by an ordinal ranking ranking problem
          (because it naturally leads to an expanded dataset), as
          we have mentioned at the beginning, the DC technique we
          proposed is applicable to general logistic regression for
          binary classification. We apply this method to a public
          advertisement dataset released by Criteo <a class="fn"
          href="#fn3" id="foot-fn3"><sup>3</sup></a>, which only
          has two outcomes, conversion versus no conversion. The
          dataset has 15 million instances. Due to memory limit
          restriction when computing BM, we randomly sampled
          <em>N</em> = 2, 120, 698 for training, 212,070 for
          validation and 848,277 for testing. We bucketize the
          continuous features into the nearest integer of their
          natural logged values. Then we apply the same hashing
          trick and map all features into a size of <em>D</em> = 1,
          024. Model tuning parameters are selected to maximize the
          AUC.</p>
          <p>Table&nbsp;<a class="tbl" href="#tab2">2</a> shows
          results for BM and DC methods at <em>M</em> = 200 and
          <em>M</em> = 1000. Since the result is binary, we report
          both AUC and absolute prediction loss. When <em>M</em> =
          200, the prediction performance is very similar for all
          types of DC methods. However, when <em>M</em> = 1000,
          only RIVWA and SA preserves comparable performance as BM.
          In all cases, RIVWA has the smallest deviation from BM in
          terms of coefficient estimation. Figure&nbsp;<a class=
          "fig" href="#fig2">2</a> shows the ROC curves of the
          different methods at <em>M</em> = 200 and <em>M</em> =
          1000. Our proposed RIVWA method achieves identical
          performance in prediction as that of BM in both
          cases.</p>
        </section>
        <section id="sec-17">
          <p><em>6.4.3 E-commerce Advertisement Data.</em> This
          dataset records online advertisement from a major
          internet based business. The dataset consists of 3
          ordinal levels: an ad impression on a publisher website
          which did not lead to a click (<em>k</em> = 1), an ad
          impression which led to a click but did not lead to any
          product purchase (<em>k</em> = 2) and an ad impression
          which led to a click followed by a product purchase
          (<em>k</em> = 3). Naturally, a purchase is valued more
          than a click, which is valued more than an impression
          which did not lead to a click (thus, a natural ordinal
          ranking is induced).</p>
          <p>For training, we collected the impression, click and
          purchase data over a period of 1 week (with 2 day click
          attribution and 7 day purchase attribution). We took a
          single day's data for validation and another day's data
          for testing. The number of instances and features are in
          the millions and we apply the same hashing trick to
          project the original feature space into a fixed
          dimensional space. The training data are randomly divided
          into <em>M</em> = 1000 parts.</p>
          <p>Table&nbsp;<a class="tbl" href="#tab2">2</a> shows
          results of different DC methods as well as the benchmark.
          We can see that RIVWA has the best prediction accuracy in
          terms of absolute prediction loss, and its estimate is
          close to that of benchmark. Although IVWA yields similar
          performance in terms of <em>d</em> <sub>1</sub> and
          <em>d</em> <sub>2</sub> to ours, it has a much larger
          prediction loss.</p>
        </section>
        <section id="sec-18">
          <p><em>6.4.4 SkillCraft Data.</em> SkillCraft is a
          dataset <a class="fn" href="#fn4" id=
          "foot-fn4"><sup>4</sup></a> for users gaming league rank
          prediction. The objective of this data is to predict the
          league of each player using some features related to
          gaming behaviors. Including all two way interactions, we
          have 152 total number of features and 3395 instances.
          Because the data size is small, we report results for
          <em>M</em> = 10 in Table&nbsp;<a class="tbl" href=
          "#tab2">2</a>. Again, we do a train-validation-testing
          split according to the ratios <span class=
          "inline-equation"><span class="tex">$60\% : 10\% :
          30\%$</span></span> .</p>
        </section>
      </section>
    </section>
    <section id="sec-19">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span> Discussion</h2>
        </div>
      </header>
      <p>RIVWA places heavy theoretical emphasis on coefficient
      estimation because many downstream analyses are dependent on
      the estimation results, such as ranking prediction,
      calibration and estimation of probabilities. In such cases,
      RIVWA is more superior than methods that purely focus on
      prediction. A limitation of our method, as is for all
      variance-dependent DC methods, is that it requires the
      feature space to be fixed in dimension. For feature space
      that are not known in advance, an additional feature
      reduction step, such as hashing or embedding, is needed to
      project the unknown dimensional space into a fixed and lower
      dimensional feature space.</p>
      <p>In the application examples considered in this paper, the
      numbers of unique class labels are small. Indeed, it is of
      great interest to extend the setting of classic multi-label
      ordinal/multinomial classification considered in this paper
      to the case where the number of labels <em>K</em> could reach
      hundres, thousands or even more. In principle, <em>K</em>
      being large will not compromise the computational efficiency
      of our divide-and-conquer algorithm because the number of
      data parts <em>M</em> can also increase to accomodate the
      large scale data expansion. However, challenges may arise
      pertaining to the issue of rare and unbalanced labels. For
      example, some data parts might not contain training samples
      from some of the rare classes, resulting in some parameters
      to be unidentifiable. Although a quick-and-dirty approach can
      be to bin the rare class labels into larger classes in the
      divided training steps, and then train another classifier for
      the binned rare labels on the combined dataset, a more
      systematic way for such extreme multi-label classification
      problem is worth exploring in future works under the
      divide-and-conquer framework.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Abraham Bagherjeiran,
        Andrew&nbsp;O Hatch, and Adwait Ratnaparkhi. 2010. Ranking
        for the conversion funnel. In <em><em>Proceedings of
        SIGIR</em></em> . ACM, 146–153.</li>
        <li id="BibPLXBIB0002" label="[2]">Kuang-Yu Chang, Chu-Song
        Chen, and Yi-Ping Hung. 2010. A ranking approach for human
        ages estimation based on face images. In <em><em>Pattern
        Recognition (ICPR), 2010 20th International Conference
        on</em></em> . IEEE, 3396–3399.</li>
        <li id="BibPLXBIB0003" label="[3]">Sougata Chaudhuri,
        Abraham Bagherjeiran, and James Liu. 2017. Ranking and
        calibrating click-attributed purchases in performance
        display advertising. In <em><em>Proceedings of the 2017
        AdKDD and TargetAd Workshop</em></em> . 145–152.</li>
        <li id="BibPLXBIB0004" label="[4]">Po-Lung Chen, Chen-Tse
        Tsai, Yao-Nan Chen, Ku-Chun Chou, Chun-Liang Li, Cheng-Hao
        Tsai, Kuan-Wei Wu, Yu-Cheng Chou, Chung-Yi Li, Wei-Shih
        Lin, <em>et al.</em> 2011. A linear ensemble of individual
        and blended models for music rating prediction. In
        <em><em>Proceedings of the 2011 International Conference on
        KDD Cup 2011-Volume 18</em></em> . JMLR. org, 21–60.</li>
        <li id="BibPLXBIB0005" label="[5]">Xueying Chen and Min-ge
        Xie. 2014. A split-and-conquer approach for analysis of
        extraordinarily large data. <em><em>Statistica
        Sinica</em></em> (2014), 1655–1684.</li>
        <li id="BibPLXBIB0006" label="[6]">Wei Chu and
        S&nbsp;Sathiya Keerthi. 2005. New approaches to support
        vector ordinal regression. In <em><em>Proceedings of the
        22nd international conference on Machine learning</em></em>
        . ACM, 145–152.</li>
        <li id="BibPLXBIB0007" label="[7]">Koby Crammer and Yoram
        Singer. 2002. Pranking with ranking. In <em><em>Advances in
        neural information processing systems</em></em> .
        641–647.</li>
        <li id="BibPLXBIB0008" label="[8]">Wan-Yu Deng, Qing-Hua
        Zheng, Shiguo Lian, Lin Chen, and Xin Wang. 2010. Ordinal
        extreme learning machine. <em><em>Neurocomputing</em></em>
        74, 1 (2010), 447–456.</li>
        <li id="BibPLXBIB0009" label="[9]">John&nbsp;C Duchi, Alekh
        Agarwal, and Martin&nbsp;J Wainwright. 2012. Dual averaging
        for distributed optimization: Convergence analysis and
        network scaling. <em><em>IEEE Transactions on Automatic
        control</em></em> 57, 3 (2012), 592–606.</li>
        <li id="BibPLXBIB0010" label="[10]">Bradley Efron and
        Robert&nbsp;J Tibshirani. 1994. <em><em>An introduction to
        the bootstrap</em></em> . CRC press.</li>
        <li id="BibPLXBIB0011" label="[11]">Rong-En Fan, Kai-Wei
        Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
        2008. LIBLINEAR: A Library for Large Linear Classification.
        <em><em>J. Mach. Learn. Res.</em></em> 9 (June 2008),
        1871–1874.</li>
        <li id="BibPLXBIB0012" label="[12]">Eibe Frank and Mark
        Hall. 2001. A simple approach to ordinal classification. In
        <em><em>European Conference on Machine Learning</em></em> .
        Springer, 145–156.</li>
        <li id="BibPLXBIB0013" label="[13]">Bin Gu, Victor&nbsp;S
        Sheng, Keng&nbsp;Yeow Tay, Walter Romano, and Shuo Li.
        2015. Incremental support vector learning for ordinal
        regression. <em><em>IEEE Transactions on Neural networks
        and learning systems</em></em> 26, 7(2015), 1403–1416.</li>
        <li id="BibPLXBIB0014" label="[14]">Yehuda Koren and Joe
        Sill. 2011. OrdRec: an ordinal model for predicting
        personalized item rating distributions. In
        <em><em>Proceedings of the fifth ACM conference on
        Recommender systems</em></em> . ACM, 117–124.</li>
        <li id="BibPLXBIB0015" label="[15]">Ling Li and Hsuan-Tien
        Lin. 2007. Ordinal regression by extended binary
        classification. <em><em>Advances in neural information
        processing systems</em></em> 19 (2007), 865.</li>
        <li id="BibPLXBIB0016" label="[16]">P. Li, C. Burges, and
        Q. Wu. 2007. McRank: Learning to Rank Using Multiple
        Classification and Gradient Boosting. In <em><em>Advances
        in Neural Information Processing Systems</em></em> ,
        Vol.&nbsp;19. The MIT Press, 897–904.</li>
        <li id="BibPLXBIB0017" label="[17]">Hsuan-Tien Lin and Ling
        Li. 2012. Reduction from cost-sensitive ordinal ranking to
        weighted binary classification. <em><em>Neural
        Computation</em></em> 24, 5 (2012), 1329–1367.</li>
        <li id="BibPLXBIB0018" label="[18]">Gideon&nbsp;S Mann,
        Ryan Mcdonald, Mehryar Mohri, Nathan Silberman, and Dan
        Walker. 2009. Efficient large-scale distributed training of
        conditional maximum entropy models. In <em><em>Advances in
        Neural Information Processing Systems</em></em> .
        1231–1239.</li>
        <li id="BibPLXBIB0019" label="[19]">Peter McCullagh. 1980.
        Regression models for ordinal data. <em><em>Journal of the
        royal statistical society. Series B
        (Methodological)</em></em> (1980), 109–142.</li>
        <li id="BibPLXBIB0020" label="[20]">Brendan McMahan. 2011.
        Follow-the-regularized-leader and mirror descent:
        Equivalence theorems and l1 regularization. In
        <em><em>Proceedings of the Fourteenth International
        Conference on Artificial Intelligence and
        Statistics</em></em> . 525–533.</li>
        <li id="BibPLXBIB0021" label="[21]">Angelia Nedic and
        Asuman Ozdaglar. 2009. Distributed subgradient methods for
        multi-agent optimization. <em><em>IEEE Trans. Automat.
        Control</em></em> 54, 1 (2009), 48–61.</li>
        <li id="BibPLXBIB0022" label="[22]">E&nbsp;Michael Nussbaum
        and Gregory Schraw. 2007. Promoting
        argument-counterargument integration in students’ writing.
        <em><em>The Journal of Experimental Education</em></em> 76,
        1 (2007), 59–92.</li>
        <li id="BibPLXBIB0023" label="[23]">Shyamsundar Rajaram,
        Ashutosh Garg, Xiang&nbsp;Sean Zhou, and Thomas&nbsp;S
        Huang. 2003. Classification approach towards ranking and
        sorting problems. In <em><em>European Conference on Machine
        Learning</em></em> . Springer, 301–312.</li>
        <li id="BibPLXBIB0024" label="[24]">S&nbsp;Sundhar Ram,
        Angelia Nedić, and Venugopal&nbsp;V Veeravalli. 2010.
        Distributed stochastic subgradient projection algorithms
        for convex optimization. <em><em>Journal of optimization
        theory and applications</em></em> 147, 3(2010),
        516–545.</li>
        <li id="BibPLXBIB0025" label="[25]">Steven&nbsp;L Scott,
        Alexander&nbsp;W Blocker, Fernando&nbsp;V Bonassi,
        Hugh&nbsp;A Chipman, Edward&nbsp;I George, and
        Robert&nbsp;E McCulloch. 2016. Bayes and big data: The
        consensus Monte Carlo algorithm. <em><em>International
        Journal of Management Science and Engineering
        Management</em></em> 11, 2(2016), 78–88.</li>
        <li id="BibPLXBIB0026" label="[26]">Amnon Shashua and Anat
        Levin. 2003. Ranking with large margin principle: Two
        approaches. In <em><em>Advances in neural information
        processing systems</em></em> . 961–968.</li>
        <li id="BibPLXBIB0027" label="[27]">Alexander&nbsp;J Sutton
        and Julian Higgins. 2008. Recent developments in
        meta-analysis. <em><em>Statistics in medicine</em></em> 27,
        5 (2008), 625–650.</li>
        <li id="BibPLXBIB0028" label="[28]">Lu Tang, Ling Zhou, and
        Peter X.-K. Song. 2016. Method of divide-and-combine in
        regularised generalised linear models for big data.
        <em><em>arXiv:1611.06208v1 [stat.ME]</em></em> (2016).</li>
        <li id="BibPLXBIB0029" label="[29]">Robert Tibshirani.
        1996. Regression shrinkage and selection via the lasso.
        <em><em>Journal of the Royal Statistical Society. Series B
        (Methodological)</em></em> (1996), 267–288.</li>
        <li id="BibPLXBIB0030" label="[30]">Yuchen Zhang,
        Martin&nbsp;J Wainwright, and John&nbsp;C Duchi. 2012.
        Communication-efficient algorithms for statistical
        optimization. In <em><em>Advances in Neural Information
        Processing Systems</em></em> . 1502–1510.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>Prudential
    Financial insurance data source <a class=
    "link-inline force-break" href=
    "https://www.kaggle.com/c/prudential-life-insurance-assessment">
    https://www.kaggle.com/c/prudential-life-insurance-assessment</a></p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>MovieLens movie
    rating data source <a class="link-inline force-break" href=
    "https://grouplens.org/datasets/movielens/20m/">https://grouplens.org/datasets/movielens/20m/</a></p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>Criteo
    advertisement conversion data source <a class=
    "link-inline force-break" href=
    "http://research.criteo.com/criteo-releases-first-public-dataset-conversion-logs/">
    http://research.criteo.com/criteo-releases-first-public-dataset-conversion-logs/</a></p>
    <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>SkillCraft
    gaming data source <a class="link-inline force-break" href=
    "http://archive.ics.uci.edu/ml/datasets/skillcraft1+master+table+dataset">
    http://archive.ics.uci.edu/ml/datasets/skillcraft1+master+table+dataset</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3191658">https://doi.org/10.1145/3184558.3191658</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
