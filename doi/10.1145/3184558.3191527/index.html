<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Combining RDF Graph Data and Embedding Models for an
  Augmented Knowledge Graph</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "../../../data/dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Combining RDF Graph Data and
          Embedding Models for an Augmented Knowledge
          Graph</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Andriy</span> <span class=
          "surName">Nikolov</span>, metaphacts GmbH, Walldorf,
          Germany, <a href=
          "mailto:an@metaphacts.com">an@metaphacts.com</a>
        </div>
        <div class="author">
          <span class="givenName">Peter</span> <span class=
          "surName">Haase</span>, metaphacts GmbH, Walldorf,
          Germany, <a href=
          "mailto:ph@metaphacts.com">ph@metaphacts.com</a>
        </div>
        <div class="author">
          <span class="givenName">Daniel M.</span> <span class=
          "surName">Herzig</span>, metaphacts GmbH, Walldorf,
          Germany, <a href=
          "mailto:dh@metaphacts.com">dh@metaphacts.com</a>
        </div>
        <div class="author">
          <span class="givenName">Johannes</span> <span class=
          "surName">Trame</span>, metaphacts GmbH, Walldorf,
          Germany, <a href=
          "mailto:jt@metaphacts.com">jt@metaphacts.com</a>
        </div>
        <div class="author">
          <span class="givenName">Artem</span> <span class=
          "surName">Kozlov</span>, metaphacts GmbH, Walldorf,
          Germany, <a href=
          "mailto:ak@metaphacts.com">ak@metaphacts.com</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191527"
        target=
        "_blank">https://doi.org/10.1145/3184558.3191527</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Vector embedding models have recently become
        popular for encoding both structured and unstructured data.
        In the context of knowledge graphs such models often serve
        as additional evidence supporting various tasks related to
        the knowledge base population: e.g., information extraction
        or link prediction to expand the original dataset. However,
        the embedding models themselves are often not used directly
        alongside structured data: they merely serve as additional
        evidence for structured knowledge extraction. In the
        <em>metaphactory</em> knowledge graph management platform,
        we use federated hybrid SPARQL queries for combining
        explicit information stated in the graph, implicit
        information from the associated embedding models, and
        information extracted using vector embeddings in a
        transparent way for the end user. In this paper we show how
        we integrated RDF data with vector space models to
        construct an augmented knowledge graph to be used in
        customer applications.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS
        Concepts:</span> • <strong>Information systems</strong> →
        <strong>Resource Description Framework (RDF);</strong>
        <em>Information extraction;</em> • <strong>Computing
        methodologies</strong> → <strong>Neural
        networks;</strong></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>knowledge
          graph</small>,</span> <span class="keyword"><small>word
          embeddings</small>,</span> <span class=
          "keyword"><small>graph embeddings</small>,</span>
          <span class="keyword"><small>SPARQL
          federation</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Andriy Nikolov, Peter Haase, Daniel M. Herzig, Johannes
          Trame, and Artem Kozlov. 2018. Combining RDF Graph Data
          and Embedding Models for an Augmented Knowledge Graph. In
          <em>WWW '18 Companion: The 2018 Web Conference
          Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon,
          France. ACM, New York, NY, USA</em> 4 Pages. <a href=
          "https://doi.org/10.1145/3184558.3191527" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3191527</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Representing information from semantic web datasets and
      free text using vector embeddings provides a powerful tool
      helping to infer implicit relations between data entities.
      These models can be used directly to predict new links in a
      knowledge graph or serve as input data for machine learning
      algorithms which perform knowledge graph population from
      unstructured sources (e.g., free text). They provide an
      alternative representation view for knowledge graph data:
      continuous multi-dimensional vectors as opposed to a directed
      graph. For this reason, vector space embedding models are
      normally used for offline tasks separately from the actual
      data: they merely provide input to other algorithms, which in
      turn have their results materialized, stored, and exploited
      in the graph form.</p>
      <p>There exist many use case scenarios where information
      provided by the embedding models serves as a valuable
      addition to the knowledge graph itself: e.g., to retrieve the
      most similar entities to provide suggestions to the user. It
      requires the ability to access and query the graph and the
      vector space models in a uniform way. Such an ability would
      allow providing the best available answer to given user
      queries: e.g., returning exact answers stored in the original
      graph in an explicit way as well as adding uncertain results
      inferred from an embedding model or extracted from external
      sources using machine learning. Moreover, different types of
      embedding models such as embeddings for entities and
      relations extracted from the graph and word2vec models
      learned from natural language text can complement each other
      to improve the performance on relevant knowledge graph
      population tasks&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0008">8</a>].</p>
      <p>The main motivation for this work comes from our
      experience with the <em>metaphactory</em> knowledge graph
      management platform<a class="fn" href="#fn1" id=
      "foot-fn1"><sup>1</sup></a>, which is used in a variety of
      application domains (e.g., cultural heritage, life sciences,
      pharmaceutics, and IoT infrastructure). In this paper we
      describe our approach to enable combined usage of the
      original RDF graph data, implicit relations encoded by word
      and graph embedding models, and additional knowledge
      extracted with the help of embeddings by transparent querying
      using federated SPARQL queries. This allows the platform to
      support building end-user knowledge graph management
      applications that make use of both explicit RDF data and
      associated vector space models in a transparent way. We call
      such integrated expanded data source an <em>augmented
      knowledge graph</em>.</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Augmented
          knowledge graph construction</h2>
        </div>
      </header>
      <p>Augmented knowledge graphs (Figure&nbsp;<a class="fig"
      href="#fig1">1</a>) includes three types of data sources:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">The original core knowledge graph
        expressed in RDF<br /></li>
        <li id="list2" label="•">Embedding models describing
        entities and relations from the original knowledge graph
        and expressed as sets of vectors<br /></li>
        <li id="list3" label="•">Additional statements extracted
        from unstructured sources (e.g., free text) using the
        information from the knowledge graph and embedding models
        as evidence<br /></li>
      </ul>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3200000/3191527/images/www18companion-266-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">Augmented knowledge graph: components and
          access.</span>
        </div>
      </figure>
      <p>The core knowledge graph represents the reference dataset
      consisting of two parts: the ontological schema and
      instance-level data. These data are stored in the triple
      store and accessed directly using the SPARQL 1.1 query
      language. Moreover, the core knowledge graph serves as a
      source of evidence for training machine learning models to
      extend it with additional data.</p>
      <p><em>Graph embedding models</em> aim at encoding
      information contained in a knowledge graph in a continuous
      vector space model that would preserve to the maximal extent
      information about the statements contained in the original
      graph and can be utilized to infer new links. Graph embedding
      models such as TransE&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0001">1</a>], TransR&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0003">3</a>], or HolE&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0006">6</a>] produce
      embedding vectors for each entity and relation in the graph.
      Combining the vectors for two entities (knowledge graph
      instances) <em>E</em> <sub>1</sub> and <em>E</em>
      <sub>2</sub> and a relation <em>R</em> provides a degree of
      confidence that the knowledge graph contains a true statement
      <em>R</em>(<em>E</em> <sub>1</sub>, <em>E</em> <sub>2</sub>).
      Close distance between two entity embedding vectors points to
      a degree of semantic similarity, i.e., that two entities
      participate in the same kinds of relations.</p>
      <p>In addition to embeddings learned directly from the graph,
      <em>word embeddings</em> produced from a related text corpus
      (e.g., using a popular <em>word2vec</em>
      algorithm&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>]) are utilized as well. Unlike the
      graph embeddings, the word2vec model contains vectors
      corresponding to the words of the natural language as opposed
      to ontological instances. This requires an additional step of
      mapping the instances from the knowledge graph to word2vec
      vectors. Such mapping can be realized in two ways:</p>
      <ul class="list-no-style">
        <li id="list4" label="•">Learning the word2vec model from
        an already annotated corpus. If knowledge graph entities
        are explicitly referenced in the text (e.g., as in
        Wikipedia), the trained model will contain vector entries
        for entities alongside words. If these entities are
        contained in the core knowledge graph, the model can be
        used directly, otherwise an additional instance matching
        step is performed.<br /></li>
        <li id="list5" label="•">Label-based mapping. For RDF
        instances not directly represented among pre-trained word
        embeddings, their labels can be used to position the
        entities in the word vector space.<br /></li>
      </ul>
      <p>Structured RDF graph model and corresponding embedding
      models complement each other. The former contains explicit
      and reliable statements about entities. Embedding models can
      be used to extract two additional kinds of statements:</p>
      <ul class="list-no-style">
        <li id="list6" label="•">Statements involving relations
        contained in the graph schema. For example, if the graph
        contains a relation <em>literaryGenre</em>, which is
        present only for some instances of type <em>Book</em>,
        possible missing values for the property can be provided by
        the graph embedding model.<br /></li>
        <li id="list7" label="•">“Fuzzy” relations not present in
        the schema. For instance, embedding models can be used to
        compute semantic similarity between instances. This allows
        posting requests such as “who is the most similar to
        Rembrandt?” although the similarity relation is not
        explicitly defined in the graph. Furthermore, vector space
        proximity can be used to compute non-standard aggregation
        functions: e.g., to find the most similar instance to a
        group of other instances.<br /></li>
      </ul>
      <p>Due to the amount of possible questions which can be
      posted to the vector space models, it makes sense to compute
      such information on demand rather than materialize as RDF and
      store inside the knowledge graph.</p>
      <p>Finally, the graph itself as well as associated embedding
      models can be used as evidence to extract additional relevant
      statements from relevant unstructured sources: e.g., text
      and/or images.</p>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Combining
          embeddings for relation extraction</h2>
        </div>
      </header>
      <p>Trained vector space embeddings can be used as input data
      for information extraction algorithms to extend the knowledge
      graph using information from unstructured data sources
      (primarily, text). In particular, relation extraction from
      text is a long-studied research direction, which benefited in
      recent years from the development of network-based
      algorithms. Embedding vectors serve as input for
      convolutional or recurrent neural network algorithms that
      make a decision on whether a particular sentence or phrase
      describes a specific ontological relation between a pair of
      entities. Usually, such algorithms rely on the word embedding
      models learned from a text corpus. We extended a
      state-of-the-art model by combining the outputs learned from
      a text sequence with the embedding vectors learned from a
      knowledge graph. As the baseline for our approach, we adapted
      a bidirectional GRU network algorithm with sentence-level
      attention&nbsp;<a class="fn" href="#fn2" id=
      "foot-fn2"><sup>2</sup></a>, which in turn is based on the
      combination of ideas described in&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0009">9</a>] and&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0004">4</a>].</p>
      <p>One training example in the training setup represents a
      single sentence mentioning two entities. The input of the
      network is constructed by encoding each token in the
      sentence. Each input vector is generated by concatenating the
      word2vec embedding of the token and the position embedding
      (positions of the token in the sentence relative to the
      entities <em>h</em> and <em>t</em>). These vector
      representations of the tokens are fed to the neural network
      (Figure&nbsp;<a class="fig" href="#fig2">2</a>) consisting of
      several layers.</p>
      <p><em>Bi-directional GRU layer</em>. The layer includes two
      sets of GRU units&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>] which process the incoming sequence
      in two different directions: forward and backward. The
      outputs of each set at each step constitute vectors
      <span class="inline-equation"><span class=
      "tex">$\overleftarrow{h}$</span></span> and <span class=
      "inline-equation"><span class=
      "tex">$\overrightarrow{h}$</span></span> , which are added to
      produce the combined output of the layer: <span class=
      "inline-equation"><span class="tex">$ {h}_i =
      \overleftarrow{h_i} \oplus
      \overrightarrow{h_i}$</span></span> . The output of the layer
      is a matrix <em>H</em> formed by vectors h<sub>1</sub>, ⋅⋅⋅,
      h <sub><em>n</em></sub> .</p>
      <p><em>Attention layer</em> The word attention layer
      post-processes the output <em>H</em> of the bi-directional
      GRU layer to produce a single output vector. The word-level
      attention layer combines the outputs produced by the
      recurrent layer using a weighted sum and produces a single
      sentence embedding vector for each training example.</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\[ M=tanh(H) \]</span><br />
        </div>
      </div>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\[ \alpha =softmax(w^T M)
          \]</span><br />
        </div>
      </div>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\[ h^* = tanh(H \alpha ^T),
          \]</span><br />
        </div>
      </div>where <em>h</em> <sup>*</sup> is the output of the
      hidden word-level attention layer.
      <p></p>
      <p>A further (optional) step involves applying sentence-level
      attention proposed by&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>]. Although a pair of entities
      <em>E</em> <sub>1</sub> and <em>E</em> <sub>2</sub>, for
      which a relation <em>R</em> holds, occurs in a sentence, it
      is not always relevant for extracting this relation: e.g., a
      sentence “Vladimir Putin visited St Petersburg in Feb 2017”
      cannot serve as a supporting evidence for a correct statement
      <em>bornIn(Vladimir Putin, St Petersburg)</em>. To address
      these, different training instances for the relation
      <em>R</em> themselves get different weights, further
      adjusting the output value <em>h</em> <sup>*</sup>.</p>
      <p><em>Word-based classification output</em> The output of
      the word-based classification of the input sentence
      <em>S</em> is produced by making a linear transformation of
      <em>h</em> <sup>*</sup> and applying the softmax
      function.</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\[
          \hat{p}(y|S)=softmax(W^{(S)}h^*+b^{(S)}) \]</span><br />
        </div>
      </div>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\[
          \hat{y}=\mathop{arg\,max}_y(\hat{p}(y|S)) \]</span><br />
        </div>
      </div>
      <p></p>
      <p><em>Combining with entity embedding vectors</em> To
      improve the quality of the classification, we further
      extended the network to include the embedding vectors learned
      from the knowledge graph data as additional evidence. An
      additional layer combines the output vector produced by the
      word-based classification model with TransE vectors. The
      input of the layer is formed by concatenating the vectors
      {<em>w<sup>out</sup></em> , <em>e</em> <sub>1</sub>,
      <em>e</em> <sub>2</sub>, d}, where <em>w<sup>out</sup></em>
      is formed by the output of the word-based classifier,
      <em>e</em> <sub>1</sub> and <em>e</em> <sub>2</sub> are
      TransE embedding vectors of entities <em>E</em> <sub>1</sub>
      and <em>E</em> <sub>2</sub>, and the vector d contains the
      vector space distances for each relation
      <em>R<sub>i</sub></em> :</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\[ d_i = ||e_1 + r_i - e_2||
          \]</span><br />
        </div>
      </div>.
      <figure id="fig2">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3200000/3191527/images/www18companion-266-fig2.svg"
        class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class=
          "figure-title">Neural network used for relation
          extraction using combined word2vec and TransE
          vectors.</span>
        </div>
      </figure>
      <p></p>
      <p>Results returned by the output classification layer are
      materialized as RDF triples and stored in a triple store.</p>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span>
          Experiments</h2>
        </div>
      </header>
      <p>We conducted experiments to investigate the added value of
      TransE graph embeddings using a subset of Wikidata
      (containing information about persons and their relations)
      and a text corpus containing Wikidata abstracts. For
      experiments, we re-trained the TransE embeddings to exclude
      relations contained in the test set. We compared the
      <em>F</em>1 measure obtained for the relation extraction task
      by the original model using only word2vec embeddings with the
      extended model utilizing both word2vec and TransE embeddings
      (Table&nbsp;<a class="tbl" href="#tab1">1</a>).</p>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">Precision, recall, and F1 measure for the
          relation extraction task obtained using only word
          embeddings vs a combination of word and graph
          embeddings.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:left;">Wikidata relation</th>
              <th colspan="3" style="text-align:left;">
                Text + word2vec embeddings
                <hr />
              </th>
              <th colspan="3" style="text-align:left;">
                Combined model
                <hr />
              </th>
            </tr>
            <tr>
              <th style="text-align:left;"></th>
              <th style="text-align:left;">p</th>
              <th style="text-align:left;">r</th>
              <th style="text-align:left;">F1</th>
              <th style="text-align:left;">p</th>
              <th style="text-align:left;">r</th>
              <th style="text-align:left;">F1</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:left;">P22 (father)</td>
              <td style="text-align:left;">0.90</td>
              <td style="text-align:left;">0.90</td>
              <td style="text-align:left;">0.90</td>
              <td style="text-align:left;">0.91</td>
              <td style="text-align:left;">0.93</td>
              <td style="text-align:left;">
              <strong>0.92</strong></td>
            </tr>
            <tr>
              <td style="text-align:left;">P40 (child)</td>
              <td style="text-align:left;">0.78</td>
              <td style="text-align:left;">0.85</td>
              <td style="text-align:left;">0.81</td>
              <td style="text-align:left;">0.88</td>
              <td style="text-align:left;">0.83</td>
              <td style="text-align:left;">
              <strong>0.85</strong></td>
            </tr>
            <tr>
              <td style="text-align:left;">P26 (spouse)</td>
              <td style="text-align:left;">0.89</td>
              <td style="text-align:left;">0.75</td>
              <td style="text-align:left;">0.81</td>
              <td style="text-align:left;">0.89</td>
              <td style="text-align:left;">0.77</td>
              <td style="text-align:left;">
              <strong>0.83</strong></td>
            </tr>
            <tr>
              <td style="text-align:left;">P3373 (sibling)</td>
              <td style="text-align:left;">0.85</td>
              <td style="text-align:left;">0.78</td>
              <td style="text-align:left;">0.81</td>
              <td style="text-align:left;">0.92</td>
              <td style="text-align:left;">0.78</td>
              <td style="text-align:left;">
              <strong>0.85</strong></td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>While the TransE embeddings themselves do not achieve high
      accuracy in the link prediction task for the very precise
      factual information (F1 measure between 0.36 and 0.65), they
      provide added value in refining the output of the text
      extraction model leading to improved accuracy in all cases.
      Their main impact was in filtering out spurious candidate
      pairs.</p>
      <p>RDF statements extracted from text, which do not have 100%
      precision are stored separately from the main knowledge graph
      in a special repository.</p>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Augmented
          knowledge graph querying</h2>
        </div>
      </header>
      <p>Different components of the augmented knowledge graph are
      expressed in different formats: RDF triples and embedding
      vectors. In order to achieve seamless integration of graph
      and vector space models, these mutually complementary
      components must be queried in the same way. To this end, we
      extend the standard SPARQL 1.1 federation mechanism for
      hybrid queries. The Ephedra query federation
      architecture&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0007">7</a>] allows querying external compute
      services as SPARQL 1.1 federation members. This is achieved
      by building wrappers that translate SPARQL 1.1 SERVICE
      clauses into service requests and then bind results returned
      by the service to the output variables.</p>
      <p>Thus, in order to be able to query vector embedding models
      using SPARQL 1.1, the embedding wrapper service must
      transform information expressed in embedding vectors into RDF
      triples. As discussed in section&nbsp;<a class="sec" href=
      "#sec-7">2</a>, vector embeddings can be used to retrieve two
      kinds of statements: additional instantiations of the object
      properties from the knowledge graph schema and similarity
      relations based on the proximity between instances in the
      vector space. The first kind of statements is trivial to
      obtain from the graph embeddings such as TransE: given two
      elements of a triple, one can calculate the expected
      embedding vector for the third one and retrieve the instances
      with the shortest distance to this expected one. For example,
      to retrieve the expected object value for a property
      <em>R</em> of a subject instance <em>E<sub>s</sub></em> , one
      would need to compute the position of the expected value
      using the corresponding embedding vectors <em>r</em> and
      <em>e</em> <sub>1</sub>: <span class=
      "inline-equation"><span class=
      "tex">$\hat{e}_o=e_1+r$</span></span> and then return the
      instance <em>E<sub>o</sub></em> such that <span class=
      "inline-equation"><span class="tex">$e_o =
      \mathop{arg\,min}_i(||e_i-\hat{e}_o||)$</span></span> .</p>
      <p>To incorporate additional relations based on similarity,
      we defined an artificial predicate <em>similarTo</em>, which
      returns the most similar objects to a given subject instance:
      given <em>E<sub>s</sub></em> , return <em>E<sub>o</sub></em>
      such that <span class="inline-equation"><span class=
      "tex">$e_o = \mathop{arg\,min}_i(||e_i-e_s||)$</span></span>
      . Additionally, similarity is defined as an aggregation
      function returning entities which are close to a group of
      other entities. For this, the service first computes a
      centroid vector <em>e<sub>c</sub></em> =
      <em>avg</em>(<em>e<sub>k</sub></em> ) for the set of input
      entities <em>E<sub>k</sub></em> and then returns
      <em>E<sub>o</sub></em> such that <span class=
      "inline-equation"><span class="tex">$e_o =
      \mathop{arg\,min}_i(||e_i-e_c||)$</span></span> .</p>
      <p>Unlike the TransE graph embedding model, embeddings
      trained from text using word2vec do not contain relation
      embedding vectors explicitly. To compute these, we need to
      involve information from the main knowledge graph. In order
      to compute an embedding vector <em>r</em> in the word2vec
      vector embedding space for an object property <em>R</em>, we
      first need to select all pairs <span class=
      "inline-equation"><span class="tex">$(E^h_i,
      E^t_i)$</span></span> from the knowledge graph such that the
      relation <span class="inline-equation"><span class=
      "tex">$R(E^h_i, E^t_i)$</span></span> holds for them. Then,
      the embedding vector <em>r</em> for the relation <em>R</em>
      can be calculated as <span class=
      "inline-equation"><span class=
      "tex">$r=avg(e^t_i-e^h_i)$</span></span> .</p>
      <p>In this way, we implemented the entity retrieval service
      that for a given pair (<em>E<sub>s</sub></em> , <em>R</em>)
      or (<em>R</em>, <em>E<sub>o</sub></em> ) is able to return
      the most likely value for <em>E<sub>o</sub></em> or
      <em>E<sub>s</sub></em> respectively and exposed it as a REST
      API. For this service, we built an Ephedra wrapper which is
      able to transform a SPARQL 1.1 SERVICE clause into a REST API
      call to the entity retrieval service and then convert
      retrieved results into SPARQL variable bindings. The SPARQL
      service accepts the following kinds of input patterns:</p>
      <ul class="list-no-style">
        <li id="list8" label="•"><em>:subjectURI :propertyURI
        ?objectVariable</em><br /></li>
        <li id="list9" label="•"><em>?subjectValue :propertyURI
        :objectURI</em><br /></li>
        <li id="list10" label="•"><em>?variable emb:limit “K”</em>,
        where “K” is a constant denoting the expected number of the
        most fitting results<br /></li>
      </ul>
      <p>With this approach, we are able to formulate SPARQL
      queries returning results over vector space models: e.g.,
      “retrieve a list of entities most similar to
      <em>Rembrandt</em>” or “retrieve the most relevant theme of
      <em>War and Peace</em>”. These results can be joined with
      information explicitly contained in the core knowledge graph
      as RDF using hybrid federated queries. Such queries can
      potentially include more than one SERVICE clause. For
      example, the following query retrieves 10 books most similar
      to “War and Peace” (according to the word2vec embedding
      model) and additionally retrieves information about the
      genres of these books, both stored explicitly in Wikidata and
      guessed using the TransE graph embeddings.</p>
      <p><img src=
      "../../../data/deliveryimages.acm.org/10.1145/3200000/3191527/images/www18companion-266-img1.svg"
      class="img-responsive" alt="" longdesc="" /></p>
    </section>
    <section id="sec-11">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Conclusion and
          Outlook</h2>
        </div>
      </header>
      <p>In this paper we described an architecture enabling a
      unified access to the complementary information contained in
      the knowledge graph and pre-trained embedding vectors.
      Combining the alternative views over data helps to answer
      more complex queries over graph data including fuzzy
      information. Moreover, exploiting different types of vector
      embeddings for the task of knowledge graph population allows
      the performance of the relation extraction procedure to be
      improved.</p>
      <p>In our future work we plan to explore two directions.
      First, we want to focus further on the use of combined
      embedding models for the task of link discovery with external
      datasets to enable smooth inclusion of additional datasets
      into the augmented knowledge graph. Second, we aim at
      exploiting the augmented knowledge graph model to assist the
      user with data authoring tasks: e.g, by providing intelligent
      autosuggestions and pre-filling the initial values in the
      data editing forms.</p>
    </section>
    <section id="sec-12">
      <header>
        <div class="title-info">
          <h2>Acknowledgements</h2>
        </div>
      </header>
      <p>This work has been supported by the Eurostars project
      DIESEL (E!9367) and by the German BMWI Project GEISER
      (project no. 01MD16014).</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Antoine Bordes, Nicolas
        Usunier, Alberto García-Durán, Jason Weston, and Oksana
        Yakhnenko. 2013. Translating Embeddings for Modeling
        Multi-relational Data. In <em><em>NIPS 2013</em></em> .
        2787–2795.</li>
        <li id="BibPLXBIB0002" label="[2]">Kyunghyun Cho, Bart van
        Merrienboer, Çaglar Gülçehre, Dzmitry Bahdanau, Fethi
        Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning
        Phrase Representations using RNN Encoder-Decoder for
        Statistical Machine Translation. In <em><em>EMNLP 2014,
        Doha, Qatar</em></em> . 1724–1734.</li>
        <li id="BibPLXBIB0003" label="[3]">Yankai Lin, Zhiyuan Liu,
        Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning Entity
        and Relation Embeddings for Knowledge Graph Completion. In
        <em><em>AAAI 2015</em></em> . 2181–2187.</li>
        <li id="BibPLXBIB0004" label="[4]">Yankai Lin, Shiqi Shen,
        Zhiyuan Liu, Huanbo Luan, and Maosong Sun. 2016. Neural
        Relation Extraction with Selective Attention over
        Instances. In <em><em>ACL 2016</em></em> .</li>
        <li id="BibPLXBIB0005" label="[5]">Tomas Mikolov, Ilya
        Sutskever, Kai Chen, Greg&nbsp;S Corrado, and Jeff Dean.
        2013. Distributed representations of words and phrases and
        their compositionality. In <em><em>Advances in neural
        information processing systems</em></em> . 3111–3119.</li>
        <li id="BibPLXBIB0006" label="[6]">Maximilian Nickel,
        Lorenzo Rosasco, and Tomaso&nbsp;A. Poggio. 2016.
        Holographic Embeddings of Knowledge Graphs. In <em><em>AAAI
        2016, Phoenix, Arizona, USA.</em></em> 1955–1961.</li>
        <li id="BibPLXBIB0007" label="[7]">Andriy Nikolov, Peter
        Haase, Johannes Trame, and Artem Kozlov. 2017. Ephedra:
        Efficiently Combining RDF Data and Services Using SPARQL
        Federation. In <em><em>KESW 2017</em></em> . 246–262.</li>
        <li id="BibPLXBIB0008" label="[8]">Steffen Thoma, Achim
        Rettinger, and Fabian Both. 2017. Towards Holistic Concept
        Representations: Embedding Relational Knowledge, Visual
        Attributes, and Distributional Word Semantics. In
        <em><em>ISWC 2017, Vienna, Austria</em></em> .
        694–710.</li>
        <li id="BibPLXBIB0009" label="[9]">Peng Zhou, Wei Shi, Jun
        Tian, Zhenyu Qi, Bingchen Li, Hongwei Hao, and Bo Xu. 2016.
        Attention-Based Bidirectional Long Short-Term Memory
        Networks for Relation Classification. In <em><em>ACL 2016,
        Berlin, Germany</em></em> .</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class=
    "link-inline force-break" href=
    "http://www.metaphactory.com/">http://www.metaphactory.com/</a></p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class=
    "link-inline force-break" href=
    "https://github.com/thunlp/TensorFlow-NRE">https://github.com/thunlp/TensorFlow-NRE</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3191527">https://doi.org/10.1145/3184558.3191527</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
