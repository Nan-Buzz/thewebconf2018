<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Scalable Supervised Discrete Hashing for Large-Scale
  Search</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186072'>https://doi.org/10.1145/3178876.3186072</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186072'>https://w3id.org/oa/10.1145/3178876.3186072</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Scalable Supervised Discrete
          Hashing for Large-Scale Search</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Xin</span> <span class=
          "surName">Luo</span>, Shandong University, <a href=
          "mailto:luoxin.lxin@gmail.com">luoxin.lxin@gmail.com</a>
        </div>
        <div class="author">
          <span class="givenName">Ye</span> <span class=
          "surName">Wu</span>, Shandong University, <a href=
          "mailto:kimiwadewu@gmail.com">kimiwadewu@gmail.com</a>
        </div>
        <div class="author">
          <span class="givenName">Xin-Shun</span> <span class=
          "surName">Xu<a class="fn" href="#fn1" id=
          "foot-fn1"><sup>⁎</sup></a></span>, Shandong University,
          <a href=
          "mailto:xuxinshun@sdu.edu.cn">xuxinshun@sdu.edu.cn</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.3186072"
        target=
        "_blank">https://doi.org/10.1145/3178876.3186072</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Supervised hashing methods have attracted much
        attention in these years. However, most existing supervised
        hashing algorithms have some of the following problems.
        First, most of them leverage the pairwise similarity
        matrix, whose size is quadratic to the number of training
        samples, to supervise the learning of hash codes. Thus,
        they are not scalable when dealing with large data. Second,
        most of them relax the discrete constraints for easy
        optimization and then quantize the learnt real-valued
        solution to binary hash codes. Therefore, the quantization
        error caused by the relaxation may lead to a decline of
        retrieval performance. To address these issues and make the
        supervised method scalable to large datasets, we present a
        novel hashing method, named Scalable Supervised Discrete
        Hashing (SSDH). Specifically, based on a new loss function,
        SSDH bypasses the direct optimization on the <em>n</em> by
        <em>n</em> pairwise similarity matrix. In addition, SSDH
        adopts no relaxation optimization scheme in the learning
        procedure and avoids the large quantization error problem.
        Moreover, during learning, it leverages both the pairwise
        similarity matrix and label matrix; thus, more semantic
        information can be embedded to the learning of hash codes.
        Extensive experiments are conducted on six benchmark
        datasets including two large-scale datasets, i.e., NUS-WIDE
        and ImageNet. The results show that SSDH can outperform
        state-of-the-art baselines on these datasets, demonstrating
        its effectiveness and efficiency.</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Learning-to-Hash; Supervised
          Hashing; Scalable Search; Discrete
          Optimization</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Xin Luo, Ye Wu, and Xin-Shun Xu. 2018. Scalable
          Supervised Discrete Hashing for Large-Scale Search. In
          <em>WWW 2018: The 2018 Web Conference,</em> <em>April
          23–27, 2018 (WWW 2018),</em> <em>Lyon, France. ACM, New
          York, NY, USA</em> 10 Pages. <a href=
          "https://doi.org/10.1145/3178876.3186072" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3178876.3186072</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>With the exponential growth of data, real-world
      applications, such as recommendation [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0013">13</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0014">14</a>], retrieval [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0039">39</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0040">40</a>], and
      multimedia analysis [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0038">38</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0056">56</a>] have experienced great changes.
      Thereinto, many important applications utilize the similarity
      search technique, which can return similar data instances to
      a given query instance. As the amount of data increases
      explosively [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0050">50</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0051">51</a>], the
      exhaustive comparisons among the query instance and candidate
      ones in original high dimensional space make traditional
      similarity search methods inappropriate for scalable search.
      To do fast similarity search, many promising hashing methods
      have been proposed in recent years [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0001">1</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0015">15</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0023">23</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0027">27</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0047">47</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0063">63</a>]. And they have been
      successfully used for many problems including web image
      retrieval [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0028">28</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0035">35</a>], mobile
      landmark search [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0064">64</a>], video retrieval [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0012">12</a>], recommendation
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0059">59</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0062">62</a>], person
      re-identification [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0061">61</a>], sequential or online data search
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0002">2</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0003">3</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0054">54</a>],
      cross-modal or cross-view retrieval [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0022">22</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0031">31</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0036">36</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0037">37</a>], search in a distributed
      setting [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0026">26</a>]
      and so on.</p>
      <p>Hashing methods learn the hash function to transform
      original data into compact binary hash codes (typically ≤ 128
      bits); by storing the hash codes instead of the original
      high-dimensional data, storage cost can be highly reduced.
      When queries come, they will first be transformed into binary
      hash codes by the learnt function; then, similarity search
      can be simply done by calculating the Hamming distances
      between the hash codes of available data instances and
      queries. As the Hamming distance between two binary codes is
      simply the number of bits that differ and can be calculated
      using the bitwise operation XOR, the retrieval process can be
      efficiently conducted. Due to the advantages mentioned above,
      i.e., the low storage cost and high efficiency of pairwise
      comparison, hashing methods are suitable for scalable data
      search.</p>
      <p>Hashing methods can be divided into data-independent and
      data-dependent ones. Data-independent hashing methods do not
      consider the specific data, and leverage random projections
      to learn the hash function. Locality-Sensitive Hashing (LSH)
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0008">8</a>] is one of
      the most popular data-independent methods. With the success
      of LSH, it has been extended to a variety of similarity
      measures, e.g., <em>p</em>-norm distances [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0007">7</a>], the Mahalanobis metric
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0021">21</a>], and
      kernel similarity [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0020">20</a>]. The main drawback of these methods
      is that they need long codes to guarantee high precision,
      which leads to a huge storage overhead. In contrast to
      data-independent hashing, data-dependent ones take the
      specific data into consideration and learn compact binary
      codes, which can effectively and highly efficiently index and
      organize massive data. A good deal of such methods have been
      proposed in the literature, and can be further summarized
      into two categories: unsupervised and supervised methods.</p>
      <p>Unsupervised methods do not leverage the label/semantic
      information and learn hash codes or hash functions through
      exploiting the relations of training data. There are a number
      of representative unsupervised hashing methods, e.g. Spectral
      Hashing [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0052">52</a>],
      Iterative Quantization [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0009">9</a>], Inductive Hashing on Manifolds
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0046">46</a>], Circulant
      Binary Embedding [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0057">57</a>], Discrete Graph Hashing [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0033">33</a>], and
      Scalable Graph Hashing [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0017">17</a>], etc. When the label information is
      available, supervised hashing methods can embed the semantic
      information into the learning of hash codes and have
      demonstrated better performance than that of unsupervised
      ones in many real-world applications. Thus, supervised
      hashing has attracted more and more attention recently. Some
      representative supervised hashing methods include
      Semi-Supervised Hashing [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0048">48</a>], Minimal Loss Hashing [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0042">42</a>], Two-Step
      Hashing [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0030">30</a>],
      Supervised Hashing with Latent Factor [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0060">60</a>], Fast Supervised Hashing
      with Decision Trees [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0029">29</a>], Supervised Discrete Hashing
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0045">45</a>], and
      Column Sampling Based Discrete Supervised Hashing [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0018">18</a>], etc. More
      methods can be found in surveys on hashing in [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0004">4</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0005">5</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0049">49</a>].</p>
      <p>Although existing supervised hashing has offered promising
      performance, there are some problems that need to be further
      considered. First, the binary constraints of hash codes lead
      to a discrete optimization problem which is hard to solve. To
      tackle it, most existing methods first relax the discrete
      constraints and transform the original problem into a
      continuous one which is easier to solve; then, they quantize
      the continuous solution into the binary hash codes space.
      However, the solution may be sub-optimal and the error caused
      by relaxation usually degrades the performance. Second, as
      the supervised methods need to embed the label information,
      most of them construct a <em>n</em> × <em>n</em>
      instance-pairwise similarity matrix which is leveraged in the
      learning procedure. Such instance-pairwise similarity matrix
      has an obvious drawback, i.e., the space cost. Especially
      when dealing with large-scale data, the <em>n</em> ×
      <em>n</em> space cost is not affordable. Thus, these hashing
      methods are time-consuming and unscalable. To tackle this,
      they have to sample a small subset of instances for training
      and discard the others. Apparently, this may cause
      information loss and result in poor performance.</p>
      <p>To consider these problems mentioned above, in this paper,
      we propose a novel method named Scalable Supervised Discrete
      Hashing (SSDH). It can discretely and efficiently learn the
      hash codes by making full use of all training samples and
      semantic information. To summarize, the main contributions of
      SSDH include:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">It takes both the pairwise
        similarity <strong>S</strong> and the label matrix
        <strong>L</strong> into consideration, which can ensure
        more precise hash codes.<br /></li>
        <li id="list2" label="•">By representing the hash codes
        matrix <strong>B</strong> with a real-valued transformation
        from label matrix <strong>L</strong>, SSDH avoids the
        direct optimization on <em>n</em> × <em>n</em> large matrix
        <strong>S</strong>, which makes the space cost acceptable
        when dealing with large-scale data. Besides, using
        real-valued matrix and hash codes rather than only binary
        matrix can permit more accurate approximation of
        <strong>S</strong>.<br /></li>
        <li id="list3" label="•">An alternating discrete
        optimization algorithm is proposed to efficiently learn the
        hash codes, which is scalable to deal with the large-scale
        datasets.<br /></li>
        <li id="list4" label="•">Extensive experiments are
        conducted on six widely used datasets. The results
        demonstrate the superiority of SSDH to the state-of-the-art
        supervised hashing methods.<br /></li>
      </ul>
      <p>The rest of this paper is organized as follows. The highly
      related work is discussed in Section 2. Section 3 introduces
      the proposed SSDH model including the loss function,
      optimization algorithm and its extension to out-of-sample
      data. Section 4 presents the experimental results and
      analysis on several benchmark datasets. Finally, Section 5
      concludes this paper.</p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related Work:
          Two-step Hashing</h2>
        </div>
      </header>
      <p>Most hashing methods learn hash codes and hash functions
      simultaneously, which we can call one-step hashing.
      Differently, two-step hashing methods divide the learning of
      hash codes and hash functions into two steps. In the first
      step, the two-step hashing methods generate hash codes by the
      supervision of loss functions. In the second step, given the
      learnt hash codes, two-step hashing methods learn hash
      functions which can transform the original features into the
      compact binary codes. There have been plenty of two-step
      hashing methods [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0034">34</a>].</p>
      <p>Usually, the performance of a two-step hashing method
      highly depends on the quality of the hash codes learnt in the
      first step. Thus, two-step hashing focuses more on the
      criterion of generating hash codes, i.e. the design of loss
      functions. In fact, as revealed in [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0030">30</a>], once the hash codes are
      learnt, for any bit of the hash codes, learning the
      corresponding hash function to project features into it can
      be modelled as a binary classification problem. Thus, any
      effective predictive model can be leveraged as hash function
      in the second step, such as linear classifiers [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0018">18</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0048">48</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0058">58</a>], SVM with
      RBF kernel [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0030">30</a>],
      deep convolutional network [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0053">53</a>], boosted decision trees [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0018">18</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0029">29</a>].
      Generally, the more powerful classifiers one uses as hash
      function, the better accuracy one can achieve and also the
      more training time will be consumed.</p>
      <p>The proposed SSDH belongs to two-step hashing and its loss
      function as well as the corresponding optimization algorithm
      make SSDH different from other two-step methods.</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Our Method</h2>
        </div>
      </header>
      <p>This section presents the details of SSDH. It is also a
      two-step hashing method, which means that the training of
      SSDH can be divided into two steps, i.e., the hash codes
      learning step and hash function learning step.</p>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Notations
            and Problem Definition</h3>
          </div>
        </header>
        <p>Assume we have <em>n</em> labeled instances, i.e.,
        <span class="inline-equation"><span class="tex">${\bf
        x}_i\in \mathbb {R}^d$</span></span> with its label vector
        <strong>y</strong> <sub><em>i</em></sub> ∈ {0, 1}
        <sup><em>c</em></sup> (<em>i</em> = 1, 2, ..., <em>n</em>).
        <em>d</em> is the dimension of each instance and <em>c</em>
        is the number of classes. Correspondingly, <span class=
        "inline-equation"><span class="tex">${\bf X}\in \mathbb
        {R}^{n\times d}$</span></span> and <strong>Y</strong> ∈ {0,
        1} <sup><em>n</em> × <em>c</em></sup> are the feature and
        label matrices, respectively. For example, <span class=
        "inline-equation"><span class="tex">${\bf X}^\top
        _{i*}={\bf x}_i$</span></span> and <span class=
        "inline-equation"><span class="tex">${\bf Y}^\top
        _{i*}={\bf y}_i$</span></span> . Moreover,
        <strong>Y</strong> <sub><em>ik</em></sub> is the
        <em>k</em>-th element of <span class=
        "inline-equation"><span class="tex">${\bf
        y}_i^\top$</span></span> ; <strong>Y</strong>
        <sub><em>ik</em></sub> = 1 if <em>x<sub>i</sub></em>
        belongs to class <em>k</em> and <strong>Y</strong>
        <sub><em>ik</em></sub> = 0 otherwise. In addition,
        <strong>S</strong> ∈ { − 1, 1} <sup><em>n</em> ×
        <em>n</em></sup> denotes the instance-pairwise semantic
        similarity, where <strong>S</strong> <sub><em>ij</em></sub>
        = 1 means point <em>i</em> and point <em>j</em> are
        semantically similar, and <strong>S</strong>
        <sub><em>ij</em></sub> = −1 otherwise.</p>
        <p>SSDH aims to learn a <em>r</em>-bit binary hash code
        <strong>b</strong> <sub><em>i</em></sub> ∈ { − 1, 1}
        <sup><em>r</em></sup> for each instance, and
        <strong>B</strong> ∈ { − 1, 1} <sup><em>n</em> ×
        <em>r</em></sup> is the hash code matrix with each row
        <span class="inline-equation"><span class="tex">${\bf
        B}_{i*}^\top ={\bf b}_i$</span></span> . Hash function
        <em>F</em>(·) transforms <strong>X</strong> to
        <strong>B</strong>, i.e, <strong>B</strong> =
        <em>F</em>(<strong>X</strong>) =
        <em>sgn</em>(<strong>X</strong> <strong>W</strong>), where
        <strong>W</strong> is the projection matrix and
        <em>sgn</em>(·) is an element-wise sign function defined as
        <em>sgn</em>(<em>x</em>) = 1 if <em>x</em> ≥ 0, and − 1
        otherwise. Without loss of generality, we assume the input
        instances to be zero centered, i.e., <span class=
        "inline-equation"><span class="tex">$\sum ^n_{i=1} {\bf
        x}_i=0$</span></span> .</p>
      </section>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Hash Codes
            Learning – Design of Loss Function</h3>
          </div>
        </header>
        <p>To leverage the semantic information to learn the hash
        codes, many hashing methods [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0018">18</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0025">25</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0029">29</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0030">30</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0034">34</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0053">53</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0060">60</a>] embed the similarity matrix into
        the following loss function:</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            &amp; \min _{\bf B}\parallel r {\bf S} -{\bf B} {\bf
            B}^\top \parallel _F^2,\\ &amp; s.t. \ \ \ {\bf B}\in
            \lbrace -1,1\rbrace ^{n\times r}. \end{split}
            \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>As proved in [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0034">34</a>], the inner product of hash codes
        reflects the opposite of the Hamming distance. Thus, Eq.
        (<a class="eqn" href="#eq1">1</a>) uses the inner product
        to approximate the semantic similarities with the square
        loss. The main drawback of this model is that it is
        time-consuming for optimization when <em>n</em> is large.
        <p></p>
        <p>To tackle this problem, we propose the following novel
        loss function:</p>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            &amp; \min _{{\bf B},{\bf G}}\parallel r {\bf S} -{\bf
            B} ({\bf Y}{\bf G})^\top \parallel _F^2 + \mu \parallel
            {\bf B} -{\bf Y}{\bf G} \parallel _F^2\\ &amp; s.t. \ \
            \ {\bf B}\in \lbrace -1,1\rbrace ^{n\times r},
            \end{split} \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>where we introduce two matrices into the loss
        function, i.e, <strong>G</strong> and <strong>Y</strong>.
        <span class="inline-equation"><span class="tex">${\bf G}\in
        \mathbb {R}^{c\times r}$</span></span> is a projection from
        <strong>Y</strong> to <strong>B</strong>;
        <strong>Y</strong> is the label matrix, and <em>μ</em> is a
        balance parameter.
        <p></p>
        <p>The design of Eq. (<a class="eqn" href="#eq2">2</a>) has
        several major advantages. First, we can supervise the
        learning of hash codes by leveraging both pairwise
        similarity <strong>S</strong> and label matrix
        <strong>Y</strong> rather than only one of them, which can
        ensure more precise hash codes. Second, as revealed in
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0010">10</a>], using
        the real-valued information in Eq. (<a class="eqn" href=
        "#eq1">1</a>) rather than the binary <strong>B</strong> can
        obtain more accurate approximation of similarity
        <strong>S</strong>. Thus, we use real-valued
        <strong>YG</strong> to replace one binary matrix
        <strong>B</strong> in Eq. (<a class="eqn" href=
        "#eq1">1</a>), and <strong>YG</strong> has been proved
        effective to approximate <strong>B</strong> in [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0011">11</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0045">45</a>]. Third,
        by introducing <strong>YG</strong> and replacing one
        <strong>B</strong>, we can tactfully avoid the direct
        optimization on large <strong>S</strong>. As will be
        discussed in the optimization section, we can compute
        <strong>SY</strong> offline and directly use the term of
        <strong>SY</strong> instead of <strong>S</strong> in the
        learning. It is notable that the size of
        <strong>SY</strong> is only <em>n</em> × <em>c</em>
        (<em>c</em> is usually much smaller than <em>n</em>); thus,
        solving the optimization problem can become much more
        efficient.</p>
      </section>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span> Hash Codes
            Learning – Optimization of Loss Function</h3>
          </div>
        </header>
        <p>As shown above, there are two variables in Eq.
        (<a class="eqn" href="#eq2">2</a>), i.e.,
        <strong>B</strong> and <strong>G</strong>. To tackle this
        optimization problem, in this section, we propose an
        alternating strategy for it, which has two alternating
        steps: Updating <strong>G</strong> by fixing
        <strong>B</strong> and updating <strong>B</strong> by
        fixing <strong>G</strong>.</p>
        <section id="sec-10">
          <header>
            <div class="title-info">
              <h4><span class="section-number">3.3.1</span>
              Updating <em>G</em> by Fixing <em>B</em></h4>
            </div>
          </header>
          <p>Apparently, once <strong>B</strong> is fixed, the
          optimization problem has a closed-form solution. Then, we
          can get <strong>G</strong> by setting the derivative of
          (<a class="eqn" href="#eq2">2</a>) with respect to
          <strong>G</strong> equal to zero, and we obtain:</p>
          <div class="table-responsive" id="eq3">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} {\bf
              G}=({\bf Y}^\top {\bf Y})^{-1}(r({\bf SY})^\top {\bf
              B}+ \mu {\bf Y}^\top {\bf B})({\bf B}^\top {\bf B}
              +\mu {\bf I}_{r\times r})^{-1} .
              \end{equation}</span><br />
              <span class="equation-number">(3)</span>
            </div>
          </div>If we directly use <strong>S</strong> during the
          optimization, the space and time cost is unacceptable
          when training data set is large. Fortunately, we can
          compute <strong>SY</strong> offline before the training
          and directly load <strong>SY</strong> during the
          optimization. Denoting <strong>SY</strong> as
          <strong>A</strong>, Eq. (<a class="eqn" href=
          "#eq3">3</a>) can be further rewritten as:
          <div class="table-responsive" id="eq4">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} {\bf
              G}=({\bf Y}^\top {\bf Y})^{-1}(r{\bf A}^\top {\bf B}+
              \mu {\bf Y}^\top {\bf B})({\bf B}^\top {\bf B} +\mu
              {\bf I}_{r\times r})^{-1},
              \end{equation}</span><br />
              <span class="equation-number">(4)</span>
            </div>
          </div>where the size of <strong>A</strong> is <em>n</em>
          × <em>c</em>, and <em>c</em> is usually much smaller than
          <em>n</em>. Thus, during the optimization, SSDH can
          bypass the drawback of using large pairwise similarity
          matrix.
          <p></p>
        </section>
        <section id="sec-11">
          <header>
            <div class="title-info">
              <h4><span class="section-number">3.3.2</span>
              Updating <em>B</em> by Fixing <em>G</em></h4>
            </div>
          </header>
          <p>When updating <strong>B</strong>, we need to consider
          two scenarios, i.e., single-label data and multi-label
          data. Both of them are discussed in the following
          paragraphs.</p>
          <p><strong>Single-Label Data:</strong> To consider the
          first term in Eq. (<a class="eqn" href="#eq2">2</a>),
          inspired by the work in [<a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0018">18</a>], we first replace the Frobenius
          norm of it with the <em>L</em> <sub>1</sub> norm;
          therefore, the problem becomes:</p>
          <div class="table-responsive" id="eq5">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} \min _{{\bf
              B}}\parallel r {\bf S} -{\bf B} ({\bf YG})^\top
              \parallel _1, \quad s.t., {\bf B}\in \lbrace
              -1,1\rbrace ^{n\times r}. \end{equation}</span><br />
              <span class="equation-number">(5)</span>
            </div>
          </div>Then we have the solution <strong>B</strong> =
          <em>sgn</em>(<strong>SYG</strong>). For single-label
          data, we can easily find the value of
          <em>sgn</em>(<strong>SYG</strong>) is equivalent to
          <em>sgn</em>(<strong>YG</strong>). Thus, for the first
          term in Eq. (<a class="eqn" href="#eq2">2</a>),
          <strong>B</strong> = <em>sgn</em>(<strong>YG</strong>) is
          the solution. For the second term in Eq. (<a class="eqn"
          href="#eq2">2</a>), we can easily find that
          <strong>B</strong> = <em>sgn</em>(<strong>YG</strong>) is
          also the solution.
          <p></p>
          <p>Thus, for single-label data, the solution to Eq.
          (<a class="eqn" href="#eq2">2</a>) is:</p>
          <div class="table-responsive" id="eq6">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} {\bf
              B}=sgn({\bf YG}). \end{equation}</span><br />
              <span class="equation-number">(6)</span>
            </div>
          </div>
          <p></p>
          <p><strong>Multi-Label Data:</strong> For this scenario,
          <em>sgn</em>(<strong>SYG</strong>) is not equivalent to
          <em>sgn</em>(<strong>YG</strong>) any more, which means
          that <strong>B</strong> =
          <em>sgn</em>(<strong>YG</strong>) is no longer a solution
          to Eq. (<a class="eqn" href="#eq2">2</a>). Instead, we
          use discrete cyclic coordinate descent (DCC) to obtain
          <strong>B</strong> with a closed-form solution. First, by
          omitting constant terms <span class=
          "inline-equation"><span class="tex">$\parallel r{\bf
          S}\parallel _F^2$</span></span> , <span class=
          "inline-equation"><span class="tex">$ \mu \parallel {\bf
          B}\parallel _F^2$</span></span> and <span class=
          "inline-equation"><span class="tex">$\mu \parallel {\bf
          YG}\parallel _F^2$</span></span> , we rewrite Eq.
          (<a class="eqn" href="#eq2">2</a>) as follows:</p>
          <div class="table-responsive" id="eq7">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation}
              \begin{split} &amp; \min _{{\bf B}} \parallel {\bf
              YGB}^\top \parallel _F^2- 2Tr({\bf B}^\top {\bf
              SYG}+\mu {\bf B}^\top {\bf YG}))\\ &amp; \ \ \ \ \
              =\parallel {\bf YGB}^\top \parallel _F^2- 2Tr({\bf
              B}^\top ({\bf AG}+\mu {\bf YG}))\\ &amp; \ \ \ \ \
              =\parallel {\bf CB}^\top \parallel _F^2 - 2Tr({\bf
              B}^\top {\bf Q})\\ &amp; s.t. \ \ \ {\bf B}\in
              \lbrace -1,1\rbrace ^{n\times r}, \end{split}
              \end{equation}</span><br />
              <span class="equation-number">(7)</span>
            </div>
          </div>where <strong>A</strong> = <strong>SY</strong>,
          <strong>C</strong> = <strong>YG</strong> and
          <strong>Q</strong> = <strong>AG</strong> + <em>μ</em>
          <strong>C</strong>. Then, we solve <strong>B</strong> bit
          by bit, which means that we iteratively learn every
          column of <strong>B</strong> by fixing all other columns.
          To do this, we suppose <strong>b</strong> is the
          <em>l</em>-th column of <strong>B</strong>, i.e.,
          <strong>b</strong> is the vector composed of the
          <em>l</em>-th bits of all samples, <em>l</em> = 1, 2⋅⋅⋅,
          <em>r</em> and <strong>B</strong>′ is the matrix
          excluding <strong>b</strong>. Similarly,
          <strong>q</strong> is the <em>l</em>-th row of
          <strong>Q</strong>, <strong>Q</strong>′ is the matrix of
          <strong>Q</strong> excluding <strong>q</strong>;
          <strong>c</strong> is the <em>l</em>-th row of
          <strong>C</strong>, <strong>C</strong>′ the matrix of
          <strong>C</strong> excluding <strong>c</strong>. Then we
          have:
          <div class="table-responsive" id="eq8">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation}
              \begin{split} &amp; \parallel {\bf CB}^\top \parallel
              _F^2= Tr({\bf BC}^\top {\bf CB}^\top)\\ &amp; \quad
              \quad \quad \quad \ \ = \parallel {\bf bc} \parallel
              _F^2 + 2{\bf cC}^{\prime }{\bf B}^{\prime \top }{\bf
              b} +const\\ &amp; \quad \quad \quad \quad \ \ =2{\bf
              c}^\top {\bf C}^{\prime }{\bf B}^{\prime \top }{\bf
              b} +const.\\ \end{split} \end{equation}</span><br />
              <span class="equation-number">(8)</span>
            </div>
          </div>Here <span class="inline-equation"><span class=
          "tex">$\parallel {\bf bc} \parallel _F^2=Tr({\bf c}^\top
          {\bf b}^\top {\bf b} {\bf c})=n {\bf c}^\top {\bf
          c}=const$</span></span> . Correspondingly, we have:
          <div class="table-responsive" id="eq9">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} 2Tr({\bf
              B}^\top {\bf Q})= {\bf q}^\top {\bf b}+const.
              \end{equation}</span><br />
              <span class="equation-number">(9)</span>
            </div>
          </div>Then, the optimization problem can be further
          reduced to the following form:
          <div class="table-responsive" id="eq10">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation}
              \begin{split} &amp; \min _{\bf c} \quad ({\bf c}^\top
              {\bf C}^{\prime }{\bf B}^{\prime \top }+ {\bf
              q}^\top){\bf b} \\ &amp; s.t. \quad {\bf b}\in
              \lbrace -1,1\rbrace ^n. \\ \end{split}
              \end{equation}</span><br />
              <span class="equation-number">(10)</span>
            </div>
          </div>And the optimal solution is:
          <div class="table-responsive" id="eq11">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} {\bf
              b}=sgn({\bf q}-{\bf B}^{\prime }{\bf C}^{\prime \top
              }{\bf c}). \end{equation}</span><br />
              <span class="equation-number">(11)</span>
            </div>
          </div>We can see that each bit b is computed based on the
          pre-learnt bits of <strong>B</strong>. We can iteratively
          update each bit until the procedure converges to a set of
          better codes B.
          <p></p>
        </section>
        <section id="sec-12">
          <p><em>3.3.3 The Whole Algorithm.</em> The above
          optimization procedure of SSDH is summarized in Algorithm
          1.</p>
          <p><img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186072/images/www2018-81-img1.svg"
          class="img-responsive" alt="" longdesc="" /></p>
        </section>
      </section>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.4</span> Hash
            Function Learning</h3>
          </div>
        </header>
        <p>Once the hash codes are learnt, SSDH needs to learn hash
        function which can transform the original features into
        binary codes, e.g., for out-of-sample instances. As
        mentioned previously, the hash function learning can be
        viewed as a binary classification problem for any bit of
        the codes and any arbitrary classifiers can be adopted as
        hash function. SSDH chooses linear regression on account of
        its efficiency <a class="fn" href="#fn2" id=
        "foot-fn2"><sup>1</sup></a>.</p>
        <p>When the linear regression is adopted, the hash function
        can be obtained by solving the following square loss
        problem:</p>
        <div class="table-responsive" id="Xeq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} L_e =
            \parallel {\bf B}-{\bf XW} \parallel ^2_F + \lambda _e
            \parallel {\bf W}\parallel ^2_F,
            \end{equation}</span><br />
            <span class="equation-number">(12)</span>
          </div>
        </div>where <em>λ<sub>e</sub></em> is a balance parameter,
        and <span class="inline-equation"><span class=
        "tex">$\parallel {\bf W}\parallel ^2_F$</span></span> is a
        regularization term. Then, we can get the optimal solution
        as:
        <div class="table-responsive" id="Xeq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} {\bf W}=({\bf
            X}^\top {\bf X}+ \lambda _e {\bf I})^{-1}{\bf X}^\top
            {\bf B}. \end{equation}</span><br />
            <span class="equation-number">(13)</span>
          </div>
        </div>
        <p></p>
      </section>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.5</span>
            Out-of-Sample Extension</h3>
          </div>
        </header>
        <p>Once the hash function is learnt, SSDH can easily
        generate the hash codes for new queries. Suppose
        <em>X<sub>query</sub></em> and <em>B<sub>query</sub></em>
        are the original features and corresponding hash codes of
        queries, respectively. Then, <em>B<sub>query</sub></em> can
        be obtained by</p>
        <div class="table-responsive" id="Xeq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} {\bf
            B}_{query}=F({\bf X}_{query})=sgn({\bf X}_{query}{\bf
            W}). \end{equation}</span><br />
            <span class="equation-number">(14)</span>
          </div>
        </div>
        <p></p>
      </section>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.6</span>
            Kernelization</h3>
          </div>
        </header>
        <p>Kernelization is a popular and powerful technique in
        supervised hashing literature. For data point <span class=
        "inline-equation"><span class="tex">${\bf x}\in \mathbb
        {R}^d$</span></span> , we randomly sampled <em>m</em>
        anchor points, i.e., <strong>o</strong> <sub>1</sub>,
        <strong>o</strong> <sub>2</sub>, ⋅⋅⋅, <strong>o</strong>
        <sub><em>m</em></sub> and mapped <strong>x</strong> into an
        <em>m</em>-dimensional kernel feature representation,
        using</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation*} \phi
            (x)=[exp({\parallel {\bf x}- {\bf o}_1 \parallel
            ^{2}}/{\sigma }),\cdots ,exp({\parallel {\bf x}-{\bf
            o}_m \parallel ^{2}}/{\sigma
            })].\end{equation*}</span><br />
          </div>
        </div>Here, <em>σ</em> is the kernel width. We set
        <em>m</em> = 1, 000 and estimated <em>σ</em> according to
        the average Euclidean distances between the training
        samples.
        <p></p>
      </section>
    </section>
    <section id="sec-16">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Experimental
          results</h2>
        </div>
      </header>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">General statistics of six datasets.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:center;">dataset</th>
              <th style="text-align:center;">label kind</th>
              <th style="text-align:center;">training size</th>
              <th style="text-align:center;">query size</th>
              <th style="text-align:center;">number of labels</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:center;">MNIST</td>
              <td style="text-align:center;">single-label</td>
              <td style="text-align:center;">69,000</td>
              <td style="text-align:center;">1,000</td>
              <td style="text-align:center;">10</td>
            </tr>
            <tr>
              <td style="text-align:center;">MIRFlickr</td>
              <td style="text-align:center;">multi-label</td>
              <td style="text-align:center;">15,738</td>
              <td style="text-align:center;">1,000</td>
              <td style="text-align:center;">24</td>
            </tr>
            <tr>
              <td style="text-align:center;">CIFAR-10</td>
              <td style="text-align:center;">single-label</td>
              <td style="text-align:center;">59,000</td>
              <td style="text-align:center;">1,000</td>
              <td style="text-align:center;">10</td>
            </tr>
            <tr>
              <td style="text-align:center;">CIFAR-100</td>
              <td style="text-align:center;">single-label</td>
              <td style="text-align:center;">59,000</td>
              <td style="text-align:center;">1,000</td>
              <td style="text-align:center;">100</td>
            </tr>
            <tr>
              <td style="text-align:center;">NUS-WIDE</td>
              <td style="text-align:center;">multi-label</td>
              <td style="text-align:center;">193,833</td>
              <td style="text-align:center;">2,100</td>
              <td style="text-align:center;">21</td>
            </tr>
            <tr>
              <td style="text-align:center;">ImageNet</td>
              <td style="text-align:center;">single-label</td>
              <td style="text-align:center;">1,198,336</td>
              <td style="text-align:center;">63,070</td>
              <td style="text-align:center;">1,000</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="table-responsive" id="tab2">
        <div class="table-caption">
          <span class="table-number">Table 2:</span> <span class=
          "table-title">The MAP results and training time of all
          methods on MNIST. The best MAPs for each category are
          shown in boldface.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:center;"></th>
              <th colspan="5" style="text-align:center;">
                MAP
                <hr />
              </th>
              <th colspan="5" style="text-align:center;">
                Training Time (in second)
                <hr />
              </th>
            </tr>
            <tr>
              <th style="text-align:center;">Method</th>
              <th style="text-align:center;">8 bits</th>
              <th style="text-align:center;">16 bits</th>
              <th style="text-align:center;">32 bits</th>
              <th style="text-align:center;">64 bits</th>
              <th style="text-align:center;">96 bits</th>
              <th style="text-align:center;">8 bits</th>
              <th style="text-align:center;">16 bits</th>
              <th style="text-align:center;">32 bits</th>
              <th style="text-align:center;">64 bits</th>
              <th style="text-align:center;">96 bits</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:center;">LSH</td>
              <td style="text-align:center;">0.1731</td>
              <td style="text-align:center;">0.2202</td>
              <td style="text-align:center;">0.2686</td>
              <td style="text-align:center;">0.3267</td>
              <td style="text-align:center;">0.3553</td>
              <td style="text-align:center;">0.040</td>
              <td style="text-align:center;">0.044</td>
              <td style="text-align:center;">0.062</td>
              <td style="text-align:center;">0.091</td>
              <td style="text-align:center;">0.129</td>
            </tr>
            <tr>
              <td style="text-align:center;">ITQ</td>
              <td style="text-align:center;">0.3818</td>
              <td style="text-align:center;">0.4132</td>
              <td style="text-align:center;">0.4367</td>
              <td style="text-align:center;">0.4601</td>
              <td style="text-align:center;">0.4673</td>
              <td style="text-align:center;">0.892</td>
              <td style="text-align:center;">1.42</td>
              <td style="text-align:center;">2.72</td>
              <td style="text-align:center;">5.27</td>
              <td style="text-align:center;">7.18</td>
            </tr>
            <tr>
              <td style="text-align:center;">KSH</td>
              <td style="text-align:center;">0.7103</td>
              <td style="text-align:center;">0.7880</td>
              <td style="text-align:center;">0.8258</td>
              <td style="text-align:center;">0.8434</td>
              <td style="text-align:center;">0.8428</td>
              <td style="text-align:center;">48.02</td>
              <td style="text-align:center;">90.72</td>
              <td style="text-align:center;">179.82</td>
              <td style="text-align:center;">337.53</td>
              <td style="text-align:center;">508.68</td>
            </tr>
            <tr>
              <td style="text-align:center;">SDH</td>
              <td style="text-align:center;">0.5956</td>
              <td style="text-align:center;">0.8544</td>
              <td style="text-align:center;">0.8861</td>
              <td style="text-align:center;">0.8945</td>
              <td style="text-align:center;">0.8963</td>
              <td style="text-align:center;">6.45</td>
              <td style="text-align:center;">7.13</td>
              <td style="text-align:center;">17.27</td>
              <td style="text-align:center;">59.60</td>
              <td style="text-align:center;">127.06</td>
            </tr>
            <tr>
              <td style="text-align:center;">NSH</td>
              <td style="text-align:center;">0.7314</td>
              <td style="text-align:center;">0.8667</td>
              <td style="text-align:center;">0.8934</td>
              <td style="text-align:center;">0.9102</td>
              <td style="text-align:center;">0.9105</td>
              <td style="text-align:center;">4.33</td>
              <td style="text-align:center;">5.25</td>
              <td style="text-align:center;">5.38</td>
              <td style="text-align:center;">6.89</td>
              <td style="text-align:center;">8.51</td>
            </tr>
            <tr>
              <td style="text-align:center;">FSDH</td>
              <td style="text-align:center;">0.8701</td>
              <td style="text-align:center;">0.8940</td>
              <td style="text-align:center;">0.9139</td>
              <td style="text-align:center;">0.9200</td>
              <td style="text-align:center;">0.9253</td>
              <td style="text-align:center;">8.60</td>
              <td style="text-align:center;">7.93</td>
              <td style="text-align:center;">8.71</td>
              <td style="text-align:center;">9.94</td>
              <td style="text-align:center;">10.46</td>
            </tr>
            <tr>
              <td style="text-align:center;">COSDISH</td>
              <td style="text-align:center;">0.7895</td>
              <td style="text-align:center;">0.8498</td>
              <td style="text-align:center;">0.8740</td>
              <td style="text-align:center;">0.8866</td>
              <td style="text-align:center;">0.8861</td>
              <td style="text-align:center;">4.59</td>
              <td style="text-align:center;">8.08</td>
              <td style="text-align:center;">30.31</td>
              <td style="text-align:center;">107.01</td>
              <td style="text-align:center;">241.08</td>
            </tr>
            <tr>
              <td style="text-align:center;">SSDH</td>
              <td style="text-align:center;">
              <strong>0.9338</strong></td>
              <td style="text-align:center;">
              <strong>0.9557</strong></td>
              <td style="text-align:center;">
              <strong>0.9639</strong></td>
              <td style="text-align:center;">
              <strong>0.9669</strong></td>
              <td style="text-align:center;">
              <strong>0.9683</strong></td>
              <td style="text-align:center;">3.68</td>
              <td style="text-align:center;">3.80</td>
              <td style="text-align:center;">3.81</td>
              <td style="text-align:center;">3.93</td>
              <td style="text-align:center;">4.09</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="table-responsive" id="tab3">
        <div class="table-caption">
          <span class="table-number">Table 3:</span> <span class=
          "table-title">The MAP results and training time of all
          methods on MIRFlickr. The best MAPs for each category are
          shown in boldface.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:center;"></th>
              <th colspan="5" style="text-align:center;">
                MAP
                <hr />
              </th>
              <th colspan="5" style="text-align:center;">
                Training Time (in second)
                <hr />
              </th>
            </tr>
            <tr>
              <th style="text-align:center;">Method</th>
              <th style="text-align:center;">8 bits</th>
              <th style="text-align:center;">16 bits</th>
              <th style="text-align:center;">32 bits</th>
              <th style="text-align:center;">64 bits</th>
              <th style="text-align:center;">96 bits</th>
              <th style="text-align:center;">8 bits</th>
              <th style="text-align:center;">16 bits</th>
              <th style="text-align:center;">32 bits</th>
              <th style="text-align:center;">64 bits</th>
              <th style="text-align:center;">96 bits</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:center;">LSH</td>
              <td style="text-align:center;">0.5669</td>
              <td style="text-align:center;">0.5760</td>
              <td style="text-align:center;">0.5712</td>
              <td style="text-align:center;">0.5862</td>
              <td style="text-align:center;">0.5885</td>
              <td style="text-align:center;">0.005</td>
              <td style="text-align:center;">0.005</td>
              <td style="text-align:center;">0.007</td>
              <td style="text-align:center;">0.013</td>
              <td style="text-align:center;">0.016</td>
            </tr>
            <tr>
              <td style="text-align:center;">ITQ</td>
              <td style="text-align:center;">0.5760</td>
              <td style="text-align:center;">0.5721</td>
              <td style="text-align:center;">0.5794</td>
              <td style="text-align:center;">0.5796</td>
              <td style="text-align:center;">0.5806</td>
              <td style="text-align:center;">0.134</td>
              <td style="text-align:center;">0.154</td>
              <td style="text-align:center;">0.305</td>
              <td style="text-align:center;">0.589</td>
              <td style="text-align:center;">0.925</td>
            </tr>
            <tr>
              <td style="text-align:center;">KSH</td>
              <td style="text-align:center;">0.5780</td>
              <td style="text-align:center;">0.5775</td>
              <td style="text-align:center;">0.5794</td>
              <td style="text-align:center;">0.5782</td>
              <td style="text-align:center;">0.5790</td>
              <td style="text-align:center;">28.69</td>
              <td style="text-align:center;">57.02</td>
              <td style="text-align:center;">109.05</td>
              <td style="text-align:center;">219.11</td>
              <td style="text-align:center;">329.99</td>
            </tr>
            <tr>
              <td style="text-align:center;">SDH</td>
              <td style="text-align:center;">0.6023</td>
              <td style="text-align:center;">0.6071</td>
              <td style="text-align:center;">0.6138</td>
              <td style="text-align:center;">0.6207</td>
              <td style="text-align:center;">0.6220</td>
              <td style="text-align:center;">1.31</td>
              <td style="text-align:center;">1.90</td>
              <td style="text-align:center;">3.99</td>
              <td style="text-align:center;">13.19</td>
              <td style="text-align:center;">30.38</td>
            </tr>
            <tr>
              <td style="text-align:center;">NSH</td>
              <td style="text-align:center;">0.6143</td>
              <td style="text-align:center;">0.6180</td>
              <td style="text-align:center;">0.6158</td>
              <td style="text-align:center;">0.6243</td>
              <td style="text-align:center;">0.6270</td>
              <td style="text-align:center;">0.873</td>
              <td style="text-align:center;">0.932</td>
              <td style="text-align:center;">1.03</td>
              <td style="text-align:center;">1.31</td>
              <td style="text-align:center;">1.59</td>
            </tr>
            <tr>
              <td style="text-align:center;">FSDH</td>
              <td style="text-align:center;">0.5908</td>
              <td style="text-align:center;">0.5957</td>
              <td style="text-align:center;">0.6053</td>
              <td style="text-align:center;">0.6124</td>
              <td style="text-align:center;">0.6152</td>
              <td style="text-align:center;">2.01</td>
              <td style="text-align:center;">2.02</td>
              <td style="text-align:center;">2.07</td>
              <td style="text-align:center;">2.13</td>
              <td style="text-align:center;">2.20</td>
            </tr>
            <tr>
              <td style="text-align:center;">COSDISH</td>
              <td style="text-align:center;">0.6819</td>
              <td style="text-align:center;">0.6939</td>
              <td style="text-align:center;">0.7036</td>
              <td style="text-align:center;">0.7173</td>
              <td style="text-align:center;">0.7185</td>
              <td style="text-align:center;">0.639</td>
              <td style="text-align:center;">1.66</td>
              <td style="text-align:center;">6.04</td>
              <td style="text-align:center;">29.85</td>
              <td style="text-align:center;">69.99</td>
            </tr>
            <tr>
              <td style="text-align:center;">SSDH</td>
              <td style="text-align:center;">
              <strong>0.7099</strong></td>
              <td style="text-align:center;">
              <strong>0.7128</strong></td>
              <td style="text-align:center;">
              <strong>0.7154</strong></td>
              <td style="text-align:center;">
              <strong>0.7198</strong></td>
              <td style="text-align:center;">
              <strong>0.7258</strong></td>
              <td style="text-align:center;">0.722</td>
              <td style="text-align:center;">0.849</td>
              <td style="text-align:center;">1.32</td>
              <td style="text-align:center;">3.10</td>
              <td style="text-align:center;">6.29</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="table-responsive" id="tab4">
        <div class="table-caption">
          <span class="table-number">Table 4:</span> <span class=
          "table-title">The MAP results and training time of all
          methods on CIFAR-10. The best MAPs for each category are
          shown in boldface.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:center;"></th>
              <th colspan="5" style="text-align:center;">
                MAP
                <hr />
              </th>
              <th colspan="5" style="text-align:center;">
                Training Time (in second)
                <hr />
              </th>
            </tr>
            <tr>
              <th style="text-align:center;">Method</th>
              <th style="text-align:center;">8 bits</th>
              <th style="text-align:center;">16 bits</th>
              <th style="text-align:center;">32 bits</th>
              <th style="text-align:center;">64 bits</th>
              <th style="text-align:center;">96 bits</th>
              <th style="text-align:center;">8 bits</th>
              <th style="text-align:center;">16 bits</th>
              <th style="text-align:center;">32 bits</th>
              <th style="text-align:center;">64 bits</th>
              <th style="text-align:center;">96 bits</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:center;">LSH</td>
              <td style="text-align:center;">0.1077</td>
              <td style="text-align:center;">0.1165</td>
              <td style="text-align:center;">0.1199</td>
              <td style="text-align:center;">0.1270</td>
              <td style="text-align:center;">0.1360</td>
              <td style="text-align:center;">0.021</td>
              <td style="text-align:center;">0.025</td>
              <td style="text-align:center;">0.032</td>
              <td style="text-align:center;">0.044</td>
              <td style="text-align:center;">0.064</td>
            </tr>
            <tr>
              <td style="text-align:center;">ITQ</td>
              <td style="text-align:center;">0.1429</td>
              <td style="text-align:center;">0.1482</td>
              <td style="text-align:center;">0.1569</td>
              <td style="text-align:center;">0.1487</td>
              <td style="text-align:center;">0.1551</td>
              <td style="text-align:center;">0.483</td>
              <td style="text-align:center;">0.743</td>
              <td style="text-align:center;">1.32</td>
              <td style="text-align:center;">2.54</td>
              <td style="text-align:center;">3.98</td>
            </tr>
            <tr>
              <td style="text-align:center;">KSH</td>
              <td style="text-align:center;">0.2315</td>
              <td style="text-align:center;">0.2623</td>
              <td style="text-align:center;">0.2905</td>
              <td style="text-align:center;">0.3095</td>
              <td style="text-align:center;">0.3199</td>
              <td style="text-align:center;">29.91</td>
              <td style="text-align:center;">59.59</td>
              <td style="text-align:center;">121.00</td>
              <td style="text-align:center;">243.73</td>
              <td style="text-align:center;">359.11</td>
            </tr>
            <tr>
              <td style="text-align:center;">SDH</td>
              <td style="text-align:center;">0.2373</td>
              <td style="text-align:center;">0.3528</td>
              <td style="text-align:center;">0.3868</td>
              <td style="text-align:center;">0.4049</td>
              <td style="text-align:center;">0.4159</td>
              <td style="text-align:center;">4.58</td>
              <td style="text-align:center;">5.55</td>
              <td style="text-align:center;">9.09</td>
              <td style="text-align:center;">29.54</td>
              <td style="text-align:center;">83.13</td>
            </tr>
            <tr>
              <td style="text-align:center;">NSH</td>
              <td style="text-align:center;">0.2902</td>
              <td style="text-align:center;">0.2936</td>
              <td style="text-align:center;">0.3220</td>
              <td style="text-align:center;">0.3390</td>
              <td style="text-align:center;">0.3687</td>
              <td style="text-align:center;">2.99</td>
              <td style="text-align:center;">3.675</td>
              <td style="text-align:center;">3.70</td>
              <td style="text-align:center;">4.81</td>
              <td style="text-align:center;">5.75</td>
            </tr>
            <tr>
              <td style="text-align:center;">FSDH</td>
              <td style="text-align:center;">0.3311</td>
              <td style="text-align:center;">0.3884</td>
              <td style="text-align:center;">0.4270</td>
              <td style="text-align:center;">0.4522</td>
              <td style="text-align:center;">0.4646</td>
              <td style="text-align:center;">6.05</td>
              <td style="text-align:center;">6.09</td>
              <td style="text-align:center;">6.26</td>
              <td style="text-align:center;">6.65</td>
              <td style="text-align:center;">7.05</td>
            </tr>
            <tr>
              <td style="text-align:center;">COSDISH</td>
              <td style="text-align:center;">0.5012</td>
              <td style="text-align:center;">0.5745</td>
              <td style="text-align:center;">0.6094</td>
              <td style="text-align:center;">0.6321</td>
              <td style="text-align:center;">0.6394</td>
              <td style="text-align:center;">2.10</td>
              <td style="text-align:center;">4.33</td>
              <td style="text-align:center;">15.19</td>
              <td style="text-align:center;">76.99</td>
              <td style="text-align:center;">180.34</td>
            </tr>
            <tr>
              <td style="text-align:center;">SSDH</td>
              <td style="text-align:center;">
              <strong>0.5151</strong></td>
              <td style="text-align:center;">
              <strong>0.6698</strong></td>
              <td style="text-align:center;">
              <strong>0.6991</strong></td>
              <td style="text-align:center;">
              <strong>0.7046</strong></td>
              <td style="text-align:center;">
              <strong>0.7063</strong></td>
              <td style="text-align:center;">2.61</td>
              <td style="text-align:center;">2.69</td>
              <td style="text-align:center;">2.66</td>
              <td style="text-align:center;">2.67</td>
              <td style="text-align:center;">2.73</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="table-responsive" id="tab5">
        <div class="table-caption">
          <span class="table-number">Table 5:</span> <span class=
          "table-title">The MAP results and training time of all
          methods on CIFAR-100. The best MAPs for each category are
          shown in boldface.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:center;"></th>
              <th colspan="5" style="text-align:center;">
                MAP
                <hr />
              </th>
              <th colspan="5" style="text-align:center;">
                Training Time (in second)
                <hr />
              </th>
            </tr>
            <tr>
              <th style="text-align:center;">Method</th>
              <th style="text-align:center;">8 bits</th>
              <th style="text-align:center;">16 bits</th>
              <th style="text-align:center;">32 bits</th>
              <th style="text-align:center;">64 bits</th>
              <th style="text-align:center;">96 bits</th>
              <th style="text-align:center;">8 bits</th>
              <th style="text-align:center;">16 bits</th>
              <th style="text-align:center;">32 bits</th>
              <th style="text-align:center;">64 bits</th>
              <th style="text-align:center;">96 bits</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:center;">LSH</td>
              <td style="text-align:center;">0.0117</td>
              <td style="text-align:center;">0.0125</td>
              <td style="text-align:center;">0.0139</td>
              <td style="text-align:center;">0.0153</td>
              <td style="text-align:center;">0.0169</td>
              <td style="text-align:center;">0.021</td>
              <td style="text-align:center;">0.025</td>
              <td style="text-align:center;">0.027</td>
              <td style="text-align:center;">0.0485</td>
              <td style="text-align:center;">0.059</td>
            </tr>
            <tr>
              <td style="text-align:center;">ITQ</td>
              <td style="text-align:center;">0.0125</td>
              <td style="text-align:center;">0.0151</td>
              <td style="text-align:center;">0.0170</td>
              <td style="text-align:center;">0.0193</td>
              <td style="text-align:center;">0.0203</td>
              <td style="text-align:center;">0.468</td>
              <td style="text-align:center;">0.711</td>
              <td style="text-align:center;">1.28</td>
              <td style="text-align:center;">2.46</td>
              <td style="text-align:center;">4.01</td>
            </tr>
            <tr>
              <td style="text-align:center;">KSH</td>
              <td style="text-align:center;">0.0225</td>
              <td style="text-align:center;">0.0268</td>
              <td style="text-align:center;">0.0290</td>
              <td style="text-align:center;">0.0307</td>
              <td style="text-align:center;">0.0338</td>
              <td style="text-align:center;">32.63</td>
              <td style="text-align:center;">63.60</td>
              <td style="text-align:center;">128.91</td>
              <td style="text-align:center;">257.12</td>
              <td style="text-align:center;">386.89</td>
            </tr>
            <tr>
              <td style="text-align:center;">SDH</td>
              <td style="text-align:center;">0.0217</td>
              <td style="text-align:center;">0.0339</td>
              <td style="text-align:center;">0.0473</td>
              <td style="text-align:center;">0.0589</td>
              <td style="text-align:center;">0.0392</td>
              <td style="text-align:center;">3.83</td>
              <td style="text-align:center;">5.77</td>
              <td style="text-align:center;">9.69</td>
              <td style="text-align:center;">80.92</td>
              <td style="text-align:center;">190.57</td>
            </tr>
            <tr>
              <td style="text-align:center;">NSH</td>
              <td style="text-align:center;">0.0323</td>
              <td style="text-align:center;">0.0483</td>
              <td style="text-align:center;">0.0649</td>
              <td style="text-align:center;">0.0758</td>
              <td style="text-align:center;">0.0837</td>
              <td style="text-align:center;">3.24</td>
              <td style="text-align:center;">3.53</td>
              <td style="text-align:center;">4.07</td>
              <td style="text-align:center;">5.58</td>
              <td style="text-align:center;">6.99</td>
            </tr>
            <tr>
              <td style="text-align:center;">FSDH</td>
              <td style="text-align:center;">0.0256</td>
              <td style="text-align:center;">0.0419</td>
              <td style="text-align:center;">0.0598</td>
              <td style="text-align:center;">0.0690</td>
              <td style="text-align:center;">0.0884</td>
              <td style="text-align:center;">6.61</td>
              <td style="text-align:center;">6.55</td>
              <td style="text-align:center;">6.73</td>
              <td style="text-align:center;">7.01</td>
              <td style="text-align:center;">7.57</td>
            </tr>
            <tr>
              <td style="text-align:center;">COSDISH</td>
              <td style="text-align:center;">0.0379</td>
              <td style="text-align:center;">0.0752</td>
              <td style="text-align:center;">0.1449</td>
              <td style="text-align:center;">0.2019</td>
              <td style="text-align:center;">0.2292</td>
              <td style="text-align:center;">1.99</td>
              <td style="text-align:center;">6.39</td>
              <td style="text-align:center;">16.76</td>
              <td style="text-align:center;">79.82</td>
              <td style="text-align:center;">185.28</td>
            </tr>
            <tr>
              <td style="text-align:center;">SSDH</td>
              <td style="text-align:center;">
              <strong>0.1001</strong></td>
              <td style="text-align:center;">
              <strong>0.1640</strong></td>
              <td style="text-align:center;">
              <strong>0.2348</strong></td>
              <td style="text-align:center;">
              <strong>0.2824</strong></td>
              <td style="text-align:center;">
              <strong>0.2674</strong></td>
              <td style="text-align:center;">3.03</td>
              <td style="text-align:center;">3.11</td>
              <td style="text-align:center;">3.16</td>
              <td style="text-align:center;">3.30</td>
              <td style="text-align:center;">3.34</td>
            </tr>
          </tbody>
        </table>
      </div>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span>
            Experimental Setup</h3>
          </div>
        </header>
        <p><strong>Datasets:</strong> We conducted experiments on
        six publicly available and widely used datasets to evaluate
        the proposed method.</p>
        <ul class="list-no-style">
          <li id="list5" label="•">
            <em>MNIST</em> <a class="fn" href="#fn3" id=
            "foot-fn3"><sup>2</sup></a> [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0024">24</a>]:
            This dataset is a subset of a larger set available from
            NIST. It consists of 70,000 images of handwritten
            digits from ‘0’ to ‘9’, and thus has 10 classes. Each
            image in this dataset is represented by 784-dimension
            feature vectors.<br />
          </li>
          <li id="list6" label="•">
            <em>MIRFlickr</em> <a class="fn" href="#fn4" id=
            "foot-fn4"><sup>3</sup></a> [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0016">16</a>]: It
            is a real-word dataset collected from Flickr website
            with 25,000 instances. Each instance is manually
            annotated with at least one of 24 labels. Following the
            pretreatment in [<a class="bib" data-trigger="hover"
            data-toggle="popover" data-placement="top" href=
            "#BibPLXBIB0031">31</a>, <a class="bib" data-trigger=
            "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0055">55</a>], we remove the instances
            without labels or textual tags appearing less than 20
            times. Finally, there are 16,738 instances are left.
            For each instance, its image is represented by
            150-dimension edge histogram.<br />
          </li>
          <li id="list7" label="•">
            <em>CIFAR-10</em> <a class="fn" href="#fn5" id=
            "foot-fn5"><sup>4</sup></a> [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0019">19</a>]: It
            is collected from 80 million tiny images. Every image
            in CIFAR-10 is manually labeled with one of 10 classes;
            with each class containing 6,000 samples, CIFAR-10 has
            a number of 60,000 images in all. Images are
            represented by 512-dimension GIST [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0043">43</a>]
            feature vectors extracted from the original color image
            of size 32 × 32.<br />
          </li>
          <li id="list8" label="•">
            <em>CIFAR-100</em> <a class="fn" href="#fn6" id=
            "foot-fn6"><sup>5</sup></a> [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0019">19</a>]: It
            is also collected from the 80 million tiny images. It
            consists of 100 classes with each class containing 600
            color images, which results in 60,000 images in total.
            Every image is represented by a 512-dimensional GIST
            feature vector.<br />
          </li>
          <li id="list9" label="•">
            <em>NUS-WIDE</em> <a class="fn" href="#fn7" id=
            "foot-fn7"><sup>6</sup></a> [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0006">6</a>]: It
            is a real-world image dataset originally containing
            269,648 samples collected from Flickr. As in [<a class=
            "bib" data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0045">45</a>], we
            collect the 21 most frequent label for evaluating and
            195,834 images are left. The provided 500-dimensional
            bag-of-words features are used.<br />
          </li>
          <li id="list10" label="•">
            <em>ImageNet</em> <a class="fn" href="#fn8" id=
            "foot-fn8"><sup>7</sup></a> [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0044">44</a>]: We
            also evaluate our method on the training set of
            ILSVRC2010. This dataset is a subset of ImageNet and
            contains 1.2 million images. These images belong to
            1,000 categories, with each category having at least
            600 samples. We use the released 1,000-dimensional BoW
            features, which are computed from SIFT features of
            original images, to represent instances.<br />
          </li>
        </ul>
        <p>Each dataset is randomly split into a training set and a
        query set. On NUS-WIDE, for each label, 100 images are
        randomly sampled (2,100 images with duplication) for the
        query set. On ImageNet, we construct a query set by
        randomly sampling 5% instances. The statistics of these
        datasets are given in Table <a class="tbl" href=
        "#tab1">1</a>.</p>
        <p>For single-label datasets, if two samples have the same
        class label, they are considered to be semantically
        similar, and dissimilar otherwise. For multi-label
        datasets, if two samples share at least one semantic label,
        they are considered to be semantically similar.</p>
        <p><strong>Competing Methods:</strong> We compared SSDH
        against seven state-of-the-art hashing algorithms,
        including unsupervised and supervised ones:</p>
        <ul class="list-no-style">
          <li id="list11" label="•">LSH [<a class="bib"
          data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0008">8</a>]:
            Locality-Sensitive Hashing (unsupervised). Its basic
            idea is to hash the points from the database so as to
            ensure that the probability of collision is much higher
            for objects that are close to each other than for those
            that are far apart.<br />
          </li>
          <li id="list12" label="•">ITQ [<a class="bib"
          data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0009">9</a>]:
            Iterative Quantization (unsupervised). ITQ contains a
            simple and efficient alternating minimization scheme
            for finding a rotation of zero-centered data so as to
            minimize the quantization error of mapping this data to
            the vertices of a zero-centered binary hypercube.<br />
          </li>
          <li id="list13" label="•">KSH [<a class="bib"
          data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0034">34</a>]:
            Kernel-Based Supervised Hashing (supervised). KSH
            utilizes the equivalence between optimizing the code
            inner products and the Hamming distances.<br />
          </li>
          <li id="list14" label="•">SDH [<a class="bib"
          data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0045">45</a>]:
            Supervised Discrete Hashing (supervised). Its learning
            objective is to generate the optimal binary hash codes
            for linear classification.<br />
          </li>
          <li id="list15" label="•">NSH [<a class="bib"
          data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0032">32</a>]
            Natural Supervised Hashing (supervised). The key idea
            of NSH is to treat label vectors as binary codes and to
            learn target codes which have similar structure to
            label vectors.<br />
          </li>
          <li id="list16" label="•">FSDH [<a class="bib"
          data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0011">11</a>] :
            Fast Supervised Discrete Hashing (supervised). FSDH
            uses a very simple yet effective regression of the
            class labels of training examples to the corresponding
            hash code to accelerate the algorithm.<br />
          </li>
          <li id="list17" label="•">COSDISH [<a class="bib"
          data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0018">18</a>]:
            Column Sampling based Discrete Supervised Hashing
            (supervised). COSDISH directly learns the discrete hash
            code from semantic information.<br />
          </li>
        </ul>
        <figure id="fig1">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186072/images/www2018-81-fig1.jpg"
          class="img-responsive" alt="Figure 1" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span>
            <span class="figure-title">Precision v.s. Recall curves
            on MNIST, MIRFlickr, CIFAR-10 and CIFAR-100 with code
            lengths from 8 to 96.</span>
          </div>
        </figure>
        <p>For most baselines we used the codes kindly provided by
        the authors and we carefully tuned their parameters
        according to the scheme suggested by the authors. As the
        code of NSH and FSDH are not publicly available, we
        implemented the code exactly following the algorithms of
        them and tuned the parameters according to the scheme
        suggested in their papers. For SSDH, we set <em>t</em> = 5
        which is enough to get satisfactory performance, <em>μ</em>
        = 1 and <em>λ<sub>e</sub></em> = 1. All methods run on a
        workstation with Intel(R) XEON(R) CPU E5-2650@2.30GHz,
        128GB memory.</p>
        <p>Following [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0018">18</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0030">30</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0034">34</a>], we randomly sampled 2,000 images
        as training sets for KSH on all datasets due to its high
        time complexity.</p>
        <p><strong>Evaluation Metrics:</strong> To fully evaluate
        SSDH and all of baselines, we adopted three widely used
        metrics, i.e., mean average precision (MAP),
        precision-recall curves and topN-precision curves. For all
        metrics, a larger value indicates the better retrieval
        performance.</p>
        <p>The average precision (AP) for a query is defined as</p>
        <div class="table-responsive" id="Xeq4">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} AP=
            \frac{1}{R}\sum _{r=1}^n Precision(r)\delta (r).
            \end{equation}</span><br />
            <span class="equation-number">(15)</span>
          </div>
        </div>where <em>R</em> is the number of ground-truth
        neighbors of the query in a database, <em>n</em> is the
        number of samples in the database,
        <em>Precision</em>(<em>r</em>) denotes the precision of the
        top <em>r</em> retrieved entities, and
        <em>δ</em>(<em>r</em>) = 1 if the <em>r</em>-th retrieved
        entity is a ground-truth neighbour and
        <em>δ</em>(<em>r</em>) = 0 otherwise. For a query set whose
        size is <em>M</em>, the MAP is defined as the mean of the
        average precision scores for all the queries in the query
        set, i.e.,
        <div class="table-responsive" id="Xeq5">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            MAP=\frac{1}{M}\sum _{i=1}^M AP_i.
            \end{equation}</span><br />
            <span class="equation-number">(16)</span>
          </div>
        </div>
        <p></p>
        <p>Precision-recall curves can be obtained by varying the
        Hamming radius of the retrieved points and evaluating the
        precision, recall and the number of retrieved points.</p>
        <p>TopN-precision curves reflects the change of precision
        with respect to the number of top-ranked <em>N</em>
        instances returned to the users, which is expressive for
        retrieval.</p>
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186072/images/www2018-81-fig2.jpg"
          class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">TopN-precision curves on
            MNIST, MIRFlickr, CIFAR-10 and CIFAR-100 with code
            lengths from 8 to 96.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Comparison
            Results</h3>
          </div>
        </header>
        <section id="sec-19">
          <p><em>4.2.1 MAP and Time.</em> The MAP results and
          training time of all methods on MNIST, MIRFlickr,
          CIFAR-10 and CIFAR-100 are listed in Table <a class="tbl"
          href="#tab2">2</a>, <a class="tbl" href="#tab3">3</a>,
          <a class="tbl" href="#tab4">4</a>, and <a class="tbl"
          href="#tab5">5</a>, respectively.</p>
          <p>From these tables, we can observe that:</p>
          <ul class="list-no-style">
            <li id="list18" label="•">SSDH can outperform all
            baselines on MAP results in all cases, which verifies
            its effectiveness.<br /></li>
            <li id="list19" label="•">Unsupervised hashing methods
            LSH and ITQ require the least amount of training time.
            However, all supervised methods outperform
            them.<br /></li>
            <li id="list20" label="•">On single-label datasets,
            i.e., MNIST, CIFAR-10, and CIFAR-100, SSDH can be
            efficiently trained. For example, SSDH needs shorter
            time than other supervised baselines. Besides, SSDH's
            training time is robust to hash bit lengths while KSH,
            SDH, and COSDISH need more training time with longer
            bit lengths.<br /></li>
            <li id="list21" label="•">On multi-label datasets,
            i.e., MIRFlickr, we can also train SSDH fast. As SSDH
            needs to learn binary codes bit by bit, it takes more
            time to learn longer hash codes. However, compared to
            baselines KSH, SDH, and COSDISH which also learn hash
            codes bit by bit, SSDH is still the fastest
            one.<br /></li>
            <li id="list22" label="•">When the number of labels
            getting larger, data becomes more complicated and
            search becomes more challenging. It can be seen from
            that MAP results of all methods on CIFAR-100 are much
            worse than those on CIFAR-10.<br /></li>
          </ul>
          <p>From the MAP and time cost results in these table, we
          can conclude SSDH is effective and efficient on these
          datasets.</p>
        </section>
        <section id="sec-20">
          <p><em>4.2.2 Precision-Recall and TopN-Precision
          Curves.</em> To gain further insights, we plotted the
          precision-recall curves and topN-precision curves on
          MNIST, MIRFlickr, CIFAR-10, and CIFAR-100 in Figure
          <a class="fig" href="#fig1">1</a> and Figure <a class=
          "fig" href="#fig2">2</a>, respectively. Note that one
          column in these figures demonstrates the results on one
          dataset.</p>
          <p>From these figures, we can find that:</p>
          <ul class="list-no-style">
            <li id="list23" label="•">In terms of precision-recall
            curves, SSDH performs much better than all baselines in
            all cases.<br /></li>
            <li id="list24" label="•">In terms of the
            topN-precision curves, in all cases, the performance
            gains provided by SSDH over the best baseline are
            significant. Especially, SSDH obtains much better
            results than other baselines when <em>N</em> is small.
            This means that SSDH can return much more similar
            samples at the beginning, which is very important for a
            retrieval model.<br /></li>
          </ul>
          <p>From the results of these figures, we can also
          conclude, compared to all baselines, SSDH can achieve
          competitive performance.</p>
          <div class="table-responsive" id="tab6">
            <div class="table-caption">
              <span class="table-number">Table 6:</span>
              <span class="table-title">The MAP results and
              training time of all methods on NUS-WIDE.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:center;"></th>
                  <th colspan="3" style="text-align:center;">
                    MAP
                    <hr />
                  </th>
                  <th colspan="3" style="text-align:center;">
                    Training Time (in second)
                    <hr />
                  </th>
                </tr>
                <tr>
                  <th style="text-align:center;">Method</th>
                  <th style="text-align:center;">16 bits</th>
                  <th style="text-align:center;">32 bits</th>
                  <th style="text-align:center;">64 bits</th>
                  <th style="text-align:center;">16 bits</th>
                  <th style="text-align:center;">32 bits</th>
                  <th style="text-align:center;">64 bits</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:center;">LSH</td>
                  <td style="text-align:center;">0.3107</td>
                  <td style="text-align:center;">0.3165</td>
                  <td style="text-align:center;">0.3197</td>
                  <td style="text-align:center;">0.06</td>
                  <td style="text-align:center;">0.08</td>
                  <td style="text-align:center;">0.13</td>
                </tr>
                <tr>
                  <td style="text-align:center;">ITQ</td>
                  <td style="text-align:center;">0.3343</td>
                  <td style="text-align:center;">0.3348</td>
                  <td style="text-align:center;">0.3364</td>
                  <td style="text-align:center;">2.55</td>
                  <td style="text-align:center;">5.53</td>
                  <td style="text-align:center;">9.63</td>
                </tr>
                <tr>
                  <td style="text-align:center;">KSH</td>
                  <td style="text-align:center;">0.3703</td>
                  <td style="text-align:center;">0.3728</td>
                  <td style="text-align:center;">0.3785</td>
                  <td style="text-align:center;">52.53</td>
                  <td style="text-align:center;">105.24</td>
                  <td style="text-align:center;">208.97</td>
                </tr>
                <tr>
                  <td style="text-align:center;">SDH</td>
                  <td style="text-align:center;">0.4113</td>
                  <td style="text-align:center;">0.4114</td>
                  <td style="text-align:center;">0.4135</td>
                  <td style="text-align:center;">28.94</td>
                  <td style="text-align:center;">77.95</td>
                  <td style="text-align:center;">250.95</td>
                </tr>
                <tr>
                  <td style="text-align:center;">NSH</td>
                  <td style="text-align:center;">0.4075</td>
                  <td style="text-align:center;">0.4135</td>
                  <td style="text-align:center;">0.4133</td>
                  <td style="text-align:center;">10.97</td>
                  <td style="text-align:center;">11.93</td>
                  <td style="text-align:center;">15.26</td>
                </tr>
                <tr>
                  <td style="text-align:center;">FSDH</td>
                  <td style="text-align:center;">0.4052</td>
                  <td style="text-align:center;">0.4115</td>
                  <td style="text-align:center;">0.4155</td>
                  <td style="text-align:center;">19.86</td>
                  <td style="text-align:center;">19.26</td>
                  <td style="text-align:center;">21.48</td>
                </tr>
                <tr>
                  <td style="text-align:center;">COSDISH</td>
                  <td style="text-align:center;">0.5765</td>
                  <td style="text-align:center;">0.5947</td>
                  <td style="text-align:center;">0.5942</td>
                  <td style="text-align:center;">16.11</td>
                  <td style="text-align:center;">56.27</td>
                  <td style="text-align:center;">232.55</td>
                </tr>
                <tr>
                  <td style="text-align:center;">SSDH</td>
                  <td style="text-align:center;">
                  <strong>0.6023</strong></td>
                  <td style="text-align:center;">
                  <strong>0.6035</strong></td>
                  <td style="text-align:center;">
                  <strong>0.6069</strong></td>
                  <td style="text-align:center;">10.88</td>
                  <td style="text-align:center;">20.86</td>
                  <td style="text-align:center;">56.02</td>
                </tr>
              </tbody>
            </table>
          </div>
          <div class="table-responsive" id="tab7">
            <div class="table-caption">
              <span class="table-number">Table 7:</span>
              <span class="table-title">The MAP results and
              training time of all methods on ImageNet.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:center;"></th>
                  <th colspan="3" style="text-align:center;">
                    MAP
                    <hr />
                  </th>
                  <th colspan="3" style="text-align:center;">
                    Training Time (in second)
                    <hr />
                  </th>
                </tr>
                <tr>
                  <th style="text-align:center;">Method</th>
                  <th style="text-align:center;">16 bits</th>
                  <th style="text-align:center;">32 bits</th>
                  <th style="text-align:center;">64 bits</th>
                  <th style="text-align:center;">16 bits</th>
                  <th style="text-align:center;">32 bits</th>
                  <th style="text-align:center;">64 bits</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:center;">LSH</td>
                  <td style="text-align:center;">0.0015</td>
                  <td style="text-align:center;">0.0018</td>
                  <td style="text-align:center;">0.0021</td>
                  <td style="text-align:center;">0.40</td>
                  <td style="text-align:center;">0.51</td>
                  <td style="text-align:center;">0.92</td>
                </tr>
                <tr>
                  <td style="text-align:center;">ITQ</td>
                  <td style="text-align:center;">0.0027</td>
                  <td style="text-align:center;">0.0028</td>
                  <td style="text-align:center;">0.0031</td>
                  <td style="text-align:center;">23.16</td>
                  <td style="text-align:center;">35.92</td>
                  <td style="text-align:center;">60.20</td>
                </tr>
                <tr>
                  <td style="text-align:center;">KSH</td>
                  <td style="text-align:center;">0.0023</td>
                  <td style="text-align:center;">0.0020</td>
                  <td style="text-align:center;">0.0024</td>
                  <td style="text-align:center;">41.81</td>
                  <td style="text-align:center;">92.13</td>
                  <td style="text-align:center;">228.22</td>
                </tr>
                <tr>
                  <td style="text-align:center;">SDH</td>
                  <td style="text-align:center;">0.0026</td>
                  <td style="text-align:center;">0.0038</td>
                  <td style="text-align:center;">0.0051</td>
                  <td style="text-align:center;">979.42</td>
                  <td style="text-align:center;">1859.35</td>
                  <td style="text-align:center;">5327.54</td>
                </tr>
                <tr>
                  <td style="text-align:center;">NSH</td>
                  <td style="text-align:center;">0.0045</td>
                  <td style="text-align:center;">0.0052</td>
                  <td style="text-align:center;">0.0065</td>
                  <td style="text-align:center;">92.46</td>
                  <td style="text-align:center;">112.55</td>
                  <td style="text-align:center;">145.41</td>
                </tr>
                <tr>
                  <td style="text-align:center;">FSDH</td>
                  <td style="text-align:center;">0.0027</td>
                  <td style="text-align:center;">0.0037</td>
                  <td style="text-align:center;">0.0051</td>
                  <td style="text-align:center;">222.28</td>
                  <td style="text-align:center;">230.02</td>
                  <td style="text-align:center;">248.99</td>
                </tr>
                <tr>
                  <td style="text-align:center;">COSDISH</td>
                  <td style="text-align:center;">0.0041</td>
                  <td style="text-align:center;">0.0141</td>
                  <td style="text-align:center;">0.0212</td>
                  <td style="text-align:center;">99.33</td>
                  <td style="text-align:center;">344.98</td>
                  <td style="text-align:center;">1837.24</td>
                </tr>
                <tr>
                  <td style="text-align:center;">SSDH</td>
                  <td style="text-align:center;">
                  <strong>0.0122</strong></td>
                  <td style="text-align:center;">
                  <strong>0.0209</strong></td>
                  <td style="text-align:center;">
                  <strong>0.0335</strong></td>
                  <td style="text-align:center;">269.38</td>
                  <td style="text-align:center;">282.78</td>
                  <td style="text-align:center;">290.51</td>
                </tr>
              </tbody>
            </table>
          </div>
        </section>
      </section>
      <section id="sec-21">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Scalable
            Search</h3>
          </div>
        </header>
        <p>We further carried out experiments on two large-scale
        datasets, i.e., NUS-WIDE and ImageNet.</p>
        <section id="sec-22">
          <p><em>4.3.1 Results on NUS-WIDE.</em> The MAP results of
          all methods on NUS-WIDE are shown in Table <a class="tbl"
          href="#tab6">6</a>. To further evaluate the scalability
          of SSDH and all baselines, training time is also reported
          in this table. From this table, we can find that:</p>
          <ul class="list-no-style">
            <li id="list25" label="•">SSDH obtains the best MAP
            results in all cases.<br /></li>
            <li id="list26" label="•">The training process of SSDH
            is very fast and scales well. On NUS-WIDE, which has
            nearly 200,000 samples, the training costs in cases of
            16-bit, 32-bit, and 64-bit are about 10, 20, and 56
            seconds, respectively.<br /></li>
            <li id="list27" label="•">The MAP results of COSDISH
            are comparable to those of SSDH and both of them
            perform better than other baselines with large accuracy
            gains. But COSDISH needs much more training time than
            SSDH. Thus, SSDH is more scalable than
            COSDISH.<br /></li>
            <li id="list28" label="•">With code lengths being 32
            and 64, NSH and FSDH can be trained faster than SSDH
            because they simultaneously learn all bits. As SSDH
            learns hash codes bit by bit for multi-label data, it
            needs more time than NSH and FSDH. However, SSDH can
            obtain much better MAP results than both NSH and FSDH
            with slightly increased time cost.<br /></li>
          </ul>
          <p>In a nutshell, SSDH is the most practical supervised
          hashing method, especially for large-scale datasets.</p>
        </section>
        <section id="sec-23">
          <p><em>4.3.2 Results on ImageNet.</em> All methods’ MAP
          results and training time on ImageNet are listed in Table
          <a class="tbl" href="#tab7">7</a>. From this table, we
          can observe that:</p>
          <ul class="list-no-style">
            <li id="list29" label="•">SSDH obtains much better
            accuracy than all baselines in all cases on this
            dataset.<br /></li>
            <li id="list30" label="•">Compared to the results on
            other datasets, the accuracy of all methods on ImageNet
            is a little low. The main reason is that ImageNet is a
            more challenging dataset. For example, it has more than
            1 million instances; moreover, it has as much as 1,000
            classes, which makes it complicated.<br /></li>
            <li id="list31" label="•">SDH and KSH are not scalable
            as they need too much time. Note that KSH is trained on
            a subset containing 2,000 samples.<br /></li>
            <li id="list32" label="•">COSDISH can outperform other
            baselines in cases of 32-bit and 64-bit. But with the
            code length increasing, it becomes time-consuming and
            cannot scale well.<br /></li>
            <li id="list33" label="•">Compared to SSDH, NSH, and
            FSDH need less time for training; however, their
            accuracy is not satisfactory, even not acceptable.
            Besides, compared to them, SSDH only needs a little
            more time to finish its training.<br /></li>
          </ul>
          <p>From the results on ImageNet, we can further conclude
          that SSDH scales well on large-scale dataset (more than 1
          million) and is the most practical supervised hashing
          method.</p>
        </section>
      </section>
    </section>
    <section id="sec-24">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span>
          Conclusions</h2>
        </div>
      </header>
      <p>In this paper, we proposed a novel scalable hashing
      method, i.e., the Scalable Supervised Discrete Hashing
      (SSDH). By replacing one binary matrix <strong>B</strong> by
      <strong>YG</strong> (<strong>Y</strong> is the label matrix,
      <strong>G</strong> is a projection matrix) and computing
      <strong>SY</strong> offline, SSDH bypasses the direct
      optimization on <em>n</em> × <em>n</em> large matrix
      <strong>S</strong> during the optimization. Besides, as SSDH
      makes use of both pairwise similarity matrix
      <strong>S</strong> and label matrix <strong>L</strong>, more
      semantic information can be embedded to the learning of hash
      codes. Moreover, based on the proposed optimization
      algorithm, SSDH can discretely learn hash codes. Due to the
      well-designed loss function and the efficient alternative
      optimization algorithm, SSDH achieves high accuracy with
      acceptable time cost; even the large-scale data can be
      efficiently and effectively handled. Experiments conducted on
      six datasets demonstrate the superiority of SSDH to the
      existing state-of-the-art unsupervised and supervised hashing
      methods.</p>
    </section>
    <section id="sec-25">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span>
          Acknowledgements</h2>
        </div>
      </header>
      <p>This work was partially supported by the Key Research and
      Development Program of Shandong Province (2016GGX101044) and
      National Natural Science Foundation of China (61573212).</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Alexandr Andoni, Piotr
        Indyk, Thijs Laarhoven, Ilya Razenshteyn, and Ludwig
        Schmidt. 2015. Practical and optimal LSH for angular
        distance. In <em>NIPS</em>. 1225–1233.</li>
        <li id="BibPLXBIB0002" label="[2]">Fatih Cakir and Stan
        Sclaroff. 2015. Adaptive hashing for fast similarity
        search. In <em>ICCV</em>. 1044–1052.</li>
        <li id="BibPLXBIB0003" label="[3]">Fatih Cakir and Stan
        Sclaroff. 2015. Online supervised hashing. In
        <em>ICIP</em>. 2606–2610.</li>
        <li id="BibPLXBIB0004" label="[4]">Yuan Cao, Heng Qi,
        Wenrui Zhou, Jien Kato, Keqiu Li, Xiulong Liu, and Jie Gui.
        2018. Binary hashing for approximate nearest neighbor
        search on big data: A survey. <em>IEEE Access</em> 6(2018),
        2039–2054.</li>
        <li id="BibPLXBIB0005" label="[5]">Lianhua Chi and Xingquan
        Zhu. 2017. Hashing Techniques: A survey and taxonomy.
        <em>CSUR</em> 50, 1 (2017), 11.</li>
        <li id="BibPLXBIB0006" label="[6]">Tat-Seng Chua, Jinhui
        Tang, Richang Hong, Haojie Li, Zhiping Luo, and Yan-Tao
        Zheng. 2009. NUS-WIDE: A real-world web image database from
        National University of Singapore. In <em>CIVR</em>.
        48:1–48:9.</li>
        <li id="BibPLXBIB0007" label="[7]">Mayur Datar, Nicole
        Immorlica, Piotr Indyk, and Vahab&nbsp;S Mirrokni. 2004.
        Locality-sensitive hashing scheme based on p-stable
        distributions. In <em>SoCG</em>. 253–262.</li>
        <li id="BibPLXBIB0008" label="[8]">Aristides Gionis, Piotr
        Indyk, Rajeev Motwani, <em>et al.</em> 1999. Similarity
        search in high dimensions via hashing. In <em>VLDB</em>.
        518–529.</li>
        <li id="BibPLXBIB0009" label="[9]">Yunchao Gong, Svetlana
        Lazebnik, Albert Gordo, and Florent Perronnin. 2013.
        Iterative quantization: A procrustean approach to learning
        binary codes for large-scale image retrieval.
        <em>TPAMI</em> 35, 12 (2013), 2916–2929.</li>
        <li id="BibPLXBIB0010" label="[10]">Albert Gordo, Florent
        Perronnin, Yunchao Gong, and Svetlana Lazebnik. 2014.
        Asymmetric distances for binary embeddings. <em>TPAMI</em>
        36, 1 (2014), 33–47.</li>
        <li id="BibPLXBIB0011" label="[11]">Jie Gui, Tongliang Liu,
        Zhenan Sun, Dacheng Tao, and Tieniu Tan. 2018. Fast
        supervised discrete hashing. <em>TPAMI</em> 40, 2 (2018),
        490–496.</li>
        <li id="BibPLXBIB0012" label="[12]">Yanbin Hao, Tingting
        Mu, John&nbsp;Y Goulermas, Jianguo Jiang, Richang Hong, and
        Meng Wang. 2017. Unsupervised t-distributed video hashing
        and its deep hashing extension. <em>TIP</em> 26, 11 (2017),
        5531–5544.</li>
        <li id="BibPLXBIB0013" label="[13]">Xiangnan He and
        Tat-Seng Chua. 2017. Neural factorization machines for
        sparse predictive analytics. In <em>SIGIR</em>. ACM,
        355–364.</li>
        <li id="BibPLXBIB0014" label="[14]">Xiangnan He, Hanwang
        Zhang, Min-Yen Kan, and Tat-Seng Chua. 2016. Fast matrix
        factorization for online recommendation with implicit
        feedback. In <em>SIGIR</em>. 549–558.</li>
        <li id="BibPLXBIB0015" label="[15]">Long-Kai Huang and
        Sinno&nbsp;Jialin Pan. 2016. Class-wise supervised hashing
        with label embedding and active bits. In <em>IJCAI</em>.
        1585–1591.</li>
        <li id="BibPLXBIB0016" label="[16]">Mark&nbsp;J. Huiskes
        and Michael&nbsp;S. Lew. 2008. The MIR flickr retrieval
        evaluation. In <em>MIR</em>. 39–43.</li>
        <li id="BibPLXBIB0017" label="[17]">Qing-Yuan Jiang and
        Wu-Jun Li. 2015. Scalable graph hashing with feature
        transformation. In <em>IJCAI</em>. 2248–2254.</li>
        <li id="BibPLXBIB0018" label="[18]">Wang-Cheng Kang, Wu-Jun
        Li, and Zhi-Hua Zhou. 2016. Column sampling based discrete
        supervised hashing. In <em>AAAI</em>. 1230–1236.</li>
        <li id="BibPLXBIB0019" label="[19]">Alex Krizhevsky and
        Geoffrey Hinton. 2009. Learning multiple layers of features
        from tiny images. <em>Technical Report, University of
        Toronto</em> (2009).</li>
        <li id="BibPLXBIB0020" label="[20]">Brian Kulis and Kristen
        Grauman. 2009. Kernelized locality-sensitive hashing for
        scalable image search. In <em>ICCV</em>. 2130–2137.</li>
        <li id="BibPLXBIB0021" label="[21]">Brian Kulis, Prateek
        Jain, and Kristen Grauman. 2009. Fast similarity search for
        learned metrics. <em>TPAMI</em> 31, 12 (2009),
        2143–2157.</li>
        <li id="BibPLXBIB0022" label="[22]">Shaishav Kumar and
        Raghavendra Udupa. 2011. Learning hash functions for
        cross-view similarity search. In <em>IJCAI</em>.
        1360–1365.</li>
        <li id="BibPLXBIB0023" label="[23]">Hanjiang Lai, Yan Pan,
        Ye Liu, and Shuicheng Yan. 2015. Simultaneous feature
        learning and hash coding with deep neural networks. In
        <em>CVPR</em>. 3270–3278.</li>
        <li id="BibPLXBIB0024" label="[24]">Yann LeCun, Léon
        Bottou, Yoshua Bengio, and Patrick Haffner. 1998.
        Gradient-based learning applied to document recognition.
        <em>P IEEE</em> 86, 11 (1998), 2278–2324.</li>
        <li id="BibPLXBIB0025" label="[25]">Cong Leng, Jian Cheng,
        Jiaxiang Wu, Xi Zhang, and Hanqing Lu. 2014. Supervised
        hashing with soft constraints. In <em>CIKM</em>.
        1851–1854.</li>
        <li id="BibPLXBIB0026" label="[26]">Cong Leng, Jiaxiang Wu,
        Jian Cheng, Xi Zhang, and Hanqing Lu. 2015. Hashing for
        distributed data. In <em>ICML</em>. 1642–1650.</li>
        <li id="BibPLXBIB0027" label="[27]">Ping Li, Anshumali
        Shrivastava, Joshua&nbsp;L Moore, and Arnd&nbsp;C König.
        2011. Hashing algorithms for large-scale learning. In
        <em>NIPS</em>. 2672–2680.</li>
        <li id="BibPLXBIB0028" label="[28]">Wu-Jun Li, Sheng Wang,
        and Wang-Cheng Kang. 2016. Feature learning based deep
        supervised hashing with pairwise labels. In <em>IJCAI</em>.
        1711–1717.</li>
        <li id="BibPLXBIB0029" label="[29]">Guosheng Lin, Chunhua
        Shen, Qinfeng Shi, Anton Van&nbsp;den Hengel, and David
        Suter. 2014. Fast supervised hashing with decision trees
        for high-dimensional data. In <em>CVPR</em>.
        1963–1970.</li>
        <li id="BibPLXBIB0030" label="[30]">Guosheng Lin, Chunhua
        Shen, David Suter, and Anton van&nbsp;den Hengel. 2013. A
        general two-step approach to learning-based hashing. In
        <em>ICCV</em>. 2552–2559.</li>
        <li id="BibPLXBIB0031" label="[31]">Zijia Lin, Guiguang
        Ding, Mingqing Hu, and Jianmin Wang. 2015.
        Semantics-preserving hashing for cross-view retrieval. In
        <em>CVPR</em>. 3864–3872.</li>
        <li id="BibPLXBIB0032" label="[32]">Qi Liu and Hongtao Lu.
        2016. Natural supervised hashing. In <em>IJCAI</em>.
        1788–1794.</li>
        <li id="BibPLXBIB0033" label="[33]">Wei Liu, Cun Mu, Sanjiv
        Kumar, and Shih-Fu Chang. 2014. Discrete graph hashing. In
        <em>NIPS</em>. 3419–3427.</li>
        <li id="BibPLXBIB0034" label="[34]">Wei Liu, Jun Wang,
        Rongrong Ji, Yu-Gang Jiang, and Shih-Fu Chang. 2012.
        Supervised hashing with kernels. In <em>CVPR</em>.
        2074–2081.</li>
        <li id="BibPLXBIB0035" label="[35]">Xianglong Liu, Cheng
        Deng, Bo Lang, Dacheng Tao, and Xuelong Li. 2016.
        Query-adaptive reciprocal hash tables for nearest neighbor
        search. <em>TIP</em> 25, 2 (2016), 907–919.</li>
        <li id="BibPLXBIB0036" label="[36]">Xianglong Liu, Lei
        Huang, Cheng Deng, Jiwen Lu, and Bo Lang. 2015. Multi-view
        complementary hash tables for nearest neighbor search. In
        <em>ICCV</em>. 1107–1115.</li>
        <li id="BibPLXBIB0037" label="[37]">Mingsheng Long, Yue
        Cao, Jianmin Wang, and Philip&nbsp;S Yu. 2016. Composite
        correlation quantization for efficient multimodal
        retrieval. In <em>SIGIR</em>. 579–588.</li>
        <li id="BibPLXBIB0038" label="[38]">Liqiang Nie, Meng Wang,
        Zhengjun Zha, Guangda Li, and Tat-Seng Chua. 2011.
        Multimedia answering: enriching text QA with media
        information. In <em>SIGIR</em>. 695–704.</li>
        <li id="BibPLXBIB0039" label="[39]">Liqiang Nie, Meng Wang,
        Zheng-Jun Zha, and Tat-Seng Chua. 2012. Oracle in image
        search: A content-based approach to performance prediction.
        <em>TOIS</em>30, 2 (2012), 13.</li>
        <li id="BibPLXBIB0040" label="[40]">Liqiang Nie, Shuicheng
        Yan, Meng Wang, Richang Hong, and Tat-Seng Chua. 2012.
        Harvesting visual concepts for image search with complex
        queries. In <em>MM</em>. 59–68.</li>
        <li id="BibPLXBIB0041" label="[41]">Liqiang Nie, Yi-Liang
        Zhao, Mohammad Akbari, Jialie Shen, and Tat-Seng Chua.
        2015. Bridging the vocabulary gap between health seekers
        and healthcare knowledge. <em>TKDE</em> 27, 2 (2015),
        396–409.</li>
        <li id="BibPLXBIB0042" label="[42]">Mohammad Norouzi and
        David&nbsp;M Blei. 2011. Minimal loss hashing for compact
        binary codes. In <em>ICML</em>. 353–360.</li>
        <li id="BibPLXBIB0043" label="[43]">Aude Oliva and Antonio
        Torralba. 2001. Modeling the shape of the scene: A holistic
        representation of the spatial envelope. <em>IJCV</em> 42, 3
        (2001), 145–175.</li>
        <li id="BibPLXBIB0044" label="[44]">Olga Russakovsky, Jia
        Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
        Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael
        Bernstein, Alexander&nbsp;C. Berg, and Li Fei-Fei. 2015.
        ImageNet large scale visual recognition challenge.
        <em>IJCV</em> 115, 3 (2015), 211–252.</li>
        <li id="BibPLXBIB0045" label="[45]">Fumin Shen, Chunhua
        Shen, Wei Liu, and Heng Tao&nbsp;Shen. 2015. Supervised
        discrete hashing. In <em>CVPR</em>. 37–45.</li>
        <li id="BibPLXBIB0046" label="[46]">Fumin Shen, Chunhua
        Shen, Qinfeng Shi, Anton Hengel, and Zhenmin Tang. 2013.
        Inductive hashing on manifolds. In <em>CVPR</em>.
        1562–1569.</li>
        <li id="BibPLXBIB0047" label="[47]">Anshumali Shrivastava
        and Ping Li. 2014. Asymmetric LSH (ALSH) for sublinear time
        maximum inner product search (MIPS). In <em>NIPS</em>.
        2321–2329.</li>
        <li id="BibPLXBIB0048" label="[48]">Jun Wang, Sanjiv Kumar,
        and Shih-Fu Chang. 2010. Semi-supervised hashing for
        scalable image retrieval. In <em>CVPR</em>. 3424–3431.</li>
        <li id="BibPLXBIB0049" label="[49]">Jingdong Wang, Ting
        Zhang, Jingkuan Song, Nicu Sebe, and Heng&nbsp;Tao Shen.
        2018. A survey on learning to hash. <em>TPAMI</em> 40, 4
        (2018), 769–790.</li>
        <li id="BibPLXBIB0050" label="[50]">Meng Wang, Weijie Fu,
        Shijie Hao, Hengchang Liu, and Xindong Wu. 2017. Learning
        on big graph: Label inference and regularization with
        anchor hierarchy. <em>TKDE</em> 29, 5 (2017),
        1101–1114.</li>
        <li id="BibPLXBIB0051" label="[51]">Meng Wang, Weijie Fu,
        Shijie Hao, Dacheng Tao, and Xindong Wu. 2016. Scalable
        semi-supervised learning by efficient anchor graph
        regularization. <em>TKDE</em> 28, 7 (2016), 1864–1877.</li>
        <li id="BibPLXBIB0052" label="[52]">Yair Weiss, Antonio
        Torralba, and Rob Fergus. 2009. Spectral hashing. In
        <em>NIPS</em>. 1753–1760.</li>
        <li id="BibPLXBIB0053" label="[53]">Rongkai Xia, Yan Pan,
        Hanjiang Lai, Cong Liu, and Shuicheng Yan. 2014. Supervised
        hashing for image retrieval via image representation
        learning. In <em>AAAI</em>. 2156–2162.</li>
        <li id="BibPLXBIB0054" label="[54]">Liang Xie, Jialie Shen,
        and Lei Zhu. 2016. Online cross-modal hashing for web image
        retrieval. In <em>AAAI</em>. 294–300.</li>
        <li id="BibPLXBIB0055" label="[55]">Xing Xu, Fumin Shen,
        Yang Yang, Heng&nbsp;Tao Shen, and Xuelong Li. 2017.
        Learning discriminative binary codes for large-scale
        cross-modal retrieval. <em>TIP</em>26, 5 (2017),
        2494–2507.</li>
        <li id="BibPLXBIB0056" label="[56]">Xun Yang, Meng Wang,
        Richang Hong, Qi Tian, and Yong Rui. 2017. Enhancing person
        re-identification in a self-trained subspace. <em>TOMM</em>
        13, 3 (2017), 27:1–27:23.</li>
        <li id="BibPLXBIB0057" label="[57]">Felix Yu, Sanjiv Kumar,
        Yunchao Gong, and Shih-Fu Chang. 2014. Circulant binary
        embedding. In <em>ICML</em>. 946–954.</li>
        <li id="BibPLXBIB0058" label="[58]">Dongqing Zhang and
        Wu-Jun Li. 2014. Large-scale supervised multimodal hashing
        with semantic correlation maximization. In <em>AAAI</em>.
        2177–2183.</li>
        <li id="BibPLXBIB0059" label="[59]">Hanwang Zhang, Fumin
        Shen, Wei Liu, Xiangnan He, Huanbo Luan, and Tat-Seng Chua.
        2016. Discrete collaborative filtering. In <em>SIGIR</em>.
        325–334.</li>
        <li id="BibPLXBIB0060" label="[60]">Peichao Zhang, Wei
        Zhang, Wu-Jun Li, and Minyi Guo. 2014. Supervised hashing
        with latent factor models. In <em>SIGIR</em>. 173–182.</li>
        <li id="BibPLXBIB0061" label="[61]">Ruimao Zhang, Liang
        Lin, Rui Zhang, Wangmeng Zuo, and Lei Zhang. 2015.
        Bit-scalable deep hashing with regularized similarity
        learning for image retrieval and person re-identification.
        <em>TIP</em> 24, 12 (2015), 4766–4779.</li>
        <li id="BibPLXBIB0062" label="[62]">Zhiwei Zhang, Qifan
        Wang, Lingyun Ruan, and Luo Si. 2014. Preference preserving
        hashing for efficient recommendation. In <em>SIGIR</em>.
        183–192.</li>
        <li id="BibPLXBIB0063" label="[63]">Yi Zhen, Piyush Rai,
        Hongyuan Zha, and Lawrence Carin. 2015. Cross-modal
        similarity learning via pairs, preferences, and active
        supervision. In <em>AAAI</em>. 3203–3209.</li>
        <li id="BibPLXBIB0064" label="[64]">Lei Zhu, Zi Huang,
        Xiaobai Liu, Xiangnan He, Jiande Sun, and Xiaofang Zhou.
        2017. Discrete multimodal hashing with canonical views for
        robust mobile landmark search. <em>TMM</em> 19, 9 (2017),
        2066–2079.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>⁎</sup></a>Corresponding
    author.</p>
    <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a>SSDH can choose
    more powerful classifiers and the accuracy can be further
    improved. But the choice of classifiers is not the focus of our
    paper, and we leave the study of other candidate classifiers
    for future pursuit.</p>
    <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a><a class=
    "link-inline force-break" href=
    "http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></p>
    <p id="fn4"><a href="#foot-fn4"><sup>3</sup></a><a class=
    "link-inline force-break" href=
    "http://press.liacs.nl/mirflickr/mirdownload.html">http://press.liacs.nl/mirflickr/mirdownload.html</a></p>
    <p id="fn5"><a href="#foot-fn5"><sup>4</sup></a><a class=
    "link-inline force-break" href=
    "https://www.cs.toronto.edu/">https://www.cs.toronto.edu/&nbsp;kriz/cifar.html</a></p>
    <p id="fn6"><a href="#foot-fn6"><sup>5</sup></a><a class=
    "link-inline force-break" href=
    "https://www.cs.toronto.edu/">https://www.cs.toronto.edu/&nbsp;kriz/cifar.html</a></p>
    <p id="fn7"><a href="#foot-fn7"><sup>6</sup></a><a class=
    "link-inline force-break" href=
    "http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm">http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm</a></p>
    <p id="fn8"><a href="#foot-fn8"><sup>7</sup></a><a class=
    "link-inline force-break" href=
    "http://image-net.org/challenges/LSVRC/2010/">http://image-net.org/challenges/LSVRC/2010/</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3178876.3186072">https://doi.org/10.1145/3178876.3186072</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
