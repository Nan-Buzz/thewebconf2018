<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Crowdsourcing Multi-Objective Recommendation System&#x204E;&#x204E;Produces the permission block, and copyright information</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Crowdsourcing Multi-Objective Recommendation System<a class="fn" href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>      </span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Eiman</span>      <span class="surName">Aldhahri</span>     The University of Memphis, Memphis, Tennessee, <a href="mailto:aldhahri@memphis.edu">aldhahri@memphis.edu</a>     </div>     <div class="author">     <span class="givenName">Vivek</span>      <span class="surName">Shandilya</span>     Jacksonville University, Jacksonville, Florida, <a href="mailto:shandilya@ju.edu">shandilya@ju.edu</a>     </div>     <div class="author">     <span class="givenName">Sajjan</span>      <span class="surName">Shiva</span>     The University of Memphis, Memphis, Tennessee, <a href="mailto:sshivi@memphis.edu">sshivi@memphis.edu</a>     </div>                 </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3191579" target="_blank">https://doi.org/10.1145/3184558.3191579</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 1997</p>    </div>    <div class="abstract">     <p>     <small>Crowdsourcing is an approach whereby employers call for workers online with different capabilities to process a task for monetary reward. With a vast amount of tasks posted every day, satisfying the workers, employers, and service providers who are the stakeholders of any crowdsourcing system is critical to its success. To achieve this, the system should address three objectives: (1) match the worker with suitable tasks that fit the worker&#x0027;s interests and skills and raise the worker&#x0027;s rewards and rating, (2) give the employer more acceptable solutions with lower cost and time and raise the employer&#x0027;s rating, and (3) raise the rate of accepted tasks, which will raise the aggregated commissions to the service provider and improve the average rating of the registered users (employers and workers) accordingly. For these objectives, we present a mechanism design that is capable of reaching holistic satisfaction using a multi-objective recommendation system. In contrast, all previous crowdsourcing recommendation systems are designed to address one stakeholder who could be either the worker or the employer. Moreover, our unique contribution is to consider each stakeholder to be self serving. Considering selfish behavior from every stakeholder, we provide a more qualified recommendation for each stakeholder.</small>     </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>crowdsourcing</small>, </span>     <span class="keyword">      <small> recommendation</small>, </span>     <span class="keyword">      <small> task matching.</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Eiman Aldhahri, Vivek Shandilya, and Sajjan Shiva. 1997. Crowdsourcing Multi-Objective Recommendation System. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>July 1997 (WWW &#x2019;18 Companion),</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 9 Pages. <a href="https://doi.org/10.1145/3184558.3191579" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3191579</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>Crowdsourcing is a process whereby an employer outsources tasks to a large network of crowd workers for monetary reward. The advantage of crowdsourcing lies in the ability of employers to access a large pool of highly skilled workers to process the outsourced tasks in a reduced amount of time and cost compared to in-house workers [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>]. Recently, there has been a significant trend towards crowdsourcing systems, and several major crowdsourcing platforms have emerged, such as ClickWorker, CloudCrowd, UpWork, and the well-known Amazon Mechanical Turk.</p>    <p>Crowdsourcing systems have three stakeholders: a worker, an employer, and a service provider. The employer posts the task to the crowd with a deadline and monetary reward. Workers apply to the tasks that could increase their reward and rating. The service provider&#x0027;s role is to provide a recommendation list that matches workers with tasks accurately in order to maximize the commission for the accepted tasks.</p>    <p>Due to the large number of tasks and workers available on crowdsourcing system, finding an appropriate task (or set of appropriate tasks) and a worker (or set of workers) is a strenuous and time-consuming process [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>]. An appropriate task depends mainly on two factors: interest and skills [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>]. Interest is measured based on multidimensional factors that are weighted differently for each worker: the monetary reward and rating score. Moreover, selecting the most qualified worker is also a challenge even if we consider the worker&#x0027;s rating score. This score could reflect the worker&#x0027;s overall proficiency rather than the specialized rating. The aforementioned task-worker matching is an important factor to eliminate low-quality solutions, which is a major problem in crowdsourcing data management [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>]. Another problem that could affect the stakeholders&#x2019; goal is if a worker works on a large number of tasks at the same time, which could decrease the solution efficiency. As an alternative, part of these tasks could be assigned to less experienced workers who have more time, which could increase the solution efficiency. In another scenario, if we recommend tasks to the most efficient worker, the employer&#x0027;s goal will be satisfied. However, the worker may get busy processing low monetary tasks and miss some high monetary tasks. Therefore, a well-structured recommendation system, which satisfies all stakeholders and addresses the aforementioned difficulties, should be constructed. Such a system would entail workers finding their preferable task, employers getting a more qualified solution, and service providers increasing the accepted task rate to increase their platforms&#x2019; income and popularity.</p>    <p>Crowdsourcing systems have four archetypes based on the platform&#x0027;s main function: Crowd Processing, Crowd Rating, Crowd Solving, and Crowd Creation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>]. Crowd Processing seeks micro-tasks that do not require specific skills such as Amazon Mechanical Turk. Crowd Rating seeks workers&#x2019; perspectives on a given topic, which is what TripAdvisor does. Crowd Solving seeks a task that requires certain skilled workers, where solutions are acquired independently, as with InnoCentive. Crowd Creation seeks defined tasks from workers who have different skills, where the submitted solutions are aggregated to include the overall task solution, as with Wikipedia [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>]. Crowdsourcing systems could also be classified based on the nature of their behavior, which can be competitive or hiring [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>]. In competitive behavior, any worker may process the task without a permission. Then, the prize goes to one or more workers who provide the best solution. In hiring behavior, employers need to grant their permission to the worker before he/she can start processing the task. Then, the hired worker receives the rewards based on its correctness. Moreover, tasks in crowdsourcing systems can be classified as micro-task (e.g., labeling an image), which takes several seconds, and macro-task (e.g., creating of an analytical paper, web design), which takes more time [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>].</p>    <p>In this paper, we consider hiring crowdsourcing with macro-tasks. As the majority of existing crowdsourced research has focused on micro-tasks, we choose to focus on macro-task which is considered an important research topic [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>]. We assume that every stakeholder acts selfishly to maximize profit. Because of this assumption, we present a mechanism design based on a multi-objective recommendation system to reach holistic satisfaction through the following: matching the worker with a suitable task that fits the worker&#x0027;s skills, raising the worker&#x0027;s rewards and rating, giving employers more qualified solutions with lower costs without affecting their rating, and raising the rate of accepted task, which will increase aggregated commissions accordingly.</p>    <p>The main contributions of this paper are</p>    <ol class="list-no-style">     <li id="list1" label="(1)">A model for quantitatively formulating the strategic interaction of the stakeholders (employers, workers, and the crowdsourcing service provider),<br/></li>     <li id="list2" label="(2)">Algorithms to compute the recommendation for both the employers and the workers, and<br/></li>     <li id="list3" label="(3)">A numerical simulation to evaluate the effectiveness of the recommendation.<br/></li>    </ol>    <p>The rest of the paper is organized as follows. Section 2 reviews related work, Section 3 describes the workflow, Section 4 presents the problem formulation, Section 5 describes the proposed recommendation model, Section 6 describes the experiment, and section 7 concludes the paper.</p>   </section>   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> RELATED WORK</h2>     </div>    </header>    <p>We have conducted a detailed survey and critical study of state-of-the-art recommendation systems that are ubiquitous among crowdsourcing and other online systems [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>]. Our research shows that most general recommendation systems [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>] address one stakeholder. The main contribution of these studies was enhancing the collaborative filtering approach by utilizing different techniques, such as user-item subgroups [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>], expert opinions [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>], social media sentiment [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>], and k-mean clustering [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>]. The other main contribution was using revolutionary algorithms, such as a genetic algorithm [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>].</p>    <p>Similarly, all crowdsourcing recommendation papers reviewed have addressed one stakeholder, either the worker [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>] or the employer [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>]. An important paper was by Yuen et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>], where the system recommends tasks on Amazon Mechanical Turk (Mturk) using a matrix factorization by extracting a worker&#x0027;s preferred tasks from both a worker&#x0027;s performance history and task search history. The other major contribution was by Lin et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>], who proposed a system that incorporates negative implicit feedback based on task availability. Yuen et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>] have considered dynamic scenarios to solve the cold start problem, which consists of new user and new item recommendation. Difallah et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>] have proposed different task recommendation approaches for crowdsourcing based on push methodology instead of the currently used pull methodology. The idea is to use the social media website Facebook to gather users&#x2019; skills and interests from the pages they liked and the tasks they completed. Then, tasks are posted on the related worker&#x0027;s page.</p>    <p>To the best of our knowledge, no prior literature has considered satisfying the goal of all three stakeholders. Moreover, none has considered the other party&#x0027;s behavior to provide more qualified recommendations. Designing such a recommendation system would be a great opportunity for effective crowdsourcing as we have suggested in this study.</p>   </section>   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> workflow</h2>     </div>    </header>    <p>In this section, we provide an overview of the work flow as an interaction scenario for the stakeholders of the crowdsourcing platform.</p>    <ul class="list-no-style">     <li id="list4" label="&#x2022;">Employers <em>e</em>     <sub>1</sub>, <em>e</em>     <sub>2</sub>, <em>e</em>     <sub>3</sub>, ... register as members.<br/></li>     <li id="list5" label="&#x2022;">Workers <em>w</em>     <sub>1</sub>, <em>w</em>     <sub>2</sub>, <em>w</em>     <sub>3</sub>, ... register as members.<br/></li>     <li id="list6" label="&#x2022;"><em>e<sub>h</sub>     </em> posts tasks <em>a<sub>j</sub>     </em>, <em>a</em>     <sub>      <em>j</em> + 1</sub>, .. : <em>h</em>, <em>j</em> = 0, 1, 2, .. at time <em>t</em>     <sub>1</sub>, <em>t</em>     <sub>2</sub>, <em>t</em>     <sub>3</sub>, ...<br/></li>     <li id="list7" label="&#x2022;">For each task, employers may specify:<br/>     <ol class="list-no-style">      <li id="list8" label="(1)">The required skills,<br/></li>      <li id="list9" label="(2)">Monetary rewards, and<br/></li>      <li id="list10" label="(3)">Time deadline.<br/></li>     </ol></li>     <li id="list11" label="&#x2022;">Workers <em>w<sub>i</sub>     </em>, <em>w</em>     <sub>      <em>i</em> + 1</sub>, <em>w</em>     <sub>      <em>i</em> + 2</sub> are qualified for the task <em>a<sub>j</sub>     </em>.<br/></li>     <li id="list12" label="&#x2022;">At time <em>t</em>     <sub>1</sub>, <em>t</em>     <sub>2</sub>, <em>t</em>     <sub>3</sub>, <em>t</em>     <sub>4</sub>, workers <em>w<sub>i</sub>     </em>, <em>w</em>     <sub>      <em>i</em> + 2</sub> apply for the task <em>a<sub>j</sub>     </em> as long as <em>t</em>     <sub>      <em>j</em> + <em>n</em>     </sub> > <em>t<sub>l</sub>     </em> : <em>l</em> = 1, 2, 3, 4. <em>t</em>     <sub>      <em>j</em> + <em>n</em>     </sub> is the threshold time when the <em>e<sub>h</sub>     </em> must respond to the workers who accepted the task with a decision of hired / not hired.<br/></li>     <li id="list13" label="&#x2022;">Employer <em>e<sub>h</sub>     </em> removes the task <em>a<sub>j</sub>     </em> from the available tasks after two conditions are met: 1) the task was allotted to the number of required workers, and 2) the employer accepted the task from one or more workers.<br/></li>     <li id="list14" label="&#x2022;">Workers <em>w<sub>i</sub>     </em>, <em>w</em>     <sub>      <em>i</em> + 2</sub> completed and submitted their work for the task <em>a<sub>j</sub>     </em>.<br/></li>     <li id="list15" label="&#x2022;">Employer <em>e<sub>h</sub>     </em> accepted the work for the task <em>a<sub>j</sub>     </em> from one or more workers, who submitted their work, and paid the associated rewards.<br/></li>     <li id="list16" label="&#x2022;">In <em>t<sub>l</sub>     </em> seconds, the service provider <em>S</em> made <em>      <em>C<sub>l</sub>      </em>     </em> dollars as a commission for the task <em>a<sub>j</sub>     </em>.<a class="fn" href="#fn3" id="foot-fn3"><sup>1</sup></a>     <br/></li>     <li id="list17" label="&#x2022;">Consider another case for task <span class="inline-equation"><span class="tex">$a_{j_1}$</span>     </span>      <em>a<sub>j</sub>     </em>, which finally gives <em>C</em>     <sub>2</sub> in <em>t</em>     <sub>2</sub> seconds.<a class="fn" href="#fn4" id="foot-fn4"><sup>2</sup></a>     <br/></li>     <li id="list18" label="&#x2022;">In a given duration of time <em>T</em>, maximize &#x2211;<em>C</em>     <sub>1</sub> + .. + <em>C<sub>n</sub>     </em>.<br/></li>     <li id="list19" label="&#x2022;">The probability that the task is completed and the employer accepted the task is <em>P</em>     <sub>1</sub>.<br/></li>     <li id="list20" label="&#x2022;">The probability that <em>S</em> will get the commission <em>C</em>     <sub>1</sub> is <em>P</em>     <sub>1</sub>.<br/></li>    </ul>    <p>The recommendation system should order the task&#x0027;s recommendation list to the workers such that the expected cumulative commission is maximized, which means</p>    <p>     <span class="inline-equation"><span class="tex">$ \sum {{P_1}^1 C_1 + {P_1}^2 C_2 +...+ {P_1}^n C_n}$</span>     </span> is maximized.</p>   </section>   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> PROBLEM FORMULATION</h2>     </div>    </header>    <p>The actual system that solves this problem should consider <em>k</em> employers posting <em>n</em> tasks to <em>m</em> workers to maximize the commission. This is not mainly about the money but rather a complex and definitive matrix of overall platform success. In other words, maximizing the commissions means maximizing the rate of accepted tasks, which is a consequence of satisfying the employers by giving them a qualified solution and satisfying workers by giving them the associated rewards. Below, we identify the exact role for each stakeholder in the crowdsource platform.</p>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Worker</h3>     </div>     </header>     <ul class="list-no-style">     <li id="list21" label="&#x2022;">Lists skills on the profile<br/></li>     <li id="list22" label="&#x2022;">&#x27E8;<em>Decision</em>&#x27E9; applies for <em>n</em>      <sub>1</sub>      <sub>1</sub> out of <em>n</em>      <sub>1</sub> tasks that fits the profile.<br/></li>     <li id="list23" label="&#x2022;">&#x27E8;<em>Decision</em>&#x27E9; completes <span class="inline-equation"><span class="tex">$ {{n_1}^`}_1$</span>      </span> out of <em>n</em>      <sub>1</sub>      <sub>1</sub>.<br/></li>     <li id="list24" label="&#x2022;"><span class="inline-equation"><span class="tex">$ {{n_1}^`}_1$</span>      </span> <<em>n</em>      <sub>1</sub>      <sub>1</sub> <<em>n</em>      <sub>1</sub> <<em>n</em>.<br/></li>     </ul>    </section>    <section id="sec-9">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Employer</h3>     </div>     </header>     <ul class="list-no-style">     <li id="list25" label="&#x2022;">Posts the task.<br/></li>     <li id="list26" label="&#x2022;">&#x27E8;<em>Decision</em>&#x27E9; allots the task to the best <em>m</em>      <sub>1</sub>      <sub>1</sub> workers out of <em>m</em>      <sub>1</sub> who applied for the task.<br/></li>     <li id="list27" label="&#x2022;">&#x27E8;<em>Decision</em>&#x27E9; pays the <span class="inline-equation"><span class="tex">$ {{{m_1}^`}_1}^`$</span>      </span> workers out of <span class="inline-equation"><span class="tex">$ {{m_1}^`}_1$</span>      </span> who submitted the solution to the task.<br/></li>     <li id="list28" label="&#x2022;"><span class="inline-equation"><span class="tex">$ {{{m_1}^`}_1}^`$</span>      </span> <<span class="inline-equation"><span class="tex">$ {{m_1}^`}_1$</span>      </span> <<em>m</em>      <sub>1</sub>      <sub>1</sub> <<em>m</em>      <sub>1</sub> <<em>m</em>.<br/></li>     </ul>    </section>    <section id="sec-10">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Service Provider</h3>     </div>     </header>     <ul class="list-no-style">     <li id="list29" label="&#x2022;">Orders the recommended tasks for the workers.<br/></li>     <li id="list30" label="&#x2022;">Sorts <em>n</em>      <sub>1</sub> tasks in the order that leads to maximize &#x2211;<em>c</em>      <sub>1</sub>.<br/>The ordering of <em>n</em>      <sub>1</sub> is a list that looks like this:<br/>      <span class="inline-equation"><span class="tex">$ j_{1_0}, j_{1_1}, j_{1_2}, j_{1_3},&#x0026;#8230;.,j_{1_{n_1}}.$</span>      </span>      <br/>The worker accepts tasks with probability<br/>      <span class="inline-equation"><span class="tex">$P(j_{1_0}), P(j_{1_1}), P(j_{1_2}),&#x0026;#8230;.,P(j_{1_{n_1}})$</span>      </span>      <br/>Where <span class="inline-equation"><span class="tex">$ P(j_{1_y}) \ge P(j_{1_(y+z)})$</span>      </span>      <br/>Where <em>z</em> > 0, <em>Z</em> &#x2208; <em>I</em>      <br/></li>     </ul>    </section>   </section>   <section id="sec-11">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> THE RECOMMENDATION MODEL</h2>     </div>    </header>    <p>This section describes the proposed model (Fig. <a class="fig" href="#fig1">1</a>). It is a multi-objective problem for both workers and employers. The worker&#x0027;s goal is to work on the tasks that maximize the reward and rating during a specified time. The employer&#x0027;s goal is to have more qualified solutions, pay less, and decrease the negative rating. In other words, if the employer hires a large number of workers for a task, the probability of getting more qualified solutions will increase. However, the employer in this case will have two choices. First, the employer could pay for all the workers who submitted qualified solutions, which will increase the cost. Second, the employer could pay for a subset of the workers who submitted qualified solutions, which will decrease the employer&#x0027;s rating from unsatisfied worker reviews.</p>    <p>The proposed model recommends the optimal choices for each worker and employer. Accordingly, the rate of accepted tasks will be maximized and the service provider&#x0027;s goal will be achieved.</p>    <p>There are two cases in the proposed model: Case-0, where workers can work only on one task at a time, and Case-1, where workers can work on multiple tasks at a time. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191579/images/www18companion-318-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Recommendation Model</span>     </div>     </figure>    </p>    <section id="sec-12">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.1</span> Worker&#x0027;s Objective</h3>     </div>     </header>     <p>This section describes the worker objective in detail.</p>     <p>For each worker <em>w<sub>i</sub>     </em>,</p>     <p>Step 1: Find the set of tasks that fits his or her interests</p>     <p>For each task <em>a<sub>j</sub>     </em> there are required skills <em>Sk</em>[<em>a<sub>j</sub>     </em>]={<em>sk</em>     <sub>1</sub>, <em>sk</em>     <sub>2</sub>, ..}, and each worker has a set of skills <em>Sk</em>[<em>w<sub>i</sub>     </em>] = {<em>sk</em>     <sub>1</sub>, <em>sk</em>     <sub>2</sub>, ..}. If <em>Sk</em>[<em>a<sub>j</sub>     </em>]&#x2282;<em>Sk</em>[<em>w<sub>i</sub>     </em>], then <em>a<sub>j</sub>     </em> &#x2208; <em>Tasks</em>[<em>w<sub>i</sub>     </em>] where <em>Tasks</em>[<em>w<sub>i</sub>     </em>] is the set that contains all the tasks that fit the worker&#x0027;s interests.</p>     <p>Step 2: Calculate the expected monetary rewards for each task in the list <em>Tasks</em>[<em>W<sub>i</sub>     </em>] using Algorithm 1 . Considering the history, with weighted consideration of the future expectations, we apply the Discount Factor equation Eq.(16).</p>     <p>Step 3: Calculate the expected rating for each task in the list <em>Tasks</em>[<em>w<sub>i</sub>     </em>] using Algorithm 2 .</p>     <p>Step 4: Calculate each task&#x0027;s type weight using Algorithm 3 .</p>     <p>Step 5: Recommend tasks to the worker that will maximize the rewards and rating using Algorithm 4 .</p>     <section id="sec-13">     <p><em>5.1.1 Expected Payment (ExP).</em> Each task <em>a<sub>j</sub>      </em> has a specified monetary reward, deadline, and required skills. The payment is not guaranteed unless the employer approves the work. Usually if the submitted work meets all the required specifications, the employer will approve the worker payment. However, there is no obligation for payment if the employer refuses to pay. Therefore, the employer&#x0027;s rating is an important factor to reflect the employer&#x0027;s trustworthiness.</p>     <p>From the worker&#x0027;s history, we can get an expectation of how likely the worker will be paid for each type of task in the set <em>Tasks</em>[<em>w<sub>i</sub>      </em>]. Moreover, based on the employer history, we can estimate how likely each employer will pay the worker.</p>     <p>Calculating the expected payment consists of two steps.</p>     <p>First, from the worker history, calculate the proficiency level of the worker in each skill or type of task using the following equations:</p>     <p>      <em>Q<sub>j</sub>      </em> is the probability that worker <em>w<sub>i</sub>      </em> will complete tasks from type <em>j</em>      <div class="table-responsive" id="eq1">       <div class="display-equation">        <span class="tex mytex">\begin{equation} Q_j = \frac{\sum {S[tasks_j]}}{\sum {H[tasks_j]}} \end{equation} </span>        <br/>        <span class="equation-number">(1)</span>       </div>      </div> where for each worker, <em>S</em>[<em>tasks<sub>j</sub>      </em>] is the submitted or completed tasks from type <em>j</em>, <em>H</em>[<em>tasks<sub>j</sub>      </em>] are the tasks that the worker was hired to process from type <em>j</em>.</p>     <p>      <em>Q<sub>j</sub>      </em>      <sub>1</sub> is the probability that worker <em>w<sub>i</sub>      </em> will be paid for tasks from type <em>j</em>      <div class="table-responsive" id="eq2">       <div class="display-equation">        <span class="tex mytex">\begin{equation} {Q_j}_1 = \frac{\sum {Paid[tasks_j]}}{\sum {S[tasks_j]}} \end{equation} </span>        <br/>        <span class="equation-number">(2)</span>       </div>      </div> where <em>Paid</em>[<em>tasks<sub>j</sub>      </em>] is the accepted tasks from type <em>j</em>.</p>     <p>The worker proficiency level in type <em>j</em> tasks is <div class="table-responsive" id="eq3">       <div class="display-equation">        <span class="tex mytex">\begin{equation} Prof^j = Q_j * {Q_j}_1 \end{equation} </span>        <br/>        <span class="equation-number">(3)</span>       </div>      </div>     </p>     <p>Second, calculate the degree of employer trustworthiness, considering the worker&#x0027;s rating as a substantial factor to get more accurate results. For instance, a review from a five-star worker has more impact than a review from a two-star worker because the more highly rated worker is more trustworthy.</p>     <p>From the employer history:</p>     <p>      <em>Q<sub>h</sub>      </em> is the probability that the employer <em>e<sub>h</sub>      </em> will pay the workers who submitted the solutions considering worker ratings <em>R</em>[<em>w<sub>i</sub>      </em>] as a weight factor <div class="table-responsive" id="eq4">       <div class="display-equation">        <span class="tex mytex">\begin{equation} Q_h = \frac{\sum {Paid[w_i] * R[w_i]}}{\sum {S[w_i]} * R[w_i]} \end{equation} </span>        <br/>        <span class="equation-number">(4)</span>       </div>      </div> where for each task, <em>Paid</em>[<em>w<sub>i</sub>      </em>] is the number of workers who got paid, and <em>S</em>[<em>w<sub>i</sub>      </em>] is the number of workers who submitted the task.</p>     <p>Then from Equations <a class="eqn" href="#eq3">3</a> and <a class="eqn" href="#eq4">4</a>, we can calculate the expected payment for each task in the worker&#x0027;s task list by the following equation: <div class="table-responsive" id="eq5">       <div class="display-equation">        <span class="tex mytex">\begin{equation} ExP[a_j] = Prof^j * Q_h * Reward[a_j] \end{equation} </span>        <br/>        <span class="equation-number">(5)</span>       </div>      </div> where <em>Reward</em>[<em>a<sub>j</sub>      </em>] is the monetary reward for task <em>a<sub>j</sub>      </em>, and <em>Prof<sup>i</sup>      </em> is the proficiency level of the worker in type <em>j</em> tasks.</p>     <p>Maximize <span class="inline-equation"><span class="tex">$ExP(W_i)= \displaystyle \sum _{i=1}^{y} {ExP[a_j]}$</span>      </span>     </p>     <p>where <em>y</em> is the number of tasks in the <em>Tasks</em>[<em>w<sub>i</sub>      </em>] set.</p>     <p>      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191579/images/www18companion-318-img1.svg" class="img-responsive" alt=""       longdesc=""/>     </p>     </section>     <section id="sec-14">     <p><em>5.1.2 Expected Rating (ExR).</em> The rating system in crowdsourcing allows employers and workers to rate each other. Rating is a substantial factor, so it is important to optimize the rating score. From the employer&#x0027;s perspective, workers&#x2019; ratings could help decide which worker should be hired. From the worker&#x0027;s perspective, ratings could help decide which tasks to apply for. As we have described in the employer rating Equation <a class="eqn" href="#eq4">4</a>, the evaluator rating is considered to aggregate the overall rating score. To justify the evaluator rating factor needs, consider the following example. Because the rating system is mutual, as explained above, a dishonest employer could give workers a bad rating to decrease their overall rating. This lowered rating would result in workers&#x2019; evaluations not having much effect on the employer&#x0027;s rating in Equation <a class="eqn" href="#eq4">4</a>. However, if we consider the employer&#x0027;s rating in evaluating the workers&#x2019; ratings, the rating score could be more trustworthy. <div class="table-responsive" id="eq6">       <div class="display-equation">        <span class="tex mytex">\begin{equation} ExR[j] = \frac{\sum _{x=1}^{n}{R[a_x] * R[e_h]}}{\sum _{x=1}^{n} R[e_h]} \end{equation} </span>        <br/>        <span class="equation-number">(6)</span>       </div>      </div>     </p>     <p>Where <em>ExR</em>[<em>j</em>] is the expected rating for type <em>j</em> tasks, <em>n</em> is the total number of type <em>j</em> tasks that the worker has submitted before, <em>R</em>[<em>a<sub>x</sub>      </em>] is the rating score for task <em>x</em>, and <em>R</em>[<em>e<sub>h</sub>      </em>] is the employer <em>e<sub>h</sub>      </em> rating.</p>     <p>      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191579/images/www18companion-318-img2.svg" class="img-responsive" alt=""       longdesc=""/>     </p>     </section>     <section id="sec-15">     <p><em>5.1.3 Skill Based Workload.</em> From the workers&#x2019; history, we can calculate how many tasks each worker can handle successfully at the same time, i.e., the worker&#x0027;s appropriate workload based on the task type. For example, worker <em>w<sub>i</sub>      </em> could work successfully on an average of three tasks simultaneously when working on programming tasks, two when working on design tasks, and so on for each type of task.</p>     <p>For each worker, calculate the appropriate workload for each task&#x0027;s type <em>j</em>.</p>     <p>For each worker, if <em>k</em>      <sub>1</sub> tasks were being done together during a given instance <em>s<sub>i</sub>      </em>, in which the given task type was present, find the average of the total number of tasks as follows: <div class="table-responsive" id="eq7">       <div class="display-equation">        <span class="tex mytex">\begin{equation} L[j] = \frac{\sum _{i=1}^{S}{Paid[a_j]}}{S} \end{equation} </span>        <br/>        <span class="equation-number">(7)</span>       </div>      </div> where <em>L</em>[<em>j</em>] is the worker <em>w<sub>i</sub>      </em> workload for task type <em>j</em>, <em>S</em> is the total number of instances, and <em>Paid</em>[<em>a<sub>j</sub>      </em>] is the number of the accepted tasks during an instance <em>s<sub>i</sub>      </em>, considering only the instances in which the given task type was present.</p>     <p>By applying Eq.(7) each worker <em>w<sub>i</sub>      </em> will have a different workload for each task type. Each workload will be converted to a weight score by the following equation: <div class="table-responsive" id="eq8">       <div class="display-equation">        <span class="tex mytex">\begin{equation} Tw[j] = \frac{1}{L[j]} \end{equation} </span>        <br/>        <span class="equation-number">(8)</span>       </div>      </div>     </p>     <p>where <em>Tw</em>[<em>j</em>] is the worker&#x0027;s <em>w<sub>i</sub>      </em> weight score for task type <em>j</em>.</p>     <p>For example, if the workload of worker <em>w<sub>i</sub>      </em> for a programming task is 3, that means he or she could work efficiently on two additional tasks, and the weight score for the programming tasks will be equal to 0.33.</p>     <p>      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191579/images/www18companion-318-img3.svg" class="img-responsive" alt=""       longdesc=""/>     </p>     </section>     <section id="sec-16">     <p><em>5.1.4 Worker Recommendation Task.</em> The worker utility function is <em>Maximize</em>[<em>reward</em>, <em>rating</em>]</p>     <p>It is a multi-objective optimization problem (MOP) with two objectives: reward and rating. In the literature, researchers have studied MOPs from different points of view, so different solution philosophies and goals exist. There are three main classes for preference MOP, where preference information is needed to solve the problem. These classes are <em>a priori</em>,<em>a posteriori</em>, and interactive, where a preference information is involved from the decision maker (DM) in different ways. In the <em>a priori</em> method, the DM will first determine the preference information, and then the solution will be found. In the <em>a posteriori</em> method, the solutions will be found first, and then the DM will choose from among them. In the interactive method, the DM&#x0027;s preference information will be specified during computation.</p>     <p>To optimize the worker&#x0027;s objectives, the <em>a priori</em> method is used in this paper. Workers will specify their preference rating score first, which will be used as a constraint value to solve for maximizing the reward&#x0027;s value.</p>     <p>New workers could be more interested in building a robust history and set the rating constraint value to four or five stars in order to increase their future chances to compete with senior workers, who have a high rating score. However, each worker could set the rating constraint based on interest, <div class="table-responsive" id="eq9">       <div class="display-equation">        <span class="tex mytex">\begin{equation} Maximize f(x) = \sum _{j=1}^{n}{Reward[a_j]} \end{equation} </span>        <br/>        <span class="equation-number">(9)</span>       </div>      </div>     </p>     <p>Subject to <em>R</em>[<em>a<sub>j</sub>      </em>] &#x2265; <em>R</em>     </p>     <p>where <em>R</em> is a rating constraint value set by the worker.</p>     <p>There are two cases in the proposed model:</p>     <p>Case-0: Only one task at a time. It can be solved by sorting the tasks based on the expected payment considering the expected rating as a constraint value.</p>     <p>Case-1: Multiple tasks at the same time. If the worker wants to work on a set of tasks to maximize his/her objectives during a specified time, dynamic programming is used to solve the problem. It becomes a knapsack problem where we try to maximize the value within the time limit considering the weight score for each task from Algorithm 4, where the total weight score should be equal to or less than 1. The following is an illustrated example:</p>     <p>If the worker has the tasks set as in Table 1, by applying the <em>Tw</em> Algorithm 4, the tasks demonstration during the time period is shown in Figure <a class="fig" href="#fig2">2</a>.</p>     <div class="table-responsive" id="tab1">      <div class="table-caption">       <span class="table-number">Table 1:</span>       <span class="table-title">Task List</span>      </div>      <table class="table">       <tbody>        <tr>        <td style="text-align:left;">Task</td>        <td style="text-align:left;">Type</td>        <td style="text-align:left;">Deadline</td>        <td style="text-align:left;">         <em>Tw<sub>i</sub>         </em>        </td>        <td style="text-align:left;">ExP</td>        </tr>        <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">Programming</td>        <td style="text-align:left;">30</td>        <td style="text-align:left;">0.33</td>        <td style="text-align:left;">300</td>        </tr>        <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">Programming</td>        <td style="text-align:left;">90</td>        <td style="text-align:left;">0.33</td>        <td style="text-align:left;">600</td>        </tr>        <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">Web design</td>        <td style="text-align:left;">120</td>        <td style="text-align:left;">0.5</td>        <td style="text-align:left;">500</td>        </tr>        <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">Web design</td>        <td style="text-align:left;">60</td>        <td style="text-align:left;">0.5</td>        <td style="text-align:left;">400</td>        </tr>        <tr>        <td style="text-align:left;">5</td>        <td style="text-align:left;">Programming</td>        <td style="text-align:left;">30</td>        <td style="text-align:left;">0.33</td>        <td style="text-align:left;">250</td>        </tr>        <tr>        <td style="text-align:left;">6</td>        <td style="text-align:left;">Web design</td>        <td style="text-align:left;">90</td>        <td style="text-align:left;">0.5</td>        <td style="text-align:left;">300</td>        </tr>       </tbody>      </table>     </div>     <figure id="fig2">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191579/images/www18companion-318-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Task list</span>      </div>     </figure>     <p>The Worker Recommendation Task Algorithm uses dynamic programing for the knapsack problem [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0017">17</a>], where <em>KnapSack</em>(<em>ExP</em>, <em>Tw</em>, <em>n</em>, <em>T</em>) = recommended task set, <em>ExP</em> is the item value, <em>Tw</em> is the weight value, <em>n</em> is the number of items, and <em>T</em> is the total weight.</p>     <p>      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191579/images/www18companion-318-img4.svg" class="img-responsive" alt=""       longdesc=""/>     </p>     </section>    </section>    <section id="sec-17">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.2</span> Employer&#x0027;s Objectives</h3>     </div>     </header>     <p>The employer&#x0027;s basic objective is to obtain more qualified solutions for the payment expended and rating awarded. Hiring more workers could increase the chance of receiving a better solution. Consequently, the two main objectives, which are cost and rating, will have a negative effect as described in Section 1.</p>     <p>The employer&#x0027;s objectives could be optimized by choosing fewer qualified workers. By doing so, we will decrease the number of unsatisfied (due to not being compensated as per their expectation) workers, which could cause negative ratings and decrease the rewards.</p>     <p>Another important factor is the worker&#x0027;s current workload. Some workers may apply for a large number of tasks and then choose a subset of these tasks to process. Some other workers may choose to work on a large number of tasks, which could decrease the quality of the task solution.</p>     <p>To address the employer&#x0027;s objectives, we will tackle the aforementioned factors as follows.</p>     <p>First, for each task <em>a<sub>j</sub>     </em> posted by employer <em>e<sub>h</sub>     </em>, <em>k</em> workers will apply. Each worker <em>w<sub>i</sub>     </em> will have a proficiency level for this kind of task from Equation <a class="eqn" href="#eq3">3</a>. Moreover, each worker will have a rating score based on employer evaluations. Then, for each worker, we calculate the potential success (PS) by</p>     <p>     <em>PS</em> = <em>Prof<sup>i</sup>     </em>*<em>R</em>[<em>w<sub>i</sub>     </em>]</p>     <p>Let <em>x</em> be the number of workers for task <em>a<sub>j</sub>     </em>. The expected expenditure for task <em>a<sub>j</sub>     </em> is <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} F(x) = Minimize_x[Maximize\displaystyle \sum _{i=1}^{k}{Prof^i * R[w_i]}(Reward[a_j])] \end{equation} </span>       <br/>       <span class="equation-number">(10)</span>      </div>     </div>     </p>     <p>The employer objective function will be</p>     <p>     <em>Maximize</em> [<em>workdone</em> &#x2212; <em>payment</em> &#x2212; <em>negativerating</em>]</p>     <p>Second, from the workers&#x2019; current processing tasks, we can get the current worker&#x0027;s workload based on each task&#x0027;s weight score in Section 5.1.3.</p>     <p>If the worker&#x0027;s <em>w<sub>i</sub>     </em> current workload (CW) is 0.75, that indicates the worker could still work efficiently on more tasks. However, if the CW of another worker <em>w<sub>j</sub>     </em> is 0.0, it indicates worker <em>w<sub>j</sub>     </em> could process the task better because that worker has more time than <em>w<sub>i</sub>     </em> considering an equivalent or comparable PS score for both workers.</p>     <p>Finally, to optimize the employer&#x0027;s objectives, the service provider needs to recommend workers with a higher PS score and a lower CW. To solve this MOP, the interactive method is used as follows:</p>     <ol class="list-no-style">     <li id="list31" label="(1)">Employer <em>e<sub>h</sub>      </em> sets the number of required workers.<br/></li>     <li id="list32" label="(2)">The service provider finds all the non-dominated solutions as described in the Worker Recommendation List Algorithm.<br/></li>     <li id="list33" label="(3)">Based on this list, the employer <em>e<sub>h</sub>      </em> resets the number of required workers.<br/></li>     </ol>     <p>The service provider will recommend the employer to choose at least two qualified workers and some new workers who are willing to build a history. Hiring new workers could increase the chance of getting better solutions in terms of increasing the number of workers, but it does not have much negative effect on the employer&#x0027;s rating because the new workers do not have a sufficient rating score. Employers will set their own parameters to optimize their objectives based on the applicants&#x2019; PS and CW. If there are two 0.9 applicant workers, the employer could set the number of required workers to two plus some new workers to help them in building a history. However, if the applied worker has a lower PS and higher CW, the employer could increase the number of required workers. The mutual rating system could help minimize employing unnecessarily large numbers of workers and wasting their time processing a task with a low chance of acceptance.</p>     <p>     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191579/images/www18companion-318-img5.svg" class="img-responsive" alt=""       longdesc=""/>     </p>    </section>    <section id="sec-18">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.3</span> Service Provider&#x0027;s Objective</h3>     </div>     </header>     <p>The service provider&#x0027;s objective is to maximize the aggregated commission by listing recommended tasks to the workers and the recommended workers to the employers.</p>     <p>     <em>S<sub>h</sub>     </em> : Probability that worker <em>w<sub>i</sub>     </em> will apply for task <em>a<sub>j</sub>     </em>.</p>     <p>     <span class="inline-equation"><span class="tex">${S_{h_1}}$</span>     </span>: Probability that worker <em>w<sub>i</sub>     </em> will get the task <em>a<sub>j</sub>     </em>.</p>     <p>     <span class="inline-equation"><span class="tex">${S^`}_{h_1}$</span>     </span>: Probability that worker <em>w<sub>i</sub>     </em> will complete task <em>a<sub>j</sub>     </em>.</p>     <p>     <span class="inline-equation"><span class="tex">$S_{h_1}^{`^`}$</span>     </span>: Probability that worker <em>w<sub>i</sub>     </em> will get paid for task <em>a<sub>j</sub>     </em>.</p>     <p>     <span class="inline-equation"><span class="tex">$ Maximize Task (a_j)= \displaystyle \sum _{i=1}^{y}{ S_h S_{h_1} {S^`}_{h_1} S_{h_1}^{`^`} (C) }$</span>     </span>     </p>     <p>where <em>C</em> = the commission aggregated for task <em>a<sub>j</sub>     </em>.</p>     <p>The service provider utility function is</p>     <p>     <em>Maximize [commission - negative employ rating - negative worker rating]</em>     </p>    </section>    <section id="sec-19">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.4</span> Discount Factor</h3>     </div>     </header>     <p>We get the value of <em>n</em>&#x2013; the depth of history we are going to consider &#x2013; from the demography in the system. We consider the history of similar tasks until the effect of that state becomes less than &#x03F5; in terms of probability. In other words, the effect of that state is no more than random on the present state. If most workers completed three tasks one after another, we would get <em>n</em> = 3, which means we are going to consider three history records.</p>     <p>Once we have the <em>n</em>, we can calculate the discount factor <em>&#x03B2;</em>. The discount factor is needed because we are considering that what happened in the recent past is more influential on the worker&#x0027;s future attitudes. <div class="table-responsive" id="eq10">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \beta + \frac{\beta }{2} + \frac{\beta }{3} +...+ \frac{\beta }{n} \end{equation} </span>       <br/>       <span class="equation-number">(11)</span>      </div>     </div> From Equation <a class="eqn" href="#eq10">11</a>, we can get the value of <em>&#x03B2;</em>, <div class="table-responsive" id="eq11">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \beta = \frac{1}{1+ {\frac{1}{2}} + {\frac{1}{3}} +.. {\frac{1}{n}} } \end{equation} </span>       <br/>       <span class="equation-number">(12)</span>      </div>     </div>     </p>     <p>We are looking for the probability of worker <em>w<sub>i</sub>     </em> getting payed for job <em>j<sub>i</sub>     </em> now. <div class="table-responsive" id="eq12">      <div class="display-equation">       <span class="tex mytex">\begin{equation} P(\epsilon (j_{i-1})= \beta _0 * P(\epsilon (j_{i}) + \beta _1 * P(\epsilon (j_{i_1}) +.. \beta _n * P(\epsilon (j_{i-n}) \end{equation} </span>       <br/>       <span class="equation-number">(13)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$\displaystyle \sum _{k=1}^{n} \beta _k = 1$</span>     </span>      <div class="table-responsive" id="eq13">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \displaystyle \sum _{k=1}^{n} \beta _k P(\epsilon (j_{i-K+1}) \end{equation} </span>       <br/>       <span class="equation-number">(14)</span>      </div>     </div> where<span class="inline-equation"><span class="tex">$ \displaystyle \sum _{k=1}^{n} \beta _k = 1$</span>     </span>     </p>    </section>   </section>   <section id="sec-20">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Empirical Evaluation</h2>     </div>    </header>    <p>This section describes an experiment that simulates the crowdsourcing paradigm. Our experiment is designed to address three questions:</p>    <ol class="list-no-style">     <li id="list34" label="(1)">How does the proposed method compare with baseline and state-of-the-art approaches?<br/></li>     <li id="list35" label="(2)">What is the computational complexity of the proposed recommendation model?<br/></li>     <li id="list36" label="(3)">How scalable is the proposed model?<br/></li>    </ol>    <p>To demonstrate the superiority of our proposed model, we chose two models as a baseline for the comparison: the traditional model and the most recently published model.</p>    <section id="sec-21">     <header>     <div class="title-info">      <h3>       <span class="section-number">6.1</span> Baseline Model</h3>     </div>     </header>     <p>The traditional model uses a greedy algorithm to recommend the highest reward tasks that match workers&#x2019; skills. The most recent recommendation system in crowdsourcing relies on matrix factorization based on worker performance history and worker task search history [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>].</p>    </section>    <section id="sec-22">     <header>     <div class="title-info">      <h3>       <span class="section-number">6.2</span> Dataset</h3>     </div>     </header>     <p>The data needed to evaluate our proposed model requires the complete worker history and employer history. To the best of our knowledge, such data is only accessible by the crowdsourcing administrators and is not publicly available.</p>     <p>We evaluated our model with synthesized datasets. To make the datasets realistic and unbiased, we generated them from two distributions, binomial and uniform, with different scales. Table 2 shows the characteristics of the synthesized datasets. Binomial distributions were chosen because each submitted task has only two possibilities, accept or reject. The rating value was generated using discrete uniform distribution, yielding integers only. The datasets generated are implemented using numpy.random sampling module in Python [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>]. With this module, the generated data can be customized randomly from any distribution with specified parameters. Experiments were conducted on a standard desktop PC (Quadcore Intel i7 CPU@3.5 GHz).</p>     <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Characteristics of Datasets</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:left;">Dataset</td>        <td style="text-align:left;">Dist.</td>        <td style="text-align:left;">Task</td>        <td style="text-align:left;">Category</td>        <td style="text-align:left;">Worker</td>        <td style="text-align:left;">Employer</td>       </tr>       <tr>        <td style="text-align:left;">D1</td>        <td style="text-align:left;">binomial</td>        <td style="text-align:left;">1000</td>        <td style="text-align:left;">5</td>        <td style="text-align:left;">50</td>        <td style="text-align:left;">50</td>       </tr>       <tr>        <td style="text-align:left;">D2</td>        <td style="text-align:left;">binomial</td>        <td style="text-align:left;">5000</td>        <td style="text-align:left;">10</td>        <td style="text-align:left;">100</td>        <td style="text-align:left;">100</td>       </tr>       <tr>        <td style="text-align:left;">D3</td>        <td style="text-align:left;">uniform</td>        <td style="text-align:left;">1000</td>        <td style="text-align:left;">5</td>        <td style="text-align:left;">50</td>        <td style="text-align:left;">50</td>       </tr>       <tr>        <td style="text-align:left;">D4</td>        <td style="text-align:left;">uniform</td>        <td style="text-align:left;">5000</td>        <td style="text-align:left;">10</td>        <td style="text-align:left;">100</td>        <td style="text-align:left;">100</td>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec-23">     <header>     <div class="title-info">      <h3>       <span class="section-number">6.3</span> Experimental Procedure</h3>     </div>     </header>     <p>First, we evaluated the workers&#x2019; objectives. For the comparison goals, we compared the reward average of five randomly selected workers in each model. Each worker had different proficiency and rating scores associated with each skill.</p>     <p>In our model, we calculate the expected rewards and rating. However, in the crowdsourcing paradigm, payment is not guaranteed as described earlier. To simulate the crowdsoursing paradigm, we designed a stochastic program that runs 10, 20, and 50 times, each time with a possibility of acceptance or rejection based on the employer&#x0027;s commitment score and the worker&#x0027;s proficiency score. In each run, a random number will be generated. If the number is between zero and the potential acceptance score, the task will be considered accepted; otherwise, it will be rejected. Then, the number of accepted times will be multiplied by the actual rewards. Finally, we calculate the reward&#x0027;s average. The potential acceptance is calculated by multiplying the employer&#x0027;s commitment score by the worker&#x0027;s proficiency score as described earlier in the algorithms.</p>     <p>We ran the simulation 10, 20, and 50 times on each dataset, and compared the average rewards for the selected workers in the proposed model with the average rewards of the same workers in the two baseline models. In Baseline 1, a greedy approach was used to choose the set of tasks that would maximize the worker&#x0027;s objectives. In Baseline 2, the worker&#x0027;s performance was considered and tasks would be recommended based on the worker&#x0027;s previous performance. To evaluate the potential acceptance in the baseline models, we considered additional information consisting of the employer&#x0027;s commitment score and the worker&#x0027;s proficiency score. Fig. 3 shows the average rewards for the selected workers in each dataset. <figure id="fig3">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191579/images/www18companion-318-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 3:</span>       <span class="figure-title">Evaluating the Workers&#x2019; objectives</span>      </div>     </figure>     </p>     <p>Second, we evaluated the employers&#x2019; objectives. For the comparison goals, we randomly selected five employers and for each employer we randomly selected one task. To evaluate the employers&#x2019; objectives, we compared their potential satisfaction with hiring each worker for the selected task.</p>     <p>To simulate the employer&#x0027;s role, we ran the simulation 10, 20, and 50 times on each dataset, the simulation calculate the probability of the potential satisfaction for each selected employer. Each time had a possibility of worker success or failure based on the worker&#x0027;s PS for task <em>a<sub>j</sub>     </em>. In each run, a random number was generated. If the number was in the interval of the worker&#x0027;s success range based on the <em>PS</em>[<em>a<sub>j</sub>     </em>] score, the task was considered accepted and the worker succeeded. Then, the program calculated the average of the worker&#x0027;s successful outcomes. After running the program 10, 20, and 50 times, the success average for each worker was calculated and compared with the baseline for the employer recommendation system, which recommends workers with the highest rating scores. Fig .4 shows the probability of the employer satisfaction with the recommended workers in each dataset. <figure id="fig4">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191579/images/www18companion-318-fig4.jpg" class="img-responsive" alt="Figure 4"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 4:</span>       <span class="figure-title">Evaluating the employers&#x2019; objectives</span>      </div>     </figure>     </p>    </section>   </section>   <section id="sec-24">    <header>     <div class="title-info">     <h2>      <span class="section-number">7</span> Conclusion</h2>     </div>    </header>    <p>We have proposed a multi-objective recommendation model for the crowdsourcing paradigm. The computational complexity for the algorithms is <span class="inline-equation"><span class="tex">$\operatorname{O}\bigl (nW\bigr)$</span>     </span>. The model has addressed the goals of all three stakeholders (the worker, the employer, and the service provider). The model is designed as an interactive system where every worker and employer can set the parameters that meet their goals. All previous crowdsourcing recommendation systems have been designed to address one stakeholder. Moreover, no crowdsourcing recommendation system has considered the other party&#x0027;s behavior to provide more qualified recommendations as we have done. The experimental simulation showed the superiority of the proposed model compared to two baseline models. The proposed model is a hybrid approach that combines content based and collaborative approach to overcome each approach&#x0027;s limitation. However, the model still have some cases that faces the cold start problem. The common solution in the literature is based on matrix factorization which need workers&#x2019; previous rating scores. To overcome this, we are working on different approach to solve this problem by adding a simple technique without any negative affect of the scalability. In the future, we plan to design a sequential decision recommendation model. The current model would use a one shot game where the decision is made simultaneously. However, in the sequential game, one player makes a decision and then based on that, the other player makes a decision. In this model, a recommendation decision will be provided in each stage.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Eman Aldhahri, Abdullah Abuhussein, and Sajjan Shiva. 2015. Leveraging Crowdsourcing in Cloud Application Development. <em>      <em>Software Engineering and Applications</em>     </em>(2015).</li>     <li id="BibPLXBIB0002" label="[2]">Eman Aldhahri, Vivek Shandilya, and Sajjan Shiva. 2015. Towards an Effective Crowdsourcing Recommendation System: A Survey of the State-of-the-Art. In <em>      <em>Service-Oriented System Engineering (SOSE), 2015 IEEE Symposium on</em>     </em>. IEEE, 372&#x2013;377.</li>     <li id="BibPLXBIB0003" label="[3]">Vamshi Ambati, Stephan Vogel, and Jaime&#x00A0;G Carbonell. 2011. Towards task recommendation in micro-task markets.. In <em>      <em>Human computation</em>     </em>. 1&#x2013;4.</li>     <li id="BibPLXBIB0004" label="[4]">Daren&#x00A0;C Brabham. 2008. Crowdsourcing as a model for problem solving an introduction and cases. <em>      <em>Convergence: the international journal of research into new media technologies</em>     </em>14, 1 (2008), 75&#x2013;90.</li>     <li id="BibPLXBIB0005" label="[5]">Jiajun Bu, Xin Shen, Bin Xu, Chun Chen, Xiaofei He, and Deng Cai. 2016. Improving Collaborative Recommendation via User-Item Subgroups. <em>      <em>IEEE Transactions on Knowledge and Data Engineering</em>     </em>28, 9(2016), 2363&#x2013;2375.</li>     <li id="BibPLXBIB0006" label="[6]">Djellel&#x00A0;Eddine Difallah, Gianluca Demartini, and Philippe Cudr&#x00E9;-Mauroux. 2013. Pick-a-crowd: tell me what you like, and i&#x0027;ll tell you what to do. In <em>      <em>Proceedings of the 22nd international conference on World Wide Web</em>     </em>. ACM, 367&#x2013;374.</li>     <li id="BibPLXBIB0007" label="[7]">Zhi&#x00A0;Ming Feng and Yi&#x00A0;Dan Su. 2013. Application of Using Simulated Annealing to Combine Clustering with Collaborative Filtering for Item Recommendation. In <em>      <em>Applied Mechanics and Materials</em>     </em>, Vol.&#x00A0;347. Trans Tech Publ, 2747&#x2013;2751.</li>     <li id="BibPLXBIB0008" label="[8]">David Geiger and Martin Schader. 2014. Personalized task recommendation in crowdsourcing information systems Current state of the art. <em>      <em>Decision Support Systems</em>     </em>65 (2014), 3&#x2013;16.</li>     <li id="BibPLXBIB0009" label="[9]">Jeff Howe. 2006. The rise of crowdsourcing. <em>      <em>Wired magazine</em>     </em>14, 6 (2006), 1&#x2013;4.</li>     <li id="BibPLXBIB0010" label="[10]">Chein-Shung Hwang, Yi-Ching Su, and Kuo-Cheng Tseng. 2010. Using genetic algorithms for personalized recommendation. In <em>      <em>International Conference on Computational Collective Intelligence</em>     </em>. Springer, 104&#x2013;112.</li>     <li id="BibPLXBIB0011" label="[11]">Eric Jones, Travis Oliphant, Pearu Peterson, <em>et al.</em> 2001&#x2013;. SciPy: Open source scientific tools for Python. (2001&#x2013;). <a class="link-inline force-break" href="http://www.scipy.org/" target="_blank">http://www.scipy.org/</a>[Online; accessed <today>].</li>     <li id="BibPLXBIB0012" label="[12]">Guoliang Li, Jiannan Wang, Yudian Zheng, and Michael&#x00A0;J Franklin. 2016. Crowdsourced data management: A survey. <em>      <em>IEEE Transactions on Knowledge and Data Engineering</em>     </em>28, 9(2016), 2296&#x2013;2319.</li>     <li id="BibPLXBIB0013" label="[13]">Xin Li, Mengyue Wang, and T-P Liang. 2014. A multi-theoretical kernel-based approach to social network-based recommendation. <em>      <em>Decision Support Systems</em>     </em>65 (2014), 95&#x2013;104.</li>     <li id="BibPLXBIB0014" label="[14]">Chen Lin, Runquan Xie, Lei Li, Zhenhua Huang, and Tao Li. 2012. Premise: Personalized news recommendation via implicit social experts. In <em>      <em>Proceedings of the 21st ACM international conference on information and knowledge management</em>     </em>. ACM, 1607&#x2013;1611.</li>     <li id="BibPLXBIB0015" label="[15]">Christopher&#x00A0;H Lin, Ece Kamar, and Eric Horvitz. 2014. Signals in the Silence: Models of Implicit Feedback in a Recommendation System for Crowdsourcing.. In <em>      <em>AAAI</em>     </em>. 908&#x2013;915.</li>     <li id="BibPLXBIB0016" label="[16]">Kevin Meehan, Tom Lunney, Kevin Curran, and Aiden McCaughey. 2013. Context-aware intelligent recommendation system for tourism. In <em>      <em>Pervasive Computing and Communications Workshops (PERCOM Workshops), 2013 IEEE International Conference on</em>     </em>. IEEE, 328&#x2013;331.</li>     <li id="BibPLXBIB0017" label="[17]">Paolo Toth. 1980. Dynamic programming algorithms for the zero-one knapsack problem. <em>      <em>Computing</em>     </em>25, 1 (1980), 29&#x2013;45.</li>     <li id="BibPLXBIB0018" label="[18]">Paul Whitla. 2009. Crowdsourcing and its application in marketing activities. <em>      <em>Contemporary Management Research</em>     </em>5, 1 (2009).</li>     <li id="BibPLXBIB0019" label="[19]">Man-Ching Yuen, Irwin King, and Kwong-Sak Leung. 2011. Task matching in crowdsourcing. In <em>      <em>Internet of Things (iThings/CPSCom), 2011 International Conference on and 4th International Conference on Cyber, Physical and Social Computing</em>     </em>. IEEE, 409&#x2013;412.</li>     <li id="BibPLXBIB0020" label="[20]">Man-Ching Yuen, Irwin King, and Kwong-Sak Leung. 2012. Task recommendation in crowdsourcing systems. In <em>      <em>Proceedings of the First International Workshop on Crowdsourcing and Data Mining</em>     </em>. ACM, 22&#x2013;26.</li>     <li id="BibPLXBIB0021" label="[21]">Man-Ching Yuen, Irwin King, and Kwong-Sak Leung. 2012. Task recommendation in crowdsourcing systems. In <em>      <em>Proceedings of the First International Workshop on Crowdsourcing and Data Mining</em>     </em>. ACM, 22&#x2013;26.</li>     <li id="BibPLXBIB0022" label="[22]">Man-Ching Yuen, Irwin King, and Kwong-Sak Leung. 2015. Taskrec: A task recommendation framework in crowdsourcing systems. <em>      <em>Neural Processing Letters</em>     </em>41, 2 (2015), 223&#x2013;238.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>Produces the permission block, and copyright information</p>   <p id="fn3"><a href="#foot-fn3"><sup>1</sup></a>    <em>C</em>    <sub>1</sub> is the commission that the service provider grants when the task <em>a<sub>j</sub>    </em> is accepted.</p>   <p id="fn4"><a href="#foot-fn4"><sup>2</sup></a>    <em>C</em>    <sub>2</sub> is the commission that the service provider grant when the task <span class="inline-equation"><span class="tex">$a_{j_1}$</span>    </span> is accepted.</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 1997; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04&#x2026;15.00 .<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3191579">https://doi.org/10.1145/3184558.3191579</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
