<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Flood Relevance Estimation from Visual and Textual Content in Social Media Streams</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3191620'>https://doi.org/10.1145/3184558.3191620</a> 
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3191620'>https://w3id.org/oa/10.1145/3184558.3191620</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Flood Relevance Estimation from Visual and Textual Content in Social Media Streams</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Anastasia</span> <span class="surName">Moumtzidou</span> Information Technologies Institute - Centre for Research and Technology, Thessaloniki, Greece
        </div>
        <div class="author">
          <span class="givenName">Stelios</span> <span class="surName">Andreadis</span> Information Technologies Institute - Centre for Research and Technology, Thessaloniki, Greece
        </div>
        <div class="author">
          <span class="givenName">Ilias</span> <span class="surName">Gialampoukidis</span> Information Technologies Institute - Centre for Research and Technology, Thessaloniki, Greece
        </div>
        <div class="author">
          <span class="givenName">Anastasios</span> <span class="surName">Karakostas</span> Information Technologies Institute - Centre for Research and Technology, Thessaloniki, Greece
        </div>
        <div class="author">
          <span class="givenName">Stefanos</span> <span class="surName">Vrochidis</span> Information Technologies Institute - Centre for Research and Technology, Thessaloniki, Greece
        </div>
        <div class="author">
          <span class="givenName">Ioannis</span> <span class="surName">Kompatsiaris</span> Information Technologies Institute - Centre for Research and Technology, Thessaloniki, Greece, <a href="mailto:moumtzid,%20andreadisst,%20heliasgj,%20akarakos,%20stefanos,%20ikom@iti.com">moumtzid, andreadisst, heliasgj, akarakos, stefanos, ikom@iti.com</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191620" target="_blank">https://doi.org/10.1145/3184558.3191620</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Disaster monitoring based on social media posts has raised a lot of interest in the domain of computer science the last decade, mainly due to the wide area of applications in public safety and security and due to the pervasiveness not solely on daily communication but also in life-threating situations. Social media can be used as a valuable source for producing early warnings of eminent disasters. This paper presents a framework to analyse social media multimodal content, in order to decide if the content is relevant to flooding. This is very important since it enhances the crisis situational awareness and supports various crisis management procedures such as preparedness. Evaluation on a benchmark dataset shows very good performance in both text and image classification modules.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS Concepts:</span> • <strong>Information systems</strong> → <strong>Online analytical processing;</strong> <em>Data stream mining;</em></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style="font-weight:bold;"><small>Keywords:</small></span> <span class="keyword"><small>social media</small>,</span> <span class="keyword"><small>disaster monitoring</small>,</span> <span class="keyword"><small>text classifier</small>,</span> <span class="keyword"><small>visual classifier</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Anastasia Moumtzidou, Stelios Andreadis, Ilias Gialampoukidis, Anastasios Karakostas, Stefanos Vrochidis, and Ioannis Kompatsiaris. 2018. Flood Relevance Estimation from Visual and Textual Content in Social Media Streams. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New York, NY, USA</em> 7 Pages. <a href="https://doi.org/10.1145/3184558.3191620" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3184558.3191620</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-2">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <p>The increasing popularity of social media has resulted in massive volumes of publicly available, user-generated multimodal content. Social media are not simply changing the way people communicate in their day-to-day lives, but also during disasters that endanger public health. Consequently, social media comprise an important source of information, which reports any major event including natural disasters [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>]. This fact, coupled with various severe natural disasters that have taken place around the world such as the Haiti's 2010 earthquake, the 2010 Yushu earthquake, the 2010 Pakistan floods, the 2011 Töhoku earthquake and tsunami, and the April 2015 Nepal earthquake, led to raising the interest of disaster monitoring based on social media in the domain of computer science.</p>
      <p>It is observed that social media platforms, such as Twitter, are a rich source of information about real-world events, particularly during mass emergencies, from the citizens’ point of view. The abundant nature of these data renders them as one of the most valuable sources to extract and deduct early warnings or identify an ongoing disaster [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>]. Social media can support both early warnings mechanism and decision support systems since they offer real-time citizen observations, mainly textual and visual and they have been established as one of the most important communication channels.</p>
      <p>In this work, we propose a framework for a social media monitoring tool that crawls, represents, and analyses content found in social media in order to decide whether the content is related or not to a natural disaster, using a combination of Deep Convolutional Neural Networks on visual content and Random Forests on textual features. The focus is on detecting flood events by using Twitter posts, mainly due to its real-time streaming nature, but it can be easily applied to other events and social media as well given that the framework presented is generic. The contribution of the work lies in the use of visual data, along with the textual, for determining whether the content is relevant to the disaster. The use of visual data also contributes to developing a language agnostic framework for an early warning mechanism.</p>
    </section>
    <section id="sec-3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related Work</h2>
        </div>
      </header>
      <p>There are several initiatives including projects and applications that exploit social media, such as Flickr tags [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0020">20</a>], in order to create awareness about emergency situations or any other health related issues such as environmental conditions. First, within the hackAIR project [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>], a platform has been developed for gathering and fusing environmental data and specifically Particulate Matter measurements from official sources and social media communities such as publicly available images shared through Instagram. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0021">21</a>], the authors describe a framework that distinguishes between informational and conversational tweets shared during any major event and especially natural disasters. The framework uses a Naïve Bayes classifier for tweet classification and proposes the use of nine tweet-based features including emoticons, URLs, and instructional keywords. The framework was tested during hurricane Sandy and the results demonstrate that the nine features combined with the bag-of-words features (BoW) achieve over 85% accuracy. Another work with similar focus is that of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>] that aims at removing conversational data intermixed with informational data during natural disasters. The authors use the Geoparsing process that converts free text description to geographical coordinates in order to identify the relevant tweets. Eventually, in order to assess the severity of the natural disaster, sentiment analysis is performed. Furthermore, in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0024">24</a>], the authors analyse tweets generated during natural disasters, and apply burst detection for identifying early indicators of unexpected event, as well as classification and online clustering methods for filtering and summarising disaster-related information. The features used are the tweets’ text itself and other tweet-related information such as mention and hashtag count, as also done in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>] for the estimation of the informativeness of a tweet. Another work towards this direction is that of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>], where the authors present a social media crisis mapping platform for natural disasters by using statistical analysis techniques for generating real-time crisis maps. They use locations from gazetteer, street map and volunteered geographic information sources for areas at risk of disaster which allows them to work at a building and street level resolution. Recently, Win et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0022">22</a>] introduced a tweet monitoring system that classifies messages in real-time by using LibLinear classifier and by considering linguistic features, sentiment lexicon based features and especially disaster lexicon based features. The performance was evaluated on four publicly available annotated datasets and showed that it outperformed the classifiers based on neural word embeddings and standard BoW models. Moreover, Fujitsu Laboratories developed technologies for disaster prevention and mitigation, by considering the knowledge of specialists. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>], the authors describe an enhanced estimation technique involving social networking services, to quickly identify the location of a disaster.</p>
      <p>Contrary to the above approaches, we follow a two-stage approach where relevance is assessed progressively. The classifier is a combination of Support Vector Machine (SVM) classification on visual features which are extracted using Deep Convolutional Neural Networks (DCNN) and Random Forests on textual features. In the sequel, we present briefly several approaches of visual and textual classification.</p>
      <section id="sec-4">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Image classification</h3>
          </div>
        </header>
        <p>Image classification involves the use of visual concept detection algorithms based on visual low-level features and classifiers for deciding whether an image shows evidence of flood.</p>
        <p>Regarding low-level feature extraction, the most recent trend that seems to outperform all other previously developed methods is the DCNN-based features. DCNN-based features derive from the raw image pixels using Deep Convolutional Neural Networks (DCNNs), which consist of many layers of feature extractors and they can be used either as standalone classifiers, i.e., unlabeled images are passed through a pre-trained DCNN that performs the final class label prediction directly, or as generators of image features, i.e., the output of a hidden layer of the pre-trained DCNN is used as a global image representation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>]. The latter type of features is referred to as DCNN-based. Several DCNN software libraries are available, such as Caffe [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>], and different DCNN architectures have been proposed, such as GoogLeNet [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>].</p>
        <p>Classification involves the construction of models by using the low-level visual features, and then the application of these models for image labelling. Common classifiers that are used for learning the associations between the image representations and concept labels are the SVM and Logistic Regression (LR) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>].</p>
      </section>
      <section id="sec-5">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Text classification</h3>
          </div>
        </header>
        <p>Text classification is a typical task in supervised machine learning and involves assigning categories to documents which can be documents, web pages etc. In general it involves the following steps: a) document collection, b) document preprocessing, which converts the original text data in a data-mining-ready structure, c) Text representation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>], which models documents and transforms them into numeric vectors. The most commonly model is the BoW model which can use different term weighting schemas such as the Boolean, the Term Frequency (TF), and the Term Frequency Inversed Document Frequency (TF-IDF). A more recent model version is word2vec [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>], which comprises two-layer neural networks trained to reconstruct linguistic contexts of words and produce eventually word embeddings, and d) Serving the feature vector as input to a classifier (i.e. SVM, Naïve Bayes or Random Forests (RFs) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>]) which is tuned in order to achieve maximum performance.</p>
        <p>Recently, text classification techniques that consider the characteristic features of short texts appearing in many areas such as Instant Messages and Twitter were developed. These texts are usually noisier, less topic-focused, shorter, and they contain many non-standard terms. Methods handling this type of texts include semantic analysis, semi-supervised short text classification, ensemble models for short text [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>] and feature selection [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>]. Moreover, some techniques target specifically Twitter due to its extensive use, e.g. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] that considers the emoticons, the URLs existing in the text, the number of retweets and other features. However, given that these methods do not focus on the content are usually used for classifying text in more generic classes such as news, events and opinions.</p>
      </section>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Proposed Framework</h2>
        </div>
      </header>
      <p>The proposed architecture describes a social media monitoring pipeline that collects effectively and in real-time posts from social media and specifically Twitter and classifies them as relevant or irrelevant to a natural disaster event. The classification considers both textual information and visual information (if available). The complete flow of the social media monitoring architecture is demonstrated in <a class="fig" href="#fig1">1</a>. The proposed framework involves the classification of each tweet in order to determine its relevancy to a specified natural disaster, i.e. flood. Two modalities are considered during classification; textual and visual. Visual classification is language-independent, since only visual characteristics are taken into account and in this manner it can be applied to any image retrieved regardless of the language of the tweet. Thus, if an image is uploaded along with the tweet, its visual features are extracted and it is then fed to a classifier (Section <a class="sec" href="#sec-7">3.1</a>). In case the crawled tweet does not include an image or the result of the visual classifier is negative, the actual text is used to estimate the relevancy by using a text classifier (Section <a class="sec" href="#sec-8">3.2</a>). In the sequel, we present an overview of the visual and textual classification modules.</p>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Social media image classification framework</h3>
          </div>
        </header>
        <figure id="fig1">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191620/images/www18companion-359-fig1.jpg" class="img-responsive" alt="Figure 1" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span> <span class="figure-title">Social media monitoring module architecture.</span>
          </div>
        </figure>
        <p>In the employed framework, we train a 22-layer GoogLeNet network [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>] on 5055 ImageNet concepts [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>], which are a subset of the 12,988 ImageNet concepts. Then, this network is applied on the TRECVID SIN 2013<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> development dataset and the output of the last pooling layer with dimension 1024 is used for global image representation. We use the annotated dataset for training and validating an SVM classifier. The SVM classifier can be tuned by setting different <em>t</em> and <em>g</em> values in order to achieve maximum performance. The parameter <em>t</em> in SVM classifiers defines the kernel type, while <em>g</em> stands for the gamma in the kernel function.</p>
      </section>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Social media text classification framework</h3>
          </div>
        </header>
        <p>Image classification is supported by text classification to assess the relevance of a social media post. In the employed framework, we evaluated several methods belonging to the traditional text classification, as well as the Jaccard similarity method. Jaccard similarity method [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>] is a measure that concludes whether a document belongs to a specific class by calculating its similarity with the instances that are known to belong to the class. The maximum of the similarity calculated between the query document and the set of documents belonging to the class of interest is compared to a threshold value that is defined empirically in order to decide whether the query document belongs or not to the specific class. Similar measures are the Manhattan distance, the cosine similarity, and the Euclidean distance.</p>
        <p>Thus, for the traditional text classification we approach each of the aforementioned steps as follows:</p>
        <ol class="list-no-style">
          <li id="list1" label="(1)">Collection of short text messages from Twitter Streaming API<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>.<br />
          </li>
          <li id="list2" label="(2)">Pre-processing of the collected text by either applying DBpedia Spotlight that automatically annotates it with respective DBpedia resources [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>] which can also be used as high-level textual features or simple removing punctuation, non-characters, stop words and word stemming.<br />
          </li>
          <li id="list3" label="(3)">Text representation using Term Frequency (TF), TFIDF and word2vec. Various experiments were realized for different feature length and n-gram values for the BoW methods, and different corpus and vector dimensions for the word2vec method.<br /></li>
          <li id="list4" label="(4)">Serving of feature vector as input to a classifier (i.e. SVM, Naïve Bayes or Random Forests (RFs)) which is tuned in order to achieve maximum performance.<br /></li>
        </ol>
        <p>Regarding the Jaccard similarity approach, after collecting and preprocessing the data in the same manner as previously, we calculate the Jaccard similarity coefficient between the new text description and each positively annotated text description, using <span class="inline-equation"><span class="tex">$J(W_q,W_{t_n})= \frac{|W_q \cap W_{t_n}|}{|W_q \cup W_{t_n}|}$</span></span> , where <em>W<sub>q</sub></em> stands for the set of terms of the new text description, and <span class="inline-equation"><span class="tex">$W_{t_n}$</span></span> for the set of terms of the <em>n</em> text description of the positively annotated dataset tests. Then, the maximum value of the Jaccard similarity coefficients is compared to a threshold defined empirically in order to determine whether the new text description will be considered as positive or not.</p>
        <p>In the following, we examine the performance of the proposed framework and we tune the involved parameters.</p>
      </section>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Evaluation</h2>
        </div>
      </header>
      <p>This section describes the datasets where the text and image classification modules are evaluated, and the experiments conducted. The proposed framework is evaluated for the flood event, but it can be extended to any other events.</p>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Dataset Description</h3>
          </div>
        </header>
        <p>The dataset that was used for developing and evaluating both the visual and textual classification modules, is the MediaEval 2017 dataset<a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>. It was provided within the context of the Disaster Image Retrieval from Social Media (DIRSM) subtask whose goal was to identify all images that show direct evidence of a flooding event. Along with the dataset a set of visual descriptors were also precomputed and provided to the contesters which were evaluated during the building of the visual classifier. Table <a class="tbl" href="#tab1">1</a> contains the statistics of the MediaEval2017 dataset.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class="table-title">Statistics of MediaEval 2017 dataset</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:left;" colspan="2">
                  Annotation for concept ’flood’
                  <hr />
                </th>
                <th style="text-align:left;">Sum</th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:left;">True</th>
                <th style="text-align:left;">False</th>
                <th style="text-align:left;"></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Train set</td>
                <td style="text-align:left;">1280</td>
                <td style="text-align:left;">2240</td>
                <td style="text-align:left;">3520</td>
              </tr>
              <tr>
                <td style="text-align:left;">Validation set</td>
                <td style="text-align:left;">640</td>
                <td style="text-align:left;">1120</td>
                <td style="text-align:left;">1760</td>
              </tr>
              <tr>
                <td style="text-align:left;">Total Records</td>
                <td style="text-align:left;">1920</td>
                <td style="text-align:left;">3360</td>
                <td style="text-align:left;">5280</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Experiments</h3>
          </div>
        </header>
        <p>The evaluation of the visual classification part is done by using precision, recall, and F-score. These metrics are calculated in every run in order to decide the best performing classification method.</p>
        <section id="sec-12">
          <p><em>4.2.1 Social media image classification.</em> In order to find the best performing feature and classifier for identifying images that contain evidence of flood, several features are compared and the parameters of SVM classifiers are tuned in order to maximise their performance. In detail, the features provided by the Multimedia-Satellite challenge were tested (i.e. acc, fcth, jcd, cedd, eh, sc, cl, and tamura) and the DCNN-based features that were produced from our framework. SVM classifiers were trained for each feature for different parameters and results showed that the proposed DCNN feature outperformed almost all of them (see Table <a class="tbl" href="#tab2">2</a>). The SVM parameters that were tuned were <em>t</em> that defines the type of kernel function and can be set to linear, polynomial, radial and sigmoid and <em>g</em> that is the gamma parameter in the kernel function. Consequently, the best results were obtained for the DCNN-based features for <em>t</em> = 1 (polynomial function) and <em>g</em> = 0.5 or <em>g</em> = 0,03125. Figure <a class="fig" href="#fig3">3</a> depicts the top 18 results returned by the classifier.</p>
          <div class="table-responsive" id="tab2">
            <div class="table-caption">
              <span class="table-number">Table 2:</span> <span class="table-title">Evaluation of visual features and classifiers.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:left;">Descriptors</th>
                  <th style="text-align:left;" colspan="2">
                    SVM parameters
                    <hr />
                  </th>
                  <th style="text-align:left;">Precision</th>
                  <th style="text-align:left;">Recall</th>
                  <th style="text-align:left;">F-score</th>
                </tr>
                <tr>
                  <th style="text-align:left;"></th>
                  <th style="text-align:left;">t</th>
                  <th style="text-align:left;">g</th>
                  <th style="text-align:left;"></th>
                  <th style="text-align:left;"></th>
                  <th style="text-align:left;"></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:left;">acc</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,03125</td>
                  <td style="text-align:left;">0,5359</td>
                  <td style="text-align:left;">0,1516</td>
                  <td style="text-align:left;">0,2363</td>
                </tr>
                <tr>
                  <td style="text-align:left;">acc</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,5</td>
                  <td style="text-align:left;">0,4830</td>
                  <td style="text-align:left;">0,1328</td>
                  <td style="text-align:left;">0,2083</td>
                </tr>
                <tr>
                  <td style="text-align:left;">cedd</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,03125</td>
                  <td style="text-align:left;">0,6085</td>
                  <td style="text-align:left;">0,5391</td>
                  <td style="text-align:left;">0,5717</td>
                </tr>
                <tr>
                  <td style="text-align:left;">cedd</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,5</td>
                  <td style="text-align:left;">0,5925</td>
                  <td style="text-align:left;">0,3953</td>
                  <td style="text-align:left;">0,4742</td>
                </tr>
                <tr>
                  <td style="text-align:left;">cl</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,03125</td>
                  <td style="text-align:left;">0,6115</td>
                  <td style="text-align:left;">0,3641</td>
                  <td style="text-align:left;">0,4564</td>
                </tr>
                <tr>
                  <td style="text-align:left;">cl</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,5</td>
                  <td style="text-align:left;">0,5957</td>
                  <td style="text-align:left;">0,3016</td>
                  <td style="text-align:left;">0,4004</td>
                </tr>
                <tr>
                  <td style="text-align:left;">eh</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,03125</td>
                  <td style="text-align:left;">0,6682</td>
                  <td style="text-align:left;">0,4688</td>
                  <td style="text-align:left;">0,5510</td>
                </tr>
                <tr>
                  <td style="text-align:left;">eh</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,5</td>
                  <td style="text-align:left;">0,6605</td>
                  <td style="text-align:left;">0,4469</td>
                  <td style="text-align:left;">0,5331</td>
                </tr>
                <tr>
                  <td style="text-align:left;">fcth</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,03125</td>
                  <td style="text-align:left;">0,5956</td>
                  <td style="text-align:left;">0,4625</td>
                  <td style="text-align:left;">0,5207</td>
                </tr>
                <tr>
                  <td style="text-align:left;">fcth</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,5</td>
                  <td style="text-align:left;">0,5000</td>
                  <td style="text-align:left;">0,2578</td>
                  <td style="text-align:left;">0,3402</td>
                </tr>
                <tr>
                  <td style="text-align:left;">jcd</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,03125</td>
                  <td style="text-align:left;">0,6388</td>
                  <td style="text-align:left;">0,5250</td>
                  <td style="text-align:left;">0,5763</td>
                </tr>
                <tr>
                  <td style="text-align:left;">jcd</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,5</td>
                  <td style="text-align:left;">0,6025</td>
                  <td style="text-align:left;">0,3719</td>
                  <td style="text-align:left;">0,4599</td>
                </tr>
                <tr>
                  <td style="text-align:left;">sc</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,03125</td>
                  <td style="text-align:left;">1,0000</td>
                  <td style="text-align:left;">0,0016</td>
                  <td style="text-align:left;">0,0031</td>
                </tr>
                <tr>
                  <td style="text-align:left;">sc</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,5</td>
                  <td style="text-align:left;">0,2500</td>
                  <td style="text-align:left;">0,0016</td>
                  <td style="text-align:left;">0,0031</td>
                </tr>
                <tr>
                  <td style="text-align:left;">tamura</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,03125</td>
                  <td style="text-align:left;">0,5246</td>
                  <td style="text-align:left;">0,0500</td>
                  <td style="text-align:left;">0,0913</td>
                </tr>
                <tr>
                  <td style="text-align:left;">tamura</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,5</td>
                  <td style="text-align:left;">0,3913</td>
                  <td style="text-align:left;">0,0141</td>
                  <td style="text-align:left;">0,0271</td>
                </tr>
                <tr>
                  <td style="text-align:left;"><strong>dcnn-based</strong></td>
                  <td style="text-align:left;"><strong>1</strong></td>
                  <td style="text-align:left;"><strong>0,03125</strong></td>
                  <td style="text-align:left;"><strong>0,8195</strong></td>
                  <td style="text-align:left;"><strong>0,8016</strong></td>
                  <td style="text-align:left;"><strong>0,8104</strong></td>
                </tr>
                <tr>
                  <td style="text-align:left;"><strong>dcnn-based</strong></td>
                  <td style="text-align:left;"><strong>1</strong></td>
                  <td style="text-align:left;"><strong>0,5</strong></td>
                  <td style="text-align:left;"><strong>0,8195</strong></td>
                  <td style="text-align:left;"><strong>0,8016</strong></td>
                  <td style="text-align:left;"><strong>0,8104</strong></td>
                </tr>
              </tbody>
            </table>
          </div>
          <div class="table-responsive" id="tab3">
            <div class="table-caption">
              <span class="table-number">Table 3:</span> <span class="table-title">Evaluation of TF and TF-IDF representation method.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:left;">n-gram</th>
                  <th style="text-align:left;">Text-input</th>
                  <th style="text-align:left;">Classifier</th>
                  <th style="text-align:center;" colspan="3">
                    TF
                    <hr />
                  </th>
                  <th style="text-align:center;" colspan="3">
                    TF-IDF
                    <hr />
                  </th>
                </tr>
                <tr>
                  <th style="text-align:left;"></th>
                  <th style="text-align:left;"></th>
                  <th style="text-align:left;"></th>
                  <th style="text-align:left;">Precision</th>
                  <th style="text-align:left;">Recall</th>
                  <th style="text-align:left;">Fscore</th>
                  <th style="text-align:left;">Precision</th>
                  <th style="text-align:left;">Recall</th>
                  <th style="text-align:left;">Fscore</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">Without stop words</td>
                  <td style="text-align:left;">SVM</td>
                  <td style="text-align:left;">0,72655</td>
                  <td style="text-align:left;">0,85938</td>
                  <td style="text-align:left;">0,78740</td>
                  <td style="text-align:left;">0,71120</td>
                  <td style="text-align:left;">0,82344</td>
                  <td style="text-align:left;">0,76322</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">Naive Bayes</td>
                  <td style="text-align:left;">0,78522</td>
                  <td style="text-align:left;">0,71406</td>
                  <td style="text-align:left;">0,74795</td>
                  <td style="text-align:left;">0,76311</td>
                  <td style="text-align:left;">0,65938</td>
                  <td style="text-align:left;">0,70746</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">RandomForest</td>
                  <td style="text-align:left;">0,74098</td>
                  <td style="text-align:left;">0,89844</td>
                  <td style="text-align:left;">0,81241</td>
                  <td style="text-align:left;">0,73359</td>
                  <td style="text-align:left;">0,89063</td>
                  <td style="text-align:left;">0,80452</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">Without stop words &amp; with stemming</td>
                  <td style="text-align:left;">SVM</td>
                  <td style="text-align:left;">0,73986</td>
                  <td style="text-align:left;">0,48438</td>
                  <td style="text-align:left;">0,58546</td>
                  <td style="text-align:left;">0,69727</td>
                  <td style="text-align:left;">0,43906</td>
                  <td style="text-align:left;">0,53883</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">Naive Bayes</td>
                  <td style="text-align:left;">0,78776</td>
                  <td style="text-align:left;">0,60313</td>
                  <td style="text-align:left;">0,68319</td>
                  <td style="text-align:left;">0,77186</td>
                  <td style="text-align:left;">0,56563</td>
                  <td style="text-align:left;">0,65284</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">RandomForest</td>
                  <td style="text-align:left;">0,76087</td>
                  <td style="text-align:left;">0,76563</td>
                  <td style="text-align:left;">0,76324</td>
                  <td style="text-align:left;">0,76973</td>
                  <td style="text-align:left;">0,74688</td>
                  <td style="text-align:left;">0,75813</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">DBPedia concepts</td>
                  <td style="text-align:left;">SVM</td>
                  <td style="text-align:left;">0,66185</td>
                  <td style="text-align:left;">0,35781</td>
                  <td style="text-align:left;">0,46450</td>
                  <td style="text-align:left;">0,66462</td>
                  <td style="text-align:left;">0,33750</td>
                  <td style="text-align:left;">0,44767</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">Naive Bayes</td>
                  <td style="text-align:left;">0,72624</td>
                  <td style="text-align:left;">0,50156</td>
                  <td style="text-align:left;">0,59335</td>
                  <td style="text-align:left;">0,69752</td>
                  <td style="text-align:left;">0,48281</td>
                  <td style="text-align:left;">0,57064</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">RandomForest</td>
                  <td style="text-align:left;">0,66983</td>
                  <td style="text-align:left;">0,66250</td>
                  <td style="text-align:left;">0,66614</td>
                  <td style="text-align:left;">0,69581</td>
                  <td style="text-align:left;">0,59688</td>
                  <td style="text-align:left;">0,64256</td>
                </tr>
                <tr>
                  <td style="text-align:left;"><strong>2</strong></td>
                  <td style="text-align:left;"><strong>Without stop words</strong></td>
                  <td style="text-align:left;">SVM</td>
                  <td style="text-align:left;">0,72267</td>
                  <td style="text-align:left;">0,84688</td>
                  <td style="text-align:left;">0,77986</td>
                  <td style="text-align:left;">0,70572</td>
                  <td style="text-align:left;">0,80938</td>
                  <td style="text-align:left;">0,75400</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">Naive Bayes</td>
                  <td style="text-align:left;">0,77634</td>
                  <td style="text-align:left;">0,74844</td>
                  <td style="text-align:left;">0,76213</td>
                  <td style="text-align:left;">0,76056</td>
                  <td style="text-align:left;">0,67500</td>
                  <td style="text-align:left;">0,71523</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"><strong>RandomForest</strong></td>
                  <td style="text-align:left;"><strong>0,74804</strong></td>
                  <td style="text-align:left;"><strong>0,89531</strong></td>
                  <td style="text-align:left;"><strong>0,81508</strong></td>
                  <td style="text-align:left;"><strong>0,74443</strong></td>
                  <td style="text-align:left;"><strong>0,88750</strong></td>
                  <td style="text-align:left;"><strong>0,80969</strong></td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">Without stop words&amp; with stemming</td>
                  <td style="text-align:left;">SVM</td>
                  <td style="text-align:left;">0,74485</td>
                  <td style="text-align:left;">0,45156</td>
                  <td style="text-align:left;">0,56226</td>
                  <td style="text-align:left;">0,69825</td>
                  <td style="text-align:left;">0,43750</td>
                  <td style="text-align:left;">0,53794</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">Naive Bayes</td>
                  <td style="text-align:left;">0,78044</td>
                  <td style="text-align:left;">0,61094</td>
                  <td style="text-align:left;">0,68536</td>
                  <td style="text-align:left;">0,77419</td>
                  <td style="text-align:left;">0,56250</td>
                  <td style="text-align:left;">0,65158</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">RandomForest</td>
                  <td style="text-align:left;">0,76837</td>
                  <td style="text-align:left;">0,75156</td>
                  <td style="text-align:left;">0,75987</td>
                  <td style="text-align:left;">0,76056</td>
                  <td style="text-align:left;">0,75938</td>
                  <td style="text-align:left;">0,75997</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">DBPedia concepts</td>
                  <td style="text-align:left;">SVM</td>
                  <td style="text-align:left;">0,66382</td>
                  <td style="text-align:left;">0,36406</td>
                  <td style="text-align:left;">0,47023</td>
                  <td style="text-align:left;">0,66875</td>
                  <td style="text-align:left;">0,33438</td>
                  <td style="text-align:left;">0,44583</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">Naive Bayes</td>
                  <td style="text-align:left;">0,72955</td>
                  <td style="text-align:left;">0,50156</td>
                  <td style="text-align:left;">0,59444</td>
                  <td style="text-align:left;">0,70000</td>
                  <td style="text-align:left;">0,48125</td>
                  <td style="text-align:left;">0,57037</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">RandomForest</td>
                  <td style="text-align:left;">0,67742</td>
                  <td style="text-align:left;">0,65625</td>
                  <td style="text-align:left;">0,66667</td>
                  <td style="text-align:left;">0,66831</td>
                  <td style="text-align:left;">0,63594</td>
                  <td style="text-align:left;">0,65172</td>
                </tr>
              </tbody>
            </table>
          </div>
          <div class="table-responsive" id="tab4">
            <div class="table-caption">
              <span class="table-number">Table 4:</span> <span class="table-title">Evaluation of word2vec representation method.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:left;">Text input</th>
                  <th style="text-align:left;">Corpus</th>
                  <th style="text-align:left;">Vector</th>
                  <th style="text-align:left;">Words</th>
                  <th style="text-align:left;">Training</th>
                  <th style="text-align:left;">Precision</th>
                  <th style="text-align:left;">Recall</th>
                  <th style="text-align:left;">Fscore</th>
                </tr>
                <tr>
                  <th style="text-align:left;"></th>
                  <th style="text-align:left;"></th>
                  <th style="text-align:left;">dimension</th>
                  <th style="text-align:left;">windows</th>
                  <th style="text-align:left;">algorithm</th>
                  <th style="text-align:left;"></th>
                  <th style="text-align:left;"></th>
                  <th style="text-align:left;"></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:left;">without stop words</td>
                  <td style="text-align:left;">mediaEvalFloods_corpus</td>
                  <td style="text-align:left;">100</td>
                  <td style="text-align:left;">3</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,75835</td>
                  <td style="text-align:left;">0,74531</td>
                  <td style="text-align:left;">0,75177</td>
                </tr>
                <tr>
                  <td style="text-align:left;"><strong>text with stop words removed</strong></td>
                  <td style="text-align:left;"><strong>twitterFloods_corpus</strong></td>
                  <td style="text-align:left;"><strong>200</strong></td>
                  <td style="text-align:left;"><strong>3</strong></td>
                  <td style="text-align:left;"><strong>0</strong></td>
                  <td style="text-align:left;"><strong>0,79341</strong></td>
                  <td style="text-align:left;"><strong>0,82813</strong></td>
                  <td style="text-align:left;"><strong>0,81040</strong></td>
                </tr>
                <tr>
                  <td style="text-align:left;">without stop words &amp; with stemming</td>
                  <td style="text-align:left;">mediaEvalFloods_corpus</td>
                  <td style="text-align:left;">100</td>
                  <td style="text-align:left;">3</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,76167</td>
                  <td style="text-align:left;">0,71406</td>
                  <td style="text-align:left;">0,73710</td>
                </tr>
                <tr>
                  <td style="text-align:left;">without stop words &amp; with stemming</td>
                  <td style="text-align:left;">twitterFloods_corpus</td>
                  <td style="text-align:left;">200</td>
                  <td style="text-align:left;">3</td>
                  <td style="text-align:left;">0</td>
                  <td style="text-align:left;">0,77647</td>
                  <td style="text-align:left;">0,82500</td>
                  <td style="text-align:left;">0,80000</td>
                </tr>
                <tr>
                  <td style="text-align:left;">DBPedia concepts</td>
                  <td style="text-align:left;">mediaEvalFloods_corpus</td>
                  <td style="text-align:left;">100</td>
                  <td style="text-align:left;">2</td>
                  <td style="text-align:left;">1</td>
                  <td style="text-align:left;">0,75455</td>
                  <td style="text-align:left;">0,77813</td>
                  <td style="text-align:left;">0,76615</td>
                </tr>
                <tr>
                  <td style="text-align:left;">DBPedia concepts</td>
                  <td style="text-align:left;">twitterFloods_corpus</td>
                  <td style="text-align:left;">[100 - 500]</td>
                  <td style="text-align:left;">[2,3]</td>
                  <td style="text-align:left;">[0,1]</td>
                  <td style="text-align:left;">0,86667</td>
                  <td style="text-align:left;">0,02031</td>
                  <td style="text-align:left;">0,03969</td>
                </tr>
              </tbody>
            </table>
          </div>
          <div class="table-responsive" id="tab5">
            <div class="table-caption">
              <span class="table-number">Table 5:</span> <span class="table-title">Best parameters from TF, TF-IDF, word2vec text classification methods.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:left;">Method</th>
                  <th style="text-align:left;">Text Input</th>
                  <th style="text-align:left;">Parameters</th>
                  <th style="text-align:left;">Classifiers &amp; parameters</th>
                  <th style="text-align:left;">Precision</th>
                  <th style="text-align:left;">Recall</th>
                  <th style="text-align:left;">Fscore</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:left;">TF</td>
                  <td style="text-align:left;">without stop words</td>
                  <td style="text-align:left;">n-gram = 2, min_df = 0,003,</td>
                  <td style="text-align:left;">Random Forest</td>
                  <td style="text-align:left;">0,74804</td>
                  <td style="text-align:left;">0,89531</td>
                  <td style="text-align:left;">0,81508</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">features length = 1068</td>
                  <td style="text-align:left;">Features num: auto</td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">Number of trees: 200</td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                </tr>
                <tr>
                  <td style="text-align:left;">TF-IDF</td>
                  <td style="text-align:left;">without stop words</td>
                  <td style="text-align:left;">n-gram = 2, min_df = 0,003,</td>
                  <td style="text-align:left;">Random Forest</td>
                  <td style="text-align:left;">0,74443</td>
                  <td style="text-align:left;">0,88750</td>
                  <td style="text-align:left;">0,80969</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">features length = 1068</td>
                  <td style="text-align:left;">Features num: auto</td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">Number of trees: 500</td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                </tr>
                <tr>
                  <td style="text-align:left;">word2vec</td>
                  <td style="text-align:left;">without stop words</td>
                  <td style="text-align:left;">corpus = twitterFloods_corpus,</td>
                  <td style="text-align:left;">SVM</td>
                  <td style="text-align:left;">0,79341</td>
                  <td style="text-align:left;">0,82813</td>
                  <td style="text-align:left;">0,81040</td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">vector dimension = 200</td>
                  <td style="text-align:left;">Penalty parameter: 5.0</td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">words window = 3,</td>
                  <td style="text-align:left;">Kernel type: rbf</td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                </tr>
                <tr>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;">training algorithm = 0</td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                  <td style="text-align:left;"></td>
                </tr>
              </tbody>
            </table>
          </div>
        </section>
        <section id="sec-13">
          <p><em>4.2.2 Social media text classification.</em> In the sequel, the traditional text classification methods are evaluated. In all cases, three classifiers, namely SVM, Naïve Bayes, and Random Forests, are tested for a set of parameters. Specifically, for the case of SVM the penalty parameter and the kernel type is tested, for the Naïve Bayes the additive smoothing parameter is adjusted and finally for the RFs the parameters that are tested are the number of trees in the forest and the number of features used for best split. For the remaining parameters, default values are used. Moreover, regarding the methods using TF and TF-IDF representation, different <em>n-gram</em> values and <em>min_df</em> values are considered during text vectorisation. The <em>min_df</em> value affects the size of the feature length since it ignores terms that have a document frequency strictly lower than the given threshold when building the vocabulary. Table <a class="tbl" href="#tab3">3</a> contains the best results of the TF and the TF-IDF representation methods for each different classifier for different text inputs.</p>
          <p>Regarding the word2vec methodology several runs were performed for a set of different parameters including the <em>size</em> parameter that defines the dimension of the feature vector, the <em>window</em> parameter that defines the maximum distance between the current and predicted word within a sentence and the <em>sg</em> parameter that defines the training algorithm that can either skip-gram or CBOW. Specifically, the values that are tested for the aforementioned parameters are the following: <em>size</em> = {100, 200, 300, 400, 500}, <em>window</em> = {2,3} and <em>sg</em> = {0,1}.</p>
          <p>Table <a class="tbl" href="#tab4">4</a> contains the best results of the word2vec method. The sizes of the corpora used are 6,600 records for the mediaEvalFloods_corpus, and around 830,000 records for the twitterFloods_corpus which was produced by crawling tweets that include the keyword “flooding”. After a careful observation of the table, we conclude that the larger corpus achieves better performance. The best runs from all tables along with information concerning the text representation parameters and the classifier parameters can be found in Table reftab:bestparams. From the table we can deduce that the best performing method according to F-score is the TF method, while the second best performing method is the word2vec which has slightly lower F-score but significantly better precision.</p>
          <p>Finally we evaluated for text classification uses the Jaccard Similarity Coefficient.Figure <a class="fig" href="#fig2">2</a> depicts the F-score values for different text input and different values of the <em>e</em> threshold parameter. After a careful observation of the figure, we conclude that for the Jaccard similarity with DBpedia concepts slightly improves the classification performance. Moreover, it is evident that the method has good results for very low values of the <em>e</em> parameter, i.e. around 0.1 and drops significantly after that value. The main disadvantage of the Jaccard method is that it is rather slow compared to the other methods during the evaluation of new incoming text, given that this text must be compared against all positively annotated texts in order to determine its relevancy with them. However, since the text classification method is part of the social media monitoring pipeline that is triggered very regularly (usually around 1 second), it is not considered an optimal solution.</p>
        </section>
        <section id="sec-14">
          <p><em>4.2.3 Social media visual and textual classification.</em> In this section we present the evaluation of the total framework, which is a two-stage approach that considers both visual features and textual features. Two simple ways of combining the two modalities are examined that arise from the boolean operations AND and OR. The first is based on the boolean operation OR and is a sequential mode where, the result of the visual classifier determines initially the relevancy and in case it is negative the result of the textual classifier is examined as well in order to determine the relevancy of tweet. The aim of using a sequential mode is to avoid as much as possible running unnecessary processes (i.e. two classifiers) and thus consuming more time. The second is based on the boolean operation AND and evaluates simultaneously both modes which should be both positive in order for the tweet to be considered as relevant.</p>
          <div class="table-responsive" id="tab6">
            <div class="table-caption">
              <span class="table-number">Table 6:</span> <span class="table-title">Evaluation results of single modalities and combined modalities.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:left;">Method</th>
                  <th style="text-align:left;">Precision</th>
                  <th style="text-align:left;">Recall</th>
                  <th style="text-align:left;">Fscore</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:left;">Single mode using text data (word2vec)</td>
                  <td style="text-align:left;">0,79341</td>
                  <td style="text-align:left;">0,82813</td>
                  <td style="text-align:left;">0,81040</td>
                </tr>
                <tr>
                  <td style="text-align:left;">Single mode using visual data</td>
                  <td style="text-align:left;">0,81949</td>
                  <td style="text-align:left;">0,80156</td>
                  <td style="text-align:left;">0,81043</td>
                </tr>
                <tr>
                  <td style="text-align:left;">Sequential combined mode (OR)</td>
                  <td style="text-align:left;">0.73659</td>
                  <td style="text-align:left;">0.94375</td>
                  <td style="text-align:left;">0.82740</td>
                </tr>
                <tr>
                  <td style="text-align:left;">Simultaneous combined mode (AND)</td>
                  <td style="text-align:left;">0.91245</td>
                  <td style="text-align:left;">0.73281</td>
                  <td style="text-align:left;">0.81282</td>
                </tr>
              </tbody>
            </table>
          </div>
          <p>Table <a class="tbl" href="#tab6">6</a> contains the evaluation results of both combined methods and the single modalities as well in order to allow fast comparison. We can deduce that the combined mode based on the OR boolean operation performs better given that the F-score is higher compared to the single modes and the simultaneous combined mode. After a careful observation of the table, it is evident that there is a significant decrease in the precision of the framework which is balanced by a significant increase in the recall. On the other hand the simultaneous combined mode has slightly better F-score than the single modes but has a much higher precision and lower recall which is expected given that the two modes are combined in an AND boolean way. However, a disaster monitoring systems would favor higher recall given that is is more important identifying more cases that require attention than ignoring such messages in favor of a higher precision.</p>
          <figure id="fig2">
            <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191620/images/www18companion-359-fig2.jpg" class="img-responsive" alt="Figure 2" longdesc="" />
            <div class="figure-caption">
              <span class="figure-number">Figure 2:</span> <span class="figure-title">Evaluation of Jaccard Similarity method.</span>
            </div>
          </figure>
          <p></p>
        </section>
      </section>
    </section>
    <section id="sec-15">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Conclusions</h2>
        </div>
      </header>
      <p>This work presents an original framework that assesses the relevance of a social media post to a target event, such as floods. Our framework contributes to the crisis management procedures before, during and after the crisis and can be integrated in crisis management and decision support systems. Experiments on the MediaEval benchmark dataset and crawled posts from Twitter involving visual and textual information have shown that the best performing method in the case of image classification is the use of DCNN-based features together with an SVM classifier, while in the case of text classification stand out the TF-IDF method for text representation and Random Forests as classifier. As a future work, we plan to fuse visual and textual features, as well as combine traditional text classification techniques with short text classification techniques that additional social media metadata. Finally, we plan to evaluate the framework on other events including fires and heatwave as well as in order languages.</p>
      <figure id="fig3">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191620/images/www18companion-359-fig3.jpg" class="img-responsive" alt="Figure 3" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 3:</span> <span class="figure-title">Visualisation of DCNN-based visual classifier validation results.</span>
        </div>
      </figure>
      <p></p>
    </section>
  </section>
  <section class="back-matter">
    <section id="sec-16">
      <header>
        <div class="title-info">
          <h2>ACKNOWLEDGMENTS</h2>
        </div>
      </header>
      <p>This work was partially supported by the European Commission under contracts H2020-700475 beAWARE and H2020-776019 EOPEN.</p>
    </section>
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Flavia&nbsp;Sofia Acerbo and Claudio Rossi. 2017. Filtering Informative Tweets During Emergencies: A Machine Learning Approach. In <em><em>Proceedings of the First CoNEXT Workshop on ICT Tools for Emergency Networks and DisastEr Relief</em></em> (<em>I-TENDER ’17</em>). ACM, New York, NY, USA, 1–6. <a class="link-inline force-break" href="https://doi.org/10.1145/3152896.3152897" target="_blank">https://doi.org/10.1145/3152896.3152897</a>
        </li>
        <li id="BibPLXBIB0002" label="[2]">Charu&nbsp;C Aggarwal and ChengXiang Zhai. 2012. <em><em>Mining text data</em></em> . Springer Science &amp; Business Media.</li>
        <li id="BibPLXBIB0003" label="[3]">Leo Breiman. 2001. Random forests. <em><em>Machine learning</em></em> 45, 1 (2001), 5–32.</li>
        <li id="BibPLXBIB0004" label="[4]">Joachim Daiber, Max Jakob, Chris Hokamp, and Pablo&nbsp;N Mendes. 2013. Improving efficiency and accuracy in multilingual entity extraction. In <em><em>Proceedings of the 9th International Conference on Semantic Systems</em></em> . ACM, 121–124.</li>
        <li id="BibPLXBIB0005" label="[5]">Muhammad Imran, Carlos Castillo, Fernando Diaz, and Sarah Vieweg. 2015. Processing social media messages in mass emergency: A survey. <em><em>ACM Computing Surveys (CSUR)</em></em> 47, 4 (2015), 67.</li>
        <li id="BibPLXBIB0006" label="[6]">Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. 2014. Caffe: Convolutional architecture for fast feature embedding. In <em><em>Proceedings of the 22nd ACM international conference on Multimedia</em></em> . ACM, 675–678.</li>
        <li id="BibPLXBIB0007" label="[7]">Vijaymeena M&nbsp;K and Kavitha K. 2016. A Survey on Similarity Measures in Text Mining. 3 (03 2016), 19–28.</li>
        <li id="BibPLXBIB0008" label="[8]">Foteini Markatopoulou, Vasileios Mezaris, and Ioannis Patras. 2015. Cascade of classifiers based on binary, non-binary and deep convolutional network descriptors for video concept detection. In <em><em>Image Processing (ICIP), 2015 IEEE International Conference on</em></em> . IEEE, 1786–1790.</li>
        <li id="BibPLXBIB0009" label="[9]">Raina&nbsp;M Merchant, Stacy Elmer, and Nicole Lurie. 2011. Integrating social media into emergency-preparedness efforts. <em><em>New England Journal of Medicine</em></em> 365, 4 (2011), 289–291.</li>
        <li id="BibPLXBIB0010" label="[10]">Stuart&nbsp;E Middleton, Lee Middleton, and Stefano Modafferi. 2014. Real-time crisis mapping of natural disasters using social media. <em><em>IEEE Intelligent Systems</em></em> 29, 2 (2014), 9–17.</li>
        <li id="BibPLXBIB0011" label="[11]">Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg&nbsp;S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In <em><em>Advances in neural information processing systems</em></em> . 3111–3119.</li>
        <li id="BibPLXBIB0012" label="[12]">Anastasia Moumtzidou, Symeon Papadopoulos, Stefanos Vrochidis, Ioannis Kompatsiaris, Konstantinos Kourtidis, George Hloupis, Ilias Stavrakas, Konstantina Papachristopoulou, and Christodoulos Keratidis. 2016. Towards Air Quality Estimation Using Collected Multimodal Environmental Data. In <em><em>International Workshop on the Internet for Financial Collective Awareness and Intelligence</em></em> . Springer, 147–156.</li>
        <li id="BibPLXBIB0013" label="[13]">Nikiforos Pittaras, Foteini Markatopoulou, Vasileios Mezaris, and Ioannis Patras. 2017. Comparison of fine-tuning and extension strategies for deep convolutional neural networks. In <em><em>International Conference on Multimedia Modeling</em></em> . Springer, 102–114.</li>
        <li id="BibPLXBIB0014" label="[14]">MV Sangameswar, M&nbsp;Nagabhushana Rao, and S Satyanarayana. 2017. An algorithm for identification of natural disaster affected area. <em><em>Journal of Big Data</em></em> 4, 1 (2017), 39.</li>
        <li id="BibPLXBIB0015" label="[15]">Hitoshi Sato, Kunihiro Takeda, Kazuhiro Matsumoto, Hirokazu Anai, and Yuzuru Yamakage. 2016. Efforts for Disaster Prevention/Mitigation to Protect Society from Major Natural Disasters. <em><em>FUJITSU Sci. Tech. J</em></em> 52, 1 (2016), 107–113.</li>
        <li id="BibPLXBIB0016" label="[16]">P Selvaperumal and A Suruliandi. 2014. A short message classification algorithm for tweet classification. In <em><em>Recent Trends in Information Technology (ICRTIT), 2014 International Conference on</em></em> . IEEE, 1–3.</li>
        <li id="BibPLXBIB0017" label="[17]">Karen Simonyan and Andrew Zisserman. 2014. Very Deep Convolutional Networks for Large-Scale Image Recognition. <em><em>CoRR</em></em> abs/1409.1556(2014). arxiv:1409.1556<a class="link-inline force-break" href="http://arxiv.org/abs/1409.1556" target="_blank">http://arxiv.org/abs/1409.1556</a>
        </li>
        <li id="BibPLXBIB0018" label="[18]">Ge Song, Yunming Ye, Xiaolin Du, Xiaohui Huang, and Shifu Bie. 2014. Short Text Classification: A Survey. <em><em>Journal of Multimedia</em></em> 9, 5 (2014).</li>
        <li id="BibPLXBIB0019" label="[19]">Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. Going deeper with convolutions. In <em><em>Proceedings of the IEEE conference on computer vision and pattern recognition</em></em> . 1–9.</li>
        <li id="BibPLXBIB0020" label="[20]">Nataliya Tkachenko, Stephen Jarvis, and Rob Procter. 2017. Predicting floods with Flickr tags. <em><em>PloS one</em></em> 12, 2 (2017), e0172870.</li>
        <li id="BibPLXBIB0021" label="[21]">Brandon Truong, Cornelia Caragea, Anna Squicciarini, and Andrea&nbsp;H Tapia. 2014. Identifying valuable information from twitter during natural disasters. <em><em>Proceedings of the Association for Information Science and Technology</em></em> 51, 1(2014), 1–4.</li>
        <li id="BibPLXBIB0022" label="[22]">Si&nbsp;Si&nbsp;Mar Win and Than&nbsp;Nwe Aung. 2017. Target oriented tweets monitoring system during natural disasters. In <em><em>Computer and Information Science (ICIS), 2017 IEEE/ACIS 16th International Conference on</em></em> . IEEE, 143–148.</li>
        <li id="BibPLXBIB0023" label="[23]">Jun Yan. 2009. <em><em>Text Representation</em></em> . Springer US, Boston, MA, 3069–3072. <a class="link-inline force-break" href="https://doi.org/10.1007/978-0-387-39940-9_420" target="_blank">https://doi.org/10.1007/978-0-387-39940-9_420</a>
        </li>
        <li id="BibPLXBIB0024" label="[24]">Jie Yin, Andrew Lampert, Mark Cameron, Bella Robinson, and Robert Power. 2012. Using social media to enhance emergency situation awareness. <em><em>IEEE Intelligent Systems</em></em> 27, 6 (2012), 52–59.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class="link-inline force-break" href="http://www-nlpir.nist.gov/projects/tv2013/tv2013.html">http://www-nlpir.nist.gov/projects/tv2013/tv2013.html</a></p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break" href="https://developer.twitter.com">https://developer.twitter.com</a></p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>https://multimediaeval.github.io/2017-Multimedia-Satellite-Task/</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&nbsp;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3184558.3191620">https://doi.org/10.1145/3184558.3191620</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
