<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Network Model Selection Using Task-Focused Minimum
  Description Length</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3191525'>https://doi.org/10.1145/3184558.3191525</a> 
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3191525'>https://w3id.org/oa/10.1145/3184558.3191525</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Network Model Selection Using
          Task-Focused Minimum Description Length</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Ivan</span> <span class=
          "surName">Brugere</span> University of Illinois at
          Chicago, Chicago, IL, <a href=
          "mailto:ibruge2@uic.edu">ibruge2@uic.edu</a>
        </div>
        <div class="author">
          <span class="givenName">Tanya Y.</span> <span class=
          "surName">Berger-Wolf</span> University of Illinois at
          Chicago, Chicago, IL, <a href=
          "mailto:tanyabw@uic.edu">tanyabw@uic.edu</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191525"
        target=
        "_blank">https://doi.org/10.1145/3184558.3191525</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Networks are fundamental models for data used in
        practically every application domain. In most instances,
        several implicit or explicit choices about the network
        definition impact the translation of underlying data to a
        network representation, and the subsequent question(s)
        about the underlying system being represented. Users of
        downstream network data may not even be aware of these
        choices or their impacts. We propose a task-focused network
        model selection methodology which addresses several key
        challenges. Our approach constructs network models from
        underlying data and uses minimum description length (MDL)
        criteria for selection. Our methodology measures
        <em>efficiency</em>, a <em>general</em> and comparable
        measure of the network's performance of a local (i.e.
        node-level) predictive task of interest. Selection on
        efficiency favors parsimonious (e.g. sparse) models to
        avoid overfitting and can be applied across arbitrary tasks
        and representations. We show <em>stability, sensitivity,
        and significance testing</em> in our
        methodology.</small></p>
      </div>
      <div class="classifications">
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Ivan Brugere and Tanya Y. Berger-Wolf. 2018. Network
          Model Selection Using Task-Focused Minimum Description
          Length. In <em>WWW '18 Companion: The 2018 Web Conference
          Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon,
          France. ACM, New York, NY, USA</em> 9 Pages. <a href=
          "https://doi.org/10.1145/3184558.3191525" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3191525</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Networks are fundamental models for data used in
      practically every application domain. In most instances,
      several implicit or explicit choices about the network
      definition impact the translation of underlying data to a
      network representation, and the subsequent question(s) about
      the underlying system being represented. Users of downstream
      network data may not even be aware of these choices or their
      impacts. Do these choices yield a model which is actually
      predictive of the underlying system? Can we discover better
      (i.e. more predictive, simpler) models?</p>
      <p>A network derived from some data is often assumed to be a
      true representation of the underlying system. This assumption
      introduces several challenges. First, these relationships may
      be very time-dependent: an aggregation of edges might not
      reflect the behavior of the underlying system at <em>any</em>
      time [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0004">4</a>].
      Second, relationships may be context-dependent: where the
      same network inferred from data predicts one behavior of the
      system but not another [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>]. Any subsequent measurement on the
      network (e.g. degree distribution, diameter, clustering
      coefficient, graph kernels) treats all edges equally, when a
      path or community in the network may only be an error of
      aggregation.</p>
      <p>Task-based network model selection addresses the latter
      challenge by comparing multiple representations for
      predicting a particular behavior (or context) of interest. In
      this context, the network is a space which structures a local
      predictive task (e.g. “my neighbors are most predictive of my
      behavior”), and model selection reports the best
      structure.</p>
      <p>Work in network model selection has typically focused on
      inferring parameters of generative models from a given
      network, according to some structural or spectral features
      (e.g. degree distribution, eigenvalues) [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0023">23</a>]. However, preliminary
      work has extended model selection to criteria on task
      performance with respect to generative models for a given
      network [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0005">5</a>],
      and methodologies representing underlying data as networks
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0003">3</a>].</p>
      <p>We propose a task-focused network model selection
      methodology. Our approach constructs network models from
      underlying data and uses minimum description length (MDL)
      criteria for selection. Our methodology measures
      <em>efficiency</em>, a <em>general</em> and comparable
      measure of the network's performance of a local (i.e.
      node-level) predictive task of interest. This accounts for
      complexity of both the network structure, and predictive
      models. Selection on efficiency favors parsimonious (e.g.
      sparse) models to avoid overfitting and can be applied across
      arbitrary tasks and representations. We show <em>stability,
      sensitivity, and significance testing</em> in our
      methodology.</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3200000/3191525/images/www18companion-264-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">A high-level overview of our methodology.
          <strong>(a)</strong> Given as input: nodes with
          associated attribute and label data, potential network
          structure(s) are optionally provided (dashed lines). We
          use network inference models to construct multiple
          networks from data (note: stack of models).
          <strong>(b)</strong> On each network model, for each node
          ‘<em>i</em>’, we sample nodes (shown by node color) and
          their associated attributes and labels, according to
          different sample methods and node characterization
          heuristics (e.g. ‘high degree’, ‘high activity’).
          <strong>(c)</strong> we generate ‘<em>b</em>’ samples by
          each method at varying sample size <em>k</em>, each row
          is a trained task model (e.g. random forest) to predict
          label ‘<em>i</em>’ (‘yellow’) given sampled attribute
          data and labels. <strong>(d)</strong> we encode each
          collection of task models from (c) and network
          representation from (b) to measure the most
          <em>efficient</em> model for performing the task, and
          <em>select</em> that network representation.</span>
        </div>
      </figure>
      <p></p>
      <section id="sec-4">
        <header>
          <div class="title-info">
            <h3><span class="section-number">1.1</span> Related
            work</h3>
          </div>
        </header>
        <p>Our work is related to network structure inference
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0001">1</a>, <a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0014">14</a>]. This
        area of work constructs a network <em>model</em>
        representation for attributes collected from sensors,
        online user trajectories or other underlying data. Previous
        work has focused on these network representations as models
        of local predictive tasks, performed on groups of entities,
        such as label inference [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0019">19</a>] and link prediction [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0011">11</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0016">16</a>]. A
        ‘good’ network in this setting is one which performs the
        task well, under some measure of robustness, cost, or
        stability. Previous work examined model selection under
        varying network models, single or multiple tasks, and
        varying task methods [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0003">3</a>].</p>
        <p>The minimum description length (MDL) principle
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0021">21</a>] measures
        the representation of an object or a model by its smallest
        possible encoding size in bytes. This principle is used for
        model selection for predictive models, including regression
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0009">9</a>] and
        classification [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0018">18</a>]. MDL methods have also been
        applied for model selection of <em>data
        representations</em> including clusterings, time series
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0009">9</a>, <a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0012">12</a>],
        networks [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0025">25</a>] and network summarization
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0015">15</a>]. MDL has
        been used for structural outlier and change detection in
        dynamic networks [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0022">22</a>]. Our methodology encodes a
        collection of predictive models, together with the
        underlying network representation for model selection. No
        known work encodes both of these objects for model
        selection.</p>
        <p>Several generative models exist to model correlations
        between attributes, labels, and network structure,
        including the the Attributed Graph Model (AGM) [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0020">20</a>], and
        Multiplicative Attribute Graph model (MAG) [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0013">13</a>]. These models are
        additive to our methodology, and could be applied and
        evaluated as potential models within our methodology.</p>
        <p>Our work is orthogonal to graph kernels [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0024">24</a>] and graph embeddings
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0008">8</a>]. These
        methods traverse network structure to extract path features
        and represent nodes in a low-dimensional space, or to
        compare nodes/graphs by shared structural features. We
        treat this graph traversal as one possible query of nodes
        for input to local tasks, but do not compare graphs or
        nodes directly; our focus is to evaluate how well the fixed
        model performs the local task over all nodes.</p>
      </section>
      <section id="sec-5">
        <header>
          <div class="title-info">
            <h3><span class="section-number">1.2</span>
            Contributions</h3>
          </div>
        </header>
        <p>We formulate a task-focused model selection methodology
        for networks.</p>
        <ul class="list-no-style">
          <li id="list1" label="•"><em>Model selection
          methodology</em>: We propose a generalized approach for
          evaluating networks over arbitrary data representations
          for performing particular tasks.<br /></li>
          <li id="list2" label="•"><em>Network efficiency</em>: We
          propose a general minimum description length (MDL)
          <em>efficiency</em> measure on the encoding of network
          representations and task models, which is comparable over
          varying models and datasets.<br /></li>
          <li id="list3" label="•"><em>Validation and
          significance</em> We empirically demonstrate stability,
          sensitivity, and significance testing of our model
          selection methodology.<br /></li>
        </ul>
      </section>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Methods</h2>
        </div>
      </header>
      <p>Figure <a class="fig" href="#fig1">1</a> gives a schematic
      overview of our model selection methodology. In Figure
      <a class="fig" href="#fig1">1</a>(a) as input, we are given
      attribute-set <em>A</em> and label-set <em>L</em> associated
      with entities <em>i</em> ∈ <em>V</em>. Labels are a
      notational convenience to denote an attribute of interest for
      some predictive task (e.g. label inference, link prediction).
      We <em>may</em> be given a network topology (dashed lines),
      which we treat as one possible network model in the
      evaluation.</p>
      <p>We apply a collection of network inference methods to
      generate separate network topologies. In Figure <a class=
      "fig" href="#fig1">1</a>(b), for each network topology, we
      use several network sampling methods to sample attribute and
      label data for input to a supervised
      classification/regression task. Boxes indicate different node
      characterization heuristics which can be sampled: ‘high
      degree’, ‘high activity’, or ‘communities’. Node colors
      indicate one sample from each of sampling method with respect
      to node <em>i</em>: green nodes denote a <em>local</em>,
      orange nodes denote a <em>community</em> sample (the same
      node in two samples indicated by two-color nodes). Purple is
      a sample of <em>high-degree</em> nodes. Blue represents a
      sample of high-activity nodes (e.g users with the most
      interactions, most purchases, most ratings), and cyan
      represents a random sample of nodes.</p>
      <p>In Figure <a class="fig" href="#fig1">1</a>(c), each
      network sample method produces samples of length <em>k</em>,
      and is repeatedly sampled to create <em>b</em> supervised
      classification instances per method. Each row corresponds to
      a supervised classification task trained on attributes and
      labels in the sample, to predict the label of <em>i</em>
      (e.g. ‘yellow’). Finally, in Figure <a class="fig" href=
      "#fig1">1</a>(d), we encode the predictive models (e.g. the
      coefficients of an SVM hyper-plane or random forest trees)
      and the network in an efficient byte-string representation,
      and evaluate the best model using minimum description length
      (MDL) criteria. We propose a general and interpretable
      measure of <em>efficiency</em> for solving our task of
      interest, and show stability and significance testing over
      our collection of models.</p>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span>
            Preliminaries and notation</h3>
          </div>
        </header>
        <p>Let <em>V</em> = {1..., <em>i</em>..., <em>n</em>} be a
        set of entities to which we refer to as ‘nodes.’ Let
        <span class="inline-equation"><span class="tex">$A=\lbrace
        \vec{a}_i\rbrace$</span></span> be a set of
        attribute-vectors and <em>L</em> = {<em>l<sub>i</sub></em>
        } be a set of target labels of interest to be learned,
        where <em>i</em> ∈ <em>V</em>. Let <span class=
        "inline-equation"><span class="tex">$\mathcal {Q}:V\times
        \mathbf {Z}^+ \rightarrow V^k$</span></span> be a network
        query function (see the full definition below) that
        produces query-sets of nodes <em>S</em>⊆<em>V</em> of a
        given size <em>k</em>. Let <span class=
        "inline-equation"><span class="tex">$\mathcal {C}:A\times L
        \rightarrow L$</span></span> be a classifier trained on
        attributes and labels of a node subset <em>S</em> to
        produce a prediction <span class=
        "inline-equation"><span class="tex">$l^{\prime
        }_i$</span></span> , for node <em>i</em>.<a class="fn"
        href="#fn1" id="foot-fn1"><sup>1</sup></a></p>
      </section>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Network
            query functions</h3>
          </div>
        </header>
        <p>In our methodology, we access the network for our given
        objective using a <em>network query function</em> on node
        <em>i</em>, which returns a set of nodes of arbitrary size
        subject to the network topology and function
        definition.</p>
        <p>To compare different query functions under similar
        output, we introduce a bounded query of size <em>k</em>.
        With an input of node <em>i</em> and search size
        <em>k</em>, bounded network query function <span class=
        "inline-equation"><span class="tex">$\mathcal
        {Q}$</span></span> outputs a set of unique nodes:</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathcal
            {Q}(i, k) \rightarrow \lbrace j_{1},
            j_{2},...,j_{k}\rbrace , \text{ where } i \notin
            \lbrace j_{1},...,j_{k}\rbrace
            \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>In general, these queries sample from the possible
        node-sets, yielding different result-set samples on a
        repeated input <em>i</em>. We measure these functions over
        a distribution of node-set samples, with replacement,
        analogous to the bootstrap sample [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0006">6</a>].
        <p></p>
        <p>Network <em>adjacency</em> is one such query method,
        which randomly samples from <span class=
        "inline-equation"><span class="tex">${\mathcal {N}(i)
        \choose k}$</span></span> subsets, with replacement.
        Breadth-first search <span class=
        "inline-equation"><span class="tex">$\mathcal {Q}_{\texttt
        {bfs}}(i,k,E)$</span></span> generalizes adjacency to
        higher-order neighbors, where nodes in the farthest level
        is selected at random. Over varying query size <em>k</em>,
        breadth-first search is well-suited for measuring the
        performance of the network in finding relevant nodes
        ‘nearer’ to the query.</p>
        <p>While <span class="inline-equation"><span class=
        "tex">$\mathcal {Q}$</span></span> may sample an underlying
        network edge-set <em>E</em>, our methodology evaluates any
        network query function, regardless of underlying
        implementation. In geometric space, <span class=
        "inline-equation"><span class="tex">$\mathcal
        {Q}_{l_2}$</span></span> may sample nodes in increasing
        Euclidean distance from <em>i</em>. Query heuristics can
        also be derived from the attribute-set <em>A</em>. For
        example, <span class="inline-equation"><span class=
        "tex">$\mathcal {Q}_{\texttt {activity-net}}(i, k,
        A)$</span></span> (defined below) may query points by the
        number of non-zero attributes or some other attribute
        function, and sample according to some similarity to
        <em>i</em>.</p>
        <section id="sec-9">
          <p><em>2.2.1 Network efficiency.</em> We evaluate each
          network query function according to a minimum description
          length (MDL) criterion. We repeatedly sample <span class=
          "inline-equation"><span class="tex">$\mathcal {Q}_r(i,
          k)$</span></span> (<em>r</em> for ‘rule’), to construct
          <em>b</em> samples of attribute vectors and labels, of
          size <em>k</em>. We train each classifier <span class=
          "inline-equation"><span class="tex">$\mathcal
          {C}(A[S],L[S])$</span></span> from these attribute and
          label data. Let <em>C<sub>r</sub></em> [<em>i</em>,
          <em>k</em>] be the resulting set of trained
          classifiers:</p>
          <div class="table-responsive" id="Xeq1">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation}
              \begin{aligned} C_r[i,k]= \lbrace \mathcal
              {C}(A[\mathcal {Q}_r(i,k)_1], L[\mathcal
              {Q}_r(i,k)_1]),...\\\mathcal {C}(A[\mathcal
              {Q}_r(i,k)_b], L[\mathcal {Q}_r(i,k)_b])\rbrace
              _{|b|} \end{aligned} \end{equation}</span><br />
              <span class="equation-number">(2)</span>
            </div>
          </div>Let <span class="inline-equation"><span class=
          "tex">$\mathop{correct}(C_r[i,k])$</span></span> be the
          sum of correct predictions of the <em>b</em> task
          classifiers on test input <span class=
          "inline-equation"><span class="tex">$\mathcal
          {C}_r(\vec{a_i}, l_i)$</span></span> .
          <p></p>
          <div class="definition" id="enc1">
            <label>Definition 2.1.</label>
            <p>The <em>efficiency</em> of a network query function
            <span class="inline-equation"><span class=
            "tex">$\mathcal {Q}_r$</span></span> with respect to a
            node <em>i</em> is the number of correct predictions
            per byte (higher is better). The efficiency
            <span class="inline-equation"><span class=
            "tex">$\mathcal {E}$</span></span> is the maximum given
            by the value of <em>k</em> which yields the maximum of
            correct predictions divided by the median encoding
            cost, both aggregates of <em>b</em> samples:</p>
            <div class="table-responsive" id="eq2">
              <div class="display-equation">
                <span class="tex mytex">\begin{equation} \mathcal
                {E}(\mathcal {Q}_r, i) = \max _k\left\lbrace
                {\frac{\mathop{correct}(C_r[i,k])}{\mathop{med}_b(\mathop{bytes}(C_r[i,k]))}}\right\rbrace
                . \end{equation}</span><br />
                <span class="equation-number">(3)</span>
              </div>
            </div>
            <p></p>
          </div>
          <p>Let <span class="inline-equation"><span class=
          "tex">$\kappa _i=\mathop{argmax}_{k}\mathcal {E}(\mathcal
          {Q}_r, i)$</span></span> , the <em>k</em> associated with
          the maximum efficiency of node <em>i</em>. We then sum
          <span class="inline-equation"><span class=
          "tex">$\mathop{bytes}(\mathcal {C}_r[i,\kappa
          _i])$</span></span> and <span class=
          "inline-equation"><span class=
          "tex">$\mathop{correct}(\mathcal {C}_r[i,\kappa
          _i])$</span></span> over all <em>i</em> to get efficiency
          over task models trained on samples from <span class=
          "inline-equation"><span class="tex">$\mathcal
          {Q}_r$</span></span> . We also encode <span class=
          "inline-equation"><span class="tex">$\mathcal
          {Q}_r$</span></span> and measure its
          <em>representation</em> cost:</p>
          <div class="table-responsive" id="eq3">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation}
              \begin{split} \mathop{correct}(\mathcal {C}_r){} =
              \sum _i\mathop{correct}(\mathcal {C}_r[i, \kappa
              _i])\\\mathop{bytes}(\mathcal {C}_r){} =\sum
              _i\mathop{bytes}(\mathcal {C}_r[i,\kappa _i])
              \end{split} \end{equation}</span><br />
              <span class="equation-number">(4)</span>
            </div>
          </div>Then, the overall efficiency of <span class=
          "inline-equation"><span class="tex">$\mathcal
          {Q}_r$</span></span> is given by:
          <div class="table-responsive" id="eq4">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} \mathcal
              {E}(\mathcal {Q}_r)= \frac{\mathop{correct}(\mathcal
              {C}_r)}{\mathop{bytes}(\mathcal {C}_r)+
              \mathop{bytes}(\mathcal {Q}_r)}.
              \end{equation}</span><br />
              <span class="equation-number">(5)</span>
            </div>
          </div>
          <p></p>
          <p>Encoding the function <span class=
          "inline-equation"><span class="tex">$\mathcal
          {Q}_r$</span></span> favors parsimonious models and
          avoids overfitting the representation to evaluation
          criteria such as accuracy or precision. However, such
          encoding requires careful consideration of the underlying
          representation, which we cover in Section <a class="sec"
          href="#sec-12">2.4.1</a>. Omitting the encoding cost of
          <span class="inline-equation"><span class="tex">$\mathcal
          {Q}_r$</span></span> in Equation <a class="eqn" href=
          "#eq4">5</a> measures only the extent to which the
          network query function trains ‘good’ task models in its
          top-<em>k</em> samples. This is suitable if we are not
          concerned with the structure of the underlying
          representation, such as its sparsity. To favor
          interpretability of efficiency in real units
          (correct/byte), we avoid weight factors for the terms in
          the efficiency definition. However, in practice this
          would provide more flexibility to constrain one of these
          criteria.</p>
        </section>
      </section>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.3</span> Problem
            statement</h3>
          </div>
        </header>
        <p>We can now formally define our model selection problem,
        including inputs and outputs:</p>
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191525/images/www18companion-264-fig2.jpg"
          class="img-responsive" alt="" longdesc="" />
        </figure>
        <p></p>
        <p>For brevity, we refer to ‘model selection’ simply as
        selecting the network representation and its associated
        network query function for our task of interest. The
        underlying query functions in set <em>Q</em> may be
        implemented as arbitrary representations which can be
        randomly sampled (e.g. lists). This model selection
        methodology measures, for example whether a network is a
        better model than other non-network sampling heuristics,
        group-level sampling (e.g. communities), etc. accounting
        for representation cost of each. That is, whether a network
        is necessary in the first place. As a consequence, we may
        select a different queried representation than a
        network.</p>
        <p>Previous work has evaluated network model-selection for
        robustness to multiple tasks (e.g. link prediction, label
        prediction) as well as different underlying task models
        (e.g. random forests, support vector machines) [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0003">3</a>]. Problem
        1 can straightforwardly select over varying underlying
        network models, tasks, or task models which maximize
        efficiency. We simplify the selection criteria to focus on
        measuring the efficiency of network query functions and
        their underlying representations, but this current work is
        complimentary to evaluating over larger parameter-spaces
        and model-spaces.</p>
      </section>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.4</span> Network
            models</h3>
          </div>
        </header>
        <p>We define several networks queried by network query
        functions <span class="inline-equation"><span class=
        "tex">$\mathcal {Q}_r$</span></span> . Our focus is not to
        propose a novel network inference model from attribute and
        label data (see: [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0013">13</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0020">20</a>]). Instead we apply existing common
        and interpretable network models to demonstrate our
        framework. The <em>efficiency</em> of any novel network
        inference model should be evaluated against these
        baselines.</p>
        <p>A network model <span class=
        "inline-equation"><span class="tex">$\mathcal
        {M}$</span></span> constructs an edge-set from node
        attributes and/or labels: <span class=
        "inline-equation"><span class="tex">$\mathcal {M}_j:
        \mathcal {M}_j(A,L) \rightarrow E_j$</span></span> . We use
        simple <em>k</em>-nearest neighbor (<tt>KNN</tt>) and
        Threshold (<tt>TH</tt>) models common in many domains.</p>
        <p>Given a similarity measure <span class=
        "inline-equation"><span class="tex">$\mathrm{d}(\vec{a}_i,
        \vec{a}_j) \rightarrow s_{ij}$</span></span> and a target
        edge count <em>ρ</em>, this measure is used to produces a
        pairwise attribute similarity space. We select edges
        by:</p>
        <ul class="list-no-style">
          <li id="list4" label="•"><em>k</em>-nearest neighbor
          <span class="inline-equation"><span class="tex">$\mathcal
          {M}_{\texttt {KNN}}(A, \mathrm{d}(), \rho)$</span></span>
          : for a fixed <em>i</em>, select the top <span class=
          "inline-equation"><span class="tex">$\lfloor {\frac{\rho
          }{|V|}}\rfloor$</span></span> most similar <span class=
          "inline-equation"><span class=
          "tex">$\mathrm{d}(\vec{a}_i, \lbrace A \setminus
          \vec{a}_i\rbrace)$</span></span> . In directed networks,
          this produces a network which is <em>k</em>-regular in
          out-degree, with <span class=
          "inline-equation"><span class="tex">$k=\lfloor
          {\frac{\rho }{|V|}}\rfloor$</span></span> .<br /></li>
          <li id="list5" label="•">Threshold <span class=
          "inline-equation"><span class="tex">$\mathcal
          {M}_{\texttt {TH}}(A, \mathrm{d}(), \rho)$</span></span>
          : over all pairs (<em>i</em>, <em>j</em>) ∈ <em>V</em>
          select the top <em>ρ</em> most similar <span class=
          "inline-equation"><span class=
          "tex">$\mathrm{d}(\vec{a}_i, \vec{a}_j)$</span></span>
          .<br /></li>
        </ul>
        <p>Let these edge-sets be denoted <span class=
        "inline-equation"><span class="tex">$E_{\texttt
        {KNN}}$</span></span> and <span class=
        "inline-equation"><span class="tex">$E_{\texttt
        {TH}}$</span></span> , respectively. We use varying network
        sparsity (<em>ρ</em>) on these network models to choose
        ‘sparse’ or ‘dense’ models. Similarity measures may vary
        greatly by application. In our context, attribute data are
        counts and numeric ratings of items (e.g. films, music
        artists) per user. We use a sum of intersections
        (unnormalized), which favors higher activity and does not
        penalize mismatches:</p>
        <div class="table-responsive" id="Xeq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            \begin{aligned} \mathrm{d}_{INT}(\vec{a}_i, \vec{a}_j)
            = \sum \nolimits _l \mathrm{min}(a_{il}, a_{jl})
            \end{aligned} \end{equation}</span><br />
            <span class="equation-number">(6)</span>
          </div>
        </div>
        <p></p>
        <section id="sec-12">
          <p><em>2.4.1 Encoding networks and tasks.</em> Table
          <a class="tbl" href="#tab1">1</a> summarizes the network
          query functions (Equation <a class="eqn" href=
          "#eq1">1</a>) used in our methodology, and their inputs.
          We define only a small number of possible functions,
          focusing on an interpretable set which helps
          characterizes the underlying data. The encoding cost
          increases from top to bottom.<a class="fn" href="#fn2"
          id="foot-fn2"><sup>2</sup></a></p>
          <p><tt>activity-top</tt> and <tt>degree-top</tt> are the
          simplest network query functions we define.
          <tt>activity-top</tt> sorts nodes by ‘activity’, i.e. the
          number of non-zero attributes in <span class=
          "inline-equation"><span class=
          "tex">$\vec{a}_i$</span></span> , and selects the top-ℓ
          ranked nodes (ℓ &lt; &lt; |<em>V</em>|). An ordering is
          generated by random sub-sampling of this list.
          <tt>degree-top</tt> does similar on node degree with
          respect to some input <em>E</em>.</p>
          <p><tt>cluster</tt> applies graph clustering (i.e.
          community detection) on the input edge-set <em>E</em>.
          This reduces the network to a collection of lists
          representing community affiliation. Each node is
          affiliated with at most one community label. Although
          both <tt>degree-top</tt> and <tt>cluster</tt> are derived
          from an underlying network, we only encode the reduced
          representation. This is by design, to measure whether the
          network is better represented by a simple ranking
          function which we represent in <span class=
          "inline-equation"><span class="tex">$\mathcal
          {O}(\ell)$</span></span> space, a collection of groups in
          <span class="inline-equation"><span class="tex">$\mathcal
          {O}(|V|)$</span></span> space, or edges in <span class=
          "inline-equation"><span class="tex">$\mathcal
          {O}(|E|)$</span></span> space. <tt>random</tt> produces
          random node subset, encoded in <span class=
          "inline-equation"><span class="tex">$\mathcal
          {O}(|V|)$</span></span> space.</p>
          <p><tt>bfs</tt> is a breadth-first search of an
          underlying edge-set <em>E</em> from seed <em>i</em>. This
          is encoded by an adjacency list (a list of lists), in
          <span class="inline-equation"><span class="tex">$\mathcal
          {O}(|E|)$</span></span> . <tt>degree-net</tt> is an
          ad-hoc network with all out-edges to some node in the
          top-ℓ nodes of <tt>degree-top</tt>. For each node
          <em>i</em>, we select <em>m</em> &lt; ℓ most similar
          nodes and define out-edges from <em>i</em>. This is a
          <tt>KNN</tt> graph, where <em>k</em> = <em>m</em>,
          constrained to high-degree nodes. This additional
          encoding cost relative to <tt>degree-top</tt> measures
          the extent that specialization exists in the top-ranked
          individuals as a set of task ‘exemplars’ for all nodes.
          <tt>activity-net</tt> is defined analogously with respect
          to <tt>activity-top</tt>.</p>
          <div class="table-responsive" id="tab1">
            <div class="table-caption">
              <span class="table-number">Table 1:</span>
              <span class="table-title">The input signature and
              space complexity of network query functions. We
              define four functions implemented by non-network
              structures (top), and three implemented by a network
              (bottom)</span>
            </div>
            <table class="table">
              <tbody>
                <tr>
                  <td style="text-align:left;">Network Query
                  Function</td>
                  <td style="text-align:center;">Encoding</td>
                </tr>
                <tr>
                  <td style="text-align:left;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {Q}_{\texttt
                  {activity-top}}(i,k,\mathrm{sort}(A),\ell)$</span></span></td>
                  <td style="text-align:center;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {O}(\ell)$</span></span></td>
                </tr>
                <tr>
                  <td style="text-align:left;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {Q}_{\texttt
                  {degree-top}}(i,k,\mathrm{sort}(E),\ell)$</span></span></td>
                  <td style="text-align:center;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {O}(\ell)$</span></span></td>
                </tr>
                <tr>
                  <td style="text-align:left;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {Q}_{\texttt
                  {cluster}}(i,k,\mathrm{cluster}(E))$</span></span></td>
                  <td style="text-align:center;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {O}(|V|)$</span></span></td>
                </tr>
                <tr>
                  <td style="text-align:left;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {Q}_{\texttt {random}}(i,k,V)$</span></span></td>
                  <td style="text-align:center;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {O}(|V|)$</span></span></td>
                </tr>
                <tr>
                  <td style="text-align:left;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {Q}_{\texttt {bfs}}(i,k,E)$</span></span></td>
                  <td style="text-align:center;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {O}(|E|)$</span></span></td>
                </tr>
                <tr>
                  <td style="text-align:left;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {Q}_{\texttt
                  {activity-net}}(i,k,\mathrm{sort}(A),m,\ell)$</span></span></td>
                  <td style="text-align:center;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {O}(|V|\times m)$</span></span></td>
                </tr>
                <tr>
                  <td style="text-align:left;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {Q}_{\texttt
                  {degree-net}}(i,k,\mathrm{sort}(E),m,\ell)$</span></span></td>
                  <td style="text-align:center;"><span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {O}(|V|\times m)$</span></span></td>
                </tr>
              </tbody>
            </table>
          </div>
          <p>To demonstrate our methodology, we use Random Forest
          task models. Each decision tree is encoded as a tuple of
          lists which represent left and right branches, associated
          feature ids, and associated decision thresholds. The
          random forest is then a list of these individual tree
          representations.</p>
        </section>
      </section>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.5</span> Measuring
            efficiency</h3>
          </div>
        </header>
        <p>All of our network query functions and task models can
        now be represented as a byte-encodable object ‘o’ (e.g.
        lists). Therefore, we can now measure efficiency (Equation
        <a class="eqn" href="#eq4">5</a>). To implement our
        <span class="inline-equation"><span class=
        "tex">$\mathop{bytes}(o)$</span></span> function estimating
        the minimum description length, we convert each object
        representation to a byte-string using the msgpack
        library,<a class="fn" href="#fn3" id=
        "foot-fn3"><sup>3</sup></a> We then use LZ4
        compression,<a class="fn" href="#fn4" id=
        "foot-fn4"><sup>4</sup></a> (analogous to zip) which uses
        Huffman coding to reduce the cost of the most common
        elements in the representation string (e.g high degree
        nodes, frequent features in the random forest). Both of
        these methods are chosen simply by necessity for runtime
        performance. Finally, we report the length of the
        compressed byte-string:</p>
        <div class="table-responsive" id="Xeq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            \mathop{bytes}(o) =
            |\mathrm{lz4.dumps}(\mathrm{msgpack.dumps}(o))|
            \end{equation}</span><br />
            <span class="equation-number">(7)</span>
          </div>
        </div>
        <p></p>
        <section id="sec-14">
          <p><em>2.5.1 Network query reach.</em> Let
          reach(<em>C<sub>r</sub></em> ) the reach-set of
          <em>C<sub>r</sub></em> be the set of nodes accessed at
          least <em>once</em> to train <em>any</em> model in
          <em>C<sub>r</sub></em> . We define <span class=
          "inline-equation"><span class="tex">$\mathcal
          {Q}^{*}_r$</span></span> as the representation of
          <span class="inline-equation"><span class="tex">$\mathcal
          {Q}_r$</span></span> including only nodes in the
          reach-set. If the underlying representation of
          <span class="inline-equation"><span class="tex">$\mathcal
          {Q}_r$</span></span> is a graph, the <span class=
          "inline-equation"><span class="tex">$\mathcal
          {Q}^{*}_r$</span></span> representation is an induced
          subgraph where <em>both</em> nodes incident to an edge
          are in the reach-set. If <span class=
          "inline-equation"><span class="tex">$\mathcal
          {Q}_r$</span></span> is represented as a list, we simply
          remove elements not in the reach-set.</p>
          <p>The encoding size <span class=
          "inline-equation"><span class=
          "tex">$\mathop{bytes}(\mathcal {Q}^*_r)$</span></span>
          measures only the underlying representation accessed for
          the creation of the <em>C<sub>r</sub></em> task model
          set. This is a more appropriate measure of the
          representation cost, where in practice
          |reach(<em>C<sub>r</sub></em> )| &lt; &lt; |<em>V</em>|.
          For our evaluation, we always report <span class=
          "inline-equation"><span class="tex">$\mathcal
          {E}(\mathcal {Q}^*_r)$</span></span> .</p>
        </section>
      </section>
    </section>
    <section id="sec-15">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Datasets</h2>
        </div>
      </header>
      <p>We demonstrate our model selection methodology on label
      prediction tasks of three different online user activity
      datasets with high-dimensional attributes: beer review
      history from BeerAdvocate, music listening history from
      Last.fm, and movie rating history from MovieLens.</p>
      <div class="table-responsive" id="tab2">
        <div class="table-caption">
          <span class="table-number">Table 2:</span> <span class=
          "table-title">A summary of datasets in this paper.
          |<em>L</em>| reports the total number of positive node
          labels over 8 labelsets.</span>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <td style="text-align:center;">Dataset</td>
              <td style="text-align:center;">|<em>V</em>|</td>
              <td style="text-align:center;">|<em>A</em>|</td>
              <td style="text-align:center;">Labels</td>
              <td style="text-align:center;">|<em>L</em>|</td>
            </tr>
            <tr>
              <td style="text-align:center;">
                Last.fm 20K [<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0002">2</a>]
              </td>
              <td style="text-align:center;">19,990</td>
              <td style="text-align:center;">1.2B</td>
              <td style="text-align:center;">8</td>
              <td style="text-align:center;">16628</td>
            </tr>
            <tr>
              <td style="text-align:center;">
                MovieLens [<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0010">10</a>]
              </td>
              <td style="text-align:center;">138,493</td>
              <td style="text-align:center;">20M</td>
              <td style="text-align:center;">8</td>
              <td style="text-align:center;">43179</td>
            </tr>
            <tr>
              <td style="text-align:center;">
                BeerAdvocate [<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0017">17</a>]
              </td>
              <td style="text-align:center;">33,387</td>
              <td style="text-align:center;">1.5M</td>
              <td style="text-align:center;">8</td>
              <td style="text-align:center;">13079</td>
            </tr>
          </tbody>
        </table>
      </div>
      <section id="sec-16">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span>
            Last.fm</h3>
          </div>
        </header>
        <p>Last.fm is a social network focused on music listening,
        logging and recommendation. Previous work collected the
        entirety of the social network and associated listening
        history, comparing the social network to alternative
        network models for music genre label prediction [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0002">2</a>].</p>
        <p>Sparse attribute vectors <span class=
        "inline-equation"><span class="tex">$\vec{a}_i\in
        A$</span></span> correspond to counts of artist plays,
        where a non-zero element is the number of times user
        <em>i</em> has played a particular unique artist. Last.fm
        also has an explicit ‘friendship’ network declared by
        users. We treat this as another possible network model,
        denoted as <span class="inline-equation"><span class=
        "tex">$E_{\texttt {social}}$</span></span> , and evaluate
        it against others.</p>
        <p>We evaluate the efficiency of network query functions
        for the label classification task of predicting whether
        user ‘<em>i</em>’ is a listener of a particular genre. A
        user is a ‘listener’ of an artist if they have at least 5
        plays of that artist. A user is a ‘listener’ of a genre if
        they are a listener of at least 5 artists in the top-1000
        most tagged artists with that genre tag, provided by users.
        We select a subset of 8 of these genre labels (e.g. ‘dub’,
        ‘country’, ‘piano’), chosen by guidance of label
        informativeness from previous work [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0002">2</a>].</p>
      </section>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span>
            MovieLens</h3>
          </div>
        </header>
        <p>MovieLens is a movie review website and recommendation
        engine. The MovieLens dataset [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0010">10</a>] contains 20M numeric scores (1-5
        stars) over 138K users.</p>
        <p>Sparse non-zero attribute values corresponds to a user's
        ratings of unique films. We select the most frequent
        user-generated tag data which corresponds to a variety of
        mood, genre, or other criteria of user interest (e.g.
        ‘inspirational’, ‘anime’, ‘based on a book’). We select 8
        tags based on decreasing prevalence (i.e. ‘horror’,
        ‘musical’, ‘Disney’), and predict whether a user is a
        ‘viewer’ of films of this tag (defined similarly to Last.fm
        listenership), using attributes and labels sampled by the
        network query function.</p>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span>
            BeerAdvocate</h3>
          </div>
        </header>
        <p>BeerAdvocate is a website containing text reviews and
        numerical scores of beers by users. Each beer is associated
        with a category label (e.g. ‘American Porter’,
        ‘Hefeweizen’). We select 8 categories according to
        decreasing prevalence of the category label. We predict
        whether the user is a ‘reviewer’ of a certain category of
        beer (defined similarly to Last.fm listenership).</p>
      </section>
      <section id="sec-19">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.4</span> Network and
            label sparsity</h3>
          </div>
        </header>
        <p>When building <tt>KNN</tt>&nbsp;and
        <tt>TH</tt>&nbsp;representations of our data, we construct
        both ‘dense’ and ‘sparse’ models, according to edge
        threshold <em>ρ</em>. For Last.fm, we fix <span class=
        "inline-equation"><span class="tex">$\rho = |E_{\texttt
        {social}}|$</span></span> for the dense network, and
        <span class="inline-equation"><span class="tex">$\rho = 0.5
        \times |E_{\texttt {social}}|$</span></span> for the
        sparse. For both BeerAdvocate and MovieLens, a network
        density of 0.01 represents a ‘dense’ network, and 0.0025 a
        ‘sparse’. However, all of these networks are still ‘sparse’
        by typical definitions.</p>
        <p>User labels on all three datasets are binary (‘this’
        user is a listener/reviewer of ‘this’ genre/category), and
        sparse. We therefore use a label ‘oracle’ and present only
        positive-label classification problems. This allows us to
        evaluate only distinguishing listeners etc. rather than
        learning null-label classifiers where label majority is
        always a good baseline.</p>
        <p>Table <a class="tbl" href="#tab2">2</a> (|<em>L</em>|
        columns) reports the count of non-zero labels over all 8
        labelsets. This is the total number of nodes on which
        evaluation was performed. The <em>total</em> number of task
        models instantiated per network query function is, thus,
        <em>b</em> × |<em>K</em>| × |<em>L</em>|. Each local task
        model can be independently evaluated, allowing us to scale
        arbitrarily.</p>
      </section>
      <section id="sec-20">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.5</span> Validation
            and testing</h3>
          </div>
        </header>
        <p>Following Brugere et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0003">3</a>], for each of the three
        datasets, we split data into temporally contiguous
        ‘validation,’ ‘training,’ and ‘testing,’ partitions of
        approximately 1/3 of each dataset. Training is on the
        middle third, validation is the segment prior, and testing
        on the latter segment. Model selection is performed on
        validation, and this model is evaluated on testing.</p>
      </section>
    </section>
    <section id="sec-21">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Evaluation</h2>
        </div>
      </header>
      <p>In this evaluation, we demonstrate robustness of our
      sampling strategy for stable model ranking, as well as
      present model significance testing and sensitivity to
      noise.</p>
      <section id="sec-22">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Bootstrap
            and rank stability</h3>
          </div>
        </header>
        <p>We evaluate our methodology over <em>b</em> = 20 samples
        of varying size <em>K</em> = [25, 50, ...150] for a total
        of <em>b</em> × |<em>K</em>| task instances to evaluate
        node <em>i</em> on a given label.</p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191525/images/www18companion-264-fig3.jpg"
          class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">(Left) A distribution of the
            coefficient of variation (<em>μ</em>/<em>σ</em>) over
            <em>b</em> = 20 samples for a particular
            <em>C<sub>r</sub></em> [<em>i</em>, <em>k</em>] set of
            classification instances, for Last.fm <tt>social</tt>.
            This estimates the median of <em>b</em> = 100 with low
            error (≤ 0.02). (Right) The change in efficiency
            between validation and testing partitions: <span class=
            "inline-equation"><span class="tex">$\mathcal
            {E}(\mathcal {Q}_{r, test})-\mathcal {E}(\mathcal
            {Q}_{r,validation})$</span></span> .</span>
          </div>
        </figure>
        <p></p>
        <p>We now test the stability our choice of sampling
        parameters, over <em>b</em>, and across partitions. Figure
        <a class="fig" href="#fig3">2</a> (Left) reports the
        coefficient of variation (<em>μ</em>/<em>σ</em>) of task
        encoding costs for the <em>b</em> classifiers in
        <em>C<sub>r</sub></em> [<em>i</em>, <em>k</em>]. These are
        smaller for the <tt>social</tt>-<tt>bfs</tt> model on
        Last.fm than for <tt>social</tt>-<tt>random</tt>. The
        median of these distributions at <em>b</em> = 20 estimates
        the median at <em>b</em> = 100 with low error (≤ 0.02) for
        a selection of models verified. Figure <a class="fig" href=
        "#fig3">2</a> (Right) reports the signed difference in
        efficiency between models on the test and validation
        partition. The models with <em>Δ</em>efficiency &gt; 0.004
        (or an increase of 250 bytes/correct) are all <tt>bfs</tt>
        on MovieLens, which may be a legitimate change in
        efficiency. This shows that our measurements are robust for
        estimating encoding cost at <em>k</em>, and efficiency is
        stable across partitions.</p>
        <p>We test the stability of <span class=
        "inline-equation"><span class="tex">$\mathcal {E}(\mathcal
        {Q}_r)$</span></span> and its correlation to correct
        predictions. Table <a class="tbl" href="#tab3">3</a> (Top)
        reports the Kendall's tau rank order statistic measuring
        correlation between the ‘efficiency’ ranking of models.
        This further shows stability in the models between
        validation and testing partitions. Table <a class="tbl"
        href="#tab3">3</a> (Bottom) in contrast reports the
        <em>τ</em> between the ranked models according to
        efficiency, and according to correct predictions. Within
        the same partition, this rank correlation is lower than the
        efficiency rank correlation <em>across</em> partitions.
        This means that efficiency is quite stable in absolute
        error and relative ranking, and efficiency ranking is not
        merely a surrogate for ranking by correct prediction. Were
        this true, we would not need to encode the model. Nor are
        the ranks of these measures completely
        <em>uncorrelated</em>.</p>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class=
            "table-title">(Top) The Kendall's tau rank correlation
            coefficient between model efficiency of validation vs.
            test partitions. (Bottom) <em>τ</em> rank correlation
            between efficiency and correct predictions.</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td colspan="4" style="text-align:center;">
                  <em>τ</em>, <span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {E}(\mathcal {Q}_r)$</span></span> , Validation
                  vs. Test
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">Last.fm</td>
                <td style="text-align:center;">MovieLens</td>
                <td style="text-align:center;">BeerAdvocate</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>τ</em></td>
                <td style="text-align:center;">0.89</td>
                <td style="text-align:center;">0.61</td>
                <td style="text-align:center;">0.82</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <em>p</em>-value</td>
                <td style="text-align:center;">1e-8</td>
                <td style="text-align:center;">5e-4</td>
                <td style="text-align:center;">3e-6</td>
              </tr>
              <tr>
                <td colspan="4" style="text-align:center;">
                  <em>τ</em>, <span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {E}(\mathcal {Q}_r)$</span></span> vs.
                  <span class="inline-equation"><span class=
                  "tex">$\mathop{correct}(\mathcal
                  {C}_r)$</span></span> (validation)
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>τ</em></td>
                <td style="text-align:center;">0.73</td>
                <td style="text-align:center;">0.38</td>
                <td style="text-align:center;">0.70</td>
              </tr>
              <tr>
                <td style="text-align:center;">
                <em>p</em>-value</td>
                <td style="text-align:center;">3e-6</td>
                <td style="text-align:center;">0.03</td>
                <td style="text-align:center;">7e-5</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-23">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Efficiency
            features</h3>
          </div>
        </header>
        <p>Our definition of efficiency yields interpretable
        features which can characterize models and compare
        datasets. First, we compare the model and task encoding
        cost by calculating the ratio of model encoding cost to the
        total cost of encoding the model and collection of task
        models.</p>
        <p>Second, recall that in the efficiency definition, we
        select the most efficient <em>κ<sub>i</sub></em> per node
        <em>i</em>, with <em>κ<sub>i</sub></em> ≤ 150 in our
        evaluation. This gives the model flexibility to search
        deeper in the query function for each <em>i</em>. Nodes
        with higher <em>κ<sub>i</sub></em> are likely harder to
        classify because the task encoding is typically more
        expensive with more attribute-vector instances.</p>
        <p>Figure <a class="fig" href="#fig4">3</a> compares the
        ratio of model and total encoding costs (x-axis) vs. the
        mean over all <em>κ<sub>i</sub></em> (y-axis). The models
        roughly order left-to-right on the x-axis according to
        Table <a class="tbl" href="#tab1">1</a>.</p>
        <p>All non-network models (<tt>activity-top</tt>,
        <tt>degree-top</tt>, <tt>cluster</tt>, <tt>random</tt>) are
        consistently inexpensive vs. their task models, but several
        also select a higher <em>κ<sub>i</sub></em> . In contrast,
        the <tt>degree-net</tt> and <tt>activity-net</tt> models
        are consistently costlier because they encode a fixed
        <em>m</em> &gt; max (<em>K</em>) in order to sample at each
        value <em>k</em>. All ‘sorted’ models (network and
        non-network) tend to be most efficient at a lower
        <em>κ<sub>i</sub></em> . This may indicate these sorted
        nodes are more informative per instance, and each
        additional instance is more costly to incorporate into task
        models. Finally, <tt>bfs</tt> has high variance in encoding
        cost ratio depending on the <em>reach</em> of the
        underlying topology (Section <a class="sec" href=
        "#sec-14">2.5.1</a>).</p>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191525/images/www18companion-264-fig4.jpg"
          class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">The mean over all
            <em>κ<sub>i</sub></em> : mean <sub><em>i</em></sub>
            (<em>κ<sub>i</sub></em> ) vs. the ratio of model cost
            by the total encoding cost: <span class=
            "inline-equation"><span class=
            "tex">$\mathop{bytes}(\mathcal
            {Q}_r)/(\mathop{bytes}(\mathcal
            {Q}_r)+\mathop{bytes}(\mathcal {C}_r))$</span></span> .
            Colored by network query function, with markers by
            dataset.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-24">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Model
            selection</h3>
          </div>
        </header>
        <p>We now focus on selecting models from the efficiency
        ranking in the validation partition. We've already shown
        that there is high stability in the efficiency ranking
        between validation and testing partitions, but less
        correlation between correct predictions and efficiency
        (Table <a class="tbl" href="#tab3">3</a>). Therefore, in
        this evaluation, we show we can recover the <em>best</em>
        model in test (<span class="inline-equation"><span class=
        "tex">$\mathcal {Q}_{best}$</span></span> ) with respect to
        correct predictions, using efficiency selection
        criteria.</p>
        <div class="table-responsive" id="tab4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class=
            "table-title">Model selection on ‘efficiency’ ranking
            in validation (<span class=
            "inline-equation"><span class="tex">$\mathcal
            {Q}_{select}$</span></span> , Column 1) compared to the
            best model in test ranked by correct predictions
            (<span class="inline-equation"><span class=
            "tex">$\mathcal {Q}_{best}$</span></span> ), for
            efficiency, encoding cost, and correct prediction
            ratios (Columns 2,3,4).</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td colspan="4" style="text-align:center;">
                  Model Selection: <span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {E}(\mathcal {Q}_r)$</span></span> , Evaluation:
                  <span class="inline-equation"><span class=
                  "tex">$\mathop{correct}(C_r)$</span></span>
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:center;"><span class=
                "inline-equation"><span class="tex">$\mathcal
                {Q}_{select}$</span></span> (validation)</td>
                <td style="text-align:center;"><span class=
                "inline-equation"><span class="tex">$\frac{\mathcal
                {E}(\mathcal {Q}_{select})}{\mathcal {E}(\mathcal
                {Q}_{best})}$</span></span></td>
                <td style="text-align:center;"><span class=
                "inline-equation"><span class=
                "tex">$\frac{\mathop{bytes}(\mathcal
                {Q}_{select})}{\mathop{bytes}(\mathcal
                {Q}_{best})}$</span></span></td>
                <td style="text-align:center;"><span class=
                "inline-equation"><span class=
                "tex">$\frac{\mathop{correct}(\mathcal
                {Q}_{select})}{\mathop{correct}(\mathcal
                {Q}_{best})}$</span></span></td>
              </tr>
              <tr>
                <td colspan="4" style="text-align:center;">
                  Last.fm, <span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {Q}_{best}$</span></span> :
                  <tt>social</tt>-<tt>bfs</tt>
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:left;">1.
                <tt>social</tt>-<tt>bfs</tt></td>
                <td style="text-align:center;">1.00</td>
                <td style="text-align:center;">1.00</td>
                <td style="text-align:center;">1.00</td>
              </tr>
              <tr>
                <td style="text-align:left;">2.
                <tt>social</tt>-<tt>cluster</tt></td>
                <td style="text-align:center;">0.78</td>
                <td style="text-align:center;">0.29</td>
                <td style="text-align:center;">0.56</td>
              </tr>
              <tr>
                <td style="text-align:left;">3. <span class=
                "inline-equation"><span class="tex">$\texttt
                {KNN}_s$</span></span> -<tt>cluster</tt></td>
                <td style="text-align:center;">0.72</td>
                <td style="text-align:center;">0.08</td>
                <td style="text-align:center;">0.50</td>
              </tr>
              <tr>
                <td colspan="4" style="text-align:center;">
                  MovieLens, <span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {Q}_{best}$</span></span> : <tt>activity-top</tt>
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:left;">1.
                <tt>activity-top</tt></td>
                <td style="text-align:center;">1.00</td>
                <td style="text-align:center;">1.00</td>
                <td style="text-align:center;">1.00</td>
              </tr>
              <tr>
                <td style="text-align:left;">2. <span class=
                "inline-equation"><span class="tex">$\texttt
                {KNN}_s$</span></span> -<tt>bfs</tt></td>
                <td style="text-align:center;">0.12</td>
                <td style="text-align:center;">15.79</td>
                <td style="text-align:center;">0.28</td>
              </tr>
              <tr>
                <td style="text-align:left;">3.
                <tt>activity-net</tt></td>
                <td style="text-align:center;">0.20</td>
                <td style="text-align:center;">130.14</td>
                <td style="text-align:center;">0.91</td>
              </tr>
              <tr>
                <td colspan="4" style="text-align:center;">
                  BeerAdvocate, <span class=
                  "inline-equation"><span class="tex">$\mathcal
                  {Q}_{best}$</span></span> : <tt>activity-net</tt>
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:left;">1.
                <tt>activity-top</tt></td>
                <td style="text-align:center;">1.20</td>
                <td style="text-align:center;">0.01</td>
                <td style="text-align:center;">0.86</td>
              </tr>
              <tr>
                <td style="text-align:left;">2.
                <tt>activity-net</tt></td>
                <td style="text-align:center;">1.00</td>
                <td style="text-align:center;">1.00</td>
                <td style="text-align:center;">1.00</td>
              </tr>
              <tr>
                <td style="text-align:left;">3. <span class=
                "inline-equation"><span class="tex">$\texttt
                {KNN}_s$</span></span> -<tt>cluster</tt></td>
                <td style="text-align:center;">0.22</td>
                <td style="text-align:center;">0.09</td>
                <td style="text-align:center;">0.20</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>The left-most column of Table <a class="tbl" href=
        "#tab4">4</a> shows the three top-ranked models
        (<span class="inline-equation"><span class="tex">$\mathcal
        {Q}_{select}$</span></span> ) by efficiency in validation.
        The ratios report the relative performance of the selected
        model (evaluated in test) for efficiency, total encoding
        size, and correct predictions.The second column–efficiency
        ratio–is not monotonically decreasing, because model
        ranking by efficiency may be different in test than
        validation (Table <a class="tbl" href="#tab3">3</a>).</p>
        <p>The selection by efficiency shows an intuitive trade-off
        between encoding cost and predictive performance. For
        Last.fm, the <tt>social</tt>-<tt>bfs</tt> model performs
        best, but the inexpensive <tt>social</tt>-<tt>cluster</tt>
        model is an alternative. This is consistent with previous
        results which show <tt>social</tt>-<tt>bfs</tt> is much
        more predictive than network adjacency, and of other
        underlying network models [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0002">2</a>].</p>
        <p>According to performance ratios, <tt>activity-net</tt>
        is extremely preferred in MovieLens and BeerAdvocate. This
        measures the extent that the most active users are also
        most informative in terms of efficiency in these two
        domains.</p>
        <p>MovieLens correctly selects <tt>activity-top</tt>, and
        <tt>activity-net</tt> is an order of magnitude costlier
        while maintaining similar correct predictions. On
        BeerAdvocate, <tt>activity-net</tt> performs best on
        correct predictions, but <tt>activity-top</tt> is the
        better model since it preserves 0.86 of correct predictions
        but is 0.01 the encoding cost (it is first ranked by
        efficiency). This clearly shows why efficiency is preferred
        to favor parsimonious models.</p>
        <figure id="fig5">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191525/images/www18companion-264-fig5.jpg"
          class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">Models ranked (x-axis) by
            efficiency (Left), total encoding cost <span class=
            "inline-equation"><span class=
            "tex">$\mathop{bytes}(\mathcal {C}_r)+
            \mathop{bytes}(\mathcal {Q}_r)$</span></span> (Middle),
            and the number of correct predictions (Right).</span>
          </div>
        </figure>
        <p></p>
        <p>Figure <a class="fig" href="#fig5">4</a> reports models
        ranked by efficiency (Left) total encoding cost (Middle),
        and correct predictions (Right). The Last.fm ranking has
        more models because <tt>social</tt> are included. Ranking
        by correct predictions shows the extent that the top-ranked
        <tt>activity-net</tt> and <tt>activity-top</tt> models
        dominate the correct predictions on BeerAdvocate and
        MovieLens, which yields low ratios against <span class=
        "inline-equation"><span class="tex">$\mathcal
        {Q}_{best}$</span></span> in Table <a class="tbl" href=
        "#tab4">4</a>. Figure <a class="fig" href="#fig5">4</a>
        (Middle) shows that each dataset grows similarly over our
        set of models, but that each has a different baseline of
        encoding cost. Last.fm is particularly costly; the median
        non-zero attributes per node (e.g. artists listened) is
        578, or 7 times larger than MovieLens. These larger
        attribute vectors yield more expensive task models,
        requiring more bytes for the same correct predictions.
        These baselines also yield the same dataset ordering in
        efficiency. So, the <em>worst</em> model on MovieLens
        (<tt>random</tt>, 1084 bytes/correct) is more efficient
        than the <em>best</em> model on Last.fm
        (<tt>social</tt>-<tt>bfs</tt>, 1132 bytes/correct).</p>
      </section>
      <section id="sec-25">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.4</span> Model
            significance</h3>
          </div>
        </header>
        <p>In order to compare models with respect to a particular
        dataset, we measure the <em>significance</em> of each model
        relative to the efficiency over the complete set of
        models.</p>
        <p>We compare the median difference of efficiency of
        <span class="inline-equation"><span class="tex">$\mathcal
        {Q}_r$</span></span> to all other models against the median
        pairwise difference of all models excluding <span class=
        "inline-equation"><span class="tex">$\mathcal
        {Q}_r$</span></span> , over the inter-quartile range (IQR)
        of pairwise difference. This measure is a non-parametric
        analogue to the <em>z</em>-score, where the median
        <span class="inline-equation"><span class="tex">$\mathcal
        {Q}_r$</span></span> differences deviate from the pairwise
        expectation by at least a ‘<em>λ</em>’ factor of IQR.</p>
        <p>Let <span class="inline-equation"><span class="tex">$e_i
        = \mathcal {E}(\mathcal {Q}_i)$</span></span> , the
        efficiency value for an arbitrary network query function
        <span class="inline-equation"><span class="tex">$\mathcal
        {Q}_i$</span></span> , and <em>λ</em> a significance level
        threshold, then for <em>i</em> = 1...|<em>F</em>|,
        <em>j</em> = 1...|<em>F</em>|; <em>i</em>, <em>j</em> ≠
        <em>r</em>:</p>
        <div class="table-responsive" id="eq5">
          <div class="display-equation">
            <span class="tex mytex">\begin{multline}
            \mathrm{significance}(F, r, \lambda) = \\
            \frac{\mathop{med}_i(|e_r - e_i|) -
            \mathop{med}_{i,j}(|e_i- e_j|)}{\mathop{iqr}_{i,j}(|e_i
            - e_j|)} \ge \lambda\end{multline}</span><br />
            <span class="equation-number">(8)</span>
          </div>
        </div>This is a <em>signed</em> test favoring larger
        efficiency of <span class="inline-equation"><span class=
        "tex">$\mathcal {Q}_r$</span></span> than the expectation.
        The median estimates of the <em>e<sub>r</sub></em>
        comparisons and pairwise comparisons are also robust to a
        small number of other significant models, and like the
        <em>z</em>-score, this test scales with the dispersion of
        the pairwise differences.
        <p></p>
        <p>This test only assumes ‘significant’ models are an
        outlier class in all evaluated models <em>Q</em>. We
        propose a diverse set of possible representations; we use
        this diversity to treat consistency in the pairwise
        distribution as a robust null hypothesis: i.e. there is no
        appropriate model of the data within <em>Q</em>. Future
        work will more deeply focus on measuring this ‘diversity’,
        and determining the most robust set of models suitable for
        null modeling.</p>
        <p>At <em>λ</em> = 1 in validation, we find five
        significant models, corresponding to models reported in
        Table <a class="tbl" href="#tab4">4</a>:
        <tt>social</tt>-<tt>bfs</tt> on Last.fm (= 1.30),
        <tt>activity-top</tt> and <tt>activity-net</tt> on
        MovieLens (= 12.29, 1.21) and <tt>activity-top</tt> and
        <tt>activity-net</tt> on BeerAdvocate (= 7.64, ~6.00).</p>
      </section>
      <section id="sec-26">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.5</span> Model
            stability</h3>
          </div>
        </header>
        <p>For each of the significant models, we measure the
        impact of noise on its efficiency and significance. We
        apply node rewiring on the model we are testing, and leave
        all other models intact. For each neighbor of a node
        <em>i</em>, we re-wire <em>i</em> to a new node at
        probability <em>p</em>. This is an out-degree preserving
        randomization, which is appropriate because outgoing edges
        determine the input for the task model on <em>i</em>.
        Sorting heuristics <tt>activity-net</tt> and
        <tt>degree-net</tt> are implemented as ad-hoc networks,
        where each node <em>i</em> has directed edges to some
        <em>m</em>-sized subset of top-ranked nodes. For each
        top-ranked node adjacent to <em>i</em>, we re-map
        <em>i</em> to a random node (possibly not in the top-ranked
        subset) with probability <em>p</em>. This again preserves
        the out-degree of <em>i</em>, and reduces the in-degree of
        top-ranked nodes.</p>
        <figure id="fig6">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191525/images/www18companion-264-fig6.jpg"
          class="img-responsive" alt="Figure 5" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span>
            <span class="figure-title">Varying level of noise for 5
            ‘significant’ models (x-axis), reporting Efficiency
            (Left) and Significance (Right)</span>
          </div>
        </figure>
        <p></p>
        <p>Figure <a class="fig" href="#fig6">5</a> shows the
        effect of varying noise <em>p</em> (x-axis), on the
        efficiency (Left), and significance (Right) of each
        significant model. <tt>activity-net</tt> on both MovieLens
        and BeerAdvocate quickly lose efficiency under even small
        noise, and are no longer significant for <em>λ</em> = 1 at
        <em>p</em> = 0.025, and <em>p</em> = 0.10, respectively.
        <tt>activity-top</tt> is more robust, remaining significant
        to <em>p</em> = 0.225.</p>
        <p><tt>activity-net</tt> is particularly sensitive to noise
        due to decreased performance in <em>both</em> encoding cost
        and correct predictions. At only <em>p</em> = 0.025,
        <tt>activity-net</tt> on BeerAdvocate reduces in correct
        predictions by 15% and <em>increases</em> in encoding cost
        by 31%. The encoding cost greatly increases because the
        cardinality of the set of unique numbers in the
        <tt>activity-net</tt> representation is small (bound by the
        size of the top-ranked sample). When random nodes are added
        in the representation, they are near-unique values, greatly
        increasing the set cardinality and reducing the compression
        ratio. <tt>activity-top</tt> shows a similar increase, but
        proportional to nodes rather than edges.</p>
        <p>Finally, <tt>social</tt>-<tt>bfs</tt> is easily the most
        robust to noise. From a lower baseline, it remains
        significant to <em>p</em> = 0.15. It loses only 35% of its
        significance value at any noise level, while all other
        methods lose <span class="inline-equation"><span class=
        "tex">${\gt}90\%$</span></span> . This demonstrates that
        network models have robustness which might be desirable for
        further criteria in model selection. For example, our full
        methodology can be used to select on efficiency
        significance at some noise level <em>p</em>.</p>
      </section>
    </section>
    <section id="sec-27">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Conclusions and
          Future Work</h2>
        </div>
      </header>
      <p>In this paper, we have presented a minimum description
      length approach to perform model selection of networks. We
      have generalized networks as one particular representation of
      network query functions used to solve predictive tasks. This
      formulation allows comparing against arbitrary underlying
      representations and testing whether a network model is
      necessary in the first place. We propose a general efficiency
      measure for evaluating model selection for particular tasks
      on networks, and we show stability for node sampling and
      model ranking, as well as significance testing and
      sensitivity analysis for selected models. In total, this
      methodology is general and flexible enough to evaluate most
      networks inferred from attributed/labeled data, as well as
      networks given explicitly by the application of interest
      against alternative models.</p>
      <p>There are several avenues for improving this work. First,
      exploiting model similarity and prioritizing novel models may
      more quickly discover significant models and estimate their
      value against the full null model enumeration. Furthermore,
      we aim to study <em>which</em> and <em>how many</em> models
      yield a robust baseline null distribution of efficiency
      measurements for model selection.</p>
      <p>There are also extensions to this work. Currently, we
      learn node task models for each label instance. However, how
      many task models are needed on our network and can we re-use
      local models? Efficiency naturally measures the trade-off
      between eliminating task models vs. the loss in correct
      predictions. The aim is then task model-set
      <em>summarization</em> for maximum efficiency.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">I. Brugere, B.
        Gallagher, and T.&nbsp;Y. Berger-Wolf. 2016. Network
        Structure Inference, A Survey: Motivations, Methods, and
        Applications. <em><em>ArXiv e-prints</em></em> (Oct.
        2016).</li>
        <li id="BibPLXBIB0002" label="[2]">Ivan Brugere, Chris
        Kanich, and Tanya Berger-Wolf. 2017. Evaluating Social
        Networks Using Task-Focused Network Inference. In
        <em><em>Proceedings of the 13th International Workshop on
        Mining and Learning with Graphs (MLG)</em></em> .</li>
        <li id="BibPLXBIB0003" label="[3]">Ivan Brugere, Chris
        Kanich, and Tanya&nbsp;Y. Berger-Wolf. 2017. Network Model
        Selection for Task-Focused Attributed Network Inference. In
        <em><em>2017 IEEE International Conference on Data Mining
        Workshop (ICDMW)</em></em> .</li>
        <li id="BibPLXBIB0004" label="[4]">Rajmonda&nbsp;Sulo
        Caceres and Tanya Berger-Wolf. 2013. <em><em>Temporal Scale
        of Dynamic Networks</em></em> . 65–94.</li>
        <li id="BibPLXBIB0005" label="[5]">R.&nbsp;S. Caceres, L.
        Weiner, M.&nbsp;C. Schmidt, B.&nbsp;A. Miller, and
        W.&nbsp;M. Campbell. 2016. Model Selection Framework for
        Graph-based data. <em><em>ArXiv e-prints</em></em> (Sept.
        2016).</li>
        <li id="BibPLXBIB0006" label="[6]">B Efron and R&nbsp;J
        Tibshirani. 1993. <em><em>An Introduction to the
        Bootstrap</em></em> . Chapman &amp; Hall.</li>
        <li id="BibPLXBIB0007" label="[7]">J. Ferlez, C. Faloutsos,
        J. Leskovec, D. Mladenic, and M. Grobelnik. 2008.
        Monitoring Network Evolution using MDL. In <em><em>2008
        IEEE 24th International Conference on Data
        Engineering</em></em> . 1328–1330.</li>
        <li id="BibPLXBIB0008" label="[8]">W.&nbsp;L. Hamilton, R.
        Ying, and J. Leskovec. 2017. Representation Learning on
        Graphs: Methods and Applications. <em><em>ArXiv
        e-prints</em></em> (Sept. 2017).</li>
        <li id="BibPLXBIB0009" label="[9]">Mark&nbsp;H Hansen and
        Bin Yu. 2001. Model Selection and the Principle of Minimum
        Description Length. <em><em>J. Amer. Statist.
        Assoc.</em></em> 96, 454 (2001), 746–774.</li>
        <li id="BibPLXBIB0010" label="[10]">F&nbsp;Maxwell Harper
        and Joseph&nbsp;A Konstan. 2015. The MovieLens Datasets:
        History and Context. <em><em>ACM Trans. Interact. Intell.
        Syst.</em></em> 5, 4 (dec 2015), 19:1—-19:19.</li>
        <li id="BibPLXBIB0011" label="[11]">Mohammad&nbsp;Al Hasan
        and Mohammed&nbsp;J. Zaki. 2011. A Survey of Link
        Prediction in Social Networks. In <em><em>Social Network
        Data Analytics SE - 9</em></em> . 243–275.</li>
        <li id="BibPLXBIB0012" label="[12]">Bing Hu, Thanawin
        Rakthanmanon, Yuan Hao, Scott Evans, Stefano Lonardi, and
        Eamonn Keogh. 2011. Discovering the Intrinsic Cardinality
        and Dimensionality of Time Series Using MDL. In
        <em><em>Proceedings of the 2011 IEEE 11th International
        Conference on Data Mining</em></em> . 1086–1091.</li>
        <li id="BibPLXBIB0013" label="[13]">Myunghwan Kim and Jure
        Leskovec. 2012. Multiplicative Attribute Graph Model of
        Real-World Networks. <em><em>Internet Mathematics</em></em>
        8, 1-2 (Mar. 2012), 113–160.</li>
        <li id="BibPLXBIB0014" label="[14]">Eric&nbsp;D. Kolaczyk.
        2009. Network Topology Inference. In <em><em>Statistical
        Analysis of Network Data SE - 7</em></em> . Springer New
        York, 1–48.</li>
        <li id="BibPLXBIB0015" label="[15]">Danai Koutra, U Kang,
        Jilles Vreeken, and Christos Faloutsos. 2014. VOG:
        Summarizing and Understanding Large Graphs. In
        <em><em>Proceedings of the 2014 SIAM International
        Conference on Data Mining</em></em> . 91–99.</li>
        <li id="BibPLXBIB0016" label="[16]">David Liben-Nowell and
        Jon Kleinberg. 2007. The link-prediction problem for social
        networks. <em><em>Journal of the American Society for
        Information Science and Technology</em></em> 58, 7 (May
        2007), 1019–1031.</li>
        <li id="BibPLXBIB0017" label="[17]">Julian McAuley, Jure
        Leskovec, and Dan Jurafsky. 2012. Learning Attitudes and
        Attributes from Multi-aspect Reviews. In
        <em><em>Proceedings of the 2012 IEEE International
        Conference on Data Mining</em></em> . 1020–1025.</li>
        <li id="BibPLXBIB0018" label="[18]">Manish Mehta, Rakesh
        Agrawal, and Jorma Rissanen. 1996. <em><em>SLIQ: A fast
        scalable classifier for data mining</em></em> . 18–32.</li>
        <li id="BibPLXBIB0019" label="[19]">Galileo&nbsp;Mark
        Namata, Ben London, and Lise Getoor. 2015. Collective Graph
        Identification. <em><em>ACM Transactions on Knowledge
        Discovery from Data</em></em> (2015).</li>
        <li id="BibPLXBIB0020" label="[20]">Joseph&nbsp;J Pfeiffer
        III, Sebastian Moreno, Timothy La Fond, Jennifer Neville,
        and Brian Gallagher. 2014. Attributed Graph Models:
        Modeling Network Structure with Correlated Attributes. In
        <em><em>Proceedings of the 23rd International Conference on
        World Wide Web</em></em> . ACM, 831–842.</li>
        <li id="BibPLXBIB0021" label="[21]">Jorma Rissanen. 2004.
        <em><em>Minimum Description Length Principle</em></em> .
        John Wiley &amp; Sons, Inc.</li>
        <li id="BibPLXBIB0022" label="[22]">Jimeng Sun, Christos
        Faloutsos, Spiros Papadimitriou, and Philip&nbsp;S Yu.
        2007. GraphScope: parameter-free mining of large
        time-evolving graphs. In <em><em>Proceedings of the 13th
        ACM SIGKDD international conference on Knowledge discovery
        and data mining</em></em> (<em>KDD ’07</em>). ACM,
        687–696.</li>
        <li id="BibPLXBIB0023" label="[23]">Daniel&nbsp;Yasumasa
        Takahashi, João&nbsp;Ricardo Sato, Carlos&nbsp;Eduardo
        Ferreira, and Andrú Fujita. 2012. Discriminating Different
        Classes of Biological Networks by Analyzing the Graphs
        Spectra Distribution. <em><em>PLOS ONE</em></em> 7, 12 (12
        2012), 1–12.</li>
        <li id="BibPLXBIB0024" label="[24]">S.&nbsp;V.&nbsp;N.
        Vishwanathan, Nicol&nbsp;N. Schraudolph, Risi Kondor, and
        Karsten&nbsp;M. Borgwardt. 2010. Graph Kernels. <em><em>J.
        Mach. Learn. Res.</em></em> 11 (Aug. 2010), 1201–1242.</li>
        <li id="BibPLXBIB0025" label="[25]">Wentao Zhao, Erchin
        Serpedin, and Edward&nbsp;R. Dougherty. 2006. Inferring
        gene regulatory networks from time series data using the
        minimum description length principle.
        <em><em>Bioinformatics</em></em> 22, 17 (2006),
        2129–2135.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>Throughout,
    capital letters denote sets, lowercase letters denote instances
    and indices. Script characters (e.g. <span class=
    "inline-equation"><span class="tex">$\mathcal
    {C}$</span></span> ) and keywords (e.g. <span class=
    "inline-equation"><span class=
    "tex">$\mathop{bytes}()$</span></span> ) denote functions,
    teletype (e.g. <tt>KNN</tt>-<tt>bfs</tt>) denotes
    <em>models</em>, square brackets (e.g. <em>A</em>[<em>S</em>])
    denote the restriction of a set to a subset.</p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>For simplicity,
    we refer to models only by their subscript labels, e.g.
    <span class="inline-equation"><span class="tex">$\texttt
    {KNN}_s$</span></span> -<tt>bfs</tt> for the sparse
    <span class="inline-equation"><span class="tex">$\mathcal
    {Q}_{\texttt {bfs}}(E_{\texttt {KNN}})$</span></span>
    model.</p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a><a class=
    "link-inline force-break" href=
    "https://msgpack.org/">https://msgpack.org/</a></p>
    <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a><a class=
    "link-inline force-break" href=
    "https://lz4.github.io/lz4/">https://lz4.github.io/lz4/</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3191525">https://doi.org/10.1145/3184558.3191525</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
