<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Identifying Task Boundaries in Digital Assistants</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Identifying Task Boundaries in
          Digital Assistants</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Madian</span> <span class=
          "surName">Khabsa</span> Apple Inc
        </div>
        <div class="author">
          <span class="givenName">Ahmed El</span> <span class=
          "surName">Kholy</span> Microsoft Corp
        </div>
        <div class="author">
          <span class="givenName">Ahmed Hassan</span> <span class=
          "surName">Awadallah</span> Microsoft Corp
        </div>
        <div class="author">
          <span class="givenName">Imed</span> <span class=
          "surName">Zitouni</span> Microsoft Corp
        </div>
        <div class="author">
          <span class="givenName">Milad</span> <span class=
          "surName">Shokouhi</span> Microsoft Corp, <a href=
          "mailto:madian@apple.com,%20ahelkhol,hassanam,izitouni,milads@microsoft.com">
          madian@apple.com,
          ahelkhol,hassanam,izitouni,milads@microsoft.com</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186952"
        target=
        "_blank">https://doi.org/10.1145/3184558.3186952</a><br />
        WWW '18: <a href=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186952/"
        target="_blank">Proceedings of The Web Conference 2018</a>,
        Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Digital assistants are emerging to become more
        prevalent in our daily lives. In interacting with these
        assistants, users may engage in multiple tasks within a
        short period of time. Identifying task boundaries and
        isolating them within a session is critical for measuring
        the performance of the system on each individual task. In
        this paper we aim to automatically identify sequences of
        interactions that together form a task. To this end, we
        sample interactions from a real world digital assistant and
        use crowd judges to segment a session into multiple tasks.
        After that, we use a machine learned model to identify task
        boundaries. Our learned model with its features
        significantly outperform the baselines. To the best of our
        knowledge, this is the first work that aims to identify
        tasks within digital assistant sessions.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS
        Concepts:</span> • <strong>Computer systems
        organization</strong> → <strong>Embedded systems;</strong>
        <em>Redundancy;</em> Robotics; • <strong>Networks</strong>
        → Network reliability;</small></p>
      </div>
      <div class="classifications">
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Madian Khabsa, Ahmed El Kholy, Ahmed Hassan Awadallah,
          Imed Zitouni, and Milad Shokouhi. 2018. Identifying Task
          Boundaries in Digital Assistants. In <em>WWW '18
          Companion: The 2018 Web Conference Companion,</em>
          <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New
          York, NY, USA</em> 3 Pages. <a href=
          "https://doi.org/10.1145/3184558.3186952" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3186952</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Digital assistants (DA) such as Siri and Cortana are
      emerging to be part of our daily lives, with the entire
      market of virtual assistants projected to grow 34% year over
      year<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>.
      These assistants are designed to accomplish multiple tasks.
      They could be goal-oriented tasks in which the user is trying
      to accomplish a certain goal, like setting a reminder. Or
      they could be tasks that seek information about a specific
      entity, for example getting the phone number of a nearby
      restaurant. Because assistants are designed to converse with
      users interactively, they can also perform some chitchatting
      tasks. From a user perspective, the fluidity of the
      assistant's responses encourage alternating between multiple
      types of tasks within a short period of time. For digital
      assistant developers, it is imperative to track the user
      interactions with the system and identify successful
      interactions from failed ones. Since a given session might
      contain multiple interleaving tasks, the assistant might have
      succeeded in accomplishing some of them, while failed at
      others. Therefore, it is crucial to segment user interaction
      with the assistant into multiple tasks, where the success of
      each task is independently measured.</p>
      <p>While identifying task boundaries and measuring success in
      web search has been studied before [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0002">2</a>], we are not aware of any
      work that tried to automatically segment digital assistant
      sessions into tasks. Therefore, we start by studying the
      access logs of a real world digital assistant, and analyzing
      what percentage of sessions do indeed contain more than one
      task. After that we use crowd workers to build a dataset of
      tasks within sessions, and train a machine learning model to
      identify task boundaries. The problem is modeled as a binary
      classification between every pair of consecutive
      interactions. The classifier's job is to decide whether two
      consecutive interactions are part of the same task or not. A
      combination of features is used that is shown to outperform
      multiple baselines.</p>
      <p>There are two main challenges that differentiate task
      identification in digital assistants from typical search
      engines. First, digital assistants comprise multiple
      sequential components like Automatic Speech Recognition (ASR)
      and Dialogue State Tracking (DST). Each of these components
      might fail independently and introduce errors to the user
      input (query). Whereas in search engines, the system receives
      the query exactly as it was typed. Second, because users
      interact with digital assistants in natural language,
      approaches based on syntactic features and edit distance are
      less effective.</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Data</h2>
        </div>
      </header>
      <p>The data used in this study comes from user access logs of
      a commercial digital assistant. We first started by studying
      the distribution of session length for the DA users. We
      collected all sessions for a period of 3 months and examined
      the number of interactions in the session against the
      frequency of such length. Figure fig:distr shows the
      distribution of session length as measured by the number of
      interactions. As seen in the figure, more than 40% of the
      sessions were found to contain 2 or more interactions. After
      that, we sampled 500 sessions from the logs of the same DA
      making sure each session contains 2 or more interactions. We
      use the standard session definition that is used in search
      engines wherein a period of inactivity of 30 minutes or more
      separates two sessions. Each sampled sessions was shown to 3
      judges. The judges were asked to review the entire session,
      then flag the interaction that marks the end of the current
      task. By definition, the first interaction in a session
      starts a new task. For each interaction the judge viewed the
      user input, system response, along with the timestamps.
      Because the logs are stored in privacy preserving manner,
      certain inputs from the user and responses from the system
      are redacted.</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186952/images/www18companion-1-fig2.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">Figure (a) shows distribution of session
          length in terms of the number of interactions within the
          session. Figure (b) shows the distribution of number of
          tasks in sessions that contains 2 or more
          interactions</span>
        </div>
      </figure>
      <p></p>
      <p>In collecting the labels, a <strong>task</strong> was
      defined as follows: <em>a sequence of requests are considered
      to be part of a single task if they collectively try to
      achieve a certain goal</em>. There are two properties that
      determine if a request belongs to the current task or not:
      <strong>(1) Reformulation</strong>: The user is trying to
      repeat himself in a different way to achieve the same goal of
      a previous request. <strong>(2) Dependence</strong>: The
      current request depends on the output of the previous
      request. That is, the user depends on the DA response to
      issue the following request.</p>
      <p>The judges generated 1631 data points, each data point
      corresponds to the label between two consecutive instances
      within the same session. Overall 929 instances indicated that
      the following interaction belongs to the same task as the
      previous one. Whereas, 703 instances corresponded to the
      following interaction being part of a separate task. The
      kappa inter-annotator agreement was 0.74 which indicates a
      substantial agreement among the judges. We further analyzed
      the tasks identified by the judges to understand how common
      is it for sessions to contain multiple tasks. The
      distribution of number of tasks in a session is plotted in
      Figure fig:tasksdist . From the plot, we find that for
      sessions with multiple interactions, nearly 60% of them
      contain 2 or more tasks. This result motivates the need to
      develop an approach to automatically identify task
      boundaries.</p>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">The performance of the task boundary
          detection classifier using different combination of
          features. <strong>+</strong> sign indicates the feature
          being added to all previous features. Baseline 1: a
          majority classifier, and Baseline 2 is [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0003">3</a>]</span>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <td style="text-align:left;"></td>
              <td colspan="3" style="text-align:left;">
                Start of new task
                <hr />
              </td>
              <td colspan="3" style="text-align:left;">
                Continue Same Task
                <hr />
              </td>
            </tr>
            <tr>
              <td style="text-align:left;">Features</td>
              <td style="text-align:left;">P</td>
              <td style="text-align:left;">R</td>
              <td style="text-align:left;">F1</td>
              <td style="text-align:left;">P</td>
              <td style="text-align:left;">R</td>
              <td style="text-align:left;">F1</td>
            </tr>
            <tr>
              <td style="text-align:left;">Text</td>
              <td style="text-align:left;">0.62</td>
              <td style="text-align:left;">0.61</td>
              <td style="text-align:left;">0.62</td>
              <td style="text-align:left;">0.71</td>
              <td style="text-align:left;">0.71</td>
              <td style="text-align:left;">0.71</td>
            </tr>
            <tr>
              <td style="text-align:left;">+ NER</td>
              <td style="text-align:left;">0.63</td>
              <td style="text-align:left;">0.64</td>
              <td style="text-align:left;">0.63</td>
              <td style="text-align:left;">0.71</td>
              <td style="text-align:left;">0.71</td>
              <td style="text-align:left;">0.72</td>
            </tr>
            <tr>
              <td style="text-align:left;">+ Time</td>
              <td style="text-align:left;">0.70</td>
              <td style="text-align:left;">0.67</td>
              <td style="text-align:left;">0.68</td>
              <td style="text-align:left;">0.76</td>
              <td style="text-align:left;">0.78</td>
              <td style="text-align:left;">0.77</td>
            </tr>
            <tr>
              <td style="text-align:left;">+ Embedding</td>
              <td style="text-align:left;">0.69</td>
              <td style="text-align:left;">0.67</td>
              <td style="text-align:left;">0.68</td>
              <td style="text-align:left;">0.75</td>
              <td style="text-align:left;">0.77</td>
              <td style="text-align:left;">0.76</td>
            </tr>
            <tr>
              <td style="text-align:left;">+ Metaphone</td>
              <td style="text-align:left;">0.70</td>
              <td style="text-align:left;">0.67</td>
              <td style="text-align:left;">0.69</td>
              <td style="text-align:left;">0.76</td>
              <td style="text-align:left;">0.78</td>
              <td style="text-align:left;">0.77</td>
            </tr>
            <tr>
              <td style="text-align:left;">+ Response</td>
              <td style="text-align:left;">0.70</td>
              <td style="text-align:left;">0.66</td>
              <td style="text-align:left;">0.68</td>
              <td style="text-align:left;">0.76</td>
              <td style="text-align:left;">0.78</td>
              <td style="text-align:left;">0.77</td>
            </tr>
            <tr>
              <td style="text-align:left;">+ RequestNgram</td>
              <td style="text-align:left;">
              <strong>0.72</strong></td>
              <td style="text-align:left;">0.75</td>
              <td style="text-align:left;">0.73</td>
              <td style="text-align:left;">0.80</td>
              <td style="text-align:left;">
              <strong>0.78</strong></td>
              <td style="text-align:left;">
              <strong>0.79</strong></td>
            </tr>
            <tr>
              <td style="text-align:left;">+ ResponseNgram</td>
              <td style="text-align:left;">0.71</td>
              <td style="text-align:left;">
              <strong>0.76</strong></td>
              <td style="text-align:left;">
              <strong>0.74</strong></td>
              <td style="text-align:left;">
              <strong>0.81</strong></td>
              <td style="text-align:left;">0.77</td>
              <td style="text-align:left;">0.79</td>
            </tr>
            <tr>
              <td style="text-align:left;">Baseline 1</td>
              <td style="text-align:left;">0</td>
              <td style="text-align:left;">0</td>
              <td style="text-align:left;">0</td>
              <td style="text-align:left;">0.57</td>
              <td style="text-align:left;">1</td>
              <td style="text-align:left;">0.73</td>
            </tr>
            <tr>
              <td style="text-align:left;">Baseline 2</td>
              <td style="text-align:left;">0.68</td>
              <td style="text-align:left;">0.26</td>
              <td style="text-align:left;">0.38</td>
              <td style="text-align:left;">0.62</td>
              <td style="text-align:left;">0.9</td>
              <td style="text-align:left;">0.74</td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Approach</h2>
        </div>
      </header>
      <p>Similar to [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>] we formulate the problem of
      identifying task boundaries as a binary classification task
      where the goal is to predict for every pair of consecutive
      user requests <em>r<sub>i</sub></em> and <em>r</em>
      <sub><em>i</em> + 1</sub> if they belong to the same task or
      not. Random Forest is used as a classifier since it
      outperform other classifiers we experimented with. Model
      hyperparameters were tuned using grid search. The following
      features were used in the classifier: <strong>Text</strong>:
      A collection of features derived from textual similarity
      between the two consecutive requests. The features include
      Levenshtein distance, Jaccard similarity, longest common
      substring, shared prefix and postfix, and number of shared
      words. <strong>NER</strong>: The number of shared named
      entities between the two pair of requests.
      <strong>Time</strong>: The time delta in seconds between the
      two consecutive requests <strong>Embedding</strong>: Word2Vec
      derived features between the two consecutive requests. This
      feature computes the number and ratio of words whose
      embedding vectors are close. <strong>Metaphone</strong>: The
      number and ratio of common metaphones between the words of
      the consecutive requests. This feature captures
      reformulations that are due to errors in speech recognition.
      <strong>Response</strong>: A collection of textual features
      that are derived from the two consecutive <em>responses</em>
      of the DA. They are similar to textual features described
      above. <strong>RequestNgram and ResponseNgram</strong>:
      Unigrams and Bigrams of the two consecutive <em>requests</em>
      and <em>responses</em>, respectively.</p>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Results</h2>
        </div>
      </header>
      <p>We use the dataset collected in Section 2 as the gold
      standard used for training and testing. The results of the
      classifier on a 5 fold cross validation are reported in Table
      <a class="tbl" href="#tab1">1</a>. In the table, the first
      row indicates using Text features only, whereas every
      subsequent row denotes the results of using the specified
      feature <em>in addition</em> to every feature listed above it
      in the table. For example, the row with feature
      <em>+ResponseNgram</em> indicates the performance when every
      listed feature was used in the classifier. From Table
      <a class="tbl" href="#tab1">1</a>, we see that the classifier
      is able to identify more than 75% of the requests that mark
      the beginning of a new task, with 71% precision. We notice
      that the Time feature is responsible for a significant boost
      in the precision, whereas adding Ngram features lead to
      increase in recall. To get an understanding about how good or
      bad our classifier is, we compare the performance against the
      following 2 baselines. Baseline 1 is simple a majority class
      classifier that classifies every instance as <em>Continue
      Same Task</em>. In other words, every session contains one
      task only. Baseline 2 is based on the work of
      Mehrotra&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>] wherein we will assume that a new
      session as defined by [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>] corresponds to a new task. This
      baseline is basically a time delta classifier that was
      learned from a Mixture of Gaussians [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0003">3</a>]. As seen in Table
      <a class="tbl" href="#tab1">1</a>, our approach significantly
      outperforms both baselines. We also wanted to measure the
      performance of the task boundary segmentation classifier at
      the session level instead of the pairwise request level. In
      other words, given a session <em>S</em> that contains
      <em>n</em> request and response pairs that form <em>m</em>
      tasks, we wanted to test the accuracy of the classifier in
      retrieving all <em>m</em> tasks of the session. The
      classifier built using all the features achieved an accuracy
      of 46.8%. Note that this is a hard task because it requires
      the classifier to make the correct prediction in each of the
      <em>n</em> request/response pairs, and a single mistake
      results in an inaccurate session segmentation. This suggests
      that although our approach is able to perform generally well
      on identifying the start of new task, there is still room for
      improvement at accurately segmenting an entire session.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Rosie Jones and
        Kristina&nbsp;Lisa Klinkner. 2008. Beyond the session
        timeout: automatic hierarchical segmentation of search
        topics in query logs. In <em><em>Proceedings of the 17th
        ACM conference on Information and knowledge
        management</em></em> . ACM, 699–708.</li>
        <li id="BibPLXBIB0002" label="[2]">Claudio Lucchese,
        Salvatore Orlando, Raffaele Perego, Fabrizio Silvestri, and
        Gabriele Tolomei. 2011. Identifying task-based sessions in
        search engine query logs. In <em><em>Proceedings of the
        fourth ACM international conference on Web search and data
        mining</em></em> . ACM, 277–286.</li>
        <li id="BibPLXBIB0003" label="[3]">Rishabh Mehrotra,
        Ahmed&nbsp;El Kholy, Imez Zitouni, Milad Shokouhi, and
        Ahmed Hassan. 2017. Identifying User Sessions in
        Interactions with Intelligent Digital Assistants. In
        <em><em>Proceedings of the 26th International Conference on
        World Wide Web Companion</em></em> . 821–822.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class=
    "link-inline force-break" href=
    "https://www.gminsights.com/industry-analysis/intelligent-virtual-assistant-iva-market">https://www.gminsights.com/industry-analysis/intelligent-virtual-assistant-iva-market</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3186952">https://doi.org/10.1145/3184558.3186952</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
