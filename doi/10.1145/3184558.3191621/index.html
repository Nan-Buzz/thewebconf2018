<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Class Specific TF-IDF Boosting for Short-text Classification</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Class Specific TF-IDF Boosting for Short-text Classification</span>      <br/>      <span class="subTitle">       <SubTitle>Application to Short-texts Generated During Disasters</SubTitle>      </span>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author"><a href="https://orcid.org/1234-5678-9012-3456" ref="author"><span class="givenName">Samujjwal</span>      <span class="surName">Ghosh</span></a>,     IIT Hyderabad, Hyderabad, Telangana, IN, <a href="mailto:cs16resch01001@iith.ac.in">cs16resch01001@iith.ac.in</a>     </div>     <div class="author">     <span class="givenName">Maunendra Sankar</span>      <span class="surName">Desarkar</span>,     IIT Hyderabad, Hyderabad, Telangana, IN, <a href="mailto:maunendra@iith.ac.in">maunendra@iith.ac.in</a>     </div>    </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3191621" target="_blank">https://doi.org/10.1145/3184558.3191621</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Proper formulation of features plays an important role in short-text classification tasks as the amount of text available is very little. In literature, Term Frequency - Inverse Document Frequency (TF-IDF) is commonly used to create feature vectors for such tasks. However, TF-IDF formulation does not utilize the class information available in supervised learning. For classification problems, if it is possible to identify terms that can strongly distinguish among classes, then more weight can be given to those terms during feature construction phase. This may result in improved classifier performance with the incorporation of extra class label related information. We propose a supervised feature construction method to classify tweets, based on the actionable information that might be present, posted during different disaster scenarios. Improved classifier performance for such classification tasks can be helpful in the rescue and relief operations. We used three benchmark datasets containing tweets posted during Nepal and Italy earthquakes in 2015 and 2016 respectively. Experimental results show that the proposed method obtains better classification performance on these benchmark datasets.</small>     </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Information Retrieval; Short-text Classification; Feature Engineering; Entropy-based Feature Generation</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Samujjwal Ghosh and Maunendra Sankar Desarkar. 2018. Class Specific TF-IDF Boosting for Short-text Classification: Application to Short-texts Generated During Disasters. In <em>The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France</em>. ACM, New York, NY, USA, 9 Pages. <a href="https://doi.org/10.1145/3184558.3191621" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3191621</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-3">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>Short texts like tweet contain very limited contextual information due to their length restriction. Because of this, classifying short texts using machine learning techniques is a challenging task. Proper formulation of feature vector plays an important role in such a scenario. In disaster mitigation related literature, where textual feature is used, most common technique used for feature representation is Term Frequency - Inverse Document Frequency (TF-IDF). In TF-IDF feature representation, each document or short-text is represented as a vector where the fields correspond to the terms in the vocabulary. The value stored in a field is the TF-IDF score of the corresponding term. The TF-IDF score is the product of the Term Frequency (TF) of the term in that document and the Inverse Document Frequency (IDF) of that term in the corpus. Mathematically, TF-IDF can be denoted by, <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\[ TF.IDF = tf^i_d \times \log {\frac{N}{df^i}} \] </span>      <br/>     </div>     </div> where <span class="inline-equation"><span class="tex">$tf^i_d$</span>     </span> is the number of times term <em>i</em> occurred in document <em>d</em>, <em>N</em> is the total number of documents in the corpus and <em>df<sup>i</sup>     </em> is the number of documents in which term <em>i</em> occurred. TF captures the importance of the term in the document and is computed as an increasing function of the term&#x0027;s frequency. On the other hand, IDF tries to measure how informative a term is in the corpus. The assumption commonly made here is, if a term is frequent in a corpus then it is not much informative, whereas terms that are rare are more informative and hence important. IDF is modeled as a decreasing function of the term&#x0027;s document frequency. This feature construction strategy using TF-IDF is often used to classify text documents - both short [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>] and long [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>].</p>    <p>For supervised classification problems, labeled training data is assumed to be available. The TF-IDF based approaches do not consider these class labels during feature construction. However, from the labeled data it might be possible to identify terms that are discriminative and hence strong indicators for certain classes. We want to add the term&#x0027;s importance (distinguishing power) among different classes as an extra information in the feature construction process. A term is considered discriminative if it occurs sufficiently large number of times in a particular class but rarely occurs in other classes. Let <em>t</em>     <sub>1</sub> and <em>t</em>     <sub>2</sub> be two terms that occurred <em>k</em> times in a corpus. However, <em>t</em>     <sub>1</sub> appeared uniformly in documents across all classes, but <em>t</em>     <sub>2</sub> occurred in class <em>c<sub>i</sub>     </em> sufficiently more times than it occurred in other classes combined (i.e. &#x2200;<em>c<sub>j</sub>     </em> &#x2208; <em>C</em>; <em>c<sub>j</sub>     </em> &#x2260; <em>c<sub>i</sub>     </em>). IDF score for both the terms <em>t</em>     <sub>1</sub> and <em>t</em>     <sub>2</sub> will be same. However, it is evident that the term <em>t</em>     <sub>2</sub> has more discriminating power as its presence in a future document is strongly indicative of the document&#x0027;s belongingness to that particular class (i.e. in our example class <em>c<sub>i</sub>     </em>).</p>    <p>We wish to capture this distinguishing power of different terms and use this information during feature construction phase. In this work, we propose techniques of boosting TF-IDF scores to better represent the term distribution among classes. Classifiers can then exploit this extra information to make better decisions. These general techniques can be applied in different applications where bag-of-word based TF-IDF features are used. We applied our proposed approach to classify disaster related tweets to understand its impact and usefulness over using traditional TF-IDF.</p>    <p>During disasters, people have been found to post lots of messages in the micro-blogging sites such as Twitter, Weibo etc. Some of these posts may actually contain information regarding damages to the infrastructure, requirement of resources such as water, medicines, etc. Proper annotation of such posts with kind of information they contain can help in the rescue and relief operations, thereby mitigating the miseries of people affected by the disaster.</p>    <p>There have been many studies in the literature, regarding proper utilization of short-texts generated during disaster, to effectively plan rescue and relief operations [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>]. Here we present a consolidated summary of different work related to disaster related tweet classification. Paper [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>] presented a comparative study of disaster related tweet classification using various algorithms with TF-IDF features. Authors in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>] proposed a system which not only filters and categorizes English tweets, but also worked on multilingual tweets related to typhoon Lawin (international name: Haima) and Karen (international name: Sarika). This system was built by using TF-IDF features with Support Vector Machine (SVM) classifier. Although, [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>] mainly concentrates on neural network based approaches to retrieve disaster related micro-blogs, they used TF-IDF Rocchio scores to expand their query before using them on neural networks. Domain adaptation approach, which learns classifiers from unlabelled target data, is taken in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>] in which authors utilized information available from a past disaster to filter tweets related to a new disaster. Domain adaptation was achieved by using self-training technique on modified version of weighted Naive Bayes classifier with TF-IDF features. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>] built a system which automatically detects any disaster happening by monitoring the Twitter stream. Authors used Naive Bayes and SVM as their classifier with TF-IDF based feature vectors. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>], authors proposed an automated text classification system which filters only disaster related short-texts. The proposed method works by selecting prominent TF-IDF features using Chi-square technique. A study between matching based and learning based approaches to filter relevant tweets generated during disaster were done by the authors of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>]. They employed various techniques like geo-tag information, word2vec [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>] embedding along with TF-IDF scores. As we can see from these discussions use of TF-IDF is very common in the area of disaster related tweet classification.</p>    <p>In this work we focus on the task of classifying informative tweets posted during disasters. The example classes we consider are resource availability and requirement related, infrastructure damage related, etc. Even minor improvement in the classification performance can help the rescue organizations to look at specific messages and accordingly make decisions to channel the relief operations in appropriate manner. We used three disaster related tweet datasets to test the effectiveness of our proposed feature construction techniques. Our methods significantly outperformed the TF-IDF based classification method on these benchmark datasets.</p>    <p>The rest of the paper is organized as follows. In Section <a class="sec" href="#sec-4">2</a> we discuss related works in the field of TF-IDF score modification for classification task. We define the problem in Section <a class="sec" href="#sec-5">3</a>. Section <a class="sec" href="#sec-6">4</a> discusses about proposed approach in detail. Discussion about our experimental setup along with dataset details are given in Section <a class="sec" href="#sec-9">5</a>. Finally, we will present our experimental results in Section <a class="sec" href="#sec-13">6</a>.</p>   </section>   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>     </div>    </header>    <p>In this Section, we look at different work from the literature that deals with variants of TF-IDF modification for classification tasks. However, most techniques are based on feature-selection approach, rather than TF-IDF score modification, in which a subset of features are selected based on terms&#x2019; discriminative power. This subset selection can be done using various methods like, Information Gain (IG) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>], Chi-square [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>], Mutual Information [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>], etc. However, these methods do not take advantage of term&#x0027;s frequency among classes. However, people have experimented with different TF-IDF modification techniques. Below we discuss few such approaches present in literature.</p>    <p>Authors in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] incorporated bi-grams along with traditional uni-grams based features to incorporate extra information. Although this approach does not alter the values of TF-IDF, they increase the number of unique features in the vocabulary. They showed that increasing the vocabulary size might increase classifier performance. Bi-Normal Separation (BNS) was used instead of IDF when generating features by the authors of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>]. BNS ranks terms based on their distinguishing power. Authors found scaling terms&#x2019; importance by BNS without any feature selection improved their classifier accuracy. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>] an entropy based approach was proposed called Entropy-based Category Coverage Difference (ECCD) in which they calculated the entropy of each term across classes to get the importance of terms for different class concentrations. To tackle class imbalance problem, [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>] proposed a probability based term weighting scheme which improved classifier performance for classes in which number of data points are less compared to other classes. In another approach, semantically modified TF-IDF scores were used to categorize biomedical data by [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>]. Better performance of SVM classifier using modified feature set was found. Delta TF-IDF was proposed by [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>] which modifies the TF-IDF score to better understand sentiments of blogs. The Delta part was calculated by taking the difference in the TF-IDF score of positive and negative sentiments of training data. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>], authors used inverse-class-frequency (ICF) similar to IDF which denotes how important a term is. ICF gives highest score to those terms which occur in few classes and lowest score to terms which occur in many classes. They showed using ICF instead of IDF gives better classifier performance. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>] shows the effect of using IG to select most prominent features instead of using all the features. They found that use of IG improved their classification accuracy. The work by [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>] proposed low granular features for short text classification task focusing mainly on Chinese texts. Authors in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>] also proposed two entropy based approaches called tf.dc and tf.bdc which measure the Distributional Concentration (DC) among classes. In DC approach, entropy was calculated over classes rather than documents. In second approach Balanced Distributional Concentration (BDC) was proposed which takes class size into account to calculate DC. However, most of these approaches are tuned for long-text and does not optimize for short texts where context information is limited.</p>   </section>   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Problem Definition</h2>     </div>    </header>    <p>Our main goal in this work is to classify short-texts, given a set of short-texts and their classes. The problem can be formulated as:</p>    <ul class="list-no-style">     <li id="uid1">Let, <em>T</em> = {t<sup>1</sup>, t<sup>2</sup>, &#x22C5;&#x22C5;&#x22C5;, t<sup>      <em>N</em>     </sup>} be a set of <em>N</em> textual data points and <em>C</em> = {1, 2, &#x22C5;&#x22C5;&#x22C5;, <em>m</em>} be a set of <em>m</em> classes. Given a set of mappings of the form <span class="inline-equation"><span class="tex">$\lbrace {t}^i, {c^i_1, \cdots , c^i_k} \rbrace$</span>     </span> where data t<sup>      <em>i</em>     </sup> &#x2208; <em>T</em> and classes <span class="inline-equation"><span class="tex">$c^i_1, \cdots , c^i_k \in C$</span>     </span>, our goal is to find all applicable classes for a new data t<sup>      <em>new</em>     </sup>.<br/></li>    </ul>    <p>Below we discuss our proposed methods of utilizing term-class relationship when constructing TF-IDF features.</p>   </section>   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Proposed Method</h2>     </div>    </header>    <p>We want to classify unseen short texts, given a set of short-texts and their class labels as training data. Keeping this objective in mind, we first try to identify ways of measuring the term&#x0027;s relationship with different classes. Then we see how this information can be leveraged to assign new tweets to appropriate classes. For terms that are inherently specific to certain classes, we expect their distributions to be concentrated in those classes. On the other hand, terms that are generic may be roughly uniformly distributed over all the classes. One common way to identify presence or absence of such concentrations is through Entropy. We compute the entropy of a term <em>t<sub>i</sub>     </em> as <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\[ H(t^i) = - \sum _{c} p^i_c \times \log _2(p^i_c) \] </span>      <br/>     </div>     </div> where <span class="inline-equation"><span class="tex">$p^i_c$</span>     </span> is the probability that if a term <em>t<sub>i</sub>     </em> is present in a document, then the document comes from class <em>c</em>. We estimate <span class="inline-equation"><span class="tex">$p^i_c$</span>     </span> as the ratio of number of times <em>t<sub>i</sub>     </em> is present in class <em>c</em> and the number of times it is present across all classes. Then, the formula for computing entropy of a term <em>t<sub>i</sub>     </em> can be written as: <div class="table-responsive" id="eq1">     <div class="display-equation">      <span class="tex mytex">\begin{equation} H(t^i) = - \sum _{c=1}^{m} \frac{tc^i_c}{tc^i} \times \log _2\left(\frac{tc^i_c}{tc^i}\right). \end{equation} </span>      <br/>      <span class="equation-number">(1)</span>     </div>     </div> where <span class="inline-equation"><span class="tex">$tc^i_c$</span>     </span> denotes the count of term <em>t<sup>i</sup>     </em> in class <em>c</em> and <em>tc<sup>i</sup>     </em> denotes the count across all classes, i.e. <em>tc<sup>i</sup>     </em> = <span class="inline-equation"><span class="tex">$\sum _{k=1}^{m} tc^i_k$</span>     </span>.</p>    <section id="sec-7">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Normalized Entropy Boosting</h3>     </div>     </header>     <p>Once we calculated the entropy of each term in the corpus, we want to get an estimate of how informative (concentrated) a term is for each class. We proposed an entropy based approach called Normalized Entropy Boosting. We calculated Normalized Entropy (NE) for term <em>t<sup>i</sup>     </em> by, <div class="table-responsive" id="eq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} NE(t^i) = \frac{H_{max} - H(t^i)}{H_{max}} \end{equation} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$H_{max} = \max _{t^i} H(t^i)$</span>     </span> and <em>H<sub>max</sub>     </em> denotes the maximum value of all the entropies. We modified the TF-IDF values by following equation, <div class="table-responsive" id="eq3">      <div class="display-equation">       <span class="tex mytex">\begin{equation} TF.IDF_{NE}(t^i) = TF.IDF(t^i) \times NE(t^i) \end{equation} </span>       <br/>       <span class="equation-number">(3)</span>      </div>     </div> Terms which are concentrated in few classes should have higher NE whereas terms that are almost uniformly distributed among classes should have lower NE. Although TF.IDF<sub>      <em>NE</em>     </sub> gives better precision than traditional TF-IDF, but Recall is very low as observed in Table <a class="tbl" href="#tab4">4</a>. We propose another approach in Section <a class="sec" href="#sec-8">4.2</a> to improve performance over TF.IDF<sub>      <em>NE</em>     </sub>.</p>    </section>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Class Normalized Entropy Boosting</h3>     </div>     </header>     <p>Here we propose our second approach which handles the low Recall problem mentioned in Section <a class="sec" href="#sec-7">4.1</a>. This approach retains the actual TF-IDF score and boosts the class-specific term&#x0027;s importance as a side information. In this way, we would be able to retain significance of TF-IDF based scores and also be able to give extra boost to known important terms. The entropy measure described in above Section <a class="sec" href="#sec-7">4.1</a> suffers from class size imbalance, mainly for smaller classes. In this approach, we also factor in the class sizes when computing the Importance Weight (IW) of a term. We can calculate the IW of term <em>t<sup>i</sup>     </em> for class <em>c</em> as follows: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\[ IW(t^i_c) = \frac{tc^i_c}{k_c} \] </span>       <br/>      </div>     </div> where <em>k<sub>c</sub>     </em> denotes the number of terms present in class <em>c</em>. Now, we calculate the Class Normalized Entropy (CNE) by considering both entropy and importance according to the following equation. <div class="table-responsive" id="eq4">      <div class="display-equation">       <span class="tex mytex">\begin{equation} TF.IDF_{CNE}(t^i_c) = \left\{\begin{array}{ll} TF.IDF(t^i) + \frac{NE(t^i) \times IW(t^i_c)}{k}, & \text{if } TF.IDF(t^i) \gt 0\\[3pt] 0, & \text{otherwise} \end{array}\right. \end{equation} </span>       <br/>       <span class="equation-number">(4)</span>      </div>     </div> The denominator <em>k</em> works as a normalizing hyper-parameter. Effects of the additional boosting can be controlled by changing the value of <em>k</em>. More detailed effects of <em>k</em> is discussed in Section <a class="sec" href="#sec-12">5.3</a>.</p>    </section>   </section>   <section id="sec-9">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Experimental Details</h2>     </div>    </header>    <p>In our experiments, we used Support Vector Machine (SVM) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>] with linear kernel as our classifier. Many studies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>] found SVM works best with TF-IDF feature vectors in disaster scenario. SVM with three different TF-IDF boosting approaches were used for experiments. <em>TF</em>.<em>IDF</em> denotes simple TF-IDF values, <SmallCap>TF.IDF<sub>      <em>NE</em>     </sub>     </SmallCap> denotes TF-IDF values with Normalized Entropy. Our other approach in Section <a class="sec" href="#sec-8">4.2</a> is denoted as <SmallCap>TF.IDF<sub>      <em>CNE</em>     </sub>     </SmallCap>. We also implemented the approach discussed in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>] called ECCD and denoted as <SmallCap>TF.IDF<sub>      <em>ECCD</em>     </sub>     </SmallCap> in Table <a class="tbl" href="#tab4">4</a><a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>.</p>    <section id="sec-10">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.1</span> Datasets</h3>     </div>     </header>     <p>Three disaster related tweets datasets were used for experimentation. &#x201C;Forum for Information Retrieval Evaluation&#x201D; 2016 (FIRE16) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0006">6</a>] and 2017 (FIRE17) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>] datasets which contain tweets posted during Nepal 2015 earthquake were selected. Class details of FIRE16 and FIRE17 are mentioned in Tables <a class="tbl" href="#tab1">1</a> and <a class="tbl" href="#tab1">1</a> respectively. We also tested with &#x201C;Social Media for Emergency Relief and Preparedness&#x201D; 2017 (SMERP17) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0007">7</a>] dataset containing tweets posted during August 2016 earthquake in Italy. Details of the SMERP17 dataset are given in Table <a class="tbl" href="#tab1">1</a><a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>. We also created a custom dataset by merging SMERP17 and FIRE16 datasets denoted as FIRE16+SMERP17 <a class="tbl" href="#tab1">1</a>. As the number of classes varies between them, we mapped FIRE16 to 4 classes similar to SMERP17. The mapping between the two datasets is given in Table <a class="tbl" href="#tab3">3</a>. We could not find any suitable mapping for class 5 of dataset FIRE16, so we removed all the tweets which occurs only in class 5. All of the above mentioned datasets were divided into train and test sets with 70% and 30% of the total available labeled data respectively. The class details were given in TREC format. Description of each class contains four fields: the class ID, title (small title to denote the class), desc (short description of the class) and narr (detailed narrative of which text should be considered for this class). Example of class description in TREC format is given below for class 7 of FIRE16 dataset and class 1 of SMERP17 dataset.</p> <div style="border:solid; padding:10px"> <p><tt><<em>num</em>> Number: FMT7</tt></p>     <p>     <tt><<em>title</em>> WHAT INFRASTRUCTURE DAMAGE AND RESTORATION WERE BEING REPORTED</tt>     </p>     <p>     <tt><<em>desc</em>> Description: Identify the messages which contain information related to infrastructure damage or restoration.</tt>     </p>     <p>     <tt><<em>narr</em>> A relevant message must mention the damage or restoration of some specific infrastructure resources, such as structures (e.g., dams, houses, mobile tower), communication infrastructure (e.g., roads, runways, railway), electricity, mobile or Internet connectivity, etc. Generalized statements without reference to infrastructure resources would not be relevant.</tt></p> </div> <br/><div style="border:solid; padding:10px"> <p>     <tt><<em>num</em>> Number: SMERP-T1</tt>     </p>     <p>     <tt><<em>title</em>> WHAT RESOURCES ARE AVAILABLE</tt>     </p>     <p>     <tt><<em>desc</em>> Identify messages which describe the availability of some resources.</tt>     </p>     <p>     <tt><<em>narr</em>> A relevant message must mention the availability of some resource like food, drinking water, shelter, clothes, blankets, blood, human resources like volunteers, resources to build or support infrastructure, like tents, water filter, power supply, etc. Messages informing the availability of transport vehicles for assisting the resource distribution process would also be relevant. Also, messages indicating any services like free wi-fi, sms, calling facility etc. will also be relevant. In addition, any message or announcement about donation of money will also be relevant. However, generalized statements without reference to any resource would not be relevant.</tt>     </p> </div>     <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">Class number, title and training and test data counts.</span>     </div>     <table class="table">      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(a) Class specific details of dataset FIRE16</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>Title</strong>        </td>        <td style="text-align:left;">        <strong>Train</strong>        </td>        <td style="text-align:left;">        <strong>Test</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">Resources Available</td>        <td style="text-align:left;">401</td>        <td style="text-align:left;">175</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">Resources Required</td>        <td style="text-align:left;">210</td>        <td style="text-align:left;">81</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">Medical Resources Available</td>        <td style="text-align:left;">231</td>        <td style="text-align:left;">100</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">Medical Resources Required</td>        <td style="text-align:left;">75</td>        <td style="text-align:left;">36</td>       </tr>       <tr>        <td style="text-align:left;">5</td>        <td style="text-align:left;">Resources Specific Locations</td>        <td style="text-align:left;">135</td>        <td style="text-align:left;">53</td>       </tr>       <tr>        <td style="text-align:left;">6</td>        <td style="text-align:left;">Activities NGOs / Government</td>        <td style="text-align:left;">252</td>        <td style="text-align:left;">119</td>       </tr>       <tr>        <td style="text-align:left;">7</td>        <td style="text-align:left;">Infrastructure Damage Restoration</td>        <td style="text-align:left;">178</td>        <td style="text-align:left;">74</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">Average tweets per class</td>        <td style="text-align:left;">211</td>        <td style="text-align:left;">91</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(b) Class specific details of dataset FIRE17</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>Title</strong>        </td>        <td style="text-align:left;">        <strong>Train</strong>        </td>        <td style="text-align:left;">        <strong>Test</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">Need related</td>        <td style="text-align:left;">461</td>        <td style="text-align:left;">207</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">Availability related</td>        <td style="text-align:left;">148</td>        <td style="text-align:left;">55</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">Average tweets per class</td>        <td style="text-align:left;">304</td>        <td style="text-align:left;">131</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(c) Class specific details of dataset SMERP17</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>Title</strong>        </td>        <td style="text-align:left;">        <strong>Train</strong>        </td>        <td style="text-align:left;">        <strong>Test</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">Resources Available</td>        <td style="text-align:left;">228</td>        <td style="text-align:left;">82</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">Resources Required</td>        <td style="text-align:left;">152</td>        <td style="text-align:left;">62</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">Infrastructure Damage, Restoration, Casualties</td>        <td style="text-align:left;">1405</td>        <td style="text-align:left;">611</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">Rescue Activities NGOs / Government</td>        <td style="text-align:left;">255</td>        <td style="text-align:left;">105</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">Average tweets per class</td>        <td style="text-align:left;">510</td>        <td style="text-align:left;">215</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(d) Class specific details of dataset FIRE16 + SMERP17</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>Title</strong>        </td>        <td style="text-align:left;">        <strong>Train</strong>        </td>        <td style="text-align:left;">        <strong>Test</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">Resources Available</td>        <td style="text-align:left;">733</td>        <td style="text-align:left;">367</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">Resources Required</td>        <td style="text-align:left;">402</td>        <td style="text-align:left;">156</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">Infrastructure Damage Restoration</td>        <td style="text-align:left;">1610</td>        <td style="text-align:left;">658</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">Activities NGOs / Government</td>        <td style="text-align:left;">494</td>        <td style="text-align:left;">237</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">Average tweets per class</td>        <td style="text-align:left;">809</td>        <td style="text-align:left;">354</td>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec-11">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.2</span> Preprocessing</h3>     </div>     </header>     <p>Before working with the data we preprocessed and cleaned it by performing the below-mentioned steps in sequence.</p>     <ol class="list-no-style">     <li id="list1" label="(1)"><strong>Acronym Expansion:</strong> Tweets are generally written with various acronyms. We used a modified version of the dictionary given in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0009">9</a>] by adding some extra terms ourselves. All the abbreviated words were replaced by the phrase/words given in the dictionary.<br/></li>     <li id="list2" label="(2)"><strong>Removal of Emoticons and non-ASCII Characters:</strong> Another prevalent problem with tweets is emoticons. We search for and removed all emoticon and non-ASCII characters by pattern matching.<br/></li>     <li id="list3" label="(3)"><strong>Case Folding:</strong> All tweet texts were converted to lower case after all the above mentioned processing was done.<br/></li>     <li id="list4" label="(4)"><strong>Stop-words and Punctuation Removal:</strong> After all the above mentioned steps were done we removed any word from the tweet which is present in the nltk stopwords<a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>.<br/></li>     <li id="list5" label="(5)"><strong>Special Character Removal:</strong> We removed characters like &#x2018;#&#x2019;, &#x2018;@&#x2019; without removing the corresponding hashtags or user mentions. Also, we removed some other special words like &#x201C;rt&#x201D;, &#x201C;via&#x201D; and &#x201C;amp&#x201D; which are not stop-words but contains no value whatsoever.<br/></li>     <li id="list6" label="(6)"><strong>URLs and Phone numbers handling:</strong> URLs&#x2019; and phone numbers present in any tweet was replaced by keywords &#x201C;urlurl&#x201D; and &#x201C;phonenumber&#x201D; respectively.<br/></li>     </ol>     <p>Below we show a tweet in original form and after preprocessing was done:</p>     <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Tweet before and after preprocessing.</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:left;">        <strong>Before:</strong>        </td>        <td>Doctors Italian Relief Corps of the Order of Malta are providing help in areas hit by violent earthquake in Italy <a class="link-inline force-break" href="https://t.co/DDszXXhKgn">https://t.co/DDszXXhKgn</a></td>       </tr>       <tr>        <td style="text-align:left;">        <strong>After:</strong>        </td>        <td>doctors italian relief corps order malta providing help areas hit violent earthquake italy urlurl</td>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec-12">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.3</span> Parameter Tuning and Cross Validation</h3>     </div>     </header>     <p>We have two different types of hyper-parameter. First parameter is the value of <em>k</em> in Equation (<a class="eqn" href="#eq4">4</a>) which decides the contribution of class specific boosting of our approach TF.IDF<sub>      <em>CNE</em>     </sub> and the regularization parameter for SVM classifier. We first tuned the boosting parameter <em>k</em> without tuning the regularization parameter<a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a>. We considered [1, 2, 3, &#x22C5;&#x22C5;&#x22C5;10] as values of <em>k</em> to tune the boosting parameter and found <em>k</em> = 2 gives best result <a class="fn" href="#fn5" id="foot-fn5"><sup>5</sup></a>. We fixed the value of <em>k</em> for all subsequent operations.</p>     <p>We used 5-fold cross validation on the training set to tune the regularization parameter of SVM. It was tuned with values [10<sup>&#x2212; 1</sup>, 10<sup>0</sup>, 10<sup>1</sup>, &#x22C5;&#x22C5;&#x22C5;, 10<sup>4</sup>]. Regularization parameter in SVM indicates the amount of importance to be given to wrong classifications. Higher value signifies higher cost for miss classifications. However, there is a trade-off of incrementing, as it shrinks the margin between classes. As a result we will get a classifier with a small margin. It should be noted that in case of TF.IDF<sub>      <em>CNE</em>     </sub> regularization parameter was tuned after our boosting parameter tuning was done.</p>     <div class="table-responsive" id="tab3">     <div class="table-caption">      <span class="table-number">Table 3:</span>      <span class="table-title">Class mappings between FIRE16 and SMERP17.</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:left;">        <strong>FIRE16 Class</strong>        </td>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>SMERP17 Class</strong>        </td>        <td style="text-align:left;">        <strong>Class</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">Resources Available</td>        <td style="text-align:left;">1</td>        <td style="text-align:left;">Resources Available</td>        <td>1</td>       </tr>       <tr>        <td style="text-align:left;">Medical Resources Available</td>        <td style="text-align:left;">3</td>        <td style="text-align:left;"/>        <td/>       </tr>       <tr>        <td style="text-align:left;">Resources Required</td>        <td style="text-align:left;">2</td>        <td style="text-align:left;">Resources Required</td>        <td>2</td>       </tr>       <tr>        <td style="text-align:left;">Medical Resources Required</td>        <td style="text-align:left;">4</td>        <td style="text-align:left;"/>        <td/>       </tr>       <tr>        <td style="text-align:left;">Resources Specific Locations</td>        <td style="text-align:left;">5</td>        <td style="text-align:left;"/>        <td>-</td>       </tr>       <tr>        <td style="text-align:left;">Activities NGOs / Government</td>        <td style="text-align:left;">6</td>        <td style="text-align:left;">Rescue Activities NGOs / Government</td>        <td>4</td>       </tr>       <tr>        <td style="text-align:left;">Infrastructure damage restoration</td>        <td style="text-align:left;">7</td>        <td style="text-align:left;">Infrastructure Damage, Restoration, Casualties</td>        <td>3</td>       </tr>      </tbody>     </table>     </div>    </section>   </section>   <section id="sec-13">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Results</h2>     </div>    </header>    <p>In this Section, we discuss our findings related to the effects of TF-IDF boosting for disaster related tweets.</p>    <section id="sec-14">     <header>     <div class="title-info">      <h3>       <span class="section-number">6.1</span> Results for the complete collection - all classes considered together</h3>     </div>     </header>     <p>Table <a class="tbl" href="#tab4">4</a> lists the F<sub>1</sub>, Precision and Recall of our experiments on 4 datasets mentioned in Section <a class="sec" href="#sec-10">5.1</a>. We can observe from Table <a class="tbl" href="#tab4">4</a> that incorporating class specific information in the TF-IDF formulation has significantly increased classifier accuracy over traditional TF-IDF in all datasets.</p>     <p>In the NE approach (TF.IDF<sub>      <em>NE</em>     </sub>), we can clearly see that the Precision has increased over traditional TF.IDF but Recall went down bringing down the F<sub>1</sub> score. Although TF.IDF<sub>      <em>NE</em>     </sub> gives better precision than traditional TF-IDF, it fails to generalize where new data points do not contain any important terms from the existing training set vocabulary. As a result, NE value for those new terms will be very low and TF.IDF<sub>      <em>NE</em>     </sub> gives very low score to that data point. This happens because of the multiplicative nature of Equation (<a class="eqn" href="#eq3">3</a>). This is in-fact one of the limitations of TF.IDF<sub>      <em>NE</em>     </sub> boosting approach. As we are multiplying the boosted value with TF-IDF, if the boosting value is low it will bring down the overall score for TF.IDF<sub>      <em>NE</em>     </sub>. We found this happens significantly more in smaller classes (small number of data points in the training set) because the vocabulary size for that class will be very limited. However, this technique might be useful in scenarios where Precision has higher priority than Recall.</p>     <p>Our second approach called TF.IDF<sub>      <em>CNE</em>     </sub> generalizes better than TF.IDF<sub>      <em>NE</em>     </sub> as seen in Table <a class="tbl" href="#tab4">4</a>. This technique is able to handle unseen terms better and works well for smaller datasets where some of the actual important terms may not have sufficient statistics in the observed data as it incorporates the vocabulary size of each class. Our approach gives better result than TF.IDF<sub>      <em>ECCD</em>     </sub>. However, we still see Recall is low in the first two datasets. This is happening because of the small number of data points. One of the obvious remedy of this problem is to have more data. FIRE16 and FIRE17 have 211 and 304 data point per class on average respectively as mentioned in Table <a class="tbl" href="#tab1">1</a> and <a class="tbl" href="#tab1">1</a>. More data will most likely include all possible important terms to the vocabulary. This behavior can be observed in case of SMERP17 and the FIRE16 + SMERP17 dataset as they on average have 510 (Table <a class="tbl" href="#tab1">1</a>) and 809 (Table <a class="tbl" href="#tab1">1</a>) data points per class respectively.</p>     <div class="table-responsive" id="tab4">     <div class="table-caption">      <span class="table-number">Table 4:</span>      <span class="table-title">Consolidated results of TF-IDF boosting approaches.</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:left;">        <strong>Dataset</strong>        </td>        <td style="text-align:left;">        <strong>Feature</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub> score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td rowspan="4" style="vertical-align:middle;">FIRE16</td>        <td style="text-align:left;">TF.IDF</td>        <td style="text-align:left;">0.6701</td>        <td style="text-align:left;">0.6526</td>        <td style="text-align:left;">        <strong>0.6936</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>NE</em>        </sub>        </td>        <td style="text-align:left;">0.6535</td>        <td style="text-align:left;">0.7396</td>        <td style="text-align:left;">0.6081</td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>ECCD</em>        </sub>        </td>        <td style="text-align:left;">0.6801</td>        <td style="text-align:left;">0.7633</td>        <td style="text-align:left;">0.6284</td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>CNE</em>        </sub>        </td>        <td style="text-align:left;">        <strong>0.6856</strong>        </td>        <td style="text-align:left;">        <strong>0.7643</strong>        </td>        <td style="text-align:left;">0.6380</td>       </tr>       <tr>        <td rowspan="4" style="vertical-align:middle;">FIRE17</td>        <td style="text-align:left;">TF.IDF</td>        <td style="text-align:left;">0.8751</td>        <td style="text-align:left;">0.8703</td>        <td style="text-align:left;">        <strong>0.8801</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>NE</em>        </sub>        </td>        <td style="text-align:left;">0.8417</td>        <td style="text-align:left;">0.8647</td>        <td style="text-align:left;">0.8237</td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>ECCD</em>        </sub>        </td>        <td style="text-align:left;">0.8710</td>        <td style="text-align:left;">0.8831</td>        <td style="text-align:left;">0.8600</td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>CNE</em>        </sub>        </td>        <td style="text-align:left;">        <strong>0.8767</strong>        </td>        <td style="text-align:left;">        <strong>0.8849</strong>        </td>        <td style="text-align:left;">0.8692</td>       </tr>       <tr>        <td rowspan="4" style="vertical-align:middle;">SMERP17</td>        <td style="text-align:left;">TF.IDF</td>        <td style="text-align:left;">0.8605</td>        <td style="text-align:left;">0.8629</td>        <td style="text-align:left;">0.8604</td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>NE</em>        </sub>        </td>        <td style="text-align:left;">0.8771</td>        <td style="text-align:left;">0.8851</td>        <td style="text-align:left;">        <strong>0.8711</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>ECCD</em>        </sub>        </td>        <td style="text-align:left;">0.8677</td>        <td style="text-align:left;">        <strong>0.9082</strong>        </td>        <td style="text-align:left;">0.8333</td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>CNE</em>        </sub>        </td>        <td style="text-align:left;">        <strong>0.8825</strong>        </td>        <td style="text-align:left;">0.8994</td>        <td style="text-align:left;">0.8680</td>       </tr>       <tr>        <td rowspan="4" style="vertical-align:middle;">FIRE16 + SMERP17</td>        <td style="text-align:left;">TF.IDF</td>        <td style="text-align:left;">0.8034</td>        <td style="text-align:left;">0.8276</td>        <td style="text-align:left;">0.7831</td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>NE</em>        </sub>        </td>        <td style="text-align:left;">0.8365</td>        <td style="text-align:left;">0.8386</td>        <td style="text-align:left;">        <strong>0.8350</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>ECCD</em>        </sub>        </td>        <td style="text-align:left;">0.8443</td>        <td style="text-align:left;">        <strong>0.8686</strong>        </td>        <td style="text-align:left;">0.8223</td>       </tr>       <tr>        <td style="text-align:left;">TF.IDF<sub>         <em>CNE</em>        </sub>        </td>        <td style="text-align:left;">        <strong>0.8452</strong>        </td>        <td style="text-align:left;">0.8663</td>        <td style="text-align:left;">0.8260</td>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec-15">     <header>     <div class="title-info">      <h3>       <span class="section-number">6.2</span> Results for individual classes</h3>     </div>     </header>     <p>In this Section we look more deeply into individual class label performances of our proposed approaches. Consolidated performances of all the approaches mentioned in Section <a class="sec" href="#sec-8">4.2</a> is provided in Table <a class="tbl" href="#tab5">5</a>, <a class="tbl" href="#tab6">6</a>, <a class="tbl" href="#tab7">7</a> and <a class="tbl" href="#tab8">8</a>. We see better performance of our proposed approaches than traditional TF-IDF when available training data was large. Our approach TF.IDF<sub>      <em>CNE</em>     </sub> performed poorly than traditional TF.IDF for only for class 4 of FIRE16 dataset as observed in Table <a class="tbl" href="#tab5">5</a>. It should also be noted that class 4 of FIRE16 has only 75 training data among all the classes across all datasets as seen on Table <a class="tbl" href="#tab1">1</a>. Figure 1a, 1b, 1c, 1d display the F<sub>1</sub> scores of FIRE16, FIRE17, SMERP17 and FIRE16 + SMERP17 datasets respectively.</p>     <div class="table-responsive" id="tab5">     <div class="table-caption">      <span class="table-number">Table 5:</span>      <span class="table-title">Class specific results for FIRE16.</span>     </div>     <table class="table">      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(a) Class specific results for FIRE16 dataset with TF.IDF</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.6949</td>        <td style="text-align:left;">0.7028</td>        <td style="text-align:left;">0.6871</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.6708</td>        <td style="text-align:left;">0.6543</td>        <td style="text-align:left;">0.6883</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.7794</td>        <td style="text-align:left;">0.7600</td>        <td style="text-align:left;">0.8000</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.4666</td>        <td style="text-align:left;">0.3888</td>        <td style="text-align:left;">0.5833</td>       </tr>       <tr>        <td style="text-align:left;">5</td>        <td style="text-align:left;">0.5420</td>        <td style="text-align:left;">0.5471</td>        <td style="text-align:left;">0.5370</td>       </tr>       <tr>        <td style="text-align:left;">6</td>        <td style="text-align:left;">0.6120</td>        <td style="text-align:left;">0.5966</td>        <td style="text-align:left;">0.6283</td>       </tr>       <tr>        <td style="text-align:left;">7</td>        <td style="text-align:left;">0.9251</td>        <td style="text-align:left;">0.9189</td>        <td style="text-align:left;">0.9315</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(b) Class specific results for FIRE16 dataset with TF.IDF<sub>          <em>NE</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.7288</td>        <td style="text-align:left;">0.7206</td>        <td style="text-align:left;">0.7371</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7125</td>        <td style="text-align:left;">0.7215</td>        <td style="text-align:left;">0.7037</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.8205</td>        <td style="text-align:left;">0.8421</td>        <td style="text-align:left;">0.8000</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.3333</td>        <td style="text-align:left;">0.6666</td>        <td style="text-align:left;">0.2222</td>       </tr>       <tr>        <td style="text-align:left;">5</td>        <td style="text-align:left;">0.5000</td>        <td style="text-align:left;">0.6285</td>        <td style="text-align:left;">0.4150</td>       </tr>       <tr>        <td style="text-align:left;">6</td>        <td style="text-align:left;">0.6139</td>        <td style="text-align:left;">0.6875</td>        <td style="text-align:left;">0.5546</td>       </tr>       <tr>        <td style="text-align:left;">7</td>        <td style="text-align:left;">0.8652</td>        <td style="text-align:left;">0.9104</td>        <td style="text-align:left;">0.8243</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(c) Class specific results for FIRE16 dataset with TF.IDF<sub>          <em>ECCD</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.7365</td>        <td style="text-align:left;">0.7303</td>        <td style="text-align:left;">0.7428</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7374</td>        <td style="text-align:left;">0.7468</td>        <td style="text-align:left;">0.7283</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.8242</td>        <td style="text-align:left;">0.8651</td>        <td style="text-align:left;">0.7700</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.4230</td>        <td style="text-align:left;">0.6875</td>        <td style="text-align:left;">0.3055</td>       </tr>       <tr>        <td style="text-align:left;">5</td>        <td style="text-align:left;">0.5617</td>        <td style="text-align:left;">0.6944</td>        <td style="text-align:left;">0.4716</td>       </tr>       <tr>        <td style="text-align:left;">6</td>        <td style="text-align:left;">0.5999</td>        <td style="text-align:left;">0.6923</td>        <td style="text-align:left;">0.5294</td>       </tr>       <tr>        <td style="text-align:left;">7</td>        <td style="text-align:left;">0.8873</td>        <td style="text-align:left;">0.9264</td>        <td style="text-align:left;">0.8513</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(d) Class specific results for FIRE16 dataset with TF.IDF<sub>          <em>CNE</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.7380</td>        <td style="text-align:left;">0.7277</td>        <td style="text-align:left;">0.7485</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7530</td>        <td style="text-align:left;">0.7530</td>        <td style="text-align:left;">0.7530</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.8210</td>        <td style="text-align:left;">0.8666</td>        <td style="text-align:left;">0.7800</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.4230</td>        <td style="text-align:left;">0.6875</td>        <td style="text-align:left;">0.3055</td>       </tr>       <tr>        <td style="text-align:left;">5</td>        <td style="text-align:left;">0.5617</td>        <td style="text-align:left;">0.6944</td>        <td style="text-align:left;">0.4716</td>       </tr>       <tr>        <td style="text-align:left;">6</td>        <td style="text-align:left;">0.5999</td>        <td style="text-align:left;">0.6923</td>        <td style="text-align:left;">0.5294</td>       </tr>       <tr>        <td style="text-align:left;">7</td>        <td style="text-align:left;">0.9027</td>        <td style="text-align:left;">0.9285</td>        <td style="text-align:left;">0.8783</td>       </tr>      </tbody>     </table>     </div>     <div class="table-responsive" id="tab6">     <div class="table-caption">      <span class="table-number">Table 6:</span>      <span class="table-title">Class specific results for FIRE17.</span>     </div>     <table class="table">      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(a) Class specific results for FIRE17 dataset with TF.IDF</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.9466</td>        <td style="text-align:left;">0.9512</td>        <td style="text-align:left;">0.9420</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.8035</td>        <td style="text-align:left;">0.7894</td>        <td style="text-align:left;">0.8181</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(b) Class specific results for FIRE17 dataset with TF.IDF<sub>          <em>NE</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.9383</td>        <td style="text-align:left;">0.9209</td>        <td style="text-align:left;">0.9565</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7450</td>        <td style="text-align:left;">0.8085</td>        <td style="text-align:left;">0.6909</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(c) Class specific results for FIRE17 dataset with TF.IDF<sub>          <em>ECCD</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.9496</td>        <td style="text-align:left;">0.9428</td>        <td style="text-align:left;">0.9565</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7924</td>        <td style="text-align:left;">0.8235</td>        <td style="text-align:left;">0.7636</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(d) Class specific results for FIRE17 dataset with TF.IDF<sub>          <em>CNE</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.9496</td>        <td style="text-align:left;">0.9428</td>        <td style="text-align:left;">0.9428</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.8037</td>        <td style="text-align:left;">0.8269</td>        <td style="text-align:left;">0.7818</td>       </tr>      </tbody>     </table>     </div>     <div class="table-responsive" id="tab7">     <div class="table-caption">      <span class="table-number">Table 7:</span>      <span class="table-title">Class specific results for SMERP17.</span>     </div>     <table class="table">      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(a) Class specific results for SMERP17 dataset with TF.IDF</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.7931</td>        <td style="text-align:left;">0.7500</td>        <td style="text-align:left;">0.8414</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7833</td>        <td style="text-align:left;">0.7966</td>        <td style="text-align:left;">0.7704</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.9901</td>        <td style="text-align:left;">0.9885</td>        <td style="text-align:left;">0.9918</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.8756</td>        <td style="text-align:left;">0.9166</td>        <td style="text-align:left;">0.8380</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(b) Class specific results for SMERP17 dataset with TF.IDF<sub>          <em>NE</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.8352</td>        <td style="text-align:left;">0.8068</td>        <td style="text-align:left;">0.8658</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7758</td>        <td style="text-align:left;">0.8181</td>        <td style="text-align:left;">0.7377</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.9902</td>        <td style="text-align:left;">0.9854</td>        <td style="text-align:left;">0.9950</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.9073</td>        <td style="text-align:left;">0.9300</td>        <td style="text-align:left;">0.8857</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(c) Class specific results for SMERP17 dataset with TF.IDF<sub>          <em>ECCD</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.8148</td>        <td style="text-align:left;">0.8250</td>        <td style="text-align:left;">0.8048</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7747</td>        <td style="text-align:left;">0.8600</td>        <td style="text-align:left;">0.7049</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.9934</td>        <td style="text-align:left;">0.9918</td>        <td style="text-align:left;">0.9950</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.8877</td>        <td style="text-align:left;">0.9570</td>        <td style="text-align:left;">0.8285</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(d) Class specific results for SMERP17 dataset with TF.IDF<sub>          <em>CNE</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.8352</td>        <td style="text-align:left;">0.8255</td>        <td style="text-align:left;">0.8658</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7931</td>        <td style="text-align:left;">0.8363</td>        <td style="text-align:left;">0.7540</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.9918</td>        <td style="text-align:left;">0.9886</td>        <td style="text-align:left;">0.9950</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.9000</td>        <td style="text-align:left;">0.9473</td>        <td style="text-align:left;">0.8571</td>       </tr>      </tbody>     </table>     </div>     <div class="table-responsive" id="tab8">     <div class="table-caption">      <span class="table-number">Table 8:</span>      <span class="table-title">Class specific results for FIRE16 + SMERP17.</span>     </div>     <table class="table">      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(a) Class specific results for FIRE16 + SMERP17 dataset with TF.IDF</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.7808</td>        <td style="text-align:left;">0.8118</td>        <td style="text-align:left;">0.7520</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7622</td>        <td style="text-align:left;">0.8385</td>        <td style="text-align:left;">0.6987</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.9749</td>        <td style="text-align:left;">0.9771</td>        <td style="text-align:left;">0.9726</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.6957</td>        <td style="text-align:left;">0.6829</td>        <td style="text-align:left;">0.7089</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(b) Class specific results for FIRE16 + SMERP17 dataset with TF.IDF<sub>          <em>NE</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.8354</td>        <td style="text-align:left;">0.8483</td>        <td style="text-align:left;">0.8228</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.7973</td>        <td style="text-align:left;">0.8133</td>        <td style="text-align:left;">0.7820</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.9756</td>        <td style="text-align:left;">0.9756</td>        <td style="text-align:left;">0.9756</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.7377</td>        <td style="text-align:left;">0.7171</td>        <td style="text-align:left;">0.7594</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(c) Class specific results for FIRE16 + SMERP17 dataset with TF.IDF<sub>          <em>ECCD</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.8446</td>        <td style="text-align:left;">0.8768</td>        <td style="text-align:left;">0.8147</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.8054</td>        <td style="text-align:left;">0.8613</td>        <td style="text-align:left;">0.7564</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.9831</td>        <td style="text-align:left;">0.9907</td>        <td style="text-align:left;">0.9756</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.7441</td>        <td style="text-align:left;">0.7457</td>        <td style="text-align:left;">0.7426</td>       </tr>      </tbody>      <tbody>       <tr>        <td colspan="4" style="text-align:center;">        <strong>(d) Class specific results for FIRE16 + SMERP17 dataset with TF.IDF<sub>          <em>CNE</em>         </sub>        </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Class</strong>        </td>        <td style="text-align:left;">        <strong>F<sub>1</sub>-score</strong>        </td>        <td style="text-align:left;">        <strong>Precision</strong>        </td>        <td style="text-align:left;">        <strong>Recall</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">1</td>        <td style="text-align:left;">0.8455</td>        <td style="text-align:left;">0.8724</td>        <td style="text-align:left;">0.8201</td>       </tr>       <tr>        <td style="text-align:left;">2</td>        <td style="text-align:left;">0.8095</td>        <td style="text-align:left;">0.8623</td>        <td style="text-align:left;">0.7628</td>       </tr>       <tr>        <td style="text-align:left;">3</td>        <td style="text-align:left;">0.9802</td>        <td style="text-align:left;">0.9817</td>        <td style="text-align:left;">0.9787</td>       </tr>       <tr>        <td style="text-align:left;">4</td>        <td style="text-align:left;">0.7457</td>        <td style="text-align:left;">0.7489</td>        <td style="text-align:left;">0.7426</td>       </tr>      </tbody>     </table>     </div>     <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191621/images/www18companion-360-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">F<sub>1</sub> scores of different classes</span>     </div>     </figure>    </section>   </section>   <section id="sec-16">    <header>     <div class="title-info">     <h2>      <span class="section-number">7</span> Conclusion</h2>     </div>    </header>    <p>In this paper we studied the usefulness of class specific TF-IDF score boosting. It is evident that incorporating class details by the means of entropy and term frequencies can improve classifier accuracy over a purely TF-IDF scoring scheme. We showed our approach to work on 4 different multi-label disaster related datasets of short-texts. However, we also found that our approach works better if the classes are sufficiently large. In our future work we want to handle boosting such a way so that it can handle imbalanced class sizes. Another improvement can be explored if extra dimensional info can be incorporated for better perform.</p>   </section>  </section>  <section class="back-matter">   <section id="sec-17">    <header>     <div class="title-info">     <h2>ACKNOWLEDGMENTS</h2>     </div>    </header>    <p>The authors would like to thank the anonymous referees for their valuable comments and helpful suggestions. This work is supported by the u Vivesvaraya PhD Scheme for Electronics and IT, Ministry of Electronics &#x0026; Information Technology(MeitY), Government of India n der Grant No.:&#x02DC; EE/2016-17/034/MLA/MZAK/0235 EE/2016-17/034/MLA/MZAK/0235 .</p>   </section>   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Moumita Basu, Anurag Roy, Kripabandhu Ghosh, Somprakash Bandyopadhyay, and Saptarshi Ghosh. 2017. Microblog Retrieval in a Disaster Situation: A New Test Collection for Evaluation. In <em>      <em>Proceedings of the First International Workshop on Exploitation of Social Media for Emergency Relief and Preparedness co-located with European Conference on Information Retrieval, SMERP@ECIR 2017, Aberdeen, UK.</em></em> 22&#x2013;31. <a class="link-inline force-break"      href="http://ceur-ws.org/Vol-1832/SMERP_2017_peer_review_paper_3.pdf"      target="_blank">http://ceur-ws.org/Vol-1832/SMERP_2017_peer_review_paper_3.pdf</a></li>     <li id="BibPLXBIB0002" label="[2]">Iyad Batal and Milos Hauskrecht. 2009. Boosting KNN text classification accuracy by using supervised term weighting schemes. In <em>      <em>Proceedings of the 18th ACM conference on Information and knowledge management</em></em>. ACM, 2041&#x2013;2044.</li>     <li id="BibPLXBIB0003" label="[3]">Constantinos Boulis and Mari Ostendorf. 2005. Text classification by augmenting the bag-of-words representation with redundancy-compensated bigrams. In <em>      <em>Proc. of the International Workshop in Feature Selection in Data Mining</em></em>. Citeseer, 9&#x2013;16.</li>     <li id="BibPLXBIB0004" label="[4]">Corinna Cortes and Vladimir Vapnik. 1995. Support-vector networks. <em>      <em>Machine learning</em>     </em>20, 3 (1995), 273&#x2013;297.</li>     <li id="BibPLXBIB0005" label="[5]">George Forman. 2008. BNS feature scaling: an improved representation over tf-idf for svm text classification. In <em>      <em>Proceedings of the 17th ACM conference on Information and knowledge management</em></em>. ACM, 263&#x2013;270.</li>     <li id="BibPLXBIB0006" label="[6]">Saptarshi Ghosh and Kripabandhu Ghosh. 2016. Overview of the FIRE 2016 Microblog track: Information Extraction from Microblogs Posted during Disasters. In <em>      <em>Working notes of FIRE 2016 - Forum for Information Retrieval Evaluation, Kolkata, India</em></em>. 56&#x2013;61. <a class="link-inline force-break" href="http://ceur-ws.org/Vol-1737/T2-1.pdf"      target="_blank">http://ceur-ws.org/Vol-1737/T2-1.pdf</a></li>     <li id="BibPLXBIB0007" label="[7]">Saptarshi Ghosh, Kripabandhu Ghosh, Debasis Ganguly, Tanmoy Chakraborty, Gareth&#x00A0;J.F. Jones, and Marie-Francine Moens. 2017. ECIR 2017 Workshop on Exploitation of Social Media for Emergency Relief and Preparedness (SMERP 2017). <em>      <em>SIGIR Forum</em>     </em>51, 1 (Aug. 2017), 36&#x2013;41. <a class="link-inline force-break" href="https://doi.org/10.1145/3130332.3130338"      target="_blank">https://doi.org/10.1145/3130332.3130338</a></li>     <li id="BibPLXBIB0008" label="[8]">Samujjwal Ghosh, Srijith P.&#x00A0;K., and Maunendra&#x00A0;Sankar Desarkar. 2017. Using social media for classifying actionable insights in disaster scenario. <em>      <em>International Journal of Advances in Engineering Sciences</em>     </em>9, 4 (Dec. 2017), 224&#x2013;237. <a class="link-inline force-break"      href="https://doi.org/10.1007/s12572-017-0197-2"      target="_blank">https://doi.org/10.1007/s12572-017-0197-2</a></li>     <li id="BibPLXBIB0009" label="[9]">Muhammad Imran, Prasenjit Mitra, and Carlos Castillo. 2016. Twitter as a Lifeline: Human-annotated Twitter Corpora for NLP of Crisis-related Messages. <em>      <em>CoRR</em>     </em>abs/1605.05894 (2016). arxiv:1605.05894 <a class="link-inline force-break" href="http://arxiv.org/abs/1605.05894"      target="_blank">http://arxiv.org/abs/1605.05894</a></li>     <li id="BibPLXBIB0010" label="[10]">Randy Joy and Magno Ventayen. 2017. Classification of Local Language Disaster Related Tweets in Micro Blogs. In <em>      <em>Asia Pacific Journal of Multidisciplinary Research</em></em>.</li>     <li id="BibPLXBIB0011" label="[11]">Prannay Khosla, Moumita Basu, Kripabandhu Ghosh, and Saptarshi Ghosh. 2017. Microblog Retrieval for Post-Disaster Relief: Applying and Comparing Neural IR Models. <em>      <em>arXiv preprint arXiv:1707.06112</em></em> (2017).</li>     <li id="BibPLXBIB0012" label="[12]">Christine Largeron, Christophe Moulin, and Mathias G&#x00E9;ry. 2011. Entropy based feature selection for text categorization. In <em>      <em>Proceedings of the 2011 ACM Symposium on Applied Computing</em></em>. ACM, 924&#x2013;928.</li>     <li id="BibPLXBIB0013" label="[13]">Hongmin Li, Doina Caragea, Cornelia Caragea, and Nic Herndon. 2017. Disaster response aided by tweet classification with a domain adaptation approach. <em>      <em>Journal of Contingencies and Crisis Management</em>     </em> (2017).</li>     <li id="BibPLXBIB0014" label="[14]">Ying Liu, Han&#x00A0;Tong Loh, and Aixin Sun. 2009. Imbalanced text classification: A term weighting approach. <em>      <em>Expert systems with Applications</em>     </em>36, 1 (2009), 690&#x2013;701.</li>     <li id="BibPLXBIB0015" label="[15]">Xinghua Lu, Bin Zheng, Atulya Velivelli, and ChengXiang Zhai. 2006. Enhancing text categorization with semantic-enriched representation and training data augmentation. <em>      <em>Journal of the American Medical Informatics Association</em>     </em>13, 5 (2006), 526&#x2013;535.</li>     <li id="BibPLXBIB0016" label="[16]">Justin Martineau and Tim Finin. 2009. Delta TFIDF: An Improved Feature Space for Sentiment Analysis.<em>      <em>Icwsm</em>     </em>9 (2009), 106.</li>     <li id="BibPLXBIB0017" label="[17]">Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg&#x00A0;S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In <em>      <em>Advances in neural information processing systems</em></em>. 3111&#x2013;3119.</li>     <li id="BibPLXBIB0018" label="[18]">Beverly&#x00A0;Estephany Parilla-Ferrer, PL Fernandez, and JT Ballena. 2014. Automatic Classification of Disaster-Related Tweets. In <em>      <em>Proc. International conference on Innovative Engineering Technologies (ICIET)</em></em>. 62.</li>     <li id="BibPLXBIB0019" label="[19]">Robin&#x00A0;L Plackett. 1983. Karl Pearson and the chi-squared test. <em>      <em>International Statistical Review/Revue Internationale de Statistique</em>     </em> (1983), 59&#x2013;72.</li>     <li id="BibPLXBIB0020" label="[20]">J.&#x00A0;R. Ragini and P.&#x00A0;M.&#x00A0;R. Anand. 2016. An empirical analysis and classification of crisis related tweets. In <em>      <em>2016 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC)</em></em>. 1&#x2013;4. <a class="link-inline force-break"      href="https://doi.org/10.1109/ICCIC.2016.7919608"      target="_blank">https://doi.org/10.1109/ICCIC.2016.7919608</a></li>     <li id="BibPLXBIB0021" label="[21]">Fuji Ren and Mohammad&#x00A0;Golam Sohrab. 2013. Class-indexing-based term weighting for automatic text classification. <em>      <em>Information Sciences</em>     </em>236 (2013), 109&#x2013;125.</li>     <li id="BibPLXBIB0022" label="[22]">Yang Song, Ding Zhou, Jian Huang, Isaac&#x00A0;G Councill, Hongyuan Zha, and C&#x00A0;Lee Giles. 2006. Boosting the feature space: Text classification for unstructured data on the web. In <em>      <em>Data Mining, 2006. ICDM&#x2019;06. Sixth International Conference on</em></em>. IEEE, 1064&#x2013;1069.</li>     <li id="BibPLXBIB0023" label="[23]">Hien To, Sumeet Agrawal, Seon&#x00A0;Ho Kim, and Cyrus Shahabi. 2017. On Identifying Disaster-Related Tweets: Matching-based or Learning-based?. In <em>      <em>Multimedia Big Data (BigMM), 2017 IEEE Third International Conference on</em></em>. IEEE, 330&#x2013;337.</li>     <li id="BibPLXBIB0024" label="[24]">Hao Wang and Sanhong Deng. 2017. A paper-text perspective: Studies on the influence of feature granularity for Chinese short-text-classification in the Big Data era. <em>      <em>The Electronic Library</em>     </em>35, 4 (2017), 689&#x2013;708. <a class="link-inline force-break" href="https://doi.org/10.1108/EL-09-2016-0192"      target="_blank">https://doi.org/10.1108/EL-09-2016-0192</a></li>     <li id="BibPLXBIB0025" label="[25]">Tao Wang, Yi Cai, Ho-fung Leung, Zhiwei Cai, and Huaqing Min. 2015. Entropy-based term weighting schemes for text categorization in VSM. In <em>      <em>Tools with Artificial Intelligence (ICTAI), 2015 IEEE 27th International Conference on</em></em>. IEEE, 325&#x2013;332.</li>     <li id="BibPLXBIB0026" label="[26]">Yiming Yang and Jan&#x00A0;O Pedersen. 1997. A comparative study on feature selection in text categorization. In <em>      <em>International Conference on Machine Learning</em></em>, Vol.&#x00A0;97. 412&#x2013;420.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>The source code to reproduce the study can be found on <a class="link-inline force-break" target="_blank" href="https://github.com/samiith/smerp18.git">github</a></p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>It is to be noted that data count may vary from the original dataset mentioned. Twitter does not allow direct tweet sharing, tweets were downloaded before the experiments and some tweets may not be retrieved if it is deleted or made private.</p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a><a class="link-inline force-break"     href="https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/stopwords.zip">https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/stopwords.zip</a>   </p>   <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>Regularization parameter was set to 1 during boosting parameter <em>k</em> was tuned.</p>   <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>Results in Table <a class="tbl" href="#tab4">4</a> for TF.IDF<sub><em>CNE</em></sub> is after regularization parameter was tuned.</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18 Compaion, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3191621">https://doi.org/10.1145/3184558.3191621</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
