<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Blurb Mining : Discovering Interesting Excerpts from E-commerce Product Reviews</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
<link rel="cite-as" href="https://doi.org/10.1145/3184558.3191626"/></head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3191626'>https://doi.org/10.1145/3184558.3191626</a>.
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3191626'>https://w3id.org/oa/10.1145/3184558.3191626</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Blurb Mining : Discovering Interesting Excerpts from E-commerce Product Reviews</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Saratchandra</span> <span class="surName">Indrakanti</span> eBay Inc., 2025 Hamilton AveSan Jose, California 95125, <a href="mailto:sindrakanti@ebay.com">sindrakanti@ebay.com</a>
        </div>
        <div class="author">
          <span class="givenName">Gyanit</span> <span class="surName">Singh</span> eBay Inc., 2025 Hamilton AveSan Jose, California 95125, <a href="mailto:gysingh@ebay.com">gysingh@ebay.com</a>
        </div>
        <div class="author">
          <span class="givenName">Justin</span> <span class="surName">House</span> eBay Inc., 2025 Hamilton AveSan Jose, California 95125, <a href="mailto:juhouse@ebay.com">juhouse@ebay.com</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191626" target="_blank">https://doi.org/10.1145/3184558.3191626</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Product reviews on modern e-commerce websites have evolved into repositories of valuable firsthand opinions on products. Showcasing the opinions that reviewers express on a product in a succinct way can not only promote the product, but also provide an engaging experience that simplifies the shopping journey for online shoppers. In the case of traditional media such as movies and books, employing <em>blurbs</em> or excerpts from critic reviews for promotional purposes is an established practice among movie publicists and book editors that has proven to be an effective way of capturing attention of customers. Such excerpts can be discovered from e-commerce product reviews to highlight interesting reviewer opinions and add emotive elements to otherwise bland e-commerce product pages. While traditional movie or book blurbs are manually extracted, they must be automatically extracted from e-commerce product reviews owing to the scale of catalogues. Further, traditional blurbs are generally phrased to be very positive in tone and sometimes may take some words out of context. However, excerpts for e-commerce products must represent the true opinions of the reviewers and must capture the context in which the words were used to retain trust of users. To that end, we introduce the problem of extracting engaging excerpts from e-commerce product reviews in this paper. We present methods to automatically discover such excerpts from reviews at scale by leveraging natural language properties such as syntactic structure of sentences and sentiment, and discuss some of the underlying challenges. We further present an evaluation of the effectiveness of the proposed methods in terms of the quality of the blurbs generated and their ranking orders produced.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS Concepts:</span> • <strong>Information systems</strong> → <strong>Information extraction;</strong> <em>Sentiment analysis;</em> <em>Summarization;</em> • <strong>Computing methodologies</strong> → Language resources;</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style="font-weight:bold;"><small>Keywords:</small></span> <span class="keyword"><small>Blurbs</small>,</span> <span class="keyword"><small>Opinion Mining</small>,</span> <span class="keyword"><small>Product Reviews</small>,</span> <span class="keyword"><small>Aspect Mining</small>,</span> <span class="keyword"><small>E-commerce</small>,</span> <span class="keyword"><small>Sentiment Analysis</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Saratchandra Indrakanti, Gyanit Singh, and Justin House. 2018. Blurb Mining : Discovering Interesting Excerpts from E-commerce Product Reviews. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em> <em>April 23–27, 2018 (WWW ’18 Companion),</em> <em>Lyon, France. ACM, New York, NY, USA</em> 7 Pages. <a href="https://doi.org/10.1145/3184558.3191626" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3184558.3191626</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <p>Employing excerpts from critic reviews or <em>blurbs</em> as a promotional tool has been a long-established practice in the publishing and media industries. Movie watchers and book readers often come across excerpts such as <em>“The must-see movie of the season”</em> in movie advertisements or <em>“Every single word has immense value”</em> on book covers, attributed to seasoned critics in the field whom the target audience trust. Movie publicists and book editors meticulously select such excerpts that speak about certain characteristics of the subject that appeal to potential audience and pique their interest [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>]. In recent years, websites of various consumer products have been quoting excerpts from expert reviews as promotional verbiage for the products. The combination of interesting excerpts, or blurbs, that entice the audience along with the credibility of the review author, can capture customer attention to a product.</p>
      <p>The concept of blurbs, which have traditionally been used in media and publishing industries, easily lends itself to modern e-commerce websites. Modern e-commerce websites have vast catalogues of products listed on their platforms, offering their customers with a wide array of choices. Many of these products attract a large number of reviews from buyers who share their firsthand experiences in using the product. Online shoppers have increasingly been relying on product reviews to make their buying decisions. Nevertheless, owing to the large selection of products listed on these websites and the growing content on the product pages, it becomes increasingly unrealistic to expect shoppers to read all the reviews for a product. This necessitates introducing techniques to showcase the opinions about a product in a succinct and personable way to not only capture user attention, but also to improve their shopping experience. To that end, blurbs which have been extensively used in the media industry, are very well-suited to e-commerce products. For instance, <em>“Great story and magnificent graphics!”</em>, a blurb from reviews for a video game, or <em>“Images are super sharp, great noise control”</em>, a camera blurb, provide concise yet informative glimpses of the products.</p>
      <figure id="fig1">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191626/images/www18companion-365-fig1.jpg" class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class="figure-title">Illustration of a blurb showcased on an e-commerce product page</span>
        </div>
      </figure>
      <p></p>
      <p>Conventionally, blurbs are meticulously hand-picked by publicists from critic reviews. However, this is not possible in the case of e-commerce products, owing to the scale of modern e-commerce platforms which may have hundreds of millions of products listed in their catalogues. Methods must be developed to automatically discover and extract blurbs from e-commerce product reviews at scale. There are several distinctions that blurb mining methods must pay attention to. First, while movie or book blurbs are known to paraphrase the original reviews [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>], and occasionally represent words out of context, it is critical that e-commerce product blurbs ensure that the context of an excerpt is retained and refrain from exaggeration in order to preserve user trust in the platform. Further, in the case of an e-commerce website, the goal is to find enticing and representative blurbs for a given product, rather than promoting one product over another. In addition to this, blurbs don't necessarily have to be entire sentences, but can be succinct excerpts of sentences ensuring they retain the context, unlike many existing extractive summarization tasks. Specifically, taking note of the observation that reviewers often write long sentences where they may discuss multiple topics, it is important to identify excerpts of sentences to ensure that blurbs are succinct and focused on a topic. In addition to this, blurbs must comprise of product-specific opinions rather than generic statements, so that they can be informative to online shoppers. For instance, the excerpt <em>“great lens, love the low light ability”</em> is more informative than a generic excerpt such as <em>“I love this product a lot”</em></p>
      <p>In this paper, we introduce the problem of automatically discovering blurbs from product reviews. We will describe the methodology developed and discuss the challenges involved in achieving this at scale. To mine blurbs from product reviews, we identify excerpts containing product-specific opinions and subsequently rank them to discover the best ones. We employ a three-phase process that includes aspect mining, excerpt extraction and excerpt ranking to achieve this. We first discover product aspects, or attributes of a product discussed in the reviews, as part of aspect mining, by aggregating word dependencies from sentence dependency structure of review sentences. We retain those sentences where opinions have been expressed about the identified aspects. Next, we extract excerpts from those sentences while retaining the context as part of except extraction. A supervised learning model is then trained to rank the excerpts based on wisdom of crowd, popularity of topics and sentence quality to pick most accurate, clear and agreed upon excerpts. We present and evaluate the effectiveness of the proposed methods in terms of the quality of the extracted blurbs and the ranking generated, in the evaluations section.</p>
      <p>The problem of blurb mining for e-commerce products may have some commonalities with extractive summarization and opinion mining, but also differs in several ways, necessitating specialized methods to be developed. Extractive summarization involves identifying the most important sentences in a body of text, by scoring sentences based on an application-specific measure of importance. While blurb mining involves ranking excerpts, it differs in a few main ways. First, in extractive summarization, sentences are scored, whereas blurbs are not necessarily complete sentences, but excerpts of sentences. Next, blurbs must capture product-specific opinions and may not be useful as generic sentences. Further, unlike extractive summarization, the goal of blurb mining is not generating a summary of reviews, but discovering the most informative, enticing and succinct excerpts. In other words, blurb mining is aimed at narrowness but succinctness of excerpts, rather than completeness of topics in a summary. Opinion mining focuses on extracting opinions and opinion-targets from text. Similar to opinion mining, blurb mining focuses on identifying product-specific opinions and product aspects. However, in addition to that, blurb mining involves extracting excerpts from sentences that contain the opinions and product aspects. Further, the extracted opinionated excerpts must be ranked to discover the most impactful blurbs that convey popular and agreed upon topics. Hence, we propose methods specifically focused on discovering interesting blurbs from e-commerce product reviews.</p>
      <p>The contributions of this paper can be summarized as follows:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">We introduce the novel problem of blurb mining from e-commerce product reviews, and discuss the challenges involved in developing a scalable solution and its potential impact.<br /></li>
        <li id="list2" label="•">We propose scalable methods to discover blurbs from product reviews that are enticing, product-specific and succinct.<br /></li>
      </ul>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related Work</h2>
        </div>
      </header>
      <p>Blurbs have been extensively used in publicizing traditional media such as books and movies. The authors of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>] and [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>] have provided some overview of the usage of blurbs in the book publishing industry. The idea of blurbs has been adopted by movie publicists and more recently promoters of consumer products on the product webpages, by quoting expert or critic reviews. However, the blurbs in this context are manually selected and phrased by publicists or editors. We are not aware of any automated processes of blurb generation at scale or methodologies published in that regard.</p>
      <p>Nevertheless, online customer reviews including movie reviews, restaurant reviews and e-commerce product reviews have received considerable interest from the research community. Product reviews on e-commerce websites, which are the subject of this article, have been extensively studied in general and by the text mining community specifically. Several researchers have focused on opinion mining [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>], sentiment analysis [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0024">24</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>] and summarization of product reviews [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0030">30</a>] .Specifically, product feature based opinion mining and extractive summarization are areas which share commonalities with blurb mining.</p>
      <p>Product review blurbs are expected to discuss product-specific aspects and hence build upon product feature based opinion mining. In the field of opinion mining, several product aspect extraction models that are based on reviewer opinions have been presented by researchers over the past decade. Various supervised, unsupervised and semi-supervised models have been proposed to identify opinionated product aspects from reviews. Authors of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>] first introduced an unsupervised model based on frequent itemset mining. Other unsupervised methods include leveraging PMI statistics [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>], a rule based approach that employs linguistic patterns on sentence dependency trees [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0022">22</a>], a graph based method that captures word dependencies[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>], and a model to automatically infer rules to be applied on dependency trees [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>], among several others. Different variations of topic models including multi-grain topic models that extends topic modeling techniques such as LDA and PLSI to extract local and global aspects for products [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>], and probabilistic graphical models that extend PLSI [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>]. Semi-supervised models such as [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>] have been introduced to guide certain unsupervised models towards more precise aspects by using a domain specific set of seed words. Several supervised models have been proposed to extract aspects from reviews, such as [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>] based on conditional random fields and a convolutional neural network based model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0021">21</a>]. The authors of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>] presented a method based on aspect ranking and grouping to assist sellers in phrasing promotional statements for products on e-commerce websites. We adopt an unsupervised approach to discovering aspects that can be used for blurb generation, in order to develop a method that scale to a large number of diverse e-commerce product categories.</p>
      <p>Extractive summarization is another area of text mining that is related to some of the tasks involved in blurb mining. Extractive summarization techniques have been developed for a variety of domains including online review sentiment summarization [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>], restaurant domain [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0020">20</a>], biomedical domain [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] and student course feedback [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]. A survey of extractive text summarization techniques is provided in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>]. One of the main tasks in the area of extractive summarization is identifying the most important sentences in a body of text by an appropriate measure of importance. A comparative study of several sentence scoring techniques is presented in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>].</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Methodology</h2>
        </div>
      </header>
      <p>In this section, we describe in detail the 3-phase approach developed to mine blurbs from e-commerce product reviews. Specifically, we describe the aspect mining, excerpt extraction and excerpt ranking steps. We first discover product aspects, or vocabulary upon which product-specific opinions have been expressed using the methodology described in aspect mining. We then retain those review sentence that have occurrences of the discovered product aspects. Review sentences often happen to be long, and contain several different topics discussed and opinions expressed. To identify succinct and topic-focused portions of sentences, we apply excerpt extraction techniques that return excerpts of sentences that capture the context of the corresponding product aspect and opinion. Supervised learning models trained to discover interesting excerpts are applied to rank the excerpts identified and discover interesting blurbs. An overview of this methodology is provided in Figure <a class="fig" href="#fig2">2</a>.</p>
      <figure id="fig2">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191626/images/www18companion-365-fig2.jpg" class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class="figure-title">Overview of methodology for blurb discovery</span>
        </div>
      </figure>
      <p></p>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Aspect Mining</h3>
          </div>
        </header>
        <p>Excerpts that capture product-specific opinions are more informative to users than generic statements. To identify such product-specific excerpts we first discover product aspects from review content. Aspects are attributes or features of a product discussed in reviews, upon which the reviewer expresses an opinion. They are also referred to as opinion targets in the field of opinion mining. For instance, <em>shutter speed</em>, <em>aperture</em>, <em>zoom range</em>, could be aspects discussed in camera reviews. Consider the following excerpt from a review for a video game: <em>“Compelling gameplay and story and beautiful graphics”</em>. The reviewer expresses the opinion <em>compelling</em> on the aspect <em>gameplay</em>. The challenge in discovering aspect candidates mainly involves identifying those words that 1) the reviewer has expressed an opinion on, and 2) are attributes of the product and describe its features. Further, to quantify the importance of the identified aspects, the collective opinions expressed by reviewers on the aspects must be aggregated. Thus, this task entails firstly, identifying opinion and target word candidates, and next, aggregating them to quantify reviewer emphasis.</p>
        <p>We exploit the properties of sentence dependency trees to extract aspect candidates from each sentence of every review. Sentence dependency trees capture the grammatical relations between words that comprise a sentence. The dependencies are binary asymmetric relations between a word identified as head (generally a verb) and its dependents [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>]. The nature of the relationship is denoted by a dependency label associated with the edge connecting the two words in the relationship. For instance, Figure &nbsp;<a class="fig" href="#fig1">3</a> depicts the dependency tree for the following sentence: <em>“Camera is average but it will take pretty good photos at night.”</em>. A detailed description of dependency trees can be found in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>]. The open source library Spacy [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>] is employed to generate dependency trees owing to its combination of speed and accuracy [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>]. Punctuation is retained and no pre-processing is performed prior to producing dependency trees, since lemmatization or other pre-processing steps may affect the accuracy of dependency tree generation.</p>
        <figure id="fig3">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191626/images/www18companion-365-fig3.jpg" class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span> <span class="figure-title">Sentence dependency tree generated for an example review sentence <em>“Camera is average but it will take pretty good photos at night.”</em>. Nodes are individual words in a sentence, while edges represent dependencies between words.</span>
          </div>
        </figure>
        <p></p>
        <p>From a dependency tree constructed for a given sentence, we select those dependencies that capture the aspect candidates. Specifically, we identify the dependencies that capture the relations between the aspect and the opinion words associated with the aspect. Aspect candidates are identified subject to a set of dependency rules <em>R</em> described below, some of which have been defined by the authors of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0022">22</a>], that determine if a word is an aspect candidate.</p>
        <ol class="list-no-style">
          <li id="list3" label="(1)">A noun <em>n</em> is an aspect if there exists a parent-child relation between n and another word <em>a</em>, and <em>a</em> is either an adjective or an adverb. Here the set of words <em>a</em> that satisfy this condition constitute the opinion.<br /></li>
          <li id="list4" label="(2)">Adjective-adverb sibling rule: A noun <em>n</em> is selected as an aspect, and <em>a</em> as the opinion if there exists a word <em>a</em> that shares the same parent (head term), and <em>a</em> is either an adjective or adverb.<br /></li>
          <li id="list5" label="(3)">If a word <em>v</em> has a direct object relation with a noun <em>n</em>, and <em>v</em> is a verb, then <em>n</em> is selected as an aspect, with <em>v</em> being the opinion.<br /></li>
          <li id="list6" label="(4)">If A verb <em>v</em> has a noun <em>n</em> as a parent (head term), and <em>v</em> has a parent-child relation with another word <em>a</em> which is an adjective, then <em>n</em> is selected as an aspect, with <em>a</em> being the opinion.<br /></li>
          <li id="list7" label="(5)">If a noun <em>n</em> <sub>1</sub> in a conjunct relation or a prepositional relation with another noun <em>n</em> <sub>2</sub>, and <em>n</em> <sub>2</sub> is parent-child relation with an adjective a, <em>n</em> <sub>1</sub> is selected as an aspect with a being<br /></li>
          <li id="list8" label="(6)">If a word <em>v</em> is in an open clausal relationship with another word <em>a</em>, with <em>v</em> being a verb and <em>a</em> being an adjective or adverb, then select <em>v</em> as an aspect and <em>a</em> as opinion.<br /></li>
        </ol>
        <p>Given a sentence <em>s</em>, its dependency tree <em>D<sub>s</sub></em> : {<em>dep</em>⟨<em>w</em> <sub>1</sub>, <em>w</em> <sub>2</sub>⟩}, where <em>w</em> <sub>1</sub>, <em>w</em> <sub>2</sub> ∈ <em>s</em> are any two words in the sentence <em>s</em> with a dependency relation <em>dep</em>, is generated. Aspect candidates <em>α</em> satisfying atleast one of the rules in <em>R</em> are selected along with the associated opinion words and dependencies. The satisfying relations <em>dep</em>⟨<em>O<sub>α</sub></em> , <em>α</em>⟩ are returned, where <em>O<sub>α</sub></em> is the opinion term associated with <em>α</em>. Figure &nbsp;<a class="fig" href="#fig4">4</a> shows the selected dependencies for the example sentence. The selected aspect candidates and their associated opinions are aggregated to quantify their importance as collectively expressed by the reviewers. Frequency of occurrence of aspect candidates is a simple measure of their importance. Nevertheless, this can be extended to measures such as aggregate sentiment associated with an aspect candidate. A set of aspects, along with a measure of their importance is generated.</p>
        <figure id="fig4">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191626/images/www18companion-365-fig4.jpg" class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span> <span class="figure-title">Dependency relations returned after applying the dependency tree pruning algorithm on the example sentence.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Excerpt Extraction</h3>
          </div>
        </header>
        <p>As mentioned previously, blurbs must contain product-specific content, while being short in length. To that end, review sentences that have occurrences of aspects are retained to be considered for blurb generation. However, many of those sentences may be long, necessitating methods to extract excerpts that discuss the aspect and the associated opinion, yet, are coherent to read. In this section, we describe an excerpt extraction technique that identifies coherent excerpts from a sentence that are not longer than a specified length and capture a given aspect and associated opinion.</p>
        <p>The goal of constituency parsing (also known as ”phrase structure parsing”) is to identify the phrases in the text. Constituent structure is based on the observation that words combine with other words to form units. Constituency parse trees organize syntax into constituents.</p>
        <figure id="fig5">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191626/images/www18companion-365-fig5.jpg" class="img-responsive" alt="Figure 5" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span> <span class="figure-title">Illustration of excerpt extraction based on sentence parse tree. Excerpt, circled in red, consisting of aspects <em>weight and balance</em> is extracted from the parse tree for sentence <em>“The weight and balance of the club are good for my swing and it gives me a sense of confidence”</em></span>
          </div>
        </figure>
        <p></p>
        <p>The proposed excerpt extraction technique utilizes the constituency sentence parse tree of a sentence to identify coherent excerpts. Constituency parse trees organize the syntactical structure into constituents based on the observation that words combine with other words to form linguistic structures. They assist in identifying phrases in text. Stanford parser is used to generate the constituency parse tree for a given sentence. Figure <a class="fig" href="#fig5">5</a> shows a parse tree generated for the sentence <em>“The weight and balance of the club are good for my swing and it gives me a sense of confidence”</em>. Given an aspect <em>α</em> and the associated opinion <em>O<sub>α</sub></em> that has been expressed in the sentence, and a specified upper bound <em>k</em> on the number of words permissible in an excerpt, the subtree <em>τ</em> with the maximum number of leaves that confirms to the following conditions is returned.</p>
        <ol class="list-no-style">
          <li id="list9" label="(1)">The root of the subtree <em>τ</em> must be either a sentence or clause (<em>S</em>) or a noun-phrase (<em>NP</em>)<br /></li>
          <li id="list10" label="(2)">The subtree <em>τ</em> may have at the most <em>k</em> leaves<br /></li>
          <li id="list11" label="(3)">Aspect <em>α</em> and opinion <em>O<sub>α</sub></em> are leaves of the subtree <em>τ</em><br /></li>
        </ol>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class="table-title">Illustration of blurb generation for example review sentences. Here, the corresponding product-specific aspect and the extracted excerpt for the given review sentence are shown.</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:center;"><strong>Product</strong></td>
                <td style="text-align:center;"><strong>Aspect</strong></td>
                <td style="text-align:center;"><strong>Review Sentence</strong></td>
                <td style="text-align:center;"><strong>Blurb</strong></td>
              </tr>
              <tr>
                <td style="text-align:center;">Video game</td>
                <td style="text-align:center;">storyline</td>
                <td style="text-align:center;">Blood Omen: Legacy of Kain is awesome</td>
                <td style="text-align:center;">great graphics and a challenging storyline</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">with great graphics and a challenging <em>storyline</em>.</td>
                <td style="text-align:center;"></td>
              </tr>
              <tr>
                <td style="text-align:center;">GPS unit</td>
                <td style="text-align:center;">screen</td>
                <td style="text-align:center;">It is a great unit and is very easy to operate</td>
                <td style="text-align:center;">the screen is very easy to see and work</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">and the <em>screen</em> is very easy to see and work.</td>
                <td style="text-align:center;"></td>
              </tr>
              <tr>
                <td style="text-align:center;">Drill</td>
                <td style="text-align:center;">weight</td>
                <td style="text-align:center;">This one is a powerful light <em>weight</em> cordless drill.</td>
                <td style="text-align:center;">powerful light weight cordless drill</td>
              </tr>
              <tr>
                <td style="text-align:center;">Book</td>
                <td style="text-align:center;">advice</td>
                <td style="text-align:center;">It has good simple truthful <em>advice</em>, with a down to earth feel,</td>
                <td style="text-align:center;">good simple truthful advice</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">anyone can follow this book from start to finish.</td>
                <td style="text-align:center;"></td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>To identify the subtree to be returned, first the aspect and opinion leaves are retrieved from the tree and their common ancestors are discovered such that the above rules are satisfied. The subtree rooted at the selected common ancestor is returned, and its leaves constitute the extracted excerpt. For the example sentence depicted in figure <a class="fig" href="#fig5">5</a>, <em>weight</em> and <em>balance</em> are aspects on which the opinion <em>good</em> has been expressed, and let <em>k</em> = 15 for the purpose of illustration. The subtree to be returned must have at the most 15 leaves, root of the subtree must either be <em>S</em> or <em>NP</em>, and must contain the leaves <em>weight</em>, <em>balance</em> and <em>good</em>. The subtree highlighted in red in figure <a class="fig" href="#fig5">5</a> is returned which represents the excerpt <em>“The weight and balance of the club are good for my swing”</em> for this sentence.</p>
      </section>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span> Excerpt Ranking</h3>
          </div>
        </header>
        <p>We intend to discover the excerpts that could be the most interesting to users, among the excerpts candidates, to be presented as blurbs. We train a supervised learning model to assist in ranking the excerpts by leveraging crowd wisdom to represent popularity of topics and sentence quality to pick most interesting, accurate and agreed upon excerpts. The model is trained to identify excerpts that are interesting against those that aren't. The learning problem is formulated as a classification problem, where the learner is trained to classify an excerpt as <em>interesting</em>, <em>neutral</em> or <em>not interesting</em>. Several syntactic, grammatical, sentiment-based and review-specific features are used in training the model. Parts of speech tags of words in the original review sentence and excerpt are used to build features that capture the numbers of adjectives, adverbs, nouns and verbs. Features based on dependency relations between aspect and opinion terms in the excerpt provide syntactic information. Text features such as character length, number of words in the sentence and the excerpt, tf-idf scores of the corresponding aspect and its frequency of occurrence among excerpt candidates are adopted. Further, the positive, negative and compound sentiment of the sentence are used to capture the reviewer sentiment. In addition to this, product and review-specific features such as rating provided by the reviewer, overall rating for the product and numbers of positive and negative ratings for the product are used. Specifically, features related to aspect-pertinent metrics within the reviews, and those that quantify sentiment are intended to assist the classifier in learning excerpts that are interesting. A gradient boosted tree based classifier is trained to classify the excerpts to the afore-mentioned classes. The classifier prediction for an excerpt to belong to the <em>interesting</em> class is used as a measure for ranking the excerpts.</p>
      </section>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Evaluation</h2>
        </div>
      </header>
      <p>In this section, we present evaluation of the proposed methods for blurb extraction and ranking. Specifically, we evaluate the quality of the extracted blurbs and effectiveness of the ranking determined for those blurbs. To generate a ranked set of blurbs for each product, first, product-specific aspects are discovered from the reviews for that product. Next, excerpts with a specified upper bound on length (8 words in the evaluations that will be presented in this section), are extracted from review sentences containing the discovered aspects. Those excerpts are ranked with the assistance of a classifier trained on a human annotated e-commerce blurb corpus. This process is illustrated along with some examples of blurbs generated in Table <a class="tbl" href="#tab1">1</a>.</p>
      <p>To facilitate the evaluation, we curated an evaluation dataset consisting of blurbs generated for 25 products sampled from 20 different e-commerce product categories including those such as laptops, smartphones, books, movies and sporting goods. The blurbs for each of these products were labeled by 3 independent human evaluators. The evaluators were asked to label the blurbs as either <em>interesting</em>, <em>neutral</em> or <em>not interesting</em>, consistent with the labels used in the excerpt ranking phase. Blurbs that are irrelevant, improperly constructed or lacking proper context were labeled as <em>not interesting</em>. The evaluators were provided with the product title and description. The majority consensus was adopted as the label for a blurb.</p>
      <figure id="fig6">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191626/images/www18companion-365-fig6.jpg" class="img-responsive" alt="Figure 6" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 6:</span> <span class="figure-title">Plots showing the (a) Precision@k and (b) NDCG@k values computed for the evaluation dataset. Here <em>k</em> is the number of top blurbs considered for NDCG computation.</span>
        </div>
      </figure>
      <p></p>
      <p>First, we evaluate the quality of the extracted blurbs. We determine the proportion of blurbs that have been classified as <em>interesting</em>, that the evaluators labeled as <em>interesting</em>. Precision@k values are computed for the evaluation dataset, where <em>k</em> is the number of top blurbs considered in the calculation. Figure <a class="fig" href="#fig6">6</a>(a) shows the precision@k values obtained for <em>k</em> = [2, 14] ranging from 0.71 to 0.48. Next, we evaluate the quality of the ranking order generated for the blurbs. We use the NDCG metric for this purpose. Figure <a class="fig" href="#fig6">6</a>(b) shows the NDCG@k values obtained for the evaluation dataset with <em>k</em> = [2, 14]. The NDCG values range from 0.94 to 0.88, as can be observed from the plot.</p>
      <p>The precision and NDCG values obtained indicate that, while the ranking order produced for the blurbs discovered is satisfactory, there is room for improvement in the quality of the blurbs extracted. An analysis of the false positives that occurred in blurb extraction reveals two main sources of false positives. First, excerpts that are not very product-specific but are generic in nature may not be informative to online shoppers are not considered to be interesting blurbs. For instance, the excerpt <em>“I highly recommend this computer”</em> from a product review for a laptop does not provide an opinion on specific features of the laptop. Such false positives are a consequence of false positives in aspect mining. The second category of false positives are those that are either incoherent or do not represent the context of the sentence. As an example, the excerpt <em>“excellent reception and crisp voice quality”</em> misrepresents the statement <em>“My previous phone had excellent reception and crisp voice quality”</em>. False positives of this kind are a result of errors in excerpt extraction. Excerpts that misrepresent the original statement can be a consequence of a comparison to another product, usage of grammatical clauses such as contrastive conjuncts such as <em>however</em> or <em>but</em>, or the usage of negation. Some of these are known to be challenging problems in natural language. Further, while we have used 8 words as an upper bound on the excerpt length for the purpose of illustration, this can be varied based on the underlying application. Variation in the upper bound will affect the quality of the blurbs generated and the effectiveness of the ranking orders produced. Although, that is out of the context of this work, analysis of the impact of an upper bound on the length of blurb can be further explored.</p>
    </section>
    <section id="sec-11">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Summary</h2>
        </div>
      </header>
      <p>The practice of using blurbs attributed to expert or critic reviews, to capture the interest of audience and promote a product has been pervasive in the field of books and movies for a long time. This concept is gaining increasing adoption in other domains such as consumer product websites where excerpts from expert reviews are used to encourage shoppers to explore a product. With the growing prominence of product reviews on most modern e-commerce platforms and the increasing reliance of online shoppers on reviews, it seems natural to introduce blurbs to e-commerce products. In the context of e-commerce product reviews, blurbs can simplify shopping experience when facing a myriad of product choices, in addition to highlighting interesting reviewer opinions on a product.</p>
      <p>Traditionally, blurbs have been carefully handpicked by book editors or movie publishers. However, owing to the scale of modern e-commerce websites with hundreds of millions of product and product reviews, automated methods of discovering blurbs must be developed. While researchers in the area of text mining have proposed several methods focused on review mining, specifically assisting in the tasks of opinion mining, sentiment analysis and summarization, blurb mining from product reviews has not been explored. Although blurb mining has several commonalities with such methods, this task differs in several key areas. Blurb mining involves identifying product-specific excerpts, and the focus is on identifying short excerpts that retain the context rather than complete sentences. Further, the goal in blurb mining is to identify interesting and enticing excerpts rather than summarizing the reviews. Moreover, it is critical to maintain user trust on e-commerce platforms to retain context of the opinions and not misrepresent them while identifying excerpts from sentences. These unique challenges, coupled with the scale and diversity of product catalogues on e-commerce websites necessitate developing focused methods for blurb mining.</p>
      <p>In this paper, we introduced the problem of blurb mining from e-commerce product reviews, and proposed a three-phased approach to discover interesting blurbs. Specifically, we proposed methods to first discover product-specific aspects in reviews, next generate excerpts from qualifying review sentences and then rank them to select the interesting ones. We evaluated the quality of the extracted blurbs and the ranking order produced using precision@k and NDCG@k measures respectively. Although the focus of this work is on introducing the problem of blurb mining from e-commerce product reviews and presenting an approach to implement blurb discovery and ranking at scale, there are several avenues for further exploration and improvement. First, the problem of excerpts misrepresenting original sentences can be further explored, specifically with emphasis on comparative statements and sentences with contrastive clauses and negation. While there is a body of research that exists in the area of aspect mining, further research into integrating aspect mining into blurb discovery can be valuable. In this work, we employed several features pertaining to aspect-specific metrics in reviews and features that quantify sentiment to assist the classifier in distinguishing excerpts that are interesting against those that aren't. An excerpt being interesting, or in other words the catchiness of a blurb is a very subjective concept and can be difficult to quantify. Further research in quantifying the catchiness of a blurb can be beneficial.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Muhammad Abulaish, Mohammad Doja, and Tanvir Ahmad. 2009. Feature and opinion mining for customer review summarization. <em><em>Pattern recognition and machine intelligence</em></em> (2009), 219–224.</li>
        <li id="BibPLXBIB0002" label="[2]">Henry Alford. 2007. Literary Misblurbing. (April 2007). <a class="link-inline force-break" href="http://www.nytimes.com/2007/04/29/books/review/Alford.t.html%20Retrieved%20April%2029,%202007%20from" target="_blank">http://www.nytimes.com/2007/04/29/books/review/Alford.t.html Retrieved April 29, 2007 from</a>
        </li>
        <li id="BibPLXBIB0003" label="[3]">Jinho&nbsp;D Choi, Joel&nbsp;R Tetreault, and Amanda Stent. 2015. It Depends: Dependency Parser Comparison Using A Web-based Evaluation Tool.. In <em><em>ACL (1)</em></em> . 387–396.</li>
        <li id="BibPLXBIB0004" label="[4]">Marie-Catherine De&nbsp;Marneffe and Christopher&nbsp;D Manning. 2008. <em><em>Stanford typed dependencies manual</em></em> . Technical Report. Technical report, Stanford University.</li>
        <li id="BibPLXBIB0005" label="[5]">Colin Dwyer. 2015. Forget The Book, Have You Read This Irresistible Story On Blurbs? (Sept. 2015). <a class="link-inline force-break" href="https://www.npr.org/2015/09/27/429723002/forget-the-book-have-you-read-this-irresistible-story-on-blurbsRetrieved%20September%2027,%202015%20from" target="_blank">https://www.npr.org/2015/09/27/429723002/forget-the-book-have-you-read-this-irresistible-story-on-blurbsRetrieved September 27, 2015 from</a>
        </li>
        <li id="BibPLXBIB0006" label="[6]">Rafael Ferreira, Luciano de Souza&nbsp;Cabral, Rafael&nbsp;Dueire Lins, Gabriel&nbsp;Pereira e Silva, Fred Freitas, George&nbsp;DC Cavalcanti, Rinaldo Lima, Steven&nbsp;J Simske, and Luciano Favaro. 2013. Assessing sentence scoring techniques for extractive text summarization. <em><em>Expert systems with applications</em></em> 40, 14 (2013), 5755–5764.</li>
        <li id="BibPLXBIB0007" label="[7]">Mª Gea&nbsp;Valor. 2005. Advertising books: A linguistic analysis of blurbs. <em><em>Ibérica</em></em> 10(2005).</li>
        <li id="BibPLXBIB0008" label="[8]">Maria-Lluïsa Gea-Valor and Marta&nbsp;Inigo Ros. 2009. On the dynamic nature of genre: A diachronic study of blurbs. In <em><em>Academic Evaluation</em></em> . Springer, 199–216.</li>
        <li id="BibPLXBIB0009" label="[9]">Matthew Honnibal and Mark Johnson. 2015. An Improved Non-monotonic Transition System for Dependency Parsing. In <em><em>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</em></em> . Association for Computational Linguistics, Lisbon, Portugal, 1373–1378. <a class="link-inline force-break" href="https://aclweb.org/anthology/D/D15/D15-1162" target="_blank">https://aclweb.org/anthology/D/D15/D15-1162</a>
        </li>
        <li id="BibPLXBIB0010" label="[10]">Minqing Hu and Bing Liu. 2004. Mining opinion features in customer reviews. In <em><em>AAAI</em></em> , Vol.&nbsp;4. 755–760.</li>
        <li id="BibPLXBIB0011" label="[11]">Niklas Jakob and Iryna Gurevych. 2010. Extracting opinion targets in a single-and cross-domain setting with conditional random fields. In <em><em>Proceedings of the 2010 conference on empirical methods in natural language processing</em></em> . Association for Computational Linguistics, 1035–1045.</li>
        <li id="BibPLXBIB0012" label="[12]">Bing Liu and Lei Zhang. 2012. A survey of opinion mining and sentiment analysis. In <em><em>Mining text data</em></em> . Springer, 415–463.</li>
        <li id="BibPLXBIB0013" label="[13]">Qian Liu, Zhiqiang Gao, Bing Liu, and Yuanlin Zhang. 2015. Automated Rule Selection for Aspect Extraction in Opinion Mining.. In <em><em>IJCAI</em></em> . 1291–1297.</li>
        <li id="BibPLXBIB0014" label="[14]">Wencan Luo, Fei Liu, Zitao Liu, and Diane Litman. 2016. Automatic summarization of student course feedback. In <em><em>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em></em> . 80–85.</li>
        <li id="BibPLXBIB0015" label="[15]">Walaa Medhat, Ahmed Hassan, and Hoda Korashy. 2014. Sentiment analysis algorithms and applications: A survey. <em><em>Ain Shams Engineering Journal</em></em> 5, 4 (2014), 1093–1113.</li>
        <li id="BibPLXBIB0016" label="[16]">Rashmi Mishra, Jiantao Bian, Marcelo Fiszman, Charlene&nbsp;R Weir, Siddhartha Jonnalagadda, Javed Mostafa, and Guilherme Del&nbsp;Fiol. 2014. Text summarization in the biomedical domain: a systematic review of recent research. <em><em>Journal of biomedical informatics</em></em> 52 (2014), 457–467.</li>
        <li id="BibPLXBIB0017" label="[17]">Samaneh Moghaddam and Martin Ester. 2011. ILDA: interdependent LDA model for learning latent aspects and their ratings from online product reviews. In <em><em>Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval</em></em> . ACM, 665–674.</li>
        <li id="BibPLXBIB0018" label="[18]">Arjun Mukherjee and Bing Liu. 2012. Aspect extraction through semi-supervised modeling. In <em><em>Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1</em></em> . Association for Computational Linguistics, 339–348.</li>
        <li id="BibPLXBIB0019" label="[19]">Ani Nenkova and Kathleen McKeown. 2012. A survey of text summarization techniques. <em><em>Mining text data</em></em> (2012), 43–76.</li>
        <li id="BibPLXBIB0020" label="[20]">Patrick Nguyen, Milind Mahajan, and Geoffrey Zweig. 2007. Summarization of multiple user reviews in the restaurant domain. <em><em>Microsoft Research, Redmond, WA, Citeseer</em></em> (2007).</li>
        <li id="BibPLXBIB0021" label="[21]">Soujanya Poria, Erik Cambria, and Alexander Gelbukh. 2016. Aspect extraction for opinion mining with a deep convolutional neural network. <em><em>Knowledge-Based Systems</em></em> 108 (2016), 42–49.</li>
        <li id="BibPLXBIB0022" label="[22]">Soujanya Poria, Erik Cambria, Lun-Wei Ku, Chen Gui, and Alexander Gelbukh. 2014. A rule-based approach to aspect extraction from product reviews. In <em><em>Proceedings of the second workshop on natural language processing for social media (SocialNLP)</em></em> . 28–37.</li>
        <li id="BibPLXBIB0023" label="[23]">Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through double propagation. <em><em>Computational linguistics</em></em> 37, 1 (2011), 9–27.</li>
        <li id="BibPLXBIB0024" label="[24]">Huifeng Tang, Songbo Tan, and Xueqi Cheng. 2009. A survey on sentiment detection of reviews. <em><em>Expert Systems with Applications</em></em> 36, 7 (2009), 10760–10773.</li>
        <li id="BibPLXBIB0025" label="[25]">Ivan Titov and Ryan McDonald. 2008. Modeling online reviews with multi-grain topic models. In <em><em>Proceedings of the 17th international conference on World Wide Web</em></em> . ACM, 111–120.</li>
        <li id="BibPLXBIB0026" label="[26]">Ivan Titov and Ryan&nbsp;T McDonald. 2008. A Joint Model of Text and Aspect Ratings for Sentiment Summarization.. In <em><em>ACL</em></em> , Vol.&nbsp;8. 308–316.</li>
        <li id="BibPLXBIB0027" label="[27]">Takaaki Tsunoda, Takashi Inui, and Satoshi Sekine. 2015. Utilizing review analysis to suggest product advertisement improvements. In <em><em>Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</em></em> . 41–50.</li>
        <li id="BibPLXBIB0028" label="[28]">Tao Wang, Yi Cai, Ho-fung Leung, Raymond&nbsp;YK Lau, Qing Li, and Huaqing Min. 2014. Product aspect extraction supervised with online domain knowledge. <em><em>Knowledge-Based Systems</em></em> 71 (2014), 86–100.</li>
        <li id="BibPLXBIB0029" label="[29]">Zhijun Yan, Meiming Xing, Dongsong Zhang, and Baizhang Ma. 2015. EXPRS: An extended pagerank method for product feature extraction from online consumer reviews. <em><em>Information &amp; Management</em></em> 52, 7 (2015), 850–858.</li>
        <li id="BibPLXBIB0030" label="[30]">Rong Zhang, Wenzhe Yu, Chaofeng Sha, Xiaofeng He, and Aoying Zhou. 2015. Product-oriented review summarization and scoring. <em><em>Frontiers of Computer Science</em></em> 9, 2 (2015), 210–223.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&nbsp;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3184558.3191626">https://doi.org/10.1145/3184558.3191626</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
