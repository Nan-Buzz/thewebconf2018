<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>Deep Inductive Network Representation Learning</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3191524'>https://doi.org/10.1145/3184558.3191524</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3191524'>https://w3id.org/oa/10.1145/3184558.3191524</a>
</p></div>
<hr>

  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">Deep Inductive Network Representation Learning</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author">     <span class="givenName">Ryan A.</span>     <span class="surName">Rossi</span>     Adobe Research, <a href="mailto:rrossi@adobe.com">rrossi@adobe.com</a>    </div>    <div class="author">     <span class="givenName">Rong</span>     <span class="surName">Zhou</span>     Google, <a href="mailto:rongzhou@google.com">rongzhou@google.com</a>    </div>    <div class="author">     <span class="givenName">Nesreen K.</span>     <span class="surName">Ahmed</span>     Intel Labs, <a href="mailto:nesreen.k.ahmed@intel.com">nesreen.k.ahmed@intel.com</a><a href="mailto:"/></div>                </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3184558.3191524" target="_blank">https://doi.org/10.1145/3184558.3191524</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>This paper presents a general inductive graph representation learning framework called DeepGL for learning deep node <em>and</em> edge features that generalize across-networks.<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>In particular, DeepGL begins by deriving a set of base features from the graph (<em>e.g.</em>, graphlet features) and automatically learns a multi-layered hierarchical graph representation where each successive layer leverages the output from the previous layer to learn features of a higher-order. Contrary to previous work, DeepGL learns <em>relational functions</em> (each representing a feature) that naturally generalize across-networks and are therefore useful for graph-based transfer learning tasks. Moreover, DeepGL naturally supports attributed graphs, learns interpretable inductive graph representations, and is space-efficient (by learning sparse feature vectors). In addition, DeepGL is expressive, flexible with many interchangeable components, efficient with a time complexity of <span class="inline-equation"><span class="tex">$\mathcal {O}(|E|)$</span>      </span>, and scalable for large networks via an efficient parallel implementation. Compared with recent methods, DeepGL is (1) <strong>effective</strong> for across-network transfer learning tasks <em>and</em> large (attributed) graphs, (2) <strong>space-efficient</strong> requiring up to 6 &#x00D7; less memory, (3) <strong>fast</strong> with up to 182 &#x00D7; speedup in runtime performance, and (4) <strong>accurate</strong> with an average improvement in AUC of 20% or more on many learning tasks and across a wide variety of networks.</small>    </p>    </div>    <div class="CCSconcepts">    <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Computing methodologies </strong>&#x2192; <strong>Artificial intelligence;</strong> <strong>Machine learning;</strong> &#x2022;<strong> Mathematics of computing </strong>&#x2192; <strong>Graph algorithms;</strong> <em>Combinatorics;</em> <em>Graph theory;</em> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Data mining;</strong> &#x2022;<strong> Theory of computation </strong>&#x2192; <strong>Graph algorithms analysis;</strong> <strong>Streaming, sublinear and near linear time algorithms;</strong> <strong>Parallel algorithms;</strong> <strong>Logical and relational learning;</strong></small> </p>    </div>    <div class="classifications">    <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Inductive network representation learning</small>, </span>     <span class="keyword">      <small> inductive learning</small>, </span>     <span class="keyword">      <small> transfer learning</small>, </span>     <span class="keyword">      <small> network embeddings</small>, </span>     <span class="keyword">      <small> representation learning</small>, </span>     <span class="keyword">      <small> attributed networks</small>, </span>     <span class="keyword">      <small> function learning</small>, </span>     <span class="keyword">      <small> network motifs</small>, </span>     <span class="keyword">      <small> deep learning</small>     </span>    </div>    <br/>    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Ryan A. Rossi, Rong Zhou, and Nesreen K. Ahmed. 2018. Deep Inductive Network Representation Learning. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 9 Pages. <a href="https://doi.org/10.1145/3184558.3191524" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3184558.3191524</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-4">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>    </div>    </header>    <p>Learning a useful graph representation lies at the heart <em>and</em> success of many machine learning tasks such as node and link classification&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>], anomaly detection&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>], link prediction&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>], dynamic network analysis&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>], community detection&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>], role discovery&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>], visualization and sensemaking&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>], network alignment&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>], and many others. Indeed, the success of machine learning methods largely depends on data representation&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>]. Methods capable of learning such representations have many advantages over feature engineering in terms of cost and effort. For a survey and taxonomy of relational representation learning, see&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>].</p>    <p>Recent work has largely been based on the popular skip-gram model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>] originally introduced for learning vector representations of words in the natural language processing (NLP) domain. In particular, DeepWalk&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>] applied the successful word embedding framework from&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>] (called word2vec) to embed the nodes such that the co-occurrence frequencies of pairs in short random walks are preserved. More recently, node2vec&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>] introduced hyperparameters to DeepWalk that tune the depth and breadth of the random walks. These approaches have been extremely successful and have shown to outperform a number of existing methods on tasks such as node classification.</p>    <p>However, the past work has focused on learning only <em>node features</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>] for a specific graph. Features from these methods do <em>not</em> generalize to other networks and thus are unable to be used for across-network transfer learning tasks.<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a> In contrast, DeepGL learns <em>relational functions</em> that generalize for computation on any arbitrary graph, and therefore naturally supports across-network transfer learning tasks such as across-network link classification, network alignment, graph similarity, among others. Existing methods are also not space-efficient as the node feature vectors are completely dense. For large graphs, the space required to store these dense features can easily become too large to fit in-memory. The features are also notoriously difficult to interpret and explain which is becoming increasingly important in practice&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>]. Furthermore, existing embedding methods are also unable to capture higher-order subgraph structures as well as learn a hierarchical graph representation from such higher-order structures. Finally, these methods are also inefficient with runtimes that are orders of magnitude slower than the algorithms presented in this paper (as shown later in Section&#x00A0;<a class="sec" href="#sec-16">3</a>). Other key differences and limitations are discussed below.</p>    <p>In this work, we present a general, expressive, and flexible <em>deep graph representation learning framework</em> called DeepGL that overcomes many of the above limitations.<a class="fn" href="#fn3" id="foot-fn3"><sup>2</sup></a> Intuitively, DeepGL begins by deriving a set of base features using the graph structure and any attributes (if available). The base features are iteratively composed using a set of learned <em>relational feature operators</em> that operate over the feature values of the (distance-&#x2113;) neighbors of a graph element (node, edge; see Table&#x00A0;<a class="tbl" href="#tab1">1</a>) to derive higher-order features from lower-order ones forming a hierarchical graph representation where each layer consists of features of increasingly higher orders. At each feature layer, DeepGL searches over a space of relational functions defined compositionally in terms of a set of <em>relational feature operators</em> applied to each feature given as output in the previous layer. Features (or relational functions) are retained if they are novel and thus add important information that is not captured by any other feature in the set. See below for a summary of the advantages and properties of DeepGL.</p>    <section id="sec-5">    <header>     <div class="title-info">      <h3>       <span class="section-number">1.1</span> Summary of Contributions</h3>     </div>    </header>    <p>The proposed approach, DeepGL, provides a general powerful framework for learning deep graph representations from attributed graphs that are naturally inductive for use in across-network learning tasks. DeepGL overcomes many limitations of existing work and has the following key properties:</p>    <ul class="list-no-style">     <li id="list1" label="&#x2022;"><strong>Novel framework</strong>: This paper presents a deep hierarchical inductive graph representation learning framework called DeepGL for large (attributed) networks that generalizes for discovering both node and edge features. DeepGL searches a space of relational functions (representing features) that are expressed as compositions of relational feature operators applied to a set of base features. The framework is flexible with many interchangeable components, expressive, and shown to be effective for a wide variety of applications.<br/></li>     <li id="list2" label="&#x2022;"><strong>Inductive representation learning</strong>: Contrary to existing node embedding methods, DeepGL is naturally inductive by learning relational functions that generalize for computation on any arbitrary graph and therefore supports across-network transfer learning tasks.<br/></li>     <li id="list3" label="&#x2022;"><strong>Space efficiency</strong>: While most existing methods learn dense high-dimensional feature vectors that are often impractical for large graphs (<em>e.g.</em>, too large to fit in-memory), DeepGL is <em>space-efficient</em>by learning a sparse graph representation that requires up to 6x less space than existing work.<br/></li>     <li id="list4" label="&#x2022;"><strong>Fast, parallel, and scalable</strong>: It is fast with a runtime that is linear in the number of edges. It scales to large graphs via a simple and efficient parallelization. Notably, strong scaling results are observed in Section&#x00A0;<a class="sec" href="#sec-16">3</a>.<br/></li>     <li id="list5" label="&#x2022;"><strong>Hierarchical graph representation</strong>: DeepGL learns hierarchical graph representations with multiple layers where each successive layer uses the output from the previous layer as input to derive features of a higher-order.<br/></li>     <li id="list6" label="&#x2022;"><strong>Interpretable and explainable</strong>: Unlike existing embedding methods, DeepGL learns interpretable and explainable features.<br/></li>    </ul>    <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">Summary of notation. Matrices are bold upright roman letters; vectors are bold lowercase letters.</span>     </div>     <table class="table">      <tbody>       <tr>       <td style="text-align:left;">        <em>G</em>       </td>       <td style="text-align:left;">(un)directed (attributed) graph</td>       </tr>       <tr>       <td style="text-align:left;">        <strong>A</strong>       </td>       <td style="text-align:left;">sparse adjacency matrix of the graph <em>G</em> = (<em>V</em>, <em>E</em>)</td>       </tr>       <tr>       <td style="text-align:left;">        <em>N</em>, <em>M</em>       </td>       <td style="text-align:left;">number of nodes and edges in the graph</td>       </tr>       <tr>       <td style="text-align:left;">        <em>F</em>, <em>L</em>       </td>       <td style="text-align:left;">number of learned features and layers</td>       </tr>       <tr>       <td style="text-align:left;">        <span class="inline-equation"><span class="tex">$\mathcal {G}$</span>        </span>       </td>       <td style="text-align:left;">set of graph elements {<em>g</em>        <sub>1</sub>, <em>g</em>        <sub>2</sub>, &#x22C5;&#x22C5;&#x22C5;} (nodes, edges)</td>       </tr>       <tr>       <td style="text-align:left;">        <span class="inline-equation"><span class="tex">$d^{+}_v$</span>        </span>, <span class="inline-equation"><span class="tex">$d^{-}_{v}$</span>        </span>, <em>d<sub>v</sub>        </em>       </td>       <td style="text-align:left;">outdegree, indegree, degree of vertex <em>v</em>       </td>       </tr>       <tr>       <td style="text-align:left;">        <span class="inline-equation"><span class="tex">$\Gamma ^{+}_{}\!(g_i)$</span>        </span>, <span class="inline-equation"><span class="tex">$\Gamma ^{-}_{}\!(g_i)$</span>        </span>       </td>       <td style="text-align:left;">out/in neighbors of graph element <em>g<sub>i</sub>        </em>       </td>       </tr>       <tr>       <td style="text-align:left;">        <em>&#x0393;</em>(<em>g<sub>i</sub>        </em>)</td>       <td style="text-align:left;">neighbors (adjacent graph elements) of <em>g<sub>i</sub>        </em>       </td>       </tr>       <tr>       <td style="text-align:left;">        <em>&#x0393;</em>        <sub>&#x2113;</sub>(<em>g<sub>i</sub>        </em>)</td>       <td style="text-align:left;">&#x2113;-neighborhood <span class="inline-equation"><span class="tex">$\Gamma (g_i) = \lbrace g_j \in \mathcal {G} \,|\, \mathrm{dist}(g_i, g_j) \le \ell \rbrace$</span>        </span>       </td>       </tr>       <tr>       <td style="text-align:left;">dist(<em>g<sub>i</sub>        </em>, <em>g<sub>j</sub>        </em>)</td>       <td style="text-align:left;">shortest distance between <em>g<sub>i</sub>        </em> and <em>g<sub>j</sub>        </em>       </td>       </tr>       <tr>       <td style="text-align:left;">        <em>S</em>       </td>       <td style="text-align:left;">set of graph elements related to <em>g<sub>i</sub>        </em>, <em>e.g.</em>, <em>S</em> = <em>&#x0393;</em>(<em>g<sub>i</sub>        </em>)</td>       </tr>       <tr>       <td style="text-align:left;">        <strong>X</strong>       </td>       <td style="text-align:left;">a feature matrix</td>       </tr>       <tr>       <td style="text-align:left;">x</td>       <td style="text-align:left;">an <em>N</em> or <em>M</em>-dimensional feature vector</td>       </tr>       <tr>       <td style="text-align:left;">        <em>x<sub>i</sub>        </em>       </td>       <td style="text-align:left;">the <em>i</em>-th element of x for graph element <em>g<sub>i</sub>        </em>       </td>       </tr>       <tr>       <td style="text-align:left;">|<strong>X</strong>|</td>       <td style="text-align:left;">number of nonzeros in a matrix <strong>X</strong>       </td>       </tr>       <tr>       <td style="text-align:left;">        <span class="inline-equation"><span class="tex">$\mathcal {F}$</span>        </span>       </td>       <td style="text-align:left;">set of <em>feature definitions/functions</em> from DeepGL</td>       </tr>       <tr>       <td style="text-align:left;">        <span class="inline-equation"><span class="tex">$\mathcal {F}_k$</span>        </span>       </td>       <td style="text-align:left;">        <em>k</em>-th feature layer (where <em>k</em> is the depth)</td>       </tr>       <tr>       <td style="text-align:left;">        <em>f<sub>i</sub>        </em>       </td>       <td style="text-align:left;">relational function (definition) of x<sub>         <em>i</em>        </sub>       </td>       </tr>       <tr>       <td style="text-align:left;">        <em>&#x03A6;</em>       </td>       <td style="text-align:left;">set of relational operators <em>&#x03A6;</em> = {<em>&#x03A6;</em>        <sub>1</sub>, &#x22C5;&#x22C5;&#x22C5;, <em>&#x03A6;<sub>K</sub>        </em>}</td>       </tr>       <tr>       <td style="text-align:left;">        <span class="inline-equation"><span class="tex">$\mathbb {K}(\cdot)$</span>        </span>       </td>       <td style="text-align:left;">a feature score function</td>       </tr>       <tr>       <td style="text-align:left;">        <em>&#x03BB;</em>       </td>       <td style="text-align:left;">tolerance/feature similarity threshold</td>       </tr>       <tr>       <td style="text-align:left;">        <em>&#x03B1;</em>       </td>       <td style="text-align:left;">transformation hyperparameter (<em>e.g.</em>, bin size in log binning 0 &#x2264; <em>&#x03B1;</em> &#x2264; 1)</td>       </tr>       <tr>       <td style="text-align:left;">x&#x2032; = <em>&#x03A6;<sub>i</sub>        </em>&#x27E8;x&#x27E9;</td>       <td style="text-align:left;">relational operator applied to each graph element</td>       </tr>      </tbody>     </table>    </div>    </section>   </section>   <section id="sec-6">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> Framework</h2>    </div>    </header>    <p>This section presents the DeepGL framework. Since the framework naturally generalizes for learning node and edge representations, it is described generally for a set of graph elements (<em>e.g.</em>, nodes or edges).<a class="fn" href="#fn4" id="foot-fn4"><sup>3</sup></a>    </p>    <section id="sec-7">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Base Graph Features</h3>     </div>    </header>    <p>The first step of DeepGL (Alg.&#x00A0;) is to derive a set of <em>base graph features</em><a class="fn" href="#fn5" id="foot-fn5"><sup>4</sup></a>using the graph topology and attributes (if available). Initially, the feature matrix <strong>X</strong> contains only the attributes given as input by the user. If no attributes are provided, then <strong>X</strong> will consist of only the base features derived below. Note that DeepGL can use any arbitrary set of base features, and thus it is not limited to the base features discussed below. Given a graph <em>G</em> = (<em>V</em>, <em>E</em>), we first decompose <em>G</em> into its smaller subgraph components called graphlets (network motifs)&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>] using local graphlet decomposition methods&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>] and concatenate the graphlet count-based feature vectors to the feature matrix <strong>X</strong>. This work derives such features by counting all node or edge <em>orbits</em> with up to 4 and/or 5-vertex graphlets. Orbits (graphlet automorphisms) are counted for each node or edge in the graph based on whether a node or edge-based feature representation is warranted (as our approach naturally generalizes to both). Note there are 15 node and 12 edge orbits with 2-4 nodes; and 73 node and 68 edge orbits with 2-5 nodes.</p>    <p>We also derive simple base features such as in/out/total/weighted degree and k-core numbers for each graph element (node, edge) in <em>G</em>. For edge feature learning we derive edge degree features for each edge (<em>v</em>, <em>u</em>) &#x2208; <em>E</em> and each &#x25CB; &#x2208; { +, &#x00D7;} as follows: <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \big [ {\begin{array}{*10c}\, d^{+}_v \circ d^{+}_{u}, &#x0026;\, d^{-}_v \circ d^{-}_{u}, &#x0026;\, d^{-}_v \circ d^{+}_{u}, &#x0026;\, d^{+}_v \circ d^{-}_{u}, &#x0026;\, d_v \circ d_u\, \\ \end{array}}\big ] \end{equation} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$d_v = d^{+}_v \circ d^{-}_v$</span>     </span> and recall from Table&#x00A0;<a class="tbl" href="#tab1">1</a> that <span class="inline-equation"><span class="tex">$d^{+}_v$</span>     </span>, <span class="inline-equation"><span class="tex">$d^{-}_{v}$</span>     </span>, and <em>d<sub>v</sub>     </em> denote the out/in/total degree of <em>v</em>. In addition, egonet features are also used&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>]. Given a node <em>v</em> and an integer &#x2113;, the &#x2113;-egonet of <em>v</em> is defined as the set of graph elements &#x2113;-hops away from <em>v</em> (<em>i.e.</em>, distance at most &#x2113;) and all edges and nodes between that set. The external and within-egonet features for nodes are provided in Figure&#x00A0;<a class="fig" href="#fig1">1</a> and used as base features in DeepGL-node. For all the above base features, we also derive variations based on direction (in/out/both) and weights (weighted/unweighted). Observe that DeepGL naturally supports many other graph properties including efficient/linear-time properties such as PageRank. Moreover, fast approximation methods with provable bounds can also be used to derive features such as the local coloring number and largest clique centered at the neighborhood of each graph element (node, edge) in <em>G</em>. <figure id="fig1">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191524/images/www18companion-263-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 1:</span>       <span class="figure-title">       <strong>Egonet Features</strong>. The set of base (&#x2113;=1 hop)-egonet graph features. <strong>(a)</strong> the external egonet features; <strong>(b)</strong> the within egonet features. See the legend for the vertex types: ego-center (&#x2022;), within-egonet vertex (&#x2022;), and external egonet vertices (&#x25CB;).</span>      </div>     </figure>    </p>    <p>A key advantage of DeepGL lies in its ability to naturally handle attributed graphs. In particular, any set of initial attributes given as input can simply be concatenated with <strong>X</strong> and treated the same as the initial base features. <figure id="fig2">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191524/images/www18companion-263-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Overview of the DeepGL architecture for graph representation learning. Let <strong>W</strong> = [<em>w<sub>ij</sub>       </em>] be a matrix of feature weights where <em>w<sub>ij</sub>       </em> (or <em>W<sub>ij</sub>       </em>) is the weight between the feature vectors x<sub>        <em>i</em>       </sub> and x<sub>        <em>j</em>       </sub>. Notice that <strong>W</strong> has the constraint that <em>i</em> < <em>j</em> < <em>k</em> and x<sub>        <em>i</em>       </sub>, x<sub>        <em>j</em>       </sub>, and x<sub>        <em>k</em>       </sub> are increasingly deeper. Each feature layer <span class="inline-equation"><span class="tex">$\mathcal {F}_{h} \in \mathcal {F}$</span>       </span> defines a set of unique <em>relational functions</em>        <span class="inline-equation"><span class="tex">$\mathcal {F}_h = \lbrace \,\cdots \!, \, f_k, \, \cdots \, \rbrace$</span>       </span> of order <em>h</em> (depth) and each <span class="inline-equation"><span class="tex">$f_k \in \mathcal {F}_{h}$</span>       </span> denotes a <em>relational function</em>. Further, let <span class="inline-equation"><span class="tex">$\mathcal {F} = \mathcal {F}_{1} \cup \mathcal {F}_{2} \cup \cdots \cup \mathcal {F}_{\tau }$</span>       </span> and <span class="inline-equation"><span class="tex">$\left|\mathcal {F}\right| = |\mathcal {F}_{1}| + |\mathcal {F}_{2}| + \cdots + |\mathcal {F}_{\tau }|$</span>       </span>. Moreover, the layers are ordered where <span class="inline-equation"><span class="tex">$\mathcal {F}_{1} {\lt} \mathcal {F}_{2} {\lt} \cdots {\lt} \mathcal {F}_{\tau }$</span>       </span> such that if <em>i</em> < <em>j</em> then <span class="inline-equation"><span class="tex">$\mathcal {F}_{j}$</span>       </span> is said to be a deeper layer <span class="inline-equation"><span class="tex">$\emph {w.r.t.}$</span>       </span>        <span class="inline-equation"><span class="tex">$\mathcal {F}_{i}$</span>       </span>. See Table&#x00A0;<a class="tbl" href="#tab1">1</a> for a summary of notation.</span>      </div>     </figure>    </p>    </section>    <section id="sec-8">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Relational Function Space &#x0026; Expressivity</h3>     </div>    </header>    <p>In this section, we formulate the space of relational functions<a class="fn" href="#fn6" id="foot-fn6"><sup>5</sup></a> that can be expressed and searched over by DeepGL. A relational function (feature) in DeepGL is defined as a composition of relational feature operators applied to an initial base feature x. Recall that unlike recent node embedding methods&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>], the proposed approach learns graph functions that are transferable across-networks for a variety of important graph-based transfer learning tasks such as <em>across-network</em>prediction, anomaly detection, graph similarity, matching, among others.</p>    <section id="sec-9">     <p><em>2.2.1 Composing Relational Functions.</em> The space of relational functions searched via DeepGL is defined <em>compositionally</em> in terms of a set of <em>relational feature operators &#x03A6;</em> = {<em>&#x03A6;</em>      <sub>1</sub>, &#x22C5;&#x22C5;&#x22C5;, <em>&#x03A6;<sub>K</sub>      </em>}. A few relational feature operators are defined formally in Table&#x00A0;<a class="tbl" href="#tab2">2</a>; see&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0028">28</a>] (pp. 404) for a wide variety of other useful relational feature operators. The expressivity of DeepGL (space of relational functions expressed by DeepGL) depends on a few flexible and interchangeable components including: (<em>i</em>) the initial base features (derived using the graph structure, initial attributes given as input, or both), (<em>ii</em>) a set of <em>relational feature operators &#x03A6;</em> = {<em>&#x03A6;</em>      <sub>1</sub>, &#x22C5;&#x22C5;&#x22C5;, <em>&#x03A6;<sub>K</sub>      </em>}, (<em>iii</em>) the sets of &#x201C;related graph elements&#x201D; <span class="inline-equation"><span class="tex">$S \in \mathcal {S}$</span>      </span> (<em>e.g.</em>, the in/out/all neighbors within &#x2113; hops of a given node/edge) that are used with each relational feature operator <em>&#x03A6;<sub>p</sub>      </em> &#x2208; <em>&#x03A6;</em>, and finally, (<em>iv</em>) the number of times each relational function is composed with another (<em>i.e.</em>, the depth). Observe that under this formulation each feature vector x&#x2032; from <strong>X</strong> (that is not a base feature) can be written as a composition of relational feature operators applied over a base feature. For instance, given an initial <em>base feature</em> x, by abuse of notation let x&#x2032; = <em>&#x03A6;<sub>k</sub>      </em>(<em>&#x03A6;<sub>j</sub>      </em>(<em>&#x03A6;<sub>i</sub>      </em>&#x27E8;x&#x27E9;)) = (<em>&#x03A6;<sub>k</sub>      </em>&#x25CB;&#x2009;<em>&#x03A6;<sub>j</sub>      </em>&#x25CB;&#x2009;<em>&#x03A6;<sub>i</sub>      </em>)(x) be a feature vector given as output by applying the relational function constructed by composing the <em>relational feature operators</em> &#x2009;      <em>&#x03A6;<sub>k</sub>      </em>&#x25CB;&#x2009;<em>&#x03A6;<sub>j</sub>      </em>&#x25CB;&#x2009;<em>&#x03A6;<sub>i</sub>      </em> to every graph element <span class="inline-equation"><span class="tex">$g_i \in \mathcal {G}$</span>      </span> and its set <em>S</em> of related elements.<a class="fn" href="#fn7" id="foot-fn7"><sup>6</sup></a>Obviously, more complex relational functions are easily expressed such as those involving compositions of different relational feature operators (and possibly different sets of related graph elements). Furthermore, DeepGL is able to learn relational functions that often correspond to increasingly higher-order subgraph features based on a set of initial lower-order (base) subgraph features (Figure&#x00A0;<a class="fig" href="#fig2">2</a>). Intuitively, just as filters are used in Convolutional Neural Networks (CNNs)&#x00A0; [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0012">12</a>], one can think of DeepGL in a similar way, but instead of simple filters, we have features derived from lower-order subgraphs being combined in various ways to capture higher-order subgraph patterns of increasingly complexity at each successive layer.</p>    </section>    <section id="sec-10">     <p><em>2.2.2 Summation and Multiplication of Functions.</em> We can also derive a wide variety of <em>relational functions</em> compositionally by adding and multiplying relational functions (<em>e.g.</em>, <em>&#x03A6;<sub>i</sub>      </em> + <em>&#x03A6;<sub>j</sub>      </em>, and <em>&#x03A6;<sub>i</sub>      </em> &#x00D7; <em>&#x03A6;<sub>j</sub>      </em>). A <em>sum of relational functions</em> is similar to an OR operation in that two instances are &#x201C;close&#x201D; if either has a large value, and similarly, a <em>product of relational functions</em> is analogous an AND operation as two instances are close if both relational functions have large values.</p>     <div class="table-responsive" id="tab2">      <div class="table-caption">       <span class="table-number">Table 2:</span>       <span class="table-title">Definitions of a few <strong>relational feature operators</strong>. Recall the notation from Table&#x00A0;<a class="tbl" href="#tab1">1</a>. For generality, <em>S</em> is defined in Table&#x00A0;<a class="tbl" href="#tab1">1</a> as a set of related graph elements (nodes, edges) of <em>g<sub>i</sub>       </em> and thus <em>s<sub>j</sub>       </em> &#x2208; <em>S</em> may be an edge <em>s<sub>j</sub>       </em> = <em>e<sub>j</sub>       </em> or a node <em>s<sub>j</sub>       </em> = <em>v<sub>j</sub>       </em>; in this work <span class="inline-equation"><span class="tex">$S \in \big \lbrace \Gamma _{\ell }(g_i),\, \Gamma ^{+}_{\ell }\!(g_i),\, \Gamma ^{-}_{\ell }\!(g_i)\big \rbrace$</span>       </span>. The relational operators generalize to &#x2113;-distance neighborhoods (<em>e.g.</em>, <em>&#x0393;</em>       <sub>&#x2113;</sub>(<em>g<sub>i</sub>       </em>) where &#x2113; is the distance). Note <span class="inline-equation"><span class="tex">${\rm x}= \big [ \; x_1 \;\; x_2 \;\; \cdots \;\; x_i \;\; \cdots \; \big ] \in \mathbb {R}^{M}$</span>       </span> where <em>x<sub>i</sub>       </em> is the <em>i</em>-th element of x for <em>g<sub>i</sub>       </em>.</span>      </div>      <table class="table">       <tbody>       <tr>        <td style="text-align:left;">         <strong>Operator</strong>        </td>        <td style="text-align:left;">         <strong>Definition</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">Hadamard</td>        <td style="text-align:left;">         <span class="inline-equation"><span class="tex">$\Phi \langle S, {\rm x} \rangle = \prod \limits _{s_j \in S} x_{j}$</span>         </span>        </td>       </tr>       <tr>        <td style="text-align:left;">mean</td>        <td style="text-align:left;">         <span class="inline-equation"><span class="tex">$\Phi \langle S, {\rm x} \rangle = \frac{1}{|S|} \sum \limits _{s_j \in S} x_{j}$</span>         </span>        </td>       </tr>       <tr>        <td style="text-align:left;">sum</td>        <td style="text-align:left;">         <span class="inline-equation"><span class="tex">$\Phi \langle S, {\rm x} \rangle = \sum \limits _{s_j \in S} x_{j}$</span>         </span>        </td>       </tr>       <tr>        <td style="text-align:left;">maximum</td>        <td style="text-align:left;">         <span class="inline-equation"><span class="tex">$\Phi \langle S, {\rm x} \rangle = \max \limits _{s_j \in S} \; x_{j}$</span>         </span>        </td>       </tr>       <tr>        <td style="text-align:left;">Weight. <em>L<sup>p</sup>         </em>        </td>        <td style="text-align:left;">         <span class="inline-equation"><span class="tex">$\Phi \langle S, {\rm x} \rangle = \sum \limits _{s_j \in S} \left|x_{i} - x_{j}\right|^{p}$</span>         </span>        </td>       </tr>       <tr>        <td style="text-align:left;">RBF</td>        <td style="text-align:left;">         <span class="inline-equation"><span class="tex">$\Phi \langle S, {\rm x} \rangle =\exp \Big (- \frac{1}{\sigma ^2} \sum \limits _{s_j \in S} \big [x_{i} - x_{j}\big ]^{2}\Big)$</span>         </span>        </td>       </tr>       </tbody>      </table>     </div>    </section>    </section>    <section id="sec-11">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.3</span> Searching the Relational Function Space</h3>     </div>    </header>    <p>A general and flexible framework for DeepGL is given in Alg.&#x00A0;. Recall that DeepGL begins by deriving a set of base features which are used as a basis for learning deeper and more discriminative features of increasing complexity (Line&#x00A0;). The base feature vectors are then transformed (Line&#x00A0;). For instance, one may transform each feature vector x<sub>      <em>i</em>     </sub> using logarithmic binning as follows: sort x<sub>      <em>i</em>     </sub> in ascending order and set the <em>&#x03B1;M</em> graph elements (edges/nodes) with smallest values to 0 where 0 < <em>&#x03B1;</em> < 1, then set <em>&#x03B1;</em> fraction of remaining graph elements with smallest value to 1, and so on. Many other techniques exist for transforming the feature vectors and the selected technique will largely depend on the graph structure. <figure id="fig3">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191524/images/www18companion-263-fig3.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>    </p>    <p>The framework proceeds to learn a hierarchical graph representation (Figure&#x00A0;<a class="fig" href="#fig2">2</a>) where each successive layer represents increasingly deeper higher-order (edge/node) graph functions: <span class="inline-equation"><span class="tex">$\mathcal {F}_{1} {\lt} \mathcal {F}_{2} {\lt} \cdots {\lt} \mathcal {F}_{\tau }$</span>     </span>     <em>s.t.</em> if <em>i</em> < <em>j</em> then <span class="inline-equation"><span class="tex">$\mathcal {F}_{j}$</span>     </span> is said to be deeper than <span class="inline-equation"><span class="tex">$\mathcal {F}_{i}$</span>     </span>. In particular, the feature layers <span class="inline-equation"><span class="tex">$\mathcal {F}_2, \mathcal {F}_{3}, \cdots , \mathcal {F}_{\tau }$</span>     </span> are derived as follows (Alg.&#x00A0;1 Lines&#x00A0;-): First, we derive the feature layer <span class="inline-equation"><span class="tex">$\mathcal {F}_{\tau }$</span>     </span> by searching over the space of graph functions that arise from applying the relational feature operators <em>&#x03A6;</em> to each of the novel features <span class="inline-equation"><span class="tex">$f_i \in \mathcal {F}_{\tau -1}$</span>     </span> learned in the previous layer (Alg.&#x00A0;1 Line&#x00A0;). An algorithm for deriving a feature layer is provided in Alg.&#x00A0;. Next, the feature vectors from layer <span class="inline-equation"><span class="tex">$\mathcal {F}_{\tau }$</span>     </span> are transformed in Line&#x00A0; as discussed previously.</p>    <p>The resulting features in layer <em>&#x03C4;</em> are then evaluated. The feature evaluation routine (in Alg.&#x00A0;1 Line&#x00A0;) chooses the important features (relational functions) at each layer <em>&#x03C4;</em> from the space of novel relational functions (at depth <em>&#x03C4;</em>) constructed by applying the relational feature operators to each feature (relational function) learned (and given as output) in the previous layer <em>&#x03C4;</em> &#x2212; 1. Notice that DeepGL is extremely flexible as the feature evaluation routine (Alg.&#x00A0;) called in Line&#x00A0; of Alg.&#x00A0;1 is completely interchangeable and can be fine-tuned for specific applications and/or data. This approach derives a score between pairs of features. Pairs of features x<sub>      <em>i</em>     </sub> and x<sub>      <em>j</em>     </sub> that are <em>strongly dependent</em> as determined by the hyperparameter <em>&#x03BB;</em> and evaluation criterion <span class="inline-equation"><span class="tex">$\mathbb {K}$</span>     </span> are assigned <span class="inline-equation"><span class="tex">$W_{ij}=\mathbb {K}({\rm x}_i,\, {\rm x}_j)$</span>     </span> and <em>W<sub>ij</sub>     </em> = 0 otherwise (Alg.&#x00A0; Line&#x00A0;-). More formally, let <em>E<sub>F</sub>     </em> denote the set of connections representing dependencies between features: <div class="table-responsive" id="eq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} E_{F} = \big \lbrace (i, j) \; | \; \forall (i, j) \in |\mathcal {F}| \times |\mathcal {F}| \text{ \it s.t. } \mathbb {K}({\rm x}_i, {\rm x}_j) {\gt} \lambda \big \rbrace \end{equation} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div> The result is a <em>weighted feature dependence graph</em>     <span class="inline-equation"><span class="tex">$\mathcal {G}_F$</span>     </span>. Now, <span class="inline-equation"><span class="tex">$\mathcal {G}_F$</span>     </span> is used to select a subset of important features from layer <em>&#x03C4;</em>. Features are selected as follows: First, the feature graph <span class="inline-equation"><span class="tex">$\mathcal {G}_F$</span>     </span> is partitioned into groups of features <span class="inline-equation"><span class="tex">$\lbrace \mathcal {C}_1, \mathcal {C}_2, \ldots \rbrace$</span>     </span> where each set <span class="inline-equation"><span class="tex">$\mathcal {C}_k \in \mathcal {C}$</span>     </span> represents features that are dependent (though not necessarily pairwise dependent). To partition the feature graph <span class="inline-equation"><span class="tex">$\mathcal {G}_F$</span>     </span>, Alg.&#x00A0;uses connected components, though other methods are also possible, <em>e.g.</em>, a clustering or community detection method. Next, one or more representative features are selected from each group (cluster) of dependent features. Alternatively, it is also possible to derive a new feature from the group of dependent features, <em>e.g.</em>, finding a low-dimensional embedding of these features or taking the principal eigenvector. In Alg.&#x00A0;the earliest feature in each connected component <span class="inline-equation"><span class="tex">$\mathcal {C}_{k} = \lbrace ...,f_i,...,f_j,...\rbrace \in \mathcal {C}$</span>     </span> is selected and all others are removed. After pruning the feature layer <span class="inline-equation"><span class="tex">$\mathcal {F}_{\tau }$</span>     </span>, the discarded features are removed from <strong>X</strong> and DeepGL updates the set of features learned thus far by setting <span class="inline-equation"><span class="tex">$\mathcal {F}\leftarrow \mathcal {F}\,\cup \, \mathcal {F}_{\tau }$</span>     </span> (Alg.&#x00A0;1: Line&#x00A0;). Next, Line&#x00A0; increments <em>&#x03C4;</em> and sets <span class="inline-equation"><span class="tex">$\mathcal {F}_{\tau } \leftarrow \varnothing$</span>     </span>. Finally, we check for convergence, and if the stopping criterion is not satisfied, then DeepGL learns an additional feature layer (Line&#x00A0;-).</p>    <p>In contrast to node embedding methods that output only a <em>node</em> feature matrix <strong>X</strong>, DeepGL also outputs the (hierarchical) relational functions <span class="inline-equation"><span class="tex">$\mathcal {F}$</span>     </span> corresponding to the learned features. Maintaining the relational functions are important for transferring the features to another arbitrary graph of interest, but also for interpreting them. Moreover, DeepGL is an inductive representation learning approach as the relational functions can be used to derive embeddings for new nodes or even graphs.</p>    </section>    <section id="sec-12">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.4</span> Feature Diffusion</h3>     </div>    </header>    <p>We introduce the notion of feature diffusion where the feature matrix at each layer can be smoothed using an arbitrary feature diffusion process. As an example, suppose <strong>X</strong> is the resulting feature matrix from layer <em>&#x03C4;</em>, then we can set <span class="inline-equation"><span class="tex">$\bar{{\bf X}}^{(0)}\leftarrow {\bf X}$</span>     </span> and solve <div class="table-responsive" id="eq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \bar{{\bf X}}^{(t)} = {\bf D}^{-1}{\bf A}\bar{{\bf X}}^{(t-1)} \end{equation} </span>       <br/>       <span class="equation-number">(3)</span>      </div>     </div> where <strong>D</strong> is the diagonal degree matrix and <strong>A</strong> is the adjacency matrix of <em>G</em>. The diffusion process above is repeated for a fixed number of iterations <em>t</em> = 1, 2, ..., <em>T</em> or until convergence; and <span class="inline-equation"><span class="tex">$\bar{{\bf X}}^{(t)} = {\bf D}^{-1}{\bf A}\bar{{\bf X}}^{(t-1)}$</span>     </span> corresponds to a simple feature propagation. More complex feature diffusion processes can also be used in DeepGL such as the normalized Laplacian feature diffusion defined as <div class="table-responsive" id="eq3">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \bar{{\bf X}}^{(t)} = (1-\theta){\bf L}\bar{{\bf X}}^{(t-1)} + \theta {\bf X},\quad \text{ for } t=1,2,... \end{equation} </span>       <br/>       <span class="equation-number">(4)</span>      </div>     </div> where <strong>L</strong> is the normalized Laplacian: <div class="table-responsive" id="Xeq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} {\bf L}= {\bf I} - {\bf D}^{{1}{2}}{\bf A}{\bf D}^{{1}{2}} \end{equation} </span>       <br/>       <span class="equation-number">(5)</span>      </div>     </div> The resulting diffused feature vectors <span class="inline-equation"><span class="tex">$\bar{{\bf X}} = \big [\;\; \bar{{\rm x}}_1 \;\; \bar{{\rm x}}_2 \;\; \cdots \;\; \big ]$</span>     </span> are effectively smoothed by the features of related graph elements (nodes/edges) governed by the particular diffusion process. Notice that feature vectors given as output at each layer can be diffused (<em>e.g.</em>, after Line&#x00A0; or&#x00A0; of Alg.&#x00A0;1). Note <span class="inline-equation"><span class="tex">$\bar{{\bf X}}$</span>     </span> can be leveraged in a variety of ways: <span class="inline-equation"><span class="tex">${\bf X}\leftarrow \bar{{\bf X}}$</span>     </span> (replacing previous) or concatenated by <span class="inline-equation"><span class="tex">${\bf X}\leftarrow \big [ \, {\bf X}\; \bar{{\bf X}} \, \big ]$</span>     </span>. Feature diffusion can be viewed as a form of graph regularization as it can improve the generalizability of a model learned using the graph embedding. <figure id="fig4">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191524/images/www18companion-263-fig4.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>     <figure id="fig5">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191524/images/www18companion-263-fig5.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>    </p>    </section>    <section id="sec-13">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.5</span> Computational Complexity</h3>     </div>    </header>    <p>Recall that <em>M</em> is the number of edges, <em>N</em> is the number of nodes, and <em>F</em> is the number of features.</p>    <section id="sec-14">     <p><em>2.5.1 Learning.</em> The total computational complexity of the <em>edge representation learning</em> from the DeepGL framework is: <div class="table-responsive" id="eq4">       <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathcal {O}\big (F(M+MF)\big) \end{equation} </span>       <br/>       <span class="equation-number">(6)</span>       </div>      </div> For <em>node representation learning</em>, the time complexity of DeepGL is: <div class="table-responsive" id="eq5">       <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathcal {O}\big (F(M+NF)\big) \end{equation} </span>       <br/>       <span class="equation-number">(7)</span>       </div>      </div> Thus, in both cases, the runtime of representation learning in DeepGL is linear in the number of edges. As an aside, the initial graphlet features are computed using fast and accurate estimation methods, see Ahmed&#x00A0;<em>et al.</em> &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0003">3</a>].</p>    </section>    <section id="sec-15">     <p><em>2.5.2 Inductive relational functions.</em> We now state the computational complexity of directly computing the set of inductive relational functions (feature definitions) which were previously learned on another arbitrary graph. Computation of the relational functions <span class="inline-equation"><span class="tex">$\mathcal {F}$</span>      </span> on another arbitrary graph is important for inductive across-network learning tasks. Given the set of learned relational functions <span class="inline-equation"><span class="tex">$\mathcal {F}$</span>      </span>, the total computational complexity of the <em>edge relational functions</em> is: <div class="table-responsive" id="eq6">       <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathcal {O}\big (FM\big) \end{equation} </span>       <br/>       <span class="equation-number">(8)</span>       </div>      </div> Similarly, the time complexity of the <em>node relational functions</em> is also <span class="inline-equation"><span class="tex">$\mathcal {O}\big (FM\big)$</span>      </span>.</p>     <p>Thus, the runtime of deriving the edge and node relational functions in DeepGL is linear in the number of edges. Computing the set of inductive relational functions on another arbitrary graph obviously requires less work than learning the actual set of inductive relational functions (Section&#x00A0;<a class="sec" href="#sec-14">2.5.1</a>). The key difference is that features are not evaluated when deriving the relational functions directly. In contrast, representation learning in DeepGL scores the features at each layer.</p>    </section>    </section>   </section>   <section id="sec-16">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> Experiments</h2>    </div>    </header>    <p>This section demonstrates the effectiveness of the proposed framework.</p>    <section id="sec-17">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Experimental settings</h3>     </div>    </header>    <p>In these experiments, we use the following instantiation of DeepGL: Features are transformed using logarithmic binning and evaluated using a simple agreement score function where <span class="inline-equation"><span class="tex">$\mathbb {K}({\rm x}_i, {\rm x}_j)=$</span>     </span> fraction of graph elements that agree. More formally, agreement scoring is defined as: <div class="table-responsive" id="Xeq3">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathbb {K} ({\rm x}_i,{\rm x}_j) = \frac{\left|\big \lbrace (x_{ik},x_{jk}), \; \forall k = 1,\ldots ,\!N\; | \; x_{ik}=x_{jk}\big \rbrace \right|}{N} \end{equation} </span>       <br/>       <span class="equation-number">(9)</span>      </div>     </div> where <em>x<sub>ik</sub>     </em> and <em>x<sub>jk</sub>     </em> are the <em>k</em>-th feature value of the <em>N</em>-dimensional vectors x<sub>      <em>i</em>     </sub> and x<sub>      <em>j</em>     </sub>, respectively. Unless otherwise mentioned, we set <em>&#x03B1;</em> = 0.5 (bin size of logarithmic binning) and perform a grid search over <em>&#x03BB;</em> &#x2208; {0.01, 0.05, 0.1, 0.2, 0.3} and <em>&#x03A6;</em> &#x2208; {<em>&#x03A6;</em>     <sub>mean</sub>, <em>&#x03A6;</em>     <sub>sum</sub>, <em>&#x03A6;</em>     <sub>prod</sub>, {<em>&#x03A6;</em>     <sub>mean</sub>, <em>&#x03A6;</em>     <sub>sum</sub>}, {<em>&#x03A6;</em>     <sub>prod</sub>, <em>&#x03A6;</em>     <sub>sum</sub>}, {<em>&#x03A6;</em>     <sub>prod</sub>, <em>&#x03A6;</em>     <sub>mean</sub>}}.</p>    <p>See Table&#x00A0;<a class="tbl" href="#tab2">2</a>. Note <em>&#x03A6;</em>     <sub>prod</sub> refers to the Hadamard relational operator defined formally in Table&#x00A0;<a class="tbl" href="#tab2">2</a>. As an aside, DeepGL has fewer hyperparameters than node2vec, DeepWalk, and LINE used in the comparison below. The specific model defined by the above instantiation of DeepGL is selected using 10-fold cross-validation on 10% of the labeled data. Experiments are repeated for 10 random seed initializations. All results are statistically significant with p-value < 0.01.</p>    <p>We evaluate the proposed framework against node2vec&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>], DeepWalk&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>], and LINE&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>]. For node2vec, we use the hyperparameters and grid search over <em>p</em>, <em>q</em> &#x2208; {0.25, 0.50, 1, 2, 4} as mentioned in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>]. The experimental setup mentioned in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>] is used for DeepWalk and LINE. Unless otherwise mentioned, we use logistic regression with an L2 penalty and one-vs-rest for multiclass problems. Data has been made available at NetworkRepository&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>].<a class="fn" href="#fn8" id="foot-fn8"><sup>7</sup></a>    </p>    <div class="table-responsive" id="tab3">     <div class="table-caption">      <span class="table-number">Table 3:</span>      <span class="table-title">AUC scores for <em>Within-network Link Classification</em>      </span>     </div>     <table class="table">      <tbody>       <tr>       <td style="text-align:left;">        <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191524/images/www18companion-263-graphic6.jpg" class="img-responsive" alt=""         longdesc=""/>       </td>       </tr>      </tbody>     </table>    </div>    </section>    <section id="sec-18">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Within-Network Link Classification</h3>     </div>    </header>    <p>We first evaluate the effectiveness of DeepGL for link classification. To be able to compare DeepGL to node2vec and the other methods, we focus in this section on <em>within-network link classification</em>. For comparison, we use the same set of binary operators to construct features for the edges <em>indirectly</em> using the learned node representations: Given the feature vectors x<sub>      <em>i</em>     </sub> and x<sub>      <em>j</em>     </sub> for node <em>i</em> and <em>j</em>, (x<sub>      <em>i</em>     </sub> + x<sub>      <em>j</em>     </sub>)/2 is the <SmallCap>mean</SmallCap>; x<sub>      <em>i</em>     </sub>&#x2299;x<sub>      <em>j</em>     </sub> is the (Hadamard) <SmallCap>product</SmallCap>; |x<sub>      <em>i</em>     </sub> &#x2212; x<sub>      <em>j</em>     </sub>| and (x<sub>      <em>i</em>     </sub> &#x2212; x<sub>      <em>j</em>     </sub>)<sup>&#x25CB;2</sup> is the <SmallCap>weighted</SmallCap>-<SmallCap>l</SmallCap>     <sub>1</sub> and <SmallCap>weighted</SmallCap>-<SmallCap>l</SmallCap>     <sub>2</sub> binary operators, respectively.<a class="fn" href="#fn9" id="foot-fn9"><sup>8</sup></a>Note that these binary operators (used to create edge features) are not to be confused with the relational feature operators defined in Table&#x00A0;<a class="tbl" href="#tab2">2</a>. In Table&#x00A0;<a class="tbl" href="#tab3">3</a>, we observe that DeepGL outperforms node2vec, DeepWalk, and LINE with an average gain between 18.09% and 20.80% across all graphs and binary operators.</p>    <p>Notice that node2vec, DeepWalk, and LINE all require that the training graph contain at least one edge among each node in <em>G</em>. However, DeepGL overcomes this fundamental limitation and can actually predict the class label of edges that are not in the training graph as well as the class labels of edges in an entirely different network. <figure id="fig6">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191524/images/www18companion-263-fig6.jpg" class="img-responsive" alt="Figure 6"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 6:</span>       <span class="figure-title">DeepGL requires up to 6x less space than node2vec and other methods that learn dense embeddings.</span>      </div>     </figure>    </p>    </section>    <section id="sec-19">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> Analysis of Space-Efficiency</h3>     </div>    </header>    <p>Learning sparse space-efficient node and edge feature representations is of vital importance for large networks where storing even a modest number of <em>dense</em> features is impractical (especially when stored in-memory). Despite the importance of learning a sparse space-efficient representation, existing work has been limited to discovering completely dense (node) features&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>]. To understand the effectiveness of the proposed framework for learning sparse graph representations, we measure the density of each representation learned from DeepGL and compare these against the state-of-the-art methods&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>]. We focus first on node representations since existing methods are limited to only node features. Results are shown in Figure&#x00A0;<a class="fig" href="#fig6">3</a>. In all cases, the node representations learned by DeepGL are extremely sparse and significantly more space-efficient than node2vec&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>] as observed in Figure&#x00A0;<a class="fig" href="#fig6">3</a>. DeepWalk and LINE use nearly the same space as node2vec, and thus are omitted for brevity. Strikingly, DeepGL uses only a fraction of the space required by existing methods (Figure&#x00A0;<a class="fig" href="#fig6">3</a>). Moreover, the density of node and edge representations from DeepGL is between <span class="inline-equation"><span class="tex">$\big [{{\begin{array}{*10c}0.162, &#x0026; 0.334\end{array}}}\big ]$</span>     </span> for nodes and <span class="inline-equation"><span class="tex">$\big [{{\begin{array}{*10c}0.164, &#x0026; 0.318\end{array}}}\big ]$</span>     </span> for edges and up to 6 &#x00D7; more space-efficient than existing methods.</p>    <p>Notably, recent node embedding methods not only output dense node features, but are also real-valued and often negative (<em>e.g.</em>,&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>]). Thus, they require 8 bytes per feature-value, whereas DeepGL requires only 2 bytes and can sometimes be reduced to even 1 byte if needed by adjusting <em>&#x03B1;</em> (<em>i.e.</em>, the bin size of the log binning transformation). To understand the impact of this, assume both approaches learn a node representation with 128 dimensions (features) for a graph with 10,000,000 nodes. In this case, node2vec, DeepWalk, and LINE require 10.2GB, whereas DeepGL uses only 0.768GB (assuming a modest 0.3 density) &#x2014; a significant reduction in space by a factor of 13. <figure id="fig7">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191524/images/www18companion-263-fig7.jpg" class="img-responsive" alt="Figure 7"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 7:</span>       <span class="figure-title">Runtime comparison on Erd&#x00F6;s-R&#x00E9;nyi graphs with an average degree of 10. The proposed approach is shown to be orders of magnitude faster than node2vec&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0013">13</a>].</span>      </div>     </figure>    </p>    </section>    <section id="sec-20">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.4</span> Runtime &#x0026; Scalability</h3>     </div>    </header>    <p>To evaluate the performance and scalability of the proposed framework, we learn node representations for Erd&#x00F6;s-R&#x00E9;nyi graphs of increasing size (from 100 to 10,000,000 nodes) such that each graph has an average degree of 10. We compare the performance of DeepGL against node2vec&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>] which is designed specifically to be <em>scalable</em> for large graphs and shown to be faster than DeepWalk and LINE. Default parameters are used for each method. In Figure&#x00A0;<a class="fig" href="#fig7">4</a>, we observe that DeepGL is significantly faster and more scalable than node2vec. In particular, node2vec takes 1.8 days (45.3 hours) for 10 million nodes, whereas DeepGL finishes in only 15 minutes; see Figure&#x00A0;<a class="fig" href="#fig7">4</a>. Strikingly, this is 182 times faster than node2vec. <figure id="fig8">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191524/images/www18companion-263-fig8.jpg" class="img-responsive" alt="Figure 8"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 8:</span>       <span class="figure-title">Parallel speedup of different variants from the DeepGL framework. See text for discussion.</span>      </div>     </figure>    </p>    </section>    <section id="sec-21">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.5</span> Parallel Scaling</h3>     </div>    </header>    <p>This section investigates the parallel performance of DeepGL. To evaluate the effectiveness of the parallel algorithm we measure speedup defined as <span class="inline-equation"><span class="tex">$S_p = \frac{T_1}{T_p}$</span>     </span> where <em>T</em>     <sub>1</sub> and <em>T<sub>p</sub>     </em> are the execution time of the sequential and parallel algorithms (w/ <em>p</em> processing units), respectively. In Figure&#x00A0;<a class="fig" href="#fig8">5</a>, we observe strong parallel scaling for all DeepGL variants with the edge representation learning variants performing slightly better than the node representation learning methods from DeepGL. Results are reported for <span class="inline-equation"><span class="tex">${\mathsf {soc}\text{--}{\mathbf {\tt gowalla}}}$</span>     </span> on a machine with 4 Intel Xeon E5-4627 v2 3.3GHz CPUs. Other graphs and machines gave similar results.</p>    <div class="table-responsive" id="tab4">     <div class="table-caption">      <span class="table-number">Table 4:</span>      <span class="table-title">AUC scores for node classification</span>     </div>     <table class="table">      <tbody>       <tr>       <td style="text-align:left;">        <strong>graph</strong>       </td>       <td style="text-align:left;">        <span class="inline-equation"><span class="tex">$|\mathcal {C}|$</span>        </span>       </td>       <td style="text-align:left;">        <span class="inline-equation"><span class="tex">$\mathrm{\bf DeepGL}$</span>        </span>       </td>       <td style="text-align:left;">        <strong>node2vec</strong>       </td>       </tr>       <tr>       <td style="text-align:left;">DD242</td>       <td style="text-align:left;">20</td>       <td style="text-align:left;">        <strong>0.730</strong>       </td>       <td style="text-align:left;">0.673</td>       </tr>       <tr>       <td style="text-align:left;">DD497</td>       <td style="text-align:left;">20</td>       <td style="text-align:left;">        <strong>0.696</strong>       </td>       <td style="text-align:left;">0.660</td>       </tr>       <tr>       <td style="text-align:left;">DD68</td>       <td style="text-align:left;">20</td>       <td style="text-align:left;">        <strong>0.730</strong>       </td>       <td style="text-align:left;">0.713</td>       </tr>       <tr>       <td style="text-align:left;">ENZYMES118</td>       <td style="text-align:left;">2</td>       <td style="text-align:left;">        <strong>0.779</strong>       </td>       <td style="text-align:left;">0.610</td>       </tr>       <tr>       <td style="text-align:left;">ENZYMES295</td>       <td style="text-align:left;">2</td>       <td style="text-align:left;">        <strong>0.872</strong>       </td>       <td style="text-align:left;">0.588</td>       </tr>       <tr>       <td style="text-align:left;">ENZYMES296</td>       <td style="text-align:left;">2</td>       <td style="text-align:left;">        <strong>0.823</strong>       </td>       <td style="text-align:left;">0.610</td>       </tr>      </tbody>     </table>    </div>    </section>    <section id="sec-22">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.6</span> Node Classification</h3>     </div>    </header>    <p>For node classification, we use the <span class="inline-equation"><span class="tex">$\emph {i.i.d.}$</span>     </span> variant of <span class="inline-equation"><span class="tex">$\textsc {rsm}$</span>     </span>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>] since it is able to handle multiclass problems in a direct fashion (as opposed to indirectly, <em>e.g.</em>, one-vs-rest) and consistently outperformed other indirect approaches such as LR and SVM. In particular, <span class="inline-equation"><span class="tex">$\textsc {rsm}$</span>     </span> assigns a test vector x<sub>      <em>i</em>     </sub> to the class that is most similar <span class="inline-equation"><span class="tex">$\emph {w.r.t.}$</span>     </span> the training vectors (<em>i.e.</em>, feature vectors of the nodes with known labels); see&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>] for further details. Similarity is measured using the RBF kernel and RBF&#x0027;s hyperparameter <em>&#x03C3;</em> is set using cross-validation with a grid search over <em>&#x03C3;</em> &#x2208; {0.001, 0.01, 0.1, 1}. Results are shown in Table&#x00A0;<a class="tbl" href="#tab4">4</a>. In all cases, we observe that DeepGL significantly outperforms node2vec across all graphs and node classification problems including both binary and multiclass problems. Further, DeepGL achieves the best improvement in AUC on ENZYMES295 of 48%. As an aside, results for DeepWalk and LINE were removed for brevity since node2vec outperformed them in all cases.</p>    </section>   </section>   <section id="sec-23">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> Related Work</h2>    </div>    </header>    <p>Related research is categorized below.</p>    <p>    <strong>Node embedding methods</strong>: There has been a lot of interest recently in learning a set of useful <em>node features</em> from large-scale networks automatically&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>]. In particular, recent methods that apply the popular word2vec framework to learn node embeddings&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>]. The proposed DeepGL framework differs from these methods in six fundamental ways: (1) DeepGL learns complex relational functions that generalize for across-network transfer learning. Features learned from DeepGL on one graph can be extracted from another graph for transfer learning tasks such as network alignment, graph similarity, role discovery, temporal graph modeling, among others. (2) DeepGL learns sparse features and thus is extremely space-efficient for large networks. (3) DeepGL learns important and useful edge <em>and</em> node representations whereas existing work is limited to <em>node features</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>]. (4) DeepGL naturally supports attributed graphs. (5) DeepGL is fast and efficient with a runtime that is linear in the number of edges. (6) DeepGL is also completely parallel and shown in Section&#x00A0;<a class="sec" href="#sec-16">3</a> to scale strongly.</p>    <p>There is also another related body of work focused on attributed graphs. Recently, Huang&#x00A0;<em>et al.</em> &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>] proposed a label informed embedding method for attributed networks. This approach assumes the graph is labeled and uses this information to improve predictive performance. However, this work is significantly different. First and foremost, while DeepGL is able to naturally support attributed graphs, this work does not focus on such graphs. Moreover, DeepGL does not require attributes or class labels on the nodes. Another important fundamental difference is that DeepGL learns features representing relational functions that generalize for extraction on any other arbitrary graph. The relational functions naturally represent higher-order structures when based on lower-order subgraph features (Figure&#x00A0;<a class="fig" href="#fig2">2</a>). DeepGL also learns features that are sparse and therefore space-efficient for large graphs. Moreover, it is fast with a runtime that is linear in the number of edges and is completely parallel with strong scaling. There has also been some recent work on heterogeneous network embeddings&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>], semi-supervised network embeddings&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>], and methods for improving the learned representations&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>]. This work investigates entirely different problems than the one discussed in this paper.</p>    <p>We can also use the inferred embeddings for <em>graph-based transfer learning</em>. This is possible since DeepGL learns relational functions that generalize across-networks and therefore are easily extracted on another arbitrary graph. Other key differences were summarized previously in Section&#x00A0;<a class="sec" href="#sec-4">1</a>.</p>    <p>    <strong>Higher-order network analysis</strong>: Other methods use high-order network properties (such as graphlet frequencies) as features for graph classification&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>]. Graphlets (network motifs) are small induced subgraphs and have been used for graph classification&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>], role discovery&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>], and visualization and exploratory analysis&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>]. However, our work focuses on using graphlet frequencies as base features for learning node and edge representations from large networks. To the best of our knowledge, this paper is the first to use network motifs (including all motifs of size 3, 4, and 5 vertices) as base features for graph representation learning.</p>    <p>    <strong>Sparse graph feature learning</strong>: This work proposes the first practical space-efficient approach that learns sparse node/edge feature vectors. Notably, DeepGL requires significantly less space than existing node embedding methods&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>] (see Section&#x00A0;<a class="sec" href="#sec-16">3</a>). In contrast, existing embedding methods store completely dense feature vectors which is impractical for any relatively large network, <em>e.g.</em>, they require more than 3TB of memory for a 750 million node graph with 1K features.</p>   </section>   <section id="sec-24">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Conclusion</h2>    </div>    </header>    <p>We proposed DeepGL, a general, flexible, and highly expressive framework for learning deep node and edge features that generalize for across-network transfer learning tasks. Each feature learned by DeepGL corresponds to a composition of relational feature operators applied over a base feature. Thus, features learned by DeepGL are interpretable and naturally generalize for across-network transfer learning tasks as they can be derived on any arbitrary graph. The framework is flexible with many interchangeable components, expressive, interpretable, parallel, and is both space- and time-efficient for large graphs with runtime that is linear in the number of edges. DeepGL has all the following desired properties:</p>    <ul class="list-no-style">    <li id="list7" label="&#x2022;"><strong>Effective</strong> for learning functions (features) that generalize for graph-based transfer learning <em>and</em> large (attributed) graphs<br/></li>    <li id="list8" label="&#x2022;"><strong>Space-efficient</strong> requiring up to 6 &#x00D7; less memory<br/></li>    <li id="list9" label="&#x2022;"><strong>Fast</strong> with up to 182 &#x00D7; speedup in runtime performance<br/></li>    <li id="list10" label="&#x2022;"><strong>Accurate</strong> with a mean improvement in AUC of 20% or more on many applications<br/></li>    <li id="list11" label="&#x2022;"><strong>Expressive and flexible</strong>with many interchangeable components making it useful for a range of applications, graph types, and learning scenarios.<br/></li>    <li id="list12" label="&#x2022;"><strong>Parallel</strong> with strong scaling results.</li>    </ul>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">Nesreen&#x00A0;K. Ahmed, Jennifer Neville, Ryan&#x00A0;A. Rossi, and Nick Duffield. 2015. Efficient Graphlet Counting for Large Networks. In <em>      <em>ICDM</em>     </em>. 10.</li>    <li id="BibPLXBIB0002" label="[2]">Nesreen&#x00A0;K. Ahmed, Ryan&#x00A0;A. Rossi, Theodore&#x00A0;L. Willke, and Rong Zhou. 2017. Edge Role Discovery via Higher-order Structures. In <em>      <em>PAKDD</em>     </em>. Springer.</li>    <li id="BibPLXBIB0003" label="[3]">Nesreen&#x00A0;K. Ahmed, Theodore&#x00A0;L. Willke, and Ryan&#x00A0;A. Rossi. 2016. Estimation of Local Subgraph Counts. In <em>      <em>IEEE BigData</em>     </em>. 586&#x2013;595.</li>    <li id="BibPLXBIB0004" label="[4]">Leman Akoglu, Mary McGlohon, and Christos Faloutsos. 2010. Oddball: Spotting anomalies in weighted graphs. <em>      <em>PAKDD</em>     </em> (2010), 410&#x2013;421.</li>    <li id="BibPLXBIB0005" label="[5]">Leman Akoglu, Hanghang Tong, and Danai Koutra. 2015. Graph based anomaly detection and description: a survey. <em>      <em>DMKD</em>     </em>29, 3 (2015), 626&#x2013;688.</li>    <li id="BibPLXBIB0006" label="[6]">Mohammad Al&#x00A0;Hasan and Mohammed&#x00A0;J Zaki. 2011. A survey of link prediction in social networks. In <em>      <em>Social Network Data Analytics</em>     </em>. Springer, 243&#x2013;275.</li>    <li id="BibPLXBIB0007" label="[7]">Yoshua Bengio. 2009. Learning deep architectures for AI. <em>      <em>Foundations and Trends in Machine Learning</em>     </em>2, 1 (2009), 1&#x2013;127.</li>    <li id="BibPLXBIB0008" label="[8]">Yoshua Bengio. 2013. Deep learning of representations: Looking forward. In <em>      <em>SLSP</em>     </em>. Springer, 1&#x2013;37.</li>    <li id="BibPLXBIB0009" label="[9]">Adrien Bibal and Beno&#x00EE;t Fr&#x00E9;nay. 2016. Interpretability of machine learning models and representations: an introduction. In <em>      <em>Proc. ESANN</em>     </em>. 77&#x2013;82.</li>    <li id="BibPLXBIB0010" label="[10]">Shiyu Chang, Wei Han, Jiliang Tang, Guo-Jun Qi, Charu&#x00A0;C Aggarwal, and Thomas&#x00A0;S Huang. 2015. Heterogeneous network embedding via deep architectures. In <em>      <em>SIGKDD</em>     </em>. 119&#x2013;128.</li>    <li id="BibPLXBIB0011" label="[11]">Ting Chen and Yizhou Sun. 2017. Task-Guided and Path-Augmented Heterogeneous Network Embedding for Author Identification. In <em>      <em>WSDM</em>     </em>. 295&#x2013;304.</li>    <li id="BibPLXBIB0012" label="[12]">Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. <em>      <em>Deep learning</em>     </em>. MIT Press.</li>    <li id="BibPLXBIB0013" label="[13]">Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In <em>      <em>KDD</em>     </em>. 855&#x2013;864.</li>    <li id="BibPLXBIB0014" label="[14]">Xiao Huang, Jundong Li, and Xia Hu. 2017. Label informed attributed network embedding. In <em>      <em>WSDM</em>     </em>. 731&#x2013;739.</li>    <li id="BibPLXBIB0015" label="[15]">Thomas&#x00A0;N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In <em>      <em>ICLR</em>     </em>.</li>    <li id="BibPLXBIB0016" label="[16]">Mehmet Koyut&#x00FC;rk, Yohan Kim, Umut Topkara, Shankar Subramaniam, Wojciech Szpankowski, and Ananth Grama. 2006. Pairwise alignment of protein interaction networks. <em>      <em>JCB</em>     </em>13, 2 (2006), 182&#x2013;199.</li>    <li id="BibPLXBIB0017" label="[17]">Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. <em>      <em>Nature</em>     </em>521, 7553 (2015), 436&#x2013;444.</li>    <li id="BibPLXBIB0018" label="[18]">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. In <em>      <em>ICLR Workshop</em>     </em>.</li>    <li id="BibPLXBIB0019" label="[19]">Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg&#x00A0;S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In <em>      <em>NIPS</em>     </em>.</li>    <li id="BibPLXBIB0020" label="[20]">Jennifer Neville and David Jensen. 2000. Iterative classification in relational data. In <em>      <em>AAAI Workshop on Learning Statistical Models from Relational Data</em>     </em>. 13&#x2013;20.</li>    <li id="BibPLXBIB0021" label="[21]">Vincenzo Nicosia, John Tang, Cecilia Mascolo, Mirco Musolesi, Giovanni Russo, and Vito Latora. 2013. Graph metrics for temporal networks. In <em>      <em>Temporal Networks</em>     </em>. Springer, 15&#x2013;40.</li>    <li id="BibPLXBIB0022" label="[22]">Mathias Niepert, Mohamed Ahmed, and Konstantin Kutzkov. 2016. Learning Convolutional Neural Networks for Graphs. In <em>      <em>arXiv:1605.05273</em>     </em>.</li>    <li id="BibPLXBIB0023" label="[23]">Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In <em>      <em>KDD</em>     </em>. 701&#x2013;710.</li>    <li id="BibPLXBIB0024" label="[24]">Robert Pienta, James Abello, Minsuk Kahng, and Duen&#x00A0;Horng Chau. 2015. Scalable graph exploration and visualization: Sensemaking challenges and opportunities. In <em>      <em>BigComp</em>     </em>.</li>    <li id="BibPLXBIB0025" label="[25]">F. Radicchi, C. Castellano, F. Cecconi, V. Loreto, and D. Parisi. 2004. Defining and identifying communities in networks. <em>      <em>PNAS</em>     </em>101, 9 (2004), 2658&#x2013;2663.</li>    <li id="BibPLXBIB0026" label="[26]">Ryan&#x00A0;A. Rossi and Nesreen&#x00A0;K. Ahmed. 2015. The Network Data Repository with Interactive Graph Analytics and Visualization. In <em>      <em>AAAI</em>. http://networkrepository.com</em>.</li>    <li id="BibPLXBIB0027" label="[27]">Ryan&#x00A0;A. Rossi and Nesreen&#x00A0;K. Ahmed. 2015. Role Discovery in Networks. <em>      <em>TKDE</em>     </em>27, 4 (2015), 1112&#x2013;1131.</li>    <li id="BibPLXBIB0028" label="[28]">Ryan&#x00A0;A. Rossi, Luke&#x00A0;K. McDowell, David&#x00A0;W. Aha, and Jennifer Neville. 2012. Transforming graph data for statistical relational learning. <em>      <em>JAIR</em>     </em>45, 1 (2012), 363&#x2013;441.</li>    <li id="BibPLXBIB0029" label="[29]">Ryan&#x00A0;A. Rossi, Rong Zhou, and Nesreen&#x00A0;K. Ahmed. 2016. Relational Similarity Machines. In <em>      <em>KDD MLG</em>     </em>. 1&#x2013;8.</li>    <li id="BibPLXBIB0030" label="[30]">Ryan&#x00A0;A. Rossi, Rong Zhou, and Nesreen&#x00A0;K. Ahmed. 2017. Deep Feature Learning for Graphs. In <em>      <em>arXiv:1704.08829</em>     </em>. 11.</li>    <li id="BibPLXBIB0031" label="[31]">Franco Scarselli, Marco Gori, Ah&#x00A0;Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2009. The graph neural network model. <em>      <em>IEEE Transactions on Neural Networks</em>     </em>20, 1 (2009), 61&#x2013;80.</li>    <li id="BibPLXBIB0032" label="[32]">Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale Information Network Embedding.. In <em>      <em>WWW</em>     </em>.</li>    <li id="BibPLXBIB0033" label="[33]">Alfredo Vellido, Jos&#x00E9;&#x00A0;David Mart&#x00ED;n-Guerrero, and Paulo&#x00A0;JG Lisboa. 2012. Making machine learning models interpretable.. In <em>      <em>ESANN</em>     </em>, Vol.&#x00A0;12. 163&#x2013;172.</li>    <li id="BibPLXBIB0034" label="[34]">S&#x00A0;Vichy&#x00A0;N Vishwanathan, Nicol&#x00A0;N Schraudolph, Risi Kondor, and Karsten&#x00A0;M Borgwardt. 2010. Graph kernels. <em>      <em>JMLR</em>     </em>11(2010), 1201&#x2013;1242.</li>    <li id="BibPLXBIB0035" label="[35]">Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural deep network embedding. In <em>      <em>SIGKDD</em>     </em>. 1225&#x2013;1234.</li>    <li id="BibPLXBIB0036" label="[36]">Jason Weston, Fr&#x00E9;d&#x00E9;ric Ratle, and Ronan Collobert. 2008. Deep learning via semi-supervised embedding. In <em>      <em>ICML</em>     </em>. 1168&#x2013;1175.</li>    <li id="BibPLXBIB0037" label="[37]">Linchuan Xu, Xiaokai Wei, Jiannong Cao, and Philip&#x00A0;S Yu. 2017. Embedding of Embedding (EOE): Joint Embedding for Coupled Heterogeneous Networks. In <em>      <em>WSDM</em>     </em>. ACM, 741&#x2013;749.</li>    <li id="BibPLXBIB0038" label="[38]">Zhilin Yang, William&#x00A0;W Cohen, and Ruslan Salakhutdinov. 2016. Revisiting semi-supervised learning with graph embeddings. <em>      <em>arXiv preprint arXiv:1603.08861</em>     </em>(2016).</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>This manuscript first appeared in April 2017 as R. Rossi&#x00A0;<em>et al.</em>, &#x201C;Deep Feature Learning for Graphs&#x201D;&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"    href="#BibPLXBIB0030">30</a>].</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a>The terms transfer learning and inductive learning are used interchangeably.</p>   <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a>Note a deep learning method as defined by Bengio&#x00A0;<em>et al.</em> &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"    href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"    href="#BibPLXBIB0008">8</a>] is one that learns multiple levels of representation with higher levels capturing more abstract concepts through a deeper composition of computations&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"    href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"    href="#BibPLXBIB0017">17</a>]. This definition includes neural network based approaches as well as DeepGL and many other deep learning paradigms.</p>   <p id="fn4"><a href="#foot-fn4"><sup>3</sup></a>For convenience, DeepGL-edge and DeepGL-node are sometimes used to refer to the edge and node representation learning variants of DeepGL, respectively.</p>   <p id="fn5"><a href="#foot-fn5"><sup>4</sup></a>The term <em>graph feature</em> refers to an edge or node feature.</p>   <p id="fn6"><a href="#foot-fn6"><sup>5</sup></a>The terms graph function and relational function are used interchangeably.</p>   <p id="fn7"><a href="#foot-fn7"><sup>6</sup></a>For simplicity, we use <em>&#x03A6;</em>&#x27E8;x&#x27E9; (whenever clear from context) to refer to the application of <em>&#x03A6;</em> to all sets <em>S</em> derived from each graph element <span class="inline-equation"><span class="tex">$g_i \in \mathcal {G}$</span>    </span> and thus the output of <em>&#x03A6;</em>&#x27E8;x&#x27E9; in this case is a feature vector with a single feature-value for each graph element.</p>   <p id="fn8"><a href="#foot-fn8"><sup>7</sup></a>See <a class="link-inline force-break" href="http://networkrepository.com/">http://networkrepository.com/</a> for data description and statistics</p>   <p id="fn9"><a href="#foot-fn9"><sup>8</sup></a>Note x<sup>&#x25CB;2</sup> is the element-wise Hadamard power; x<sub>    <em>i</em>    </sub>&#x2299;&#x2009;x<sub>    <em>j</em>    </sub> is the element-wise product.</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International (CC-BY-NC-ND&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY-NC-ND&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3191524">https://doi.org/10.1145/3184558.3191524</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
