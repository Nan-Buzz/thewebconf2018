<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>On the Causal Effect of Badges</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
<link rel="cite-as" href="https://doi.org/10.1145/3178876.3186147"/></head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186147'>https://doi.org/10.1145/3178876.3186147</a>.
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186147'>https://w3id.org/oa/10.1145/3178876.3186147</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">On the Causal Effect of Badges</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Tomasz</span> <span class="surName">Kuśmierczyk</span>, Norwegian University of Science and Technology, <a href="mailto:tomaszku@ntnu.no">tomaszku@ntnu.no</a>
        </div>
        <div class="author">
          <span class="givenName">Manuel</span> <span class="surName">Gomez-Rodriguez</span>, Max Planck Institute for Software Systems, <a href="mailto:manuelgr@mpi-sws.org">manuelgr@mpi-sws.org</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/doi.org/10.1145/3178876.3186147" target="_blank">https://doi.org/doi.org/10.1145/3178876.3186147</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>A wide variety of online platforms use digital badges to encourage users to take certain types of <em>desirable</em> actions. However, despite their growing popularity, their <em>causal effect</em> on users’ behavior is not well understood. This is partly due to the lack of counterfactual data and the myriad of complex factors that influence users’ behavior over time. As a consequence, their design and deployment lacks general principles.</small></p>
        <p><small>In this paper, we focus on first-time badges, which are awarded after a user takes a particular type of action for the first time, and study their causal effect by harnessing the delayed introduction of several badges in a popular Q&amp;A website. In doing so, we introduce a novel causal inference framework for first-time badges whose main technical innovations are a robust survival-based hypothesis testing procedure, which controls for the heterogeneity in the benefit users obtain from taking an action, and a bootstrap difference-in-differences method, which controls for the random fluctuations in users’ behavior over time. Our results suggest that first-time badges steer users’ behavior if the initial benefit a user obtains from taking the corresponding action is sufficiently low, otherwise, we do not find significant effects. Moreover, for badges that successfully steered user behavior, we perform a counterfactual analysis and show that they significantly improved the functioning of the site at a community level.</small></p>
      </div>
      <div class="classifications">
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Tomasz Kuśmierczyk and Manuel Gomez-Rodriguez. 2018. On the Causal Effect of Badges. In <em>WWW 2018: The 2018 Web Conference,</em> <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New York, NY, USA</em> 10 Pages. <a href="https://doi.org/doi.org/10.1145/3178876.3186147" class="link-inline force-break" target="_blank">https://doi.org/doi.org/10.1145/3178876.3186147</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <p>In recent years, social media sites and online communities have increasingly relied on digital badges to reward their users for different types of online behavior. Similarly as their physical counterpart, digital badges have been used both as a reputation mechanism, summarizing the skills and accomplishments of the users who receive them, and as an <em>incentive</em> mechanism, encouraging users to take certain type of <em>desirable</em> actions. The promise of digital badges is that automated fine-grained monitoring and greater degree of control will help refine their design as incentive mechanisms, increasing users’ engagement and improving the functioning of the corresponding online platform. However, to fulfill this promise, it is necessary to better understand their causal effect on the online behavior of the users who may receive them—identify <em>when</em> and <em>why</em> they are (not) able to steer their behavior.</p>
      <p>In this paper, we focus on first-time badges, which are awarded after a user takes a particular type of action for the first time. First-time badges are the simplest type of the highly popular threshold badges [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0035">35</a>], which are awarded after a user has taken an action a pre-specified number of times. More specifically, we study the causal effect induced by first-time badges by harnessing several <em>natural experiments</em> in Stack Overflow<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>, a popular Q&amp;A website, consisting of the <em>delayed</em> introduction of a badge some time after the site's inception. Despite their simplicity, we need to tackle several challenges, which require careful reasoning:</p>
      <p><em>— Measuring progress towards the badge:</em> since first-time badges are awarded after performing just one single action, the action count does not provide a direct measure of progress towards the badge. This is in contrast with (non-binary) threshold badges, which were typically the focus of previous work [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0035">35</a>].</p>
      <p><em>— Utility heterogeneity:</em> the benefit (or <em>utility</em>) each user obtains from taking an action differs wildly due to, <em>e.g.</em>, user's intrinsic motivation, the target of the action, or other users’ actions. As a consequence, the times users take to perform an action for the first time spans a large range of values.</p>
      <p><em>— Random temporal changes:</em> one can frequently observe random fluctuations in users’ behavior over time due to many different complex factors. As a consequence, to assess the strength of the causal effect induced by a badge, it is necessary to control for these random fluctuations.</p>
      <p>We address the above mentioned challenges by developing a novel causal inference framework for first-time badges, especially designed for our problem setting. Our framework avoids modeling the mechanisms underlying individual user actions and instead adopts a data-driven approach based on survival analysis and statistical hypothesis testing. At the heart of our approach there are two technical innovations: (i) a robust survival-based hypothesis testing procedure, which allows us to account for the utility heterogeneity, and (ii) a <em>bootstrap difference-in-differences</em> method, inspired by the economics literature on natural experiments [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0031">31</a>], which allows us to control for the random fluctuations in users’ behavior over time. Moreover, while our framework focuses on first-time badges, we argue that our methodological innovations will also shed light on more complex badges, <em>e.g.</em>, non-binary threshold badges.</p>
      <p>In contrast with recent empirical studies on threshold badges [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0035">35</a>], which typically assume or conclude that, to some degree, badges always steer users’ behavior, we do not find statistically significant evidence to back up this conclusion in all the first-time badges we considered. Instead, we provide empirical evidence of a more subtle picture. In particular, our results suggest that first-time badges steer users’ behavior if the utility a user obtains from taking the corresponding action is sufficiently low, otherwise, the badge does not seem to have a significant effect. Moreover, we hypothesize that this may be also the case for non-binary threshold badges and thus argue that the user utilities should be carefully considered on the design and deployment of badges. Finally, for badges that successfully steered user behavior, we go a step further and, using a survival-based counterfactual analysis, show that they significantly improve the functioning of the site at a community level.</p>
      <p><strong>Related work.</strong> Our work contributes to the growing literature on badges [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0035">35</a>], which can be broadly divided into theoretical and empirical studies.</p>
      <p>Theoretical studies on badges [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0035">35</a>] analyze the effect of badges on users’ behavior under stylized models of badges, which make strong assumptions, often without empirical support. Moreover, they typically ignore the inherent utility a user receives from taking the action the badge rewards—the action payoff and cost. In contrast, in our work, we avoid making strong assumptions about the mechanisms underlying individual user actions and instead adopt a data-driven approach, which enable us to account for the utility a user obtains from taking an action.</p>
      <p>Empirical studies on badges [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>] have mainly focused on threshold badges, where the action count provides a direct measure of progress towards the badge. In this context, several authors [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>] have provided empirical evidence in favor of the <em>goal-gradient hypothesis</em>, which posits users increase their engagement as they get closer to earning a badge, while other authors [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>] found that degree of success of a badge may depend on different complex factors. However, most of these studies did not have access to control groups, which would have allowed them to assess users’ behavior in the absence of a badge and control for random fluctuations in users’ behavior over time. A notable exception is by Bornfeld et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>], which has been concurrently and independently conducted with our work, and it also leverages natural experiments in the context of badges. However, in contrast to our work, they rely on standard statistical tests on aggregated counts, account for the temporal fluctuations in users’ behavior in an ad-hoc manner, and ignore the utility heterogeneity across users.</p>
      <p>Moreover, badges can be viewed as a <em>gamification</em> mechanism, <em>i.e.</em>, a mechanism in which game-design elements are used in a non-gaming environment to encourage users to perform certain tasks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0032">32</a>]. Therefore, our research adds up to the existing studies on practical implications of gamification for, <em>e.g.</em>, increasing user engagement in learning [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] and e-learning [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>], shaping healthy behavioral patterns [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0024">24</a>], systems design [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>] or crowdsourcing [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>].</p>
      <p>Finally, natural experiments [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0031">31</a>], difference-in-difference designs [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>] and propensity score matching [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0033">33</a>] have been increasingly used to identify causal effects from observational data in online settings, <em>e.g.</em>, social influence [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0022">22</a>] or network formation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0030">30</a>]. However, together with Bornfeld et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>], the present work is one of the first that leverage natural experiments to quantify causal effects in the context of badges.</p>
    </section>
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Data description</h2>
        </div>
      </header>
      <p>Our Stack Overflow dataset<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a> comprises of all individual timestamped actions performed by all users from the site's inception from July 31, 2008 to September 14, 2014, which allow us to track the complete sequence of actions users take.</p>
      <p><strong>First-time badges: natural experiments.</strong> There are a great variety of badges, which reward users for different types of behaviors. In this work, we focus on <em>first-time</em> badges, which are awarded after a user takes a particular type of action for the first time, and identify those that were introduced some time after the site's inception. The <em>delayed</em> introduction of these badges can be thought of as <em>natural experiments</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0031">31</a>], where the treatment of earning a badge is assigned <em>as if random</em> among users. Figure <a class="fig" href="#fig1">1</a> illustrates an example of such badge.</p>
      <figure id="fig1">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186147/images/www2018-156-fig1.jpg" class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class="figure-title">Time when users first edited a tag wiki (user action time, <em>t</em>) against time when they became eligible to edit tag wikis (user start time, <em>s</em>). The horizontal black line denotes the time when the <tt>Tag editor</tt> badge was introduced, which is awarded after a user edits a tag wiki for the first time.</span>
        </div>
      </figure>
      <p></p>
      <p>More specifically, we select three first-time badges that reward actions whose utilities to the users are clearly different:</p>
      <p><em>— <tt>Tag Editor</tt>badge:</em> Stack Overflow users can include tags on questions (or answers) to concisely describe their content. In July 2010, Stack Overflow enabled the creation of tag wikis by the community, which aim to provide a description of all used tags. Shortly afterwards, it introduced a badge called <tt>Tag Editor</tt>, awarded after a user edits a tag wiki for the first time, to encourage users to edit tag wikis. To ensure the quality of the wiki tags, only users with at least a reputation level of 1, 500 could (initially) edit a tag wiki<a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>. Finally, note that a user obtains a <em>low</em> utility from editing a wiki tag—it requires some effort and she only receives the <em>intangible</em> reward of helping the community. Moreover, the more uncommon a tag is, the least this intangible reward may be since she will help a smaller part of the community.</p>
      <p><em>— <tt>Promoter</tt>badge:</em> When a Stack Overflow user does not receive a satisfactory answer to one of her questions, she can offer a <em>bounty</em> to reward, in the form of reputation points, the user who would provide such a satisfactory answer<a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a>. In July 2010, Stack Overflow introduced a badge called <tt>Promoter</tt>, awarded after a user offers a bounty for an answer to one of her questions for the first time, to encourage users to offer more bounties. Only users with at least a reputation of 75 points can offer a bounty. In contrast with editing a wiki tag, a user obtains a <em>high</em> utility from offering a bounty—it requires little effort and she may receive an answer to a question she is personally interested in, however, it entails a cost in terms of the reputation she transfers to the user providing the answer.</p>
      <p><em>— <tt>Investor</tt>badge:</em> Stack Overflow users can also offer bounties to receive a satisfactory answer to a question that has been asked by another user. In July 2010, Stack Overflow introduced a first-time badge called <tt>Investor</tt> to encourage users to offer more bounties for answers to other users’ questions. Similarly as in the <tt>Promoter</tt> badge, only users with at least a reputation of 75 points can offer a bounty for an answer to a question asked by another user. However, in this case, a user may obtain a <em>lower</em> utility from offering a bounty for an answer to another user's question than her own—on the one hand, she may be less interested in an answer since she did not originally ask the question and, on the other hand, the question may have already a (relatively) satisfactory answer when she found it.</p>
      <p>Table <a class="tbl" href="#tab1">1</a> provides general statistics on the number of eligible users and user actions in our dataset.</p>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class="table-title">General statistics on the number of users and actions in our dataset. The time when a badge is introduced is denoted by <em>τ</em>, the time when a user becomes eligible to perform an action is denoted by <em>s<sub>u</sub></em> and the time when a user performs the action is denoted by <em>t<sub>u</sub></em>.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:left;"></th>
              <th style="text-align:center;">Tag Editor<sup>*</sup></th>
              <th style="text-align:center;">Investor</th>
              <th>Promoter</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:left;">Required reputation</td>
              <td style="text-align:center;">1, 500</td>
              <td style="text-align:center;">75</td>
              <td>75</td>
            </tr>
            <tr>
              <td style="text-align:left;">Eligible users, <em>s<sub>u</sub></em> &lt; <em>τ</em></td>
              <td style="text-align:center;">6, 396</td>
              <td style="text-align:center;">46, 148</td>
              <td>46, 148</td>
            </tr>
            <tr>
              <td style="text-align:left;">Actions, <em>t<sub>u</sub></em> &lt; <em>τ</em></td>
              <td style="text-align:center;">93</td>
              <td style="text-align:center;">4, 984</td>
              <td>205</td>
            </tr>
            <tr>
              <td style="text-align:left;">Eligible users, <em>s<sub>u</sub></em> ≥ <em>τ</em></td>
              <td style="text-align:center;">2, 095</td>
              <td style="text-align:center;">297, 481</td>
              <td>297, 481</td>
            </tr>
            <tr>
              <td style="text-align:left;">Actions, <em>t<sub>u</sub></em> ≥ <em>τ</em></td>
              <td style="text-align:center;">471</td>
              <td style="text-align:center;">30, 396</td>
              <td>7, 830</td>
            </tr>
          </tbody>
          <tfoot>
            <tr>
              <td colspan="4"><sup>*</sup>For <tt>Tag Editor</tt> badge we present statistic only until 2011-02-09 when the required reputation changed.</td>
              <td></td>
            </tr>
          </tfoot>
        </table>
      </div>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Testing the effectiveness of first-time badges</h2>
        </div>
      </header>
      <p>In this section, we first formalize the problem setting, which includes at its core a natural experiment. Then, we introduce our causal inference framework for first-time badges, discussing the assumptions it requires and elaborating on its individual components. Finally, we evaluate its effectiveness using a variety of synthetic experiments and conclude with a discussion of its limitations.</p>
      <p><strong>Problem setting.</strong> Given an action of interest <em>a</em>, we record the behavior of each user during an observation window [0, <em>T</em>] as a tuple</p>
      <div class="table-responsive" id="Xeq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} e := \begin{array}{c@{\hspace*{-30pt}}c@{\hspace*{-30pt}}c} \text{start time}&amp;&amp;\text{utility}\\ \downarrow &amp; &amp; \downarrow\\ (s_u, &amp; t_u, &amp;\color{gray}{v_u}),\\ &amp; \uparrow&amp;\\ &amp;\text{action time}\end{array} \end{equation}</span><br />
          <span class="equation-number">(1)</span>
        </div>
      </div>which means that user <em>u</em> becomes eligible<a class="fn" href="#fn5" id="foot-fn5"><sup>5</sup></a> to perform the action at time <em>s<sub>u</sub></em> , she performs the action at time <em>t<sub>u</sub></em> , with <em>t<sub>u</sub></em> ≥ <em>s<sub>u</sub></em> , and obtains a utility <em>v<sub>u</sub></em> , which is often intangible. If a user does not perform the action during the observation window [0, <em>T</em>], we set the action time to <em>t<sub>u</sub></em> = ∞, however, this does not imply she will never perform the action. Moreover, we assume a first-time badge <em>b</em> is introduced at time <em>τ</em> ∈ (0, <em>T</em>] to incentivize users to take action <em>a</em>. That means, after time <em>τ</em>, a user receives badge <em>b</em> the first time she takes action <em>a</em>, potentially <em>increasing</em> its corresponding utility <em>v<sub>u</sub></em>. Here, the <em>delayed</em> introduction of badge <em>b</em> at time <em>τ</em> can be thought of as a natural experiment [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0031">31</a>], where the treatment of earning a badge is assigned <em>as if random</em> among users who are eligible to perform an action. Note that users who performed action <em>a</em> before the badge introduction time <em>τ</em> receive the badge automatically at <em>τ</em>, however, this does not influence our analysis since our focus is on the potential effect that first-time badges may have on the first time users take the action, and not on subsequent times.
      <p></p>
      <p>Given the above setup, our goal is then to assess to which extent the introduction of the badge <em>changes</em> users’ behavior, as measured by the time users take to perform the action for the first time, <em>i.e.</em>, <em>t<sub>u</sub></em> − <em>s<sub>u</sub></em>. Next, we present a high-level overview of our causal inference framework, highlighting the assumption it requires, and then elaborate on its individual components.</p>
      <p><strong>Our causal inference framework.</strong> Given an action of interest <em>a</em>, its corresponding first-time badge <em>b</em> with introduction time <em>τ</em>, the behavior of <em>n</em> users with respect to <em>a</em>, <em>i.e.</em>, <span class="inline-equation"><span class="tex">$\mathcal {D}_a = \lbrace (s_u, t_u, v_u) \rbrace _{u \in [n]}$</span></span> , one could just consider the set of users who performed the action for the first time before the badge introduction, <em>i.e.</em>, <em>t<sub>u</sub></em> &lt; <em>τ</em>, as control group, and the set of users who became eligible to perform the action after the badge introduction, <em>i.e.</em>, <em>τ</em> &lt; <em>s<sub>u</sub></em> , as treatment group. However, proceeding that way would have several limitations. First, a potential difference among the treatment and control groups could be due to random fluctuations in users’ behavior over time due to many complex, confounding factors. Second, one would be unable to consider users who became eligible before the badge introduction but performed the action for the first time after the badge introduction. These users are the ones who were actually exposed to the badge introduction.</p>
      <p>Our causal inference framework overcomes the above limitations by redefining the treatment and control groups as follows. We define the treatment group as the set of users who became eligible to perform the action at a time <em>s<sub>u</sub></em> ∈ [<em>τ</em> − <em>w</em>/2, <em>τ</em> + <em>w</em>/2], where <em>w</em> ≥ 0 is a given parameter. We define several control groups, each of them associated to a <em>virtual</em> badge <em>b<sub>i</sub></em> introduced at time <em>τ<sub>i</sub></em> ∈ [<em>w</em>/2, <em>τ</em> − <em>w</em>]∪[<em>τ</em> + <em>w</em>, <em>T</em> − <em>w</em>/2], picked uniformly at random. Under these definitions, the treatment group represents the <em>true world</em> where the badge is introduced and the control groups represent different <em>counterfactual worlds</em> where a virtual badge, which models random fluctuation in users’ behavior, is introduced. As long as the allocation of users across the treatment and control groups resemble random assignment, if the strength of the change induced by the badge in the true world (as measured by survival-based hypothesis testing) is larger than the strength of the changes induced by the virtual badges in a variety of counterfactual worlds, we can conclude that the change in the true world is not due to random fluctuation in users’ behavior with higher confidence.</p>
      <p>Next, we elaborate on two survival-based hypothesis testing procedures of increasing statistical power, which we use to measure the strength of the change induced by a (true or virtual) badge, and then describe how to formally compare the strength of the changes induced by the true and the virtual badges by means of a novel bootstrap difference in differences method.</p>
      <p><em>— Basic survival-based hypothesis testing:</em> Given an action of interest <em>a</em>, we model the time <em>t<sub>u</sub></em> when a user <em>u</em> takes action <em>a</em> using a survival process [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>]. Following the literature on temporal point processes, we represent such survival process as a binary counting process <em>N<sub>u</sub></em> (<em>t</em>) ∈ {0, 1}, which becomes one when the user performs the action for the first time. Then, we characterize this counting process using its corresponding intensity <em>λ<sub>u</sub></em> (<em>t</em>), <em>i.e.</em>, <span class="inline-equation"><span class="tex">$\mathbb {E}[dN_u(t)] = \lambda _u(t) dt$</span></span> , which we define as follows:</p>
      <div class="table-responsive" id="eq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \lambda _u(t) = {\left\lbrace \begin{array}{@{}l@{\quad }l@{}}0 &amp; \text{if}\enspace t {\lt} s_u \\ {\lambda _0} &amp; \text{if}\enspace s_u \le t {\lt} \tau \\ {\lambda _1} &amp; \text{otherwise} \end{array}\right.} \end{equation}</span><br />
          <span class="equation-number">(2)</span>
        </div>
      </div>where <em>s<sub>u</sub></em> is the time when user <em>u</em> becomes eligible to perform action <em>a</em>, <em>τ</em> is the time when the first-time badge is introduced, and <em>λ</em> <sub>0</sub> and <em>λ</em> <sub>1</sub> are parameters shared across all users, which depend on the (intangible) utility users obtain from taking the action for the first time before and after the badge introduction, respectively.
      <p></p>
      <p>Under this model, the null hypothesis <span class="inline-equation"><span class="tex">$\mathcal {H}_0$</span></span> , <em>i.e.</em>, the badge did not have an effect, corresponds to <em>λ</em> <sub>0</sub> = <em>λ</em> <sub>1</sub> ≥ 0 and the alternative hypothesis <span class="inline-equation"><span class="tex">$\mathcal {H}_1$</span></span> is <em>λ</em> <sub>0</sub> ≠ <em>λ</em> <sub>1</sub> with <em>λ</em> <sub>0</sub> ≥ 0 and <em>λ</em> <sub>1</sub> ≥ 0. Moreover, given the behavior of <em>n</em> users, the maximum likelihood estimators of the model parameters, <span class="inline-equation"><span class="tex">$\hat{\lambda }_0$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\lambda }_1$</span></span> , can be computed analytically. In particular, under the null hypothesis, they are readily given by:</p>
      <div class="table-responsive" id="eq2">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \hat{\lambda }_0 = \hat{\lambda }_1 = \frac{\sum _{u \in [n]} \mathbb {I}(t_u \le T)}{\sum _{u \in [n]} (\min (t_u, T) - s_u)}, \end{equation}</span><br />
          <span class="equation-number">(3)</span>
        </div>
      </div>and under the alternative hypothesis, they are given by:
      <div class="table-responsive" id="eq3">
        <div class="display-equation">
          <span class="tex mytex">\begin{align} \hat{\lambda }_0 &amp;= \frac{\sum _{u \in [n]} \mathbb {I}(t_u \le \tau)}{\sum _{u \in [n]} (\min (t_u, \tau) - s_u) \mathbb {I}(s_u {\lt} \tau)} \nonumber \\\hat{\lambda }_1 &amp;= \frac{\sum _{u \in [n]} \mathbb {I}(\tau {\lt} t_u \le T)}{\sum _{u \in [n]} (\min (t_u, T) - \tau) \mathbb {I}(t_u {\gt} \tau)}, \end{align}</span><br />
          <span class="equation-number">(4)</span>
        </div>
      </div>where <span class="inline-equation"><span class="tex">$\mathbb {I}(\cdot)$</span></span> is the indicator function and all the sums are over eligible users. Then, we can use a test statistic such as standard log-likelihood ratio (<em>LLR</em>) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>] to measure the strength of the change induced by the badge, <em>i.e.</em>,
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\begin{align*} LLR &amp;= \sum _{u \in [n] : t_u {\lt} T} \log f(s_u, t_u ; \hat{\lambda }_0, \hat{\lambda }_1) - \log f(s_u, t_u ; \hat{\lambda }_0) \\ &amp;+ \sum _{u \in [n] : t_u = \infty } \log S(s_u, T ; \hat{\lambda }_0, \hat{\lambda }_1) - \log S(s_u, T ; \hat{\lambda }_0)\end{align*}</span><br />
        </div>
      </div>where <span class="inline-equation"><span class="tex">$f(s_u, t_u ; \hat{\lambda }_0)$</span></span> and <span class="inline-equation"><span class="tex">$f(s_u, t_u; \hat{\lambda }_0, \hat{\lambda }_1)$</span></span> are the likelihoods of the action times under the null and alternative model, respectively, and <span class="inline-equation"><span class="tex">$S(s_u, T ; \hat{\lambda }_0, \hat{\lambda }_1)$</span></span> and <span class="inline-equation"><span class="tex">$S(s_u, T ; \hat{\lambda }_0)$</span></span> are the corresponding survival functions. Here, the likelihoods and survivals can be computed using the intensity <em>λ<sub>u</sub></em> (<em>t</em>) defined by Eq. <a class="eqn" href="#eq1">2</a>, with <em>λ</em> <sub>0</sub> = <em>λ</em> <sub>1</sub> for the null model and <em>λ</em> <sub>0</sub> ≠ <em>λ</em> <sub>1</sub> for the alternative model, as noted elsewhere [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>].
      <p></p>
      <p><em>— Robust survival-based hypothesis testing:</em> The basic survival-based hypothesis testing procedure described above assumes the model parameters are shared across all users and, by doing so, it ignores the utility heterogeneity across users. Here, we account for the utility heterogeneity by considering different latent parameters per user, but sampled from the same distributions, <em>i.e.</em>,</p>
      <div class="table-responsive" id="eq4">
        <div class="display-equation">
          <span class="tex mytex">\begin{align} \lambda _u(t) &amp;= {\left\lbrace \begin{array}{@{}l@{\quad }l@{}}0 &amp; \text{if}\enspace t {\lt} s_u \\ {\lambda _0(u)} &amp; \text{if}\enspace s_u \le t {\lt} \tau \\ {\lambda _1(u)} &amp; \text{otherwise} \end{array}\right.} \nonumber \\\lambda _0(u) &amp;\sim \mbox{Gamma}(k_0, r) \nonumber \\\lambda _1(u) &amp;\sim \mbox{Gamma}(k_1, r) \end{align}</span><br />
          <span class="equation-number">(5)</span>
        </div>
      </div>where <em>s<sub>u</sub></em> is the time when user <em>u</em> becomes eligible to perform action <em>a</em>, <em>τ</em> is the time when the first-time badge is introduced, <em>k</em> <sub>0</sub>, <em>k</em> <sub>1</sub> are shape parameters and <em>r</em> is a rate parameter. Here, note that <span class="inline-equation"><span class="tex">$\mathbb {E}[\lambda _0] = k_0 / r$</span></span> and <span class="inline-equation"><span class="tex">$\mathbb {E}[\lambda _1] = k_1 / r$</span></span> .
      <p></p>
      <p>Then, we define the null and alternative hypothesis in terms of the shape parameters, <em>i.e.</em>,</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\begin{align*} \mathcal {H}_0 &amp; \,:\, k_0 = k_1 \ge 0 \\\mathcal {H}_1 &amp; \,:\, k_0 \ne k_1, k_0 \ge 0, k_1 \ge 0\end{align*}</span><br />
        </div>
      </div>Moreover, given the behavior of <em>n</em> users, we can estimate the shape parameters using maximum likelihood estimation, integrating out the latent parameters <em>λ</em> <sub>0</sub>(<em>u</em>) and <em>λ</em> <sub>1</sub>(<em>u</em>), and estimate the rate parameter by cross validation. More specifically, under the null hypothesis, the shape parameters are given by:
      <div class="table-responsive" id="eq5">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \hat{k}_0 = \hat{k}_1 = -\frac{\sum _{u \in [n]} \mathbb {I}(t_u \le T)}{ \sum _{u \in [n]} \log \left(\frac{r}{r+\min (t_u, T) - s_u} \right) } \end{equation}</span><br />
          <span class="equation-number">(6)</span>
        </div>
      </div>and under the alternative hypothesis, they are given by:
      <div class="table-responsive" id="eq6">
        <div class="display-equation">
          <span class="tex mytex">\begin{align} \hat{k}_0 &amp;= -\frac{\sum _{u \in [n]} \mathbb {I}(t_u \le \tau)}{ \sum _{u \in [n]} \log \left(\frac{r}{r+\min (t_u, \tau) - s_u}\right) \mathbb {I}(s_u \le \tau) } \nonumber \\\hat{k}_1 &amp;= - \frac{\sum _{u \in [n]} \mathbb {I}(\tau {\lt} t_u \le T)}{\sum _{u \in [n]} \log \left(\frac{r}{r+\min (t_u, T) - \tau }\right) \mathbb {I}(t_u {\gt} \tau) } \end{align}</span><br />
          <span class="equation-number">(7)</span>
        </div>
      </div>
      <p></p>
      <p>Similarly as in the basic survival model, we can then use a test statistic such as standard log-likelihood ratio (<em>LLR</em>) to measure the strength of the change induced by the badge.</p>
      <figure id="fig2">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186147/images/www2018-156-fig2.jpg" class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class="figure-title">Our bootstrap difference-in-difference method. The treatment group (left) consists of users whose start time <em>s<sub>u</sub></em> lies in a window of size <em>w</em> around the time <em>τ</em> the badge is introduced. Each control group <em>i</em> (right) consists of users whose start time <em>s<sub>u</sub></em> lies in a window of size <em>w</em> around the time <em>τ<sub>i</sub></em> a virtual badge is introduced. The method runs hypothesis testing on both the treatment group and all control groups and then compares the test statistic (<em>e.g.</em>, LLR) of the treatment group with the empirical distribution of the test statistic of the control groups.</span>
        </div>
      </figure><em>— Bootstrap difference-in-differences method:</em> Given an action of interest <em>a</em>, its corresponding first-time badge <em>b</em> with introduction time <em>τ</em>, the behavior of <em>n</em> users with respect to <em>a</em>, <em>i.e.</em>, <span class="inline-equation"><span class="tex">$\mathcal {D}_a = \lbrace (s_u, t_u, v_u) \rbrace _{u \in [n]}$</span></span> , and a model-based hypothesis testing procedure as the ones described above, we assess the significance of the change induced by the true badge using the following bootstrap difference-in-difference method:
      <p></p>
      <ul class="list-no-style">
        <li id="uid17" label="I.">We select all users whose start time <em>s<sub>u</sub></em> ∈ [<em>τ</em> − <em>w</em>/2, <em>τ</em> + <em>w</em>/2], where <em>w</em> ≥ 0 is a given parameter, as treatment group. Then, we compute the maximum likelihood estimators of the parameters of the model of choice using Eqs. <a class="eqn" href="#eq2">3</a>-<a class="eqn" href="#eq3">4</a> (basic) or Eqs. <a class="eqn" href="#eq5">6</a>-<a class="eqn" href="#eq6">7</a> (robust) on that subset of users and use these estimated parameters to compute the log-likelihood ratio, <em>LLR</em>.<br />
        </li>
        <li id="uid18" label="II.">We introduce a set of virtual badges <span class="inline-equation"><span class="tex">$\mathcal {V}$</span></span> at a times <em>τ<sub>i</sub></em> ∈ [<em>w</em>/2, <em>τ</em> − <em>w</em>]∪[<em>τ</em> + <em>w</em>, <em>T</em> − <em>w</em>/2], picked uniformly at random (in practice, one can use a sliding window), where <em>w</em> ≥ 0 is the same given parameter as in the first step. Then, for each virtual badge <span class="inline-equation"><span class="tex">$i \in \mathcal {V}$</span></span> , we select users whose start time <em>s<sub>u</sub></em> ∈ [<em>τ<sub>i</sub></em> − <em>w</em>/2, <em>τ<sub>i</sub></em> + <em>w</em>/2] as control group <em>i</em>. Finally, we compute the maximum likelihood estimators of the parameters of the model of choice, as in the previous step, on each of these subsets of users and use these estimated parameters to compute the log-likelihood ratio for each control group, <span class="inline-equation"><span class="tex">$LLR_{\tau _i}$</span></span> .<br /></li>
        <li id="uid19" label="III.">We measure the strength of the change induced by the badge by means of the probability that the LLR of the control groups, for which the null hypothesis holds by design since virtual badges do not exist, is larger than the LLR of the treatment group, <em>p</em> ≔ <em>F<sub>LLR</sub></em> (<em>LLR<sub>τ</sub></em> ).<br /></li>
      </ul>
      <p>The above bootstrap difference-in-differences method, which we also illustrate in Figure <a class="fig" href="#fig2">2</a>, equips us with a robust empirical estimate of the distribution of the LLR under the null hypothesis <em>F<sub>LLR</sub></em> (<em>LLR</em>) and a <em>p</em>-value <em>p</em> = <em>F<sub>LLR</sub></em> (<em>LLR<sub>τ</sub></em> ), which accounts for the temporal fluctuations in users’ behavior and allows us to reject the null hypothesis with higher confidence. Finally, as discussed previously, the main assumption needed for the above method to be valid is that the allocation of users across the treatment and control groups resemble random assignment. Table <a class="tbl" href="#tab2">2</a> shows this assumption is satisfied in our dataset, as we will discuss later.</p>
      <figure id="fig3">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186147/images/www2018-156-fig3.jpg" class="img-responsive" alt="Figure 3" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 3:</span> <span class="figure-title">Performance of our causal inference framework on synthetic data. The left panel shows the average <em>p</em>-value against expected effect strength <span class="inline-equation"><span class="tex">$\mathbb {E}[\Delta P]$</span></span> , where lower (higher) is better for <span class="inline-equation"><span class="tex">$\mathbb {E}[\Delta P] {\gt} 0$</span></span> (<span class="inline-equation"><span class="tex">$\mathbb {E}[\Delta P] \approx 0$</span></span> ). The right panel informs about tests’ statistical power by showing the rejection probability of the null hypothesis <span class="inline-equation"><span class="tex">$\mathcal {H}_0$</span></span> at <em>p</em> = 0.05 against effect strength <span class="inline-equation"><span class="tex">$\mathbb {E}[\Delta P]$</span></span> , where higher (lower) is better for <span class="inline-equation"><span class="tex">$\mathbb {E}[\Delta P] {\gt} 0$</span></span> (<span class="inline-equation"><span class="tex">$\mathbb {E}[\Delta P] \approx 0$</span></span> ).</span>
        </div>
      </figure><strong>Framework evaluation.</strong> In this section, we compare the effectiveness of the basic survival model with the theoretical distribution of the LLR under the null hypothesis (<span class="inline-equation"><span class="tex">$\chi _1^2$</span></span> , given by Wilks’ theorem [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0034">34</a>]; “basic theoretical”) and the basic and robust survival models with the empirical distribution (<em>F<sub>LLR</sub></em> ) of the LLR under the null hypothesis, as estimated by the proposed difference-in-differences bootstrap method (“basic bootstrap” and “robust bootstrap”, respectively). More specifically, we proceed as follows.
      <p></p>
      <p>First, we simulate the behavior of <em>n</em> = 10, 000 users during a time interval [0, <em>T</em>], where <em>T</em> = 360. For each user, we draw her starting times <em>s<sub>u</sub></em> ∼ <em>U</em>[0, <em>T</em>], and her action time <em>t</em> from an intensity <em>λ<sub>u</sub></em> (<em>t</em>)(1 + <em>at</em>), where <em>λ<sub>u</sub></em> (<em>t</em>) is given by Eq. <a class="eqn" href="#eq4">5</a> and <em>a</em> = 0.001. Note that the term (1 + <em>at</em>) imposes a global linear trend, which is often observed in real data<a class="fn" href="#fn6" id="foot-fn6"><sup>6</sup></a>. Moreover, in Eq. <a class="eqn" href="#eq4">5</a>, we set the badge introduction time to <em>τ</em> = <em>T</em>/2, the rate parameter to <em>r</em> = 10, and consider different badge strength values expressed as the expected increase in the probability that users perform the action in less than <em>t</em> = 10 after <em>s<sub>u</sub></em> , which we denote as <span class="inline-equation"><span class="tex">$\mathbb {E}[\Delta P]$</span></span> . For each configuration, we run 100 independent simulations.</p>
      <p>Then, we run the above methods (“basic theoretical”, “basic bootstrap”, and “robust bootstrap”) on data from each of the independent simulations and measure their effectiveness in terms of two metrics: average <em>p</em>-value and rejection probability of the null hypothesis <span class="inline-equation"><span class="tex">$\mathcal {H}_0$</span></span> at <em>p</em> = 0.05. Figure <a class="fig" href="#fig3">3</a> summarizes the results, which show that the robust bootstrap has a superior performance: it is more likely to reject <span class="inline-equation"><span class="tex">$\mathcal {H}_0$</span></span> when a badge is introduced (<em>i.e.</em>, <span class="inline-equation"><span class="tex">$\mathbb {E}[\Delta P] {\gt} 0$</span></span> ) while it is equally likely not to reject <span class="inline-equation"><span class="tex">$\mathcal {H}_0$</span></span> when a badge is not introduced (<em>i.e.</em>, <span class="inline-equation"><span class="tex">$\mathbb {E}[\Delta P] \approx 0$</span></span> ).</p>
      <p><strong>Remarks.</strong> We acknowledge that our framework has several limitations. In its current form, the framework is only applicable to first-time badges. In principle, it may be possible to augment our framework to other types of badges. For example, in threshold badges, one could replace the binary counting processes by non binary ones representing the number of actions <em>N</em>(<em>t</em>) (<em>i.e.</em>, progress) and choose a functional form for the intensities depending on the numbers of actions, <em>i.e.</em>, <em>λ</em> <sub>1</sub>(<em>N</em>(<em>t</em>)), as suggested in previous work [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>]. However, one would need to address additional challenges, <em>e.g.</em>, accurate intensity models, and it is out of the scope of this work. Moreover, while our bootstrap difference-in-difference method does control for temporal fluctuations in the users’ behavior, it cannot rule out the possibility that the change in users’ behavior in the treatment group, if deemed significant, may be due to a hidden confounding factor rather than the badge introduction.</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Do badges work?</h2>
        </div>
      </header>
      <p>Before we apply our causal inference framework to the three first-time badges described in Section <a class="sec" href="#sec-4">2</a>, we first check the random assignment assumption between the treatment and control groups, which is necessary for our framework to provide sound conclusions. If the assignment is random, we would expect the groups (respective subpopulations) to be indistinguishable based on any additional covariates. Two groups are called indistinguishable (or balanced) if these additional covariates are within a standardized mean difference (SMD)<a class="fn" href="#fn7" id="foot-fn7"><sup>7</sup></a> of 0.25 standard deviations [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0033">33</a>]. In particular, Table <a class="tbl" href="#tab2">2</a> shows that treatment and control groups are indistinguishable in our dataset. Here, we would like to acknowledge that conclusions drawn from standardized mean differences (SMD) when evaluating variables with skewed distributions, as ours, should be taken with caution.</p>
      <p>Once we have validated the random assignment assumption, we apply our causal framework to the three first-time badges. Figure <a class="fig" href="#fig4">4</a> summarizes the results by means of:</p>
      <ul class="list-no-style">
        <li id="uid23" label="(i)">Test statistic over time for the basic and robust survival models, <em>i.e.</em>, <span class="inline-equation"><span class="tex">$LLR_{\tau _i}$</span></span> and <em>LLR<sub>τ</sub></em> against <em>τ<sub>i</sub></em> and <em>τ</em>.<br /></li>
        <li id="uid24" label="(ii)">Empirical distribution of the test statistic under <span class="inline-equation"><span class="tex">$\mathcal {H}_0$</span></span> and <em>p</em>-value for the robust survival model, <em>i.e.</em>, <em>F<sub>LLR</sub></em> (<em>LLR</em>) and<br />
        <em>F<sub>LLR</sub></em> (<em>LLR<sub>τ</sub></em> ).<br /></li>
        <li id="uid25" label="(iii)">Average intensities for first-time action under robust survival model, <em>i.e.</em>, <span class="inline-equation"><span class="tex">$\hat{k}_0$</span></span> before <em>τ</em> and <span class="inline-equation"><span class="tex">$\hat{k}_1$</span></span> after <em>τ</em>, using a sliding window of length <em>w</em> = 60 days.<br /></li>
      </ul>
      <p>Overall, the results suggest that the <tt>Tag editor</tt> and <tt>Investor</tt> badges were <em>successful</em>—they had a significant causal effect on users’ behavior (<em>p</em> = 0.004 and <em>p</em> = 0.017, respectively). In contrast, the <tt>Promoter</tt> badge was unsuccessful—it did not have a significant causal effect (<em>p</em> = 0.309). Moreover, a detailed analysis also reveals several interesting insights.</p>
      <p>First, the actions rewarded by the two successful badges were rare by the time the badges got introduced. For example, in the case of the <tt>Tag editor</tt> badge, only 100 tag wiki edits had been performed, however, there were ∼ 6, 500 users who were eligible to perform edits. In the case of the <tt>Investor</tt> badge, only 40 bounties had been offered for an answer to other users’ questions. In contrast, the action rewarded by the <tt>Promoter</tt> badge—offering a bounty for an answer to the users’ own questions—was much more common by the time the badge got introduced. As a consequence, the average intensity for the <tt>Promoter</tt> badge was an order of magnitude higher than the intensities corresponding to the <tt>Tag editor</tt> or the <tt>Investor</tt> badge.</p>
      <p>Second, the introduction of the <tt>Tag editor</tt> and <tt>Investor</tt> badges was followed by an increase on the average intensity of the corresponding first-time action of more than 4 × , from <span class="inline-equation"><span class="tex">$\hat{k}_0 \le 2 \cdot 10^{-4}$</span></span> to <span class="inline-equation"><span class="tex">$\hat{k}_1 \approx 8 \cdot 10^{-4}$</span></span> for <tt>Tag editor</tt> badge and from <span class="inline-equation"><span class="tex">$\hat{k}_0 \le 5 \cdot 10^{-5}$</span></span> to <span class="inline-equation"><span class="tex">$\hat{k}_1 \approx 2 \cdot 10^{-4}$</span></span> for <tt>Investor</tt> badge. Equivalently, the average time a user takes to perform the actions for the first time was reduced by 75%. Moreover, this change in user behavior did not vanish over time (rightmost column).</p>
      <p>Finally, in the case of the <em>Investor</em> badge, we find a transient increase on the average intensity of bounties to other users’ questions around October-November 2010, which is statistically significant. Upon investigation, we notice that several users discovered ways of benefiting from offering bounties around that time, triggering subsequent first-time uses of bounties by other users<a class="fn" href="#fn8" id="foot-fn8"><sup>8</sup></a>. Such discussions led to an increase on the minimum reputation one can transfer when offering a bounty.</p>
      <div class="table-responsive" id="tab2">
        <div class="table-caption">
          <span class="table-number">Table 2:</span> <span class="table-title">Absolute Standardized Mean Difference (|SMD|) between the treatment and the control groups.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:left;"></th>
              <th colspan="2" style="text-align:center;">
                <tt>Tag Editor</tt>
                <hr />
              </th>
              <th colspan="2" style="text-align:center;">
                <tt>Prom. &amp; Inv.</tt>
                <hr />
              </th>
            </tr>
            <tr>
              <th style="text-align:left;">feature</th>
              <th style="text-align:center;"><span class="inline-equation"><span class="tex">$\bar{\text{|SMD|}}$</span></span></th>
              <th style="text-align:center;"><em>σ</em> <sub>|SMD|</sub></th>
              <th style="text-align:center;"><span class="inline-equation"><span class="tex">$\bar{\text{|SMD|}}$</span></span></th>
              <th><em>σ</em> <sub>|SMD|</sub></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:left;">age</td>
              <td style="text-align:center;">0.10</td>
              <td style="text-align:center;">0.04</td>
              <td style="text-align:center;">0.14</td>
              <td>0.10</td>
            </tr>
            <tr>
              <td style="text-align:left;">age-NA<sup>*</sup></td>
              <td style="text-align:center;">0.08</td>
              <td style="text-align:center;">0.12</td>
              <td style="text-align:center;">0.17</td>
              <td>0.11</td>
            </tr>
            <tr>
              <td style="text-align:left;">reputation</td>
              <td style="text-align:center;">0.21</td>
              <td style="text-align:center;">0.35</td>
              <td style="text-align:center;">0.14</td>
              <td>0.11</td>
            </tr>
            <tr>
              <td style="text-align:left;">#views</td>
              <td style="text-align:center;">0.16</td>
              <td style="text-align:center;">0.23</td>
              <td style="text-align:center;">0.11</td>
              <td>0.08</td>
            </tr>
            <tr>
              <td style="text-align:left;">#upvotes</td>
              <td style="text-align:center;">0.18</td>
              <td style="text-align:center;">0.28</td>
              <td style="text-align:center;">0.13</td>
              <td>0.10</td>
            </tr>
            <tr>
              <td style="text-align:left;">#downvotes</td>
              <td style="text-align:center;">0.08</td>
              <td style="text-align:center;">0.07</td>
              <td style="text-align:center;">0.03</td>
              <td>0.02</td>
            </tr>
          </tbody>
          <tfoot>
            <tr>
              <td colspan="4"><sup>*</sup>Balance check on a binary variable indicating if the value is missing.</td>
              <td></td>
            </tr>
          </tfoot>
        </table>
      </div>
      <figure id="fig4">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186147/images/www2018-156-fig4.jpg" class="img-responsive" alt="Figure 4" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 4:</span> <span class="figure-title">Causal effect of three badges (<tt>Tag Editor</tt>, <tt>Promoter</tt> and <tt>Investor</tt>) on users’ behavior. Panels in the left show the test statistic (log-likelihood ratio; <em>LLR</em>) over time for the basic and robust survival models, <em>i.e.</em>, <span class="inline-equation"><span class="tex">$LLR_{\tau _i}$</span></span> and <em>LLR<sub>τ</sub></em> against <em>τ<sub>i</sub></em> and <em>τ</em>. Panels in the middle show the empirical distribution of the test statistic (<em>LLR</em>) under the null hypothesis <span class="inline-equation"><span class="tex">$\mathcal {H}_0$</span></span> and <em>p</em>-value for the robust survival model, <em>i.e.</em>, <em>F<sub>LLR</sub></em> (<em>LLR</em>) and <em>p</em> = <em>F<sub>LLR</sub></em> (<em>LLR<sub>τ</sub></em> ). Panels in the right show the average intensities for first-time action under robust survival model, <em>i.e.</em>, <span class="inline-equation"><span class="tex">$\hat{k}_0$</span></span> before <em>τ</em> and <span class="inline-equation"><span class="tex">$\hat{k}_1$</span></span> after <em>τ</em>, using a sliding window of length <em>w</em> = 60 days. The results suggest that the <tt>Tag editor</tt> and <tt>Investor</tt> badges were <em>successful</em> and the <tt>Promoter</tt> badge was <em>unsuccessful</em>.</span>
        </div>
      </figure>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Badges and utilities</h2>
        </div>
      </header>
      <p>In this section, we look for plausible reasons that explain <em>why</em> the <tt>Tag editor</tt> and <tt>Investor</tt> badges were successful at steering users’ behavior while the <tt>Promoter</tt> badge was unsuccessful. To this aim, we resort to game-theoretic concepts such as user utilities, action payoffs and reservation values, and identify measurable proxies of some of these concepts.</p>
      <p><strong>User utilities.</strong> In the game theory literature [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0035">35</a>], the utility a user obtains from performing an action is defined as the difference between the action payoff <em>p</em> and the cost of effort <em>c</em>, <em>i.e.</em>, <em>v</em> = <em>p</em> − <em>c</em>. Moreover, the fact that participation is a voluntary, strategic choice—users have a choice about whether to perform an action—is often modeled via a reservation value <em>ω</em> that the utility <em>v</em> must exceed in order for the user to perform the action. More specifically, if <em>p</em> − <em>c</em> &lt; <em>w</em>, the user will decide not to perform the action and, otherwise, she will perform it. In this context, a badge <em>b</em> is assumed to increase the utility a user obtains from performing the action, <em>i.e.</em>, <em>v</em> = <em>p</em> − <em>c</em> + <em>v<sub>b</sub></em> , where <em>v<sub>b</sub></em> is the badge <em>value</em>. Then, depending on the actual values of <em>p</em>, <em>c</em>, <em>v<sub>b</sub></em> and <em>ω</em>, one can argue that a badge will induce users to perform an action that, in the absence of a badge, would not perform.</p>
      <p>However, in social media sites and online communities, the action payoffs, cost of effort, badge value and reservation values are typically intangible, hidden or ambiguously defined. As a consequence, our causal inference framework did not explicitly adopt the above model and instead used a data-driven approach based on survival analysis using only the observable temporal traces. In this section, however, we turn our attention towards the above stylized model, try to identify measurable proxies of the model parameters for each of the studied badges and actions and use them to investigate the plausible reasons for the success or failure of badges at steering users’ behavior, as concluded by our framework.</p>
      <p><strong>Proxies to user utilities.</strong> We consider the following observable proxies for the utilities users obtain from editing a wiki tag and offering a bounty, respectively:</p>
      <ul class="list-no-style">
        <li id="uid29" label="(a)"><em>Tag popularity</em>: the more popular a tag is, the greater the utility <em>v</em> a user may obtain from editing its wiki tag—the user needs to put less effort to create a wiki on a popular tag and she receives the satisfaction of helping a larger part of the community.<br /></li>
        <li id="uid30" label="(b)"><em>Number of answers</em>: the higher (lower) the number of answers a question receives after (before) offering a bounty, the greater the utility <em>v</em> a user obtains from offering the bounty. Moreover, users offering a bounty for an answer to another user's question may obtain less utility from the answers since they did not originally ask the question. Here, note that we did not find a correlation between the bounty value—its cost—and the final number of answers (<em>ρ</em> ≈ 0.1) and thus we can safely ignore the bounty value.<br /></li>
      </ul>
      <p>Given the above proxies, we proceeds as follows. In terms of tag wikis, we group tags by popularity (<em>i.e.</em>, number of questions a tag was used on) and model the time the users take to create a wiki for a tag of a given popularity <em>p</em> as a survival process. Moreover, we characterize this process using an intensity <em>λ<sub>p</sub></em> (<em>t</em>), which we define as follows:</p>
      <div class="table-responsive" id="eq7">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \lambda _p(t) = {\left\lbrace \begin{array}{@{}l@{\quad }l@{}}0 &amp; \text{if}\enspace t {\lt} s \\ {\lambda _0(p)} &amp; \text{if}\enspace s \le t {\lt} \tau \\ {\lambda _1(p)} &amp; \text{otherwise} \end{array}\right.} \end{equation}</span><br />
          <span class="equation-number">(8)</span>
        </div>
      </div>where <em>λ</em> <sub>0</sub>(<em>p</em>) and <em>λ</em> <sub>0</sub>(<em>p</em>) are parameters shared across all tags with popularity <em>p</em>, <em>s</em> is the time when the tag is first used in a question, and <em>τ</em> is the time when the <tt>Tag Editor</tt> badge is introduced. Then, by comparing the maximum likelihood estimators of the model parameters, <span class="inline-equation"><span class="tex">$\hat{\lambda }_0(p)$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\lambda }_1(p)$</span></span> , for different popularity levels <em>p</em>, we can assess the causal effect of the <em>Tag Editor</em> badge on tag wikis with different utility values.
      <p></p>
      <p>In terms of bounties, we first group questions by the number of answers they received in the first two days since they were asked and then compare the additional number of answers they received after those first two days if a bounty was (not) offered in the second day. Moreover, for questions that received a bounty, we estimate the distribution of the number of answers they received before the bounty was offered both before and after the badges <tt>Promoter</tt> and <tt>Investor</tt> were introduced. By controlling for the number of answers, we can assess the causal effect of both badges for bounties with different utility values.</p>
      <figure id="fig5">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186147/images/www2018-156-fig5.jpg" class="img-responsive" alt="Figure 5" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 5:</span> <span class="figure-title">Causal effect of the <tt>Tag Editor</tt> badge for tags with different utility value, as estimated by their popularity level.</span>
        </div>
      </figure><strong>Results.</strong> Figure <a class="fig" href="#fig5">5</a> summarizes the results for the <tt>Tag Editor</tt> badge, which shows the higher the popularity (utility) of a tag, the weaker the causal effect of the badge introduction. For example, while the intensity of the tags at the bottom 50% in terms of popularity increased an order of magnitude after the badge was introduced, the intensity of the tags at the top 1% did not change. This suggests that the introduction of the badge steered users to create tag wikis for less popular, low utility tags.
      <p></p>
      <p>Figure <a class="fig" href="#fig6">6</a> summarizes the results for the <tt>Promoter</tt> and <tt>Investor</tt> badges, which let us better understand their failure and success, respectively: (i) the number of answers a bounty <em>triggers</em> (<em>i.e.</em>, its utility) increases with the number of answers the question has received in its absence (top panel); (ii) the introduction of the <tt>Promoter</tt> badge changed the users’ willingness to offer bounties to their own questions only up to a very small degree (top panel, top figure), whereas the <tt>Investor</tt> badge did change it remarkably for bounties offered to other users’ questions (bottom panel, bottom figure). In both cases, the change is statistically significant, <em>i.e.</em>, <em>χ</em> <sup>2</sup> = 86.2, <em>p</em> &lt; 0.001 for <tt>Promoter</tt> and <em>χ</em> <sup>2</sup> = 114.9, <em>p</em> &lt; 0.001 for <tt>Investor</tt> badge using Mood's median test, however, only the latter was sufficiently pointed to result in a significant change at an individual user level, as concluded in Section <a class="sec" href="#sec-6">4</a>.</p>
      <figure id="fig6">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186147/images/www2018-156-fig6.jpg" class="img-responsive" alt="Figure 6" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 6:</span> <span class="figure-title">Causal effect of the <tt>Promoter</tt> and <tt>Investor</tt> badges for bounties with different utility value, as estimated by the number of answers preceding the bounty offering.</span>
        </div>
      </figure><strong>Remarks.</strong> For the specific actions and badges under studied, we were able to manually identify sensible proxies of the users’ utilities, however, finding sensible proxies for other types of actions in Stack Overflow or other online platforms will require careful reasoning and justification.
      <p></p>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Do badges improve the community functioning?</h2>
        </div>
      </header>
      <p>In this section, we use a survival-based counterfactual analysis, in which we investigate <em>what would have happened</em> if the <tt>Tag Editor</tt> and <tt>Investor</tt> badges had not been introduced, to assess to which extent the badges improved the site functioning at a community level.</p>
      <p><strong>Counterfactual analysis.</strong> For the <tt>Tag editor</tt>, we assess the site functioning at a community level in terms of the number of new tag wikis over time and, for the <tt>Investor</tt> badges, we use the time to bounty and time to first answer across questions. More specifically, we proceed as follows.</p>
      <p><em>— New tag wikis</em>: we simulate the time the users take to create a new wiki for a tag of a given popularity <em>p</em> in the counterfactual world where the <tt>Tag editor</tt> badge is never introduced using the intensity defined by Eq. <a class="eqn" href="#eq7">8</a> with <span class="inline-equation"><span class="tex">$\lambda _{0}(p) = \lambda _{1}(p) = \hat{\lambda }_0(p)$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\lambda }_0(p)$</span></span> is the maximum likelihood estimate for <em>λ</em> <sub>0</sub>(<em>p</em>) in the true world. Then, we compare the number of new tag wikis over time as well as the popularity of their associated wikis in the true world and in the simulated counterfactual world.</p>
      <p><em>— Time to bounty and first answer</em>: for questions that received a bounty, we model the time that the users take to offer the bounty as a survival process with associated intensity <em>λ<sub>b</sub></em> (<em>t</em>), which we define as follows:</p>
      <div class="table-responsive" id="eq8">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \lambda _b(t) = {\left\lbrace \begin{array}{@{}l@{\quad }l@{}}0 &amp; \text{if}\enspace t {\lt} s \\ {\lambda _0(b)} &amp; \text{if}\enspace s \le t {\lt} \tau \\ {\lambda _1(b)} &amp; \text{otherwise} \end{array}\right.} \end{equation}</span><br />
          <span class="equation-number">(9)</span>
        </div>
      </div>where the parameter <em>b</em> ∈ {0, 1} denotes whether the badge is offered by the user asking the question or by another user, {<em>λ<sub>i</sub></em> (<em>b</em>)} <sub><em>i</em>, <em>b</em> ∈ {0, 1}</sub> are (four) parameters shared across all questions, <em>s</em> is the time since two days after the question is asked<a class="fn" href="#fn9" id="foot-fn9"><sup>9</sup></a>, and <em>τ</em> is the time when the <tt>Promoter</tt> and <tt>Investor</tt> badges are introduced. For all questions, we model the time that the users take to provide the first answer also as a survival process with an associated intensity defined similarly as in Eq. <a class="eqn" href="#eq8">9</a>, however, in this case, the parameter <em>b</em> ∈ { − 1, 0, 1} denotes whether the question received a badge and, if so, whether it was offered by the user asking the question or by another user, and thus the model has six parameters. Then, we compare the maximum likelihood estimators of the above parameters to assess what would have happened if the <tt>Investor</tt> badge had not been introduced.
      <figure id="fig7">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186147/images/www2018-156-fig7.jpg" class="img-responsive" alt="Figure 7" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 7:</span> <span class="figure-title">Tag wikis with and without the <tt>Tag Editor</tt> badge. Simulations means and 95%-CI shown.</span>
        </div>
      </figure><strong>Results.</strong> Figure <a class="fig" href="#fig7">7</a> summarizes the results for the <tt>Tag Editor</tt> badge. The top panel shows the number of unique tags with (blue) and without (green) supporting tag wiki over time in the true and in the simulated counterfactual world. Note that the number of unique tags without tag wiki grows over time as users ask questions with new (not previously used) tags. The results show that the tags with supporting tag wikis increase at a higher rate in the true world than in the counterfactual world just after the badge introduction, however, after a relatively short period of time, the rate decreased to its original value and match the rate at which tags with tag wikis grows in the counterfactual world. The bottom panel, which shows a decrease on the average rank popularity (rank) of the tags with supporting tag wikis, supports the following hypothesis to explain this phenomenon. The badge lifted the utility value of editing tag wikis, however, this increase was large enough to exceed the reservation value only for tags of certain popularity. As a consequence, after these tags had a tag wiki, the effect of the badge diminished.
      <figure id="fig8">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186147/images/www2018-156-fig8.jpg" class="img-responsive" alt="Figure 8" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 8:</span> <span class="figure-title">Time to bounty and first answer with and without the <tt>Promoter</tt> and <tt>Investor</tt> badges.</span>
        </div>
      </figure>
      <p></p>
      <p>Figure <a class="fig" href="#fig8">8</a> summarizes the results for the <tt>Investor</tt> badge, which show that the time to bounty and first answer for questions in which a bounty was offered by a user different than the user asking the question decreased (<em>i.e.</em>, the intensities increased) after the <tt>Investor</tt> was introduced, improving the site functioning. In contrast, the time to first answer (and time to bounty) in questions without bounty (and with a bounty offered by the user asking the question) increased. The latter observation suggests that the <tt>Investor</tt> badge may have mitigated the global slowdown in the time users take to answer questions by motivating more people to offer bounties faster—in the counterfactual world where the <tt>Investor</tt> badge had not been introduced, the site functioning would have actually worsened.</p>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span> Conclusions</h2>
        </div>
      </header>
      <p>Social media sites and online communities are dynamic environments where users change their behavior on a daily basis due to many complex factors. As a consequence, assessing the effectiveness of incentive mechanisms, which are ubiquitous among them, is challenging. In this work, we have focused on one of the simplest incentive mechanisms—first-time badges—and studied their effectiveness by developing a novel survival-based causal modeling framework, specially designed to harness the delayed introduction of several badges in a popular Q&amp;A website.</p>
      <p>Our work also opens up many interesting venues for future work. For example, it would be very interesting to use our framework to analyze badges in other online platforms as well as extend it to other types of badges, <em>e.g.</em>, threshold badges. Badges are typically awarded to all users whose contributions <em>exceed</em> some predefined values, however, it would be interesting to also consider incentive mechanisms where users compete for a limited reward. Finally, in this work, we have focused on assessing the causal effect of (first-time) badges. A natural follow-up would be developing principled, effective methods to optimize their design.</p>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2>Acknowledgements</h2>
        </div>
      </header>
      <p>We thank Utkarsh Upadhyay and Isabel Valera for useful discussions.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Odd Aalen, Ornulf Borgan, and Hakon Gjessing. 2008. <em><em>Survival and event history analysis: a process point of view</em></em>. Springer Science &amp; Business Media.</li>
        <li id="BibPLXBIB0002" label="[2]">Samuel Abramovich, Christian Schunn, and Ross Mitsuo Higashi. 2013. Are badges useful in education?: It depends upon the type of badge and expertise of learner. <em><em>Educational Technology Research and Development</em></em> 61, 2(2013), 217–232.</li>
        <li id="BibPLXBIB0003" label="[3]">Tim Althoff, Pranav Jindal, and Jure Leskovec. 2017. Online Actions with Offline Impact: How Online Social Networks Influence Online and Offline User Behavior. In <em><em>Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</em></em> (WSDM 2017). 537–546.</li>
        <li id="BibPLXBIB0004" label="[4]">Ashton Anderson, Daniel P. Huttenlocher, Jon M. Kleinberg, and Jure Leskovec. 2013. Steering user behavior with badges. In <em><em>Proceedings of the 22nd International World Wide Web Conference</em></em> (WWW ’13). 95–106.</li>
        <li id="BibPLXBIB0005" label="[5]">Ashton Anderson, Daniel P. Huttenlocher, Jon M. Kleinberg, and Jure Leskovec. 2014. Engaging with massive online courses. In <em><em>Proceedings of the 23rd International World Wide Web Conference</em></em> (WWW ’14). 687–698.</li>
        <li id="BibPLXBIB0006" label="[6]">Sinan Aral and Dylan Walker. 2012. Identifying influential and susceptible members of social networks. <em><em>Science</em></em> 337, 6092 (2012), 337–341.</li>
        <li id="BibPLXBIB0007" label="[7]">Benny Bornfeld and Sheizaf Rafaeli. 2017. Gamifying with badges: A big data natural experiment on Stack Exchange. <em><em>First Monday</em></em> 22, 6 (2017).</li>
        <li id="BibPLXBIB0008" label="[8]">Yubo Chen, Qi Wang, and Jinhong Xie. 2011. Online social interactions: A natural experiment on word of mouth versus observational learning. <em><em>Journal of marketing research</em></em> 48, 2 (2011), 238–254.</li>
        <li id="BibPLXBIB0009" label="[9]">Rajeev H. Dehejia and Sadek Wahba. 2002. Propensity score-matching methods for nonexperimental causal studies. <em><em>Review of Economics and statistics</em></em> 84, 1 (2002), 151–161.</li>
        <li id="BibPLXBIB0010" label="[10]">Sebastian Deterding, Miguel Sicart, Lennart Nacke, Kenton O'Hara, and Dan Dixon. 2011. Gamification. using game-design elements in non-gaming contexts. In <em><em>Proceedings of the International Conference on Human Factors in Computing Systems</em></em> (CHI 2011). 2425–2428.</li>
        <li id="BibPLXBIB0011" label="[11]">Stephen G. Donald and Kevin Lang. 2007. Inference with difference-in-differences and other panel data. <em><em>The review of Economics and Statistics</em></em> 89, 2 (2007), 221–233.</li>
        <li id="BibPLXBIB0012" label="[12]">David Easley and Arpita Ghosh. 2016. Incentives, Gamification, and Game Theory: An Economic Approach to Badge Design. <em><em>ACM Trans. Economics and Comput.</em></em> 4, 3 (2016), 16:1–16:26.</li>
        <li id="BibPLXBIB0013" label="[13]">Oriol Borrás Gené, Margarita Martínez-Núñez, and Ángel Fidalgo Blanco. 2014. Gamification in MOOC: challenges, opportunities and proposals for advancing MOOC model. In <em><em>Proceedings of the Second International Conference on Technological Ecosystems for Enhancing Multiculturality</em></em> (TEEM ’14). 215–220.</li>
        <li id="BibPLXBIB0014" label="[14]">Stefan Göbel, Sandro Hardy, Viktor Wendel, Florian Mehm, and Ralf Steinmetz. 2010. Serious games for health: personalized exergames. In <em><em>Proceedings of the 18th International Conference on Multimedia 2010</em></em> (MM ’10). 1663–1666.</li>
        <li id="BibPLXBIB0015" label="[15]">Juho Hamari, David J. Shernoff, Elizabeth Rowe, Brianno Coller, Jodi Asbell-Clarke, and Teon Edwards. 2016. Challenging games help students learn: An empirical study on engagement, flow and immersion in game-based learning. <em><em>Computers in Human Behavior</em></em> 54 (2016), 170–179.</li>
        <li id="BibPLXBIB0016" label="[16]">Michael D. Hanus and Jesse Fox. 2015. Assessing the effects of gamification in the classroom: A longitudinal study on intrinsic motivation, social comparison, satisfaction, effort, and academic performance. <em><em>Computers &amp; Education</em></em> 80 (2015), 152–161.</li>
        <li id="BibPLXBIB0017" label="[17]">Philipp Herzig, Susanne Strahringer, and Michael Ameling. 2012. Gamification of ERP systems - Exploring gamification effects on user acceptance constructs. In <em><em>Multikonferenz Wirtschaftsinformatik</em></em>. 793–804.</li>
        <li id="BibPLXBIB0018" label="[18]">Robert V. Hogg and Allen T. Craig. 1995. <em><em>Introduction to mathematical statistics</em></em>. Prentice Hall.</li>
        <li id="BibPLXBIB0019" label="[19]">Nicole Immorlica, Gregory Stoddard, and Vasilis Syrgkanis. 2015. Social Status and Badge Design. In <em><em>Proceedings of the 24th International Conference on World Wide Web</em></em> (WWW ’15). 473–483.</li>
        <li id="BibPLXBIB0020" label="[20]">Abigail Z. Jacobs, Samuel F. Way, Johan Ugander, and Aaron Clauset. 2015. Assembling thefacebook: Using Heterogeneity to Understand Online Social Network Assembly. In <em><em>Proceedings of the 7th ACM Web Science Conference</em></em> (WebSci ’15). 18:1–18:10.</li>
        <li id="BibPLXBIB0021" label="[21]">Daniel Johnson, Sebastian Deterding, Kerri-Ann Kuhn, Aleksandra Staneva, Stoyan Stoyanov, and Leanne Hides. 2016. Gamification for health and wellbeing: A systematic review of the literature. <em><em>Internet interventions</em></em> 6 (2016), 89–106.</li>
        <li id="BibPLXBIB0022" label="[22]">Adam D. I. Kramer, Jamie E. Guillory, and Jeffrey T. Hancock. 2014. Experimental evidence of massive-scale emotional contagion through social networks. <em><em>Proceedings of the National Academy of Sciences</em></em> 111, 24(2014), 8788–8790.</li>
        <li id="BibPLXBIB0023" label="[23]">Michael Lechner. 2011. The estimation of causal effects by difference-in-difference methods. <em><em>Foundations and Trends® in Econometrics</em></em> 4, 3(2011), 165–224.</li>
        <li id="BibPLXBIB0024" label="[24]">Simon McCallum and Costas Boletsis. 2013. Dementia Games: A Literature Review of Dementia-Related Serious Games. In <em><em>Proceedings of the 4th International Conference on Serious Games Development and Applications</em></em> (SGDA 2013). 15–27.</li>
        <li id="BibPLXBIB0025" label="[25]">Breed D. Meyer. 1995. Natural and quasi-experiments in economics. <em><em>Journal of business &amp; economic statistics</em></em> 13, 2 (1995), 151–161.</li>
        <li id="BibPLXBIB0026" label="[26]">Benedikt Morschheuser, Juho Hamari, and Jonna Koivisto. 2016. Gamification in Crowdsourcing: A Review. In <em><em>Proceedings of the 49th Hawaii International Conference on System Sciences</em></em> (HICSS 2016). 4375–4384.</li>
        <li id="BibPLXBIB0027" label="[27]">Cristina Muntean. 2011. Raising engagement in e-learning through gamification. In <em><em>Proceedings 6th International Conference on Virtual Learning</em></em> (ICVL 2011).</li>
        <li id="BibPLXBIB0028" label="[28]">Tobias Mutter and Dennis Kundisch. 2014. Behavioral Mechanisms Prompted by Badges: The Goal-Gradient Hypothesis. In <em><em>Proceedings of the International Conference on Information Systems - Building a Better World through Information Systems</em></em> (ICIS 2014).</li>
        <li id="BibPLXBIB0029" label="[29]">Hüseyin Oktay, Brian J. Taylor, and David D. Jensen. 2010. Causal discovery in social media using quasi-experimental designs. In <em><em>Proceedings of the 3rd Workshop on Social Network Mining and Analysis</em></em> (SNAKDD 2009). 1–9.</li>
        <li id="BibPLXBIB0030" label="[30]">Tuan Q. Phan and Edoardo M. Airoldi. 2015. A natural experiment of social network formation and dynamics. <em><em>Proceedings of the National Academy of Sciences</em></em> 112, 21(2015), 6595–6600.</li>
        <li id="BibPLXBIB0031" label="[31]">Mark R. Rosenzweig and Kenneth I. Wolpin. 2000. Natural ”natural experiments” in economics. <em><em>Journal of Economic Literature</em></em> 38, 4 (2000), 827–874.</li>
        <li id="BibPLXBIB0032" label="[32]">Katie Seaborn and Deborah I. Fels. 2015. Gamification in theory and action: A survey. <em><em>Int. J. Hum.-Comput. Stud.</em></em> 74 (2015), 14–31.</li>
        <li id="BibPLXBIB0033" label="[33]">Elizabeth A. Stuart. 2010. Matching methods for causal inference: A review and a look forward. <em><em>Statistical science: a review journal of the Institute of Mathematical Statistics</em></em> 25, 1 (2010), 1–21.</li>
        <li id="BibPLXBIB0034" label="[34]">Samuel S. Wilks. 1938. The large-sample distribution of the likelihood ratio for testing composite hypotheses. <em><em>The Annals of Mathematical Statistics</em></em> 9, 1 (1938), 60–62.</li>
        <li id="BibPLXBIB0035" label="[35]">Jiawei Zhang, Xiangnan Kong, and Philip S. Yu. 2016. Badge System Analysis and Design. In <em><em>Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</em></em> (ASONAM 2016).</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class="link-inline force-break" href="https://stackoverflow.com">https://stackoverflow.com</a></p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>Publicly available at <a class="link-inline force-break" href="https://archive.org/details/stackexchange">https://archive.org/details/stackexchange</a></p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>In February 2011, Stack Overflow lowered the minimum reputation level to 100 and thus the characteristics of the population that could earn the badge changed. Therefore, in our analysis, we only consider data up to January 2010.</p>
    <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>A user can also offer a bounty to a user after she has provided an answer, as a thank you gift, however, that usage is rarer.</p>
    <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>Stack Overflow often requires a minimum reputation level for a user to be able to perform an action. For example, only users with at least a reputation level of 75 can offer a bounty.</p>
    <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a>We obtain quantitatively similar results in the absence of a linear trend, <em>i.e.</em>, <em>a</em> = 0.</p>
    <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a>The standardized mean difference (SMD) is defined as the difference in means of the treatment and control group divided by the pooled standard deviation of both groups.</p>
    <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a><a class="link-inline force-break" href="https://meta.stackexchange.com/questions/64824/clever-bounty-reputation-hack">https://meta.stackexchange.com/questions/64824/clever-bounty-reputation-hack</a></p>
    <p id="fn9"><a href="#foot-fn9"><sup>9</sup></a>A bounty can only be offered two days after the question has been asked.</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&nbsp;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/doi.org/10.1145/3178876.3186147">https://doi.org/doi.org/10.1145/3178876.3186147</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
