<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Efficient Context-Aware Sequential Recommender System</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
<link rel="cite-as" href="https://doi.org/10.1145/3184558.3191581"/></head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3191581'>https://doi.org/10.1145/3184558.3191581</a>.
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3191581'>https://w3id.org/oa/10.1145/3184558.3191581</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Efficient Context-Aware Sequential Recommender System</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Leonardo</span> <span class="surName">Cella</span>, Dipartimento di Informatica, Università degli Studi di Milano, Via Comelico, 39Milan, Italy 20135, <a href="mailto:leonardo.cella@unimi.it">leonardo.cella@unimi.it</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191581" target="_blank">https://doi.org/10.1145/3184558.3191581</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Traditional collaborative filtering, and content-based approaches attempt to learn a static recommendation model in a batch fashion. These approaches are not suitable in highly dynamic recommendation scenarios, like news recommendation and computational advertisement. Due to this well-known limitation, in the last decade a lot of efforts have been spent over the study of online learning techniques. Currently, a lot of attention has been devoted to improvements on the theoretical guarantees, without caring too much about computational cost and memory footprint. However, in the era of big-data content features tend to be high-dimensional, which leads to a direct challenge for traditional on-line learning algorithms (e.g., multi-armed bandits) since these are mostly designed for low-dimensional feature spaces. In this work we face the aforementioned problem, investigating an approximated context-aware bandit learner. Our model takes into account the problem of finding the actual low-dimensional manifold spanned by data content-features. In particular, we propose to store the covariance matrix of the previously seen contexts in a compressed space, without losing too much in terms of recommendation quality. With this work we provide an overview over the main properties, describe the adopted techniques, and report on preliminary experimental results on a synthetic dataset. We also discuss a drawback of the proposed method that may appear in typical scenarios and suggest future research avenues.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS Concepts:</span> • <strong>Computing methodologies</strong> → <strong>Sequential decision making;</strong> <strong>Online learning settings;</strong> <em>Spectral methods;</em> • <strong>Theory of computation</strong> → <em>Online learning algorithms;</em></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style="font-weight:bold;"><small>Keywords:</small></span> <span class="keyword"><small>Online learning theory</small>,</span> <span class="keyword"><small>Incremental learning</small>,</span> <span class="keyword"><small>Recommender Systems</small>,</span> <span class="keyword"><small>Curse of dimensionality</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Leonardo Cella. 2018. Efficient Context-Aware Sequential Recommender System. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New York, NY, USA</em> 4 Pages. <a href="https://doi.org/10.1145/3184558.3191581" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3184558.3191581</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-2">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <p>The recommender system field has been largely studied since early 90s [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>]. Recommendation engines are now an essential part of many on-line businesses such as Amazon [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0020">20</a>] and Netflix [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>]. Typical examples of modern recommendation problems are news articles [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>] and computational advertisement [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]. Due to their sequential nature and the dependence on the current <em>context</em>, these application domains are not suited to standard batch algorithms that are commonly used in static settings. Static settings assumes a set of users with fixed preferences interacting with a fixed set of items. In this scenario, the well known cold-start issue, namely the lack of any information regarding the new user (or item), is usually addressed with <em>hybrid</em> approaches (e.g [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>]). As mentioned earlier, this static assumption is not always true: in online scenarios user preferences have to be computed sequentially according to previous choices. If we consider highly dynamic recommendation domains, such as newsfeeds and online advertising, the user preferences and item sets tend to be quite fluid. As a consequence, standard collaborative filtering methods as Matrix Factorization break down.</p>
      <p>Multi-armed bandit model have been the state-of-the-art for modeling online scenarios for a decade. Recently, a lot of efforts have been spent in building context-aware bandit algorithms with strong theoretical guarantees. However, there is still a certain lack of attention on the scalability issues, which makes it difficult to use these algorithms in scenarios with large amount of content features. Common scenarios that may benefit from this solution are recommender systems that exploit a Reproduced Kernel Hilbert Space for deriving product similarities [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>], and more generally recommendation algorithms that operate in scenarios with many content features [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>].</p>
      <p>We propose a sketched on-line contextual learner capable to preserve most of past spectral information while learning. More specifically, we introduce a first sketching model over a specific contextual larning algorithm, [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>]. The adopted sketching technique not only has good empirical guarantees, but also strong theoretical properties that are suited to a future theoretical analysis. We describe preliminary results derived with different sketching configurations on a synthetic dataset. We finally give some intuitions on drawbacks and possible solutions to be taken into account in future investigations.</p>
      <p>For any positive integer <em>T</em>, we will indicate with [<em>T</em>] the set 1, …<em>T</em>. We indicate matrices with bold upper-case letters <strong>W</strong>, vectors with bold lower-case letters <strong>x</strong>. We denote with ‖<strong>x</strong>‖ <sub><em>p</em></sub> the p-norm of the vector <span class="inline-equation"><span class="tex">$\mathbf {x}\in \mathbb {R}^d$</span></span> . Vectors are always column-vectors, thus <strong>x</strong> <sup>⊤</sup> is a row-vector. The inner-product of two vectors <span class="inline-equation"><span class="tex">$\mathbf {x},\mathbf {y} \in \mathbb {R}^d$</span></span> is defined as ⟨<strong>x</strong>, <strong>y</strong>⟩. Finally, given a positive definite matrix <span class="inline-equation"><span class="tex">$\mathbf {W} \in \mathbb {R}^{d\times d}$</span></span> , the matrix-norm of a vector <span class="inline-equation"><span class="tex">$\mathbf {x}\in \mathbb {R}^d$</span></span> is defined as <span class="inline-equation"><span class="tex">${\Vert \mathbf {x}\Vert }_{\mathbf {W}} = \sqrt {{\mathbf {x}}^\top \mathbf {W} \mathbf {x}}$</span></span> .</p>
    </section>
    <section id="sec-3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related Works</h2>
        </div>
      </header>
      <p>The main goal of a well-tuned multi armed bandit model (MAB) is to manage the exploration-exploitation dilemma which typically arise in a sequential setting with partial feedback. To act eventually optimally, the learner <em>exploit</em>s past observation to select the arm (item) which appears best. On the other hand, such arm could instead be suboptimal, due to lack of knowledge. To avoid selecting always a possible suboptimal arm, the learner has to consider also the option of <em>exploring</em> by selecting a so far unseen arm (e.g., an item whose feature vector is orthogonal to all the vectors selected until current trial) with the objective of gather more information about the new direction. Clearly, naive strategies of pure-exploration or pure-exploitation are far to be effective. The reason is that <em>exploration</em> is necessary to refine the learner estimation even if it may decrease the <em>short-term rewards</em>, while <em>exploitation</em> is necessary in order to trying selecting the optimal arm. This ability allow MAB algorithms to break-down also trendy deep-learning approaches when there is a continuous need of recommendations over cold-items. The MAB model was originally proposed and investigated by Robbins [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>], attracting the interest of several researchers among different communities. Contextual MAB learners, which exploit the context as additional information in order to maximize their reward, are sequential decision-making models that extend Robbins’ model and are largely adopted in the Recommender System community [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>]. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0021">21</a>] try to solve the personalized recommendation problem for fluid (new) users when no content user features are available (cold-user), with the aim of understanding as quickly as possible the class profile the user belongs to. Collaborative strategies [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>] try instead to speed-up the learning process by collaboratively sharing information. In particular they strengthen the learning phase by agglomerating similar user profiles in clusters, requiring less rewards per user and less exploration.</p>
      <p>In the big data era, it is common to deal with high-dimensional content information, while most algorithms developed so far are designed for low-dimensional data. This creates two issues. The first one are the high computational costs, the second one consists of having extremely large upper bounds over the error metric (regret) with high-dimensional data. The most popular contextual learners [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] assume a linear relation governing the reward in terms of content features, and are based on ridge-regression for the estimation of the hidden vector parameter. This means that at each round, they invert a covariance matrix defined in the original space, an operation that is computationally very costly in most practical cases. More in detail, costs are linear in <em>O</em>(<em>Td</em>), where <em>T</em> is the number of rounds, and <em>d</em> is the dimension of the feature space. As mentioned, the regret bounds are also defined in terms of the dimension of the feature space, and thus affected by the curse of dimensionality. In the machine learning community, similar problems have been already encountered in different settings, such are the online-newton-step algorithm [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>]. In these works the authors proposed compressing techniques to store the previous observed gradient vectors. As done in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>], we will adopt Frequent Directions [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>] as compressing strategy. That consists of a deterministic sketching method that maintains the invariant that the last row of the stored matrix is always <strong>0</strong>.</p>
    </section>
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Problem Formulation and Setting</h2>
        </div>
      </header>
      <p>In this section we formally present the sequential user recommendation problem, and we also make some examples in order to show how it could be adopted to solve the recommendation problem with fluid items. Following previous work [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] we call this multi-armed bandit model, <em>Contextual Bandit</em>. Formally, a contextual-bandit algorithm operates in sequential discrete rounds <em>t</em> = 1, …<em>T</em>. In each trial <em>t</em>:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">The learner observes the current user <em>u<sub>t</sub></em> and a set of arms <em>I<sub>t</sub></em> together with their feature vectors <strong>x</strong> <sub><em>i</em>, <em>t</em></sub> ∀<em>i</em> ∈ <em>I<sub>t</sub></em> . The vector <strong>x</strong> <sub><em>i</em>, <em>t</em></sub> embeds information of both user <em>u<sub>t</sub></em> and item <em>i</em>, and it will be referred to as <em>context</em>.<br /></li>
        <li id="list2" label="•">Based on the payoffs observed in previous trials [<em>t</em> − 1] with respect to the chosen contexts, the learner chooses the item to be recommended <em>i</em>(<em>t</em>).<br /></li>
        <li id="list3" label="•">According to the recommended product <strong>x</strong> <sub><em>i</em>(<em>t</em>)</sub>, the learner observes a reward <em>r</em> <sub><em>t</em>, <em>i</em>(<em>t</em>)</sub>. The expected value on the reward depends on both the user and the recommended item. It is important to emphasize that in the <strong>bandit</strong> setting, the only observed reward per round is the one corresponding to the recommended arm, no feedback is given for unchosen arms <em>i</em> ≠ <em>i</em>(<em>t</em>).<br /></li>
      </ul>
      <p>In this setting the performance will be measured as <span class="inline-equation"><span class="tex">$\sum _{t=1}^T r_{t,i(t)}$</span></span> , corresponding to the cumulative reward observed over the <em>T</em> rounds. In particular we will compare that to the optimal reward <span class="inline-equation"><span class="tex">$\sum _{t=1}^T r_{t,i^*}$</span></span> , where <em>i</em> <sup>*</sup> is the optimal arm at each round. Clearly our goal is to design a scalable strategy that maximizes the cumulative reward <span class="inline-equation"><span class="tex">$\sum _{t=1}^T r_{t,i(t)}$</span></span> . Since the optimal cumulative reward is always the same independently of the adopted learner, we consider the <em>regret</em> as the objective function to be <em>minimized</em>:</p>
      <div class="table-responsive" id="Xeq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} R_T = \sum _{t=1}^T (r_{t,i^*} - r_{t,i(t)}) \end{equation}</span><br />
          <span class="equation-number">(1)</span>
        </div>
      </div>In our setting we will refer to a special case of the general contextual bandit problem known as <em><em>K</em>-armed bandit</em> in which at each round, the set of available arms has fixed cardinality <em>K</em>. Coming back to our recommendation problem, we can consider item contexts as the arm set. In particular each item context could be viewed as the concatenation of both real <em>context</em> information regarding the user and the environment, and pure content properties of the user and the respective item. As mentioned before the linearity assumption consists of assuming a linear function mapping the expected value of the reward (loss) with the item context. We indicate with <em>θ</em> <sup>*</sup> the hidden vector that specifies this linear relation.
      <p></p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Proposed Algorithm</h2>
        </div>
      </header>
      <section id="sec-6">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Optimal Algorithm</h3>
          </div>
        </header>
        <p>According to the notation of Section <a class="sec" href="#sec-2">1</a>, we assume that the reward (loss) of an arm <em>i</em> is linear in its <em>d</em>-dimensional feature vector <strong>x</strong> <sub><em>t</em>, <em>i</em></sub> :</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} r_{t,i} = \mathbf {x}_{t,i}^\top \theta ^* + \eta _t \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>where: <span class="inline-equation"><span class="tex">$\theta ^* \in \mathbb {R}^d$</span></span> is the unknown <em>d</em>-dimensional coefficient vector governing the linear mapping, <em>η<sub>t</sub></em> is a 1-subGaussian random-noise variable. Let <span class="inline-equation"><span class="tex">$\mathbf {X}_t \in \mathbb {R}^{txd}$</span></span> be the matrix of observed contexts of <em>t</em> × <em>d</em> dimension, whose rows correspond to the <strong>x</strong> <sub><em>i</em>(1)</sub>, …<strong>x</strong> <sub><em>i</em>(<em>t</em>)</sub> contexts observed until round <em>t</em>, and <span class="inline-equation"><span class="tex">$\mathbf {r}_t \in \mathbb {R}^d$</span></span> the column-vector of corresponding feedbacks (e.g., click/no-click user feedback). Applying regularized least-square regression to (<em>X<sub>t</sub></em> , <strong>r<sub>t</sub></strong> ), the unknown vector parameter estimate is defined as:
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf{\widehat{\theta }}_t = (\mathbf {X}^\top _t \mathbf {X}_t + \mathbf {I}_d)^{-1} \mathbf {X}_t^\top \mathbf {r}_t \end{equation}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>where <strong>I</strong> <sub><em>d</em></sub> is the identity matrix with <em>d</em> components. As mentioned in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>], the exploration-exploitation management can be summarized with the following formula:
        <p></p>
        <div class="table-responsive" id="eq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf {x}_{t+1} = \arg \max _{\mathbf {x}_i \in I_{t+1}} [{\mu (\mathbf {x}_{i})} + \beta _t \sigma (\mathbf {x}_{i},\mathbf {x}_{[t]})]\nonumber\end{equation}</span><br />
            <span class="equation-number">(mid1)</span>
          </div>
        </div>
        <p>For the moment we can consider the first <em>exploitation</em> term <em>μ</em>(<strong>x</strong> <sub><em>i</em></sub> ) as the current estimate of the mean reward observed, the second term <em>σ</em>(<strong>x</strong> <sub><em>i</em></sub> , <strong>x</strong> <sub>[<em>t</em>]</sub>) as the <em>exploration</em> bonus term times a time-dependent hyper-parameter <em>β<sub>t</sub></em> . Let <em>η<sub>t</sub></em> = (<em>η</em> <sub>1</sub>, …<em>η<sub>t</sub></em> )<sup>⊤</sup>, <strong>X</strong> = <strong>X</strong> <sub>1: <em>t</em></sub> , thanks to the linearity assumption (Equation <a class="eqn" href="#eq1">2</a>), the original form of the ridge-regression estimation for <span class="inline-equation"><span class="tex">$\widehat{\theta }$</span></span> can be rewritten as:</p>
        <div class="table-responsive" id="eq4">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \widehat{\theta }_t = (\mathbf {X}^\top \mathbf {X} + \lambda I)^{-1} \mathbf {X}^\top (\mathbf {X}\theta _* + \eta _t) \end{equation}</span><br />
            <span class="equation-number">(4)</span>
          </div>
        </div>where (<strong>X</strong> <em>θ</em> <sub>*</sub> + <em>η<sub>t</sub></em> ) is the sequence of previously observed rewards. According to [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] the arm selection phase, could be written as:
        <div class="table-responsive" id="eq5">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf {x}_{(t)} = \arg \max _{\mathbf {x}\in I_t} \langle \mathbf {x},\widehat{\mathbf {\theta }}\rangle + {\log \big (\frac{t}{\delta }\big)}^\frac{1}{2} {\Vert {\bf x}\Vert }_{V^{-1}_{t-1}} \end{equation}</span><br />
            <span class="equation-number">(5)</span>
          </div>
        </div>where <strong>V</strong> <sub><em>t</em></sub> = <strong>X</strong> <sup>⊤</sup> <strong>X</strong> + <em>λ</em> <strong>I</strong> <sub><em>d</em></sub> and <em>λ</em> is a regularization parameter.
        <p></p>
      </section>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Efficiency via Sketching</h3>
          </div>
        </header>
        <p>The just presented model requires <em>Ω</em>(<em>d</em> <sup>2</sup>) time and space for storing the covariance matrix <strong>V</strong> <sub><em>t</em></sub> , and has <em>Ω</em>(<em>d</em> <sup>3</sup>) time complexity for its inverse computation. The adoption of sketching is motivated by its ability of maintaining an approximation of the <em>to-sketch</em> matrix <strong>X</strong> <sub><em>t</em></sub> , that we will denote as <span class="inline-equation"><span class="tex">$\mathbf {B}_t \in \mathbb {R}^{mxd}$</span></span> , where <em>m</em> is the <em>sketch size</em> (<em>m</em> ≪ <em>d</em>) whose optimal value is the data really spanned dimension.</p>
        <div class="table-responsive" id="eq6">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split} \mathbf {V}_t &amp;= \mathbf {V}_{0} + \sum _{s=1}^{s=t} {\bf x}_s{\bf x}^\top _s \\ &amp;= \mathbf {V}_{0} + \mathbf {X}^\top _t \mathbf {X}_t \\ &amp;\approx \mathbf {V}_{0} + \mathbf {B}^\top _t \mathbf {B}_t \end{split} \end{equation}</span><br />
            <span class="equation-number">(6)</span>
          </div>
        </div>Regarding its inversion, we leverage on the Sherman-Morrison formula, with <strong>V</strong> <sub>0</sub> = <em>λ</em> <strong>I</strong> <sub><em>d</em></sub> :
        <div class="table-responsive" id="Xeq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split} V^{-1}_t &amp;= \frac{1}{\lambda } \big (\mathbf {I}_d - \mathbf {B}^\top _t(\lambda \mathbf {I}_m + \mathbf {B}_t \mathbf {B}^\top _t)^{-1}\mathbf {B}_t\big)\\ &amp;= \frac{1}{\lambda } \big (\mathbf {I}_d + \mathbf {B}^\top _t \mathbf {H}_t \mathbf {B}_t \big) \end{split} \end{equation}</span><br />
            <span class="equation-number">(7)</span>
          </div>
        </div>
        <p></p>
        <p><img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191581/images/www18companion-320-img1.svg" class="img-responsive" alt="" longdesc="" /> To see why this gives an efficient algorithm we can notice that Equation <a class="eqn" href="#eq4">4</a> becomes: <span class="inline-equation"><span class="tex">$\widehat{\theta }_t = \frac{1}{\lambda } \big (\mathbf {X}^\top \mathbf {Y}_t + \mathbf {B}^{\top }_{t} \mathbf {H}_t \mathbf {B}_t^\top \mathbf {X}^\top \mathbf {Y}_t \big)$</span></span> . Regarding the arm selection Equation <a class="eqn" href="#eq5">5</a> we now have:</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation*} \mathbf {x}_t = \arg \max _{\mathbf {x}\in I_t} \langle \mathbf {x},\frac{1}{\lambda } \big (\mathbf {X}^\top \mathbf {Y}_t + \mathbf {B}^{\top }_{t} \mathbf {H}_t \mathbf {B}_t^\top \mathbf {X}^\top \mathbf {Y}_t \big)\rangle + {\log \big (\frac{t}{\delta }\big)}^\frac{1}{2} {\Vert {\bf x}\Vert }_{V_{t-1}} \nonumber\end{equation*}</span><br />
          </div>
        </div>The operations involving <strong>B</strong> <sub><em>t</em></sub> <strong>x</strong> <sub><em>t</em></sub> require only <em>O</em>(<em>md</em>) time, while matrix vector product with <strong>H</strong> <sub><em>t</em></sub> requires only <em>O</em>(<em>d</em> <sup>2</sup>). We call this algorithm <strong>Sketched OFUL</strong>. For the experiment we have adopted [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>] as sketching technique, its main drawback is that requires a predefined sketch-size. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>] proposes a new sketching learning, based on ridge leverage scores that avoids high-regret when the dataset rank is bigger than the predefined sketched-dimension. It adaptively increases the size of its sketch, providing a favorable regret-performance trade-off. This is advantageous when the context vectors do not span a low-dimensional space but range uniformly over the whole <em>d</em> − dimensional space.
        <p></p>
      </section>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Experimental Analysis</h2>
        </div>
      </header>
      <p>We compare our algorithm to [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] without sketching. The comparison is made on an artificially generated dataset. We adopt two different dataset versions according to the data really-spanned manifold dimension (Table &nbsp;<a class="tbl" href="#tab1">1</a>). All of them have been used to evaluate the algorithm over <em>T</em> = 5000 trials comparing to the performance obtained by the original linear contextual learner, that is the objective of our approximation. The artificial contexts have been generated starting from a low-dimensional manifold, expressed in terms of orthonormal basis. This basis has been enlarged to generate the bigger <em>d</em> − dimensional space, by linear combinations of its vectors. All the context vectors have finally been normalized according to the l2-norm. The same holds for the generation of the hidden vector <span class="inline-equation"><span class="tex">$\theta ^* \in \mathbb {R}^d$</span></span> . Finally, the rewards have been generated as <strong>x</strong> <sup>⊤</sup> <em>θ</em> <sup>*</sup> + <em>η</em> <sub><em>i</em>, <em>t</em></sub> where <em>η</em> <sub><em>i</em>, <em>t</em></sub> is random noise with 0 mean and 0.5 variance. The performance have been measured in terms of difference between the best expectation, defined as the cumulative reward obtained knowing the hidden vector <span class="inline-equation"><span class="tex">$\theta ^* \in \mathbb {R}^d$</span></span> and the cumulative reward collected by the learning policy:</p>
      <div class="table-responsive" id="Xeq3">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \sum _{t=1}^{T} \arg \max _{i \in I(t)} (\mathbf {x}_{i}^\top \theta ^{*} + \eta _{i}) - r_{policy(t)} \end{equation}</span><br />
          <span class="equation-number">(8)</span>
        </div>
      </div>
      <p></p>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class="table-title">Statistic of used datasets.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:center;">Dataset - name</th>
              <th style="text-align:center;">original-dimension</th>
              <th style="text-align:center;">sketched-dimension</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:center;">Synthetic 1 - s1</td>
              <td style="text-align:center;">100</td>
              <td style="text-align:center;">70</td>
            </tr>
            <tr>
              <td style="text-align:center;">Synthetic 2 - s2</td>
              <td style="text-align:center;">100</td>
              <td style="text-align:center;">80</td>
            </tr>
          </tbody>
        </table>
      </div>
      <figure id="fig1">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191581/images/www18companion-320-fig1.jpg" class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class="figure-title">Mean regret obtained with compression ratio of 30%. On the left the mean regret obtained by the original contextual learner, on the right the one obtained by the sketched version.</span>
        </div>
      </figure>
      <figure id="fig2">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191581/images/www18companion-320-fig2.jpg" class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class="figure-title">Mean regret obtained with compression ratio of 20%. On the left the mean regret obtained by the original contextual learner, on the right the one obtained by the sketched version.</span>
        </div>
      </figure>
      <div class="table-responsive" id="tab2">
        <div class="table-caption">
          <span class="table-number">Table 2:</span> <span class="table-title">Policies performance measured as regret mean ± regret standard deviation.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:center;">Regret:</th>
              <th style="text-align:center;">LinUCB</th>
              <th style="text-align:center;">Sketched LinUCB</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:center;">s1</td>
              <td style="text-align:center;">1762.8480 ± 29.8683</td>
              <td style="text-align:center;">1936.7079 ± 36.0234</td>
            </tr>
            <tr>
              <td style="text-align:center;">s2</td>
              <td style="text-align:center;">1764.7769 ± 7.5479</td>
              <td style="text-align:center;">1864.7969 ± 13.9649</td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>The results are shown in Table <a class="tbl" href="#tab2">2</a> , and Figures &nbsp;<a class="fig" href="#fig1">1</a>,&nbsp;<a class="fig" href="#fig2">2</a>. In particular, we can notice that the empirical regret achieved by the sketched learner is close to the original one.</p>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Conclusions</h2>
        </div>
      </header>
      <p>We have initiated an investigation of approximation in contextual linear bandit algorithms operating in relevant scenarios where vendors acquire and maintain a large amount of content in their repository, or may be using a Reproduced Kernel Hilbert Space for storing similarities (which, theoretically, may have infinitely many feature dimensions). We have proposed the adoption of a deterministic sketching technique for compressing the original feature space. We carried out a preliminary experimental evaluation with very encouraging results by using high-dimensional artificially generated data. Future investigations regard the evaluation over real dataset, the study of the theoretical guarantees, and the adoption of size-adaptive sketching techniques as in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>].</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Li&nbsp;Zhou;&nbsp;Emma Brunskill. July 2016. Latent contextual bandits and their application to personalized recommendations for new users. In <em><em>IJCAI’16Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</em></em> . 3646–3653.</li>
        <li id="BibPLXBIB0002" label="[2]">Mattia Bianchi; Federico Cesaro; Filippo Ciceri; Mattia Dagrada; Alberto Gasparin; Daniele Grattarola; Ilyas Inajjar; Alberto Maria Metelli;&nbsp;Leonardo Cella. August 2017. Content-Based approaches for Cold-Start Job Recommendations. In <em><em>RecSys’17, Proceeding RecSys Challenge ’17 Proceedings of the Recommender Systems Challenge 2017</em></em> . <a class="link-inline force-break" href="https://doi.org/10.1145/3124791.3124793" target="_blank">https://doi.org/10.1145/3124791.3124793</a>
        </li>
        <li id="BibPLXBIB0003" label="[3]">Leonardo Cella; Romaric Gaudel;&nbsp;Paolo Cremonesi. August 2017. Kernalized Collaborative Contextual Bandits. In <em><em>In Proceedings of RecSys 2017 Posters</em></em> .</li>
        <li id="BibPLXBIB0004" label="[4]">Leonardo Cella; Stefano Cereda; Massimo Quadrana;&nbsp;Paolo Cremonesi. July 2017. Deriving Item Features Relevance from Past User Interactions. In <em><em>UMAP’17 Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization</em></em> . 275–279. <a class="link-inline force-break" href="https://doi.org/10.1145/3079628.3079695" target="_blank">https://doi.org/10.1145/3079628.3079695</a>
        </li>
        <li id="BibPLXBIB0005" label="[5]">Philippe&nbsp;Preux Cricia Z. Felicio; Klerisson V.R. Paixao; Celia A.Z.&nbsp;Barcelos. July 2017. A Multi-Armed Bandit Model Selection for Cold-Start User Recommendation. In <em><em>UMAP ’17 Proceedings of the 25th Conference on User Modeling, Adaptation and Personalization</em></em> . 32–40. <a class="link-inline force-break" href="https://doi.org/10.1145/3079628.3079681" target="_blank">https://doi.org/10.1145/3079628.3079681</a>
        </li>
        <li id="BibPLXBIB0006" label="[6]">Michal Valko; Nathaniel Korda; Remi Munos; Ilias Flaounas;&nbsp;Nelo Cristianini. August 2013. Finite-Time Analysis of Kernelised Contextual Bandits. In <em><em>UAI13 Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence</em></em> . 654–663.</li>
        <li id="BibPLXBIB0007" label="[7]">Shuai Li; Alexandros Karatzoglou;&nbsp;Claudio Gentile. July 2016. Collaborative Filtering Bandits. In <em><em>SIGIR ’16 Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</em></em> .</li>
        <li id="BibPLXBIB0008" label="[8]">Haipeng Luo; Alekh Agarwal; Nicolo Cesa-Bianchi;&nbsp;John Langford. December 2016. Efficient Second Order Online Learning by Sketching. In <em><em>NIPS’16 30th Conference on Neural Information Processing Systems</em></em> .</li>
        <li id="BibPLXBIB0009" label="[9]">Lihong Li and Robert E.&nbsp;Schapire Wei&nbsp;Chu, John&nbsp;Langford. April 2010. A contextual-bandit approach to personalized news article recommendation. In <em><em>WWW’10 Proceedings of the 19th international conference on World wide web</em></em> . 661–670. <a class="link-inline force-break" href="https://doi.org/10.1145/1772690.1772758" target="_blank">https://doi.org/10.1145/1772690.1772758</a>
        </li>
        <li id="BibPLXBIB0010" label="[10]">Branislav Kveton; Csaba Szepesvari; Anup Rao; Zheng Wen; Yasin Abbasi-Yadkori;&nbsp;S. Muthukrishnan. December 2017. Stochastic Low-Rank Bandits. In <em><em>arXiv:1712.04644</em></em> .</li>
        <li id="BibPLXBIB0011" label="[11]">James Bennett; Stan Lanning;&nbsp;Netflix Netflix. 2007. The Netflix Prize (2007). In <em><em>In KDD Cup and Workshop in conjunction with KDD</em></em> .</li>
        <li id="BibPLXBIB0012" label="[12]">Giovanni&nbsp;Zappella Nicolo Cesa-Bianchi, Claudio&nbsp;Gentile. December 2013. A Gang of Bandits. In <em><em>NIPS’13 Advances in Neural Information Processing Systems 26</em></em> . 737–745.</li>
        <li id="BibPLXBIB0013" label="[13]">Abhinandan S. Das; Mayur Datar; Ashutosh Garg;&nbsp;Shyam Rajaram. Google news personalization: scalable online collaborative filtering. In <em><em>WWW ’07 Proceedings of the 16th international conference on World Wide Web</em></em> . 271–280. <a class="link-inline force-break" href="https://doi.org/10.1145/1242572.1242610" target="_blank">https://doi.org/10.1145/1242572.1242610</a>
        </li>
        <li id="BibPLXBIB0014" label="[14]">Aris Anagnostopoulos; Andrei Z. Broder; Evgeniy Gabrilovich; Vanja Josifovski;&nbsp;Lance Riedel. Just-in-time contextual advertising. In <em><em>CIKM ’07 Proceedings of the sixteenth ACM conference on Conference on information and knowledge management</em></em> .</li>
        <li id="BibPLXBIB0015" label="[15]">Herbert Robbins. 1952. <em><em>Some aspects of the sequential design of experiments</em></em> . Vol.&nbsp;58. Bulletin of the American Mathematical Society, 527–535.</li>
        <li id="BibPLXBIB0016" label="[16]">Yasin Abbasi Yadkori; David Pal;&nbsp;Csaba Szepesvari. December 2011. Improved algorithms for linear stochastic bandits. In <em><em>NIPS’11 Proceedings of the 24th International Conference on Neural Information Processing Systems</em></em> .</li>
        <li id="BibPLXBIB0017" label="[17]">Daniele Calandriello; Alessandro Lazaric;&nbsp;Michal Valko. 2017. Second-Order Kernel Online Convex Optimization with Adaptive Sketching. In <em><em>ICML’17 Proceedings of the 34th International Conference on Machine Learning</em></em> .</li>
        <li id="BibPLXBIB0018" label="[18]">Paul Resnick; Hal&nbsp;R. Varian. March 2997. <em><em>Recommender Systems</em></em> . Vol.&nbsp;40. Magazine Communications of the ACM, 56–58. <a class="link-inline force-break" href="https://doi.org/10.1145/245108.245121" target="_blank">https://doi.org/10.1145/245108.245121</a>
        </li>
        <li id="BibPLXBIB0019" label="[19]">Mina Ghashami; Edo Liberty; Jeff M. Phillips; David&nbsp;P. Woodruff. September 2016. Frequent Directions: simple and deterministic matrix sketching. (September 2016).</li>
        <li id="BibPLXBIB0020" label="[20]">G.&nbsp;Linden ; B. Smith ;&nbsp;J. York. January 2003. Amazon.com recommendations: item-to-item collaborative filtering. In <em><em>IEEE Internet Computing</em></em> . 76 – 80. <a class="link-inline force-break" href="https://doi.org/10.1109/MIC.2003.1167344" target="_blank">https://doi.org/10.1109/MIC.2003.1167344</a>
        </li>
        <li id="BibPLXBIB0021" label="[21]">Aditya Gopalan; Odalric-Ambrym Maillard;&nbsp;Mohammadi Zaki. September 2016. Low-rank Bandits with Latent Mixtures. In <em><em>arXiv:1609.01508</em></em> .</li>
        <li id="BibPLXBIB0022" label="[22]">Claudio Gentile; Shuai Li;&nbsp;Giovanni Zappella. June 2014. Online clustering of bandits. In <em><em>ICML ’14 Proceedings of the 31st International Conference on International Conference on Machine Learning</em></em> . 757–765.</li>
        <li id="BibPLXBIB0023" label="[23]">Claudio Gentile; Shuai Li; Purushottam Kar; Alexandros Karatzoglou; Evans Etrue;&nbsp;Giovanni Zappella. February 2017. On Context-Dependent Clustering of Bandits. In <em><em>Proceedings of the 34th International Conference on Machine Learning</em></em> .</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International (CC-BY-NC-ND&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY-NC-ND&nbsp;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3184558.3191581">https://doi.org/10.1145/3184558.3191581</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
