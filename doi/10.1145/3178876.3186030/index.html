<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>CESI: Canonicalizing Open Knowledge Bases using Embeddings and Side Information</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
  <link rel="cite-as" href="https://doi.org/10.1145/3178876.3186030"/>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186030'>https://doi.org/10.1145/3178876.3186030</a>.
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186030'>https://w3id.org/oa/10.1145/3178876.3186030</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">CESI: Canonicalizing Open Knowledge Bases using Embeddings and Side Information</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <a href="https://orcid.org/0000-0002-6258-2494" ref="author"><span class="givenName">Shikhar</span> <span class="surName">Vashishth</span></a>, Indian Institute of Science, Bangalore, India, <a href="mailto:shikhar@iisc.ac.in">shikhar@iisc.ac.in</a>
        </div>
        <div class="author">
          <span class="givenName">Prince</span> <span class="surName">Jain,<a class="fn" href="#fn1" id="foot-fn1"><sup>*</sup></a></span> Microsoft, Bangalore, India, <a href="mailto:prince.jain@microsoft.com">prince.jain@microsoft.com</a>
        </div>
        <div class="author">
          <span class="givenName">Partha</span> <span class="surName">Talukdar</span>, Indian Institute of Science, Bangalore, India, <a href="mailto:ppt@iisc.ac.in">ppt@iisc.ac.in</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.3186030" target="_blank">https://doi.org/10.1145/3178876.3186030</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Open Information Extraction (OpenIE) methods extract <em>(noun phrase, relation phrase, noun phrase)</em> triples from text, resulting in the construction of large Open Knowledge Bases (Open KBs). The noun phrases (NPs) and relation phrases in such Open KBs are not <em>canonicalized</em>, leading to the storage of redundant and ambiguous facts. Recent research has posed canonicalization of Open KBs as clustering over <em>manually-defined</em> feature spaces. Manual feature engineering is expensive and often sub-optimal. In order to overcome this challenge, we propose Canonicalization using Embeddings and Side Information (CESI) – a novel approach which performs canonicalization over <em>learned</em> embeddings of Open KBs. CESI extends recent advances in KB embedding by incorporating relevant NP and relation phrase side information in a principled manner. Through extensive experiments on multiple real-world datasets, we demonstrate CESI's effectiveness.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS Concepts:</span> • <strong>Computing methodologies</strong> → <em>Knowledge representation and reasoning;</em> <em>Information extraction;</em></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style="font-weight:bold;"><small>Keywords:</small></span> <span class="keyword"><small>Canonicalization; Knowledge Graphs; Knowledge Graph Embeddings; Open Knowledge Bases</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Shikhar Vashishth, Prince Jain, and Partha Talukdar. 2018. CESI: Canonicalizing Open Knowledge Bases using Embeddings and Side Information. In <em>WWW 2018: The 2018 Web Conference,</em> <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New York, NY, USA</em> 10 Pages. <a href="https://doi.org/10.1145/3178876.3186030" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3178876.3186030</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <p>Recent research has resulted in the development of several large <em>Ontological</em> Knowledge Bases (KBs), examples include DBpedia [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>], YAGO [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0036">36</a>], and Freebase [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>]. These KBs are called ontological as the knowledge captured by them conform to a fixed ontology, i.e., pre-specified Categories (e.g., <em>person, city</em>) and Relations (e.g., <em>mayorOfCity(Person, City)</em>). Construction of such ontological KBs require significant human supervision. Moreover, due to the need for pre-specification of the ontology, such KB construction methods can't be quickly adapted to new domains and corpora. While other ontological KB construction approaches such as NELL [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>] learn from limited human supervision, they still suffers from the quick adaptation bottleneck.</p>
      <p>In contrast, Open Information Extraction (OpenIE) methods need neither supervision nor any pre-specified ontology. Given unstructured text documents, OpenIE methods readily extract triples of the form <em>(noun phrase, relation phrase, noun phrase)</em> from them, resulting in the development of large Open Knowledge Bases (Open KBs). Examples of Open KBs include TextRunner [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>], ReVerb [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>], and OLLIE [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0033">33</a>]. While this makes OpenIE methods highly adaptable, they suffer from the following shortcoming: unlike Ontological KBs, the Noun Phrases (NPs) and relation phrases in Open KBs are not <em>canonicalized</em>. This results in storage of redundant and ambiguous facts.</p>
      <p>Let us explain the need for canonicalization through a concrete example. Please consider the two sentences below.</p>
      <p><em>Barack Obama was the president of US.</em></p>
      <p><em>Obama was born in Honolulu.</em></p>
      <p>Given the two sentences above, an OpenIE method may extract the two triples below and store them in an Open KB.</p>
      <p><em>(Barack Obama, was president of, US)</em></p>
      <p><em>(Obama, born in, Honolulu)</em></p>
      <p>Unfortunately, neither such OpenIE methods nor the associated Open KBs have any knowledge that both <em>Barack Obama</em> and <em>Obama</em> refer to the same person. This can be a significant problem as Open KBs will not return all the facts associated with <em>Barack Obama</em> on querying for it. Such KBs will also contain redundant facts, which is undesirable. Thus, there is an urgent need to <em>canonicalize</em> noun phrases (NPs) and relations in Open KBs.</p>
      <p>In spite of its importance, canonicalization of Open KBs is a relatively unexplored problem. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>], canonicalization of Open KBs is posed as a clustering problem over <em>manually</em> defined feature representations. Given the costs and sub-optimality involved with manual feature engineering, and inspired by recent advances in knowledge base embedding [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>], we pose canonicalization of Open KBs as a clustering over <em>automatically learned</em> embeddings. We make the following contributions in this paper.</p>
      <ul class="list-no-style">
        <li id="list1" label="•">We propose Canonicalization using Embeddings and Side Information (CESI), a novel method for canonicalizing Open KBs using learned embeddings. To the best of our knowledge, this is the first approach to use learned embeddings and side information for canonicalizing an Open KB.<br /></li>
        <li id="list2" label="•">CESI models the problem of noun phrase (NP) and relation phrase canonicalization <em>jointly</em> using relevant side information in a principled manner. This is unlike prior approaches where NP and relation phrase canonicalization were performed sequentially.<br /></li>
        <li id="list3" label="•">We build and experiment with ReVerb45K, a new dataset for Open KB canonicalization. ReVerb45K consists of 20x more NPs than the previous biggest dataset for this task. Through extensive experiments on this and other real-world datasets, we demonstrate CESI's effectiveness (Section&nbsp;<a class="sec" href="#sec-12">7</a>).<br />
        </li>
      </ul>
      <p>CESI's source code and datasets used in the paper are available at <tt><a href="https://github.com/malllabiisc/cesi" target="_blank">https://github.com/malllabiisc/cesi</a></tt> .</p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related Work</h2>
        </div>
      </header>
      <p><strong>Entity Linking</strong>: One traditional approach to canonicalizing noun phrases is to map them to an existing KB such as Wikipedia or Freebase. This problem is known as Entity Linking (EL) or Named Entity Disambiguation (NED). Most approaches generate a list of candidate entities for each NP and re-rank them using machine learning techniques. Entity linking has been an active area of research in the NLP community [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0039">39</a>]. A major problem with these kind of approaches is that many NPs may refer to new and emerging entities which may not exist in KBs. One approach to resolve these noun phrases is to map them to NIL or an OOKB (Out of Knowledge Base) entity, but the problem still remains as to how to cluster these NIL mentions. Although entity linking is not the best approach to NP canonicalization, we still leverage signals from entity linking systems for improved canonicalization in CESI.</p>
      <p><strong>Canonicalization in Ontological KBs</strong>: Concept Resolver [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>] is used for clustering NP mentions in NELL [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>]. It makes “one sense per category” assumption which states that a noun phrase can refer to at most one concept in each category of NELL's ontology. For example, the noun phrase “Apple” can either refer to a company or a fruit, but it can refer to only one company and only one fruit. Another related problem to NP canonicalization is Knowledge Graph Identification [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0031">31</a>], where given a noisy extraction graph, the task is to produce a consistent Knowledge Graph (KG) by performing entity resolution, entity classification and link prediction jointly. Pujara et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0031">31</a>] incorporate information from multiple extraction sources and use ontological information to infer the most probable knowledge graph using probabilistic soft logic (PSL) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>]. However, both of these approaches require additional information in the form of an ontology of relations, which is not available in the Open KB setting.</p>
      <p><strong>Relation Taxonomy Induction</strong>: SICTF [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>] tries to learn relation schemas for different OpenIE relations. It is built up on RESCAL [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>], and uses tensor factorization methods to cluster noun phrases into <em>categories</em> (such as “person”, “disease”, etc.). We, however, are interested in clustering noun phrases into entities.</p>
      <p>There has been relatively less work on the task of relation phrase canonicalization. Some of the early works include DIRT [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>], which proposes an unsupervised method for discovering inference rules of the form “<em>X is the author of Y</em> ≈ <em>X wrote Y</em>” using paths in dependency trees; and the PATTY system [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0024">24</a>], which tries to learn subsumption rules among relations (such as <em>son-of</em> ⊂ <em>child-of</em>) using techniques based on frequent itemset mining. These approaches are more focused on finding a taxonomy of relation phrases, while we are looking at finding equivalence between relation phrases.</p>
      <p><strong>Knowledge Base Embedding</strong>: KB embedding techniques such as TransE [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>], HolE [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>] try to learn vector space embeddings for entities and relations present in a KB. TransE makes the assumption that for any <em>⟨subject, relation, object⟩</em> triple, the relation vector is a translation from the subject vector to the object vector. HolE, on the other hand, uses non-linear operators to model a triple. These embedding methods have been successfully applied for the task of link prediction in KBs. In this work, we build up on HolE while exploiting relevant side information for the task of Open KB canonicalization. We note that, even though KB embedding techniques like HolE have been applied to ontological KBs, CESI might be the first attempt to use them in the context of Open KBs.</p>
      <p><strong>Canonicalizing Open KBs</strong>: The RESOLVER system [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0042">42</a>] uses string similarity based features to cluster phrases in TextRunner [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>] triples. String similarity features, although being effective, fail to handle synonymous phrases which have completely different surface forms, such as <em>Myopia</em> and <em>Near-sightedness</em>.</p>
      <p>KB-Unify [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>] addresses the problem of unifying multiple Ontological and Open KBs into one KB. However, KB-Unify requires a pre-determined sense inventory which is not available in the setting CESI operates.</p>
      <p>The most closely related work to ours is [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]. They perform NP canonicalization by performing Hierarchical Agglomerative Clustering (HAC) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0038">38</a>] over manually-defined feature spaces, and subsequently perform relation phrase clustering by using the AMIE algorithm [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>]. CESI significantly outperforms this prior method (Section&nbsp;<a class="sec" href="#sec-12">7</a>).</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Proposed Approach: CESI</h2>
        </div>
      </header>
      <figure id="fig1">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186030/images/www2018-39-fig1.jpg" class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class="figure-title">Overview of CESI. CESI first acquires side information of noun and relation phrases of Open KB triples. In the second step, it learns embeddings of these NPs and relation phrases while utilizing the side information obtained in previous step. In the third step, CESI performs clustering over the learned embeddings to canonicalize NP and relation phrases. Please see Section&nbsp;<a class="sec" href="#sec-6">3</a> for more details.</span>
        </div>
      </figure>
      <p>Overall architecture and dataflow of CESI is shown in Figure <a class="fig" href="#fig1">1</a>. The input to CESI is an un-canonicalized Open Knowledge Base (KB) with source information for each triple. The output is a list of canonicalized noun and relation phrases, which can be used to identify equivalent entities and relations or canonicalize the KB. CESI achieves this through its three step procedure:</p>
      <ol class="list-no-style">
        <li id="list4" label="(1)">
          <strong>Side Information Acquisition:</strong> The goal of this step is to gather various NP and relation phrase side information for each triple in the input by running several standard algorithms on the source text of the triples. More details can be found in Section <a class="sec" href="#sec-7">4</a>.<br />
        </li>
        <li id="list5" label="(2)"><strong>Embedding NP and Relation Phrases:</strong> In this step, CESI learns specialized vector embeddings for all NPs and relation phrases in the input by making principled use of side information available from the previous step.<br /></li>
        <li id="list6" label="(3)"><strong>Clustering Embeddings and Canonicalization:</strong> Goal of this step is to cluster the NPs and relation phrases on the basis of their distance in the embedding space. Each cluster represents a specific entity or relation. Based on certain relevant heuristics, we assign a representative to each NP and relation phrase cluster.<br /></li>
      </ol>
      <p>Details of different steps of CESI are described next.</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Side Information Acquisition</h2>
        </div>
      </header>
      <p>Noun and relation phrases in Open KBs often have relevant side information in the form of useful context in the documents from which the triples were extracted. Sometimes, such information may also be present in other related KBs. Previous Open KB canonicalization methods [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>] ignored such available side information and performed canonicalization in isolation focusing only on the Open KB triples. CESI attempts to exploit such side information to further improve the performance on this problem. In CESI, we make use of five types of NP side information to get equivalence relations of the form <em>e</em> <sub>1</sub> ≡ <em>e</em> <sub>2</sub> between two entities <em>e</em> <sub>1</sub> and <em>e</em> <sub>2</sub>. Similarly, relation phrase side information is used to derive relation equivalence, <em>r</em> <sub>1</sub> ≡ <em>r</em> <sub>2</sub>. All equivalences are used as soft constraints in later steps of CESI (details in Section <a class="sec" href="#sec-10">5</a>).</p>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Noun Phrase side Information</h3>
          </div>
        </header>
        <p>In the present version of CESI, we make use of the following five types of NP side information:</p>
        <ol class="list-no-style">
          <li id="list7" label="(1)">
            <strong>Entity Linking</strong>: Given unstructured text, entity linking algorithms identify entity mentions and link them to Ontological KBs such as Wikipedia, Freebase etc. We make use of Stanford CoreNLP entity linker which is based on [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0035">35</a>] for getting NP to Wikipedia entity linking. Roughly, in about 30% cases, we get this information for NPs. If two NPs are linked to the same Wikipedia entity, we assume them to be equivalent as per this information. For example, <em>US</em> and <em>America</em> can get linked to the same Wikipedia entity <em>United_States</em>.<br />
          </li>
          <li id="list8" label="(2)">
            <strong>PPDB Information</strong>: We make use of PPDB 2.0 [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>], a large collection of paraphrases in English, for identifying equivalence relation among NPs. We first extracted high confidence paraphrases from the dataset while removing duplicates. Then, using union-find, we clustered all the equivalent phrases and randomly assigned a representative to each cluster. Using an index created over the obtained clusters, we find cluster representative for each NP. If two NPs have the same cluster representative then they are considered to be equivalent. NPs not present in the dataset are skipped. This information helps us identifying equivalence between NPs such as <em>management</em> and <em>administration</em>.<br />
          </li>
          <li id="list9" label="(3)">
            <strong>WordNet with Word-sense Disambiguation</strong>: Using word-sense disambiguation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>] with Wordnet [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0022">22</a>], we identify possible synsets for a given NP. If two NPs share a common synset, then they are marked as similar as per this side information. For example, <em>picture</em> and <em>image</em> can get linked to the same synset <em>visualize.v.01</em>.<br />
          </li>
          <li id="list10" label="(4)">
            <strong>IDF Token Overlap</strong>: NPs sharing infrequent terms give a strong indication of them referring to the same entity. For example, it is very likely for <em>Warren Buffett</em> and <em>Buffett</em> to refer to the same person. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>], IDF token overlap was found to be the most effective feature for canonicalization. We assign a score for every pair of NPs based on the standard IDF formula:
            <div class="table-responsive">
              <div class="display-equation">
                <span class="tex mytex">\[ score_{{idf}}(n, n^{\prime }) = \dfrac{\sum _{x \in w(n) \cap w(n^{\prime })}{\log {(1+f(x))^{-1}}}}{\sum _{x \in w(n) \cup w(n^{\prime })}{\log {(1+f(x))^{-1}}}} \]</span><br />
              </div>
            </div><br />
            Here, <em>w</em>(·) for a given NP returns the set of its terms, excluding stop words. <em>f</em>(·) returns the document frequency for a token.<br />
          </li>
          <li id="list11" label="(5)">
            <strong>Morph Normalization</strong>: We make use of multiple morphological normalization operations like tense removal, pluralization, capitalization and others as used in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>] for finding out equivalent NPs. We show in Section <a class="sec" href="#sec-22">8.2</a> that this information helps in improving performance.<br />
          </li>
        </ol>
      </section>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Relation Phrase Side Information</h3>
          </div>
        </header>
        <p>Similar to noun phrases, we make use of PPDB and WordNet side information for relation phrase canonicalization as well. Apart from these, we use the following two additional types of side information involving relation phrases.</p>
        <ol class="list-no-style">
          <li id="list12" label="(1)">
            <strong>AMIE Information</strong>: AMIE algorithm [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>] tries to learn implication rules between two relations <em>r</em> and <em>r</em>′ of the form <em>r</em>⇒<em>r</em>′. These rules are detected based on statistical rule mining, for more details refer [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]. It declares two relations <em>r</em> and <em>r</em>′ to be equivalent if both <em>r</em>⇒<em>r</em>′ and <em>r</em>′⇒<em>r</em> satisfy support and confidence thresholds. AMIE accepts a semi-canonicalized KB as input, i.e., a KB where NPs are already canonicalized. Since this is not the case with Open KBs, we first canonicalized NPs morphologically and then applied AMIE over the NP-canonicalized KB. We chose morphological normalization for this step as such normalization is available for all NPs, and also because we found this side information to be quite effective in large Open KBs.<br />
          </li>
          <li id="list13" label="(2)">
            <strong>KBP Information</strong>: Given unstructured text, Knowledge Base Population (KBP) systems detect relations between entities and link them to relations in standard KBs. For example, <em>“Obama was born in Honolulu”</em> contains <em>“was born in”</em> relation between <em>Obama</em> and <em>Honolulu</em>, which can be linked to <em>per:city_of_birth</em> relation in KBs. In CESI, we use Stanford KBP [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0037">37</a>] to categorize relations. If two relations fall in the same category, then they are considered equivalent as per this information.<br />
          </li>
        </ol>
        <p>The given list can be further extended based on the availability of other side information. For the experiments in this paper, we have used the above mentioned NP and relation phrase side information. Some of the equivalences derived from different side information might be erroneous, therefore, instead of using them as hard constraints, we try to use them as supplementary information as described in the next section. Even though side information might be available only for a small fraction of NPs and relation phrases, the hypothesis is that it will result in better overall canonicalization. We find this to be true, as shown in Section <a class="sec" href="#sec-18">8</a>.</p>
      </section>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Embedding NP and Relation Phrases</h2>
        </div>
      </header>
      <p>For learning embeddings of NPs and relation phrases in a given Open KB, CESI optimizes HolE's [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>] objective function along with terms for penalizing violation of equivalence conditions from the NP and relation phrase side information. Since the conditions from side information might be spurious, a factor (<em>λ</em> <sub>ent/rel, <em>θ</em></sub> ) is multiplied with each term, which acts as a hyper-parameter and is tuned on a held out validation set. We also keep a constant (<em>λ<sub>str</sub></em> ) with HolE objective function, to make selective use of structural information from KB for canonicalization. We choose HolE because it is one of the best performing KB embeddings techniques for tasks like link prediction in knowledge graphs. Since KBs store only true triples, we generate negative examples using local closed world heuristic [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>]. To keep the rank of true triples higher than the non-existing ones, we use pairwise ranking loss function. The final objective function is described below.</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation*} \begin{split} \min _{\Theta } &amp; \hspace{5.69054pt} \lambda _{str} \sum _{i \in D_+} \sum _{j \in D_-}{ \text{max} (0, \gamma + \sigma (\eta _j) - \sigma (\eta _i))} \\ &amp; + \sum _{\theta \in \mathscr{C}_{\text{ent}}} \dfrac{\lambda _{\text{ent}, \theta }}{|\mathcal {Z}_{\text{ent}, \theta }|} \sum _{v, v^{^{\prime }} \in \mathcal {Z}_{\text{ent}, \theta }}{\Vert e_v - e_{v^{^{\prime }}}\Vert ^2} \\ &amp; + \sum _{\phi \in \mathscr{C}_{\text{rel}}} \dfrac{\lambda _{\text{rel}, \phi }}{|\mathcal {Z}_{\text{rel}, \phi }|} \sum _{u, u^{^{\prime }} \in \mathcal {Z}_{\text{rel}, \phi }}{\Vert r_u - r_{u^{^{\prime }}}\Vert ^2} \\ &amp; + \lambda _{\text{reg}} \left(\sum _{v \in V} \Vert e_v\Vert ^2 + \sum _{r \in R} \Vert e_r\Vert ^2 \right). \end{split}\end{equation*}</span><br />
        </div>
      </div>
      <p>The objective function, consists of three main terms, along with one term for regularization. Optimization parameter, <em>Θ</em> = {<em>e<sub>v</sub></em> } <sub><em>v</em> ∈ <em>V</em></sub> ∪{<em>r<sub>u</sub></em> } <sub><em>u</em> ∈ <em>R</em></sub> , is the set of all NP (<em>e<sub>v</sub></em> ) and relation phrase (<em>r<sub>u</sub></em> ) <em>d</em>-dimensional embeddings, where, <em>V</em> and <em>R</em> denote the set of all NPs and relation phrases in the input. In the first term, <em>D</em> <sub>+</sub>, <em>D</em> <sub>−</sub> specify the set of positive and negative examples and <em>γ</em> &gt; 0 refers to the width of the margin [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>]. Further, <em>σ</em>(·) denotes the logistic function and for a triple <em>t<sub>i</sub></em> (<em>s</em>, <em>p</em>, <em>o</em>), <span class="inline-equation"><span class="tex">$\eta _i = r_p^T(e_s \star e_o)$</span></span> , where ⋆: <em>R<sup>d</sup></em> × <em>R<sup>d</sup></em> → <em>R<sup>d</sup></em> is the circular correlation operator defined as follows.</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\begin{align*} {[}a \star b]_{k} = \sum _{i=0}^{d-1} a_i b_{(k+i) \text{ mod} \hspace{2.84526pt} d}.\end{align*}</span><br />
        </div>
      </div>The first index of (<em>a</em>⋆<em>b</em>) measures the similarity between <em>a</em> and <em>b</em>, while other indices capture the interaction of features from <em>a</em> and <em>b</em>, in a particular order. Please refer to [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>] for more details.
      <p></p>
      <p>In the second and third terms, <span class="inline-equation"><span class="tex">$\mathscr{C}_{\text{ent}}$</span> and <span class="inline-equation"><span class="tex">$\mathscr{C}_{\text{rel}}$</span> are the collection of all types of NP and relation side information available from the previous step (Section <a class="sec" href="#sec-7">4</a>), i.e., <span class="inline-equation"><span class="tex">$\mathscr{C}_{\text{ent}}$</span> = {Entity Linking, PPDB, ..} and <span class="inline-equation"><span class="tex">$\mathscr{C}_{\text{rel}}$</span> = {AMIE, KBP, ..}. Further, <em>λ</em><sub>ent, <em>θ</em></sub> and <em>λ</em><sub>rel, <em>ϕ</em></sub> denote the constants associated with entity and relation side information. Their value is tuned using grid search on a held out validation set. The set of all equivalence conditions from a particular side information is denoted by <span class="inline-equation"><span class="tex">$\mathcal {Z}_{\text{ent}, \theta }$</span></span> and <span class="inline-equation"><span class="tex">$\mathcal {Z}_{\text{rel}, \phi }$</span></span> . The rationale behind putting these terms is to allow inclusion of side information while learning embeddings, by enforcing two NPs or relations close together if they are equivalent as per the available side information. Since the side information is available for a fraction of NPs and relation phrases in the input, including these terms in the objective does not slow down the training of embeddings significantly.</span></span></span></span></p>
      <p>The last term adds L2 regularization on the embeddings. All embeddings are initialized by averaging GloVe vectors [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0030">30</a>]. We use mini-batch gradient descent for optimization.</p>
    </section>
    <section id="sec-11">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Clustering Embeddings and Canonicalization</h2>
        </div>
      </header>
      <p>CESI clusters NPs and relation phrases by performing Hierarchical Agglomerative Clustering (HAC) using cosine similarity over the embeddings learned in the previous step (Section <a class="sec" href="#sec-10">5</a>). HAC was preferred over other clustering methods because the number of clusters are not known beforehand. Complete linkage criterion is used for calculating the similarity between intermediate clusters as it gives smaller sized clusters, compared to single and average linkage criterion. This is more reasonable for canonicalization problem, where cluster sizes are expected to be small. The threshold value for HAC was chosen based on held out validation dataset.</p>
      <p>The time complexity of HAC with complete linkage criterion is <em>O</em>(<em>n</em> <sup>2</sup>) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>]. For scaling up CESI to large knowledge graphs, one may go for modern variants of approximate Hierarchical clustering algorithms [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>] at the cost of some loss in performance.</p>
      <p>Finally, we decide a representative for each NP and relation phrase cluster. For each cluster, we compute a mean of all elements’ embeddings weighted by the frequency of occurrence of each element in the input. NP or relation phrase which lies closest to the weighted cluster mean is chosen as the representative of the cluster.</p>
    </section>
    <section id="sec-12">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span> Experimental Setup</h2>
        </div>
      </header>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">7.1</span> Datasets</h3>
          </div>
        </header>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class="table-title">Details of datasets used. ReVerb45K is the new dataset we propose in this paper. Please see Section&nbsp;<a class="sec" href="#sec-13">7.1</a> for details.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Datasets</th>
                <th style="text-align:center;"># Gold</th>
                <th style="text-align:center;">#NPs</th>
                <th style="text-align:center;">#Relations</th>
                <th style="text-align:center;">#Triples</th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">Entities</th>
                <th style="text-align:center;"></th>
                <th style="text-align:center;"></th>
                <th style="text-align:center;"></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">Base</td>
                <td style="text-align:center;">150</td>
                <td style="text-align:center;">290</td>
                <td style="text-align:center;">3K</td>
                <td style="text-align:center;">9K</td>
              </tr>
              <tr>
                <td style="text-align:center;">Ambiguous</td>
                <td style="text-align:center;">446</td>
                <td style="text-align:center;">717</td>
                <td style="text-align:center;">11K</td>
                <td style="text-align:center;">37K</td>
              </tr>
              <tr>
                <td style="text-align:center;">ReVerb45K</td>
                <td style="text-align:center;">7.5K</td>
                <td style="text-align:center;">15.5K</td>
                <td style="text-align:center;">22K</td>
                <td style="text-align:center;">45K</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>Statistics of the three datasets used in the experiments of this paper are summarized in Table&nbsp;<a class="tbl" href="#tab1">1</a>. We present below brief summary of each dataset.</p>
        <ol class="list-no-style">
          <li id="list14" label="(1)">
            <strong>Base and Ambiguous Datasets:</strong> We obtained the Base and Ambiguous datasets from the authors of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]. Base dataset was created by collecting triples containing 150 sampled Freebase entities that appear with at least two aliases in ReVerb Open KB. The same dataset was further enriched with mentions of homonym entities to create the Ambiguous dataset. Please see [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>] for more details.<br />
          </li>
          <li id="list15" label="(2)">
            <strong>ReVerb45K:</strong> This is the new Open KB canonicalization dataset we propose in this paper. ReVerb45K is a significantly extended version of the Ambiguous dataset, containing more than 20x NPs. ReVerb45K is constructed by intersecting information from the following three sources: ReVerb Open KB [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>], Freebase entity linking information from [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>], and Clueweb09 corpus [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>]. Firstly, for every triple in ReVerb, we extracted the source text from Clueweb09 corpus from which the triple was generated. In this process, we rejected triples for which we could not find any source text. Then, based on the entity linking information from [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>], we linked all subjects and objects of triples to their corresponding Freebase entities. If we could not find high confidence linking information for both subject and object in a triple, then it was rejected. Further, following the dataset construction procedure adopted by [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>], we selected triples associated with all Freebase entities with at least two aliases occurring as subject in our dataset. Through these steps, we obtained 45K high-quality triples which we used for evaluation. We call this resulting dataset ReVerb45K.<br />
            In contrast to Base and Ambiguous datasets, the number of entities, NPs and relation phrases in ReVerb45K are significantly larger. Please see Table&nbsp;<a class="tbl" href="#tab1">1</a> for a detailed comparison. This better mimics real-world KBs which tend to be sparse with very few edges per entity, as also observed by [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>].<br />
          </li>
        </ol>
        <p>For getting test and validation set for each dataset, we randomly sampled 20% Freebase entities and called all the triples associated with them as validation set and rest was used as the test set.</p>
      </section>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">7.2</span> Evaluation Metrics</h3>
          </div>
        </header>
        <p>Following [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>], we use macro-, micro- and pairwise metrics for evaluating Open KB canonicalization methods. We briefly describe below these metrics for completeness. In all cases, <em>C</em> denotes the clusters produced by the algorithm to be evaluated, and <em>E</em> denotes the gold standard clusters. In all cases, F1 measure is given as the harmonic mean of precision and recall.</p>
        <p><strong>Macro:</strong> Macro precision (<em>P</em> <sub>macro</sub>) is defined as the fraction of pure clusters in <em>C</em>, i.e., clusters in which all the NPs (or relations) are linked to the same gold entity (or relation). Macro recall (<em>R</em> <sub>macro</sub>) is calculated like macro precision but with the roles of <em>E</em> and <em>C</em> interchanged.</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray*} P_{\mathrm{macro}}(C, E) &amp;=&amp; \dfrac{|\lbrace c \in C:\exists e \in E : e \supseteq c\rbrace |}{|C|} \\R_{\mathrm{macro}}(C, E) &amp;=&amp; P_{\mathrm{macro}}(E, C)\end{eqnarray*}</span><br />
          </div>
        </div><strong>Micro:</strong> Micro precision (<em>P</em> <sub>micro</sub>) is defined as the purity of <em>C</em> clusters [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0020">20</a>] based on the assumption that the most frequent gold entity (or relation) in a cluster is correct. Micro recall (<em>R</em> <sub>micro</sub>) is defined similarly as macro recall.
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray*} P_{\mathrm{micro}}(C, E) &amp;=&amp; \dfrac{1}{N} \sum _{c \in C} \max _{e \in E} |c \cap e| \\R_{\mathrm{micro}}(C, E) &amp;=&amp; P_{\mathrm{micro}}(E, C)\end{eqnarray*}</span><br />
          </div>
        </div><strong>Pairwise:</strong> Pairwise precision (<em>P</em> <sub>pair</sub>) is measured as the ratio of the number of hits in <em>C</em> to the total possible pairs in <em>C</em>. Whereas, pairwise recall (<em>R</em> <sub>pair</sub>) is the ratio of number of hits in <em>C</em> to all possible pairs in <em>E</em>. A pair of elements in a cluster in <em>C</em> produce a hit if they both refer to the same gold entity (or relation).
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray*} P_{\mathrm{pair}}(C, E) &amp;=&amp; \dfrac{\sum _{c \in C}{|\lbrace (v,v^{\prime }) \in e, \exists e \in E, \forall (v,v^{\prime }) \in c\rbrace |}}{\sum _{c \in C}{{}^{|c|}C_{2}}} \\R_{\mathrm{pair}}(C, E) &amp;=&amp; \dfrac{\sum _{c \in C}{|\lbrace (v,v^{\prime }) \in e, \exists e \in E, \forall (v,v^{\prime }) \in c\rbrace |}}{\sum _{e \in E}{{}^{|e|}C_{2}}} \\\end{eqnarray*}</span><br />
          </div>
        </div>
        <p></p>
        <p>Let us illustrate these metrics through a concrete NP canonicalization example shown in Figure <a class="fig" href="#fig2">2</a>. In this Figure, we can see that only <em>c</em> <sub>2</sub> and <em>c</em> <sub>3</sub> clusters in C are pure because they contain mentions of only one entity, and hence, <span class="inline-equation"><span class="tex">$P_{\mathrm{macro}} = \frac{2}{3}$</span></span> . On the other hand, we have <em>e</em> <sub>1</sub> and <em>e</em> <sub>3</sub> as pure clusters if we interchange the roles of <em>E</em> and <em>C</em>. So, <span class="inline-equation"><span class="tex">$R_{\mathrm{macro}} = \frac{2}{3}$</span></span> in this case. For micro precision, we can see that <em>America</em>, <em>New York</em>, and <em>California</em> are the most frequent gold entities in <em>C</em> clusters. Hence, <span class="inline-equation"><span class="tex">$P_{\mathrm{micro}} = \frac{6}{7}$</span></span> . Similarly, <span class="inline-equation"><span class="tex">$R_{\mathrm{micro}} = \frac{6}{7}$</span></span> in this case. For pairwise analysis, we need to first calculate the number of hits in <em>C</em>. In <em>c</em> <sub>1</sub> we have 3 possible pairs out of which only 1, (<em>America, USA</em>) is a hit as they belong to same gold cluster <em>e</em> <sub>1</sub>. Similarly, we have 3 hits in <em>c</em> <sub>2</sub> and 0 hits in <em>c</em> <sub>3</sub>. Hence, <span class="inline-equation"><span class="tex">$P_{\mathrm{pair}} = \frac{4}{6}$</span></span> . To compute <em>R</em> <sub>pair</sub>, we need total number of pairwise decisions in <em>E</em>, which is 1 + 6 + 0 , thus, <span class="inline-equation"><span class="tex">$R_{\mathrm{pair}} = \frac{4}{7}$</span></span> . All the results are summarized in Table&nbsp;<a class="fig" href="#fig2">2</a>.</p>
        <figure id="fig2">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186030/images/www2018-39-fig2.jpg" class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span> <span class="figure-title">Top: Illustrative example for different evaluation metrics. <em>e<sub>i</sub></em> denotes actual clusters, whereas <em>c<sub>i</sub></em> denotes predicted clusters. Bottom: Metric results for the above example. Please see Section&nbsp;<a class="sec" href="#sec-14">7.2</a> for details.</span>
          </div>
        </figure>
        <p>For evaluating NP canonicalization, we use Macro, Micro and Pairwise F1 score. However, in the case of relations, where gold labels are not available, we use macro, micro and pairwise precision values based on the scores given by human judges.</p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class="table-title">NP Canonicalization Results. CESI outperforms all other methods across datasets (Best in 7 out of 9 cases. Section&nbsp;<a class="sec" href="#sec-20">8.1.1</a>)</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;">Method</th>
                <th style="text-align:center;" colspan="3">
                  Base Dataset
                  <hr />
                </th>
                <th style="text-align:center;" colspan="3">
                  Ambiguous Dataset
                  <hr />
                </th>
                <th style="text-align:center;" colspan="3">
                  ReVerb45K
                  <hr />
                </th>
                <th></th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">Macro</th>
                <th style="text-align:center;">Micro</th>
                <th style="text-align:center;">Pair.</th>
                <th style="text-align:center;">Macro</th>
                <th style="text-align:center;">Micro</th>
                <th style="text-align:center;">Pair.</th>
                <th style="text-align:center;">Macro</th>
                <th style="text-align:center;">Micro</th>
                <th style="text-align:center;">Pair.</th>
                <th>Row Average</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Morph Norm</td>
                <td style="text-align:center;">58.3</td>
                <td style="text-align:center;">88.3</td>
                <td style="text-align:center;">83.5</td>
                <td style="text-align:center;">49.1</td>
                <td style="text-align:center;">57.2</td>
                <td style="text-align:center;">70.9</td>
                <td style="text-align:center;">1.4</td>
                <td style="text-align:center;">77.7</td>
                <td style="text-align:center;">75.1</td>
                <td>62.3</td>
              </tr>
              <tr>
                <td style="text-align:left;">PPDB</td>
                <td style="text-align:center;">42.4</td>
                <td style="text-align:center;">46.9</td>
                <td style="text-align:center;">32.2</td>
                <td style="text-align:center;">37.3</td>
                <td style="text-align:center;">60.2</td>
                <td style="text-align:center;">69.3</td>
                <td style="text-align:center;">46.0</td>
                <td style="text-align:center;">45.4</td>
                <td style="text-align:center;">64.2</td>
                <td>49.3</td>
              </tr>
              <tr>
                <td style="text-align:left;">EntLinker</td>
                <td style="text-align:center;">54.9</td>
                <td style="text-align:center;">65.1</td>
                <td style="text-align:center;">75.2</td>
                <td style="text-align:center;">49.7</td>
                <td style="text-align:center;">83.2</td>
                <td style="text-align:center;">68.8</td>
                <td style="text-align:center;">62.8</td>
                <td style="text-align:center;">81.8</td>
                <td style="text-align:center;">80.4</td>
                <td>69.1</td>
              </tr>
              <tr>
                <td style="text-align:left;">Galárraga-StrSim</td>
                <td style="text-align:center;">88.2</td>
                <td style="text-align:center;">96.5</td>
                <td style="text-align:center;">97.7</td>
                <td style="text-align:center;">66.6</td>
                <td style="text-align:center;">85.3</td>
                <td style="text-align:center;">82.2</td>
                <td style="text-align:center;">69.9</td>
                <td style="text-align:center;">51.7</td>
                <td style="text-align:center;">0.5</td>
                <td>70.9</td>
              </tr>
              <tr>
                <td style="text-align:left;">Galárraga-IDF</td>
                <td style="text-align:center;">94.8</td>
                <td style="text-align:center;">97.9</td>
                <td style="text-align:center;">98.3</td>
                <td style="text-align:center;">67.9</td>
                <td style="text-align:center;">82.9</td>
                <td style="text-align:center;">79.3</td>
                <td style="text-align:center;">71.6</td>
                <td style="text-align:center;">50.8</td>
                <td style="text-align:center;">0.5</td>
                <td>71.5</td>
              </tr>
              <tr>
                <td style="text-align:left;">Galárraga-Attr</td>
                <td style="text-align:center;">76.1</td>
                <td style="text-align:center;">51.4</td>
                <td style="text-align:center;">18.1</td>
                <td style="text-align:center;"><strong>82.9</strong></td>
                <td style="text-align:center;">27.7</td>
                <td style="text-align:center;">8.4</td>
                <td style="text-align:center;"><strong>75.1</strong></td>
                <td style="text-align:center;">20.1</td>
                <td style="text-align:center;">0.2</td>
                <td>40.0</td>
              </tr>
              <tr>
                <td style="text-align:left;">GloVe</td>
                <td style="text-align:center;">95.7</td>
                <td style="text-align:center;">97.2</td>
                <td style="text-align:center;">91.1</td>
                <td style="text-align:center;">65.9</td>
                <td style="text-align:center;">89.9</td>
                <td style="text-align:center;">90.1</td>
                <td style="text-align:center;">56.5</td>
                <td style="text-align:center;">82.9</td>
                <td style="text-align:center;">75.3</td>
                <td>82.7</td>
              </tr>
              <tr>
                <td style="text-align:left;">HolE (Random)</td>
                <td style="text-align:center;">69.5</td>
                <td style="text-align:center;">91.3</td>
                <td style="text-align:center;">86.6</td>
                <td style="text-align:center;">53.3</td>
                <td style="text-align:center;">85.0</td>
                <td style="text-align:center;">75.1</td>
                <td style="text-align:center;">5.4</td>
                <td style="text-align:center;">74.6</td>
                <td style="text-align:center;">50.9</td>
                <td>65.7</td>
              </tr>
              <tr>
                <td style="text-align:left;">HolE (GloVe)</td>
                <td style="text-align:center;">75.2</td>
                <td style="text-align:center;">93.6</td>
                <td style="text-align:center;">89.3</td>
                <td style="text-align:center;">53.9</td>
                <td style="text-align:center;">85.4</td>
                <td style="text-align:center;">76.7</td>
                <td style="text-align:center;">33.5</td>
                <td style="text-align:center;">75.8</td>
                <td style="text-align:center;">51.0</td>
                <td>70.4</td>
              </tr>
              <tr>
                <td style="text-align:left;">CESI</td>
                <td style="text-align:center;"><strong>98.2</strong></td>
                <td style="text-align:center;"><strong>99.8</strong></td>
                <td style="text-align:center;"><strong>99.9</strong></td>
                <td style="text-align:center;">66.2</td>
                <td style="text-align:center;"><strong>92.4</strong></td>
                <td style="text-align:center;"><strong>91.9</strong></td>
                <td style="text-align:center;">62.7</td>
                <td style="text-align:center;"><strong>84.4</strong></td>
                <td style="text-align:center;"><strong>81.9</strong></td>
                <td><strong>86.3</strong></td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">7.3</span> Methods Compared</h3>
          </div>
        </header>
        <section id="sec-16">
          <header>
            <div class="title-info">
              <h4><span class="section-number">7.3.1</span> <strong>Noun Phrase Canonicalization</strong></h4>
            </div>
          </header>
          <p>For NP canonicalization, CESI has been compared against the following methods:</p>
          <ul class="list-no-style">
            <li id="list16" label="•">
              <strong>Morphological Normalization:</strong> As used in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>], this involves applying simple normalization operations like removing tense, pluralization, capitalization etc. over NPs and relation phrases.<br />
            </li>
            <li id="list17" label="•">
              <strong>Paraphrase Database (PPDB):</strong> Using PPDB 2.0 [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>], we clustered two NPs together if they happened to share a common paraphrase. NPs which could not be found in PPDB are put into singleton clusters.<br />
            </li>
            <li id="list18" label="•">
              <strong>Entity Linking</strong>: Since the problem of NP canonicalization is closely related to entity linking, we compare our method against Stanford CoreNLP Entity Linker [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0035">35</a>]. Two NPs linked to the same entity are clustered together.<br />
            </li>
            <li id="list19" label="•">
              <strong>Galárraga-IDF [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]</strong>: IDF Token Overlap was the best performing method proposed in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>] for NP canonicalization. In this method, IDF token similarity is defined between two NPs as in Section&nbsp;<a class="sec" href="#sec-8">4.1</a>, and HAC is used to cluster the mentions.<br />
            </li>
            <li id="list20" label="•">
              <strong>Galárraga-StrSim [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]</strong>: This method is similar to Galarraga-IDF, but with similarity metric being the Jaro-Winkler [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0041">41</a>] string similarity measure.<br />
            </li>
            <li id="list21" label="•">
              <strong>Galárraga-Attr [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]</strong>: Again, this method is similar to the Galarraga-IDF, except that Attribute Overlap is used as the similarity metric between two NPs in this case. Attribute for a NP <em>n</em>, is defined as the set of relation-NP pairs which co-occur with <em>n</em> in the input triples. Attribute overlap similarity between two NPs, is defined as the Jaccard coefficient of the set of attributes:
              <div class="table-responsive">
                <div class="display-equation">
                  <span class="tex mytex">\[ f_{\text{attr}}(n,n^{\prime }) = \dfrac{|A \cap A^{\prime }|}{|A \cup A^{\prime }|} \]</span><br />
                </div>
              </div>where, <em>A</em> and <em>A</em>′ denote the set of attributes associated with <em>n</em> and <em>n</em>′.<br />
              Since canonicalization methods using above similarity measures were found to be most effective in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>], even outperforming Machine Learning-based alternatives, we consider these three baselines as representatives of state-of-the-art in Open KB canonicalization.<br />
            </li>
            <li id="list22" label="•">
              <strong>GloVe</strong>: In this scheme, each NP and relation phrase is represented by a 300 dimensional GloVe embedding [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0030">30</a>] trained on Wikipedia 2014 and Gigaword 5 [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>] datasets with 400k vocabulary size. Word vectors were averaged together to get embeddings for multi-word phrases. These GloVE embeddings were then clustered for final canonicalization.<br />
            </li>
            <li id="list23" label="•">
              <strong>HolE</strong>: In this method, embeddings of NPs and relation phrases in an Open KB are obtained by applying HolE [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>] over the Open KB. These embeddings are then clustered to obtain the final canonicalized groupings. Based on the initialization of embeddings, we differentiate between <strong>HolE(Random)</strong> and <strong>HolE(GloVe)</strong>.<br />
            </li>
            <li id="list24" label="•">
              <strong>CESI</strong>: This is the method proposed in this paper, please see Section&nbsp;<a class="sec" href="#sec-6">3</a> for more details.<br />
            </li>
          </ul>
          <p><strong>Hyper-parameters</strong>: Following [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>], we used Hierarchical Agglomerative Clustering (HAC) as the default clustering method across all methods (wherever necessary). For all methods, grid search over the hyperparameter space was performed, and results for the best performing setting are reported. This process was repeated for each dataset.</p>
        </section>
        <section id="sec-17">
          <header>
            <div class="title-info">
              <h4><span class="section-number">7.3.2</span> <strong>Relation Phrase Canonicalization</strong></h4>
            </div>
          </header>
          <p>AMIE [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>] was found to be effective for relation phrase canonicalization in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]. We thus consider AMIE<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a> as the state-of-the-art baseline for relation phrase canonicalization and compare against CESI. We note that AMIE requires NPs of the input Open KB to be already canonicalized. In all our evaluation datasets, we already have <em>gold</em> NP canonicalization available. We provide this gold NP canonicalization information as input to AMIE. Please note that CESI doesn't require such pre-canonicalized NP as input, as it performs <em>joint</em> NP and relation phrase canonicalization. Moreover, providing gold NP canonicalization information to AMIE puts CESI at a disadvantage. We decided to pursue this choice anyways in the interest of stricter evaluation. However, in spite of starting from this disadvantageous position, CESI significantly outperforms AMIE in relation phrase canonicalization, as we will see in Section&nbsp;<a class="sec" href="#sec-21">8.1.2</a>.</p>
          <p>For evaluating performance of both algorithms, we randomly sampled 25 non-singleton relation clusters for each of the three datasets and gave them to five different human evaluators<a class="fn" href="#fn3" id="foot-fn3"><sup>2</sup></a> for assigning scores to each cluster. The setting was kept blind, i.e., identity of the algorithm producing a cluster was not known to the evaluators. Based on the average of evaluation scores, precision values were calculated. Only non-singleton clusters were sampled, as singleton clusters will always give a precision of one.</p>
        </section>
      </section>
    </section>
    <section id="sec-18">
      <header>
        <div class="title-info">
          <h2><span class="section-number">8</span> Results</h2>
        </div>
      </header>
      <p>In this section, we evaluate the following questions.</p>
      <ul class="list-no-style">
        <li id="uid43" label="Q1.">Is CESI effective in Open KB canonicalization? (Section&nbsp;<a class="sec" href="#sec-19">8.1</a>)<br />
        </li>
        <li id="uid44" label="Q2.">What is the effect of side information in CESI's performance? (Section&nbsp;<a class="sec" href="#sec-22">8.2</a>)<br />
        </li>
        <li id="uid45" label="Q3.">Does addition of entity linking side information degrade CESI's ability to canonicalize unlinked NPs (i.e., NPs missed by the entity linker)? (Section&nbsp;<a class="sec" href="#sec-23">8.3</a>)<br />
        </li>
      </ul>
      <p>Finally, in Section&nbsp;<a class="sec" href="#sec-24">8.4</a>, we present qualitative examples and discussions.</p>
      <section id="sec-19">
        <header>
          <div class="title-info">
            <h3><span class="section-number">8.1</span> Evaluating Effectiveness of CESI in Open KB Canonicalization</h3>
          </div>
        </header>
        <section id="sec-20">
          <header>
            <div class="title-info">
              <h4><span class="section-number">8.1.1</span> <strong>Noun Phrase Canonicalization</strong></h4>
            </div>
          </header>
          <p>Results for NP canonicalization are summarized in Table&nbsp;<a class="tbl" href="#tab2">2</a>. Overall, we find that CESI performs well consistently across the datasets. Morphological Normalization failed to give competitive performance in presence of homonymy. PPDB, in spite of being a vast reservoir of paraphrases, lacks information about real-world entities like people, places etc. Therefore, its performance remained weak throughout all datasets. Entity linking methods make use of contextual information from source text of each triple to link a NP to a KB entity. But their performance is limited because they are restricted by the entities in KB. String similarity also gave decent performance in most cases but since they solely rely on surface form of NPs, they are bound to fail with NPs having dissimilar mentions.</p>
          <p>Methods such as Galárraga-IDF, Galárraga-StrSim, and Galárraga-Attr performed poorly on ReVerb45K. Although, their performance is considerably better on the other two datasets. This is because of the fact that in contrast to Base and Ambiguous datasets, ReVerb45K has considerably large number of entities and comparatively fewer triples (Table&nbsp;<a class="tbl" href="#tab1">1</a>). Galárraga-IDF token overlap is more likely to put two NPs together if they share an uncommon token, i.e., one with high IDF value. Hence, accuracy of the method relies heavily on the quality of document frequency estimates which may be quite misleading when we have smaller number of triples. Similar is the case with Galárraga-Attr which decides similarity of NPs based on the set of shared attributes. Since, attributes for a NP is defined as a set of relation-NP pairs occurring with it across all triples, sparse data also results in poor performance for this method.</p>
          <p>GloVe captures semantics of NPs and unlike string similarity it doesn't rely on the surface form of NPs. Therefore, its performance has been substantial across all the datasets. HolE captures structural information from the given triples and uses it for learning embeddings. Through our experiments, we can see that solely structural information from KB is quite effective for NP canonicalization. CESI performs the best across the datasets in 7 out of the 9 settings, as it incorporates the strength of all the listed methods. The superior performance of CESI compared to HolE clearly indicates that the side information is indeed helpful for canonicalization task. Results of GloVe, HolE and CESI suggest that embeddings based method are much more effective for Open KB canonicalization.</p>
          <div class="table-responsive" id="tab3">
            <div class="table-caption">
              <span class="table-number">Table 3:</span> <span class="table-title">Relation canonicalization results. Compared to AMIE, CESI canonicalizes more number of relation phrases at higher precision. Please see Section&nbsp;<a class="sec" href="#sec-21">8.1.2</a> for details.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;">Macro</th>
                  <th style="text-align:center;">Micro</th>
                  <th style="text-align:center;">Pairwise</th>
                  <th style="text-align:center;">Induced</th>
                </tr>
                <tr>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;">Precision</th>
                  <th style="text-align:center;">Precision</th>
                  <th style="text-align:center;">Precision</th>
                  <th style="text-align:center;">Relation</th>
                </tr>
                <tr>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;">Clusters</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="5" style="text-align:center;"><strong>Base Dataset</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;">AMIE</td>
                  <td style="text-align:center;">42.8</td>
                  <td style="text-align:center;">63.6</td>
                  <td style="text-align:center;">43.0</td>
                  <td style="text-align:center;">7</td>
                </tr>
                <tr>
                  <td style="text-align:center;">CESI</td>
                  <td style="text-align:center;"><strong>88.0</strong></td>
                  <td style="text-align:center;"><strong>93.1</strong></td>
                  <td style="text-align:center;"><strong>88.1</strong></td>
                  <td style="text-align:center;"><strong>210</strong></td>
                </tr>
                <tr>
                  <td colspan="5" style="text-align:center;"><strong>Ambiguous Dataset</strong> <!--hr/--></td>
                </tr>
                <tr>
                  <td style="text-align:center;">AMIE</td>
                  <td style="text-align:center;">55.8</td>
                  <td style="text-align:center;">64.6</td>
                  <td style="text-align:center;">23.4</td>
                  <td style="text-align:center;">46</td>
                </tr>
                <tr>
                  <td style="text-align:center;">CESI</td>
                  <td style="text-align:center;"><strong>76.0</strong></td>
                  <td style="text-align:center;"><strong>91.9</strong></td>
                  <td style="text-align:center;"><strong>80.9</strong></td>
                  <td style="text-align:center;"><strong>952</strong></td>
                </tr>
                <tr>
                  <td colspan="5" style="text-align:center;"><strong>ReVerb45K</strong> <!--hr/--></td>
                </tr>
                <tr>
                  <td style="text-align:center;">AMIE</td>
                  <td style="text-align:center;">69.3</td>
                  <td style="text-align:center;">84.2</td>
                  <td style="text-align:center;">66.2</td>
                  <td style="text-align:center;">51</td>
                </tr>
                <tr>
                  <td style="text-align:center;">CESI</td>
                  <td style="text-align:center;"><strong>77.3</strong></td>
                  <td style="text-align:center;"><strong>87.8</strong></td>
                  <td style="text-align:center;"><strong>72.6</strong></td>
                  <td style="text-align:center;"><strong>2116</strong></td>
                </tr>
              </tbody>
            </table>
          </div>
        </section>
        <section id="sec-21">
          <header>
            <div class="title-info">
              <h4><span class="section-number">8.1.2</span> <strong>Relation Phrase Canonicalization</strong></h4>
            </div>
          </header>
          <p>Results for relation phrase canonicalization are presented in Table&nbsp;<a class="tbl" href="#tab3">3</a>. For all experiments, in spite of using quite low values for minimum support and confidence, AMIE was unable to induce any reasonable number of non-singleton clusters (e.g., only 51 clusters out of the 22K relation phrases in the ReVerb45K dataset). For relation canonicalization experiments, AMIE was evaluated on gold NP canonicalized data as the algorithm requires NPs to be already canonicalized. CESI, on the other hand, was tested on all the datasets without making use of gold NP canonicalization information.</p>
          <p>Based on the results in Table&nbsp;<a class="tbl" href="#tab3">3</a>, it is quite evident that AMIE induces too few relation clusters to be of value in practical settings. On the other hand, CESI consistently performs well across all the datasets and induces significantly larger number of clusters.</p>
        </section>
      </section>
      <section id="sec-22">
        <header>
          <div class="title-info">
            <h3><span class="section-number">8.2</span> Effect of Side Information in CESI</h3>
          </div>
        </header>
        <figure id="fig3">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186030/images/www2018-39-fig3.jpg" class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span> <span class="figure-title">Performance comparison of various side information-ablated versions of CESI for NP canonicalization in the ReVerb45K dataset. Overall, side information helps CESI improve performance. Please see Section&nbsp;<a class="sec" href="#sec-22">8.2</a> for details.</span>
          </div>
        </figure>
        <p>In this section, we evaluate the effect of various side information in CESI's performance. For this, we evaluated the performances of various versions of CESI, each one of them obtained by ablating increasing amounts of side information from the full CESI model. Experimental results comparing these ablated versions on the ReVerb45K are presented in Figure&nbsp;<a class="fig" href="#fig3">3</a>. From this figure, we observe that while macro performance benefits most from different forms of side information, micro and pairwise performance also show increased performance in the presence of various side information. This validates one of the central thesis of this paper: side information, along with embeddings, can result in improved Open KB canonicalization.</p>
        <div class="table-responsive" id="tab4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class="table-title">CESI's performance in canonicalizing unlinked NPs, with and without Entity Linking (EL) side information, in the ReVerb45K dataset. We observe that CESI does not overfit to EL side information, and thereby helps prevent performance degradation in unlinked NP canonicalization (in fact it even helps a little). Please see Section&nbsp;<a class="sec" href="#sec-23">8.3</a> for details.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">Macro F1</th>
                <th style="text-align:center;">Micro F1</th>
                <th style="text-align:center;">Pairwise F1</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">CESI</td>
                <td style="text-align:center;">81.7</td>
                <td style="text-align:center;">87.6</td>
                <td style="text-align:center;">81.5</td>
              </tr>
              <tr>
                <td style="text-align:left;">CESI w/o EL</td>
                <td style="text-align:center;">81.3</td>
                <td style="text-align:center;">87.3</td>
                <td style="text-align:center;">80.7</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-23">
        <header>
          <div class="title-info">
            <h3><span class="section-number">8.3</span> Effect of Entity Linking Side Information on Unlinked NP Canonicalization</h3>
          </div>
        </header>
        <p>From experiments in Section&nbsp;<a class="sec" href="#sec-22">8.2</a>, we find that Entity Linking (EL) side information (see Section&nbsp;<a class="sec" href="#sec-8">4.1</a>) is one of the most useful side information that CESI exploits. However, such side information is not available in case of unlinked NPs, i.e., NPs which were not linked by the entity linker. So, this naturally raises the following question: does CESI overfit to the EL side information and ignore the unlinked NPs, thereby resulting in poor canonicalization of such unlinked NPs?</p>
        <p>In order to evaluate this question, we compared CESI's performance on unlinked NPs in the ReVerb45K dataset, with and without EL side information. We note that triples involving unlinked NPs constitute about 25% of the entire dataset. Results are presented in Table&nbsp;<a class="tbl" href="#tab4">4</a>. From this table, we observe that CESI doesn't overfit to EL side information, and it selectively uses such information when appropriate (i.e., for linked NPs). Because of this robust nature, presence of EL side information in CESI doesn't have an adverse effect on the unlinked NPs, in fact there is a small gain in performance.</p>
        <figure id="fig4">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186030/images/www2018-39-fig4.jpg" class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span> <span class="figure-title">t-SNE visualization of NP and relation phrase (marked in ’ &lt; ⋅⋅⋅ &gt; ’) embeddings learned by CESI for ReVerb45K dataset. We observe that CESI is able to induce non-trivial canonical clusters. Please see Section&nbsp;<a class="sec" href="#sec-24">8.4</a> for details.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-24">
        <header>
          <div class="title-info">
            <h3><span class="section-number">8.4</span> Qualitative Evaluation</h3>
          </div>
        </header>
        <p>Figure <a class="fig" href="#fig4">4</a> shows some of the NP and relation phrase clusters detected by CESI in ReVerb45K dataset. These results highlight the efficacy of algorithm in canonicalizing non-trivial NPs and relation phrases. The figure shows t-SNE [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0040">40</a>] visualization of NP and relation phrase (marked in ’ &lt; ⋅⋅⋅ &gt; ’) embeddings for a few examples. We can see that the learned embeddings are actually able to capture equivalence of NPs and relation phrases. The algorithm is able to correctly embed <em>Prozac</em>, <em>Sarafem</em> and <em>Fluoxetine</em> together (different names of the same drug), despite their having completely different surface forms.</p>
        <p>Figure <a class="fig" href="#fig4">4</a> also highlights the failures of CESI. For example, <em>Toyota</em> and <em>Nissan</em> have been embedded together although the two being different companies. Another case is with <em>Pablo</em> and <em>Juan Pablo Angel</em>, which refer to different entities. The latter case can be avoided by keeping track of the source domain type information of each NP for disambiguation. In this if we know that <em>Juan Pablo Angel</em> has come from <em>SPORTS</em> domain, whereas <em>Pablo</em> has come from a different domain then we can avoid putting them together. We tried using DMOZ [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0034">34</a>] dataset, which provide mapping from URL domain to their categories, for handling such errors. But, because of poor coverage of URLs in DMOZ dataset, we couldn't get significant improvement in canonicalization results. We leave this as a future work.</p>
      </section>
    </section>
    <section id="sec-25">
      <header>
        <div class="title-info">
          <h2><span class="section-number">9</span> Conclusion</h2>
        </div>
      </header>
      <p>Canonicalizing Open Knowledge Bases (KBs) is an important but underexplored problem. In this paper, we proposed CESI, a novel method for canonicalizing Open KBs using learned embeddings and side information. CESI solves a joint objective to learn noun and relation phrase embeddings, while utilizing relevant side information in a principled manner. These learned embeddings are then clustered together to obtain canonicalized noun and relation phrase clusters. In this paper, we also propose ReVerb45K, a new and larger dataset for Open KB canonicalization. Through extensive experiments on this and other real-world datasets, we demonstrate CESI's effectiveness over state-of-the-art baselines. CESI's source code and all data used in the paper are publicly available<a class="fn" href="#fn4" id="foot-fn4"><sup>3</sup></a>.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="sec-26">
      <header>
        <div class="title-info">
          <h2>ACKNOWLEDGMENTS</h2>
        </div>
      </header>
      <p>We thank the reviewers for their constructive comments. This work is supported in part by MHRD, Govt. of India, and by gifts from Google Research and Accenture. We thank Anand Mishra and other members of MALL Lab, IISc for carefully reading drafts of this paper.</p>
    </section>
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. DBpedia: A Nucleus for a Web of Open Data. In <em><em>Proceedings of the 6th International The Semantic Web and 2Nd Asian Conference on Asian Semantic Web Conference</em></em> (ISWC’07/ASWC’07). Springer-Verlag, Berlin, Heidelberg, 722–735. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=1785162.1785216" target="_blank">http://dl.acm.org/citation.cfm?id=1785162.1785216</a>
        </li>
        <li id="BibPLXBIB0002" label="[2]">Satanjeev Banerjee and Ted Pedersen. 2002. <em><em>An Adapted Lesk Algorithm for Word Sense Disambiguation Using WordNet</em></em> . Springer Berlin Heidelberg, Berlin, Heidelberg, 136–145. <a class="link-inline force-break" href="https://doi.org/10.1007/3-540-45715-1_11" target="_blank">https://doi.org/10.1007/3-540-45715-1_11</a>
        </li>
        <li id="BibPLXBIB0003" label="[3]">Michele Banko, Michael&nbsp;J. Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2007. Open Information Extraction from the Web. In <em><em>Proceedings of the 20th International Joint Conference on Artifical Intelligence</em></em> .</li>
        <li id="BibPLXBIB0004" label="[4]">Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge. In <em><em>Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data</em></em> (SIGMOD ’08). ACM, New York, NY, USA, 1247–1250. <a class="link-inline force-break" href="https://doi.org/10.1145/1376616.1376746" target="_blank">https://doi.org/10.1145/1376616.1376746</a>
        </li>
        <li id="BibPLXBIB0005" label="[5]">Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating Embeddings for Modeling Multi-relational Data. In <em><em>Advances in Neural Information Processing Systems 26</em></em> , C.&nbsp;J.&nbsp;C. Burges, L.&nbsp;Bottou, M.&nbsp;Welling, Z.&nbsp;Ghahramani, and K.&nbsp;Q. Weinberger (Eds.). Curran Associates, Inc., 2787–2795. <a class="link-inline force-break" href="http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf" target="_blank">http://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.pdf</a>
        </li>
        <li id="BibPLXBIB0006" label="[6]">Matthias Bröcheler, Lilyana Mihalkova, and Lise Getoor. 2010. Probabilistic Similarity Logic. In <em><em>Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence</em></em> (UAI’10). AUAI Press, Arlington, Virginia, United States, 73–82. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=3023549.3023558" target="_blank">http://dl.acm.org/citation.cfm?id=3023549.3023558</a>
        </li>
        <li id="BibPLXBIB0007" label="[7]">Jamie Callan, Mark Hoy, Changkuk Yoo, and Le Zhao. 2009. Clueweb09 data set. (2009).</li>
        <li id="BibPLXBIB0008" label="[8]">Janara Christensen, Mausam, Stephen Soderland, and Oren Etzioni. 2011. An Analysis of Open Information Extraction Based on Semantic Role Labeling. In <em><em>Proceedings of the Sixth International Conference on Knowledge Capture</em></em> (K-CAP ’11). ACM, New York, NY, USA, 113–120. <a class="link-inline force-break" href="https://doi.org/10.1145/1999676.1999697" target="_blank">https://doi.org/10.1145/1999676.1999697</a>
        </li>
        <li id="BibPLXBIB0009" label="[9]">Daniel Defays. 1977. An efficient algorithm for a complete link method. <em><em>Comput. J.</em></em> 20, 4 (1977), 364–366.</li>
        <li id="BibPLXBIB0010" label="[10]">Claudio Delli Bovi, Luis Espinosa Anke, and Roberto Navigli. 2015. Knowledge Base Unification via Sense Embeddings and Disambiguation. In <em><em>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</em></em> . Association for Computational Linguistics, Lisbon, Portugal, 726–736. <a class="link-inline force-break" href="http://aclweb.org/anthology/D15-1084" target="_blank">http://aclweb.org/anthology/D15-1084</a>
        </li>
        <li id="BibPLXBIB0011" label="[11]">Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014. Knowledge Vault: A Web-scale Approach to Probabilistic Knowledge Fusion. In <em><em>Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em></em> (KDD ’14). ACM, New York, NY, USA, 601–610. <a class="link-inline force-break" href="https://doi.org/10.1145/2623330.2623623" target="_blank">https://doi.org/10.1145/2623330.2623623</a>
        </li>
        <li id="BibPLXBIB0012" label="[12]">Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying Relations for Open Information Extraction. In <em><em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em></em> (EMNLP ’11). Association for Computational Linguistics, Stroudsburg, PA, USA, 1535–1545. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=2145432.2145596" target="_blank">http://dl.acm.org/citation.cfm?id=2145432.2145596</a>
        </li>
        <li id="BibPLXBIB0013" label="[13]">Evgeniy Gabrilovich, Michael Ringgaard, and Amarnag Subramanya. 2013. FACC1: Freebase annotation of ClueWeb corpora, Version 1. <em><em>Release date</em></em> (2013), 06–26.</li>
        <li id="BibPLXBIB0014" label="[14]">Luis Galárraga, Geremy Heitz, Kevin Murphy, and Fabian&nbsp;M. Suchanek. 2014. Canonicalizing Open Knowledge Bases. In <em><em>Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management</em></em> (CIKM ’14). ACM, New York, NY, USA, 1679–1688. <a class="link-inline force-break" href="https://doi.org/10.1145/2661829.2662073" target="_blank">https://doi.org/10.1145/2661829.2662073</a>
        </li>
        <li id="BibPLXBIB0015" label="[15]">Luis&nbsp;Antonio Galárraga, Christina Teflioudi, Katja Hose, and Fabian Suchanek. 2013. AMIE: Association Rule Mining Under Incomplete Evidence in Ontological Knowledge Bases. In <em><em>Proceedings of the 22Nd International Conference on World Wide Web</em></em> (WWW ’13). ACM, New York, NY, USA, 413–422. <a class="link-inline force-break" href="https://doi.org/10.1145/2488388.2488425" target="_blank">https://doi.org/10.1145/2488388.2488425</a>
        </li>
        <li id="BibPLXBIB0016" label="[16]">Ari Kobren, Nicholas Monath, Akshay Krishnamurthy, and Andrew McCallum. 2017. A Hierarchical Algorithm for Extreme Clustering. In <em><em>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em></em> (KDD ’17). ACM, New York, NY, USA, 255–264. <a class="link-inline force-break" href="https://doi.org/10.1145/3097983.3098079" target="_blank">https://doi.org/10.1145/3097983.3098079</a>
        </li>
        <li id="BibPLXBIB0017" label="[17]">Jayant Krishnamurthy and Tom&nbsp;M. Mitchell. 2011. Which Noun Phrases Denote Which Concepts?. In <em><em>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1</em></em> (HLT ’11). Association for Computational Linguistics, Stroudsburg, PA, USA, 570–580. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=2002472.2002545" target="_blank">http://dl.acm.org/citation.cfm?id=2002472.2002545</a>
        </li>
        <li id="BibPLXBIB0018" label="[18]">Dekang Lin and Patrick Pantel. 2001. DIRT @SBT@Discovery of Inference Rules from Text. In <em><em>Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em></em> (KDD ’01). ACM, New York, NY, USA, 323–328. <a class="link-inline force-break" href="https://doi.org/10.1145/502512.502559" target="_blank">https://doi.org/10.1145/502512.502559</a>
        </li>
        <li id="BibPLXBIB0019" label="[19]">Thomas Lin, Mausam, and Oren Etzioni. 2012. Entity Linking at Web Scale. In <em><em>Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction</em></em> (AKBC-WEKEX ’12). Association for Computational Linguistics, Stroudsburg, PA, USA, 84–88. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=2391200.2391216" target="_blank">http://dl.acm.org/citation.cfm?id=2391200.2391216</a>
        </li>
        <li id="BibPLXBIB0020" label="[20]">Christopher&nbsp;D. Manning, Prabhakar Raghavan, and Hinrich Schütze. 2008. <em><em>Introduction to Information Retrieval</em></em> . Cambridge University Press, New York, NY, USA.</li>
        <li id="BibPLXBIB0021" label="[21]">Mausam Mausam. 2016. Open Information Extraction Systems and Downstream Applications. In <em><em>Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</em></em> (IJCAI’16). AAAI Press, 4074–4077. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=3061053.3061220" target="_blank">http://dl.acm.org/citation.cfm?id=3061053.3061220</a>
        </li>
        <li id="BibPLXBIB0022" label="[22]">George&nbsp;A. Miller. 1995. WordNet: A Lexical Database for English. <em><em>Commun. ACM</em></em> 38, 11 (Nov. 1995), 39–41. <a class="link-inline force-break" href="https://doi.org/10.1145/219717.219748" target="_blank">https://doi.org/10.1145/219717.219748</a>
        </li>
        <li id="BibPLXBIB0023" label="[23]">T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, J. Betteridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel, J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed, N. Nakashole, E. Platanios, A. Ritter, M. Samadi, B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, and J. Welling. 2015. Never-Ending Learning. In <em><em>Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15)</em></em> .</li>
        <li id="BibPLXBIB0024" label="[24]">Ndapandula Nakashole, Gerhard Weikum, and Fabian Suchanek. 2012. PATTY: A Taxonomy of Relational Patterns with Semantic Types. In <em><em>Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</em></em> (EMNLP-CoNLL ’12). Association for Computational Linguistics, Stroudsburg, PA, USA, 1135–1145. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=2390948.2391076" target="_blank">http://dl.acm.org/citation.cfm?id=2390948.2391076</a>
        </li>
        <li id="BibPLXBIB0025" label="[25]">Maximilian Nickel, Lorenzo Rosasco, and Tomaso Poggio. 2016. Holographic Embeddings of Knowledge Graphs. In <em><em>Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</em></em> (AAAI’16). AAAI Press, 1955–1961. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=3016100.3016172" target="_blank">http://dl.acm.org/citation.cfm?id=3016100.3016172</a>
        </li>
        <li id="BibPLXBIB0026" label="[26]">Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2011. A Three-way Model for Collective Learning on Multi-relational Data. In <em><em>Proceedings of the 28th International Conference on International Conference on Machine Learning</em></em> (ICML’11). Omnipress, USA, 809–816. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=3104482.3104584" target="_blank">http://dl.acm.org/citation.cfm?id=3104482.3104584</a>
        </li>
        <li id="BibPLXBIB0027" label="[27]">Madhav Nimishakavi, Uday&nbsp;Singh Saini, and Partha Talukdar. 2016. Relation Schema Induction using Tensor Factorization with Side Information. In <em><em>Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</em></em> . Association for Computational Linguistics, 414–423. <a class="link-inline force-break" href="https://doi.org/10.18653/v1/D16-1040" target="_blank">https://doi.org/10.18653/v1/D16-1040</a>
        </li>
        <li id="BibPLXBIB0028" label="[28]">Robert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2011. <em><em>English gigaword fifth edition, linguistic data consortium</em></em> . Technical Report. Technical report, Technical Report. Linguistic Data Consortium, Philadelphia.</li>
        <li id="BibPLXBIB0029" label="[29]">Ellie Pavlick, Pushpendre Rastogi, Juri Ganitkevitch, Benjamin&nbsp;Van Durme, and Chris Callison-Burch. 2015. PPDB 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification. In <em><em>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, July 26-31, 2015, Beijing, China, Volume 2: Short Papers</em></em> . 425–430. <a class="link-inline force-break" href="http://aclweb.org/anthology/P/P15/P15-2070.pdf" target="_blank">http://aclweb.org/anthology/P/P15/P15-2070.pdf</a>
        </li>
        <li id="BibPLXBIB0030" label="[30]">Jeffrey Pennington, Richard Socher, and Christopher&nbsp;D. Manning. 2014. GloVe: Global Vectors for Word Representation. In <em><em>Empirical Methods in Natural Language Processing (EMNLP)</em></em> . 1532–1543. <a class="link-inline force-break" href="http://www.aclweb.org/anthology/D14-1162" target="_blank">http://www.aclweb.org/anthology/D14-1162</a>
        </li>
        <li id="BibPLXBIB0031" label="[31]">Jay Pujara, Hui Miao, Lise Getoor, and William Cohen. 2013. Knowledge Graph Identification. In <em><em>Proceedings of the 12th International Semantic Web Conference - Part I</em></em> (ISWC ’13). Springer-Verlag New York, Inc., New York, NY, USA, 542–557. <a class="link-inline force-break" href="https://doi.org/10.1007/978-3-642-41335-3_34" target="_blank">https://doi.org/10.1007/978-3-642-41335-3_34</a>
        </li>
        <li id="BibPLXBIB0032" label="[32]">Lev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and Global Algorithms for Disambiguation to Wikipedia. In <em><em>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1</em></em> (HLT ’11). Association for Computational Linguistics, Stroudsburg, PA, USA, 1375–1384. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=2002472.2002642" target="_blank">http://dl.acm.org/citation.cfm?id=2002472.2002642</a>
        </li>
        <li id="BibPLXBIB0033" label="[33]">Swarnadeep Saha, Harinder Pal, and Mausam. 2017. Bootstrapping for Numerical Open IE. In <em><em>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em></em> . Association for Computational Linguistics, 317–323. <a class="link-inline force-break" href="https://doi.org/10.18653/v1/P17-2050" target="_blank">https://doi.org/10.18653/v1/P17-2050</a>
        </li>
        <li id="BibPLXBIB0034" label="[34]">Gaurav Sood. 2016. Parsed DMOZ data. (2016). <a class="link-inline force-break" href="https://doi.org/10.7910/DVN/OMV93V" target="_blank">https://doi.org/10.7910/DVN/OMV93V</a>
        </li>
        <li id="BibPLXBIB0035" label="[35]">Valentin&nbsp;I. Spitkovsky and Angel&nbsp;X. Chang. 2012. A Cross-Lingual Dictionary for English Wikipedia Concepts. In <em><em>Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12)</em>(23-25)</em>, Nicoletta Calzolari&nbsp;(Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet&nbsp;Uğur Doğan, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis (Eds.). European Language Resources Association (ELRA), Istanbul, Turkey.</li>
        <li id="BibPLXBIB0036" label="[36]">Fabian&nbsp;M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: A Core of Semantic Knowledge. In <em><em>Proceedings of the 16th International Conference on World Wide Web</em></em> (WWW ’07). ACM, New York, NY, USA, 697–706. <a class="link-inline force-break" href="https://doi.org/10.1145/1242572.1242667" target="_blank">https://doi.org/10.1145/1242572.1242667</a>
        </li>
        <li id="BibPLXBIB0037" label="[37]">Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher&nbsp;D. Manning. 2012. Multi-instance Multi-label Learning for Relation Extraction. In <em><em>Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</em></em> (EMNLP-CoNLL ’12). Association for Computational Linguistics, Stroudsburg, PA, USA, 455–465. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=2390948.2391003" target="_blank">http://dl.acm.org/citation.cfm?id=2390948.2391003</a>
        </li>
        <li id="BibPLXBIB0038" label="[38]">Pang-Ning Tan, Michael Steinbach, and Vipin Kumar. 2005. <em><em>Introduction to Data Mining, (First Edition)</em></em> . Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA.</li>
        <li id="BibPLXBIB0039" label="[39]">Salvatore Trani, Diego Ceccarelli, Claudio Lucchese, Salvatore Orlando, and Raffaele Perego. 2014. Dexter 2.0: An Open Source Tool for Semantically Enriching Data. In <em><em>Proceedings of the 2014 International Conference on Posters &amp;#38; Demonstrations Track - Volume 1272</em></em> (ISWC-PD’14). CEUR-WS.org, Aachen, Germany, Germany, 417–420. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=2878453.2878558" target="_blank">http://dl.acm.org/citation.cfm?id=2878453.2878558</a>
        </li>
        <li id="BibPLXBIB0040" label="[40]">L.J.P. van&nbsp;der Maaten and G.E. Hinton. 2008. Visualizing High-Dimensional Data Using t-SNE. (2008).</li>
        <li id="BibPLXBIB0041" label="[41]">William&nbsp;E Winkler. 1999. The state of record linkage and current research problems. In <em><em>Statistical Research Division, US Census Bureau</em></em> . Citeseer.</li>
        <li id="BibPLXBIB0042" label="[42]">Alexander Yates and Oren Etzioni. 2009. Unsupervised Methods for Determining Object and Relation Synonyms on the Web. <em><em>J. Artif. Int. Res.</em></em> 34, 1 (March 2009), 255–296. <a class="link-inline force-break" href="http://dl.acm.org/citation.cfm?id=1622716.1622724" target="_blank">http://dl.acm.org/citation.cfm?id=1622716.1622724</a>
        </li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>*</sup></a>Research carried out while at the Indian Institute of Science, Bangalore.</p>
    <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a>We use support and confidence values of 2 and 0.2 for all the experiments in this paper.</p>
    <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a>Authors did not participate in this evaluation.</p>
    <p id="fn4"><a href="#foot-fn4"><sup>3</sup></a> <tt><a class="link-inline force-break" href="https://github.com/malllabiisc/cesi" target="_blank">https://github.com/malllabiisc/cesi</a></tt></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&nbsp;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3178876.3186030">https://doi.org/10.1145/3178876.3186030</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
