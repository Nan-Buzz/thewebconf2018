<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>A Content Management Perspective on Fact-Checking</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main">  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">A Content Management Perspective on Fact-Checking</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author">     <span class="givenName">Sylvie</span>     <span class="surName">Cazalens</span>     Universit&#x00E9; de Lyon, CNRS INSA-Lyon, LIRIS, UMR5205, Villeurbanne, F-69621, France, <a href="mailto:sylvie.cazalens@insa-lyon.fr">sylvie.cazalens@insa-lyon.fr</a>    </div>    <div class="author">     <span class="givenName">Philippe</span>     <span class="surName">Lamarre</span>     Universit&#x00E9; de Lyon, CNRS INSA-Lyon, LIRIS, UMR5205, Villeurbanne, F-69621, France, <a href="mailto:philippe.lamarre@insa-lyon.fr">philippe.lamarre@insa-lyon.fr</a>    </div>    <div class="author"><a href="https://orcid.org/0000-0002-8662-0053" ref="author"><span class="givenName">Julien</span>      <span class="surName">Leblay</span></a>     AIRC, AIST, Tokyo, Japan, <a href="mailto:julien.leblay@aist.go.jp">julien.leblay@aist.go.jp</a>    </div>    <div class="author">     <span class="givenName">Ioana</span>     <span class="surName">Manolescu</span>     Inria, UMR7161 CNRS, Ecole Polytechnique, Palaiseau, 91120, France, <a href="mailto:ioana.manolescu@inria.fr">ioana.manolescu@inria.fr</a>    </div>    <div class="author"><a href="https://orcid.org/0000-0002-2452-8868" ref="author"><span class="givenName">Xavier</span>      <span class="surName">Tannier</span></a>     Sorbonne Universit&#x00E9;, Inserm, LIMICS, Paris, France, <a href="mailto:xavier.tannier@sorbonne-universite.fr">xavier.tannier@sorbonne-universite.fr</a>    </div>                        </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3184558.3188727" target="_blank">https://doi.org/10.1145/3184558.3188727</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>Fact checking has captured the attention of the media and the public alike; it has also recently received strong attention from the computer science community, in particular from data and knowledge management, natural language processing and information retrieval; we denote these together under the term &#x201C;content management&#x201D;. In this paper, we identify the fact checking tasks which can be performed with the help of content management technologies, and survey the recent research works in this area, before laying out some perspectives for the future. We hope our work will provide interested researchers, journalists and fact checkers with an entry point in the existing literature as well as help develop a roadmap for future research and development work.</small>    </p>    </div>    <div class="CCSconcepts">    <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> General and reference </strong>&#x2192; <em>Surveys and overviews;</em> &#x2022;<strong> Information systems </strong>&#x2192; <em>Web searching and information discovery;</em></small> </p>    </div>    <div class="classifications">    <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Computational Journalism; Content Management; Survey</small>     </span>    </div>    <br/>    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Sylvie Cazalens, Philippe Lamarre, Julien Leblay, Ioana Manolescu, and Xavier Tannier. 2018. A Content Management Perspective on Fact-Checking. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 10 Pages. <a href="https://doi.org/10.1145/3184558.3188727" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3184558.3188727</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-6">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>    </div>    </header>    <p>Journalism is about reporting the state of the world and events that affect society. Journalists&#x2019; ethics aim to accuracy, objectivity, impartiality and accountability. However, these are notoriously hard to ensure, as individuals perceive the world subjectively through the prism of their personal mix of our experiences and values. Thus, while the perception of some events may reach a certain degree of consensus (e.g.&#x00A0;ongoing natural disaster), others are violently disagreed upon (e.g.&#x00A0; claims made about candidates&#x2019; past in an election campaign). The tension between fact reporting and value- and emotion-based interpretation is also visible in the variety of journalist roles, with reporter and fact checker at one end of the spectrum focusing on facts, and analysts, pundits and columnists at the other end, each interpreting and distilling such reports into a narrative their audience appreciates them for.</p>    <p>The Internet has also changed the landscape in an unprecedented way. Paradoxically, in an era where information has never been so widely available, access to relevant, trustworthy and accurate information is hard to get. In some (mostly online) media sphere, facts widely supported with science are being ignored or marginalized in favor of narratives supported by influence groups; human impact on climate change is the foremost example. Skepticism towards journalists or more generally media has always existed; the Internet is making it easier to lead a social life from which contradiction is absent (&#x201C;bubble effect&#x201D;) and to be exposed only to content one already agrees with (&#x201C;echo chamber&#x201D;) and piercing such bubbles with facts is becoming increasingly hard. Also, the multiplication of online media outlets and the possibility to automate misinformation spreading through social bots puts this task out of the reach of human journalists; computerized tools are called for, and are increasingly explored by researchers from many scientific communities.</p>    <p>Since 2015, we have been collaborating with journalists from Le Monde, France&#x0027;s leading national newspaper, in an R&#x0026;D project named ContentCheck, focused on content management technologies for journalistic fact checking&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>]. The goal of this paper is to <em>analyze and understand what role content management technologies</em>, seen as data and knowledge management, information extraction, natural language processing, and their interactions, <em>can play toward facilitating, speeding up and improving fact-checking work</em>, whether performed by journalists or other fact-checkers.<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> We stress that we do not believe it is feasible to &#x201C;automate&#x201D; fact-checking or journalistic work; nor is it desirable, since journalistic content is authored by humans who understand, shape and drive the interests and knowledge of their fellow humans. Instead, we are interested in the role content management can play as a provider of models, algorithms and tools.</p>    <p>Below, we characterize the perimeter of fact checking-work we are interested in, delimit it from other scientific and engineering areas, and highlight its complexity (Section&#x00A0;<a class="sec" href="#sec-7">2</a>); we survey existing research in the realm of fact checking, or related to it, in recent years (Section&#x00A0;<a class="sec" href="#sec-11">3</a>); finally, we identify some open problems, promising research directions, and requirements requirements for systems and platforms that will be developed in the area, still within a content management perspective.</p>   </section>   <section id="sec-7">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> Computational fact checking</h2>    </div>    </header>    <p>We define the scientific area we consider (Section&#x00A0;<a class="sec" href="#sec-8">2.1</a>), analyze its ingredients (Section&#x00A0;<a class="sec" href="#sec-9">2.2</a>) and finish our outline by acknowledging some of its limitations (Section&#x00A0;<a class="sec" href="#sec-10">2.3</a>).</p>    <section id="sec-8">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Definition and perimeter</h3>     </div>    </header>    <p>Originally, fact checking designated the correctness checking of all facts in news article <em>before</em> they are published; this is a core part of the journalistic work. Increasingly though, the term refers to the analyses of claims <em>a posteriori</em>, after a certain article (or tweet, or speech etc.) is published, and often by people unaffiliated with the authors of the original content. Such fact checking work is performed by NGOs maintaining active, high-profile Web sites, such as FactCheck or PolitiFact in the US and FullFact in the UK, by specialists within established news organizations, such as the Fact Checker of the Washington Post<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a> in the US, the <em>D&#x00E9;codeurs</em><a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a> with Le Monde and <em>D&#x00E9;sintox</em><a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a> within Lib&#x00E9;ration, both major newspapers in France, and many others.</p>    <p>&#x00A0; <em>Definition</em>: This paper focuses on <em>a posteriori</em> fact checking, which we define as the investigative process consisting in:</p>    <ol class="list-no-style">     <li id="list1" label="(1)"><em>extracting claims</em> from some discourse,<br/></li>     <li id="list2" label="(2)"><em>searching for the facts</em> the claims are based on,<br/></li>     <li id="list3" label="(3)"><em>assessing the accuracy</em> of the claim with regards to those backing facts, and<br/></li>     <li id="list4" label="(4)"><em>providing perspective</em> to claims for which there is no straightforward settlement.<br/></li>    </ol>    <p>Other definitions and design principles proposed in prior work include&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0063">63</a>]. We believe our definition is both general and precise enough to encompass specialized systems capable of solving one of the above tasks, as well as end-to-end systems, providing solutions to several tasks. Broadly speaking, a full-fledged fact checking system enables the construction of specialized knowledge bases, lifting ambiguities inherent in natural language, correcting honest mistakes as well as purposeful misinformation, and archiving the result of such analysis in persistent, searchable, open repositories.</p>    <p>Note that some related scientific areas are left out of the focus of the present work. First, <em>audio, image and video processing</em> have been very dynamic on this subject, notably through the field of multimedia forensics (image&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0057">57</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0070">70</a>] or video&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0042">42</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0055">55</a>]), leading to verification systems and services such as RevEye, Tineye or InVID&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0061">61</a>]; we do not cover their specific techniques and instead point to the above references. Second, the area of <em>fake news detection</em> is closely related to fact checking, yet we view it as slightly distinct: the former includes any method for classifying a news item as true or false, including methods that do not consider the actual <em>content</em> of the news but instead focus on aspects such as its linguistic style or its pattern of propagation in a social network&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0049">49</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0050">50</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0054">54</a>]. We consider a technique falls in the scope of fact checking as soon as it examines the <em>facts (content)</em> of a claim, usually against some <em>reference</em> information. Clearly, fact checking can be seen a worthy component of fake news detection, to which it can bring the distinctive advantage of an <em>explainable (transparent)</em> analysis, based on the reference facts.</p>    </section>    <section id="sec-9">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Fact checking ingredients</h3>     </div>    </header>    <p>From the above definition, we can derive a set of steps involved in a fact check, up to the possible successful outcome (the fact is confirmed). This is the case if: (i) the fact leaves little to no room for alternative interpretations, (ii) it is backed by sufficient references to sources, (iii) the sources are reliable<a class="fn" href="#fn5" id="foot-fn5"><sup>5</sup></a>, and (iv) the claim is consistent with the sources.</p>    <p>If the claims is too vague, leading to <em>too many distinct interpretations</em>, it is hard or impossible to check it effectively. If the fact checker <em>lacks access to sufficient reliable sources</em>, there is not enough background against which to check. If the <em>reliability</em> of the sources is in question, the fact check conclusion is hard to trust. Even in the presence of sufficient and reliable sources, evaluating claim accuracy is tricky, due in part to the need to <em>contextualize</em> the claim, i.e., understand the precise setting (e.g., in which country, city, at which time) the claim is made; its validity can only be assessed in a specific context. Some claims may be crafted to mislead, i.e.,&#x00A0;look valid given some context or source that is either irrelevant or flawed.</p>    <p>For any step in the process not to be perceived as biased, <em>transparency</em> is key. Indeed, this is apparent in the principles instated by the International Fact-Checking Network (IFCN), an organization sponsored by the Poynter Institute to &#x201C;promote excellence in fact checking&#x201D;:<a class="fn" href="#fn6" id="foot-fn6"><sup>6</sup></a>    </p>    <ol class="list-no-style">     <li id="list5" label="(1)">A commitment to non-partisanship and fairness.<br/></li>     <li id="list6" label="(2)">A commitment to the transparency of sources.<br/></li>     <li id="list7" label="(3)">A commitment to the transparency of function and organization.<br/></li>     <li id="list8" label="(4)">A commitment to the transparency of methodology.<br/></li>     <li id="list9" label="(5)">A commitment to open and honest corrections.<br/></li>    </ol>    <p>Hence, whichever aspect of the fact checking method research tackles, transparency appears as a horizontal feature that <em>must</em> taken into account, for the fact checking output to be useful as opposed to adding more noise to an already noisy landscape.</p>    </section>    <section id="sec-10">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.3</span> The limits of fact checking</h3>     </div>    </header>    <p>While technology can make fact checking easier and faster, its effectiveness is challenged by psychological or cultural barriers. &#x201C;Confirmation bias&#x201D; is the well-known psychological observation that people are more likely to believe what fits their prior views, leading to the man-made part of the &#x201C;echo chamber&#x201D;; automated recommendation system do the rest, shutting users in their &#x201C;filter bubbles&#x201D;. The exact extent to which filter bubbles and echo chambers contribute to promoting inaccurate or biased information is still being studied, e.g.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0024">24</a>]. A study&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0041">41</a>] has found that defiance towards fact checkers may in fact reinforce a reader&#x0027;s perception if confronted directly (the so-called &#x201C;backfire effect&#x201D;), although more recent work on the topic show this may not be a primary matter of concern&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0065">65</a>].</p>    <p>Another important issue is the time of the fact check versus the time of the original statement. A compelling article&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0058">58</a>] argues that &#x201C;fact checking is <em>after-the-fact</em> checking&#x201D; in the sense that the verification may come too late, after rumors and false information have had time to &#x201C;stick&#x201D; in their audience&#x0027;s minds; the proposed solution is for correct, transparent and verifiable information to reach the audience first. Close to that idea, real-time fact checking aims at reducing the time between publication of the claim and that of their fact checks. However, near instant-correction can exacerbate the backfire effect&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0025">25</a>], ultimately making readers more immune to such corrections. It has also been shown&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0053">53</a>] that emotionally engaging information, including rumors and misinformations, spread fast on social networks, which is not always the case for corrections.</p>    <p>Yet, there is also evidence that sufficient and consistent corrections of a false perception may succeed in uprooting it&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0047">47</a>]. In a close vein, showing online readers links to &#x201C;related&#x201D; stories, include some that correct a misinforming claim on the original page, has been shown to significantly reduce misperceptions&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0007">7</a>]; this idea has been very recently taken up by Facebook in order to fight misinformation<a class="fn" href="#fn7" id="foot-fn7"><sup>7</sup></a>.</p>    <p>The &#x201C;arms race&#x201D; between misinformation and fact checking is still on and probably will be so for a while. The focus of this paper is on content management techniques which have been or could be developed toward making fact checking scalable, effective, efficient and transparent.</p>    </section>   </section>   <section id="sec-11">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> State of the art</h2>    </div>    </header>    <figure id="fig1">    <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3188727/images/www18companion-235-fig1.svg" class="img-responsive" alt="Figure 1"      longdesc=""/>    <div class="figure-caption">     <span class="figure-number">Figure 1:</span>     <span class="figure-title">Fact checking tasks, ingredients, and relevant works: an overview.</span>    </div>    </figure>    <p>Figure&#x00A0;<a class="fig" href="#fig1">1</a> presents an overview of the tasks involved in fact checking (shown in black boxes), together with their inputs and outputs (shown in blue); main relevant works from the literature appear in their respective tasks.</p>    <p>The central task is to assess the accuracy of a claim accuracy, based on reference sources; this takes as input the claim, and outputs a fact check result or analysis. The claim may have to be extracted from a text source, made available through some media, such as newspapers, social media, political or government communication etc. Reference source search may be needed to identify the reference sources most suited in order to check a given claim. An active area of fact checking work is concerned with putting claims into perspective by analyzing how claim validity is impacted by a slight change in the claim statement. Finally, content management techniques are also called upon to facilitate publishing and sharing fact checking outputs.</p>    <p>The remainder of this section presents the results and techniques involved in each task. For completeness, we start by referring to works defining the fact checking perimeter (Section&#x00A0;<a class="sec" href="#sec-12">3.1</a>); subsequently, we consider: reference data source search (Section&#x00A0;<a class="sec" href="#sec-13">3.2</a>), reference data source construction, integration and refinement (Section&#x00A0;<a class="sec" href="#sec-14">3.3</a>), claim extraction from text (Section&#x00A0;<a class="sec" href="#sec-15">3.4</a>), claim accuracy assessment (Section&#x00A0;<a class="sec" href="#sec-16">3.5</a>), context-based claim interpretation and analysis (Section&#x00A0;<a class="sec" href="#sec-17">3.6</a>) and, last but not least, publishing and sharing fact-checking outputs (Section&#x00A0;<a class="sec" href="#sec-18">3.7</a>).</p>    <p>Few platforms available today implement all (or most) tasks. ClaimBuster&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>] (whose functionalities we describe below) is quite complete; a recent vision paper&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>] points toward such a comparable architecture, and FullFact also states they are working to develop a complete platform&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>]. The CJ Workbench&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0059">59</a>] is another example of grass-root initiative to automate journalistic work. This is a very active research and development area today.</p>    <section id="sec-12">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Defining computational fact checking</h3>     </div>    </header>    <p>This very concept is still quite new, and its meaning is being gradually clarified, in an area (going between computer science and journalism) ripe with buzzwords such as fake news, post-truth and the like. We list below advances towards formally defining fact checking.</p>    <p>A pioneering paper on computational journalism&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0012">12</a>] did not explicitly mention fact checking but identified many content management functionalities which journalists are advised to rely on, such as information extraction, document exploration, and data integration. Soon after, [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>] considered ways in which technology could be used to further journalism values and goals, stated as: truth; public interest; and information. He identified NLP, data mining, machine learning, knowledge representation and information retrieval as computer science areas with the biggest contributions to computational journalism. From an NLP perspective, [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0063">63</a>] defines fact checking as the <em>assignment of a truth value to a claim made in a particular context, on an ordinal scale</em>, borrowed from the popular Truth-o-Meter scale used by fact checking web sites Politifact (&#x201C;True&#x201D;, &#x201C;Mostly True&#x201D;, &#x201C;Mostly False&#x201D;, etc). It also presents a &#x201C;golden standard&#x201D; (fact checks) dataset of manually checked statements, against which automated checking methods can be evaluated.</p>    <p>The recent white-paper by FullFact&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>] defines fact checking as a four-stage process where (i) media sources are <em>monitored</em>, (ii) claims are <em>spotted</em>, (iii) claims are <em>checked</em>, (iv) fact checking analysis <em>results</em> are created and <em>published</em>. This definition is quite consensual among the works we discuss below; claim spotting (also termed claim extraction) and claim accuracy checking have received most significant attention.</p>    </section>    <section id="sec-13">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Reference data source search</h3>     </div>    </header>    <p>To check a given claim, one needs to identify suitable reference sources against which to check, and if sources are many, select the most relevant ones.</p>    <p>In FactMinder&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0027">27</a>], the authors envision fact-checking as a manual analysis of an article (not a specific claim) published online, against a background of reference data sources. They focus on identifying, in a reference database of RDF knowledge bases and structured documents, those semantically related to the entities (people, places etc.) present in the article to be fact-checked. The technical solution is based on (i) identifying (matching) the article entities to those in the reference RDF graph and (ii) evaluated pre-defined queries to retrieve the content &#x201C;characterizing&#x201D; entities of each known type (e.g., political appointments for a politician, albums and songs for a singer etc.). Query results are then displayed to the fact-checker as a background meant to help the check. Such automated background information search is not tailored to a specific claim to check.</p>    <p>DeFacto&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0034">34</a>] leverages search engines to collect pages potentially harboring evidence proving or disproving an input claim, considered to be an RDF triple. NLP techniques are applied to translate (enhance) the RDF claim into a set of topic terms which are then looked for in Web pages.</p>    <p>Stance detection is a recent task of information extraction, aiming at determining from a text whether it is in favor of a given target, against it, neutral or unrelated. For example, the tweet <em>&#x201C;@realDonaldTrump is the only honest voice of the @GOP&#x201D;</em> expresses a positive stance towards the target Donald Trump&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>].</p>    <p>The textual sources for stance detection can be general claims&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0035">35</a>], debates in online forums [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0040">40</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0056">56</a>] or student essays&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>], but most work have focused on politically- or journalistically-related sources, such as congressional debates&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0062">62</a>], tweets&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0046">46</a>] (mainly through the organization of a SemEval evaluation campaign in 2016&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0039">39</a>]) or news articles&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0021">21</a>] (the Fake News Challenge proposed in 2017 a stance detection task as a first step toward fact-checking<a class="fn" href="#fn8" id="foot-fn8"><sup>8</sup></a>).</p>    <p>Last but not least, fact checking outputs are valuable reference sources for future checks. In 2013, Washington Post&#x0027;s TruthTeller project<a class="fn" href="#fn9" id="foot-fn9"><sup>9</sup></a> used claims manually checked by Factcheck.org; the D&#x00E9;codex plug-in developed by Le Monde also leverages their past fact checking analyses. ClaimBuster&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>] relies on a large set of claims manually checked through a crowdsourced effort.</p>    </section>    <section id="sec-14">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> Reference data source analysis, integration, refinement</h3>     </div>    </header>    <p>The availability, coverage and quality of reference data sources is crucial to the success of fact checking. We mention here areas of research work whose techniques may be beneficially used for fact checking, even though they are applicable in a wider context.</p>    <p>Truth discovery&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0036">36</a>] is a task by which the <em>truthfulness</em> of facts typically found of online data sources, is assessed based on the <em>trustworthiness</em> of those sources. Depending on the approach, both measures can influence one another, i.e.,&#x00A0;the more truthful facts a site published, the more trustworthy it is, and vice versa. Such large knowledge bases extracted from the Web appear to be good news for journalism, as they provide more reference sources. However, additional verifications are necessary due to their lack of reliability, to inherent errors introduced with automated extraction, to their becoming outdated, etc.</p>    <p>Fact checkers have today at their disposal a wealth of data sources, which for simplicity and ease of use should ideally be exploited together through a single point of access. Data integration, a well-established line of data management research, aims at allowing users to interact with a set of data sources as if it was a single database. While several flavors of data integration systems have been proposed, data spaces&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>] appear well-adapted to handling heterogeneous reference sources, independently developed, and available in disparate formats (relational data, HTML or Excel tables, CSV, RDF, JSON frequently found in open data...). Tatooine&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>] is a dataspace-style data integration prototype integrating querying, classification, and visualization components for data journalism and fact-checking applications. CJ Workbench&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0059">59</a>] is a workflow-oriented platform for retrieving, filtering, storing and analyzing data; it emphasizes collaboration, reuse, and continuously updated views over the data.</p>    </section>    <section id="sec-15">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.4</span> Claim extraction</h3>     </div>    </header>    <p>Claim extraction (also called claim detection) leverages NLP technologies to extract from text, sharp (structured) claims which one may subsequently check for accuracy.</p>    <p>An early attempt at this task in DisputeFinder&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0019">19</a>] focused on identifying, in an online text, claims potentially covered by a database of reference containing <em>disputed claims</em> (on which contrary opinions have been stated). Phrases are transformed in bags of words through stop word removal, stemming etc. and matched against the database, both in positive mode (to see if the database backs it) and in negative mode (if the contrary is stated in the database). DisputeFinder then shows users additional information on to how or why the claim is disputed, such as related articles or argumentation graph. DisputeFinder also allowed users to add claims the believed were disputed, however a user study showed users sometimes confusing &#x201C;disputed&#x201D; with &#x201C;false&#x201D;, or improperly reported claims and/or sources. This highlights that user expertise is needed in order to contribute meaningfully.</p>    <p>In&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0035">35</a>] a formal definition of the task of context-dependent claim detection is proposed: given a topic (short sentence) and a set of relevant articles, their goal is to automatically extract concise statements from the articles that directly support or contests the given topic. The authors also provide manually labeled benchmark dataset and a classification approach based on a cascade of classifiers.</p>    <p>Claim extraction from text feeds (tweeter, newspapers, legislative proceedings), and ultimately, audio and video streams is reported to be also a focus of FullFact ongoing work&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>]; in particular, they are interested in automatically identifying the claims covered by prior FullFact manual fact checking work. Technical details are not available at this time.</p>    <p>A follow-up on DeFacto&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>] also allows claims to be given in text; in this case, entity disambiguation is performed on the claim, using a reference knowledge base, to bring it to the RDF triple form DeFacto mostly considers.</p>    <p>A line of work closely related to claim extraction is identifying in a text, claims that are worth checking. Machine learning has typically been used for this task. For instance, [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0043">43</a>] presents a corpus where claims have been manually classified as verifiable and unverifiable, and&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>] uses different kinds of neural networks to learn a classification model. Support Vector Machines is used in ClaimBuster&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>] which monitors data sources such as social media, TV programs and websites, analyses the incoming stream of information and classifies claims in three categories: non-factual (e.g., opinions or subjective content); factual but not interesting (consensual, general); factual and interesting (that is, check-worthy). To train the classifier, a database of 20,000 claims annotated with these categories has been built through crowdsourcing.</p>    <p>Other work try to classify claims as either facts or opinions, [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0069">69</a>] from the perspective of an opinion question answering system, [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0064">64</a>] for research on deliberation and debate. The distinction is then made between an argument based on facts, from one appealing to feelings and emotions.</p>    <p>An important problem to solve on the way to mostly automated fact-checking is understanding the context in which a given claim is made, that is: identifying the time to which the claim refers, possibly the location or geographical scope, identifying the speaker etc. Indeed, a claim such as &#x201C;This city&#x0027;s taxes have gone up 20% since the last elections&#x201D; cannot be checked without such context. These issues are also discussed in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>].</p>    </section>    <section id="sec-16">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.5</span> Claim accuracy assessment</h3>     </div>    </header>    <p>The accuracy of a claim could be simply decided as a value between true and false, or (more frequently) from a multiple-values scale; also, the checking process often produces an analysis or detailed trace, which helps understand the accuracy judgment.</p>    <p>In DeFacto&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0034">34</a>], evidence potentially proving the claim is a text snippet found in a Web page, sufficiently close to the claim; fuzzy matching based on similar-term expansion is used to estimate this proximity. The system computes both such a support score (to which extent the proof agrees with the claim) and a trustworthiness score of the Web page comprising the proof. Trustworthiness here is understood as relevance, i.e., the focus is not on establishing a reputation for the page regardless of the query. Subsequently, a supervised machine learning (SVM) classifier is used to decide when there is sufficient evidence to consider that the fact checks. This system has a particular focus on exploiting multilingual evidence.</p>    <p>In the TruthTeller system previously mentioned, a natural language claim extracted from video or audio transcripts with the help of speech recognition, is compared to the previously checked ones from the reference source; a modified version of the Rabin-Karp algorithm using the Levenshtein distance is used.</p>    <p>In&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>], authors consider claims as RDF triples, the reference source a knowledge graph such as DBPedia, and cast the task of assessing claim accuracy as a problem of finding short paths in the knowledge graph that connect the claim subject to its object. A truth (or support) value is assigned to each such path, taking into account not only the graph proximity but also the generality of the entities encountered along the path. Here, generality is defined as the number of statements (triples) to which the entity participates: a path is less significant if it passes through very general entities (e.g., Harry Potter and Napoleon are both of Male gender, Male is very general) than if it passes through a very specific one (e.g., Harry Potter and Hermione Granger both study at Hogwarts). Finally, the support of a claim is the highest support value among all paths that support that claim. A more recent study&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0052">52</a>] also considers fact checking as a variant of link prediction, and presents a model to assess the meaning and veracity on claims under scrutiny.</p>    <p>ClaimBuster&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>] attempts to match the claims against previously checked claims from trusted repositories. If no identical or similar claim can be found, Web search engines and question answering systems such as Wolfram Alpha are leveraged to obtain evidence backing or contradicting the claim. A final step is to combine the responses obtained from this evidence gathering module into a visual interface. In a separate study, the authors show a strong correlation between the output of their system, and that claims checked by professionals at CNN and PolitiFact.</p>    <p>The Fast and Furious FactCheck Challenge<a class="fn" href="#fn10" id="foot-fn10"><sup>10</sup></a> proposed to classify news articles (not claims) among the categories <SmallCap>True</SmallCap>, <SmallCap>False</SmallCap>, <SmallCap>Somewhat True</SmallCap> and <SmallCap>Somewhat False</SmallCap> using any combination of human and automated tools; the 2016 winner states he has used NLP and other AI technologies but not much more is known.</p>    <p>We end this section discussing works which do not meet exactly our fact-checking definition yet come very close to it:</p>    <p>Les D&#x00E9;codeurs, the fact checking team of Le Monde<a class="fn" href="#fn11" id="foot-fn11"><sup>11</sup></a> have developed (and share as open data) a database of manual fact checks<a class="fn" href="#fn12" id="foot-fn12"><sup>12</sup></a>, comprising for each claim a set of Web and social media sources having propagated it, the fact checking analysis, and the final level-of-truth classification. Next, they have developed and share in open source D&#x00E9;codex, a plug-in for navigators and social media like Facebook, which signals to users visiting an information source (a Web page or Facebook account) having published a checked claim, a trust score resulting from the aggregated outputs of previous fact checks over that source. Unlike the journalists who devised it, D&#x00E9;codex does not check fact accuracy, strictly speaking. However, its ability to rate trustworthiness makes it quite relevant to this task.</p>    <p>Last but not least, a closely related (and well-established) field of natural language processing is textual entailment&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>], which considers the task of comparing two portions of text and deciding whether the information contained in the first one can be implied from the second. Textual entailment has never been applied explicitly to fact checking problems, but they obviously meet at some points&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>]. Many evaluation campaigns and benchmarks are related to textual entailment, as well as paraphrase detection in general, among which PASCAL challenge&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>], Answer Validation Exercise&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0071">71</a>], the MSRP paraphrase corpus&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>] or the SNLI corpus&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0010">10</a>]. Most of these tasks and data represent similarity between pairs of text as a binary yes/no classification decision.</p>    <p>The SemEval&#x0027;s Semantic Textual Similarity task&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>] offers a graded and typed definition of semantic similarity, which is closer to what fact checking needs, but still focused on general information extraction or machine translation.</p>    <p>Some works also focus on assessing the <em>credibility</em> of claims&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0044">44</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>], in which case the reputation of sources with matching some topic and stance is evaluated rather than the claims themselves.</p>    </section>    <section id="sec-17">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.6</span> Putting claims into perspective</h3>     </div>    </header>    <p>Even if a claim was found to be true, it may be insignificant or misleading. A typical example introduced in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0066">66</a>] is: a trend (say, a crime rate reduction) which truly holds over a certain interval of time, but had started long before this interval, cannot be attributed to an event at the beginning of the interval (say, someone&#x0027;s election). In this example, the claim significance can be understood framing it into the perspective of a longer time interval. This idea can be generalized, e.g., when the claim uses some aggregated measure at a given granularity in a dimension: a useful perspective may be obtained considering other granularities/dimensions. General statistical and data analysis tools ranging from spreadsheets to OLAP can be used here. More generally, any element related to a claim can be used to assess the claim significance. This opens up the question of a space in which to search for such elements and efficient algorithms and pruning strategies to select such perspectives.</p>    <p>The pioneering work of&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0066">66</a>] continued in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0067">67</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0068">68</a>] proposes a framework enabling to formally define the notions of counter-argument (that weakens the original claim), reverse-engineering of vague claims, and claim quality. In this setting, a claim is represented as a parametrized SQL query over some trusted (relational) data sources. The search space is defined by &#x201D;perturbing&#x201D; the different query parameters. In addition to general meta-algorithms, the authors focus on comparisons of window aggregate claims and of time series similarity claims, for which they propose specific and efficient algorithms. Windows aggregate claims compare aggregated values computed over two different windows (for example total number of adoptions during two periods of the same duration 1996-2001 and 1990-1995). In this case, perturbations concern the size of windows and their starting time. An example of time series similarity claim is &#x201C;Person A voted the same as person B <span class="inline-equation"><span class="tex">$x\%$</span>     </span> of the time during a given period&#x201D;. It requires a similarity function to compare two time series. Perturbations mainly concern the interval.</p>    <p>Data mining techniques are used in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>] to enlighten claims about behaviors in voting or rating contexts. The proposed solution aims at identifying groups of individuals and situations where their agreement significantly differs from usual. In this case, the search space is defined by varying patterns of the form &#x27E8;<em>situation</em>, <em>group</em>     <sub>1</sub>, <em>group</em>     <sub>2</sub>&#x27E9;, each item being described using attributes.</p>    <p>It is sometimes difficult to draw a clear border between providing a verdict and providing additional information to assess significance. Some works proposed for the former can be used and generalized for the latter. In&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0033">33</a>], the author introduces a model in which any fact or ontological rule can be endowed with contextual annotation, stating for instance which sources a certain fact comes from, or whether an axiom holds within a given country or period in time. Coupling thus <em>hard axioms</em> with <em>soft</em> weighted axioms, a probability is assigned to each context, reflecting what holds in it and whether it entails a contradiction. In this model, claims are represented as conjunctive queries. For each answer to a query, a function maps each context to a score. This enables the user to witness variations in claim credibility w.r.t.&#x00A0;to all possible contexts, rather than being providing a boolean, discrete or scalar value to assess its truth.</p>    <p>For claims pertaining to complex issues, system providing a more general and balanced picture of the issue can play an important role. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0051">51</a>] describes a debating system, which takes a claim as input (e.g.&#x00A0;&#x201C;casinos increase criminality&#x201D;), crawls from a textual corpus in search for article presentation positive and negative stance to the claim, and outputs a summary of the articles for each stances.</p>    </section>    <section id="sec-18">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.7</span> Sharing and publishing fact checking results</h3>     </div>    </header>    <p>An important issue is that of publishing and sharing fact checking outputs in a format that can be computationally used by other tools.</p>    <p>DeFacto&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0034">34</a>] envisioned sharing fact checking outputs as RDF graphs endowed with RDF provenance information, specifying which tool has checked the claim and when.</p>    <p>ClaimReview<a class="fn" href="#fn13" id="foot-fn13"><sup>13</sup></a> is an open community standard created by Duke in collaboration with Google and Schema.org. It enables fact checkers to annotate web content using a common vocabulary for more effective consumption. For instance, Google uses the annotations to display such fact checks in search results next to the links that are part of the normal Google search results. Technically, Schema.org is a collaborative effort to create, maintain, and promote schemas for exchanging structured data. Content organized according to a Schema.org vocabulary can be encoded in many formats, including JSON.LD (JSON linked data), microdata formats etc. The ClaimReview vocabulary comprises a claim which is of type text, and a claim review, which specializes the pre-existing Review concept from Schema.org. Further, a ClaimReview includes a review rating, and is about a CreativeWork, which can be for instance an Article, Blog, Movie etc. The integration of ClaimReview into the Schema.org vocabulary allows for interoperability with other structured (typically open) data sources.</p>    <p>A database-oriented perspective is taken by the Structured Journalism<a class="fn" href="#fn14" id="foot-fn14"><sup>14</sup></a> initiative, which encourages journalists to publish database items, that is, atomized pieces of structured information. Clearly, this can apply to raw data, used as input in the fact checking process, but also to its outputs. Publishing content in such a structured format eases data reuse and allows building several stories by selecting different subsets of the data and focusing on different trends.</p>    <p>As already pointed out, several human-powered fact checking platforms such as FactCheck.org and PolitFact already provide API access, and their output is already used by several other tools. Among automated systems ClaimBuster mentioned above, also provides access to their fact checking outputs. CJWorkbench, already mentioned, claims to enable the sharing of prior work for reuse in similar settings, for instance adapting a voter fraud analysis done on a local election in Texas to a different election in California.</p>    </section>   </section>   <section id="sec-19">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> Perspectives</h2>    </div>    </header>    <p>Having completed our study of existing systems, tools and methods, we consider the future. Section&#x00A0;<a class="sec" href="#sec-20">4.1</a> outlines open issues to be addressed for fact checking, in particular automated techniques, to gain in efficiency and effectiveness. Section&#x00A0;<a class="sec" href="#sec-21">4.2</a> discusses features of an &#x201C;ideal&#x201D; fact check management system, a (so far) inexistent system, specifically designed to support fact checking work.</p>    <section id="sec-20">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Needs and open problems</h3>     </div>    </header>    <p>Progress in several areas is needed to facilitate and empower the development of automated fact checking tools. On the research side, the following steps could be taken:</p>    <p>     <em>Develop pluridisciplinarity</em>. For several years, interactions between computer scientists and journalists have been extremely fruitful for both sides&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>]: discussing with computer scientists can give journalists access to powerful tools for discovering and exposing the truth<a class="fn" href="#fn15" id="foot-fn15"><sup>15</sup></a>. This principle is also stated in a recent white-paper from the American Press Institute&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>] Social and cognitive sciences also have valuable contributions to bring in order to help devise psychologically effective fact-checking tools. This is not a one-way lane, though: computer science research, and in particular content management, stands to benefit greatly from innovative applications with a strong social impact.</p>    <p>     <em>Establish theoretical foundations</em>. To the best of our knowledge, there have not yet been any attempts at establishing theoretical foundations for the computational fact checking task. Such foundations would be a valuable yardstick to validate the well-formedness of approaches, evaluate their coverage and efficiency, and compare their capabilities. Such foundations should provide widely accepted formal definitions for the (canonical) problems in the area, complexity results on those problems, means to solve the most complex ones with approximation guarantees, etc.</p>    <p>     <em>Improve transparency</em>. Transparency is a key issue to reach trust. A fact check result should provide answers to common questions such as the reasons for the choice of the claim, who are the fact checkers, the list of used sources with means to evaluate their relevance and credibility, the methodology and tools used. Ideally, the fact check should be reproducible and made available by a neutral entity where everyone can share, analyze, comment, etc.</p>    <p>     <em>Ensure explainability</em>. The automatic approaches used in the process of fact checking can be many and complex. They will use many sources, possibly in different languages and complicated structured formats; they will also trigger different kinds of complex algorithms, such as machine learning techniques, most of which building numerical models that behave as black boxes. This raises the question of explainability and interpretability of the results: any system aiming at supporting the journalist or the citizen to make a decision should have an &#x201C;explain facility&#x201D;.</p>    <p>     <em>Develop collaborative tools</em>. Collaboration may range from simple exchanges of trusted data or previous fact checks to coordinated work to face difficult investigations. Furthermore, when fact checkers are of different sensibilities, result credibility improves because it is more difficult to think that a claim has been chosen and treated in a partisan way. CrossCheck<a class="fn" href="#fn16" id="foot-fn16"><sup>16</sup></a> is such a collaborative fact checking project; collaboration empowered by content management tools is a strong trend in journalism as large, promoted by organizations such as the ICIJ<a class="fn" href="#fn17" id="foot-fn17"><sup>17</sup></a>.</p>    <p>     <em>Standardize</em>. The introduction of standard fact check formats such as ClaimReview (Section&#x00A0;<a class="sec" href="#sec-18">3.7</a>) is a first step toward standardization, however more standards are needed to cover additional elements (protocols, tools...) used all along the fact checking process (data cleaning, data integration, computations etc.)</p>    <p>Other steps towards improving the usefulness and effectiveness of fact checking, automated or otherwise, concern journalists and/or the society at large; technology, such as content management tools, could contribute solutions. The most significant ones include:</p>    <ol class="list-no-style">     <li id="list10" label="(1)"><strong>Adapt the delivery of fact checking results.</strong> The problem has several linked facets. One is time. On the one hand, it is sometimes important to quickly react to attempt to stop viral dissemination of misinformation. On the other hand, it is also important to take time to provide sharper arguments. The good balance has to be found. A second facet is formulation of the result: a frontal attack on one&#x0027;s convictions and beliefs is not likely to convince him or her. These were mentioned in Section&#x00A0;<a class="sec" href="#sec-10">2.3</a>, when discussing the limits on the effectiveness of manual fact checking; any automated technique must address the same issues. A third facet is the choice of the best media for fact-checking to reach each group of audience.<br/></li>     <li id="list11" label="(2)"><strong>Focus more on issues than on claims.</strong> An individual claim may be true or false, but newsworthy questions are usually broader than just a claim. For instance, a misleading statement about the criminal activity of refugees in the countries receiving them, participates to a larger discussion about immigration and the way different political parties argue it should be handled. Thus, effective fact checking should focus more broadly on issues, as noted also in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0028">28</a>]. Existing work on putting claims into perspective (Section&#x00A0;<a class="sec" href="#sec-17">3.6</a>) is a first step in this direction.<br/></li>     <li id="list12" label="(3)"><strong>Engage and entertain the audience.</strong> Fact checking success is (also) judged by the audience it can gather and retain. Journalists&#x2019; talent in making stories out of data-backed proofs needs to be deployed in novel ways, e.g. in &#x201C;live&#x201D; mode during political events; this requires near-instant answer from reference source search and claim accuracy checking tools. Journalism at large (and fact checking in particular) may also appeal to users through innovative Web-based media such as interactive, structured data exploration components, embedded inside Web pages. Fact checking components designed directly as plug-ins for social media are another example of journalism moving where the audience is; content management tools are typical tools leveraged in the development of such plug-ins.<br/></li>     <li id="list13" label="(4)"><strong>Educate.</strong> Just as computer literacy is gaining ground through its presence in school curricula, data literacy, envisioned as a set of math and statistic skills, can spread through dedicated education modules at all levels<a class="fn" href="#fn18" id="foot-fn18"><sup>18</sup></a>; understanding the way media and communication works can give the public further tools to discern manipulation, statistic or otherwise.<br/></li>    </ol>    </section>    <section id="sec-21">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Towards a fact check management system</h3>     </div>    </header>    <p>From our identified fact checking tasks, the analysis of existing works and techniques, as well as the needs and desiderata outlined above, we can derive the functionalities of an &#x201C;ideal&#x201D; fact check management system (FCMS), that is, a content management system (CMS) tailored to the needs and uses that fact checking entails:</p>    <p>     <em>Data storage</em>. The FCMS should be capable of storing data sources in various formats, such as they come in journalists&#x2019; hands: PDF, structured text, JSON, CSV, relational databases etc. Automatically detecting the data type and relying on an appropriate system to store each kind of data (or simply a file system when nothing more is available) would simplify users&#x2019; experience. Automatic back-up mechanisms e.g. toward a cloud-storage account would prevent accidental loss of data and allow data reuse. Surprising as it may seem, data used in investigations is not always saved persistently by journalists; an acceptable CMS must make the storage and retrieval experience as smooth as possible.</p>    <p>     <em>Data matching, linking and integration</em>. The FCMS should allow users to identify connections between independently produced data sources, so that they can be exploited together. Many techniques developed for data integration and for Linked Data production can be applied here. Data processing functionalities as described in this and the previous item are especially important if the FCMS is to support gathering information and checking/investigating broader issues, as discussed in Section&#x00A0;<a class="sec" href="#sec-20">4.1</a>, point&#x00A0;<a class="lst" href="#list11">b</a>.</p>    <p>     <em>NLP: large and small</em>. As shown throughout this paper, NLP techniques are crucial for working with text, the predominant form of information sharing today. Building highly accurate NLP tools for very specific tasks is and will probably stay out of reach for non specialists for a while. However, basic NLP functionalities such as named entity recognition from a knowledge base or structured database, transforming documents in bag of words, enhancing it through synonyms and close terms etc. are by now well understood and well supported by tools including open-source ones. They need to be made available and easy to integrate within the FCMS.</p>    <p>     <em>Time management</em>. Being able to trace the data and its evolution is important for accuracy, transparency, reproducibility. FCMS should be able to record and permanently store various pieces of time information such as: data creation time stamp (immutable publication date of an article or a dataset), acquisition times (can be repeated several times as the data evolves), statement date (when people made a certain statement etc.) Any kind of data is concerned including results of fact check.</p>    <p>     <em>Fact and validity time</em>. Facts and events almost all have a limited period of validity. This information can be explicit in the dataset (e.g. a knowledge base gives the starting and ending dates of World War I, or the period where W. Churchill was Prime Minister of the U.K.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0060">60</a>]); but it may need to be inferred from the different snapshots or versions of a same dataset, e.g., a list of Twitter accounts of all ministers is not time-stamped, but evolves with time. In order to understand when a claim is or is not valid, and to ensure not to lose any information through time, all facts should be associated with a validity time, and all query languages and systems should be able to handle it.</p>    <p>     <em>Data quality management</em>. This point encompasses all the tools for managing the life cycle of reference sources and fact checks. This is related to provenance and lineage management which enable to trace what data and operations are involved in producing a given result (data, fact check...).</p>    <p>     <em>Support for reproducibility</em>. In some way, fact checking may be seen as a scientific or forensic work, for which reproducibility is needed.<a class="fn" href="#fn19" id="foot-fn19"><sup>19</sup></a> Ideally, it should be able to record the trace of a fact checking effort so that one could &#x201C;replay&#x201D; it on the same inputs with the same tool, and get the same result.</p>    <p>     <em>Modularity</em>. Using today&#x0027;s technology, the processes involved in fact-checked are extremely time consuming. The FCMS should be designed from the start with modularity and reuse in mind, so that claim analysis pipelines can be easily built and their components re-used. This will offer a great advantage over &#x201C;one-off&#x201D; systems.</p>    <p>     <em>Compliance with the standards</em>. The FCMS should adopt all standards of the trade and be open in the export and sharing of its inputs and outputs.</p>    </section>   </section>   <section id="sec-22">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Conclusion</h2>    </div>    </header>    <p>This work provides a characterization of automated fact checking as a content management problem, drawing from data and knowledge management, natural language processing and information retrieval; machine learning is also leveraged for many of the tasks involved. Based on this characterization, we have identified the main tasks involved, and surveyed existing content management tools and techniques which have and/or could be used to implement the tasks. While we found the area generates a lot of excitement and many works have been put forward, most efforts are currently quite disparate, thus a main goal of our analysis has been to classify, compare, and see how current techniques could fit together. We identified a set of areas where we believe more content management research should be invested to help automated fact checking advance, and described a blueprint architecture for an ideal fact check management system; we view it as a frame for assembling (and thinking about) research efforts currently ongoing in the area.</p>   </section>   <section id="sec-23">    <header>    <div class="title-info">     <h2>Acknowledgments</h2>    </div>    </header>    <p>This work is partially supported by the French National Research Agency grant ANR-15-CE23-0025-01 (ContentCheck project) and by the KAKENHI grant number 17K12786, together with the New Energy and Industrial Technology Development Organization (NEDO), Japan.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">Eneko Agirre, Daniel Cer, Mona Diab, and Aitor Gonzalez-Agirre. 2013. *Sem 2013 Shared Task: Semantic Textual Similarity. In <em>      <em>Proceedings of the Second Joint Conference on Lexical and Computational Semantics and the Shared Task: Semantic Textual Similarity</em>     </em>. 32&#x2013;43.</li>    <li id="BibPLXBIB0002" label="[2]">Isabelle Augenstein, Tim Rockt&#x00E4;schel, Andreas Vlachos, and Kalina Bontcheva. 2016. Stance Detection with Bidirectional Conditional Encoding. In <em>      <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em>     </em>, Jian Su, Kevin Duh, and Xavier Carreras (Eds.). Association for Computational Linguistics, Austin, Texas, 876&#x2013;885. <a class="link-inline force-break" href="https://aclweb.org/anthology/D16-1084"      target="_blank">https://aclweb.org/anthology/D16-1084</a></li>    <li id="BibPLXBIB0003" label="[3]">Mevan Babakar and Will Moy. 2016. The State of Automated Factchecking. https://fullfact.org/media/uploads/full_fact-the_state_of_automated_factchecking_aug_2016.pdf. (2016).</li>    <li id="BibPLXBIB0004" label="[4]">Roy Bar-Haim, Indrajit Bhattacharya, Francesco Dinuzzo, Amrita Saha, and Noam Slonim. 2017. Stance Classification of Context-Dependent Claims. In <em>      <em>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</em>     </em>. Association for Computational Linguistics, Valencia, Spain, 251&#x2013;261. <a class="link-inline force-break" href="http://www.aclweb.org/anthology/E17-1024"      target="_blank">http://www.aclweb.org/anthology/E17-1024</a></li>    <li id="BibPLXBIB0005" label="[5]">Adnene Belfodil, Sylvie Cazalens, Philippe Lamarre, and Marc Plantevit. 2017. Flash Points: Discovering Exceptional Pairwise Behaviors in Vote or Rating Data. In <em>      <em>Machine Learning and Knowledge Discovery in Databases - European Conference, ECML PKDD 2017, Skopje, Macedonia, September 18-22, 2017, Proceedings, Part II</em>     </em>(<em>Lecture Notes in Computer Science</em>), Michelangelo Ceci, Jaakko Hollm&#x00E9;n, Ljupco Todorovski, Celine Vens, and Saso Dzeroski (Eds.). Vol.&#x00A0;10535. Springer, 442&#x2013;458. <a class="link-inline force-break"      href="https://doi.org/10.1007/978-3-319-71246-8_27"      target="_blank">https://doi.org/10.1007/978-3-319-71246-8_27</a></li>    <li id="BibPLXBIB0006" label="[6]">Gajanan&#x00A0;K. Birajdar and Vijay&#x00A0;H. Mankar. 2013. Digital Image Forgery Detection Using Passive Techniques: A Survey. <em>      <em>Digit. Investig.</em>     </em>10, 3 (Oct. 2013), 226&#x2013;245. <a class="link-inline force-break"      href="https://doi.org/10.1016/j.diin.2013.04.007"      target="_blank">https://doi.org/10.1016/j.diin.2013.04.007</a></li>    <li id="BibPLXBIB0007" label="[7]">Leticia Bode and Emily&#x00A0;K. Vraga. 2015. In Related News, That Was Wrong: The Correction of Misinformation Through Related Stories Functionality in Social Media. <em>      <em>Journal of Communication</em>     </em>65, 4 (2015), 619&#x2013;638. <a class="link-inline force-break" href="https://doi.org/10.1111/jcom.12166"      target="_blank">https://doi.org/10.1111/jcom.12166</a></li>    <li id="BibPLXBIB0008" label="[8]">Rapha&#x00EB;l Bonaque, T.&#x00A0;D. Cao, Bogdan Cautis, Fran&#x00E7;ois Goasdou&#x00E9;, J. Letelier, Ioana Manolescu, O. Mendoza, S. Ribeiro, Xavier Tannier, and Micha&#x00EB;l Thomazo. 2016. Mixed-instance querying: a lightweight integration architecture for data journalism. <em>      <em>PVLDB</em>     </em>9, 13 (2016), 1513&#x2013;1516.</li>    <li id="BibPLXBIB0009" label="[9]">Allan Borodin, Gareth&#x00A0;O. Roberts, Jeffrey&#x00A0;S. Rosenthal, and Panayiotis Tsaparas. 2005. Link Analysis Ranking: Algorithms, Theory, and Experiments. <em>      <em>ACM Trans. Internet Technol.</em>     </em>5, 1 (Feb. 2005), 231&#x2013;297. <a class="link-inline force-break" href="https://doi.org/10.1145/1052934.1052942"      target="_blank">https://doi.org/10.1145/1052934.1052942</a></li>    <li id="BibPLXBIB0010" label="[10]">Samuel&#x00A0;R. Bowman, Gabor Angeli, Christopher Potts, and Christopher&#x00A0;D. Manning. 2015. A large annotated corpus for learning natural language inference. In <em>      <em>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>     </em>. Association for Computational Linguistics.</li>    <li id="BibPLXBIB0011" label="[11]">Giovanni&#x00A0;Luca Ciampaglia, Prashant Shiralkar, Luis&#x00A0;M. Rocha, Johan Bollen, Filippo Menczer, and Alessandro Flammini. 2015. Computational fact checking from knowledge networks. <em>      <em>PloS one</em>     </em>10, 6 (2015), e0128193.</li>    <li id="BibPLXBIB0012" label="[12]">Sarah Cohen, Hamilton&#x00A0;James T., and Fred Turner. 2011. Computational Journalism. <em>      <em>Commun. ACM</em>     </em>54, 10 (Oct. 2011), 66&#x2013;71. <a class="link-inline force-break" href="https://doi.org/10.1145/2001269.2001288"      target="_blank">https://doi.org/10.1145/2001269.2001288</a></li>    <li id="BibPLXBIB0013" label="[13]">Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The PASCAL Recognising Textual Entailment Challenge. In <em>      <em>PASCAL Challenges Workshop for Recognizing Textual Entailment</em>     </em>. <a class="link-inline force-break"      href="http://oren.glickman.com/publications/LNAI_39440177.pdf"      target="_blank">http://oren.glickman.com/publications/LNAI_39440177.pdf</a></li>    <li id="BibPLXBIB0014" label="[14]">Nicholas Diakopoulos. 2012. Cultivating the Landscape of Innovation in Computational Journalism. http://www.nickdiakopoulos.com/wp-content/uploads/2012/05/diakopoulos_whitepaper_systematicinnovation.pdf. (2012).</li>    <li id="BibPLXBIB0015" label="[15]">B. Dolan, C. Quirk, and C. Brockett. 2004. Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources. In <em>      <em>Proceedings of the 20th International Conference on Computational Linguistics (Coling 04)</em>     </em>. COLING, Geneva, Switzerland.</li>    <li id="BibPLXBIB0016" label="[16]">Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014. Knowledge Vault: A Web-scale Approach to Probabilistic Knowledge Fusion. In <em>      <em>Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>     </em>(<em>KDD &#x2019;14</em>). ACM, New York, NY, USA, 601&#x2013;610. <a class="link-inline force-break" href="https://doi.org/10.1145/2623330.2623623"      target="_blank">https://doi.org/10.1145/2623330.2623623</a></li>    <li id="BibPLXBIB0017" label="[17]">Xin&#x00A0;Luna Dong, Laure Berti-Equille, and Divesh Srivastava. 2009. Truth discovery and copying detection in a dynamic world. <em>      <em>Proceedings of the VLDB Endowment</em>     </em>2, 1 (2009), 562&#x2013;573.</li>    <li id="BibPLXBIB0018" label="[18]">Xin&#x00A0;Luna Dong, Evgeniy Gabrilovich, Kevin Murphy, Van Dang, Wilko Horn, Camillo Lugaresi, Shaohua Sun, and Wei Zhang. 2015. Knowledge-Based Trust: Estimating the Trustworthiness of Web Sources. In <em>      <em>Proceedings of the VLDB Endowment</em>     </em>. <a class="link-inline force-break" href="http://arxiv.org/pdf/1502.03519v1.pdf"      target="_blank">http://arxiv.org/pdf/1502.03519v1.pdf</a></li>    <li id="BibPLXBIB0019" label="[19]">Rob Ennals, Beth Trushkowsky, and John&#x00A0;Mark Agosta. 2010. Highlighting disputed claims on the web. In <em>      <em>Proceedings of the 19th international conference on World wide web</em>     </em>. ACM, 341&#x2013;350.</li>    <li id="BibPLXBIB0020" label="[20]">Adam Faulkner. 2014. Automated Classification of Stance in Student Essays: An Approach Using Stance Target Information and the Wikipedia Link-Based Measure. In <em>      <em>Proceedings of the Twenty-Seventh International Florida Artificial Intelligence Research Society Conference</em>     </em>. Association for the Advancement of Artificial Intelligence, Pensacola Beach, USA. <a class="link-inline force-break"      href="https://pdfs.semanticscholar.org/2e8d/01e2fcf7ad7bfc889360a7c9c495effbdc34.pdf"      target="_blank">https://pdfs.semanticscholar.org/2e8d/01e2fcf7ad7bfc889360a7c9c495effbdc34.pdf</a></li>    <li id="BibPLXBIB0021" label="[21]">William Ferreira and Andreas Vlachos. 2016. Emergent: a novel data-set for stance classification. In <em>      <em>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>     </em>. Association for Computational Linguistics, San Diego, California, 1163&#x2013;1168. <a class="link-inline force-break" href="http://www.aclweb.org/anthology/N16-1138"      target="_blank">http://www.aclweb.org/anthology/N16-1138</a></li>    <li id="BibPLXBIB0022" label="[22]">Michael Franklin, Alon Halevy, and David Maier. 2005. From Databases to Dataspaces: A New Abstraction for Information Management. <em>      <em>SIGMOD Record</em>     </em>34, 4 (Dec. 2005), 27&#x2013;33. <a class="link-inline force-break" href="https://doi.org/10.1145/1107499.1107502"      target="_blank">https://doi.org/10.1145/1107499.1107502</a></li>    <li id="BibPLXBIB0023" label="[23]">R.&#x00A0;Kelly Garrett. 2009. Echo chambers online?: Politically motivated selective exposure among Internet news users1. <em>      <em>Journal of Computer-Mediated Communication</em>     </em>14, 2 (2009), 265&#x2013;285. <a class="link-inline force-break"      href="https://doi.org/10.1111/j.1083-6101.2009.01440.x"      target="_blank">https://doi.org/10.1111/j.1083-6101.2009.01440.x</a></li>    <li id="BibPLXBIB0024" label="[24]">R.&#x00A0;Kelly Garrett. 2016. Facebook&#x0027;s problem is more complicated than fake news. http://theconversation.com/facebooks-problem-is-more-complicated-than-fake-news-68886. (2016).</li>    <li id="BibPLXBIB0025" label="[25]">R.&#x00A0;Kelly Garrett and Brian&#x00A0;E. Weeks. 2013. The promise and peril of real-time corrections to political misperceptions. In <em>      <em>Proceedings of the 2013 conference on Computer supported cooperative work</em>     </em>. ACM, 1047&#x2013;1058.</li>    <li id="BibPLXBIB0026" label="[26]">Daniel Gerber, Diego Esteves, Jens Lehmann, Lorenz B&#x00FC;hmann, Ricardo Usbeck, Axel-Cyrille&#x00A0;Ngonga Ngomo, and Ren&#x00E9; Speck. 2015. DeFacto&#x2014;Temporal and multilingual Deep Fact Validation. <em>      <em>Web Semantics: Science, Services and Agents on the World Wide Web</em>     </em>35 (2015), 85&#x2013;101.</li>    <li id="BibPLXBIB0027" label="[27]">Fran&#x00E7;ois Goasdou&#x00E9;, Konstantinos Karanasos, Yannis Katsis, Julien Leblay, Ioana Manolescu, and Stamatis Zampetakis. 2013. Fact checking and analyzing the web. In <em>      <em>SIGMOD</em>     </em>, Kenneth&#x00A0;A. Ross, Divesh Srivastava, and Dimitris Papadias (Eds.). ACM, 997&#x2013;1000. <a class="link-inline force-break" href="https://doi.org/10.1145/2463676.2463692"      target="_blank">https://doi.org/10.1145/2463676.2463692</a></li>    <li id="BibPLXBIB0028" label="[28]">Alan Greenblatt. 2017. The Future of Fact-Checking: Moving ahead in political accountability journalism. https://www.americanpressinstitute.org/publications/reports/white-papers/future-of-fact-checking/. (2017).</li>    <li id="BibPLXBIB0029" label="[29]">Chinnappa Guggilla, Tristan Miller, and Iryna Gurevych. 2016. CNN- and LSTM-based Claim Classification in Online User Comments. In <em>      <em>Proceedings of the 26th International Conference on Computational Linguistics: Technical Papers (COLING 2016)</em>     </em>. 2740&#x2013;2751. <a class="link-inline force-break"      href="https://www.ukp.tu-darmstadt.de/fileadmin/user_upload/Group_UKP/publikationen/2016/2016_COLING_CG.pdf"      target="_blank">https://www.ukp.tu-darmstadt.de/fileadmin/user_upload/Group_UKP/publikationen/2016/2016_COLING_CG.pdf</a></li>    <li id="BibPLXBIB0030" label="[30]">Kazi&#x00A0;Saidul Hasan and Vincent Ng. 2013. Stance Classification of Ideological Debates: Data, Models, Features, and Constraints. In <em>      <em>Proceedings of the Sixth International Joint Conference on Natural Language Processing</em>     </em>. Asian Federation of Natural Language Processing, Nagoya, Japan, 1348&#x2013;1356. <a class="link-inline force-break" href="http://www.aclweb.org/anthology/I13-1191"      target="_blank">http://www.aclweb.org/anthology/I13-1191</a></li>    <li id="BibPLXBIB0031" label="[31]">Naeemul Hassan, Chengkai Li, and Mark Tremayne. 2015. Detecting check-worthy factual claims in presidential debates. In <em>      <em>Proceedings of International on Conference on Information and Knowledge Management</em>     </em>. ACM, 1835&#x2013;1838.</li>    <li id="BibPLXBIB0032" label="[32]">Naeemul Hassan, Gensheng Zhang, Fatma Arslan, Josue Caraballo, Damian Jimenez, Siddhant Gawsane, Shohedul Hasan, Minumol Joseph, Aaditya Kulkarni, Anil&#x00A0;Kumar Nayak, and others. 2017. ClaimBuster: The First-ever End-to-end Fact-checking System. <em>      <em>Proceedings of the VLDB Endowment</em>     </em>10, 7 (2017).</li>    <li id="BibPLXBIB0033" label="[33]">Julien Leblay. 2017. A Declarative Approach to Data-Driven Fact Checking.. In <em>      <em>AAAI</em>     </em>. 147&#x2013;153.</li>    <li id="BibPLXBIB0034" label="[34]">Jens Lehmann, Daniel Gerber, Mohamed Morsey, and Axel-Cyrille&#x00A0;Ngonga Ngomo. 2012. DeFacto-deep fact validation. In <em>      <em>International Semantic Web Conference</em>     </em>. Springer, 312&#x2013;327.</li>    <li id="BibPLXBIB0035" label="[35]">Ran Levy, Yonatan Bilu, Daniel Hershcovich, Ehud Aharoni, and Noam Slonim. 2014. Context Dependent Claim Detection. In <em>      <em>Proceedings of the 25th International Conference on Computational Linguistics (COLING 2014)</em>     </em>. Dublin City University and Association for Computational Linguistics, Dublin, Ireland, 1489&#x2013;1500. <a class="link-inline force-break" href="http://www.aclweb.org/anthology/C14-1141"      target="_blank">http://www.aclweb.org/anthology/C14-1141</a></li>    <li id="BibPLXBIB0036" label="[36]">Yaliang Li, Jing Gao, Chuishi Meng, Qi Li, Lu Su, Bo Zhao, Wei Fan, and Jiawei Han. 2016. A survey on truth discovery. <em>      <em>Acm Sigkdd Explorations Newsletter</em>     </em>17, 2 (2016), 1&#x2013;16.</li>    <li id="BibPLXBIB0037" label="[37]">Amnon Lotan, Asher Stern, and Ido Dagan. 2013. TruthTeller: Annotating Predicate Truth. In <em>      <em>Proceedings of NAACL-HLT 2013</em>     </em>. Atlanta, USA, 752&#x2013;757. <a class="link-inline force-break" href="http://www.aclweb.org/anthology/N13-1091"      target="_blank">http://www.aclweb.org/anthology/N13-1091</a></li>    <li id="BibPLXBIB0038" label="[38]">Ioana Manolescu. 2017. ContentCheck: Content Management Techniques and Tools for Fact-checking. <em>      <em>ERCIM News</em>     </em> (Oct. 2017). <a class="link-inline force-break" href="https://hal.inria.fr/hal-01596563"      target="_blank">https://hal.inria.fr/hal-01596563</a></li>    <li id="BibPLXBIB0039" label="[39]">Saif Mohammad, Svetlana Kiritchenko, Parinaz Sobhani, Xiaodan Zhu, and Colin Cherry. 2016. SemEval-2016 Task 6: Detecting Stance in Tweets. In <em>      <em>Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</em>     </em>. Association for Computational Linguistics, San Diego, California, 31&#x2013;41. <a class="link-inline force-break" href="http://www.aclweb.org/anthology/S16-1003"      target="_blank">http://www.aclweb.org/anthology/S16-1003</a></li>    <li id="BibPLXBIB0040" label="[40]">Akiko Murakami and Rudy Raymond. 2010. Support or Oppose? Classifying Positions in Online Debates from Reply Activities and Opinion Expressions. In <em>      <em>Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010)</em>     </em>. Beijing, China, 869&#x2013;875. <a class="link-inline force-break" href="http://www.aclweb.org/anthology/C10-2100"      target="_blank">http://www.aclweb.org/anthology/C10-2100</a></li>    <li id="BibPLXBIB0041" label="[41]">Brendan Nyhan and Jason Reifler. 2010. When Corrections Fail: The Persistence of Political Misperceptions. <em>      <em>Political Behavior</em>     </em>32, 2 (01 Jun 2010), 303&#x2013;330. <a class="link-inline force-break"      href="https://doi.org/10.1007/s11109-010-9112-2"      target="_blank">https://doi.org/10.1007/s11109-010-9112-2</a></li>    <li id="BibPLXBIB0042" label="[42]">Ramesh&#x00A0;C. Pandey, Sanjay&#x00A0;K. Singh, and Kaushal&#x00A0;K. Shukla. 2016. Passive Forensics in Image and Video Using Noise Features: A Review. <em>      <em>Digital Investigation</em>     </em>19, C (Dec. 2016), 1&#x2013;28. <a class="link-inline force-break"      href="https://doi.org/10.1016/j.diin.2016.08.002"      target="_blank">https://doi.org/10.1016/j.diin.2016.08.002</a></li>    <li id="BibPLXBIB0043" label="[43]">Joonsuk Park and Claire Cardie. 2014. Identifying Appropriate Support for Propositions in Online User Comments. In <em>      <em>Proceedings of the First Workshop on Argumentation Mining</em>     </em>. Association for Computational Linguistics, Baltimore, Maryland, 29&#x2013;38. <a class="link-inline force-break" href="http://www.aclweb.org/anthology/W14-2105"      target="_blank">http://www.aclweb.org/anthology/W14-2105</a></li>    <li id="BibPLXBIB0044" label="[44]">Kashyap Popat, Subhabrata Mukherjee, Jannik Str&#x00F6;tgen, and Gerhard Weikum. 2016. Credibility Assessment of Textual Claims on the Web. In <em>      <em>CIKM</em>     </em>. ACM, 2173&#x2013;2178.</li>    <li id="BibPLXBIB0045" label="[45]">Kashyap Popat, Subhabrata Mukherjee, Jannik Str&#x00F6;tgen, and Gerhard Weikum. 2017. Where the Truth Lies: Explaining the Credibility of Emerging Claims on the Web and Social Media. In <em>      <em>Proceedings of the 26th International Conference on World Wide Web Companion</em>     </em>(<em>WWW &#x2019;17 Companion</em>). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 1003&#x2013;1012. <a class="link-inline force-break" href="https://doi.org/10.1145/3041021.3055133"      target="_blank">https://doi.org/10.1145/3041021.3055133</a></li>    <li id="BibPLXBIB0046" label="[46]">Ashwin Rajadesingan and Huan Liu. 2014. Identifying Users with Opposing Opinions in Twitter Debates. In <em>      <em>7th International Conference Social Computing, Behavioral-Cultural Modeling and Prediction</em>     </em>, William&#x00A0;G. Kennedy, Nitin Agarwal, and Shanchieh&#x00A0;Jay Yang (Eds.). Springer International Publishing, Cham, 153&#x2013;160. <a class="link-inline force-break"      href="https://doi.org/10.1007/978-3-319-05579-4_19"      target="_blank">https://doi.org/10.1007/978-3-319-05579-4_19</a></li>    <li id="BibPLXBIB0047" label="[47]">David&#x00A0;P. Redlawsk, Andrew&#x00A0;JW. Civettini, and Karen&#x00A0;M. Emmerson. 2010. The affective tipping point: Do motivated reasoners ever &#x201C;get it&#x201D;?<em>      <em>Political Psychology</em>     </em>31, 4 (2010), 563&#x2013;593.</li>    <li id="BibPLXBIB0048" label="[48]">Victoria&#x00A0;L. Rubin. 2017. News Verification Suite: Towards System Design to Supplement Reporters&#x2019; and Editors&#x2019; Judgements. In <em>      <em>Proceedings of the 45th Annual Conference of The Canadian Association for Information Science/ L&#x0027;Association canadienne des sciences de l&#x0027;information (CAIS/ACSI2017)</em>     </em>.</li>    <li id="BibPLXBIB0049" label="[49]">Victoria&#x00A0;L. Rubin, Yimin Chen, and Niall&#x00A0;J. Conroy. 2015. Deception detection for news: three types of fakes. <em>      <em>Proceedings of the Association for Information Science and Technology</em>     </em>52, 1(2015), 1&#x2013;4.</li>    <li id="BibPLXBIB0050" label="[50]">Victoria&#x00A0;L. Rubin, Niall&#x00A0;J. Conroy, Yimin Chen, and Sarah Cornwell. 2016. Fake News or Truth? Using Satirical Cues to Detect Potentially Misleading News.. In <em>      <em>Proceedings of NAACL-HLT</em>     </em>. 7&#x2013;17.</li>    <li id="BibPLXBIB0051" label="[51]">Misa Sato, Kohsuke Yanai, Toshinori Miyoshi, Toshihiko Yanase, Makoto Iwayama, Qinghua Sun, and Yoshiki Niwa. 2015. End-to-end Argument Generation System in Debating. In <em>      <em>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL), System Demonstrations</em>     </em>. 109&#x2013;114. <a class="link-inline force-break"      href="http://aclweb.org/anthology/P/P15/P15-4019.pdf"      target="_blank">http://aclweb.org/anthology/P/P15/P15-4019.pdf</a></li>    <li id="BibPLXBIB0052" label="[52]">Baoxu Shi and Tim Weninger. 2016. Fact Checking in Heterogeneous Information Networks. In <em>      <em>Proceedings of the 25th International Conference Companion on World Wide Web</em>     </em>(<em>WWW &#x2019;16 Companion</em>). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 101&#x2013;102. <a class="link-inline force-break" href="https://doi.org/10.1145/2872518.2889354"      target="_blank">https://doi.org/10.1145/2872518.2889354</a></li>    <li id="BibPLXBIB0053" label="[53]">Jieun Shin, Lian Jian, Kevin Driscoll, and Fran&#x00E7;ois Bar. 2017. Political rumoring on Twitter during the 2012 US presidential election: Rumor diffusion and correction. <em>      <em>New Media &#x0026; Society</em>     </em>19, 8 (2017), 1214&#x2013;1235. <a class="link-inline force-break" href="https://doi.org/10.1177/1461444816634054"      target="_blank">https://doi.org/10.1177/1461444816634054</a>arXiv:https://doi.org/10.1177/1461444816634054</li>    <li id="BibPLXBIB0054" label="[54]">Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake News Detection on Social Media: A Data Mining Perspective. <em>      <em>ACM SIGKDD Explorations Newsletter</em>     </em>19, 1 (2017), 22&#x2013;36.</li>    <li id="BibPLXBIB0055" label="[55]">K. Sitara and B.M. Mehtre. 2016. Digital Video Tampering Detection: An Overview of Passive Techniques. <em>      <em>Digital Investigation</em>     </em>18, C (Sept. 2016), 8&#x2013;22. <a class="link-inline force-break"      href="https://doi.org/10.1016/j.diin.2016.06.003"      target="_blank">https://doi.org/10.1016/j.diin.2016.06.003</a></li>    <li id="BibPLXBIB0056" label="[56]">Swapna Somasundaran and Janyce Wiebe. 2009. Recognizing Stances in Online Debates. In <em>      <em>Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</em>     </em>. Association for Computational Linguistics, Suntec, Singapore, 226&#x2013;234. <a class="link-inline force-break"      href="http://www.aclweb.org/anthology/P/P09/P09-1026"      target="_blank">http://www.aclweb.org/anthology/P/P09/P09-1026</a></li>    <li id="BibPLXBIB0057" label="[57]">Matthew&#x00A0;C. Stamm, Min Wu, and Kuo J.&#x00A0;Ray Liu. 2013. Information Forensics: An Overview of the First Decade. <em>      <em>IEEE Access</em>     </em>1(2013), 167&#x2013;200. <a class="link-inline force-break"      href="https://doi.org/10.1109/ACCESS.2013.2260814"      target="_blank">https://doi.org/10.1109/ACCESS.2013.2260814</a></li>    <li id="BibPLXBIB0058" label="[58]">Jonathan Stray. 2017. Defense Against the Dark Arts: Networked Propaganda and Counter-Propaganda. http://jonathanstray.com/networked-propaganda-and-counter-propaganda. (2017).</li>    <li id="BibPLXBIB0059" label="[59]">Jonathan Stray. 2017. Introducing the CJ Workbench. http://jonathanstray.com/introducing-the-cj-workbench. (2017).</li>    <li id="BibPLXBIB0060" label="[60]">Mihai Surdeanu. 2013. Overview of the TAC2013 Knowledge Bbase Population Evaluation: English Slot Filling and Temporal Slot Filling. In <em>      <em>Proceedings of the TAC-KBP 2013 Workshop</em>     </em>.</li>    <li id="BibPLXBIB0061" label="[61]">Denis Teyssou, Jean-Michel Leung, Evlampios Apostolidis, Konstantinos Apostolidis, Symeon Papadopoulos, Markos Zampoglou, Olga Papadopoulou, and Vasileios Mezaris. 2017. The InVID Plug-in: Web Video Verification on the Browser. In <em>      <em>Proceedings of the 1st International Workshop on Multimedia Verification</em>     </em>. Mountain View, USA. <a class="link-inline force-break"      href="http://www.iti.gr/~bmezaris/publications/mm17_2_preprint.pdf"      target="_blank">http://www.iti.gr/~bmezaris/publications/mm17_2_preprint.pdf</a></li>    <li id="BibPLXBIB0062" label="[62]">Matt Thomas, Bo Pang, and Lillian Lee. 2006. Get out the vote: Determining support or opposition from Congressional floor-debate transcripts. In <em>      <em>Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</em>     </em>. Association for Computational Linguistics, Sydney, Australia, 327&#x2013;335. <a class="link-inline force-break"      href="https://www.cs.cornell.edu/home/llee/papers/tpl-convote.dec06.pdf"      target="_blank">https://www.cs.cornell.edu/home/llee/papers/tpl-convote.dec06.pdf</a></li>    <li id="BibPLXBIB0063" label="[63]">Andreas Vlachos and Sebastian Riedel. 2014. Fact Checking: Task definition and dataset construction. In <em>      <em>ACL 2014 Workshop on Language Technologies and Computational Social Science</em>     </em>. 18&#x2013;22. <a class="link-inline force-break" href="http://aclweb.org/anthology/W14-2508"      target="_blank">http://aclweb.org/anthology/W14-2508</a></li>    <li id="BibPLXBIB0064" label="[64]">Marilyn Walker, Jean&#x00A0;Fox Tree, Pranav Anand, Rob Abbott, and Joseph King. 2012. A Corpus for Research on Deliberation and Debate. In <em>      <em>Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&#x2019;12)</em>     </em>(23-25), Nicoletta Calzolari&#x00A0;(Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet&#x00A0;U&#x011F;ur Do&#x011F;an, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis (Eds.). European Language Resources Association (ELRA), Istanbul, Turkey.</li>    <li id="BibPLXBIB0065" label="[65]">Thomas Wood and Ethan Porter. 2016. The elusive backfire effect: mass attitudes&#x2019; steadfast factual adherence. <em>      <em>Political Behavior</em>     </em> (2016), 1&#x2013;29.</li>    <li id="BibPLXBIB0066" label="[66]">You Wu, Pankaj&#x00A0;K Agarwal, Chengkai Li, Jun Yang, and Cong Yu. 2014. Toward computational fact-checking. <em>      <em>Proceedings of the VLDB Endowment</em>     </em>7, 7 (2014), 589&#x2013;600.</li>    <li id="BibPLXBIB0067" label="[67]">You Wu, Pankaj&#x00A0;K Agarwal, Chengkai Li, Jun Yang, and Cong Yu. 2017. Computational Fact Checking through Query Perturbations. <em>      <em>ACM Transactions on Database Systems (TODS)</em>     </em>42, 1 (2017), 4.</li>    <li id="BibPLXBIB0068" label="[68]">You Wu, Junyang Gao, Pankaj&#x00A0;K Agarwal, and Jun Yang. 2017. Finding diverse, high-value representatives on a surface of answers. <em>      <em>Proceedings of the VLDB Endowment</em>     </em>10, 7 (2017), 793&#x2013;804.</li>    <li id="BibPLXBIB0069" label="[69]">Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards Answering Opinion Questions: Separating Facts from Opinions and Identifying the Polarity of Opinion Sentences. In <em>      <em>Proceedings of 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>     </em>. 129&#x2013;136.</li>    <li id="BibPLXBIB0070" label="[70]">Markos Zampoglou, Symeon Papadopoulos, and Yiannis Kompatsiaris. 2017. Large-scale Evaluation of Splicing Localization Algorithms for Web Images. <em>      <em>Multimedia Tools Appl.</em>     </em>76, 4 (Feb. 2017), 4801&#x2013;4834. <a class="link-inline force-break"      href="https://doi.org/10.1007/s11042-016-3795-2"      target="_blank">https://doi.org/10.1007/s11042-016-3795-2</a></li>    <li id="BibPLXBIB0071" label="[71]">&#x00C1;lvaro Rodrigo, Anselmo Pe&#x00F1;as, and Felisa Verdejo. 2008. Overview of the Answer Validation Exercise 2008. In <em>      <em>Proceedings of the 9th Workshop of the Cross-Language Evaluation Forum, CLEF 2008</em>     </em>. 296&#x2013;313.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>While most fact-checkers are journalists by trade, others are concerned citizens focusing on a special topic, e.g.&#x00A0; water pollution in a given city, scientists working on a topic where politics hotly disputes scientific truth etc.</p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break"    href="https://www.washingtonpost.com/news/fact-checker">https://www.washingtonpost.com/news/fact-checker</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>http://www.lemonde.fr/les-decodeurs/</p>   <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>http://www.liberation.fr/desintox</p>   <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>There can be disagreement on what is a reliable source. In this paper, we consider a source reliable to the extent that the fact checker trusts it, and/or there is significant consensus (e.g. by a very large majority) on its trustworthiness.</p>   <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a><a class="link-inline force-break"    href="https://www.poynter.org/international-fact-checking-network-fact-checkers-code-principles">https://www.poynter.org/international-fact-checking-network-fact-checkers-code-principles</a>   </p>   <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a><a class="link-inline force-break"    href="https://newsroom.fb.com/news/2017/12/news-feed-fyi-updates-in-our-fight-against-misinformation/">https://newsroom.fb.com/news/2017/12/news-feed-fyi-updates-in-our-fight-against-misinformation/</a>   </p>   <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a><a class="link-inline force-break" href="http://www.fakenewschallenge.org/">http://www.fakenewschallenge.org/</a>   </p>   <p id="fn9"><a href="#foot-fn9"><sup>9</sup></a><a class="link-inline force-break" href="http://truthteller.washingtonpost.com/">http://truthteller.washingtonpost.com/</a>   </p>   <p id="fn10"><a href="#foot-fn10"><sup>10</sup></a>https://herox.com/factcheck/</p>   <p id="fn11"><a href="#foot-fn11"><sup>11</sup></a><a class="link-inline force-break" href="http://www.lemonde.fr/les-decodeurs/">http://www.lemonde.fr/les-decodeurs/</a>   </p>   <p id="fn12"><a href="#foot-fn12"><sup>12</sup></a>http://s1.lemde.fr/mmpub/data/decodex/hoax/hoax_debunks.json</p>   <p id="fn13"><a href="#foot-fn13"><sup>13</sup></a>https://www.blog.google/products/search/fact-check-now-available-google-search-and-news-around-world/</p>   <p id="fn14"><a href="#foot-fn14"><sup>14</sup></a><a class="link-inline force-break"    href="https://reporterslab.org/structured-journalism/">https://reporterslab.org/structured-journalism/</a>   </p>   <p id="fn15"><a href="#foot-fn15"><sup>15</sup></a>A striking recent example is an analysis of the way Wisconsin voting districts are drawn (<a class="link-inline force-break"    href="https://www.nytimes.com/2017/10/06/opinion/sunday/computers-gerrymandering-wisconsin.html">https://www.nytimes.com/2017/10/06/opinion/sunday/computers-gerrymandering-wisconsin.html</a>), highlighting the (very) low probability that they may result from an &#x201C;honest&#x201D; design. In the article&#x0027;s words, &#x201C;it&#x0027;s math versus math, with democracy at stake&#x201D;.</p>   <p id="fn16"><a href="#foot-fn16"><sup>16</sup></a><a class="link-inline force-break" href="https://crosscheck.firstdraftnews.com/">https://crosscheck.firstdraftnews.com/</a>   </p>   <p id="fn17"><a href="#foot-fn17"><sup>17</sup></a>International Consortium of Investigative Journalists, behind the Panama Papers and other such high-profile international investigations.</p>   <p id="fn18"><a href="#foot-fn18"><sup>18</sup></a>See e.g. the course &#x201C;Calling Bullshit: Data Reasoning in a Digital World&#x201D; created at U.&#x00A0;Washington, <a class="link-inline force-break" href="http://callingbullshit.org/syllabus.html">http://callingbullshit.org/syllabus.html</a>   </p>   <p id="fn19"><a href="#foot-fn19"><sup>19</sup></a><a class="link-inline force-break"    href="http://ropensci.github.io/reproducibility-guide/">http://ropensci.github.io/reproducibility-guide/</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3188727">https://doi.org/10.1145/3184558.3188727</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
