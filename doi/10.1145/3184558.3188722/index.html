<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Fake News Detection in Social Networks via Crowd Signals</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Fake News Detection in Social Networks via Crowd Signals</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Sebastian</span>      <span class="surName">Tschiatschek</span><a class="fn" href="#fn1" id="foot-fn1"><sup>&#x002A;</sup></a>,     Microsoft Research, Cambridge, United Kingdom, <a href="mailto:setschia@microsoft.com">setschia@microsoft.com</a>     </div>     <div class="author">     <span class="givenName">Adish</span>      <span class="surName">Singla</span>,     MPI-SWS, Saarbr&#x00FC;cken, Germany, <a href="mailto:adishs@mpi-sws.org">adishs@mpi-sws.org</a>     </div>     <div class="author">     <span class="givenName">Manuel Gomez</span>      <span class="surName">Rodriguez</span>,     MPI-SWS, Kaiserslautern, Germany, <a href="mailto:manuelgr@mpi-sws.org">manuelgr@mpi-sws.org</a>     </div>     <div class="author">     <span class="givenName">Arpit</span>      <span class="surName">Merchant</span>,     IIIT-H, Hyderabad, India, <a href="mailto:arpitdm@gmail.com">arpitdm@gmail.com</a>     </div>     <div class="author">     <span class="givenName">Andreas</span>      <span class="surName">Krause</span>,     ETH Zurich, Zurich, Switzerland, <a href="mailto:krausea@ethz.ch">krausea@ethz.ch</a>     </div>                         </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3188722" target="_blank">https://doi.org/10.1145/3184558.3188722</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Our work considers leveraging crowd signals for detecting fake news and is motivated by tools recently introduced by Facebook that enable users to flag fake news. By aggregating users&#x2019; flags, our goal is to select a small subset of news every day, send them to an expert (e.g., via a third-party fact-checking organization), and stop the spread of news identified as fake by an expert. The main objective of our work is to minimize <em>the spread of misinformation</em> by stopping the propagation of fake news in the network. It is especially challenging to achieve this objective as it requires detecting fake news with high-confidence as quickly as possible. We show that in order to leverage users&#x2019; flags efficiently, it is crucial to learn about users&#x2019; flagging accuracy. We develop a novel algorithm, <SmallCap>Detective</SmallCap>, that performs Bayesian inference for detecting fake news and jointly learns about users&#x2019; flagging accuracy over time. Our algorithm employs posterior sampling to actively trade off exploitation (selecting news that maximize the objective value at a given epoch) and exploration (selecting news that maximize the value of information towards learning about users&#x2019; flagging accuracy). We demonstrate the effectiveness of our approach via extensive experiments and show the power of leveraging community signals for fake news detection.</small>     </p>    </div>    <div class="classifications">     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Sebastian Tschiatschek, Adish Singla, Manuel Gomez Rodriguez, Arpit Merchant, and Andreas Krause. 2018. Fake News Detection in Social Networks via Crowd Signals. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em>, 8 Pages. <a href="https://doi.org/10.1145/3184558.3188722" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3188722</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>Fake news (a.k.a. hoaxes, rumors, etc.) and the spread of misinformation have dominated the news cycle since the US presidential election (2016). Social media sites and online social networks, for example Facebook and Twitter, have faced scrutiny for being unable to curb the spread of fake news. There are various motivations for generating and spreading fake news, for instance, making political gains, harming the reputation of businesses, as clickbait for increasing advertising revenue, and for seeking attention<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a>. As a concrete example, Starbucks recently fell victim to fake news with a hoax advertisement claiming that the coffee chain would give free coffee to undocumented immigrants<a class="fn" href="#fn3" id="foot-fn3"><sup>2</sup></a>. While Starbucks raced to deny this claim by responding to individual users on social media, the lightening speed of the spread of this hoax news in online social media highlighted the seriousness of the problem and the critical need to develop new techniques to tackle this challenge. To this end, Facebook has recently announced a series of efforts towards tackling this challenge [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>].</p>    <p>     <strong>Detection via expert&#x0027;s verification.</strong>Fake news and misinformation have historically been used as tools for making political or business gains [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>]. However, traditional approaches based on verification by human editors and expert journalists do not scale to the volume of news content that is generated in online social networks. In fact, it is this volume as well as the lightening speed of spread in these networks that makes this problem challenging and requires us to develop new computational techniques. We note that such computational techniques would typically complement, and not replace, the expert verification process&#x2014;even if a news is detected as fake, some sort of expert verification is needed before one would actually block it. This has given rise to a number of third-party fact-checking organizations such as Snopes<a class="fn" href="#fn4" id="foot-fn4"><sup>3</sup></a> and Factcheck.org<a class="fn" href="#fn5" id="foot-fn5"><sup>4</sup></a> as well as a code of principles&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>] that should be followed by these organizations.</p>    <p>     <strong>Detection using computational methods.</strong> There has been a recent surge in interest towards developing computational methods for detecting fake news (cf., [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>] for a survey)&#x2014;we provide a more detailed overview of these methods in the Related Work section. These methods are typically based on building predictive models to classify whether a news is fake or not via using a combination of features related to news content, source reliability, and network structure. One of the major challenges in training such predictive models is the limited availability of corpora and the subjectivity of labelling news as fake&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>]. Furthermore, it is difficult to design methods based on estimating source reliability and network structure as the number of users who act as sources is diverse and gigantic (e.g., over one billion users on Facebook); and the sources of fake news could be normal users who unintentionally share a news story without realizing that the news is fake. A surge of interest in the problem and in overcoming these technical challenges has led to the establishment of a volunteering based association&#x2014;FakeNewsChallenge<a class="fn" href="#fn6" id="foot-fn6"><sup>5</sup></a>&#x2014;comprising over 100 volunteers and 70 teams which organizes machine learning competitions related to the problem of detecting fake news.</p>    <section id="sec-7">     <header>     <div class="title-info">      <h3>       <span class="section-number">1.1</span> Leveraging users&#x2019; flags.</h3>     </div>     </header>     <p>Given the limitation of the current state-of-the-art computational methods, an alternate approach is to develop hybrid human-AI methods via engaging users of online social networks by enabling them to report fake news. In fact, Facebook has recently taken steps towards this end by launching a fake news reporting tool in Germany [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>], as shown in Figure&#x00A0;<a class="fig" href="#fig1">1</a>. The idea of this tool is that as news propagates through the network, users can flag the news as fake. <figure id="fig1">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3188722/images/www18companion-230-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 1:</span>       <span class="figure-title">Facebook has launched tools in Germany to report fake news. Image source: [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0011">11</a>].</span>      </div>     </figure> As proposed by&#x00A0;Facebook [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>], the aggregated users&#x2019; flags as well as well as other available signals can be used to identify a set of news which potentially is fake. These news can then be sent to an expert for review via a third-party fact-checking organization. If an expert labels the news as fake, it could be removed from the network or marked as disputed making it appear lower in news-feed ranking. The contemporary work by Kim et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0016">16</a>] explored the idea of detecting fake news via leveraging users&#x2019; flagging activity by using the framework of marked temporal point processes. We highlight the key differences of their approach to ours in the next section.</p>    </section>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">1.2</span> Our Contributions</h3>     </div>     </header>     <p>In this paper, we develop algorithmic tools to effectively utilize the power of the crowd (flagging activity of users) to detect fake news. Given a set of news, our goal is to select a small subset of <em>k</em> news, send them to an expert for review, and then block the news which are labeled as fake by the expert. We formalize our objective as to minimize <em>the spread of misinformation</em>, i.e., how many users end up seeing a fake news before it is blocked. We design our algorithm <SmallCap>Detective</SmallCap>, which implements a Bayesian approach for learning about users&#x2019; accuracies over time as well as for performing inference to find which news are fake with high confidence. In short, our main contributions include:</p>     <ul class="list-no-style">     <li id="list1" label="&#x2022;">We formalize the problem of leveraging users&#x2019; flagging activity for detection of fake news. We showcase the need to learn about users&#x2019; accuracy in order to effectively leverage their flags in a robust way.<br/></li>     <li id="list2" label="&#x2022;">We develop a tractable Bayesian algorithm, <SmallCap>Detective</SmallCap>, that actively trades off between exploitation (selecting news that directly maximize the objective value) and exploration (selecting news that helps towards learning about users&#x2019; flagging accuracy).<br/></li>     <li id="list3" label="&#x2022;">We perform extensive experiments using a publicly available Facebook dataset to demonstrate the effectiveness of our approach. We plan to make the code publicly available so that other researchers can build upon our techniques for this important and timely problem of detecting fake news.<br/></li>     </ul>    </section>   </section>   <section id="sec-9">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>     </div>    </header>    <p>     <strong>Contemporary results.</strong>Kim et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>] explored the idea of detecting fake news via leveraging users&#x2019; flagging activity. In particular, they introduce a flexible representation of the above problem using the framework of marked temporal point processes. They develop an algorithm, <SmallCap>Curb</SmallCap>, to select which news to send for fact-checking via solving a novel stochastic optimal control problem. The key technical differences of the approach by Kim et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>] to ours are: (1) we learn about the flagging accuracy of individual users in an online setting; in contrast, they consider all users to be equally reliable and estimate the flagging accuracy of the population of users from historical data; (2) our algorithms are agnostic to the actual propagation dynamics of news in the network; they model the actual propagation dynamics as a continuous-time dynamical system with jumps and arrive at an algorithm by casting the problem as an optimal control problem; and (3) we use discrete epochs with a fixed budget per epoch (<em>i.e.</em>, the number of news that can be sent to an expert for reviewing); they use continuous time and consider an overall budget for their algorithm.</p>    <p>     <strong>Computational methods for detecting fake news.</strong>There is a large body of related work on rumor detection and information credibility evaluation (with a more recent focus on fake news detection) that are applicable to the problem of detecting fake news. These methods are typically based on building predictive models to classify whether a news is fake. At a high-level level, we can categorize these methods as follows: (i) based on features using news content via natural language processing techniques [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>]; (ii) via learning models of source reliability and trustworthiness [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>]; (iii) by analyzing the network structure over which a news propagated [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>]; and (iv) based on a combination of the above-mentioned features, i.e., linguistic, source, and network structure [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>]. As we pointed out in the Introduction, there are several key challenges in building accurate predictive models for identifying fake news including limited availability of corpora, subjectivity in ground truth labels, and huge variability in the sources who generate fake news (often constituting users who do it unintentionally). In short, these methods alone have so far proven to be unsuccessful in tackling the challenge of detecting fake news.</p>    <p>     <strong>Leveraging crowd signals for web applications.</strong>Crowdsourcing has been used in both industrial applications and for research studies in the context of different applications related to web security. For instance, [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>] and [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>] have evaluated the potential of leveraging the wisdom of crowds for assessing phishing websites and web security. Their studies show a high variability among users&#x2014;(i) the participation rates of users follows a power-law distribution, and (ii) the accuracy of users&#x2019; reports vary, and users with more experience tend to have higher accuracy. The authors also discuss the potential of voting fraud when using users&#x2019; reports for security related applications. Wang et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>] performed a crowdsourcing study on Amazon&#x0027;s Mechanical Turk for the task of sybil detection in online social networks. Their studies show that there is a huge variability among crowd users in terms of their reporting accuracies that needs to be taken into account for building a practical system. Chen et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>], Zheleva et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>] present a system similar to that of ours for the task of filtering email spam and SMS spam, respectively. The authors discuss a users&#x2019; reputation system whereby reliable users (based on history) can be weighted more when aggregating the reports. However, their work assumes that users&#x2019; reputation/reliability is known to the system, whereas the focus of our paper is on learning users&#x2019; reputation over time. Freeman [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>] discusses the limitations of leveraging user feedback for fake account detection in online social networks&#x2014;via data-driven studies using Linkedin data, the authors show that there is only a small number of skilled users (who have good accuracy that persists over time) for detecting fake accounts.</p>    <p>     <strong>Crowdsourcing with expert validation</strong>On a technical side, our approach can be seen as that of a semi-supervised crowdsourcing technique where users&#x2019; answers can be validated via an external expert. Hung et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>], Liu et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>] present probabilistic models to select specific news instances to be labeled by experts that would maximize the reduction in uncertainty about users&#x2019; accuracy. With a similar flavor to ours, Zhao et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>] presents a Bayesian approach to aggregate information from multiple users, and then jointly infer users&#x2019; reliability as well as ground truth labels. Similar to our approach, they model users&#x2019; accuracy via two separate parameters for false positive and false negative rates. However, their approach is studied in an unsupervised setting where no expert validation (ground truth labels) are available.</p>    <p>     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3188722/images/www18companion-230-img1.jpg" class="img-responsive" alt=""      longdesc=""/>    </p>   </section>   <section id="sec-10">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> The Model</h2>     </div>    </header>    <p>We provide a high-level specification of our model in Protocol&#x00A0;1 . There is an underlying social network denoted as <em>G</em> = (<em>U</em>, <em>E</em>) where <em>U</em> is the set of users in the network. We divide the execution into different epochs denoted as <em>t</em> = 1, 2, &#x2026;, <em>T</em>, where each epoch could denote a time window, for instance, one day. Below, we provide details of our model&#x2014;the process of news generation and spread, users&#x2019; activity of flagging the news, and selecting news to get expert&#x0027;s labels.</p>    <section id="sec-11">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> News Generation and Spread</h3>     </div>     </header>     <p>We assume that new news, denoted by the set <em>X<sup>t</sup>     </em>, are generated at the beginning of every epoch <em>t</em> (cf., line&#x00A0;4).<a class="fn" href="#fn7" id="foot-fn7"><sup>6</sup></a> In this paper, we consider a setting where each news has an underlying label (unknown to the algorithm) of being &#x201C;fake&#x201D; (<em>f</em>) or &#x201C;not fake&#x201D; (<span class="inline-equation"><span class="tex">$\bar{f}$</span>     </span>). We use random variable <em>Y</em>     <sup>*</sup>(<em>x</em>) to denote this unknown label for a news <em>x</em> and its realization is given by <span class="inline-equation"><span class="tex">$y^*(x) \in \lbrace f, \bar{f}\rbrace$</span>     </span>. The label <em>y</em>     <sup>*</sup>(<em>x</em>) can only be acquired if news <em>x</em> is sent to an expert for review who would then provide the true label. We maintain a set of &#x201C;active&#x201D; news <em>A<sup>t</sup>     </em> (cf., line&#x00A0;5) which consists of all news that have been generated by the end of epoch <em>t</em> but for which expert&#x0027;s label have not been acquired yet.</p>     <p>Each news <em>x</em> is associated with a source user who seeded this news, denoted as <em>o<sub>x</sub>     </em> (cf., line&#x00A0;4). We track the spread of news in the set <em>A<sup>t</sup>     </em> via a function <em>&#x03C0;<sup>t</sup>     </em>: <em>A<sup>t</sup>     </em> &#x2192; 2<sup>      <em>U</em>     </sup>. For a news <em>a</em> &#x2208; <em>A<sup>t</sup>     </em>, the function <em>&#x03C0;<sup>t</sup>     </em>(<em>a</em>) returns the set of users who have seen the news <em>a</em> by the end of epoch <em>t</em>. During epoch <em>t</em>, let <em>u<sup>t</sup>     </em>(<em>a</em>)&#x2286;<em>U</em>&#x2216;<em>&#x03C0;</em>     <sup>      <em>t</em> &#x2212; 1</sup>(<em>a</em>) be the set of additional users (possibly the empty set) to whom news <em>a</em> &#x2208; <em>A<sup>t</sup>     </em> propagates in epoch <em>t</em>, hence <em>&#x03C0;<sup>t</sup>     </em>(<em>a</em>) = <em>&#x03C0;</em>     <sup>      <em>t</em> &#x2212; 1</sup>(<em>a</em>)&#x222A;<em>u<sup>t</sup>     </em>(<em>a</em>) (cf., line&#x00A0;9).</p>    </section>    <section id="sec-12">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Users&#x2019; Activity of Flagging the News</h3>     </div>     </header>     <p>In epoch <em>t</em>, when a news <em>a</em> &#x2208; <em>A<sup>t</sup>     </em> propagates to a new user <em>u</em> &#x2208; <em>u<sup>t</sup>     </em>(<em>a</em>), this user can flag the news to be fake. We denote the set of users who flag news <em>a</em> as fake in epoch <em>t</em> via a set <em>l<sup>t</sup>     </em>(<em>a</em>)&#x2286;<em>u<sup>t</sup>     </em>(<em>a</em>) (cf., line&#x00A0;10). Furthermore, the function <em>&#x03C8;<sup>t</sup>     </em>(<em>a</em>) returns the complete set of users who have flagged the news <em>a</em> as fake by the end of epoch <em>t</em>.<a class="fn" href="#fn8" id="foot-fn8"><sup>7</sup></a> For any news <em>x</em> and any user <em>u</em> &#x2208; <em>U</em>, we denote the label user <em>u</em> would assign to <em>x</em> via a random variable <em>Y<sub>u</sub>     </em>(<em>x</em>). We denote the realization of <em>Y<sub>u</sub>     </em>(<em>x</em>) as <span class="inline-equation"><span class="tex">$y_u(x) \in \lbrace f, \bar{f}\rbrace$</span>     </span> where <em>y<sub>u</sub>     </em>(<em>x</em>) = <em>f</em> signifies that user has flagged the news as fake. In this paper, we consider a simple, yet realistic, probabilistic model of a user&#x0027;s flagging activity as discussed below.</p>     <p>     <strong>User abstaining from flagging activity.</strong>Reflecting the behavior of real-world users, user <em>u</em> might abstain from actively reviewing the news content (and by default, does not flag the news)&#x2014;we model this happening with a probability <em>&#x03B3;<sub>u</sub>     </em> &#x2208; [0, 1]. Intuitively, we can think of 1 &#x2212; <em>&#x03B3;<sub>u</sub>     </em> as the engagement of user <em>u</em> while participating in this crowdsourcing effort to detect fake news: <em>&#x03B3;<sub>u</sub>     </em> = 1 means that the user is not participating at all.</p>     <p>     <strong>User&#x0027;s accuracy in flagging the news.</strong>With probability (1 &#x2212; <em>&#x03B3;<sub>u</sub>     </em>), user <em>u</em> reviews the content of news <em>x</em> and labels the news. We model the accuracy/noise in the user&#x0027;s labels, conditioned on that the user is reviewing the content, as follows:</p>     <ul class="list-no-style">     <li id="list4" label="&#x2022;"><em>&#x03B1;<sub>u</sub>      </em> &#x2208; [0, 1] denotes the probability that user <em>u</em> would not flag the news as fake, conditioned on that <em>news <em>x</em> is not fake and the user is reviewing the content</em>.<br/></li>     <li id="list5" label="&#x2022;"><em>&#x03B2;<sub>u</sub>      </em> &#x2208; [0, 1] denotes the probability that user <em>u</em> would flag the news as fake, conditioned on that <em>news <em>x</em> is fake and the user is reviewing the content</em>.<br/></li>     </ul>     <p>     <strong>User&#x0027;s observed activity.</strong>Putting this together, we can quantify the observed flagging activity of user <em>u</em> for any news <em>x</em> with the following matrix defined by variables <span class="inline-equation"><span class="tex">$(\theta _{u,\bar{f}}, \theta _{u,f})$</span>     </span>: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{equation*} {\left[\begin{array}{*10c}\theta _{u,\bar{f}} &#x0026; 1 - \theta _{u,f} \\ 1 - \theta _{u,\bar{f}} &#x0026; \theta _{u,f} \\ \end{array}\right]} =\\\gamma _u {\left[\begin{array}{*10c}1 &#x0026; 1 \\ 0 &#x0026; 0 \\ \end{array}\right]} + (1 - \gamma _u) {\left[\begin{array}{*10c}\alpha _u &#x0026; 1 - \beta _u \\ 1- \alpha _u &#x0026; \beta _u \\ \end{array}\right]}\end{equation*} </span>       <br/>      </div>     </div> where <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{equation*} {\left\lbrace \begin{array}{@{}l@{\quad }l@{}}\theta _{u,\bar{f}} &#x0026;\equiv P\big (Y_u(x) = \bar{f} \mid Y^*(x) = \bar{f}\big) \\ 1 - \theta _{u,\bar{f}} &#x0026;\equiv P\big (Y_u(x) = f \mid Y^*(x) = \bar{f}\big) \\ \theta _{u,f} &#x0026;\equiv P\big (Y_u(x) = f \mid Y^*(x) = f\big) \\ 1 - \theta _{u,f} &#x0026;\equiv P\big (Y_u(x) = \bar{f} \mid Y^*(x) = f\big) \end{array}\right.}\end{equation*} </span>       <br/>      </div>     </div> The two parameters (<em>&#x03B1;<sub>u</sub>     </em>, <em>&#x03B2;<sub>u</sub>     </em>) allow us to model users of different types that one might encounter in real-world settings. For instance,</p>     <ul class="list-no-style">     <li id="list6" label="&#x2022;">a user with (<em>&#x03B1;<sub>u</sub>      </em> &#x2265; 0.5, <em>&#x03B2;<sub>u</sub>      </em> &#x2264; 0.5) can be seen as a &#x201C;news lover&#x201D; who generally tends to perceive the news as not fake; on the other hand, a user with (<em>&#x03B1;<sub>u</sub>      </em> &#x2264; 0.5, <em>&#x03B2;<sub>u</sub>      </em> &#x2265; 0.5) can be seen as a &#x201C;news hater&#x201D; who generally tends to be skeptical and flags the news (i.e., label it as fake).<br/></li>     <li id="list7" label="&#x2022;">a user with (<em>&#x03B1;<sub>u</sub>      </em> = 1, <em>&#x03B2;<sub>u</sub>      </em> = 1) can be seen as an &#x201C;expert&#x201D; who always labels correctly; a user with (<em>&#x03B1;<sub>u</sub>      </em> = 0, <em>&#x03B2;<sub>u</sub>      </em> = 0) can be seen as a &#x201C;spammer&#x201D; who always labels incorrectly.<br/></li>     </ul>    </section>    <section id="sec-13">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> Selecting News to Get Expert&#x0027;s Label</h3>     </div>     </header>     <p>At the end of every epoch <em>t</em>, we apply an algorithm <SmallCap>Algo</SmallCap>&#x2014;on behalf of the network provider&#x2014;which selects news <em>S<sup>t</sup>     </em>&#x2286;<em>A<sup>t</sup>     </em> to send to an expert for reviewing and acquiring the true labels <em>y</em>     <sup>*</sup>(<em>s</em>)&#x2009;&#x2200;<em>s</em> &#x2208; <em>S<sup>t</sup>     </em> (cf., line&#x00A0;11). If a news is labeled as fake by the expert (i.e., <em>y</em>     <sup>*</sup>(<em>s</em>) = <em>f</em>), this news is then blocked from the network (cf., line&#x00A0;12). At the end of the epoch, the algorithm updates the set of active news as <em>A<sup>t</sup>     </em> = <em>A<sup>t</sup>     </em>&#x2216;<em>S<sup>t</sup>     </em> (cf., line&#x00A0;13). We will develop our algorithm in the next section; below we introduce the formal objective of minimizing the spread of misinformation via fake news in the network.</p>    </section>    <section id="sec-14">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.4</span> Objective: Minimizing the Spread of Fake News</h3>     </div>     </header>     <p>Let&#x0027;s begin by quantifying the utility of blocking a news <em>a</em> &#x2208; <em>A<sup>t</sup>     </em> at epoch <em>t</em>&#x2014;it is important to note that, by design, only the fake news are being blocked in the network. Recall that |<em>&#x03C0;<sup>t</sup>     </em>(<em>a</em>)| denotes the number of users who have seen news <em>a</em> by the end of epoch <em>t</em>. We introduce |<em>&#x03C0;</em>     <sup>&#x221E;</sup>(<em>a</em>)| to quantify the number of users who would <em>eventually</em> see the news <em>a</em> if we let it spread in the network. Then, if a news <em>a</em> is fake, we define the utility of blocking news <em>a</em> at epoch <em>t</em> as <span class="inline-equation"><span class="tex">${\rm {val}}^t(a) = |\pi ^\infty (a)| - |\pi ^t(a)|$</span>     </span>, i.e., the utility corresponds to the number of users saved from being exposed to fake news <em>a</em>. If an algorithm <SmallCap>Algo</SmallCap> selects set <em>S<sup>t</sup>     </em> in epoch <em>t</em>, then the total expected utility of the algorithm for <em>t</em> = 1, &#x2026;, <em>T</em> is given by <div class="table-responsive" id="eq1">      <div class="display-equation">       <span class="tex mytex">\begin{align} {\rm{Util}}(T, {\rm\small{ALGO}}) = \sum _{t = 1}^{T} \mathbb {E}\Big [\sum _{s \in S^t} \mathbf {1}_{\lbrace y^*(s) = f\rbrace } {\rm{val}}^t(s)\Big ] \end{align} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div> where the expectation is over the randomness of the spread of news and the randomness in selecting <em>S<sup>t</sup>     </em>&#x2009;&#x2200;<em>t</em> &#x2208; {1, &#x2026;, <em>T</em>}.</p>     <p>In this work, we will assume that the quantity <span class="inline-equation"><span class="tex">${\rm{val}}^t(a)$</span>     </span> in Equation&#x00A0;<a class="eqn" href="#eq1">1</a> can be estimated by the algorithm. For instance, this can be done by fitting parameters of an information cascade model on the spread <em>&#x03C0;<sup>t</sup>     </em>(<em>a</em>) seen so far for news <em>a</em>, and then simulating the future spread by using the learnt parameters&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>].</p>     <p>Given the utility values <span class="inline-equation"><span class="tex">${\rm{val}}^t(\cdot)$</span>     </span>, we can consider an oracle <SmallCap>Oracle</SmallCap> that has access to the true labels <em>y</em>     <sup>*</sup>(&#x00B7;) for all the news and maximizes the objective in Equation&#x00A0;<a class="eqn" href="#eq1">1</a> by simply selecting <em>k</em> fake news with highest utility. In the next section, we develop our algorithm <SmallCap>Detective</SmallCap> that performs Bayesian inference to compute <em>y</em>     <sup>*</sup>(&#x00B7;) using the flagging activity of users as well as via learning users&#x2019; flagging accuracy <span class="inline-equation"><span class="tex">$\lbrace \theta _{u,{\bar{f}}}, \theta _{u,{f}} \rbrace _{u \in U}$</span>     </span> from historic data.</p>    </section>   </section>   <section id="sec-15">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Our Methodology</h2>     </div>    </header>    <p>In this section we present our methodology and our algorithm <SmallCap>Detective</SmallCap>. We start by describing how news labels can be inferred for the case in which users&#x2019; parameters are fixed. Next, we consider the case in which users&#x2019; parameters are unknown and employ a Bayesian approach for inferring news labels and learning users&#x2019; parameters. Given a prior distributions on the users&#x2019; parameters and a history of observed data (users&#x2019; flagging activities and experts&#x2019; labels obtained), one common approach is to compute a point estimate for the users&#x2019; parameters (such as MAP) and use that. However, this can lead to suboptimal solutions because of limited exploration towards learning users&#x2019; parameters. In <SmallCap>Detective</SmallCap>, we overcome this issue by employing the idea of <em>posterior sampling</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>].</p>    <section id="sec-16">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Inferring News Labels: Fixed Users&#x2019; Params</h3>     </div>     </header>     <p>We take a Bayesian approach to deal with unknown labels <em>y</em>     <sup>*</sup>(&#x00B7;) for maximizing the objective in Equation&#x00A0;<a class="eqn" href="#eq1">1</a>. As a warm-up, we begin with a simpler setting where we fix the users&#x2019; labeling parameters <span class="inline-equation"><span class="tex">$(\theta _{u, {\bar{f}}}, \theta _{u, {f}})$</span>     </span> for all users <em>u</em> &#x2208; <em>U</em>. Let&#x0027;s consider epoch <em>t</em> and news <em>a</em> &#x2208; <em>A<sup>t</sup>     </em> for which we want to infer the true label <em>y</em>     <sup>*</sup>(<em>a</em>). Let <em>&#x03C9;</em> be the prior that a news is fake; then, we are interested in computing: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{align*} &#x0026;P(Y^*(a)={f}\mid \lbrace \theta _{u,{\bar{f}}}, \theta _{u,{f}}\rbrace _{u \in U}, \omega , \psi ^t(a), \pi ^t(a))\nonumber \\ &#x0026;\propto \omega \cdot \prod _{u \in \psi ^t(a)} P\Big (Y_u(a) = f \mid Y^*(a) = f, \theta _{u, {f}} \Big) \cdot \nonumber \\ &#x0026;\ \ \ \quad \prod _{u \in \pi ^t(a) \setminus \psi ^t(a)} P\Big (Y_u(a) = \bar{f} \mid Y^*(a) = f, \theta _{u, {f}}\Big) \nonumber \\ &#x0026;= \omega \cdot \prod _{u \in \psi ^t(a)} \theta _{u, f} \cdot \prod _{u \in \pi ^t(a) \setminus \psi ^t(a)} (1 - \theta _{u, f})\end{align*} </span>       <br/>      </div>     </div> where the last two steps follow from applying Bayes rule and assuming that users&#x2019; labels are generated independently. Note that both users&#x2019; parameters <span class="inline-equation"><span class="tex">$\lbrace \theta _{u, \bar{f}}, \theta _{u, f}\rbrace _{u \in U}$</span>     </span> affect the posterior probability of a news being fake as the normalization constant depends on both <em>P</em>(<em>Y</em>     <sup>*</sup>(<em>a</em>) = <em>f</em>&#x2223; &#x00B7;) and <span class="inline-equation"><span class="tex">$P(Y^*(a)={\bar{f}}\mid \cdot)$</span>     </span>.</p>     <p>At every time <em>t</em> &#x2208; {1, &#x2026;, <em>T</em>}, we can use the inferred posterior probabilities to greedily select <em>k</em> news <em>S<sup>t</sup>     </em>&#x2286;<em>A<sup>t</sup>     </em>, |<em>S<sup>t</sup>     </em>| = <em>k</em> that maximize the total expected utility, i.e., <div class="table-responsive" id="eq2">      <div class="display-equation">       <span class="tex mytex">\begin{align} \sum _{s \in S^t} P(Y^*(s)={f}\mid \cdot) \cdot {\rm{val}}^t(s). \end{align} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div> This greedy selection can be performed optimally by selecting <em>k</em> news with the highest expected utility. This is implemented in our algorithm <SmallCap>TopX</SmallCap>, shown in Algorithm&#x00A0;2 .</p>    </section>    <section id="sec-17">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Inferring News Labels: Learning Users&#x2019; Params</h3>     </div>     </header>     <p>In our setting, the users&#x2019; parameters <span class="inline-equation"><span class="tex">$\lbrace \theta _{u, {\bar{f}}}, \theta _{u, {f}}\rbrace _{u \in U}$</span>     </span> are unknown and need to be learnt over time.</p>     <p>     <strong>Learning about users.</strong> We assume a prior distribution over the users&#x2019; parameters <span class="inline-equation"><span class="tex">$(\Theta _{{\bar{f}}}, \Theta _{{f}})$</span>     </span> shared among all users. For each user <em>u</em> &#x2208; <em>U</em>, we maintain the data history in form of the following matrix: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{align*} \mathcal {D}^t_u = {\left[\begin{array}{*10c}d^t_{u, {\bar{f}}\mid {\bar{f}}} &#x0026; d^t_{u, {\bar{f}}\mid {f}} \\d^t_{u,{f}\mid {\bar{f}}} &#x0026; d^t_{u, {f}\mid {f}}\\\end{array}\right]}.\end{align*} </span>       <br/>      </div>     </div> The entries of this matrix are computed from the news for which experts&#x2019; labels were acquired. For instance, <span class="inline-equation"><span class="tex">$d^t_{u, {\bar{f}}\mid {\bar{f}}}$</span>     </span> represents the count of how often the user <em>u</em> labeled a news as not fake and the acquired expert&#x0027;s label was not fake.</p>     <p>Given <span class="inline-equation"><span class="tex">$\mathcal {D}^t_u$</span>     </span>, we can compute the posterior distribution over the users&#x2019; parameters using Bayes rules as follows: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{align*} P(\theta _{u,{\bar{f}}} \mid \Theta _{\bar{f}}, \mathcal {D}_u^t) \propto P(\mathcal {D}_u^t \mid \theta _{u,{\bar{f}}}) \cdot P(\theta _{u,{\bar{f}}} \mid \Theta _{\bar{f}}) \\ = (\theta _{u, \bar{f}})^{d^t_{u,{\bar{f}}\mid {\bar{f}}}} \cdot (1 - \theta _{u, \bar{f}})^{d^t_{u, {f}\mid {\bar{f}}}} \cdot P(\theta _{u, \bar{f}} \mid \Theta _{{\bar{f}}})\end{align*} </span>       <br/>      </div>     </div> Similarly, one can compute <em>P</em>(<em>&#x03B8;</em>     <sub>      <em>u</em>, <em>f</em>     </sub>&#x2223; &#x00B7;).</p>     <p>     <strong>Inferring labels.</strong>We can now use the users&#x2019; parameters posteriors distributions to infer the labels, for instance, by first computing the MAP parameters <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{equation*}\theta^{{\rm MAP}_{u,{\bar{f}}}} = {\rm arg} \max_{\theta_{u,{\bar{f}}}} P(\theta_{u,{\bar{f}}} \mid \Theta_{\bar{f}}, \mathcal{D}_u^t)\end{equation*} </span>       <br/>      </div>     </div> (and <span class="inline-equation"><span class="tex">$\theta^{{\rm{MAP}}}_{u,{f}}$</span>     </span> similarly) and invoking the results from the previous section.<a class="fn" href="#fn9" id="foot-fn9"><sup>8</sup></a>     </p>     <p>Then, at every epoch <em>t</em> we can invoke <SmallCap>TopX</SmallCap> with a point estimate for the users&#x2019; parameters to select a set <em>S<sup>t</sup>     </em> of news. However this approach can perform arbitrarily bad compared to an algorithm that knows the true users&#x2019; parameters (we refer to this algorithm as <SmallCap>Opt</SmallCap>) as we show in our analysis. The key challenge here is that of actively trading off exploration (selecting news that maximize the value of information towards learning users&#x2019; parameters) and exploration (selecting news that directly expected utility at a given epoch). This is a fundamental challenge that arises in sequential decision making problems, e.g., in multi-armed bandits&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>], active search&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0030">30</a>] and reinforcement learning.</p>     <p>     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3188722/images/www18companion-230-img2.svg" class="img-responsive" alt=""       longdesc=""/>     </p>    </section>    <section id="sec-18">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Our Algorithm <SmallCap>Detective</SmallCap>      </h3>     </div>     </header>     <p>In this section, we present our algorithm <SmallCap>Detective</SmallCap>, shown in Algorithm&#x00A0;3, that actively trades off between exploration and exploitation by the use of posterior sampling aka Thompson sampling&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0024">24</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>]. On every invocation, the algorithm samples the users&#x2019; parameters from the current users&#x2019; posterior distributions and invokes <SmallCap>TopX</SmallCap> with these parameters. Intuitively, we can think of this approach as sampling users&#x2019; parameters according to the probability they are optimal.</p>     <p>     <strong>Analysis.</strong> We analyze our algorithms in a simplified variant of Protocol&#x00A0;1, in particular we make the following simplifications:</p>     <ol class="list-no-style">     <li id="list8" label="(1)">There are <em>M</em> sources <em>o</em>      <sub>1</sub>, &#x2026;, <em>o<sub>M</sub>      </em>, each generating news every epoch <em>t</em>.<br/></li>     <li id="list9" label="(2)">For any news <em>x</em> seeded at epoch <em>t</em>, <span class="inline-equation"><span class="tex">${\rm{val}}^\tau (x) {\gt} 0$</span>      </span> only for <em>&#x03C4;</em> = <em>t</em>. This means that news <em>x</em> reaches it maximum spread at the next timestep <em>t</em> + 1, hence the utility of detecting that news drops to 0.<br/></li>     </ol>     <p>     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3188722/images/www18companion-230-img3.svg" class="img-responsive" alt=""       longdesc=""/> To state our theoretical results, let us introduce the regret of an algorithm <SmallCap>Algo</SmallCap> as <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{equation*} \textrm{Regret}(T,\rm\small{ALGO}) = \textrm{Util}(T, \rm\small{OPT}) - \textrm{Util}(T, \rm\small{ALGO}).\end{equation*} </span>       <br/>      </div>     </div> We can now immediately state our first theoretical result, highlighting the necessity of exploration.</p>     <div class="proposition" id="enc1">     <Label>Proposition 4.1.</Label>     <p> Any algorithm <SmallCap>Algo</SmallCap> using deterministic point estimates for the users&#x2019; parameters suffers linear regret, i.e., <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\[ \textrm{Regret}(T, \rm\small{ALGO}) = \Theta (T). \] </span>        <br/>       </div>      </div>     </p>     </div>     <div class="proof" id="proof1">     <Label>Proof Proof sketch</Label>     <p> The proof follows by considering a simple problem involving two users, where we have perfect knowledge about one user with parameters (0.5 + &#x03F5;, 0.5 + &#x03F5;) and the other user either has parameters (1, 1) or (0, 0) (<em>expert</em> or <em>spamer</em>). The key idea here is that any algorithm using point estimates can be tricked into always making decisions based on the first user&#x0027;s flagging activities and is never able to learn about the perfect second user. &#x25A1;</p>     </div>     <p>The above result is a consequence of insufficient exploration which is overcome by our algorithm <SmallCap>Detective</SmallCap>, as formalized by the following theorem.</p>     <div class="theorem" id="enc2">     <Label>Theorem 4.1.</Label>     <p> The expected regret of our algorithm <SmallCap>Detective</SmallCap> is <span class="inline-equation"><span class="tex">$\mathbb {E}[\textrm{Regret}(T, \rm\small{DETECTIVE})] = \mathcal {O}(C\sqrt {M^{\prime }T\log (CM^{\prime }T)})$</span>      </span>, where <span class="inline-equation"><span class="tex">$M^{\prime }=\binom{M}{k}$</span>      </span> and <em>C</em> is a problem dependent parameter. <em>C</em> quantifies the total number of realizations of how <em>M</em> news can spread to <em>U</em> users and how these users label the news.</p>     </div>     <div class="proof" id="proof2">     <Label>Proof Proof sketch</Label>     <p> The proof of this theorem follows via interpreting the simplified setting as a reinforcement learning problem. Then, we can apply the generic results for reinforcement learning via posterior sampling of&#x00A0;Osband et&#x00A0;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0024">24</a>]. In particular, we map our problem to an MDP with horizon 1 as follows. The actions in the MDP correspond to selecting <em>k</em> news from the <em>M</em> sources, the reward for selecting a set of news <em>S</em> is given by Equation&#x00A0;<a class="eqn" href="#eq2">2</a> (evaluated using the true users&#x2019; parameters).</p>     </div>     <p>Given that the regret only grows as <span class="inline-equation"><span class="tex">$\mathcal {O}(\sqrt {T})$</span>     </span> (i.e., sublinear in <em>T</em>), this theorem implies that <SmallCap>Detective</SmallCap> converges to <SmallCap>Opt</SmallCap> as <em>T</em> &#x2192; &#x221E;. However, as a conservative bound on <em>C</em> could be exponential in |<em>U</em>| and <em>M</em>, convergence may be slow. Nevertheless, in practice we observe competitive performance of <SmallCap>Detective</SmallCap> compared to <SmallCap>Opt</SmallCap> as indicated in our experiments. Hence, <SmallCap>Detective</SmallCap> overcomes the issues in Proposition&#x00A0;<a class="enc" href="#enc1">1</a>, and actively trades off exploration and exploitation.   </section>   <section id="sec-19">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Experimental Setup</h2>     </div>    </header>    <p>     <strong>Social network graph and news generation.</strong> We consider the <em>social circles Facebook</em> graph&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>], consisting of 4,039 users (nodes) <em>U</em> and 88,234 edges, computed from survey data collected by using a Facebook app for identifying social circles. Every user can be the seed of news as described shortly and to every user a probability is assigned with which it (hypothetically) generates fake news in case it seeds news. In particular, 20% of the users generate fake news with probability 0.6, 40% of the users generate fake news with probability 0.2 and the remaining 40% of the users generate fake news with probability 0.01 (the class of a user is assigned randomly). For determining the seeds of news, we partition the users into users <em>U<sub>n</sub>     </em> which commonly spread news and users <em>U<sub>r</sub>     </em> = <em>U</em>&#x2216;<em>U<sub>n</sub>     </em> which only occasionally spread news. That is, in every iteration of Protocol&#x00A0;1, we select <em>M</em> = 25 users for generating news, where users in <em>U<sub>n</sub>     </em> are selected with probability <span class="inline-equation"><span class="tex">$\tfrac{0.5}{|U_n|}$</span>     </span> and users in <em>U<sub>r</sub>     </em> are selected with probability <span class="inline-equation"><span class="tex">$\tfrac{0.5}{|U_r|}$</span>     </span>. Hence, in our experimental setup this corresponds to a prior for seeding fake news of about 20%, i.e., <em>&#x03C9;</em> &#x2248; 0.2.</p>    <p>     <strong>News spreading.</strong> In our experiments, news spread according to an independent cascade model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>], i.e., the diffusion process of every news is a separate independent cascade with infection probability <span class="inline-equation"><span class="tex">$0.1 + \mathcal {U}[0, 0.1]$</span>     </span> (fixed when the news is seeded). In every epoch of Protocol&#x00A0;1, we perform two iterations of the independent cascade models to determine the news spread at the next epoch. We estimate the number of users who would eventually see news <em>a</em>, i.e., |<em>&#x03C0;</em>     <sup>&#x221E;</sup>(<em>a</em>)|, by executing the independent cascade models for each news for 600 iterations.</p>    <p>     <strong>Users&#x2019; parameters.</strong> In our experiments we consider three types of users, i.e., <em>good users</em> (<em>&#x03B1;<sub>u</sub>     </em> = <em>&#x03B2;<sub>u</sub>     </em> = 0.9), <em>spammers</em> (<em>&#x03B1;<sub>u</sub>     </em> = <em>&#x03B2;<sub>u</sub>     </em> = 0.1) and <em>indifferent users</em> (<em>&#x03B1;<sub>u</sub>     </em> = <em>&#x03B2;<sub>u</sub>     </em> = 0.5). Unless specified otherwise, each user is randomly assigned to one of these three types. Also, we set <em>&#x03B3;<sub>u</sub>     </em> = 0 unless specified otherwise (note that 1 &#x2212; <em>&#x03B3;<sub>u</sub>     </em> quantifies the engagement of a user).</p>    <p>     <strong>Algorithms.</strong> We execute Protocol&#x00A0;1 for <em>T</em> = 100 epochs. In every epoch of Protocol&#x00A0;1, the evaluated algorithms select <em>k</em> = 5 news to be reviewed by an expert. In our experiments we compare the performance of <SmallCap>Detective</SmallCap>, <SmallCap>Opt</SmallCap> (unrealistic: <SmallCap>TopX</SmallCap> invoked with the true users&#x2019; parameters), <SmallCap>Oracle</SmallCap> (unrealistic: knows the true news labels). In addition, we consider the following baselines:</p>    <ul class="list-no-style">     <li id="list10" label="&#x2022;"><SmallCap>Fixed-CM</SmallCap>. This algorithm leverages users&#x2019; flags without learning about or distinguishing between users. It uses fixed users parameters <span class="inline-equation"><span class="tex">$\theta _{u,{\bar{f}}}=\theta _{u,{f}}=0.6$</span>     </span> for invoking <SmallCap>TopX</SmallCap>.<br/></li>     <li id="list11" label="&#x2022;"><SmallCap>No-Learn</SmallCap>. This algorithm does not learn about users and does not consider any user flags. It greedily selects those news with highest <span class="inline-equation"><span class="tex">${\rm{val}}^t(\cdot)$</span>     </span>, i.e., <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\[ S^t = \arg \max _{S \subseteq A^t, |S|=k} \sum _{s \in S} {\rm{val}}^t(s). \] </span>       <br/>      </div>     </div>     <br/></li>     <li id="list12" label="&#x2022;"><SmallCap>Random</SmallCap>. This algorithm selects a random set <em>S<sup>t</sup>     </em>&#x2286;<em>A<sup>t</sup>     </em>, |<em>S<sup>t</sup>     </em>| = <em>k</em> of active news for labeling by experts.<br/></li>    </ul>   </section>   <section id="sec-20">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Experimental Results</h2>     </div>    </header>    <p>In this section we demonstrate the efficiency of our proposed algorithm for fake news detection in a social network. All reported utilities are normalized by <span class="inline-equation"><span class="tex">$\textrm{Util}(T,\rm\small{ORACLE})$</span>     </span> and all results are averaged over 5 runs.</p>    <p>     <strong>Learning about users and and exploiting user&#x0027;s flags.</strong> In this experiment we compare the average utility, i.e., <span class="inline-equation"><span class="tex">$\tfrac{1}{t} \textrm{Util}(t,\rm\small{ALGO})$</span>     </span> (cf., Equation&#x00A0;<a class="eqn" href="#eq1">1</a>), achieved by the different algorithms at epoch <em>t</em> for <em>t</em> = 1, &#x2026;, <em>T</em>. The results are shown in Figure&#x00A0;<a class="fig" href="#fig2">2a</a> . We observe that <SmallCap>Detective</SmallCap> and <SmallCap>Opt</SmallCap> achieve performance close to that of <SmallCap>Oracle</SmallCap>. This is impressive, as these algorithms can only use the users&#x2019; flags and the users&#x2019; parameters <span class="inline-equation"><span class="tex">$\lbrace \theta _{u,{\bar{f}}}, \theta _{u,{f}} \rbrace _{u \in U}$</span>     </span> (or their beliefs about the users&#x2019; parameters in case of <SmallCap>Detective</SmallCap>) to make their predictions. We also observe that the performance of <SmallCap>Detective</SmallCap> converges to that of <SmallCap>Opt</SmallCap> as <SmallCap>Detective</SmallCap> progressively learns the users&#x2019; parameters. The algorithms <SmallCap>No-Learn</SmallCap> and <SmallCap>Random</SmallCap> achieve clearly inferior performance compare to <SmallCap>Detective</SmallCap>.</p> <figure id="fig2">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3188722/images/www18companion-230-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Experimental results. <em>(a)</em> Learning about users: <SmallCap>Detective</SmallCap> achieves average utility competitive compared to that of <SmallCap>Oracle</SmallCap> (which knows the true news labels). The average utility of <SmallCap>Detective</SmallCap> converges to that of <SmallCap>Opt</SmallCap> as <SmallCap>Detective</SmallCap> progressively learns the users&#x2019; parameters. <em>(b)</em> Users&#x2019; engagement in flagging: even with low engagement <SmallCap>Detective</SmallCap> can effectively leverage crowd signals to detect fake news. <em>(c)</em> Robustness against spammers: <SmallCap>Detective</SmallCap> is effective even if the majority of users is adversarial, highlighting the importance of learning about users&#x2019; flagging accuracy for robustly leveraging crowd signals.</span>      </div>     </figure>     </p>    </section>    <p>     <strong>Users&#x2019; engagement in flagging.</strong> In this experiment, we vary the engagement 1 &#x2212; <em>&#x03B3;<sub>u</sub>     </em> of the users. We report the utilities <span class="inline-equation"><span class="tex">$\textrm{Util}(T,\rm\small{ALGO})$</span>     </span> in Figure&#x00A0;<a class="fig" href="#fig2">2b</a> . We observe that with increasing engagement the performance of <SmallCap>Detective</SmallCap> and <SmallCap>Opt</SmallCap> improves while the performance of the other shown algorithms is not affected by the increased engagement. Importantly, note that also with a low engagement <SmallCap>Detective</SmallCap> can effectively leverage crowd signals to detect fake news.</p>    <p>     <strong>Robustness against spammers.</strong> In this experiment we consider only two types of users, i.e., good users and spammers. We vary the fraction of good users relative to the total number of users. We report the utilities <span class="inline-equation"><span class="tex">$\textrm{Util}(T,\rm\small{ALGO})$</span>     </span> achieved by the different algorithms in Figure&#x00A0;<a class="fig" href="#fig2">2c</a> . We also plot the additional baseline <SmallCap>Fixed-CM</SmallCap>. Observe that the performance of <SmallCap>Fixed-CM</SmallCap> degrades with a decreasing fraction of good users. <SmallCap>Detective</SmallCap> (thanks to learning about users) is effective even if the majority of users is adversarial. This highlights the fact that it is crucial to learn about users&#x2019; flagging accuracy in order to robustly leverage crowd signals.</p>   </section>   <section id="sec-21">    <header>     <div class="title-info">     <h2>      <span class="section-number">7</span> Conclusions</h2>     </div>    </header>    <p>In our paper we considered the important problem of leveraging crowd signals for detecting fake news. We demonstrated that any approach that is not learning about users&#x2019; flagging behaviour is prone to failure in the presence of adversarial/spam users (who want to &#x201C;promote&#x201D; fake news). We proposed the algorithm <SmallCap>Detective</SmallCap> that performs Bayesian inference for detecting fake news and jointly learns about users over time. Our experiments demonstrate that <SmallCap>Detective</SmallCap> is competitive with the fictitious algorithm <SmallCap>Opt</SmallCap>, which knows the true users&#x2019; flagging behaviour. Importantly, <SmallCap>Detective</SmallCap> (thanks to learning about users) is robust in leveraging flags even if a majority of the users is adversarial. There are some natural extensions for future work. For instance, it would be useful to extend our approach to model and infer the trustworthiness of sources. It would also be important to conduct user studies by deploying our algorithm in a real-world social system.</p>   </section>  </section>  <section class="back-matter">   <section id="sec-22">    <header>     <div class="title-info">     <h2>ACKNOWLEDGMENTS</h2>     </div>    </header>    <p>This work was supported in part by the Swiss National Science Foundation, and Nano-Tera.ch program as part of the Opensense II project, ERC StG 307036, and a Microsoft Research Faculty Fellowship. Adish Singla acknowledges support by a Facebook Graduate Fellowship.</p>   </section>   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information credibility on twitter. In <em>      <em>WWW</em>     </em>. 675&#x2013;684.</li>     <li id="BibPLXBIB0002" label="[2]">Olivier Chapelle and Lihong Li. 2011. An empirical evaluation of thompson sampling. In <em>      <em>NIPS</em>     </em>. 2249&#x2013;2257.</li>     <li id="BibPLXBIB0003" label="[3]">Liang Chen, Zheng Yan, Weidong Zhang, and Raimo Kantola. 2015. TruSMS: a trustworthy SMS spam control system based on trust management. <em>      <em>Future Generation Computer Systems</em>     </em>49 (2015), 77&#x2013;93.</li>     <li id="BibPLXBIB0004" label="[4]">Yuxin Chen, Jean-Michel Renders, Morteza&#x00A0;Haghir Chehreghani, and Andreas Krause. 2017. Efficient Online Learning for Optimizing Value of Information: Theory and Application to Interactive Troubleshooting. In <em>      <em>UAI</em>     </em>.</li>     <li id="BibPLXBIB0005" label="[5]">Pern&#x00A0;Hui Chia and Svein&#x00A0;Johan Knapskog. 2011. Re-evaluating the wisdom of crowds in assessing web security. In <em>      <em>International Conference on Financial Cryptography and Data Security</em>     </em>. 299&#x2013;314.</li>     <li id="BibPLXBIB0006" label="[6]">Giovanni&#x00A0;Luca Ciampaglia, Prashant Shiralkar, Luis&#x00A0;M Rocha, Johan Bollen, Filippo Menczer, and Alessandro Flammini. 2015. Computational fact checking from knowledge networks. <em>      <em>PloS one</em>     </em>10, 6 (2015), e0128193.</li>     <li id="BibPLXBIB0007" label="[7]">Niall&#x00A0;J Conroy, Victoria&#x00A0;L Rubin, and Yimin Chen. 2015. Automatic deception detection: Methods for finding fake news. <em>      <em>Proceedings of the Association for Information Science and Technology</em>     </em>52, 1 (2015), 1&#x2013;4.</li>     <li id="BibPLXBIB0008" label="[8]">Nan Du, Le Song, Manuel Gomez-Rodriguez, and Hongyuan Zha. 2013. Scalable Influence Estimation in Continuous-Time Diffusion Networks. In <em>      <em>NIPS</em>     </em>. 3147&#x2013;3155.</li>     <li id="BibPLXBIB0009" label="[9]">Stuart Ewen. 1998. <em>      <em>PR!: a social history of spin</em>     </em>. Basic Books.</li>     <li id="BibPLXBIB0010" label="[10]">Facebook. 2016. News Feed FYI: Addressing Hoaxes and Fake News. <a class="link-inline force-break" href="https://newsroom.fb.com/news/2016/12/news-feed-fyi-addressing-hoaxes-and-fake-news/">https://newsroom.fb.com/news/2016/12/news-feed-fyi-addressing-hoaxes-and-fake-news/</a>. (December 2016).</li>     <li id="BibPLXBIB0011" label="[11]">Facebook. 2017. Umgang mit Falschmeldungen (Handling of false alarms). <a class="link-inline force-break" href="https://de.newsroom.fb.com/news/2017/01/umgang-mit-falschmeldungen/">https://de.newsroom.fb.com/news/2017/01/umgang-mit-falschmeldungen/</a>. (January 2017).</li>     <li id="BibPLXBIB0012" label="[12]">David&#x00A0;Mandell Freeman. 2017. Can You Spot the Fakes?: On the Limitations of User Feedback in Online Social Networks. In <em>      <em>WWW</em>     </em>. 1093&#x2013;1102.</li>     <li id="BibPLXBIB0013" label="[13]">Aditi Gupta, Ponnurangam Kumaraguru, Carlos Castillo, and Patrick Meier. 2014. Tweetcred: Real-time credibility assessment of content on twitter. In <em>      <em>International Conference on Social Informatics</em>     </em>. Springer, 228&#x2013;243.</li>     <li id="BibPLXBIB0014" label="[14]">Nguyen Quoc&#x00A0;Viet Hung, Duong&#x00A0;Chi Thang, Matthias Weidlich, and Karl Aberer. 2015. Minimizing efforts in validating crowd answers. In <em>      <em>SIGMOD</em>     </em>. 999&#x2013;1014.</li>     <li id="BibPLXBIB0015" label="[15]">David Kempe, Jon Kleinberg, and &#x00C9;va Tardos. 2003. Maximizing the spread of influence through a social network. In <em>      <em>KDD</em>     </em>. 137&#x2013;146.</li>     <li id="BibPLXBIB0016" label="[16]">J. Kim, B. Tabibian, A. Oh, B. Schoelkopf, and M. Gomez-Rodriguez. 2018. Leveraging the Crowd to Detect and Reduce the Spread of Fake News and Misinformation. In <em>      <em>WSDM &#x2019;18: Proceedings of the 11th ACM International Conference on Web Search and Data Mining</em>     </em>.</li>     <li id="BibPLXBIB0017" label="[17]">Srijan Kumar, Robert West, and Jure Leskovec. 2016. Disinformation on the web: Impact, characteristics, and detection of wikipedia hoaxes. In <em>      <em>WWW</em>     </em>. 591&#x2013;602.</li>     <li id="BibPLXBIB0018" label="[18]">Sejeong Kwon, Meeyoung Cha, and Kyomin Jung. 2017. Rumor detection over varying time windows. <em>      <em>PloS one</em>     </em>12, 1 (2017), e0168344.</li>     <li id="BibPLXBIB0019" label="[19]">Jure Leskovec and Julian&#x00A0;J Mcauley. 2012. Learning to discover social circles in ego networks. In <em>      <em>NIPS</em>     </em>. 539&#x2013;547.</li>     <li id="BibPLXBIB0020" label="[20]">Yaliang Li, Qi Li, Jing Gao, Lu Su, Bo Zhao, Wei Fan, and Jiawei Han. 2015. On the discovery of evolving truth. In <em>      <em>KDD</em>     </em>. 675&#x2013;684.</li>     <li id="BibPLXBIB0021" label="[21]">Mengchen Liu, Liu Jiang, Junlin Liu, Xiting Wang, Jun Zhu, and Shixia Liu. 2017. Improving Learning-from-Crowds through Expert Validation. In <em>      <em>IJCAI</em>     </em>. 2329&#x2013;2336.</li>     <li id="BibPLXBIB0022" label="[22]">Cristian Lumezanu, Nick Feamster, and Hans Klein. 2012. # bias: Measuring the tweeting behavior of propagandists. In <em>      <em>AAAI Conference on Weblogs and Social Media</em>     </em>.</li>     <li id="BibPLXBIB0023" label="[23]">Tyler Moore and Richard Clayton. 2008. Evaluating the wisdom of crowds in assessing phishing websites. <em>      <em>Lecture Notes in Computer Science</em>     </em>5143 (2008), 16&#x2013;30.</li>     <li id="BibPLXBIB0024" label="[24]">Ian Osband, Dan Russo, and Benjamin Van&#x00A0;Roy. 2013. (More) efficient reinforcement learning via posterior sampling. In <em>      <em>NIPS</em>     </em>. 3003&#x2013;3011.</li>     <li id="BibPLXBIB0025" label="[25]">Poynter. 2016. International Fact-Checking Network: Fact-Checkers Code Principles. <a class="link-inline force-break" href="https://www.poynter.org/international-fact-checking-network-fact-checkers-code-principles">https://www.poynter.org/international-fact-checking-network-fact-checkers-code-principles</a>. (September 2016).</li>     <li id="BibPLXBIB0026" label="[26]">Marian-Andrei Rizoiu, Lexing Xie, Scott Sanner, Manuel Cebri&#x00E1;n, Honglin Yu, and Pascal&#x00A0;Van Hentenryck. 2017. Expecting to be HIP: Hawkes Intensity Processes for Social Media Popularity. In <em>      <em>WWW</em>     </em>. 735&#x2013;744.</li>     <li id="BibPLXBIB0027" label="[27]">Victoria&#x00A0;L Rubin, Yimin Chen, and Niall&#x00A0;J Conroy. 2015. Deception detection for news: three types of fakes. <em>      <em>Proceedings of the Association for Information Science and Technology</em>     </em>52, 1 (2015), 1&#x2013;4.</li>     <li id="BibPLXBIB0028" label="[28]">Behzad Tabibian, Isabel Valera, Mehrdad Farajtabar, Le Song, Bernhard Sch&#x00F6;lkopf, and Manuel Gomez-Rodriguez. 2017. Distilling information reliability and source trustworthiness from digital traces. In <em>      <em>WWW</em>     </em>. 847&#x2013;855.</li>     <li id="BibPLXBIB0029" label="[29]">William&#x00A0;R Thompson. 1933. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. <em>      <em>Biometrika</em>     </em>25, 3/4 (1933), 285&#x2013;294.</li>     <li id="BibPLXBIB0030" label="[30]">Hastagiri&#x00A0;P Vanchinathan, Andreas Marfurt, Charles-Antoine Robelin, Donald Kossmann, and Andreas Krause. 2015. Discovering valuable items from massive data. In <em>      <em>KDD</em>     </em>. 1195&#x2013;1204.</li>     <li id="BibPLXBIB0031" label="[31]">Svitlana Volkova, Kyle Shaffer, Jin&#x00A0;Yea Jang, and Nathan Hodas. 2017. Separating Facts from Fiction: Linguistic Models to Classify Suspicious and Trusted News Posts on Twitter. In <em>      <em>ACL</em>     </em>, Vol.&#x00A0;2. 647&#x2013;653.</li>     <li id="BibPLXBIB0032" label="[32]">Gang Wang, Manish Mohanlal, Christo Wilson, Xiao Wang, Miriam&#x00A0;J. Metzger, Haitao Zheng, and Ben&#x00A0;Y. Zhao. 2013. Social Turing Tests: Crowdsourcing Sybil Detection. In <em>      <em>NDSS</em>     </em>.</li>     <li id="BibPLXBIB0033" label="[33]">William&#x00A0;Yang Wang. 2017. &#x201D;Liar, Liar Pants on Fire&#x201D;: A New Benchmark Dataset for Fake News Detection. In <em>      <em>ACL</em>     </em>. 422&#x2013;426.</li>     <li id="BibPLXBIB0034" label="[34]">Wei Wei and Xiaojun Wan. 2017. Learning to Identify Ambiguous and Misleading News Headlines. In <em>      <em>IJCAI</em>     </em>. 4172&#x2013;4178.</li>     <li id="BibPLXBIB0035" label="[35]">Shu Wu, Qiang Liu, Yong Liu, Liang Wang, and Tieniu Tan. 2016. Information Credibility Evaluation on Social Media.. In <em>      <em>AAAI</em>     </em>. 4403&#x2013;4404.</li>     <li id="BibPLXBIB0036" label="[36]">Bo Zhao, Benjamin&#x00A0;IP Rubinstein, Jim Gemmell, and Jiawei Han. 2012. A bayesian approach to discovering truth from conflicting sources for data integration. <em>      <em>Proceedings of the VLDB Endowment</em>     </em>5, 6 (2012), 550&#x2013;561.</li>     <li id="BibPLXBIB0037" label="[37]">Qingyuan Zhao, Murat&#x00A0;A. Erdogdu, Hera&#x00A0;Y. He, Anand Rajaraman, and Jure Leskovec. 2015. SEISMIC: A Self-Exciting Point Process Model for Predicting Tweet Popularity. In <em>      <em>KDD</em>     </em>. 1513&#x2013;1522.</li>     <li id="BibPLXBIB0038" label="[38]">Zhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015. Enquiring minds: Early detection of rumors in social media from enquiry posts. In <em>      <em>WWW</em>     </em>. 1395&#x2013;1405.</li>     <li id="BibPLXBIB0039" label="[39]">Elena Zheleva, Aleksander Kolcz, and Lise Getoor. 2008. Trusting spam reporters: A reporter-based reputation system for email filtering. <em>      <em>TOIS</em>     </em>27, 1 (2008), 3.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x002A;</sup></a>Work performed while at ETH Zurich.</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a>Snopes compiles a list of top 50 fake news stories: <a class="link-inline force-break" href="http://www.snopes.com/50-hottest-urban-legends/">http://www.snopes.com/50-hottest-urban-legends/</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a><a class="link-inline force-break"     href="http://uk.businessinsider.com/fake-news-starbucks-free-coffee-to-undocumented-immigrants-2017-8">http://uk.businessinsider.com/fake-news-starbucks-free-coffee-to-undocumented-immigrants-2017-8</a>   </p>   <p id="fn4"><a href="#foot-fn4"><sup>3</sup></a><a class="link-inline force-break" href="http://www.snopes.com/">http://www.snopes.com/</a>   </p>   <p id="fn5"><a href="#foot-fn5"><sup>4</sup></a><a class="link-inline force-break" href="http://factcheck.org/">http://factcheck.org/</a>   </p>   <p id="fn6"><a href="#foot-fn6"><sup>5</sup></a>    <a class="link-inline force-break" href="http://www.fakenewschallenge.org/">http://www.fakenewschallenge.org/</a>   </p>   <p id="fn7"><a href="#foot-fn7"><sup>6</sup></a>For simplicity of presentation, we consider every news generated in the network to be unique. In real-world settings, the same news might be posted by multiple users because of externalities, and it is easy to extend our model to consider this scenario.</p>   <p id="fn8"><a href="#foot-fn8"><sup>7</sup></a>Note that as per specification of Protocol&#x00A0;1, for any news <em>x</em>, the source user <em>o<sub>x</sub>    </em> doesn&#x0027;t participate in flagging <em>x</em>.</p>   <p id="fn9"><a href="#foot-fn9"><sup>8</sup></a>Note that a fully Bayesian approach for integrating out uncertainty about users&#x2019; parameters in this case is equivalent to using the mean point estimate of the posterior distribution.</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18 Companion, April 23&#x2013;27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. <br/>ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3188722">https://doi.org/10.1145/3184558.3188722</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
