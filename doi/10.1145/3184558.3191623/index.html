<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>SAVITR: A System for Real-time Location Extraction from
  Microblogs during Emergencies</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a HTML copy of <a href='https://doi.org/10.1145/3184558.3191623'>https://doi.org/10.1145/3184558.3191623</a> 
originally published by ACM, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML accessability, compatibility, 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3191623'>https://w3id.org/oa/10.1145/3184558.3191623</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">SAVITR: A System for Real-time
          Location Extraction from Microblogs during
          Emergencies</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Ritam</span> <span class=
          "surName">Dutt</span> Dept. of Computer Science and
          EngineeringIndian Institute of Technology Kharagpur,
          India 721302, <a href=
          "mailto:ritam@iitkgp.ac.in">ritam@iitkgp.ac.in</a>
        </div>
        <div class="author">
          <span class="givenName">Kaustubh</span> <span class=
          "surName">Hiware</span> Dept. of Computer Science and
          EngineeringIndian Institute of Technology Kharagpur,
          India 721302, <a href=
          "mailto:hiwarekaustubh@iitkgp.ac.in">hiwarekaustubh@iitkgp.ac.in</a>
        </div>
        <div class="author">
          <span class="givenName">Avijit</span> <span class=
          "surName">Ghosh</span> Dept. of Chemical and Financial
          EngineeringIndian Institute of Technology Kharagpur,
          India 721302, <a href=
          "mailto:avijitg22@iitkgp.ac.in">avijitg22@iitkgp.ac.in</a>
        </div>
        <div class="author">
          <span class="givenName">Rameshwar</span> <span class=
          "surName">Bhaskaran</span> Dept. of Computer Science and
          EngineeringIndian Institute of Technology Kharagpur,
          India 721302, <a href=
          "mailto:rameshwar.cs@iitkgp.ac.in">rameshwar.cs@iitkgp.ac.in</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3191623"
        target=
        "_blank">https://doi.org/10.1145/3184558.3191623</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>We present SAVITR, a system that leverages the
        information posted on the Twitter microblogging site to
        monitor and analyse emergency situations. Given that only a
        very small percentage of microblogs are geo-tagged, it is
        essential for such a system to extract locations from the
        text of the microblogs. We employ natural language
        processing techniques to infer the locations mentioned in
        the microblog text, in an unsupervised fashion and display
        it on a map-based interface. The system is designed for
        efficient performance, achieving an F-score of 0.81, and is
        approximately two orders of magnitude faster than other
        available tools for location extraction.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS
        Concepts:</span> • <strong>Information systems</strong> →
        <strong>Information retrieval;</strong></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Emergencies</small>,</span>
          <span class="keyword"><small>microblogs</small>,</span>
          <span class="keyword"><small>location
          extraction</small>,</span> <span class=
          "keyword"><small>Geonames</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Ritam Dutt, Kaustubh Hiware, Avijit Ghosh, and Rameshwar
          Bhaskaran. 2018. SAVITR: A System for Real-time Location
          Extraction from Microblogs during Emergencies. In <em>WWW
          '18 Companion: The 2018 Web Conference Companion,</em>
          <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New
          York, NY, USA</em> 7 Pages. <a href=
          "https://doi.org/10.1145/3184558.3191623" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3191623</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Online social media sites, especially microblogging sites
      like Twitter and Weibo, have been shown to be very useful for
      gathering situational information in
      real-time&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0016">16</a>]. Consequently, it is imperative to
      not only process the vast incoming data stream on a real-time
      basis, but also to extract relevant information from the
      unstructured and noisy data accurately.</p>
      <p>It is especially crucial to extract geographical locations
      from tweets (microblogs), since the locations help to
      associate the information available online with the physical
      locations. This task is challenging since geo-tagged tweets
      are very sparse, especially in developing countries like
      India, accounting for only 0.36% of the total tweet traffic.
      Hence it becomes necessary to extract locations from the text
      of the tweets. This work proposes a novel and fast method of
      extracting locations from English tweets posted during
      emergency situations. The location is inferred from the
      tweet-text in an unsupervised fashion as opposed to using the
      geo-tagged field.</p>
      <p>Note that several methodologies for extracting locations
      from tweets have been proposed in literature; some of these
      are discussed in the next section. We compare the proposed
      methodology with several existing methodologies in terms of
      coverage (Recall) and accuracy (Precision). Additionally, we
      also compared the speed of operation of different methods,
      which is crucial for real-time deployment of the methods. The
      proposed method achieves very competitive values of Recall
      and Precision with the baseline methods, and the highest
      F-score among all methods. Importantly, the proposed
      methodology is several orders of magnitude faster than most
      of the prior methods, and is hence suitable for real-time
      deployment.</p>
      <p>We deploy the proposed methodology on a system available
      at <a class="link-inline force-break" href=
      "http://savitr.herokuapp.com">http://savitr.herokuapp.com</a>,
      which is described in a later section.</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related
          Work</h2>
        </div>
      </header>
      <p>We discuss some existing information systems for use
      during emergencies, and some prior methods for location
      extraction from microblogs.</p>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Systems for
            emergency informatics</h3>
          </div>
        </header>
        <p>A few Information Systems have already been implemented
        in various countries for emergency informatics, and their
        efficacy has been demonstrated in a variety of situations.
        Previous work on real-time earthquake detection in Japan
        was deployed by&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0017">17</a>] using Twitter users as social
        sensors. Simple systems like the Chennai Flood
        Map&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href="#BibPLXBIB0003">3</a>]
        have demonstrated the need and utility of Information
        Systems during the 2015 floods in the city of Chennai,
        India. This system used a combination of crowdsourcing,
        open source mapping technologies and contributed to
        large-scale civic participation.</p>
        <p>Likewise, Ushahidi&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0001">1</a>] is a non-profit crisis-mapping
        software company which utilises the concept of
        crowdsourcing for social activism and public
        accountability. It enables local observers to submit
        reports using their mobile phones or the Internet, thereby
        creating a temporal and geospatial archive of an ongoing
        event. Ushahidi has been deployed in situations such as
        earthquakes in Haiti, Chile, forest fires in Italy and
        Russia.</p>
        <p>The system developed in the present work functions on
        the same basic principle as the aforementioned ones –
        information extraction from crowdsourced data. However,
        unlike Mapbox&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0003">3</a>] and Ushahidi&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0001">1</a>], it is not necessary for
        the users to explicitly specify the location. Rather, we
        infer it from the tweet text, without any prior manual
        labeling.</p>
      </section>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Location
            Inferencing methods</h3>
          </div>
        </header>
        <p>Location inferencing is a specific variety of Named
        Entity Recognition (NER), whereby only the entities
        corresponding to valid geographical locations are
        extracted. There have been seminal works regarding location
        extraction from microblog text, inferring the location of a
        user from the user's set of posted tweets and even
        predicting the probable location of a tweet by training on
        previous tweets having valid geo-tagged fields. Publicly
        available tools like Stanford NER [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0007">7</a>], TwitterNLP [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0015">15</a>], OpenNLP
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0002">2</a>] and
        Google Cloud<a class="fn" href="#fn1" id=
        "foot-fn1"><sup>1</sup></a>, are also available for tasks
        such as location extraction from text.</p>
        <p>We focus our work only on extracting the locations from
        the tweet text, since we have observed that (i)&nbsp;a very
        small fraction of tweets are geo-tagged&nbsp;<a class="fn"
        href="#fn2" id="foot-fn2"><sup>2</sup></a>, and
        (ii)&nbsp;even for geo-tagged tweets, a tweet's geo-tagged
        location is not always a valid representative of the
        incident mentioned in the tweet text. For instance, the
        tweet “<em>Will discuss on TimesNow at 8.30 am today
        regarding Dengue Fever in Tamil Nadu.</em>” clearly refers
        to Tamil Nadu, but the geo-tagged location is New Delhi
        (from where the tweet was posted).</p>
        <p>We give an overview of the different types of
        methodologies used in location extraction systems. Prior
        state-of-the-art methods have performed common
        preprocessing steps like noun-phrase extraction and phrase
        matching&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0012">12</a>], or regex matching&nbsp;[<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0006">6</a>] before
        employing some of the following techniques for location
        extraction.</p>
        <ul class="list-no-style">
          <li id="list1" label="•">Gazetteer lookup: Gazetteer
          based search and n-gram based matching have been employed
          by [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0012">12</a>], [<a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0013">13</a>] , [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0008">8</a>].
            Usually some publicly available gazetteers like
            GeoNames or OpenStreetMap are used.<br />
          </li>
          <li id="list2" label="•">Handcrafted rules were employed
          in [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0012">12</a>] and [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0008">8</a>]<br />
          </li>
          <li id="list3" label="•">Supervised methods: Well-known
          supervised models used in this current context are:<br />

            <ol class="list-no-style">
              <li id="list4" label="(1)">Models based on
              Conditional Random Fields (CRF) such as the Stanford
              NER parser which was employed by [<a class="bib"
              data-trigger="hover" data-toggle="popover"
              data-placement="top" href="#BibPLXBIB0008">8</a>] and
              [<a class="bib" data-trigger="hover" data-toggle=
              "popover" data-placement="top" href=
              "#BibPLXBIB0012">12</a>]. While [<a class="bib"
              data-trigger="hover" data-toggle="popover"
              data-placement="top" href="#BibPLXBIB0008">8</a>]
              trained the model on tweet texts, [<a class="bib"
              data-trigger="hover" data-toggle="popover"
              data-placement="top" href="#BibPLXBIB0012">12</a>]
              used the parser without training.<br />
              </li>
              <li id="list5" label="(2)">Maximum entropy based
              models such as the OpenNLP was deployed by
                [<a class="bib" data-trigger="hover" data-toggle=
                "popover" data-placement="top" href=
                "#BibPLXBIB0011">11</a>] without training and it
                infers location using ME.<br />
              </li>
            </ol>
          </li>
          <li id="list6" label="•">Semi-supervised methods: The
          work&nbsp;[<a class="bib" data-trigger="hover"
          data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0010">10</a>] used semi-supervised methods
          such as beam-search and structured perceptrons to label
          sequences and linked them with corresponding Foursquare
          location entities.<br />
          </li>
        </ul>
      </section>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Extracting
          locations from microblogs</h2>
        </div>
      </header>
      <p>We now describe the proposed methodology for inferring
      locations from tweet text. The methodology involves the
      following tasks.</p>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Hashtag
            Segmentation</h3>
          </div>
        </header>
        <p>Hashtags are a relevant source of information in
        Twitter. Especially for tweets posted during emergency
        situations, hashtags often contain location names embedded
        in them, e.g., #NepalQuake, #GujaratFloods, #puertorico,
        #HoustonStrong, #MumbaiRains. In fact, it was observed that
        there are as many as 21 valid locations among the 100 most
        frequent hashtags posted during some recent emergency
        events related to floods, earthquakes and rain. However,
        due to the peculiar style of coining hashtags, it becomes
        imperative to break them into meaningful words. Similar
        to&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0012">12</a>] and&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0005">5</a>], we adopt a statistical
        word segmentation based algorithm&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0014">14</a>] to break a hashtag into
        distinct words, and extract locations from the distinct
        words. We also retain the original hashtag, to ensure we do
        not lose out on meaningful remote locations simply because
        they are uncommon.</p>
        <p>We have observed that hashtag segmentation has some
        unforeseen outcomes. While trying to optimize recall from a
        tweet, it hampers precision, especially when the segmented
        words corresponds to actual locations. For example
        ‘#Bengaluru’ (a place in India) is broken down into
        ‘bengal’ and ‘uru’, which are two other places in India.
        Likewise,‘#Kisiizi hospital’, a hospital in Uganda, in the
        tweet ”<em>We've dispatched off equipment to #Kabale and
        #Kisiizi hospital as an emergency intervention following
        recent devastations</em>”, is incorrectly segmented into
        ‘kissi’ and ‘zi’, none of which are location names. In
        spite of these limitations of hashtag segmentation, we
        still carry out this step since we seek to extract all
        possible location names, including those embedded within
        hashtags.</p>
      </section>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Tweet
            Preprocessing</h3>
          </div>
        </header>
        <p>We have employed common pre-processing techniques on the
        tweet text to remove URLs, mentions, stray characters like
        brackets, ’RT’, #, &amp;, ellipses and specific Unicode
        characters corresponding to emojis as observed in Figure
        <a class="fig" href="#fig1">1</a>. We also segmented
        CamelCase words and joint alphanumeric terms like
        ‘Chennai2015’ into distinct terms (‘Chennai’ and ‘2015’).
        We did <em>not</em> perform case-folding on the text since
        we wanted to detect proper nouns. Likewise, we also
        abstained from stemming since location names might get
        altered and cannot be detected using the gazetteer.</p>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span>
            Disambiguating Proper Nouns from Parse Trees</h3>
          </div>
        </header>
        <p>Since most location names are likely to be proper nouns,
        we use a heuristic to determine whether a proper noun is a
        location. We first apply a Parts-of-Speech (POS) tagger to
        yield POS tags. There are several POS taggers publicly
        available, which could be applied, such as SPaCy<a class=
        "fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>, the
        Twitter-specific CMU TweeboParser<a class="fn" href="#fn4"
        id="foot-fn4"><sup>4</sup></a>, and so on. We employ the
        POS Tagger of SPaCy, in preference to the CMU TweeboParser,
        due to the heavy processing time of the latter. The
        TweeboParser was 1000 times slower as opposed to SpaCy. We
        considered the speed to be a viable trade-off for accuracy
        since we want the method to be deployed on a real-time
        basis and we observed the processing time would be a
        bottleneck in this regard.</p>
        <p>Let <em>T<sub>i</sub></em> denote the POS tag of the
        <em>i<sup>th</sup></em> word <em>w<sub>i</sub></em> of the
        tweet. If <em>T<sub>i</sub></em> corresponds to a proper
        noun, we keep on appending words that succeed
        <em>w<sub>i</sub></em> , provided they are also proper
        nouns, or adjectives or delimiters (conjunctions (‘and’,
        ‘or’) or punctuations (‘;’, ‘)’). We have developed a list
        of common suffixes of location names (explained below). If
        <em>w<sub>i</sub></em> is followed by a noun in this suffix
        list, we consider it to be a viable location. Acknowledging
        the fact that Out of Vocabulary (OOV) words are common in
        Twitter, we also consider those words which have a high
        Jaro-Winkler similarity with the words in the suffix list.
        We also check the word immediately preceding
        <em>w<sub>i</sub></em> , to see if it is a preposition that
        usually precedes a place or location, such as ‘at’, ‘in’,
        ‘from’, ‘to’, ‘near’, etc, or directions like north,
        eastern etc. We then split the stream of words obtained via
        the delimiters. Thus, we attempt to infer from the text
        proper nouns which conform to locations from their
        syntactic structure.</p>
        <p>We illustrate the working of this procedure using the
        processed tweet text ‘<em>18 doctors on 18 motorcycles rode
        to 132 flood-hit villages in Bainsa division of Purnia
        district in Bihar</em> also depicted in the flowchart in
        Figure&nbsp;<a class="fig" href="#fig1">1</a>. The
        algorithm identifies ’Bainsa’, ’Purnia’ and ’Bihar’ as
        proper nouns. Since ‘Purnia’ is followed by the word
        ‘district’, the phrase ‘Purnia district’ is identified as a
        location. However, ‘Bainsa’ and ‘Bihar’ are also detected
        as viable locations because they were treated as
        prepositional objects with respect to the preposition
        ‘in’.</p>
      </section>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.4</span> Regex
            matches</h3>
          </div>
        </header>
        <p>As mentioned in the previous section, we have compiled a
        suffix list containing words that usually come after a
        location name. The suffix list comprises different naming
        conventions for landforms<a class="fn" href="#fn5" id=
        "foot-fn5"><sup>5</sup></a>, roads<a class="fn" href="#fn6"
        id="foot-fn6"><sup>6</sup></a> <a class="fn" href="#fn7"
        id="foot-fn7"><sup>7</sup></a>, buildings<a class="fn"
        href="#fn8" id="foot-fn8"><sup>8</sup></a> and towns In a
        similar fashion, we have also compiled a prefix list, which
        specifies the direction that prepend a location, like
        Southern California, West Bengal. A part of the suffix and
        prefix list is shown in Table&nbsp;<a class="tbl" href=
        "#tab1">1</a>.</p>
        <p>We identify the prefix and suffix elements from the
        tweet text and treat the words that succeed or precede it
        as viable locations. We perform this additional task of
        regex similarity to account for cases when the tweet is
        posted in lowercase, making it difficult to detect and
        disambiguate proper nouns. Using the suffix list enables us
        to detect places like ‘Vinayak hospital’ and ‘Gujranwala
        town’ from the tweet “<em>Urgent B+ group platelets
        suffering from dengue,Ankit Arora At Vinayak hospital,
        Gujranwala town,delhi</em>”.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Examples of suffixes and
            emergency-related words</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:center;">Type</td>
                <td style="text-align:center;">Common Examples</td>
              </tr>
              <tr>
                <td style="text-align:center;">Landforms</td>
                <td style="text-align:center;">doab, lake, steam,
                river, island, valley, mountain, hill</td>
              </tr>
              <tr>
                <td style="text-align:center;">Roads</td>
                <td style="text-align:center;">street, st,
                boulevard, junction, lane, rd, avenue, bridge</td>
              </tr>
              <tr>
                <td style="text-align:center;">Buildings</td>
                <td style="text-align:center;">hospital, school,
                shrine, cinema,villa, temple, mosque,</td>
              </tr>
              <tr>
                <td style="text-align:center;">Towns</td>
                <td style="text-align:center;">city, district,
                village, gram, place,town, nagar,</td>
              </tr>
              <tr>
                <td style="text-align:center;">Directions</td>
                <td style="text-align:center;">south, eastern, NW,
                SE, west, western, north east,</td>
              </tr>
              <tr>
                <td style="text-align:center;">Diseases</td>
                <td style="text-align:center;">dengue, ebola,
                cholera, zika, malaria, chikungunya</td>
              </tr>
              <tr>
                <td style="text-align:center;">Disasters</td>
                <td style="text-align:center;">earthquake, floods,
                drought, tsunami, landslide, rains</td>
              </tr>
            </tbody>
          </table>
        </div>
        <figure id="fig1">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191623/images/www18companion-362-fig1.jpg"
          class="img-responsive" alt="Figure 1" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span>
            <span class="figure-title">Flowchart depicting the
            functioning of our algorithm on a sample tweet “<em>RT
            firstpost: 18 doctors on 18 motorcycles rode to 132
            flood-hit villages in Bainsa division of Purnia
            district in #Bihar https://t.co</em>”.</span>
          </div>
        </figure>
      </section>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.5</span> Dependency
            Parsing of Emergency words</h3>
          </div>
        </header>
        <p>So far, the methodology aims at improving the precision,
        by considering specific norms or patterns by which
        locations are usually identified. This step is meant to
        improve recall by capturing those locations which do not
        follow the common patterns listed above.</p>
        <p>Taking into consideration that our objective is to
        monitor emergency scenarios, we identify a comprehensive
        set of words corresponding to epidemic disasters<a class=
        "fn" href="#fn9" id="foot-fn9"><sup>9</sup></a> and natural
        disasters<a class="fn" href="#fn10" id=
        "foot-fn10"><sup>10</sup></a>, some of which are shown in
        Table &nbsp;<a class="tbl" href="#tab1">1</a>. We identify
        the list of emergency words in the tweet text and consider
        words, namely proper nouns, nouns and adjectives, which are
        <em>at a short distance of 3-4 from the emergency word</em>
        in the dependency graph obtained for the tweet text. The
        distance metric refers to the number of links connecting
        the words in the dependency graph of the tweet text. A
        short dependency implies the word is more intimately
        affected by the emergency word. We had taken randomly 100
        tweets which had 153 locations identifiable by manual
        annotation, out of which 139 were correctly identified. The
        average distance between the emergency word and the
        identifiable locations via the dependency graph was found
        to be 3.942 while the orthographic distance (the number of
        words between the emergency and and target word) was
        5.111.</p>
        <p>As an example, Figure&nbsp;<a class="fig" href=
        "#fig2">2</a> shows the dependency graph for the tweet
        “<em>Mumbai lost its mudflats and wetlands, now floods with
        every monsoon.</em>”. We see that the distance between
        Mumbai and floods in the dependency graph of the tweet is
        2, whereas the actual distance between the words in the
        text is 7. Hence we can identify Mumbai as a proper
        location via dependency parsing.</p>
        <p>Thereafter, we also extract the noun phrases from the
        dependency graph similar to &nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0012">12</a>]. These noun phrases can
        represent potential locations as illustrated in the
        <a class="fig" href="#fig1">1</a>, wherein the NP (Noun
        Phrase) Chunker gave viable locations like ‘Purnia
        district’, ‘Bainsa division’, besides redundant information
        like ‘132 flood-hit villages’. Finally, for sake of
        completeness, we use an NER tagger in a fashion similar
        to&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href="#BibPLXBIB0008">8</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0011">11</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0012">12</a>]. We have
        leveraged the NER Tagger provided by SpaCy as opposed to
        the more commonly available NER tools like Stanford
        NER&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0007">7</a>], Twitter NLP&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0015">15</a>], Open
        NLP&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0002">2</a>], due to the faster execution time
        of the former as observed in Table <a class="tbl" href=
        "#tab2">2</a>.</p>
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191623/images/www18companion-362-fig2.jpg"
          class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">Dependency graph for a
            sample tweet “<em>Mumbai lost its mudflats and
            wetlands, now floods with every monsoon.</em>”.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.6</span> Gazetteer
            Verification</h3>
          </div>
        </header>
        <p>The list of phrases and locations extracted by the above
        methods are then verified using a gazetteer, to retain only
        those words that correspond to real-world locations. As
        evident from Figure&nbsp;<a class="fig" href="#fig1">1</a>,
        the gazetteer verification step is essential to filter out
        redundant noun phrases and nouns obtained via dependency
        parsing and regex matches, such as ‘18 doctors’, ‘flood-hit
        villages’, ‘division’, etc. For our system, the gazetteers
        also returns the geo-spatial coordinates to enable plotting
        the location on a map. The gazetteer choice depends upon
        the granularity and precision of our location and also on
        the performance speed. There is a trade-off for finer
        accuracy against performance which we illustrate in the
        later sections.</p>
      </section>
    </section>
    <section id="sec-16">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Comparative
          evaluation of the location inference</h2>
        </div>
      </header>
      <p>In this section, we describe the evaluation of the
      proposed methodology, and compare it with several baseline
      methods. We start by describing the dataset and some design
      choices made by us.</p>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span>
            Dataset</h3>
          </div>
        </header>
        <p>We used the Twitter Streaming API<a class="fn" href=
        "#fn11" id="foot-fn11"><sup>11</sup></a>, to collect tweets
        from 12 <sup><em>th</em></sup> September, 2017 to 13
        <sup><em>th</em></sup> October, 2017, and filtered those
        tweets that contained either of the two words ’dengue’ or
        ’flood’. This step produced a dataset of 317,567 tweets
        collected over a period of 31 days. The tweets were
        preprocessed to remove duplicates and also tweets written
        in non-English languages. This filtering resulted in
        239,276 distinct tweets.</p>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Gazetteer
            employed</h3>
          </div>
        </header>
        <p>In this work, we currently focus on collecting and
        displaying tweets within the bounding box of the country of
        India. Thus, we need some lexicon / gazetteer to
        disambiguate whether a place is located inside India and
        what its geographical coordinates are. To that end, we
        scraped the data publicly available from Geonames<a class=
        "fn" href="#fn12" id="foot-fn12"><sup>12</sup></a> and
        created a dictionary corresponding to different locations
        within India. The dictionary has the information of 449,973
        locations within India. However, some places mentioned in
        this dictionary have high orthographic similarity with
        common English nouns. For example, we find that the word
        ‘song’ is a place located in Sikkim (within India), whose
        coordinates are 27.24641′<em>N</em>, 88.50622′<em>E</em>.
        Moreover, Geonames does <em>not</em> contain fine-grained
        information of addresses such as roads and buildings.</p>
        <p>Consequently, we explored another gazetteer – the Open
        Street Map gazetteer<a class="fn" href="#fn13" id=
        "foot-fn13"><sup>13</sup></a> which has a comprehensive
        list of all possibles addresses for India. However, the
        sheer volume of the data – ≈ 530 times larger than Geonames
        – hampers performance in a real-time setting. Also, API
        calls take considerable time as opposed to querying the
        downloaded dump of the Geonames Gazetteer<a class="fn"
        href="#fn14" id="foot-fn14"><sup>14</sup></a>.</p>
        <p>Thus the choice of the gazetteer is governed by a
        trade-off between recall and efficiency. We report
        performances using both gazetteers in this paper. Hence we
        consider two variants of the proposed methodology:</p>
        <ul class="list-no-style">
          <li id="list7" label="•">GeoLoc - Our proposed
          methodology using Geonames as the gazetteer.<br /></li>
          <li id="list8" label="•">OSMLoc - Our proposed
          methodology using Open Street Maps as the
          gazetteer.<br /></li>
        </ul>
      </section>
      <section id="sec-19">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Baseline
            methodologies</h3>
          </div>
        </header>
        <p>We compared the proposed approach of our algorithm with
        several baseline methodologies which are enlisted
        below:</p>
        <ul class="list-no-style">
          <li id="list9" label="•">UniLoc- Take all unigrams in the
          processed tweet text and infer if any of those correspond
          to a possible location (by referring to a
          gazetteer).<br /></li>
          <li id="list10" label="•">BiLoc- Similar to UniLoc,
          except we consider both unigrams and bigrams in the tweet
          text.<br /></li>
          <li id="list11" label="•">StanfordNER - Employs the NER
          of coreNLP parser&nbsp;[<a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top"
            href="#BibPLXBIB0007">7</a>].<br />
          </li>
          <li id="list12" label="•">TwitterNLP - Employ the NER of
          Twitter NLP parser developed by Ritter et
          al.&nbsp;[<a class="bib" data-trigger="hover"
            data-toggle="popover" data-placement="top" href=
            "#BibPLXBIB0015">15</a>]<br />
          </li>
          <li id="list13" label="•">GoogleCloud - Use the Google
          Cloud Natural Language Platform to infer
          locations.<a class="fn" href="#fn15" id=
          "foot-fn15"><sup>15</sup></a><br />
          </li>
          <li id="list14" label="•">SpaCyNER - Use the trained
          SpaCy NER tagger.<br /></li>
        </ul>
        <p>For all the baseline methods, the potential locations
        are checked using the GeoNames gazetteer.</p>
      </section>
      <section id="sec-20">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.4</span> Evaluation
            Measures</h3>
          </div>
        </header>
        <p>Given a tweet text, we wish to infer all possible
        locations contained in the tweet. Thus we should prefer a
        method which has higher recall. However, since we also aim
        to plot the location obtained from the tweet, the precision
        of our extracted locations also matters. Hence we apply the
        following measures.</p>
        <div class="table-responsive" id="Xeq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} Precision
            =\frac{\left| \mbox{Correct Locations} \bigcap
            \mbox{Retrieved Locations} \right|}{ \mbox{Retrieved
            Locations}} \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>
        <div class="table-responsive" id="Xeq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} Recall
            =\frac{\left| \mbox{Correct Locations} \bigcap
            \mbox{Retrieved Locations} \right|}{ \mbox{Correct
            Locations}} \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>where ‘Correct locations’ is the set of locations
        actually mentioned in a tweet, as found by human
        annotators, and ‘Retrieved locations’ is the set of
        locations inferred by a certain methodology from the same
        tweet. To get an idea of both precision and recall, we use
        F-score which is the harmonic mean of precision and recall.
        <p></p>
        <p>Moreover, since we wish to deploy the system on a
        real-time basis, the <em>evaluation time</em> taken by a
        method is also a justifiable metric.</p>
      </section>
      <section id="sec-21">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.5</span> Evaluation
            results</h3>
          </div>
        </header>
        <p>We randomly selected 1,000 tweets from the collected set
        of tweets (as described earlier), and asked human
        annotators to identify those tweets which contain some
        location names. The annotators identified a set of 99
        tweets that contained at least one location name, all of
        which were located within India's geographical boundaries.
        Hence the comparative evaluation is carried out over this
        set of 99 tweets. Table&nbsp;<a class="tbl" href=
        "#tab2">2</a> compares the performances of the baseline
        methods and the proposed method. The last column shows the
        total time in seconds needed to process the 99 tweets that
        we are using for evaluation.</p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Evaluation Performance of the baseline
            methods and the proposed methods (two variants, one
            using GeoNames gazetteer, and the other using Open
            Street Maps gazetteer).</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:center;">Method</td>
                <td style="text-align:center;">Precision</td>
                <td style="text-align:center;">Recall</td>
                <td style="text-align:center;">F-score</td>
                <td style="text-align:right;">Timing (in s)</td>
              </tr>
              <tr>
                <td style="text-align:center;">UNILoc</td>
                <td style="text-align:center;">0.3848</td>
                <td style="text-align:center;">0.7852</td>
                <td style="text-align:center;">0.5165</td>
                <td style="text-align:right;">0.0553</td>
              </tr>
              <tr>
                <td style="text-align:center;">BILoc</td>
                <td style="text-align:center;">0.4025</td>
                <td style="text-align:center;">0.8590</td>
                <td style="text-align:center;">0.5482</td>
                <td style="text-align:right;">0.0624</td>
              </tr>
              <tr>
                <td style="text-align:center;">StanfordNER</td>
                <td style="text-align:center;">0.8103</td>
                <td style="text-align:center;">0.6322</td>
                <td style="text-align:center;">0.6988</td>
                <td style="text-align:right;">175.0124</td>
              </tr>
              <tr>
                <td style="text-align:center;">TwitterNLP</td>
                <td style="text-align:center;">0.6356</td>
                <td style="text-align:center;">0.5474</td>
                <td style="text-align:center;">0.5882</td>
                <td style="text-align:right;">28.0001</td>
              </tr>
              <tr>
                <td style="text-align:center;">GoogleCloud</td>
                <td style="text-align:center;">0.6321</td>
                <td style="text-align:center;">0.5339</td>
                <td style="text-align:center;">0.5789</td>
                <td style="text-align:right;">NA</td>
              </tr>
              <tr>
                <td style="text-align:center;">SpaCyNER</td>
                <td style="text-align:center;">
                <strong>0.9883</strong></td>
                <td style="text-align:center;">0.5555</td>
                <td style="text-align:center;">0.7113</td>
                <td style="text-align:right;">1.0891</td>
              </tr>
              <tr>
                <td style="text-align:center;">GeoLoc</td>
                <td style="text-align:center;">0.7987</td>
                <td style="text-align:center;">0.8300</td>
                <td style="text-align:center;">
                <strong>0.8141</strong></td>
                <td style="text-align:right;">1.1901</td>
              </tr>
              <tr>
                <td style="text-align:center;">OSMLoc</td>
                <td style="text-align:center;">0.3383</td>
                <td style="text-align:center;">
                <strong>0.8888</strong></td>
                <td style="text-align:center;">0.4901</td>
                <td style="text-align:right;">711.5817</td>
              </tr>
              <tr>
                <td style="text-align:center;">GeoLocNoNER</td>
                <td style="text-align:center;">0.7987</td>
                <td style="text-align:center;">0.7987</td>
                <td style="text-align:center;">0.7987</td>
                <td style="text-align:right;">1.1687</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>We observe that GeoLoc performs the best in terms of F1
        score as compared to all other methods. It also scores high
        on precision, ranking only third to StanfordNER and
        SpaCyNER. The high precision of SpaCyNer is counterbalanced
        by its poor recall due to which it was hardly able to
        detect remote places. For instance, for the tweet
        <em>‘Urgent B+ blood needed for a crit dengue patient at
        May Hosp. , Mohali,(Chandigarh)’</em>, SpaCyNer fails to
        detect locations like ‘Mohali’ from the tweet. However,
        ‘Mohali’ is detected by our GeoLoc algorithm.</p>
        <p>The slight decrease in precision is attributed to some
        common words like ‘song’, ‘monsoon’, ‘parole’ being chosen
        as potential locations due to incorrect hashtag
        segmentation, and then the gazetter tagging these words as
        locations, since these are also names of certain places in
        India.</p>
        <p>It can also be seen that, the proposed method using
        GeoNames gazetteer is much faster than the other methods
        which achieve comparable performance (e.g., StanfordNER).
        We also note the performance of our proposed algorithm in
        the absence of any NER tool, denoted by GeoLocNoNER in the
        Table <a class="tbl" href="#tab2">2</a>. It is observed
        that our proposed methodology performs better than the
        pre-existing ones and suffer only a slight decrease in
        recall (3.7%) as compared to GeoLoc. This validates the
        claim that our proposed methodology is not solely dependent
        on the accuracy of the NER tool employed.</p>
        <p><strong>Choice of gazetteer:</strong>As stated earlier,
        the Geonames gazetteer lacks information of a granular
        level. Consequently specific places pertaining to hospitals
        and streets are often not recognized as valid locations.
        This hampers the recall of the system, e.g., the proposed
        methodology was unable to detect ‘star hospital’ in the
        tweet “<em>We need O-ve blood grup for 8 years boy
        suffering with dengue in star hospital in karimnagar ,
        please Contact</em>.”</p>
        <p>Open Street Map (OSM) is able to detect such specific
        locations and thus exhibits the highest recall amongst all
        other methods. However, using OSM has the side-effect of
        classifying many simple noun phrases as valid locations.
        For instance, ‘silicon city’ is detected as a location in
        the tweet “<em>@rajeev_mp seems its time to rename
        Bangalore as Floods city I/O silicon city.</em>”, since
        ‘silicon city’ is judged a shortening for the entry
        ‘Concorde Silicon Valley, Electronics City Phase 1,
        Vittasandra, Bangalore’. As a result of such errors, the
        method using OSM has the lowest precision score amongst all
        the methods.</p>
        <p><strong>Performance over the entire
        dataset:</strong>From the entire set of 239,276 distinct
        tweets, only 3,493 were geo-tagged, out of which 869 were
        from India (which corresponds to a minute 0.36% of the
        entire dataset). The number of tweets which were
        successfully tagged from the entire dataset, using our
        proposed technique and Geonames was 68,793, which
        corresponds to approximately 26.15%. Hence the coverage
        increased drastically. The method could identify niche and
        remote places in India, like ‘Ghatkopar’, ‘Guntur’, ‘Pipra
        village’ and ‘Kharagpur’, besides metropolitan cities like
        ‘Delhi’, ‘Kolkata’ and ‘Mumbai’.</p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191623/images/www18companion-362-fig3.jpg"
          class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">System architecture of the
            SAVITR system</span>
          </div>
        </figure>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3200000/3191623/images/www18companion-362-fig4.jpg"
          class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">Snapshot of the SAVITR
            system: Tweets visualised on India's map</span>
          </div>
        </figure>
        <p></p>
      </section>
    </section>
    <section id="sec-22">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> SAVITR:
          Deploying the location inference method</h2>
        </div>
      </header>
      <p>We have deployed the proposed techniques (using GeoNames)
      on a system named SAVITR, which is live at <a class=
      "link-inline force-break" href=
      "http://savitr.herokuapp.com">http://savitr.herokuapp.com</a>.
      The software architecture of Savitr is presented in
      Figure&nbsp;<a class="fig" href="#fig3">3</a>. Since the
      amount of data to be displayed is massive, we had to
      implement certain design considerations so that the
      information displayed is both compact and visually enriching,
      while at the same time scalable. The system was built using
      the Dash framework by Plotly&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0004">4</a>]. For our visualization
      purpose, we settled on a mapbox Map at the heart of the UI,
      with various controls, as described below. A snapshot of the
      system is shown in Figure&nbsp;<a class="fig" href=
      "#fig4">4</a>.</p>
      <ul class="list-no-style">
        <li id="list15" label="•">A search bar at the top of the
        page. Whenever a term is entered into the search bar, the
        map refreshes and shows tweets pertaining to that query
        term. It also supports multiple search queries like
        ”Dengue, Malaria”.<br /></li>
        <li id="list16" label="•">The tweets on the map are color
        coded according to the time of the day. Tweets posted in
        the night are darker.<br /></li>
        <li id="list17" label="•">A date-picker – if one wishes to
        visualize tweets posted during a particular time duration,
        this provides fine grained date selection, both at the
        month and date level.<br /></li>
        <li id="list18" label="•">A Histogram – this shows the
        number of relevant (tagged) tweets posted per
        day.<br /></li>
        <li id="list19" label="•">Untagged tweets – Finally, at the
        bottom of the page we display the tweets for which location
        could not be inferred (and hence they could not be shown on
        the map).<br /></li>
      </ul>
      <p>We report the performance of the system during the massive
      dengue outbreak that plagued India in the fall of
      2017.<a class="fn" href="#fn16" id=
      "foot-fn16"><sup>16</sup></a> The state of Kerala was
      severely affected by the outbreak. During this period, as
      many as 2204 tweets mentioning Kerala were identified by the
      system, which is far higher than the average rate at which
      other locations were detected. Additionally, out of the 2204
      tweets containing the location ‘Kerala’, 1960 (88.92%) also
      contained the term ‘dengue’ which is included in the list of
      disaster terms compiled by us (see Table&nbsp;<a class="tbl"
      href="#tab1">1</a>). These statistics demonstrate how the
      SAVITR system can be used as an ‘Early warning system’ to
      flag any upcoming emergency situation.</p>
      <p>Though the SAVITR system presently infers locations within
      India, it can be easily extended to infer locations within
      other countries, and the whole world in general.</p>
    </section>
    <section id="sec-23">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Discussion</h2>
        </div>
      </header>
      <p>A natural quest is to extend the scope of the system,
      e.g., to non-English tweets and to the whole world (instead
      of just India). To this end, we have observed several
      challenges that remains to be solved, some of which we
      enumerate in this section.</p>
      <section id="sec-24">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.1</span> Handling
            non-English tweets</h3>
          </div>
        </header>
        <p>The methodology currently focuses on inferring locations
        from English tweets. However, the techniques in this paper
        leverage simple syntactic and semantic techniques and hence
        can be extended to other languages, like German and Hindi,
        provided the requisite tools (POS Tagger, dependency
        parser, lexicon) are available. We only need to craft the
        rules such as disambiguating proper nouns, in a manner
        which conforms with the grammatical structure. However, the
        more challenging issue lies in extracting locations from
        code-mixed and code-borrowed tweets. A simple, crude
        technique would involve identifying the different languages
        from the tweet text, transliteration into English, and
        thereafter applying the algorithm as described in the
        paper. However whether this task can be accomplished on a
        real-time basis with decent accuracy remains
        unresolved.</p>
      </section>
      <section id="sec-25">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.2</span> Identifying
            locations globally</h3>
          </div>
        </header>
        <p>The system currently implemented focuses only on
        locations within the geographical boundaries of the country
        of India. We have experimented with different gazetteers at
        varying degrees of granularity and observed that a
        comprehensive/extensive gazetteer is able to capture
        finer-grained locations at the expense of greater
        misclassification. Thus, in order to infer locations on a
        global scale, we require a location disambiguation
        algorithm to distinguish between two distinct locations
        sharing the same name. For instance, the location ‘Kota’ in
        the tweets ”<em>3 out of 6 members of my family had dengue
        last week in Kota, Rajasthan.</em>” and ”<em>Floods in Kota
        Belud cuts off access to 8 villages</em>” refer to a place
        in Rajasthan, India and another place in Malaysia
        respectively.</p>
        <p>Any location disambiguation technique would need to rely
        on social cues, such as user-name of the person who posted
        the tweet, or the geo-tagged location of the tweet/user, in
        addition to the text. The short length of the tweet text
        might not be capable of providing sufficient context.
        However, in case of a global calamity, people all over the
        world express their opinion/ sympathy, which exacerbates
        the challenge of discerning the location of a text from the
        user name itself.</p>
        <p>Likewise for some geo-tagged tweets, it is observed that
        a tweet can be posted from a different place as compared to
        the locations mentioned in the text. A common phenomenon is
        that a tweet posted from a metropolitan city (e.g., New
        Delhi) contains some information about a suburb. How to
        deal with such tweets is application-specific.</p>
      </section>
      <section id="sec-26">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.3</span> System
            improvements</h3>
          </div>
        </header>
        <p>Specific changes need to incorporated into the system as
        well if we intend to deploy it on a global scale. The
        massive information overload would deem it infeasible to
        display both tagged and untagged tweets on an individual
        basis. This necessitates implementing an automated
        summarization technique to capture and display summaries on
        the system. In the event of an epidemic, it is essential to
        classify tweets into different medical concepts like
        treatment, symptoms, transmission, death reports etc, which
        are important to different stakeholders. The system can be
        extended to display such crucial information on the map
        using different color codes.</p>
      </section>
    </section>
    <section id="sec-27">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span> Conclusion</h2>
        </div>
      </header>
      <p>We proposed a methodology for real-time inference of
      locations from tweet text, and deployed the methodology in a
      system (SAVITR). The proposed methodology performs better
      than many prior methods, and is much more suitable for
      real-time deployment. We also discussed the challenges that
      need to be solved for extending the scope of the system.</p>
    </section>
    <section id="sec-28">
      <header>
        <div class="title-info">
          <h2>Acknowledgements</h2>
        </div>
      </header>
      <p>The authors thank Dr. Saptarshi Ghosh, Department of
      Computer Science and Engineering, IIT Kharagpur, for
      mentorship and guidance throughout the project. The authors
      acknowledge the annotators (Sohan Patro and others) who
      helped in evaluation of the methodologies, and useful
      discussions with Nishant Nikhil in the early stage of the
      project. The authors also thank the anonymous reviewers whose
      comments helped to improve the paper. The work is partially
      supported by Microsoft Research India, and part of the work
      was done at the 2017 MSR India Summer Workshop on Artificial
      Social Intelligence.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">2008. Ushahidi.
        https://www.ushahidi.com/. (2008). Accessed:
        2018-01-22.</li>
        <li id="BibPLXBIB0002" label="[2]">2010. OpenNLP.
        http://opennlp.apache.org. (2010).</li>
        <li id="BibPLXBIB0003" label="[3]">2015. Chennai floods
        map: Crowdsourcing data and crisis mapping for emergency
        response.
        https://osm-in.github.io/flood-map/chennai.html#11/13.0000/80.2000.
        (2015). Accessed: 2018-01-22.</li>
        <li id="BibPLXBIB0004" label="[4]">2016. Plotly.
        https://plot.ly/products/dash/. (2016).</li>
        <li id="BibPLXBIB0005" label="[5]">Hussein&nbsp;S.
        Al-Olimat, Krishnaprasad Thirunarayan, Valerie&nbsp;L.
        Shalin, and Amit&nbsp;P. Sheth. 2017. Location Name
        Extraction from Targeted Text Streams using Gazetteer-based
        Statistical Language Models. <em><em>CoRR</em></em>
        abs/1708.03105(2017). arxiv:1708.03105<a class=
        "link-inline force-break" href=
        "http://arxiv.org/abs/1708.03105" target=
        "_blank">http://arxiv.org/abs/1708.03105</a>
        </li>
        <li id="BibPLXBIB0006" label="[6]">Kalina Bontcheva, Leon
        Derczynski, Adam Funk, Mark&nbsp;A Greenwood, Diana
        Maynard, and Niraj Aswani. 2013. TwitIE: An Open-Source
        Information Extraction Pipeline for Microblog Text. In
        <em><em>In Proceedings of the Recent Advances in Natural
        Language Processing (RANLP 2013), Hissar</em>.
        Citeseer</em>.</li>
        <li id="BibPLXBIB0007" label="[7]">Jenny&nbsp;Rose Finkel,
        Trond Grenager, and Christopher Manning. 2005.
        Incorporating Non-local Information into Information
        Extraction Systems by Gibbs Sampling. In
        <em><em>Proceedings of the 43rd Annual Meeting on
        Association for Computational Linguistics</em></em>
        (<em>ACL ’05</em>). Association for Computational
        Linguistics, Stroudsburg, PA, USA, 363–370. <a class=
        "link-inline force-break" href=
        "http://dx.doi.org/10.3115/1219840.1219885" target=
        "_blank">http://dx.doi.org/10.3115/1219840.1219885</a>
        </li>
        <li id="BibPLXBIB0008" label="[8]">Judith Gelernter and Wei
        Zhang. 2013. Cross-lingual geo-parsing for non-structured
        data. In <em><em>Proceedings of the 7th Workshop on
        Geographic Information Retrieval</em></em> . ACM,
        64–71.</li>
        <li id="BibPLXBIB0009" label="[9]">Muhammad Imran, Carlos
        Castillo, Fernando Diaz, and Sarah Vieweg. 2015. Processing
        Social Media Messages in Mass Emergency: A Survey.
        <em><em>Comput. Surveys</em></em> 47, 4 (June 2015),
        67:1–67:38.</li>
        <li id="BibPLXBIB0010" label="[10]">Zongcheng Ji, Aixin
        Sun, Gao Cong, and Jialong Han. 2016. Joint recognition and
        linking of fine-grained locations from tweets. In
        <em><em>Proceedings of the 25th International Conference on
        World Wide Web</em></em> . International World Wide Web
        Conferences Steering Committee, 1271–1281.</li>
        <li id="BibPLXBIB0011" label="[11]">John Lingad, Sarvnaz
        Karimi, and Jie Yin. 2013. Location extraction from
        disaster-related microblogs. In <em><em>Proceedings of the
        22nd international conference on world wide web</em></em> .
        ACM, 1017–1020.</li>
        <li id="BibPLXBIB0012" label="[12]">Shervin Malmasi and
        Mark” Dras. 2016. Location Mention Detection in Tweets and
        Microblogs. In <em><em>Computational Linguistics</em></em>
        , Kôiti Hasida and Ayu Purwarianti (Eds.). Springer
        Singapore, Singapore, 123–134.</li>
        <li id="BibPLXBIB0013" label="[13]">Stuart&nbsp;E
        Middleton, Lee Middleton, and Stefano Modafferi. 2014.
        Real-time crisis mapping of natural disasters using social
        media. <em><em>IEEE Intelligent Systems</em></em> 29, 2
        (2014), 9–17.</li>
        <li id="BibPLXBIB0014" label="[14]">Peter Norvig. 2009.
        Natural Language Corpus Data. (01 2009).</li>
        <li id="BibPLXBIB0015" label="[15]">Alan Ritter, Sam Clark,
        Mausam, and Oren Etzioni. 2011. Named Entity Recognition in
        Tweets: An Experimental Study. In <em><em>Proceedings of
        the Conference on Empirical Methods in Natural Language
        Processing</em></em> (<em>EMNLP ’11</em>). Association for
        Computational Linguistics, Stroudsburg, PA, USA, 1524–1534.
        <a class="link-inline force-break" href=
        "http://dl.acm.org/citation.cfm?id=2145432.2145595"
          target="_blank">http://dl.acm.org/citation.cfm?id=2145432.2145595</a>
        </li>
        <li id="BibPLXBIB0016" label="[16]">Koustav Rudra, Subham
        Ghosh, Pawan Goyal, Niloy Ganguly, and Saptarshi Ghosh.
        2015. Extracting Situational Information from Microblogs
        during Disaster Events: A Classification-Summarization
        Approach. In <em><em>Proc. ACM CIKM</em></em> .</li>
        <li id="BibPLXBIB0017" label="[17]">Takeshi Sakaki, Makoto
        Okazaki, and Yutaka Matsuo. 2010. Earthquake Shakes Twitter
        Users: Real-time Event Detection by Social Sensors. In
        <em><em>Proc. International Conference on World Wide Web
        (WWW)</em></em> . 851–860.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class=
    "link-inline force-break" href=
    "https://cloud.google.com/natural-language/">https://cloud.google.com/natural-language/</a></p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>Note that in a
    geo-tagged tweet, the location is explicitly provided by the
    user as a separate field, regardless of whether it is present
    in the text</p>
    <p id="fn3"><a href=
    "#foot-fn3"><sup>3</sup></a>https://spacy.io/</p>
    <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a><a class=
    "link-inline force-break" href=
    "http://www.cs.cmu.edu/">http://www.cs.cmu.edu/</a>&nbsp;ark/TweetNLP/</p>
    <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a><a class=
    "link-inline force-break" href=
    "https://en.wikipedia.org/wiki/List_of_landforms">https://en.wikipedia.org/wiki/List_of_landforms</a></p>
    <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a><a class=
    "link-inline force-break" href=
    "https://wiki.waze.com/wiki/India/Editing/Roads">https://wiki.waze.com/wiki/India/Editing/Roads</a></p>
    <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a><a class=
    "link-inline force-break" href=
    "http://www.haringey.gov.uk">http://www.haringey.gov.uk</a></p>
    <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a><a class=
    "link-inline force-break" href=
    "https://en.wikipedia.org/wiki/List_of_building_types">https://en.wikipedia.org/wiki/List_of_building_types</a></p>
    <p id="fn9"><a href="#foot-fn9"><sup>9</sup></a><a class=
    "link-inline force-break" href=
    "https://en.wikipedia.org/wiki/List_of_epidemics">https://en.wikipedia.org/wiki/List_of_epidemics</a></p>
    <p id="fn10"><a href="#foot-fn10"><sup>10</sup></a><a class=
    "link-inline force-break" href=
    "https://en.wikipedia.org/wiki/Lists_of_disasters">https://en.wikipedia.org/wiki/Lists_of_disasters</a></p>
    <p id="fn11"><a href="#foot-fn11"><sup>11</sup></a><a class=
    "link-inline force-break" href=
    "https://developer.twitter.com/en/docs">https://developer.twitter.com/en/docs</a></p>
    <p id="fn12"><a href="#foot-fn12"><sup>12</sup></a><a class=
    "link-inline force-break" href=
    "http://www.geonames.org/">http://www.geonames.org/</a></p>
    <p id="fn13"><a href=
    "#foot-fn13"><sup>13</sup></a>http://geocoder.readthedocs.io/providers/OpenStreetMap.html</p>
    <p id="fn14"><a href=
    "#foot-fn14"><sup>14</sup></a>http://download.geofabrik.de/asia/india.html</p>
    <p id="fn15"><a href="#foot-fn15"><sup>15</sup></a><a class=
    "link-inline force-break" href=
    "https://cloud.google.com/natural-language/">https://cloud.google.com/natural-language/</a></p>
    <p id="fn16"><a href="#foot-fn16"><sup>16</sup></a><a class=
    "link-inline force-break" href=
    "https://www.telegraphindia.com/india/dengue-spurt-in-south-182846">https://www.telegraphindia.com/india/dengue-spurt-in-south-182846</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3191623">https://doi.org/10.1145/3184558.3191623</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
