<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>A NeuRetrieval Model for Human-Computer Conversations</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">A NeuRetrieval Model for Human-Computer Conversations</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Rui</span>      <span class="surName">Yan</span>,     Institute of Computer Science and Technology (ICST), Peking University, Beijing 100871, China, <a href="mailto:ruiyan@pku.edu.cn">ruiyan@pku.edu.cn</a>     </div>     <div class="author">     <span class="givenName">Dongyan</span>      <span class="surName">Zhao</span>,     Institute of Computer Science and Technology (ICST), Peking University, Beijing 100871, China, <a href="mailto:zhaody@pku.edu.cn">zhaody@pku.edu.cn</a>     </div>            </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3186341" target="_blank">https://doi.org/10.1145/3184558.3186341</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>To establish an automatic conversation system between human and computer is regarded as one of the most hardcore problems in computer science. It requires interdisciplinary techniques of information retrieval, natural language processing, data management as well as artificial intelligence. The arrival of big data era reveals the feasibility to create a conversation system empowered by data-driven approaches. Now we are able to collect extremely large conversational data on Web, and organize them to launch a human-computer conversation system. Owing to the diversity of Web resources available, a retrieval-based conversation system will be able to find at least some responses from the massive data repository for any user inputs. Given a human issued utterance, i.e., a query, a retrieval-based conversation system will search for appropriate replies, conduct a relevance ranking, and then output the highly relevant one as the response. In this paper, we propose a novel retrieval model named NeuRetrieval for short text understanding, representation and semantic matching. The proposed model is general and unified for both single-turn and multi-turn conversation scenarios in open domain. In the experiments, we investigate the effectiveness of the proposed deep neural network model for human-computer conversations. We demonstrate performance improvement against a series of baseline methods in several evaluation metrics. In contrast with previously proposed methods, NeuRetrieval is tailored for conversation scenarios and demonstrated to be more effective.</small>     </p>    </div>    <div class="CCSconcepts">     <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Retrieval models and ranking;</strong> <strong>Learning to rank;</strong> <em>Web applications;</em></small> </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Conversation system; neural networks; retrieval model</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Rui Yan and Dongyan Zhao. 2018. A NeuRetrieval Model for Human-Computer Conversations. In <em>Proceedings of The 2018 Web Conference Companion (WWW'18 Companion)</em>. ACM, New York, NY, USA, 8 pages. <a href="https://doi.org/10.1145/3184558.3186341" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3186341</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-3">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>To have an intelligent virtual assistant and/or chat companion through a conversation system using natural languages has always been a long cherished goal for researchers and practitioners. A significant amount of efforts have been devoted to this area for decades, and promising achievements have been gradually achieved so that we can expect real conversation applications in real life, rather than in Sci-Fi movies or research labs only. The demand for conversation systems leads to cutting-edge technology in the spotlight from both academia and industry. Creating a smart human-computer conversation system is no longer a fantasy.</p>    <p>It is believed to be challenging for computers to maintain a relevant, meaningful and continuous conversation with humans. To have conversations with humans generally involves interdisciplinary techniques such as information retrieval, natural language processing, data management, as well as artificial intelligence. The arrival of big data era also accelerates the development of human-computer conversation studies. Owing to tons of public resources for conversations available on the Web, we shall learn what to respond given (almost) any inputs by retrieving materials from a conversational data repository. It is time to build data-driven conversation systems between human and computer.</p>    <p>Building conversation systems, in fact, has attracted many attentions over the past decades. In early years, researchers have investigated into task-oriented conversation systems [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0044">44</a>], which are basically for vertical domains. The conversational inputs are restricted and predictable; hence it would be easier&#x2014;compared with open-domain systems&#x2014;to design the logic, create the rules, prepare the data and construct the candidate reply to handle the particular task [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>]. For instance, in a conversation system for flight booking or bus route inquiring, the computer side only needs to capture the origin, destination and flight/bus information, and then respond accordingly with templates [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0044">44</a>]. One of the most obvious limitations of task-specific service is that the conversation cannot exceed the system topic scope. Illegible inputs will not be accepted, which is regarded as a hard constraint. The underlying system design philosophy is nearly impossible to generalize to the open domain.</p>    <p>It is only recently that researchers focus on non-task-oriented (i.e., open-domain) conversation systems for their functional, social, and entertainment roles in real-world applications [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>]. Creating an open-domain conversation system to interact with humans is an interesting but notoriously challenging problem. Since people are free to say anything to the system, it is impossible to prepare the interaction logic and domain knowledge, which can be, in contrast, specified in task-specific systems before hand. Besides, the number of possible combinations of conversation status are literally infinite, so that conventional hand-crafted rules and templates would fail [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>].</p>    <p>Along with the maturity of Web 2.0, there has been an explosion in the number of people having public conversations on websites such as Bulletin Board System (BBS) forums, social media (e.g., Facebook, Twitter) and community question answering (cQA) platforms (e.g., Baidu Zhidao, Yahoo!&#x00A0;Answers). These resources provide a unique opportunity to build collections of naturally occurring conversations that are orders of magnitude larger than those previously available. They also propel the development of retrieval-based techniques in the field of open-domain conversation research. The merit is that, owing to the diversity on the Web, the system will be able to retrieve at least some responses for any user input.</p>    <p>The big data era, however, seems like a double-edged sword. On one side, it brings the great opportunity, as mentioned above, to build practical human-computer conversation systems in open domain. On the other side, there are also challenges. Given a user-issued query, we need to find appropriate candidate replies from a very large volume of data. In this paper, we propose a new retrieval model based on deep neural network structures, namely &#x201C;NeuRetrieval&#x201D;. The intuition is mani-fold. Firstly, neural networks are demonstrated to be effective to represent short texts. For short text conversations, abstractive representation by neural networks could be a natural solution for retrieval tasks. Secondly, there are two typical scenarios for human-computer conversation: single-turn and multi-turn. For multi-turn conversations, there is always additional information to be used such as &#x201C;contexts&#x201D; (a.k.a. previous utterance sentences in a continuous conversation session). The proposed method should be general for both single-turn and multi-turn conversation scenarios, while capture and integrate as much information as possible. It is less feasible and less practical to apply keyword-based search for an entire conversation session with multiple utterances. In this case, neural networks are more powerful to characterize a condensed representation especially for multi-turns. We use neural networks to formulate the NeuRetrieval model to represent, to match and hence to retrieve replies accordingly. The proposed model is tailored for human-computer conversation. A deep neural network (DNN)-based retrieval model tells how likely each reply is appropriate to respond the query given the context (if any). We retrieve highly relevant replies.</p>    <p>We conduct extensive experiments for conversation setups between humans and computers. In particular, we build the system upon an extremely large conversation resource, i.e., almost 10 million pairs of atomic human conversations. We then run experiments against several other rival algorithms to verify the effectiveness of the neural retrieval model. Our system (generally) outperforms traditional and recent baselines regarding a variety of different evaluation metrics in terms of p@1, MAP, nDCG and MRR. The result indicates that our conversation system provides a novel and useful insight to facilitate human-computer conversations.</p>    <p>To sum up, our contributions are novel in following ways:</p>    <p>We propose a new retrieval model named &#x201C;NeuRetrieval&#x201D; for the human-computer conversation system. The NeuRetrieval model is demonstrated to be effective to represent, to match, and hence to retrieve short texts for conversations with deep neural networks.</p>    <p>There are two typical scenarios for human-computer conversations: 1) single-turn and 2) multi-turn. The proposed model is general and well unified to adapt for both scenarios. Different structures in conversation sessions are also investigated in this study.</p>    <p>The rest of the paper is organized as follows. We start by reviewing related work. In Sections 3 and 4, we describe the framework of conversation system and task formulation. We introduce the detailed mechanisms of the NeuRetrieval model in single-turn and multi-turn conversations. We devise experimental setups and evaluations against a variety of baselines and discuss results in Section 5. Finally we draw conclusions in Section&#x00A0;6.</p>   </section>   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>     </div>    </header>    <section id="sec-5">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Conversation Systems</h3>     </div>     </header>     <p>Early work on conversation systems is generally based on rules or templates and is designed for specific domains [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0024">24</a>]. These rule-based approaches require no data or few data for training, while instead require many manual efforts to build the model, or to handcraft rules, which is usually very costly. The conversation structure and status tracking in vertical domains are more feasible to learn and to infer [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0044">44</a>]. However, the coverage of such systems are also far from satisfaction. Later, people begin to pay more attention to automatic conversation systems in open domains [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0021">21</a>].</p>     <p>From specific domains to the open domain, the need for a big amount of data is increasing substantially to build a conversation system. As information retrieval techniques are developing fast, researchers obtain promising achievements in (deep) question and answering systems. In this way, an alternative approach is to build a conversation system with a knowledge base consisting of a number of question-answer pairs. Leuski <em>et al.</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>] build systems to select the most suitable response to the current message from the question-answer pairs using a statistical language model in cross-lingual information retrieval, but have a major bottleneck of the creation of the knowledge base (i.e., question-answer pairs) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0019">19</a>]. Researchers propose to augment the knowledge base with question-answer pairs derived from plain texts [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>]. The number of resource pairs can be, to some extent, expanded, but are still relatively small.</p>     <p>Nowadays, with the prosperity of social media and other Web 2.0 resources, such as community question and answering (cQA) or microblogging services, a very large amount of conversation data become available [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0016">16</a>]. A series of information retrieval-based methods are applied to short text conversation using microblog data [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0036">36</a>]. Higashinaka <em>et al.</em> also combine template generation with the search-based methods [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0018">18</a>]. Ritter <em>et al.</em> have investigated the feasibility of conducting short text conversation by using statistical machine translation (SMT) techniques, as well as millions of naturally occurring conversation data in Twitter [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0012">12</a>]. In the approach, a response is generated from a model, not retrieved from a repository, and thus it cannot be guaranteed to be a legitimate natural language text.</p>     <p>In previous studies of conversation systems, few approaches take into account the structure information in the conversation stream, especially in multi-turn conversations. Now we provide a general and unified solution based on the deep neural network architecture tackling both single-turn and multi-turn conversations. Besides, structure information in the conversation flow is also incorporated. The approach shows a novel insight in conversation systems.</p>    </section>    <section id="sec-6">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Deep Neural Networks</h3>     </div>     </header>     <p>In recent years, deep neural networks (DNNs, also known as <em>deep learning</em>) have made significant improvement in Natural Language Processing. DNNs are highly automated learning machines; they can extract underlying abstract features of data automatically by exploring multiple layers of non-linear transformation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>].</p>     <p>In NLP models, a word typically acts as an atomic unit. However, words are discrete by nature; it seems nonsensical to feed word indexes to DNNs. A typical approach is to map a discrete word to a dense, low-dimensional, real-valued vector, called an <em>embedding</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>]. Each dimension in the vector captures some aspect of underlying word meanings.</p>     <p>Prevailing DNNs for sentence-level modeling include convolutional neural networks (CNNs) and recurrent neural networks (RNNs). In CNNs, we have a fixed-size sliding window to capture local patterns of successive words [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>], whereas RNNs keep one or a few hidden states, and collect information along the word sequence in an iterative fashion [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0035">35</a>]. The multi-layer RNN structure has been investigated for document-paragraph modeling [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>]. Socher <em>et al.</em> leverage sentence parse trees and build recursive networks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0030">30</a>]. However, conversational utterances are usually casual, and hence recursive models are less applicable.</p>     <p>Beyond a single sentence, some studies are aimed to capture the relationship between two sentences&#x2014;known as sentence pair modeling&#x2014;with applications like paraphrase detection [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>], discourse unit recognition [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0043">43</a>], textual entailment recognition [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>], etc. A sentence-pair DNN model is typically built upon underlying sentence-level models (CNNs/RNNs). Then two sentences&#x2019; information is combined by matching heuristics like concatenation, cosine measure, or inner-product [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>]. Hu <em>et al.</em> develop word-by-word matching approaches [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>], and obtain a similarity matrix between two sentences. Recently, Rockt&#x00E4;schel <em>et al.</em> propose context-aware matching approaches [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>], where the first sentence&#x0027;s information is available when modeling the second one. Such context-awareness interweaves individual sentence modeling and sentence matching, prohibiting pre-calculating the vector representation of a sentence; hence these methods are considerably more computational intensive. For efficiency consideration, we choose to leverage vector concatenation, which is simple yet effective.</p>     <p>We revisit recent context-aware method from both retrieval-based systems or generative conversation systems. They are all based on sentence sequences with orders [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0038">38</a>] or without orders [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>]. Contextual utterances are modeled with hierarchies on word- and sentence-levels [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0034">34</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>] or without hierarchies at all [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0038">38</a>]. The proposed NeuRetrieval model is more than traditional matching and ranking. The conversation is streamed as utterance stream flows, and there are contextual information needs to be incorporated in a multi-turn conversation scenario. The proposed deep retrieval model utilizes context information tailored for human-computer conversation, and we make thorough comparisons in the experimental evaluations.</p>    </section>   </section>   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Methodology</h2>     </div>    </header>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Problem Formulation</h3>     </div>     </header>     <p>The research problem of automatic human-computer conversation is defined as one or more turns of interactions between human and computer. Within each turn of the conversation, given the message issued from the human, the computer would provide a reply in response to the coming message. To this end, given the user message as a query <em>q</em>, our system searches for similar postings <em>p</em> from the vast repository of conversational data. The associated replies <em>r</em> of the obtained postings <em>p</em> within a &#x27E8;<em>posting</em>-<em>reply</em>&#x27E9; pair is fed into the representation and matching part. Finally, the best matched reply <em>r</em> will be returned as an appropriate response to output. As we propose to suit both scenarios of single-turn and multi-turn conversations, we manage to use the context of previous utterances <span class="inline-equation"><span class="tex">$\mathcal {C}$</span>     </span>={<em>s</em>     <sub>1</sub>, <em>s</em>     <sub>2</sub>, &#x2026;} in the conversation session as well.</p>     <p>We would firstly introduce query representation, which is actually an encoder, using query with or without context information. After we encode the query as a representation vector, we also learn to encode the candidate replies. Next we match the query and reply through the deep neural networks.</p>    </section>    <section id="sec-9">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Query Representation</h3>     </div>     </header>     <p>In recent years, deep neural networks (DNNs, also known as <em>deep learning</em>) have made significant improvement. With big data available, DNNs are highly automated learning machines; they can extract underlying abstract features of data automatically by exploring multiple layers of non-linear transformation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>]. We first give a quick overview of word embedding and the neural network structure in Long-Short Term Memory (LSTM).</p>     <p>     <strong>Word Embeddings.</strong> Traditional models usually treat a word as a discrete token; thus, the internal relation between similar words would be lost. Word embedding [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>] is a standard apparatus in neural network-based text processing. A word is mapped to a low dimensional, real-valued vector. This process, known as vectorization, captures some underlying meanings. Given enough data, usage, and context, word embeddings can make highly accurate guesses about the meaning of a particular word. Embeddings can equivalently be viewed that a word is first represented as a one-hot vector and multiplied by a look-up table [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>].</p>     <p>In our model, we first vectorize all words using their embeddings, which serve as the foundation of our deep neural networks. Word embeddings are initialized randomly, and then tuned during training as part of model parameters.</p>     <p>     <strong>Bi-Directional LSTM.</strong> We use a bi-directional long short term memory (Bi-LSTM) recurrent network to propagate information along the word sequence. A recurrent neural network (RNN) keeps a hidden state vector, which changes according to the input in each time step. As RNNs can iteratively aggregate information along a sequence, they are naturally suitable for sentence modeling.     </p>     <p>LSTM is an advanced type of RNN by using memory cells and gates to learn long term dependencies within a sequence [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0033">33</a>]. LSTM models are defined as follows: given a sequence of inputs, an LSTM associates each position with <em>input</em>, <em>forget</em>, and <em>output gates</em>, denoted as <em>i<sub>t</sub>     </em>, <em>f<sub>t</sub>     </em>, and <em>o<sub>t</sub>     </em> respectively. The vector <em>l<sub>t</sub>     </em> is used to additively modify the memory contents. Given an input sentence <em>s</em>&#x00A0;= {<em>x</em>     <sub>0</sub>, <em>x</em>     <sub>1</sub>, &#x2026;, <em>x<sub>T</sub>     </em>}, where <em>x<sub>t</sub>     </em> is a sequence of inputs while <em>e<sub>t</sub>     </em> denotes the vector for embedding of individual unit (i.e., word or sentence) at position <em>t</em> in the sentence. LSTM outputs a representation <em>h<sub>t</sub>     </em> for position <em>t</em> by combining <em>h</em>     <sub>      <em>t</em> &#x2212; 1</sub> and <em>e<sub>t</sub>     </em>, given by <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \begin{aligned} \left[\begin{array}{c}i_t\\f_t\\o_t\\l_t \end{array} \right]&#x0026;= \left[\begin{array}{c}\sigma \\\sigma \\\sigma \\\text{tanh} \end{array} \right]W \cdot \left[\begin{array}{c}h_{t-1}\\e_{t} \end{array} \right] \\\tilde{h}_t &#x0026;= f_t \cdot \tilde{h}_{t-1} + i_t \cdot l_t \\h^{s}_{t} &#x0026;= o_t \cdot \tilde{h}_t \end{aligned} \end{equation} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$\tilde{h}$</span>     </span> is an auxiliary variable and can be viewed as the information stored in memory cell. <span class="inline-equation"><span class="tex">$\sigma (\cdot)=\frac{1}{1+e^{-\cdot }}$</span>     </span> is a known as a sigmoid/logistic function.</p>     <p>A single directional LSTM typically propagates information from the first word to the last; hence the hidden state at a certain step is dependent on its previous words only and is thus blind of future words. The variant Bi-LSTM [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>] is proposed to utilize both previous and future words by two separate RNNs, propagating forward and backward, and generating two independent hidden state vectors <span class="inline-equation"><span class="tex">$\overrightarrow{h_t}$</span>     </span> and <span class="inline-equation"><span class="tex">$\overleftarrow{h_t}$</span>     </span>, respectively. The two state vectors are concatenated to represent the meaning of the <em>t</em>-th word in the sentence, i.e., <span class="inline-equation"><span class="tex">$h_t=\left[\overrightarrow{h_t}; \overleftarrow{h_t}\right]$</span>     </span>.</p>     <section id="sec-10">     <p><em>3.2.1 Single-Turn Query Encoder.</em> Here we denote a query as a sequence of tokens, i.e., words. Each word is associated with its <em>d</em>-dimensional embedding. We need to represent the query as a <em>d</em>-dimensional representation. An encoder is a neural model where output units are directly connected with or identical to input units. Typically, inputs are compressed into a representation using neural models (encoding). For a single-turn query encoder, the input is the query only.</p>     <p>For simplicity, we define Bi-LSTM(<em>h</em>      <sub>       <em>t</em> &#x2212; 1</sub>, <em>e<sub>t</sub>      </em>) to be the Bi-LSTM operation on vectors <em>h</em>      <sub>       <em>t</em> &#x2212; 1</sub> and <em>e<sub>t</sub>      </em> to achieve <em>h<sub>t</sub>      </em>.</p>     <p>For the single-turn representation, the query is treated as one sequence of tokens. Following Sutskever <em>et al.</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0033">33</a>], we trained an encoder that first maps input documents into vector representations from a Bi-LSTM encoder. No context information will be considered (Model 1, Figure <a class="fig" href="#fig1">1</a>).</p> <figure id="fig1">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186341/images/www18companion-103-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 1:</span>       <span class="figure-title">Different models with and without context information. For Model 1 and Model 2, we have word-level representations while for Model 3, we have both word-level and sentence-level representations.</span>      </div>     </figure>     </section>     <section id="sec-11">     <p><em>3.2.2 Multi-Turn Query Encoder.</em> We now take the context information into account in order to formulate an enriched representation of queries with contexts, a.k.a., multi-turn representations. An intuitive solution is a simple extension of the single-turn representation: we incorporate multi-utterance information (i.e., different sentences). Note that each sentence ends up with a special end-of-sentence symbol &#x27E8;<em>eos</em>&#x27E9;. For clarification, we use notations as:</p>     <p>&#x2022; <span class="inline-equation"><span class="tex">$h^w_t$</span>      </span> and <span class="inline-equation"><span class="tex">$h^s_t$</span>      </span> denote hidden vectors from Bi-LSTM models, the subscripts of which indicate time step <em>t</em>, the superscripts of which indicate operations at word level (<em>w</em>) or utterance sentence level (<em>s</em>). <span class="inline-equation"><span class="tex">$h^s_t$</span>      </span> (enc) specifies encoding stage.</p>     <p>&#x2022; <span class="inline-equation"><span class="tex">$e^w_t$</span>      </span> and <span class="inline-equation"><span class="tex">$e^s_t$</span>      </span> denotes word-level and sentence-level embedding for word and sentence at position <em>t</em> in terms of its residing sentence or session context.</p>     <p>The simple extension of multi-turn representation treats all the input as a long sequence of tokens: all the utterances as well as the query is concatenated from head to tail. Hence we can also train an encoder using the Bi-LSTM operation. Here sentence structures are utilized as a plain model, as shown in Model 2, Figure <a class="fig" href="#fig1">1</a>. The calculation is defined as: <div class="table-responsive" id="Xeq2">       <div class="display-equation">        <span class="tex mytex">\begin{equation} h^s_t(enc) = \text{Bi-LSTM}^{sentence}_{encode}(e^{w}_t, h^w_{t-1}(enc)) \end{equation} </span>        <br/>        <span class="equation-number">(2)</span>       </div>      </div>     </p>     <p>We notice that words creates a joint meaning of a sentence, the juxtaposition of sentences also creates a joint meaning of a conversation session. Such an observation indicates a hierarchical structure between words and sentences. We hence propose a hierarchical multi-turn representation for queries and the associated context information. We first obtain representation vectors at the sentence level by putting one layer of LSTM (i.e., LSTM<span class="inline-equation"><span class="tex">$^{word}_{encode}$</span>      </span>) on top: <div class="table-responsive" id="Xeq3">       <div class="display-equation">        <span class="tex mytex">\begin{equation} h^w_t(enc) = \text{Bi-LSTM}^{word}_{encode}(e^w_t,h^w_{t-1}(enc)) \end{equation} </span>        <br/>        <span class="equation-number">(3)</span>       </div>      </div>     </p>     <p>The vector output at the ending time-step is used to represent the entire utterance sentence. To build representation for the current conversation session with multiple turns, another layer of LSTM (denoted as LSTM<span class="inline-equation"><span class="tex">$^{sentence}_{encode}$</span>      </span>) is placed on top of all sentences, computing representations sequentially: <div class="table-responsive" id="Xeq4">       <div class="display-equation">        <span class="tex mytex">\begin{equation} h^s_t(enc)=\text{Bi-LSTM}^{sentence}_{encode}(e^s_t,h^s_{t-1}(enc)) \end{equation} </span>        <br/>        <span class="equation-number">(4)</span>       </div>      </div>     </p>     <p>Thus one Bi-LSTM operates at the word level, leading to the acquisition of sentence-level representations that are then used as inputs into the second Bi-LSTM that acquires higher-level representations in a hierarchical structure (shown in Model 3, Figure <a class="fig" href="#fig1">1</a>).</p>     </section>    </section>    <section id="sec-12">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> Matching</h3>     </div>     </header>     <p>As mentioned, we need to compare the candidate replies with the query (and the context). The scoring function outputs a scalar in <span class="inline-equation"><span class="tex">$\mathbb {R}$</span>     </span> (appropriateness or inappropriateness) for a particular candidate, given either the query itself or with contexts. The matching scores are computed by the deep neural network architecture.</p>     <p>Our sentence models based on Bi-LSTM learn to encode the replies and queries (with or without contexts) as vectors, which can then be used to compute their similarity. These are then used to compute a <em>query-reply</em> similarity score, which together with the query and reply vectors are joined in a single representation.</p>     <p>On the basis of sentence representations using Bi-LSTM, we can model the interactions between queries and replies. Given the output of sentences for processing queries and replies, their resulting vector representations <tt>x</tt>     <sub>      <em>q</em>     </sub> and <tt>x</tt>     <sub>      <em>r</em>     </sub>, can be used to compute a <em>query-reply</em> similarity score. We follow the approach of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>] that defines the similarity between <tt>x</tt>     <sub>      <em>q</em>     </sub> and <tt>x</tt>     <sub>      <em>r</em>     </sub> vectors as follows: <div class="table-responsive" id="Xeq5">      <div class="display-equation">       <span class="tex mytex">\begin{equation} sim(\texttt {x}_q,\texttt {x}_r) = \texttt {x}_q^{T}M \texttt {x}_r \end{equation} </span>       <br/>       <span class="equation-number">(5)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$M \in \mathbb {R}^{d \times d}$</span>     </span> is a similarity matrix. Here, we seek a transformation of the candidate posting <span class="inline-equation"><span class="tex">$\texttt {x}^{\prime }_r$</span>     </span> = <span class="inline-equation"><span class="tex">$M\texttt {x}_r$</span>     </span> that is the closest to the input query <span class="inline-equation"><span class="tex">$\texttt {x}_q$</span>     </span>. The similarity matrix <em>M</em> is a parameter of the network and is optimized during training.</p>     <p>After the match using the similarity matrix <em>M</em>, Equation (5) produces a single score <em>x<sub>sim</sub>     </em> capturing various aspects of similarity (syntactic and semantic) between the input information. The joint layer concatenates all intermediate vectors as well as the similarity score into a single vector: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \texttt {x}_{join} = [\texttt {x}^{T}_q;\texttt {x}_{sim};\texttt {x}^{T}_{r}]\end{equation} </span>       <br/>      </div>     </div>     </p>     <p>Then the concatenated vectors are fed to an ensuing network for further information mixing. Vector concatenation for sentence matching is also applied in other studies like [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0043">43</a>], which is effective yet of low complexity order, compared with other word-by-word matching [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>].</p>     <p>The joint vector is then passed through a 3-layer, fully-connected, feed-forward neural network, also known as <em>multi-layer perceptron</em> (MLP) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>], which allows rich interactions between a vector pair. The network enables to extract features automatically, starting from lower-level representations to higher-level ones. Finally, a single neuron outputs the score between a query (or the context) and a reply. The final scoring neuron is essentially a linear regression.</p>     <p>Ranking problems can apply pairwise ranking loss such as hinge loss or cross-entropy loss. Here we apply hinge loss to train our DNN network. Given a triple score(<em>q</em>, <em>r</em>     <sup>+</sup>) in the training set, we randomly sample a negative instance <em>r</em>     <sup>&#x2212;</sup>. The objective is to maximize the scores of positive samples while minimizing that of the negative samples. Concretely, we would like score(<em>q</em>, <em>r</em>     <sup>+</sup>) to be as least score(<em>q</em>, <em>r</em>     <sup>&#x2212;</sup>) plus a margin <em>&#x0394;</em>. The training objective is to <div class="table-responsive" id="Xeq6">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathop{min}_{\Omega }\ \sum _{q,r^+}\max \left\lbrace 0, \Delta +\mathcal {F}(q,r^+)-\mathcal {F}(q,r^-)\right\rbrace +\lambda \Vert \Omega \Vert _2^2 \end{equation} </span>       <br/>       <span class="equation-number">(6)</span>      </div>     </div>     </p>     <p>Neural networks have a large capacity to learn complex decision functions they tend to easily over-fit. To mitigate the over-fitting issue we augment the cost function with an &#x2113;<sub>2</sub> penalty with coefficient <em>&#x03BB;</em> for all the parameters <em>&#x03A9;</em> which are weight and bias values optimized by the network.</p>    </section>   </section>   <section id="sec-13">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Experiments and Evaluation</h2>     </div>    </header>    <p>In this section, we evaluate our proposed model for the conversation task against a series of baselines given a huge conversation resource. The objectives of our experiments are 1) to evaluate the effectiveness of our proposed NeuRetrieval model compared a series of baselines, and 2) to evaluate contextual information usage for query representation.</p>    <section id="sec-14">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Dataset</h3>     </div>     </header>     <p>We use the data which contain a large number of human conversations crawled from open Web, where the users publish a posting visible to the public, and then receive a bunch of subsequent replies to their utterances. We conducted data filtering and cleaning procedures by removing extremely short utterances and those of low linguistic quality as indicated in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0040">40</a>]. In total, we have 9,023,854 virtual documents of (<em>posting</em>, <em>reply</em>) pairs extracted [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>].</p>     <p>In the retrieval repository, a subsequent <em>reply</em> has a responding relationship to the antecedent <em>posting</em>, and each pair can be regarded as an atomic conversation of two utterances. The data repository is demonstrated to be a rich resource to facilitate human-computer conversations based on retrieval [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>].</p>    </section>    <section id="sec-15">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Experimental Setups</h3>     </div>     </header>     <section id="sec-16">     <p><em>4.2.1 Evaluation Metrics.</em> Since we have labeled replies for test queries from the data [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0037">37</a>], given the ranking lists, we evaluated the performance in terms of the following metrics: precision@1 (p@1), mean average precision (MAP) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0021">21</a>], and the normalized discounted cumulative gain (nDCG) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0013">13</a>]. Since the system outputs the best selected reply, p@1 is the precision at the 1st position, and should be the most natural way to indicate the fraction of suitable responses among the top-1 reply retrieved. Besides, we provided a top-<em>k</em> ranking list for the test queries using nDCG and MAP, which test the potential for a system to provide more than one appropriate response as candidates. We aimed at selecting as many appropriate responses as possible into the top-<em>k</em> list and rewarding methods that return suitable replies.</p>     <p>Unlike MAP and nDCG, which examine the ranks of appropriate candidates, Mean Reciprocal Rank (MRR) focuses on evaluating the capability of retrieval systems to find (perhaps) the best result which means the positive triples created by humans in our dataset. MRR is useful but does not test the full capability because there can be multiple appropriate utterances to continue a conversation.</p>     </section>     <section id="sec-17">     <header>      <div class="title-info">       <h4>        <span class="section-number">4.2.2</span> Algorithms for Comparison</h4>      </div>     </header>     <p>To illustrate the performance of our approach, we include several alternative algorithms as baselines for comparison. The baselines can be divided into two categories, i.e., 1) generation-based methods and 2) retrieval-based methods for conversation systems from very recent studies. Since our proposed approach is technically a retrieval-based method, we mainly focus on the second category. For fairness we conducted the same pre-processing procedures and data cleaning for all algorithms.</p>     <p>      <strong>Generation-based Conversation.</strong> For this group of algorithms, the conversation system will generate a response from a given input, i.e., a query from the user under the conversational scenario.</p>     <p>&#x2022; <em>Statistical Machine Translation (SMT)</em>: SMT is a machine translation paradigm which &#x201C;translates&#x201D; a query into a &#x201C;reply&#x201D;. We implemented the phrase-based translation for the conversation modeling in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0012">12</a>].</p>     <p>&#x2022; <em>LSTM-RNN</em>: LSTM-RNN is basically a Recurrent Neural Network (RNN) using the Long Short Term Memory (LSTM) architecture. The RNN with LSTM units consists of memory cells in order to store information for extended periods of time. We use LSTM-RNN for both generation and retrieval baselines. For generation, we first use an LSTM-RNN to encode the input sequence (query) to a vector space, and then use another LSTM-RNN to decode the vector into the output sequence (reply) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0033">33</a>]; for retrievals, we adopt the LSTM-RNN to construct sentence representations and use cosine similarity to output the matching score [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0025">25</a>].</p>     <p>&#x2022; <em>Neural Responding Machine.</em> We implement the neural responding machine (NRM) proposed in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0029">29</a>], which is an RNN-based generation approach.</p>     <p>      <strong>Retrieval-based Conversation.</strong> The approaches within this group of baselines are based on retrieval systems, which return the best matched candidate reply out of the conversational repository given a particular query.</p>     <p>&#x2022; <em>Okapi BM25.</em> We include the standard retrieval technique to rank candidate replies. For each query, we find the most relevant reply using BM25 model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0017">17</a>] from the corpus.</p>     <p>&#x2022; <em>DeepMatch.</em> The DeepMatch method considers multiple granularity from the perspective of topics via LDA [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0010">10</a>].</p>     <p>&#x2022; <em>ARC-CNN.</em> This approach is a CNN based method with convolutionary layers which construct sentence representations and produce the matching scores via a MLP layer [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0011">11</a>].</p>     <p>&#x2022; <em>Rank Optimized Conversation Framework (ROCF)</em>. The ROCF uses context information [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0038">38</a>], which aims at retrieving more appropriate replies based on contexts from previous turns. It is a combination of context-insensitive ranking and context-aware ranking.</p>     <p>&#x2022; <em>Deep Learning-to-Respond (DL2R)</em>. The DL2R uses a query reformulation framework [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0037">37</a>]. The query reformulation is based on different context utilization strategies.</p>     <p>&#x2022; <em>NeuRetrieval</em>. We propose the NeuRetrieval system for short-text conversation between human and computer. We have some novel insights by investigating 1) the sequential modeling of contextual information for query representation in multi-turn conversations, 2) a plain/hierarchial structure for utterance fusion, and 3) a deep learning framework for semantic matching given the learned representations.</p>     </section>    </section>    <section id="sec-18">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Overall Performance</h3>     </div>     </header>     <p>We compare the performance of all methods including baselines and our proposed NeuRetrieval model measured in terms of MAP and nDCG, shown in Table <a class="tbl" href="#tab1">1</a>.</p>     <div class="table-responsive" id="tab1">      <div class="table-caption">       <span class="table-number">Table 1:</span>       <span class="table-title">Retrieval performance against baselines. For generative methods, they generate one response given each query. Hence the p@1 in fact refers to accuracy. Other metrics are not applicable. Note that there are variants for the <em>NeuRetrieval</em> method, denoting single-turn representation, multi-turn representation with plain structure or with hierarchical structure (i.e., Model 1, Model 2 and Model 3).</span>      </div>      <table class="table">       <thead>        <tr>        <th style="text-align:center;">         G<Small>ENERATIVE METHODS</Small>        </th>        <th style="text-align:center;">p@1</th>        <th style="text-align:center;">MAP</th>        <th style="text-align:center;">nDCG@5</th>        <th style="text-align:center;">nDCG@10</th>        <th style="text-align:center;">nDCG@20</th>        <th style="text-align:center;">MRR</th>        </tr>        </thead> 						<tbody> 						<tr>        <td style="text-align:center;">SMT [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"          href="#BibPLXBIB0012">12</a>]</td>        <td style="text-align:center;">0.363</td>        <td colspan="5" rowspan="3" style="text-align:center;background-color:#999999;"/>        </tr>        <tr>        <td style="text-align:center;">LSTM-RNN [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"          href="#BibPLXBIB0033">33</a>]</td>        <td style="text-align:center;">0.441</td>        </tr>        <tr>        <td style="text-align:center;">NRM [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"          href="#BibPLXBIB0029">29</a>]</td>        <td style="text-align:center;">0.465</td>        </tr>        <tr>        <td style="text-align:center;">         <Small>C<Small>ONTEXT</Small>-I<Small>NSENSITIVE</Small> R<Small>ETRIEVAL</Small>        </td>        <td style="text-align:center;">p@1</td>        <td style="text-align:center;">MAP</td>        <td style="text-align:center;">nDCG@5</td>        <td style="text-align:center;">nDCG@10</td>        <td style="text-align:center;">nDCG@20</td>        <td style="text-align:center;">MRR</td>        </tr>        <tr>        <td style="text-align:center;">Okapi BM25</td>        <td style="text-align:center;">0.272</td>        <td style="text-align:center;">0.253</td>        <td style="text-align:center;">0.337</td>        <td style="text-align:center;">0.302</td>        <td style="text-align:center;">0.368</td>        <td style="text-align:center;">0.169</td>        </tr>        <tr>        <td style="text-align:center;">DeepMatch [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"          href="#BibPLXBIB0010">10</a>]</td>        <td style="text-align:center;">0.457</td>        <td style="text-align:center;">0.317</td>        <td style="text-align:center;">0.419</td>        <td style="text-align:center;">0.454</td>        <td style="text-align:center;">0.508</td>        <td style="text-align:center;">0.275</td>        </tr>        <tr>        <td style="text-align:center;">LSTM-RNN [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"          href="#BibPLXBIB0025">25</a>]</td>        <td style="text-align:center;">0.338</td>        <td style="text-align:center;">0.283</td>        <td style="text-align:center;">0.330</td>        <td style="text-align:center;">0.371</td>        <td style="text-align:center;">0.431</td>        <td style="text-align:center;">0.228</td>        </tr>        <tr>        <td style="text-align:center;">ARC-CNN [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"          href="#BibPLXBIB0011">11</a>]</td>        <td style="text-align:center;">0.394</td>        <td style="text-align:center;">0.294</td>        <td style="text-align:center;">0.397</td>        <td style="text-align:center;">0.421</td>        <td style="text-align:center;">0.477</td>        <td style="text-align:center;">0.232</td>        </tr>        <tr>        <td style="text-align:center;">         <Small>C<Small>ONTEXT</Small>-A<Small>WARE</Small> R<Small>ETRIEVAL</Small>        </td>        <td style="text-align:center;">p@1</td>        <td style="text-align:center;">MAP</td>        <td style="text-align:center;">nDCG@5</td>        <td style="text-align:center;">nDCG@10</td>        <td style="text-align:center;">nDCG@20</td>        <td style="text-align:center;">MRR</td>        </tr>        <tr>        <td style="text-align:center;">ROCF [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"          href="#BibPLXBIB0038">38</a>]</td>        <td style="text-align:center;">0.711</td>        <td style="text-align:center;">0.412</td>        <td style="text-align:center;">0.651</td>        <td style="text-align:center;">0.666</td>        <td style="text-align:center;">0.702</td>        <td style="text-align:center;">0.321</td>        </tr>        <tr>        <td style="text-align:center;">DL2R [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"          href="#BibPLXBIB0037">37</a>]</td>        <td style="text-align:center;">0.731</td>        <td style="text-align:center;">0.416</td>        <td style="text-align:center;">0.663</td>        <td style="text-align:center;">0.682</td>        <td style="text-align:center;">0.717</td>        <td style="text-align:center;">0.333</td>        </tr>        <tr>        <td style="text-align:center;">NeuRetrieval (Model 1)</td>        <td style="text-align:center;">0.435</td>        <td style="text-align:center;">0.320</td>        <td style="text-align:center;">0.404</td>        <td style="text-align:center;">0.456</td>        <td style="text-align:center;">0.498</td>        <td style="text-align:center;">0.265</td>        </tr>        <tr>        <td style="text-align:center;">NeuRetrieval (Model 2)</td>        <td style="text-align:center;">0.721</td>        <td style="text-align:center;">0.411</td>        <td style="text-align:center;">0.660</td>        <td style="text-align:center;">0.657</td>        <td style="text-align:center;">0.708</td>        <td style="text-align:center;">0.331</td>        </tr>        <tr>        <td style="text-align:center;">NeuRetrieval (Model 3)</td>        <td style="text-align:center;">0.735</td>        <td style="text-align:center;">0.418</td>        <td style="text-align:center;">0.669</td>        <td style="text-align:center;">0.683</td>        <td style="text-align:center;">0.715</td>        <td style="text-align:center;">0.338</td>        </tr>       </tbody>      </table>     </div>     <p>For the generative methods, the baselines provide one generation as the response to output. Hence we do not compare MAP or nDCG for this algorithm group. Note that the original response is not likely to be generated; thus it is infeasible to calculate the MRR. In general, the generative algorithms have relatively high p@1 scores, but the generated responses are ambiguous or broad but not specific enough. Such responses might be relevant but not appropriate enough for conversation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>].</p>     <p>We can see great improvement for NeuRetrieval against original retrieval-based baselines. <em>Okapi BM25</em> represents the standard (and simple) retrieval system. The performance for BM25 is not as good as the other deep learning-based retrieval systems. Deep learning systems are proved to have strong capabilities to learn the abstractive representation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0030">30</a>]. BM25 only utilizes the shallow representation of term-level processing. The deep learning algorithm groups in general overwhelm shallow learning algorithms. The observation is similar for both the context insensitive retrieval group and the context-aware retrieval group.</p>     <p>The context-aware methods outperform the standard deep learning baselines. The benefits are believed to be due to the context information, while the other deep learning baselines are matching metrics for single turn conversations only.</p>     <p>We compare the context-aware retrieval methods in details. The proposed NeuRetrieval model shows a better performance against context-aware baselines. The difference is that we change to a new context modeling method: we use a sequential modeling rather than a simple integration or a combination of all possible utterances. The structure of conversation session is also incorporated in the NeuRetrieval model. Sequential and hierarchical modeling for conversation streams might result in the improvement.</p>     <p>We have different ways to use contextual information via contextual query representation as shown in Figure <a class="fig" href="#fig1">1</a>. <em>Model 1</em> actually degenerates to a single-turn conversation scenario. No context information is integrated. There are two different ways to incorporate context information, either <em>Model 2</em>, which does not distinguish word-level and sentence-level information, or <em>Model 3</em>, which models the word-level and sentence-level information in two hierarchies.</p>     <p>We can see that the improvement between <em>Model 1</em> and <em>Model&#x00A0;2</em> or <em>Model 3</em> is rather obvious, indicating that context information is quite beneficial to retrieve better candidates especially under the conversational scenarios. The results show that <em>Model 3</em> outperforms <em>Model 2</em>. The results indicate a proper way to characterize context information is important. The hybrid modeling of word and sentence information in different hierarchies is demonstrated to be better.</p>    </section>   </section>   <section id="sec-19">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Conclusions</h2>     </div>    </header>    <p>In this paper, we propose to establish a new retrieval method for search-based human-computer conversation system. Given a human-issued utterance as the query, our proposed system will return the corresponding responses based on a <em>NeuRetrieval</em> model using deep neural networks. There are three major contributions in this work: 1) we propose a contextual query encoder with sequential information captured for the conversation task; 2) we investigated different context representation strategies, with or without hierarchical structures; 3) we establish the deep neural network architecture featured with above strategies and components.</p>    <p>We examine the effect of our proposed NeuRetrieval model with several baselines using a series of evaluation metrics. Our method (generally) outperforms strong baselines. In general, context information is demonstrated to be useful for conversations, especially for multi-turn conversations. Hierarchical modeling for the context and the query is also helpful. In the future, we will investigate more features for further improvements in performance.</p>   </section>  </section>  <section class="back-matter">   <section id="sec-20">    <header>     <div class="title-info">     <h2>ACKNOWLEDGMENTS</h2>     </div>    </header>    <p>We thank the reviewers for their insightful comments. This work was supported by the National Key Research and Development Program of China (No. 2017YFC0804001), the National Science Foundation of China (No. 61672058). Rui Yan was sponsored by CCF-Tencent Open Research Fund and Microsoft Collaborative Research Program.</p>   </section>   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Pear Analytics. 2009. Twitter Study&#x2013;August 2009. 15 (2009).</li>     <li id="BibPLXBIB0002" label="[2]">Yoshua Bengio. 2009. Learning deep architectures for AI. <em>      <em>Foundations and Trends in Machine Learning</em>     </em>2, 1 (2009), 1&#x2013;127.</li>     <li id="BibPLXBIB0003" label="[3]">L&#x00E9;on Bottou. 1998. Online learning and stochastic approximations. <em>      <em>On-line learning in neural networks</em>     </em>17 (1998), 9.</li>     <li id="BibPLXBIB0004" label="[4]">Miguel&#x00A0;A Carreira-Perpinan and Geoffrey&#x00A0;E Hinton. 2005. On contrastive divergence learning. In <em>      <em>Artificial Intelligence and Statistics</em>     </em>, Vol.&#x00A0;2005. 17.</li>     <li id="BibPLXBIB0005" label="[5]">George Casella and Edward&#x00A0;I George. 1992. Explaining the Gibbs sampler. <em>      <em>The American Statistician</em>     </em>46 (1992), 167&#x2013;174.</li>     <li id="BibPLXBIB0006" label="[6]">Kailong Chen, Tianqi Chen, Guoqing Zheng, Ou Jin, Enpeng Yao, and Yong Yu. 2012. Collaborative Personalized Tweet Recommendation. In <em>      <em>SIGIR &#x2019;12</em>     </em>. 661&#x2013;670.</li>     <li id="BibPLXBIB0007" label="[7]">Gao Cong, Long Wang, Chin-Yew Lin, Young-In Song, and Yueheng Sun. 2008. Finding Question-answer Pairs from Online Forums. In <em>      <em>SIGIR&#x2019;08</em>     </em>. 467&#x2013;474.</li>     <li id="BibPLXBIB0008" label="[8]">Alan Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speech recognition with deep recurrent neural networks. In <em>      <em>Proc. Acoustics, Speech and Signal Processing</em>     </em>. 6645&#x2013;6649.</li>     <li id="BibPLXBIB0009" label="[9]">Hua He, Kevin Gimpel, and Jimmy Lin. 2015. Multi-perspective sentence similarity modeling with convolutional neural networks. In <em>      <em>EMNLP</em>     </em>. 1576&#x2013;1586.</li>     <li id="BibPLXBIB0010" label="[10]">John Hopcroft, Tiancheng Lou, and Jie Tang. 2011. Who Will Follow You Back?: Reciprocal Relationship Prediction. In <em>      <em>CIKM &#x2019;11</em>     </em>. 1137&#x2013;1146.</li>     <li id="BibPLXBIB0011" label="[11]">Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen. 2014. Convolutional neural network architectures for matching natural language sentences. In <em>      <em>NIPS</em>     </em>. 2042&#x2013;2050.</li>     <li id="BibPLXBIB0012" label="[12]">Kalervo J&#x00E4;rvelin and Jaana Kek&#x00E4;l&#x00E4;inen. 2002. Cumulated Gain-based Evaluation of IR Techniques. <em>      <em>ACM Trans. Inf. Syst.</em>     </em>20, 4 (2002), 422&#x2013;446.</li>     <li id="BibPLXBIB0013" label="[13]">Kalervo J&#x00E4;rvelin and Jaana Kek&#x00E4;l&#x00E4;inen. 2002. Cumulated Gain-based Evaluation of IR Techniques. <em>      <em>ACM Trans. Inf. Syst.</em>     </em>20, 4 (2002), 422&#x2013;446.</li>     <li id="BibPLXBIB0014" label="[14]">Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A convolutional neural network for modelling sentences. <em>      <em>arXiv preprint arXiv:1404.2188</em>     </em>(2014).</li>     <li id="BibPLXBIB0015" label="[15]">Ross Kindermann, James&#x00A0;Laurie Snell, <em>et al.</em> 1980. <em>      <em>Markov random fields and their applications</em>     </em>. Vol.&#x00A0;1. American Mathematical Society Providence, RI.</li>     <li id="BibPLXBIB0016" label="[16]">Tsung-Ting Kuo, Rui Yan, Yu-Yang Huang, Perng-Hwa Kung, and Shou-De Lin. 2013. Unsupervised Link Prediction Using Aggregative Statistics on Heterogeneous Social Networks. In <em>      <em>KDD &#x2019;13</em>     </em>. 775&#x2013;783.</li>     <li id="BibPLXBIB0017" label="[17]">John Lafferty and Chengxiang Zhai. 2001. Document Language Models, Query Models, and Risk Minimization for Information Retrieval. In <em>      <em>SIGIR &#x2019;01</em>     </em>. 111&#x2013;119.</li>     <li id="BibPLXBIB0018" label="[18]">Victor Lavrenko and W.&#x00A0;Bruce Croft. 2001. Relevance Based Language Models. In <em>      <em>SIGIR &#x2019;01</em>     </em>. 120&#x2013;127.</li>     <li id="BibPLXBIB0019" label="[19]">Anton Leuski and David Traum. 2011. NPCEditor: Creating virtual human dialogue using information retrieval techniques. <em>      <em>AI Magazine</em>     </em>32, 2 (2011), 42&#x2013;56.</li>     <li id="BibPLXBIB0020" label="[20]">Jiwei Li, Minh-Thang Luong, and Dan Jurafsky. 2015. A Hierarchical Neural Autoencoder for Paragraphs and Documents. In <em>      <em>ACL-IJCNLP&#x2019;15</em>     </em>. 1106&#x2013;1115.</li>     <li id="BibPLXBIB0021" label="[21]">Christopher&#x00A0;D Manning, Prabhakar Raghavan, and Hinrich Sch&#x00FC;tze. 2008. <em>      <em>Introduction to information retrieval</em>     </em>. Vol.&#x00A0;1. Cambridge University Press.</li>     <li id="BibPLXBIB0022" label="[22]">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. <em>      <em>arXiv preprint arXiv:1301.3781</em>     </em>(2013).</li>     <li id="BibPLXBIB0023" label="[23]">Elnaz Nouri, Ron Artstein, Anton Leuski, and David&#x00A0;R Traum. 2011. Augmenting Conversational Characters with Generated Question-Answer Pairs.. In <em>      <em>AAAI Fall Symposium: Question Generation</em>     </em>.</li>     <li id="BibPLXBIB0024" label="[24]">Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The PageRank citation ranking: bringing order to the web.(1999).</li>     <li id="BibPLXBIB0025" label="[25]">Hamid Palangi, Li Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying Song, and Rabab Ward. 2015. Deep Sentence Embedding Using the Long Short Term Memory Network: Analysis and Application to Information Retrieval. <em>      <em>arXiv preprint arXiv:1502.06922</em>     </em>(2015).</li>     <li id="BibPLXBIB0026" label="[26]">Tim Rockt&#x00E4;schel, Edward Grefenstette, Karl&#x00A0;Moritz Hermann, Tom&#x00E1;&#x0161; Ko&#x010D;isk&#x1EF3;, and Phil Blunsom. 2015. Reasoning about Entailment with Neural Attention. <em>      <em>arXiv preprint arXiv:1509.06664</em>     </em>(2015).</li>     <li id="BibPLXBIB0027" label="[27]">Iulian&#x00A0;V Serban, Alessandro Sordoni, Yoshua Bengio, Aaron Courville, and Joelle Pineau. 2016. Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models. In <em>      <em>AAAI&#x2019;16</em>     </em>. 3776&#x2013;3783.</li>     <li id="BibPLXBIB0028" label="[28]">Aliaksei Severyn and Alessandro Moschitti. 2015. Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks. In <em>      <em>SIGIR &#x2019;15</em>     </em>. 373&#x2013;382.</li>     <li id="BibPLXBIB0029" label="[29]">Lifeng Shang, Zhengdong Lu, and Hang Li. 2015. Neural Responding Machine for Short-Text Conversation. In <em>      <em>ACL-IJCNLP&#x2019;15</em>     </em>. 1577&#x2013;1586.</li>     <li id="BibPLXBIB0030" label="[30]">Richard Socher, Jeffrey Pennington, Eric&#x00A0;H Huang, Andrew&#x00A0;Y Ng, and Christopher&#x00A0;D Manning. 2011. Semi-supervised recursive autoencoders for predicting sentiment distributions. In <em>      <em>EMNLP&#x2019;11</em>     </em>. 151&#x2013;161.</li>     <li id="BibPLXBIB0031" label="[31]">Fei Song and W.&#x00A0;Bruce Croft. 1999. A General Language Model for Information Retrieval. In <em>      <em>CIKM &#x2019;99</em>     </em>. 316&#x2013;321.</li>     <li id="BibPLXBIB0032" label="[32]">Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015. A Neural Network Approach to Context-Sensitive Generation of Conversational Responses. In <em>      <em>NAACL&#x2019;15</em>     </em>. 196&#x2013;205.</li>     <li id="BibPLXBIB0033" label="[33]">Ilya Sutskever, Oriol Vinyals, and Quoc&#x00A0;VV Le. 2014. Sequence to sequence learning with neural networks. In <em>      <em>NIPS</em>     </em>. 3104&#x2013;3112.</li>     <li id="BibPLXBIB0034" label="[34]">Zhiliang Tian, Rui Yan, Lili Mou, Yiping Song, Yansong Feng, and Dongyan Zhao. 2017. How to Make Context More Useful? An Empirical Study on Context-Aware Neural Conversational Models. In <em>      <em>ACL&#x2019;17</em>     </em>. 231&#x2013;236.</li>     <li id="BibPLXBIB0035" label="[35]">Yan Xu, Lili Mou, Ge Li, Yunchuan Chen, Hao Peng, and Zhi Jin. 2015. Classifying relations via long short term memory networks along shortest dependency paths. In <em>      <em>EMNLP&#x2019;15</em>     </em>. 1785&#x2013;1794.</li>     <li id="BibPLXBIB0036" label="[36]">Rui Yan, Mirella Lapata, and Xiaoming Li. 2012. Tweet Recommendation with Graph Co-ranking. In <em>      <em>ACL &#x2019;12</em>     </em>. 516&#x2013;525.</li>     <li id="BibPLXBIB0037" label="[37]">Rui Yan, Yiping Song, and Hua Wu. 2016. Learning to Respond with Deep Neural Networks for Retrieval based Human-Computer Conversation System. In <em>      <em>SIGIR &#x2019;16</em>     </em>. 55&#x2013;64.</li>     <li id="BibPLXBIB0038" label="[38]">Rui Yan, Yiping Song, Xiangyang Zhou, and Hua Wu. 2016. &#x201D;Shall I Be Your Chat Companion?&#x201D; Towards an Online Human-Computer Conversation System. In <em>      <em>CIKM&#x2019;16</em>     </em>. 649&#x2013;658.</li>     <li id="BibPLXBIB0039" label="[39]">Rui Yan, Dongyan Zhao, <em>et al.</em> 2017. Joint Learning of Response Ranking and Next Utterance Suggestion in Human-Computer Conversation System. In <em>      <em>Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>     </em>. ACM, 685&#x2013;694.</li>     <li id="BibPLXBIB0040" label="[40]">Zi Yang, Keke Cai, Jie Tang, Li Zhang, Zhong Su, and Juanzi Li. 2011. Social Context Summarization. In <em>      <em>SIGIR &#x2019;11</em>     </em>. 255&#x2013;264.</li>     <li id="BibPLXBIB0041" label="[41]">Lili Yao, Yaoyuan Zhang, Yansong Feng, Dongyan Zhao, and Rui Yan. 2017. Towards Implicit Content-Introducing for Generative Short-Text Conversation Systems. In <em>      <em>Proceedings of EMNLP 2017</em>     </em>. 2190&#x2013;2199.</li>     <li id="BibPLXBIB0042" label="[42]">Jonathan&#x00A0;S Yedidia, William&#x00A0;T Freeman, Yair Weiss, <em>et al.</em> 2000. Generalized belief propagation. In <em>      <em>NIPS</em>     </em>, Vol.&#x00A0;13. 689&#x2013;695.</li>     <li id="BibPLXBIB0043" label="[43]">Biao Zhang, Jinsong Su, Deyi Xiong, Yaojie Lu, Hong Duan, and Junfeng Yao. 2015. Shallow Convolutional Neural Network for Implicit Discourse Relation Recognition. In <em>      <em>EMNLP</em>     </em>. 2230&#x2013;2235.</li>     <li id="BibPLXBIB0044" label="[44]">Wayne&#x00A0;Xin Zhao, Jing Jiang, Jianshu Weng, Jing He, Ee-Peng Lim, Hongfei Yan, and Xiaoming Li. 2011. Comparing twitter and traditional media using topic models. In <em>      <em>ECIR &#x2019;11</em>     </em>. 338&#x2013;349.</li>     <li id="BibPLXBIB0045" label="[45]">Xiangyang Zhou, Daxiang Dong, Hua Wu, Shiqi Zhao, Dianhai Yu, Hao Tian, Xuan Liu, and Rui Yan. 2016. Multi-view Response Selection for Human-Computer Conversation.. In <em>      <em>EMNLP&#x2019;16</em>     </em>. 372&#x2013;381.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18 Companion, April 23&#x2013;27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. <br/>ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186341">https://doi.org/10.1145/3184558.3186341</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
