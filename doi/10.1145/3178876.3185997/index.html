<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Time Expression Recognition Using a Constituent-based
  Tagging Scheme</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3185997'>https://doi.org/10.1145/3178876.3185997</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3185997'>https://w3id.org/oa/10.1145/3178876.3185997</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Time Expression Recognition Using
          a Constituent-based Tagging Scheme</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Xiaoshi</span> <span class=
          "surName">Zhong</span>, School of Computer Science and
          Engineering Nanyang Technological University, Singapore
        </div>
        <div class="author">
          <span class="givenName">Erik</span> <span class=
          "surName">Cambria</span>, School of Computer Science and
          Engineering Nanyang Technological University, Singapore,
          <a href="mailto:xszhong,%20cambria@ntu.edu.sg">xszhong,
          cambria@ntu.edu.sg</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.3185997"
        target=
        "_blank">https://doi.org/10.1145/3178876.3185997</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>We find from four datasets that time expressions
        are formed by loose structure and the words used to express
        time information can differentiate time expressions from
        common text. The findings drive us to design a learning
        method named TOMN to model time expressions. TOMN defines a
        constituent-based tagging scheme named TOMN scheme with
        four tags, namely T, O, M, and N, indicating the
        constituents of time expression, namely Time token,
        Modifier, Numeral, and the words Outside time expression.
        In modeling, TOMN assigns a word with a TOMN tag under
        conditional random fields with minimal features.
        Essentially, our constituent-based TOMN scheme overcomes
        the problem of <em>inconsistent tag assignment</em> that is
        caused by the conventional position-based tagging schemes
        (e.g., BIO scheme and BILOU scheme). Experiments show that
        TOMN is equally or more effective than state-of-the-art
        methods on various datasets, and much more robust on
        cross-datasets. Moreover, our analysis can explain many
        empirical observations in other works about time expression
        recognition and named entity recognition.</small></p>
      </div>
      <div class="classifications">
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Xiaoshi Zhong and Erik Cambria. 2018. Time Expression
          Recognition Using a Constituent-based Tagging Scheme. In
          <em>WWW 2018: The 2018 Web Conference,</em> <em>April
          23–27, 2018,</em> <em>Lyon, France. ACM, New York, NY,
          USA</em> 10 Pages. <a href=
          "https://doi.org/10.1145/3178876.3185997" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3178876.3185997</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-2">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Time information plays an increasingly important role in
      data mining, information retrieval, and natural language
      processing [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0001">1</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0008">8</a>].
      Researchers from these fields have devoted tremendous effort
      to specify standards for time expression annotation
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0014">14</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0018">18</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0030">30</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0032">32</a>], build
      annotated corpora for time expression [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0018">18</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0027">27</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0031">31</a>], and recognize time
      expressions from free text [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0042">42</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0043">43</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0045">45</a>].</p>
      <p>We analyze four datasets (i.e., TimeBank [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0031">31</a>], Gigaword [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0028">28</a>], WikiWars [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0027">27</a>], and Tweets [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0047">47</a>]) for the
      characteristics of time expressions and have two important
      findings about their organization and constituent words.
      First, time expressions are formed by loose structure, with
      more than 53.5% of distinct time tokens appearing in
      different positions within time expressions. Second, time
      tokens can differentiate time expressions from common text;
      more than 91.8% of time expressions have at least one time
      token while no more than 0.7% of common text contain time
      tokens.</p>
      <p>The findings motivate us to design a learning method named
      TOMN to model time expressions. Specifically, TOMN defines a
      constituent-based tagging scheme named TOMN scheme,<a class=
      "fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> consisting of
      four tags, namely T, O, M, and N, indicating the constituents
      of time expression, namely Time token, Modifier, Numeral, and
      the words Outside time expression. Time tokens include the
      words that explicitly express information about time, such as
      ‘2006,’ ‘month,’ and ‘September.’ Modifiers are the words
      that modify time tokens and appear around them; for example,
      ‘last’ modifies ‘month’ in ‘last month.’ Numerals are the
      ordinals and numbers (except the year like ‘2006’). TOMN
      models time expressions under conditional random fields
      (CRFs) [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0019">19</a>]
      with only a kind of pre-tag features and the lemma features;
      it assigns a word with a TOMN tag.</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3185997/images/www2018-6-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">BILOU and TOMN tag assignment during
          training. BILOU scheme is based on the position within
          the chunk, while TOMN scheme bases on the constituent of
          the chunk. Here inconsistent tag assignment is defined as
          that during training, a word is assigned with different
          tags because the word appears in different positions
          within labeled chunks.<a class="fn" href="#fn2" id=
          "foot-fn2"><sup>2</sup></a></span>
        </div>
      </figure>
      <p></p>
      <p>TOMN scheme can keep the tag assignment consistent during
      training and therefore overcomes the problem of inconsistent
      tag assignment. (In a supervised learning procedure, tag
      assignment occurs in feature extraction during training and
      in tag prediction. We focus on the training stage to analyze
      the impact of tag assignment.) The loose structure by which
      time expressions are formed exhibits in two aspects. First,
      many time expressions consist of loose collocations. For
      example, the time token ‘September’ can form a time
      expression by itself, or forms ‘September 2006’ by another
      time token appearing after it, or ‘1 September 2006’ by a
      numeral before it and another time token after it. Second,
      some time expressions can change their word order without
      changing their meanings. For example, ‘September 2006’ and
      ‘2006 September’ express the same meaning. The conventional
      tagging schemes like BILOU [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0033">33</a>] are based on <em>the position within
      the chunk</em>, namely a Unit-word chunk, and the Beginning,
      Inside, and Last word of a multi-word chunk. Under BILOU
      scheme, a word that appears in different positions within
      labeled time expressions is assigned with different tags; for
      example, the above ‘September’ can be assigned with U, B, L,
      or I. See Figure 1(a) . The inconsistent tag assignment
      causes difficulty for statistical models to model time
      expressions. First, inconsistent tag assignment reduces the
      predictive power of lexicon, and this contradicts the finding
      that time tokens can differentiate time expressions from
      common text. Second, inconsistent tag assignment might cause
      the problem of tag imbalance. Our TOMN scheme instead is
      based on <strong>the constituent of the chunk</strong> (i.e.,
      Time token, Modifier, and Numeral) and assigns the same
      constituent word with the same tag, regardless of its
      frequency and its positions within time expressions. Under
      TOMN scheme, for example, the above ‘September’ is
      consistently assigned with T. See Figure <a class="fig" href=
      "#fig1">1(b)</a>. With consistent tag assignment, TOMN scheme
      avoids the potential tag imbalance and protects time tokens’
      predictive power.</p>
      <p>We evaluate TOMN against five state-of-the-art methods
      (i.e., HeidelTime [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0039">39</a>], SUTime [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0009">9</a>], SynTime [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0047">47</a>], ClearTK [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0004">4</a>], and UWTime [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0021">21</a>]) on three
      datasets (i.e., TE-3 [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0042">42</a>], WikiWars [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0027">27</a>], and Tweets [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0047">47</a>]).<a class=
      "fn" href="#fn3" id="foot-fn3"><sup>3</sup></a> Experiments
      show that TOMN is equally or more effective than the
      state-of-the-art methods, and much more robust on
      cross-dataset performance. Experiments also show the
      advantage of TOMN scheme over the position-based tagging
      schemes.</p>
      <p>In addition, we find that the named entities in CoNLL03
      English NER dataset [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0034">34</a>] demonstrate common characteristics
      similar to the time expressions (see Section <a class="sec"
      href="#sec-20">6</a> for details). The finding suggests that
      the problem of inconsistent tag assignment widely exists in
      the position-based tagging schemes and that our idea of
      defining constituent-based tagging scheme should be widely
      effective for general entities. In the future we will further
      develop that idea.</p>
      <p>To summarize, we make the contributions as follows.</p>
      <ul class="list-no-style">
        <li id="list1" label="•">We analyze four diverse datasets
        for the characteristics of time expressions and have two
        important findings about their organization and constituent
        words.<br /></li>
        <li id="list2" label="•">We discover a fundamental problem
        underlying in the position-based tagging schemes:
        inconsistent tag assignment. To overcome that problem we
        define a constituent-based tagging scheme to model time
        expressions. Our method provides an idea to model target
        entities based on their constituents.<br /></li>
        <li id="list3" label="•">We conduct experiments on various
        datasets, and the results show the effectiveness,
        efficiency, and robustness of our method compared with
        state-of-the-art methods. The results also show the
        advantage of our constituent-based tagging scheme over the
        position-based tagging schemes.<br /></li>
        <li id="list4" label="•">The analysis in this work can help
        explain many empirical results and observations reported in
        other works about time expression recognition and named
        entity recognition.<br /></li>
      </ul>
    </section>
    <section id="sec-3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related
          Work</h2>
        </div>
      </header>
      <p>Time expression identification aims to automatically
      identify time expressions from free text and it can be
      divided into two subtasks, namely recognition and
      normalization. In this paper we focus on the recognition.
      Methods for time expression recognition can be categorized
      into rule-based methods and learning-based methods.</p>
      <p><strong>Rule-based Methods.</strong> Rule-based methods
      like TempEx, GUTime, HeidelTime, and SUTime mainly handcraft
      deterministic rules to identify time expressions. TempEx and
      GUTime use both handcrafted rules and machine-learnt rules to
      resolve time expressions [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0044">44</a>]. HeidelTime manually designs rules
      with time resources to recognize time expressions [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0039">39</a>]. SUTime
      designs deterministic rules at three levels (i.e., individual
      word level, chunk level, and time expression level) for time
      expression recognition [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0009">9</a>]. A recent type-based time tagger,
      SynTime, designs general heuristic rules with a token type
      system to recognize time expressions [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0047">47</a>].</p>
      <p>TOMN uses the token regular expressions, similar to SUTime
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0009">9</a>] and SynTime
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0047">47</a>], and
      further groups them into three token types, similar to
      SynTime. While SynTime further defines 21 token types for the
      constituent words of time expression, TOMN uses the three
      general token types that are helpful for a learning method to
      connect the words with low frequencies to the words with high
      frequencies. And TOMN leverages statistical information from
      entire corpus to improve the precisions and alleviate the
      deterministic role of deterministic rules and heuristic
      rules.</p>
      <p><strong>Learning-based Methods.</strong> Learning-based
      methods in TempEval series mainly extract features from text
      (e.g., character features, word features, syntactic features,
      and semantic features), and on the features apply statistical
      models (e.g., CRFs, logistic regression, maximum entropy,
      Markov logic network, and support vector machines) to model
      time expressions [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0041">41</a>]. Besides the standard methods,
      Angeli et al., and Angeli and Uszkoreit exploit an EM-style
      approach with compositional grammar to learn latent time
      parsers [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0002">2</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0003">3</a>]. Lee et al.
      leverage combinatory categorial grammar (CCG) [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0036">36</a>] and define a collection
      of lexicon with linguistic context to model time expressions
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0021">21</a>].</p>
      <p>Unlike [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0004">4</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0015">15</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0017">17</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0023">23</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0041">41</a>] which use
      the standard features, TOMN derives features according to the
      characteristics of time expressions and uses only a kind of
      pre-tag features and the lemma features; which can enhance
      the impact of the significant features and reduce the impact
      of the insignificant features. Unlike [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0002">2</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0003">3</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0021">21</a>] which use fixed structure
      information, TOMN uses the loose structure information by
      grouping the constituent words of time expression under three
      token types, which can fully account for the loose structure
      of time expressions. More importantly, TOMN models time
      expressions under a CRFs framework with a constituent-based
      tagging scheme, which can keep the tag assignment
      consistent.</p>
      <p><strong>Time Expression Normalization.</strong> Methods
      for time expression normalization are mainly based on rules
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0004">4</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0015">15</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0023">23</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0039">39</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0041">41</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0044">44</a>]. Since the
      rule methods are highly similar, Llorens et al. suggest to
      construct a large shared knowledge base for public use
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0022">22</a>]. Lee et
      al., Angeli et al., and Angeli and Uszkoreit combine grammar
      rules and machine learning techniques to normalize time
      expressions [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0002">2</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0003">3</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0021">21</a>]. TOMN
      focuses on the recognition and leaves the normalization to
      those highly similar rule methods or the future work.</p>
    </section>
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Time Expression
          Analysis</h2>
        </div>
      </header>
      <p><strong>Datasets.</strong> We analyze the time expressions
      from four datasets: TimeBank, Gigaword, WikiWars, and Tweets.
      TimeBank is a benchmark dataset and consists of 183 news
      articles [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0031">31</a>].
      Gigaword consists of 2,452 news articles with automatically
      annotated time expressions [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0028">28</a>]. WikiWars is constructed by
      collecting war articles from Wikipedia [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0027">27</a>]. Tweets consists of 942
      tweets collected from Twitter [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0047">47</a>]. The four datasets cover
      comprehensive data (TimeBank, Gigaword, and Tweets) and
      specific domain data (WikiWars) as well as formal text
      (TimeBank, Gigaword, and WikiWars) and informal text
      (Tweets). Table <a class="tbl" href="#tab1">1</a> summarizes
      the dataset statistics.</p>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">Dataset statistics (‘timex’ denotes time
          expression.)</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:center;">
              <strong>Dataset</strong></th>
              <th style="text-align:right;">
              <strong>#Documents</strong></th>
              <th style="text-align:right;">
              <strong>#Words</strong></th>
              <th><strong>#Timex</strong></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:center;">TimeBank</td>
              <td style="text-align:right;">183</td>
              <td style="text-align:right;">61,418</td>
              <td>1,243</td>
            </tr>
            <tr>
              <td style="text-align:center;">Gigaword</td>
              <td style="text-align:right;">2,452</td>
              <td style="text-align:right;">666,309</td>
              <td>12,739</td>
            </tr>
            <tr>
              <td style="text-align:center;">WikiWars</td>
              <td style="text-align:right;">22</td>
              <td style="text-align:right;">119,468</td>
              <td>2,671</td>
            </tr>
            <tr>
              <td style="text-align:center;">Tweets</td>
              <td style="text-align:right;">942</td>
              <td style="text-align:right;">18,199</td>
              <td>1,127</td>
            </tr>
          </tbody>
        </table>
      </div>
      <section id="sec-5">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span>
            Findings</h3>
          </div>
        </header>
        <p>Although the four datasets differ in source, domain,
        corpus size, and text type, their time expressions
        demonstrate some common characteristics. We find such two
        common characteristics of time expressions about their
        organization and constituent words.</p>
        <div class="finding" id="enc1">
          <label>Finding 1.</label>
          <p>Time expressions are formed by loose structure; more
          than 53.5% of time tokens appear in different positions
          within time expressions.</p>
        </div>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Percentage of distinct time tokens and
            modifiers that appear in different positions within
            time expressions.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">
                <strong>Dataset</strong></th>
                <th colspan="2" style="text-align:center;">
                  <strong>BIO Scheme</strong>
                  <hr />
                </th>
                <th colspan="2" style="text-align:center;">
                  <strong>BILOU Scheme</strong>
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">Time Token</th>
                <th style="text-align:center;">Modifier</th>
                <th style="text-align:center;">Time Token</th>
                <th>Modifier</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">TimeBank</td>
                <td style="text-align:center;">58.18</td>
                <td style="text-align:center;">33.33</td>
                <td style="text-align:center;">63.64</td>
                <td>33.33</td>
              </tr>
              <tr>
                <td style="text-align:center;">Gigaword</td>
                <td style="text-align:center;">61.29</td>
                <td style="text-align:center;">45.83</td>
                <td style="text-align:center;">77.05</td>
                <td>46.00</td>
              </tr>
              <tr>
                <td style="text-align:center;">WikiWars</td>
                <td style="text-align:center;">53.57</td>
                <td style="text-align:center;">26.19</td>
                <td style="text-align:center;">61.40</td>
                <td>29.55</td>
              </tr>
              <tr>
                <td style="text-align:center;">Tweets</td>
                <td style="text-align:center;">67.21</td>
                <td style="text-align:center;">27.59</td>
                <td style="text-align:center;">72.58</td>
                <td>27.59</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>We find that time expressions are formed by loose
        structure and the loose structure exhibits in two aspects.
        First, many time expressions consist of loose collocations.
        For example, the time token ‘September’ can form a time
        expression by itself, or forms ‘September 2006’ by another
        time token appearing after it, or ‘1 September 2006’ by a
        numeral before it and another time token after it. Second,
        some time expressions can change their word order without
        changing their meanings. For example, ‘September 2006’ can
        be written as ‘2006 September’ with the same meaning. From
        the point of view of the position within time expressions,
        the ‘September’ may appear as the (i) beginning or (ii)
        inside word of time expression when time expressions are
        modeled by BIO scheme; or it may appear as (1) a unit-word
        time expression, or the (2) beginning, (3) inside, (4) last
        word of a multi-word time expression when time expressions
        are modeled by BILOU scheme.</p>
        <p>Table <a class="tbl" href="#tab2">2</a> reports the
        percentage of distinct time tokens and modifiers that
        appear in different positions within time expressions.
        ‘Distinct’ here means ignoring the word variants and
        frequencies during counting; for example, ‘month,’
        ‘months,’ and ‘mths’ are treated the same and are counted
        only once. ‘Different positions’ means the two different
        positions under BIO scheme and at least two of the four
        different positions under BILOU scheme. For each dataset,
        under BIO scheme, more than 53.5% of distinct time tokens
        appear in different positions; and under BILOU scheme, more
        than 61.4% of distinct time tokens appear in different
        positions. The number of modifiers that appear in different
        positions is more than 27.5%. When BIO or BILOU scheme is
        applied to model time expressions, the appearance in
        different positions leads to inconsistent tag assignment,
        and the inconsistent tag assignment causes difficulty for
        statistical models to model time expressions. We need to
        explore an appropriate tagging scheme (see Section
        <a class="sec" href="#sec-8">4.1</a> for details).</p>
        <div class="finding" id="enc2">
          <label>Finding 2.</label>
          <p>Time tokens can differentiate time expressions from
          common text while modifiers and numerals cannot.</p>
        </div>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class=
            "table-title">Percentage of time expression's
            constituents that appear in time expressions
            (<em>P<sub>timex</sub></em> ) and in common text
            (<em>P<sub>text</sub></em> ).</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">
                <strong>Dataset</strong></th>
                <th colspan="2" style="text-align:center;">
                  <strong>Time Token</strong>
                  <hr />
                </th>
                <th colspan="2" style="text-align:center;">
                  <strong>Modifer</strong>
                  <hr />
                </th>
                <th colspan="2" style="text-align:center;">
                  <strong>Numeral</strong>
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">
                <em>P<sub>timex</sub></em></th>
                <th style="text-align:center;">
                <em>P<sub>text</sub></em></th>
                <th style="text-align:center;">
                <em>P<sub>timex</sub></em></th>
                <th style="text-align:center;">
                <em>P<sub>text</sub></em></th>
                <th style="text-align:center;">
                <em>P<sub>timex</sub></em></th>
                <th><em>P<sub>text</sub></em></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">TimeBank</td>
                <td style="text-align:center;">94.61</td>
                <td style="text-align:center;">0.34</td>
                <td style="text-align:center;">47.39</td>
                <td style="text-align:center;">22.56</td>
                <td style="text-align:center;">22.61</td>
                <td>3.16</td>
              </tr>
              <tr>
                <td style="text-align:center;">Gigaword</td>
                <td style="text-align:center;">96.44</td>
                <td style="text-align:center;">0.65</td>
                <td style="text-align:center;">28.05</td>
                <td style="text-align:center;">22.82</td>
                <td style="text-align:center;">20.24</td>
                <td>2.03</td>
              </tr>
              <tr>
                <td style="text-align:center;">WikiWars</td>
                <td style="text-align:center;">91.81</td>
                <td style="text-align:center;">0.14</td>
                <td style="text-align:center;">31.64</td>
                <td style="text-align:center;">26.14</td>
                <td style="text-align:center;">38.01</td>
                <td>9.82</td>
              </tr>
              <tr>
                <td style="text-align:center;">Tweets</td>
                <td style="text-align:center;">96.01</td>
                <td style="text-align:center;">0.50</td>
                <td style="text-align:center;">21.38</td>
                <td style="text-align:center;">13.03</td>
                <td style="text-align:center;">18.81</td>
                <td>1.28</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>Table <a class="tbl" href="#tab3">3</a> reports the
        percentage of time expression's constituent words appearing
        in time expressions (<em>P<sub>timex</sub></em> ) and in
        common text (<em>P<sub>text</sub></em> ). Common text here
        means the whole text with time expressions excluded.
        <em>P<sub>timex</sub></em> is defined by Equation
        (<a class="eqn" href="#eq1">1</a>) and
        <em>P<sub>text</sub></em> is by Equation (<a class="eqn"
        href="#eq2">2</a>), where <span class=
        "inline-equation"><span class="tex">$T \in \lbrace
        time\enspace {}token,\enspace {}modifier,\enspace
        {}numeral\rbrace$</span></span> .</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            P_{timex}(T)=\frac{\#timex\enspace {}that\enspace
            {}contain\enspace {}T}{\#total\enspace {}timex}
            \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            P_{text}(T)=\frac{\#tokens\enspace {}that\enspace
            {}are\enspace {}T}{\#total\enspace {}tokens}
            \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>
        <p></p>
        <p>From the second column of Table <a class="tbl" href=
        "#tab3">3</a> we can see that more than 91.8% of time
        expressions contain at least one time token; the percentage
        91.8% is consistent with the one analyzed by Zhong et al.
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0047">47</a>]. (Some
        time expressions without time token depend on other time
        expressions; for example, ‘95’ depends on ‘100 days’ in ‘95
        to 100 days.’) By contrast, the third column shows that no
        more than 0.7% of common text contain time tokens. This
        indicates that time tokens can differentiate time
        expressions from common text. On the other hand, the last
        four columns show that on average, 32.1% of time
        expressions and 21.1% of common text contain modifiers and
        24.9% of time expressions and 4.1% of common text contain
        numerals. This indicates that modifiers and numerals cannot
        differentiate time expressions from common text.</p>
        <p>Looking at the Tweets dataset, we can see that the
        <em>P<sub>timex</sub></em> of the time tokens (96.0%) is
        relatively high while the <em>P<sub>timex</sub></em> of the
        modifiers (21.4%) and numerals (18.8%) are much lower than
        the ones of other datasets. This indicates that in Twitter
        people tend to use time expressions with fewer modifiers
        and numerals.</p>
      </section>
      <section id="sec-6">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span>
            Properties</h3>
          </div>
        </header>
        <p>In addition to our findings, Zhong et al. also conclude
        some characteristics about time expressions from the same
        four datasets [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0047">47</a>]. The characteristics concluded by
        Zhong et al. are helpful for our analysis, so we briefly
        describe them here and report them as time expressions’
        properties.<a class="fn" href="#fn4" id=
        "foot-fn4"><sup>4</sup></a></p>
        <div class="property" id="enc3">
          <label>Property 1.</label>
          <p>“Time expressions are very short. More than 80% of
          time expressions contain no more than three words and
          more than 90% contain no more than four words.”
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0047">47</a>]</p>
        </div>
        <p>Time expressions across different datasets follow a
        similar length distribution and on average, time
        expressions contain about two words. For the one-word time
        expressions, the percentage of which in TimeBank is 40.3%;
        in Gigaword the percentage is 53.9%; in WikiWars it is
        36.2%; and in Tweets it is 62.9%.</p>
        <div class="property" id="enc4">
          <label>Property 2.</label>
          <p>“Only a small group of time-related keywords are used
          to express time information.” [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0047">47</a>]</p>
        </div>
        <p>There are only about 70 distinct time tokens used in
        individual dataset, regardless of the corpus sizes and the
        number of time expressions, and only 123 distinct time
        tokens across different datasets. That means time
        expressions are highly overlapped at their time tokens
        within individual dataset and across different
        datasets.</p>
        <div class="property" id="enc5">
          <label>Property 3.</label>
          <p>“POS information could not distinguish time
          expressions from common words, but within time
          expressions, POS tags can help distinguish their
          constituents.” [<a class="bib" data-trigger="hover"
          data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0047">47</a>]</p>
        </div>
        <p>Among the top 40 part-of-speech (POS) tags in time
        expressions (10 × 4 datasets), 37 tags whose percentage
        over the corresponding tags of the whole text is lower than
        20%.</p>
      </section>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> TOMN:
          Time-related Tagging Scheme</h2>
        </div>
      </header>
      <p>Figure <a class="fig" href="#fig2">2</a> shows the
      overview of TOMN, including three parts: TOMN scheme,
      TmnRegex, and time expression recognition. TOMN scheme is a
      constituent-based tagging scheme with four tags. TmnRegex is
      a set of regular expressions for time-related words. Time
      expressions are modeled under a CRFs framework with the help
      of TmnRegex and TOMN scheme.</p>
      <figure id="fig2">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3185997/images/www2018-6-fig2.jpg"
        class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class=
          "figure-title">Overview of TOMN. Top-left side shows the
          TOMN scheme, consisting of four tags. Bottom-left side is
          the TmnRegex, a set of regular expressions for
          time-related words. Right-hand side shows the time
          expression modeling, with the help of TmnRegex and TOMN
          scheme.</span>
        </div>
      </figure>
      <p></p>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> TOMN
            Scheme</h3>
          </div>
        </header>
        <p>Finding <a class="enc" href="#enc1">1</a> suggests us to
        explore an appropriate tagging scheme to model time
        expressions. We define a constituent-based tagging scheme
        named TOMN scheme with four tags: T, O, M, and N; they
        indicate the constituents of time expression, namely Time
        token, Modifier, and Numeral, and the words Outside time
        expression.</p>
        <p>Conventional tagging schemes like BIO<a class="fn" href=
        "#fn5" id="foot-fn5"><sup>5</sup></a> [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0035">35</a>] and BILOU<a class="fn"
        href="#fn6" id="foot-fn6"><sup>6</sup></a> [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0033">33</a>] are based on <em>the
        position within the chunk</em>. BIO refers to the
        Beginning, Inside, and Outside of a chunk; BILOU refers to
        a Unit-word chunk, and the Beginning, Inside, Last word of
        a multi-word chunk. TOMN scheme instead is based on
        <strong>the constituent of the chunk</strong>, indicating
        the constituents of time expression. Following we use BILOU
        scheme, the newer version, as representative of the
        conventional position-based tagging schemes for
        analysis.</p>
        <p>Using BILOU scheme for time expression recognition leads
        to inconsistent tag assignment. (A typical supervised
        learning procedure involves tag assignment in two stages;
        one is in feature extraction during training and the other
        is in tag prediction. We focus on the training stage to
        analyze the impact of tag assignment under different kinds
        of tagging schemes.) Finding <a class="enc" href=
        "#enc1">1</a> shows that time expressions are formed by
        loose structure, exhibiting in loose collocations and
        exchangeable order. Under BILOU scheme, both of loose
        collocations and exchangeable order lead to the problem of
        inconsistent tag assignment. Suppose ‘September,’
        ‘September 2006,’ ‘2006 September,’ and ‘1 September 2006’
        are four manually labeled time expressions in training
        data. During feature extraction, they are assigned as
        ‘September/U,’ ‘September/B 2006/L,’ ‘2006/B September/L,’
        and ‘1/B September/I 2006/L’ (see Figure 1(a)). The four
        ‘September’ have the same word (the word itself) and
        express the same meaning (the ninth month of the year), but
        because they appear in different positions within time
        expressions, they are assigned with different tags (i.e.,
        U, B, L, and I).</p>
        <p>The inconsistent tag assignment causes difficulty for
        statistical models to model time expressions. First,
        inconsistent tag assignment reduces the predictive power of
        lexicon. A word assigned with different tags causes
        confusion to model the word. If a word is assigned with
        different tags in equal number, then the word itself cannot
        provide any information useful to determine which tag
        should be assigned to it. Reducing the predictive power of
        lexicon indicates reducing the predictive power of time
        tokens, and this contradicts Finding <a class="enc" href=
        "#enc2">2</a> which shows that time tokens can
        differentiate time expressions from common text. Second,
        inconsistent tag assignment may cause another problem: tag
        imbalance. If a tag of a word dominates in training data,
        then all the instances of that word in test data will be
        predicted as that tag. For example, ‘1 September 2006’ can
        be written as ‘September 1, 2006’ in some cultures. If the
        training data are collected from the style of ‘1 September
        2006’ in which most ‘September’ are assigned with I, then
        it is difficult for the trained model to correctly predict
        the data collected from the style of ‘September 1, 2006’ in
        which ‘September’ should be predicted as B.</p>
        <p>TOMN scheme instead overcomes the problem of
        inconsistent tag assignment. TOMN scheme assigns a tag to a
        word according to the constituent role that the word plays
        in time expressions. Since our TmnRegex well defines the
        constituent words of time expression (see Section <a class=
        "sec" href="#sec-9">4.2</a>) and same word plays same
        constituent role in time expressions, therefore, the same
        word is assigned with the same TOMN tag, regardless of its
        frequency and its positions within time expressions. For
        example, TOMN scheme assigns the above four time
        expressions as ‘September/T,’ ‘2006/T September/T,’
        ‘September/T 2006/T,’ and ‘1/N September/T 2006/T’ (see
        Figure <a class="fig" href="#fig1">1(b)</a>). The four
        ‘September’ have the same tag of ‘T’ and statistical models
        need only to model them as ‘T,’ without any confusion. With
        consistent tag assignment, TOMN scheme avoids the potential
        tag imbalance and protects time tokens’ predictive
        power.</p>
        <p>Besides, TOMN scheme models a word by fewer tags than
        BILOU scheme does. BILOU scheme typically models a time
        token by four tags (i.e., U, B, L, or I) and models a
        modifier/numeral by five tags (i.e., U, B, L, I, or O),
        while TOMN scheme models a time token by one tag (i.e., T)
        and models a modifier/numeral by two tags (i.e., M or N if
        the modifier/numeral appears inside time expressions and O
        if it appears outside time expressions). Compared with
        BILOU scheme, TOMN scheme reduces the complexity of the
        trained model.</p>
      </section>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span>
            TmnRegex</h3>
          </div>
        </header>
        <p>Property <a class="enc" href="#enc4">2</a> indicates a
        small group of words that are used in time expressions.
        TOMN uses three time-related token types, namely time
        token, modifier, and numeral, to group those words. The
        three token types are consistent with three of the above
        four tags (i.e., T, M, and N), and are similar to the ones
        defined in SynTime [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0047">47</a>].</p>
        <p>Time tokens explicitly express information about time,
        such as year (e.g., ‘2006’), month (e.g., ‘September’),
        date (e.g., ‘2006-09-01’), and time units (e.g., ‘month’).
        Modifiers are the words that modify time tokens and appear
        around them; for example, the two modifiers ‘the’ and
        ‘last’ modify the time token ‘month’ in ‘the last month.’
        Numerals include ordinals and numbers, except those that
        are recognized as year (e.g., ‘2006’). Token types are
        defined on tokens themselves and are not necessarily
        relevant to their context. For example, ‘2006’ alone
        expresses time information, so it is a time token; although
        the ‘1’ in ‘1 September 2006’ implies the day, itself alone
        does not express time information, so it is a numeral.</p>
        <p>The three token types with the words they group form a
        set of token regular expressions, and the set of token
        regular expressions is denoted by TmnRegex. TmnRegex is
        constructed by importing token regular expressions for its
        time token, modifier, and numeral from SUTime.<a class="fn"
        href="#fn7" id="foot-fn7"><sup>7</sup></a> Like SynTime
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0047">47</a>],
        TmnRegex collects from SUTime only the regular expressions
        at the level of token. TmnRegex contains only 115 distinct
        time tokens, 57 modifiers, and 58 numerals, without
        counting the words with changing digits.</p>
      </section>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Time
            Expression Recognition</h3>
          </div>
        </header>
        <p>Time expression recognition mainly consists of two
        stages: (1) feature extraction and (2) model learning and
        tagging. When extracting features we set a guideline that
        the features should be able to help differentiate time
        expressions from common text and help build connections
        among time expressions.</p>
        <section id="sec-11">
          <p><em>4.3.1 Feature Extraction.</em> The features we
          extract include two kinds: TOMN pre-tag features and
          lemma features. When extracting features we use
          <em>w<sub>i</sub></em> to denote the <em>i</em>-th word
          in text.</p>
          <p><strong>TOMN Pre-tag Features.</strong> Finding
          <a class="enc" href="#enc2">2</a> shows that time tokens
          can differentiate time expressions from common text while
          modifiers and numerals cannot, therefore, how to leverage
          the information of these words becomes crucial. In our
          consideration, they are treated as pre-tag features under
          TOMN scheme. Specifically, a time token is pre-tagged by
          the tag of T, a modifier is pre-tagged by M, and a
          numeral is by N; other common words are by O. The
          assignment of pre-tags is conducted by simply looking up
          the words at TmnRegex.</p>
          <p>The last four columns of Table <a class="tbl" href=
          "#tab3">3</a> indicate that modifiers and numerals
          constantly appear in time expressions and in common text.
          To distinguish where a modifier or numeral appears, we
          conduct a checking for the modifiers and numerals (the
          words with pre-tag of M or N (M/N)) to record whether
          they directly or indirectly modify any time token.
          ‘Indirectly’ here means a M/N together with other M/N
          modifies a time token; for example, in ‘last two months,’
          ‘last’ (M) together with ‘two’ (N) modifies ‘months’ (T).
          The checking is a loop searching relying on the time
          tokens. For each time token we search its left side
          without exceeding its previous time token and search its
          right side without exceeding its following time token.
          When searching a side of a time token, if encounter a
          M/N, then record the M/N and continue searching; if
          encounter a word that is not M/N, then stop the searching
          for this side of this time token. After the checking,
          those M/N that modify time tokens are recorded; for
          example, the ‘two’ in ‘two months’ is recorded while in
          ‘two apples’ is not. The checking is treated as a feature
          for modeling.</p>
          <p>For the pre-tag features we extract them in a 5-word
          window of <em>w<sub>i</sub></em> , namely the pre-tags of
          <em>w</em> <sub><em>i</em> − 2</sub>, <em>w</em>
          <sub><em>i</em> − 1</sub>, <em>w<sub>i</sub></em> ,
          <em>w</em> <sub><em>i</em> + 1</sub>, and <em>w</em>
          <sub><em>i</em> + 2</sub>. For the checking feature we
          consider only the current word <em>w<sub>i</sub></em>
          .</p>
          <p>In the training phase we consider the TOMN pre-tag
          features for only the words within labeled time
          expressions. In the test phase the TOMN pre-tag features
          are extracted for all the words in text.</p>
          <p><strong>Lemma Features.</strong> The lemma features
          include the word shape of <em>w<sub>i</sub></em> in a
          5-word window, namely the lemmas of <em>w</em>
          <sub><em>i</em> − 2</sub>, <em>w</em> <sub><em>i</em> −
          1</sub>, <em>w<sub>i</sub></em> , <em>w</em>
          <sub><em>i</em> + 1</sub>, and <em>w</em> <sub><em>i</em>
          + 2</sub>. If <em>w<sub>i</sub></em> contains changing
          digit(s), then we set its lemma by its token type. For
          example, the lemma of ‘20:16’ is set by TIME. We use five
          special lemma for the words with changing digits: YEAR,
          DATE, TIME, DECADE, and NUMERAL. The lemma features can
          help build connections among time expressions; for
          example, the two different words ‘20:16’ and ‘19:25:33’
          are connected at TIME.</p>
          <p>The lemma features are extracted for all the words in
          text in both of the training phase and the test
          phase.</p>
          <p>We do not consider the features of characters nor word
          variants because they cannot help build connections among
          time expressions but hurt the modeling; for example,
          ‘Sept.’ and ‘September’ express the same thing but
          computer does not treat them as the same thing.</p>
          <p>We also do not consider the POS features nor other
          syntactic features. Property <a class="enc" href=
          "#enc5">3</a> indicates that POS tags cannot help
          differentiate time expressions from common text, and
          experiments confirm that POS tags do not improve the
          performance. On the other hand, Finding <a class="enc"
          href="#enc1">1</a> shows that time expressions are formed
          by loose structure, which together with Property
          <a class="enc" href="#enc5">3</a> suggests that other
          syntactic features (e.g., syntactic dependency) that rely
          on POS tags and fixed linguistic structure cannot provide
          extra useful information for a CRFs-based learning
          method, which already considers the dependency, to
          differentiate time expressions from common text. We
          therefore do not use those syntactic features in our
          model.</p>
          <p><strong>Feature Values.</strong> For the TOMN pre-tag
          features we separate the features with binary values. The
          theory of scales of measurement suggests that non-ordinal
          attributes should be transformed to separate dimensions
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0037">37</a>]. TOMN pre-tags are non-ordinal,
          therefore, each of TOMN pre-tags as well as the checking
          feature works as a separate feature. For the lemma
          features we follow the traditional use to incorporate
          multiple values under a feature.</p>
          <p>Table <a class="tbl" href="#tab4">4</a> summarizes the
          features that are used for time expression modeling.
          Typically up to 11 features are extracted for a word.</p>
          <div class="table-responsive" id="tab4">
            <div class="table-caption">
              <span class="table-number">Table 4:</span>
              <span class="table-title">Features of word
              <em>w<sub>i</sub></em> used for modeling.</span>
            </div>
            <table class="table">
              <tbody>
                <tr>
                  <td style="text-align:center;">1.</td>
                  <td style="text-align:left;">TOMN pre-tags of
                  <em>w<sub>i</sub></em> in a 5-word window, namely
                  the pre-tags of <em>w</em> <sub><em>i</em> −
                  2</sub>, <em>w</em> <sub><em>i</em> − 1</sub>,
                  <em>w<sub>i</sub></em> , <em>w</em>
                  <sub><em>i</em> + 1</sub>, and <em>w</em>
                  <sub><em>i</em> + 2</sub></td>
                </tr>
                <tr>
                  <td style="text-align:center;">2.</td>
                  <td style="text-align:left;">If
                  <em>w<sub>i</sub></em> is a M or N, then check
                  whether it directly or indirectly modifies any
                  time token</td>
                </tr>
                <tr>
                  <td style="text-align:center;">3.</td>
                  <td style="text-align:left;">Lemmas of
                  <em>w<sub>i</sub></em> in a 5-word window</td>
                </tr>
              </tbody>
            </table>
          </div>
        </section>
        <section id="sec-12">
          <p><em>4.3.2 Model Learning and Tagging.</em> TOMN models
          time expressions through the feature vectors under a CRFs
          framework [<a class="bib" data-trigger="hover"
          data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0019">19</a>]. In implementation, we use
          Stanford Tagger<a class="fn" href="#fn8" id=
          "foot-fn8"><sup>8</sup></a> for the lemma features and
          use CRFSuite<a class="fn" href="#fn9" id=
          "foot-fn9"><sup>9</sup></a> with default setting for
          model learning. For the tagging, each word is assigned
          with one of TOMN tags, namely T, O, M, or N. Note that
          the TOMN scheme is used in feature extraction as a kind
          of features and in sequence tagging as labeling tags.</p>
          <figure id="fig3">
            <img src=
            "../../../data/deliveryimages.acm.org/10.1145/3190000/3185997/images/www2018-6-fig3.jpg"
            class="img-responsive" alt="Figure 3" longdesc="" />
            <div class="figure-caption">
              <span class="figure-number">Figure 3:</span>
              <span class="figure-title">Examples of time
              expression extraction. The label <em>t</em> indicates
              time expression.</span>
            </div>
          </figure><strong>Time Expression Extraction.</strong>
          After sequence tagging, those T, M, and N words (or non-O
          words) that appear together are extracted as a time
          expression. See Figure 3(a) and 3(b) . A special kind of
          modifiers, i.e., the linker ‘to,’ ‘-,’ ‘or,’ and ‘and’
          separates the non-O words into parallel time expressions.
          See Figure 3(c) and 3(d) .
          <p></p>
        </section>
      </section>
    </section>
    <section id="sec-13">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span>
          Experiments</h2>
        </div>
      </header>
      <p>We conduct experiments on three datasets, namely TE-3,
      WikiWars, and Tweets, to evaluate TOMN against five
      state-of-the-art methods, namely HeidelTime (with Colloquial
      setting for Tweets), SUTime, SynTime, ClearTK-TimeML (short
      as ‘ClearTK’), and UWTime.</p>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.1</span> Experiment
            Setting</h3>
          </div>
        </header>
        <p><strong>Datasets.</strong> The three datasets used in
        our experiments are TE-3, WikiWars, and Tweets. TE-3 uses
        the TimeBank corpus as training set and the Platinum corpus
        as test set. TimeBank consists of 183 news articles and
        Platinum consists of 20 new articles; they are
        comprehensive corpora in formal text and described in
        TempEval-3 [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0042">42</a>]. WikiWars is a specific domain
        dataset in formal text, consisting of 22 English Wikipedia
        articles about famous wars [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0027">27</a>]. Tweets is a comprehensive dataset
        in informal text, with 942 tweets that contain time
        expressions [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0047">47</a>]. For WikiWars and Tweets, we
        follow previous works [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0021">21</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0047">47</a>] to set their training sets and
        test sets. The performance of a method (rule-based or
        learning-based) on a dataset is reported on the dataset's
        test set.</p>
        <p><strong>Baseline Methods.</strong> We evaluate TOMN
        against five state-of-the-art methods, including three
        rule-based methods, HeidelTime, SUTime, and SynTime, and
        two learning-based methods, ClearTK and UWTime. HeidelTime
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0039">39</a>] and
        SUTime [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href="#BibPLXBIB0009">9</a>]
        use predefined deterministic rules and achieve the best
        results in relaxed match while ClearTK [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0004">4</a>] uses a CRFs framework
        with BIO scheme and achieves the best result in strict
        match in TempEval-3 [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0042">42</a>]. UWTime uses combinatory
        categorial grammar (CCG) to predefine linguistic structure
        for time expressions and achieves better results than
        HeidelTime on TE-3 and WikiWars datasets [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0021">21</a>]. SynTime uses a set of
        general heuristic rules and achieves good results on TE-3,
        WikiWars, and Tweets datasets [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0047">47</a>]. SynTime has two versions, a basic
        version and an expanded version. Because the expanded
        version requires extra manual annotation for each dataset,
        for fair comparison, we use the basic version to ensure
        that the token regular expressions used in SynTime and TOMN
        are comparable.</p>
        <p><strong>Evaluation Metrics.</strong> We report the
        results in <em>Precision</em>, <em>Recall</em>, and
        <em>F</em> <sub>1</sub> under <em>strict match</em> and
        <em>relaxed match</em> by using the evaluation
        toolkit<a class="fn" href="#fn10" id=
        "foot-fn10"><sup>10</sup></a> of TempEval-3 [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0042">42</a>]. Strict match means
        exact match between the extracted time expressions and the
        ground truth while relaxed match means that there exists
        overlap between them.</p>
        <div class="table-responsive" id="tab5">
          <div class="table-caption">
            <span class="table-number">Table 5:</span> <span class=
            "table-title">Performance of TOMN and baseline methods.
            We make bold the best results and underline the second
            best. Some results are reported directly from the
            sources where the results are publicly
            available.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">
                <strong>Dataset</strong></th>
                <th style="text-align:center;">
                <strong>Method</strong></th>
                <th colspan="3" style="text-align:center;">
                  <strong>Strict Match</strong>
                  <hr />
                </th>
                <th colspan="3" style="text-align:center;">
                  <strong>Relaxed Match</strong>
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;"></th>
                <th style="text-align:center;"><em>Pr</em>.</th>
                <th style="text-align:center;"><em>Re</em>.</th>
                <th style="text-align:center;"><em>F</em>
                <sub>1</sub></th>
                <th style="text-align:center;"><em>Pr</em>.</th>
                <th style="text-align:center;"><em>Re</em>.</th>
                <th><em>F</em> <sub>1</sub></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">TE-3</td>
                <td style="text-align:center;">
                  HeidelTime[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0040">40</a>]
                </td>
                <td style="text-align:center;">83.85</td>
                <td style="text-align:center;">78.99</td>
                <td style="text-align:center;">81.34</td>
                <td style="text-align:center;">93.08</td>
                <td style="text-align:center;">87.68</td>
                <td>90.30</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">
                  SUTime[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0010">10</a>]
                </td>
                <td style="text-align:center;">78.72</td>
                <td style="text-align:center;">80.43</td>
                <td style="text-align:center;">79.57</td>
                <td style="text-align:center;">89.36</td>
                <td style="text-align:center;">91.30</td>
                <td>90.32</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">
                  SynTime[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0047">47</a>]
                </td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">91.43</span></td>
                <td style="text-align:center;">
                <strong>92.75</strong></td>
                <td style="text-align:center;">
                <strong>92.09</strong></td>
                <td style="text-align:center;">94.29</td>
                <td style="text-align:center;">
                <strong>95.65</strong></td>
                <td><strong>94.96</strong></td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">
                  ClearTK[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0004">4</a>]
                </td>
                <td style="text-align:center;">85.90</td>
                <td style="text-align:center;">79.70</td>
                <td style="text-align:center;">82.70</td>
                <td style="text-align:center;">93.75</td>
                <td style="text-align:center;">86.96</td>
                <td>90.23</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">
                  UWTime[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0021">21</a>]
                </td>
                <td style="text-align:center;">86.10</td>
                <td style="text-align:center;">80.40</td>
                <td style="text-align:center;">83.10</td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">94.60</span></td>
                <td style="text-align:center;">88.40</td>
                <td>91.40</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">TOMN</td>
                <td style="text-align:center;">
                <strong>92.59</strong></td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">90.58</span></td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">91.58</span></td>
                <td style="text-align:center;">
                <strong>95.56</strong></td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">93.48</span></td>
                <td><span style=
                "text-decoration: underline;">94.51</span></td>
              </tr>
              <tr>
                <td style="text-align:center;">WikiWars</td>
                <td style="text-align:center;">
                  HeidelTime[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0038">38</a>]
                </td>
                <td style="text-align:center;">
                <strong>88.20</strong></td>
                <td style="text-align:center;">78.50</td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">83.10</span></td>
                <td style="text-align:center;">95.80</td>
                <td style="text-align:center;">85.40</td>
                <td>90.30</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">SUTime</td>
                <td style="text-align:center;">78.61</td>
                <td style="text-align:center;">76.69</td>
                <td style="text-align:center;">76.64</td>
                <td style="text-align:center;">95.74</td>
                <td style="text-align:center;">89.57</td>
                <td>92.55</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">
                  SynTime[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0047">47</a>]
                </td>
                <td style="text-align:center;">80.00</td>
                <td style="text-align:center;">80.22</td>
                <td style="text-align:center;">80.11</td>
                <td style="text-align:center;">92.16</td>
                <td style="text-align:center;">
                <strong>92.41</strong></td>
                <td>92.29</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">ClearTK</td>
                <td style="text-align:center;">87.69</td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">80.28</span></td>
                <td style="text-align:center;">
                <strong>83.82</strong></td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">96.80</span></td>
                <td style="text-align:center;">90.54</td>
                <td><span style=
                "text-decoration: underline;">93.56</span></td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">
                  UWTime[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0021">21</a>]
                </td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">87.70</span></td>
                <td style="text-align:center;">78.80</td>
                <td style="text-align:center;">83.00</td>
                <td style="text-align:center;">
                <strong>97.60</strong></td>
                <td style="text-align:center;">87.60</td>
                <td>92.30</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">TOMN</td>
                <td style="text-align:center;">84.57</td>
                <td style="text-align:center;">
                <strong>80.48</strong></td>
                <td style="text-align:center;">82.47</td>
                <td style="text-align:center;">96.23</td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">92.35</span></td>
                <td><strong>94.25</strong></td>
              </tr>
              <tr>
                <td style="text-align:center;">Tweets</td>
                <td style="text-align:center;">HeidelTime</td>
                <td style="text-align:center;">
                <strong>91.67</strong></td>
                <td style="text-align:center;">74.26</td>
                <td style="text-align:center;">82.05</td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">96.88</span></td>
                <td style="text-align:center;">78.48</td>
                <td>86.71</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">SUTime</td>
                <td style="text-align:center;">77.69</td>
                <td style="text-align:center;">79.32</td>
                <td style="text-align:center;">78.50</td>
                <td style="text-align:center;">88.84</td>
                <td style="text-align:center;">90.72</td>
                <td>89.77</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">
                  SynTime[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0047">47</a>]
                </td>
                <td style="text-align:center;">89.52</td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">94.07</span></td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">91.74</span></td>
                <td style="text-align:center;">93.55</td>
                <td style="text-align:center;">
                <strong>98.31</strong></td>
                <td><strong>95.87</strong></td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">ClearTK</td>
                <td style="text-align:center;">86.83</td>
                <td style="text-align:center;">75.11</td>
                <td style="text-align:center;">80.54</td>
                <td style="text-align:center;">96.59</td>
                <td style="text-align:center;">83.54</td>
                <td>89.59</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">UWTime</td>
                <td style="text-align:center;">88.36</td>
                <td style="text-align:center;">70.76</td>
                <td style="text-align:center;">78.59</td>
                <td style="text-align:center;">
                <strong>97.88</strong></td>
                <td style="text-align:center;">78.39</td>
                <td>87.06</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">TOMN</td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">90.69</span></td>
                <td style="text-align:center;">
                <strong>94.51</strong></td>
                <td style="text-align:center;">
                <strong>92.56</strong></td>
                <td style="text-align:center;">93.52</td>
                <td style="text-align:center;"><span style=
                "text-decoration: underline;">97.47</span></td>
                <td><span style=
                "text-decoration: underline;">95.45</span></td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.2</span> Experiment
            Results</h3>
          </div>
        </header>
        <p>Table <a class="tbl" href="#tab5">5</a> reports the
        performance of TOMN and baseline methods. Among the 18
        measures, TOMN achieves 13 best or second best results. It
        is better than SynTime which achieves 10 best or second
        best results, and much better than other baselines which
        achieve at most 4 best or second best results. For each
        measure, TOMN achieves either best results or comparable
        results. Especially for the <em>F</em> <sub>1</sub>, TOMN
        performs the best in strict <em>F</em> <sub>1</sub> on
        Tweets and in relaxed <em>F</em> <sub>1</sub> on WikiWars;
        for other <em>F</em> <sub>1</sub>, TOMN performs comparably
        (most are within 0.5% difference) to the corresponding best
        results.</p>
        <section id="sec-16">
          <p><em>5.2.1 TOMN vs. Baseline Methods.</em> We further
          compare TOMN with the rule-based methods and the
          learning-based methods.</p>
          <p><strong>TOMN vs. Rule-based Baselines.</strong> On
          TE-3 and Tweets, TOMN achieves comparable results with
          SynTime. On WikiWars, TOMN achieves the <em>F</em>
          <sub>1</sub> with 2.0% to 2.3% absolute increase over
          SynTime. This indicates that compared with SynTime, TOMN
          is equally effective on comprehensive data and more
          effective on specific domain data. The reason is that the
          heuristic rules of SynTime are greedy for recalls at the
          cost of precisions, and the cost is expensive when it
          comes to specific domain data. TOMN instead leverages
          statistical information from entire corpus, which may
          miss the rare time expressions but helps recognize time
          expressions more precisely; especially in specific domain
          data, the statistical information significantly improves
          the precisions at little cost of recalls. For HeidelTime
          and SUTime, except the strict <em>F</em> <sub>1</sub> on
          WikiWars, TOMN outperforms them on all the datasets, with
          up to 15.3% absolute increase in recalls and up to 12.0%
          absolute increase in <em>F</em> <sub>1</sub>. The reason
          is that the deterministic rules of HeidelTime and SUTime
          are designed in fixed manner, which lacks flexibility
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0047">47</a>].</p>
          <p><strong>TOMN vs. Learning-based Baselines.</strong>
          Except the strict <em>F</em> <sub>1</sub> on WikiWars,
          TOMN outperforms ClearTK and UWTime on all three datasets
          in all the recalls and <em>F</em> <sub>1</sub>.
          Especially on TE-3 and Tweets datasets, TOMN improves the
          recalls by at least 9.8% in strict match and at least
          5.1% in relaxed match, and improves the <em>F</em>
          <sub>1</sub> by at least 8.5% in strict match and at
          least 3.1% in relaxed match. The reasons are that the
          fixed linguistic structure predefined in UWTime cannot
          fully capture the loose structure of time expressions,
          the BIO scheme used in ClearTK reduces the predictive
          power of time tokens, and some of their features (e.g.,
          syntactic dependency) actually hurt the modeling. For the
          strict <em>F</em> <sub>1</sub> on WikiWars, TOMN performs
          slightly worse than the two learning-based methods
          because like SynTime, TOMN follows TimeBank and SynTime
          to exclude the prepositions (except ‘of’) from time
          expressions while some time expressions in WikiWars
          include these prepositions.</p>
        </section>
        <section id="sec-17">
          <header>
            <div class="title-info">
              <h4><span class="section-number">5.2.2</span>
              Cross-dataset Performance</h4>
            </div>
          </header>
          <div class="table-responsive" id="tab6">
            <div class="table-caption">
              <span class="table-number">Table 6:</span>
              <span class="table-title">Cross-dataset performance
              on the test set of <strong>TE-3</strong>. ‘Training’
              indicates the dataset whose training set is used for
              training. Color background indicates single-dataset
              results.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:center;">
                  <strong>Training</strong></th>
                  <th style="text-align:center;">
                  <strong>Method</strong></th>
                  <th colspan="3" style="text-align:center;">
                    <strong>Strict Match</strong>
                    <hr />
                  </th>
                  <th colspan="3" style="text-align:center;">
                    <strong>Relaxed Match</strong>
                    <hr />
                  </th>
                </tr>
                <tr>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"><em>Pr</em>.</th>
                  <th style="text-align:center;"><em>Re</em>.</th>
                  <th style="text-align:center;"><em>F</em>
                  <sub>1</sub></th>
                  <th style="text-align:center;"><em>Pr</em>.</th>
                  <th style="text-align:center;"><em>Re</em>.</th>
                  <th><em>F</em> <sub>1</sub></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">ClearTK</td>
                  <td style="text-align:center;">85.90</td>
                  <td style="text-align:center;">79.70</td>
                  <td style="text-align:center;">82.70</td>
                  <td style="text-align:center;">93.75</td>
                  <td style="text-align:center;">86.96</td>
                  <td>90.23</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">UWTime</td>
                  <td style="text-align:center;">86.10</td>
                  <td style="text-align:center;">80.40</td>
                  <td style="text-align:center;">83.10</td>
                  <td style="text-align:center;">94.60</td>
                  <td style="text-align:center;">88.40</td>
                  <td>91.40</td>
                </tr>
                <tr>
                  <td style="text-align:center;">TE-3</td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">
                  <strong>92.59</strong></td>
                  <td style="text-align:center;">
                  <strong>90.58</strong></td>
                  <td style="text-align:center;">
                  <strong>91.58</strong></td>
                  <td style="text-align:center;">
                  <strong>95.56</strong></td>
                  <td style="text-align:center;">
                  <strong>93.48</strong></td>
                  <td><strong>94.51</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;">WikiWars</td>
                  <td style="text-align:center;">ClearTK</td>
                  <td style="text-align:center;">65.67</td>
                  <td style="text-align:center;">63.77</td>
                  <td style="text-align:center;">64.71</td>
                  <td style="text-align:center;">87.31</td>
                  <td style="text-align:center;">84.78</td>
                  <td>86.03</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">UWTime</td>
                  <td style="text-align:center;">76.92</td>
                  <td style="text-align:center;">72.46</td>
                  <td style="text-align:center;">74.63</td>
                  <td style="text-align:center;">88.46</td>
                  <td style="text-align:center;">83.33</td>
                  <td>85.82</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">
                  <strong>84.06</strong></td>
                  <td style="text-align:center;">
                  <strong>84.06</strong></td>
                  <td style="text-align:center;">
                  <strong>84.06</strong></td>
                  <td style="text-align:center;">
                  <strong>93.48</strong></td>
                  <td style="text-align:center;">
                  <strong>93.48</strong></td>
                  <td><strong>93.48</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;">Tweets</td>
                  <td style="text-align:center;">ClearTK</td>
                  <td style="text-align:center;">72.59</td>
                  <td style="text-align:center;">71.01</td>
                  <td style="text-align:center;">71.79</td>
                  <td style="text-align:center;">
                  <strong>93.33</strong></td>
                  <td style="text-align:center;">91.30</td>
                  <td>92.31</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">UWTime</td>
                  <td style="text-align:center;">80.00</td>
                  <td style="text-align:center;">72.46</td>
                  <td style="text-align:center;">76.05</td>
                  <td style="text-align:center;">92.80</td>
                  <td style="text-align:center;">84.06</td>
                  <td>88.21</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">
                  <strong>85.42</strong></td>
                  <td style="text-align:center;">
                  <strong>89.13</strong></td>
                  <td style="text-align:center;">
                  <strong>87.23</strong></td>
                  <td style="text-align:center;">91.67</td>
                  <td style="text-align:center;">
                  <strong>95.65</strong></td>
                  <td><strong>93.62</strong></td>
                </tr>
              </tbody>
            </table>
          </div><br />
          <br />
          <div class="table-responsive" id="tab7">
            <div class="table-caption">
              <span class="table-number">Table 7:</span>
              <span class="table-title">Cross-dataset performance
              on test set of <strong>WikiWars</strong>.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:center;">
                  <strong>Training</strong></th>
                  <th style="text-align:center;">
                  <strong>Method</strong></th>
                  <th colspan="3" style="text-align:center;">
                    <strong>Strict Match</strong>
                    <hr />
                  </th>
                  <th colspan="3" style="text-align:center;">
                    <strong>Relaxed Match</strong>
                    <hr />
                  </th>
                </tr>
                <tr>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"><em>Pr</em>.</th>
                  <th style="text-align:center;"><em>Re</em>.</th>
                  <th style="text-align:center;"><em>F</em>
                  <sub>1</sub></th>
                  <th style="text-align:center;"><em>Pr</em>.</th>
                  <th style="text-align:center;"><em>Re</em>.</th>
                  <th><em>F</em> <sub>1</sub></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:center;">TE-3</td>
                  <td style="text-align:center;">ClearTK</td>
                  <td style="text-align:center;">74.38</td>
                  <td style="text-align:center;">60.76</td>
                  <td style="text-align:center;">66.89</td>
                  <td style="text-align:center;">
                  <strong>97.54</strong></td>
                  <td style="text-align:center;">79.68</td>
                  <td>87.71</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">UWTime</td>
                  <td style="text-align:center;">
                  <strong>87.01</strong></td>
                  <td style="text-align:center;">
                  <strong>79.34</strong></td>
                  <td style="text-align:center;">
                  <strong>83.00</strong></td>
                  <td style="text-align:center;">96.07</td>
                  <td style="text-align:center;">87.60</td>
                  <td>91.64</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">82.18</td>
                  <td style="text-align:center;">75.65</td>
                  <td style="text-align:center;">79.07</td>
                  <td style="text-align:center;">96.26</td>
                  <td style="text-align:center;">
                  <strong>87.93</strong></td>
                  <td><strong>91.90</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">ClearTK</td>
                  <td style="text-align:center;">87.69</td>
                  <td style="text-align:center;">80.28</td>
                  <td style="text-align:center;">
                  <strong>83.82</strong></td>
                  <td style="text-align:center;">96.80</td>
                  <td style="text-align:center;">90.54</td>
                  <td>93.56</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">UWTime</td>
                  <td style="text-align:center;">
                  <strong>87.70</strong></td>
                  <td style="text-align:center;">78.80</td>
                  <td style="text-align:center;">83.00</td>
                  <td style="text-align:center;">
                  <strong>97.60</strong></td>
                  <td style="text-align:center;">87.60</td>
                  <td>92.30</td>
                </tr>
                <tr>
                  <td style="text-align:center;">WikiWars</td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">84.57</td>
                  <td style="text-align:center;">
                  <strong>80.48</strong></td>
                  <td style="text-align:center;">82.47</td>
                  <td style="text-align:center;">96.23</td>
                  <td style="text-align:center;">
                  <strong>92.35</strong></td>
                  <td><strong>94.25</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;">Tweets</td>
                  <td style="text-align:center;">ClearTK</td>
                  <td style="text-align:center;">57.75</td>
                  <td style="text-align:center;">54.73</td>
                  <td style="text-align:center;">56.20</td>
                  <td style="text-align:center;">91.93</td>
                  <td style="text-align:center;">87.12</td>
                  <td><strong>89.46</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">UWTime</td>
                  <td style="text-align:center;">
                  <strong>80.28</strong></td>
                  <td style="text-align:center;">62.81</td>
                  <td style="text-align:center;">
                  <strong>70.48</strong></td>
                  <td style="text-align:center;">
                  <strong>94.37</strong></td>
                  <td style="text-align:center;">73.83</td>
                  <td>82.84</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">60.29</td>
                  <td style="text-align:center;">
                  <strong>66.00</strong></td>
                  <td style="text-align:center;">63.02</td>
                  <td style="text-align:center;">84.74</td>
                  <td style="text-align:center;">
                  <strong>92.76</strong></td>
                  <td>88.57</td>
                </tr>
              </tbody>
            </table>
          </div><br />
          <br />
          <div class="table-responsive" id="tab8">
            <div class="table-caption">
              <span class="table-number">Table 8:</span>
              <span class="table-title">Cross-dataset performance
              on the test set of <strong>Tweets</strong>.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:center;">
                  <strong>Training</strong></th>
                  <th style="text-align:center;">
                  <strong>Method</strong></th>
                  <th colspan="3" style="text-align:center;">
                    <strong>Strict Match</strong>
                    <hr />
                  </th>
                  <th colspan="3" style="text-align:center;">
                    <strong>Relaxed Match</strong>
                    <hr />
                  </th>
                </tr>
                <tr>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"><em>Pr</em>.</th>
                  <th style="text-align:center;"><em>Re</em>.</th>
                  <th style="text-align:center;"><em>F</em>
                  <sub>1</sub></th>
                  <th style="text-align:center;"><em>Pr</em>.</th>
                  <th style="text-align:center;"><em>Re</em>.</th>
                  <th><em>F</em> <sub>1</sub></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:center;">TE-3</td>
                  <td style="text-align:center;">ClearTK</td>
                  <td style="text-align:center;">81.16</td>
                  <td style="text-align:center;">47.26</td>
                  <td style="text-align:center;">59.73</td>
                  <td style="text-align:center;">
                  <strong>97.10</strong></td>
                  <td style="text-align:center;">56.54</td>
                  <td>71.47</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">UWTime</td>
                  <td style="text-align:center;">89.66</td>
                  <td style="text-align:center;">65.82</td>
                  <td style="text-align:center;">75.91</td>
                  <td style="text-align:center;">94.83</td>
                  <td style="text-align:center;">69.62</td>
                  <td>80.29</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">
                  <strong>92.92</strong></td>
                  <td style="text-align:center;">
                  <strong>88.61</strong></td>
                  <td style="text-align:center;">
                  <strong>90.71</strong></td>
                  <td style="text-align:center;">96.90</td>
                  <td style="text-align:center;">
                  <strong>92.41</strong></td>
                  <td><strong>94.60</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;">WikiWars</td>
                  <td style="text-align:center;">ClearTK</td>
                  <td style="text-align:center;">72.48</td>
                  <td style="text-align:center;">45.57</td>
                  <td style="text-align:center;">55.96</td>
                  <td style="text-align:center;">95.30</td>
                  <td style="text-align:center;">59.92</td>
                  <td>73.58</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">UWTime</td>
                  <td style="text-align:center;">
                  <strong>87.43</strong></td>
                  <td style="text-align:center;">61.60</td>
                  <td style="text-align:center;">72.28</td>
                  <td style="text-align:center;">
                  <strong>95.81</strong></td>
                  <td style="text-align:center;">67.61</td>
                  <td>79.21</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">85.00</td>
                  <td style="text-align:center;">
                  <strong>86.08</strong></td>
                  <td style="text-align:center;">
                  <strong>85.53</strong></td>
                  <td style="text-align:center;">93.75</td>
                  <td style="text-align:center;">
                  <strong>94.94</strong></td>
                  <td><strong>94.34</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">ClearTK</td>
                  <td style="text-align:center;">86.83</td>
                  <td style="text-align:center;">75.11</td>
                  <td style="text-align:center;">80.54</td>
                  <td style="text-align:center;">96.59</td>
                  <td style="text-align:center;">83.54</td>
                  <td>89.59</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">UWTime</td>
                  <td style="text-align:center;">88.36</td>
                  <td style="text-align:center;">70.76</td>
                  <td style="text-align:center;">78.59</td>
                  <td style="text-align:center;">
                  <strong>97.88</strong></td>
                  <td style="text-align:center;">78.39</td>
                  <td>87.06</td>
                </tr>
                <tr>
                  <td style="text-align:center;">Tweets</td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">
                  <strong>90.69</strong></td>
                  <td style="text-align:center;">
                  <strong>94.51</strong></td>
                  <td style="text-align:center;">
                  <strong>92.56</strong></td>
                  <td style="text-align:center;">93.52</td>
                  <td style="text-align:center;">
                  <strong>97.47</strong></td>
                  <td><strong>95.45</strong></td>
                </tr>
              </tbody>
            </table>
          </div>
          <p>We conduct cross-dataset experiments and compare TOMN
          with the learning-based methods that require training.
          Specifically, a method is trained on the training set of
          one dataset and then tested on the test sets of other
          datasets. Since the three datasets used in our
          experiments are quite diverse, the cross-dataset
          experiments on the three datasets therefore can evaluate
          a learning method's robustness. Table <a class="tbl"
          href="#tab6">6</a> reports the cross-dataset performance
          on TE-3; Table <a class="tbl" href="#tab7">7</a> reports
          the performance on WikiWars; and Table <a class="tbl"
          href="#tab8">8</a> on Tweets. For comparison, Table
          <a class="tbl" href="#tab6">6</a>, <a class="tbl" href=
          "#tab7">7</a>, and <a class="tbl" href="#tab8">8</a> also
          report the performance on single-dataset;
          ‘single-dataset’ here means the training set and the test
          set belong to the same dataset. The single-dataset
          results are reported directly from Table <a class="tbl"
          href="#tab5">5</a>.</p>
          <p>On (the test set of) TE-3, TOMN achieves at least
          84.0% in strict <em>F</em> <sub>1</sub> and at least
          93.4% in relaxed <em>F</em> <sub>1</sub>. (See the rows
          of WikiWars and Tweets in Table <a class="tbl" href=
          "#tab6">6</a>.) On Tweets, TOMN achieves at least 85.5%
          and 94.3% respectively. (See the rows of TE-3 and
          WikiWars in Table <a class="tbl" href="#tab8">8</a>.) It
          significantly outperforms ClearTK and UWTime. On
          WikiWars, TOMN achieves comparable results with ClearTK
          and UWTime in relaxed match but performs worse than
          UWTime in strict match; especially when trained on
          Tweets, TOMN achieve only 63.0% in strict <em>F</em>
          <sub>1</sub>, 7.5% lower than the one of UWTime. (See the
          rows of TE-3 and Tweets in Table <a class="tbl" href=
          "#tab7">7</a>.) Tweets contains many short time
          expressions (62.9% one-word time expressions) and uses
          fewer modifiers and numerals in time expressions while
          WikiWars includes quite a few long time expressions (only
          36.2% one-word time expressions) and some descriptive
          time expressions. For these reasons, TOMN trained on
          Tweets cannot fully recognize the long and descriptive
          time expressions in WikiWars. UWTime instead predefines
          linguistic structure, which contributes significantly to
          exact recognition of those long and descriptive time
          expressions.</p>
          <p>Look at the single-dataset and cross-dataset
          performance in relaxed match. TOMN achieves similar
          performance, regardless of which dataset it is trained
          on; in relaxed <em>F</em> <sub>1</sub>, TOMN achieves
          about 93.9% on TE-3, about 91.6% on WikiWars, and about
          94.8% on Tweets. By contrast, ClearTK and UWTime perform
          well on single-dataset but much worse on cross-dataset;
          especially on Tweets, their relaxed <em>F</em>
          <sub>1</sub> drops from at least 87.0% when trained on
          Tweets to at most 80.3% when trained on other datasets.
          This indicates that TOMN is much more robust than ClearTK
          and UWTime.</p>
          <p>The robustness of TOMN can be explained by Finding
          <a class="enc" href="#enc2">2</a> and Property <a class=
          "enc" href="#enc4">2</a>. Finding <a class="enc" href=
          "#enc2">2</a> indicates that time tokens are capable of
          predicting time expressions and Property <a class="enc"
          href="#enc4">2</a> indicates that time expressions highly
          overlap at their time tokens within individual dataset
          and across different datasets. That means, the time
          tokens from one dataset can help recognize the time
          tokens from other datasets. Therefore, in terms of
          relaxed match, the cross-dataset performance should be
          comparable to the single-dataset performance.</p>
        </section>
        <section id="sec-18">
          <p><em>5.2.3 Factor Analysis.</em> We conduct experiments
          to analyze the impact of the TOMN scheme as labeling tags
          and the features used in TOMN. The results are reported
          in Table <a class="tbl" href="#tab9">9</a>.</p>
          <div class="table-responsive" id="tab9">
            <div class="table-caption">
              <span class="table-number">Table 9:</span>
              <span class="table-title">Impact of factors. ‘BIO’
              denotes the systems that replace TOMN labeling tags
              by BIO tags while ‘BILOU’ denotes the systems that
              replace by BILOU tags. ‘<em>trad</em>’ indicates the
              traditional strategy for extraction while
              ‘<em>nono</em>’ indicates the non-O strategy. ‘ − ’
              indicates the kind of features removed from TOMN;
              ‘PreTag’ denotes the TOMN pre-tag features and
              ‘Lemma’ denotes the lemma features.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:center;">
                  <strong>Dataset</strong></th>
                  <th style="text-align:center;">
                  <strong>Method</strong></th>
                  <th colspan="3" style="text-align:center;">
                    <strong>Strict Match</strong>
                    <hr />
                  </th>
                  <th colspan="3" style="text-align:center;">
                    <strong>Relaxed Match</strong>
                    <hr />
                  </th>
                </tr>
                <tr>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"></th>
                  <th style="text-align:center;"><em>Pr</em>.</th>
                  <th style="text-align:center;"><em>Re</em>.</th>
                  <th style="text-align:center;"><em>F</em>
                  <sub>1</sub></th>
                  <th style="text-align:center;"><em>Pr</em>.</th>
                  <th style="text-align:center;"><em>Re</em>.</th>
                  <th><em>F</em> <sub>1</sub></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:center;">TE-3</td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">
                  <strong>92.59</strong></td>
                  <td style="text-align:center;">
                  <strong>90.58</strong></td>
                  <td style="text-align:center;">
                  <strong>91.58</strong></td>
                  <td style="text-align:center;">95.56</td>
                  <td style="text-align:center;">93.48</td>
                  <td><strong>94.51</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BIO
                  <sub><em>trad</em></sub></td>
                  <td style="text-align:center;">83.06</td>
                  <td style="text-align:center;">74.64</td>
                  <td style="text-align:center;">78.63</td>
                  <td style="text-align:center;">94.35</td>
                  <td style="text-align:center;">84.78</td>
                  <td>89.31</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BIO
                  <sub><em>nono</em></sub></td>
                  <td style="text-align:center;">84.68</td>
                  <td style="text-align:center;">76.09</td>
                  <td style="text-align:center;">80.15</td>
                  <td style="text-align:center;">94.35</td>
                  <td style="text-align:center;">84.78</td>
                  <td>89.31</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BILOU
                  <sub><em>trad</em></sub></td>
                  <td style="text-align:center;">84.75</td>
                  <td style="text-align:center;">72.46</td>
                  <td style="text-align:center;">78.12</td>
                  <td style="text-align:center;">94.92</td>
                  <td style="text-align:center;">81.16</td>
                  <td>87.50</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BILOU
                  <sub><em>nono</em></sub></td>
                  <td style="text-align:center;">86.44</td>
                  <td style="text-align:center;">73.91</td>
                  <td style="text-align:center;">79.69</td>
                  <td style="text-align:center;">94.92</td>
                  <td style="text-align:center;">81.16</td>
                  <td>87.50</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">− PreTag</td>
                  <td style="text-align:center;">89.36</td>
                  <td style="text-align:center;">60.87</td>
                  <td style="text-align:center;">72.41</td>
                  <td style="text-align:center;">
                  <strong>95.74</strong></td>
                  <td style="text-align:center;">65.22</td>
                  <td>77.59</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">− Lemma</td>
                  <td style="text-align:center;">81.56</td>
                  <td style="text-align:center;">83.33</td>
                  <td style="text-align:center;">82.44</td>
                  <td style="text-align:center;">92.20</td>
                  <td style="text-align:center;">
                  <strong>94.20</strong></td>
                  <td>93.19</td>
                </tr>
                <tr>
                  <td style="text-align:center;">WikiWars</td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">84.57</td>
                  <td style="text-align:center;">
                  <strong>80.48</strong></td>
                  <td style="text-align:center;">
                  <strong>82.47</strong></td>
                  <td style="text-align:center;">96.23</td>
                  <td style="text-align:center;">92.35</td>
                  <td><strong>94.25</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BIO
                  <sub><em>trad</em></sub></td>
                  <td style="text-align:center;">77.75</td>
                  <td style="text-align:center;">71.03</td>
                  <td style="text-align:center;">74.24</td>
                  <td style="text-align:center;">93.39</td>
                  <td style="text-align:center;">85.31</td>
                  <td>89.17</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BIO
                  <sub><em>nono</em></sub></td>
                  <td style="text-align:center;">77.75</td>
                  <td style="text-align:center;">71.03</td>
                  <td style="text-align:center;">74.24</td>
                  <td style="text-align:center;">93.39</td>
                  <td style="text-align:center;">85.31</td>
                  <td>89.17</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BILOU
                  <sub><em>trad</em></sub></td>
                  <td style="text-align:center;">79.56</td>
                  <td style="text-align:center;">72.03</td>
                  <td style="text-align:center;">75.61</td>
                  <td style="text-align:center;">93.56</td>
                  <td style="text-align:center;">84.71</td>
                  <td>88.91</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BILOU
                  <sub><em>nono</em></sub></td>
                  <td style="text-align:center;">79.78</td>
                  <td style="text-align:center;">72.23</td>
                  <td style="text-align:center;">75.82</td>
                  <td style="text-align:center;">93.56</td>
                  <td style="text-align:center;">84.71</td>
                  <td>88.91</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">− PreTag</td>
                  <td style="text-align:center;">
                  <strong>87.22</strong></td>
                  <td style="text-align:center;">70.02</td>
                  <td style="text-align:center;">77.68</td>
                  <td style="text-align:center;">
                  <strong>99.25</strong></td>
                  <td style="text-align:center;">79.68</td>
                  <td>88.39</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">− Lemma</td>
                  <td style="text-align:center;">74.80</td>
                  <td style="text-align:center;">75.25</td>
                  <td style="text-align:center;">75.03</td>
                  <td style="text-align:center;">92.20</td>
                  <td style="text-align:center;">
                  <strong>92.56</strong></td>
                  <td>92.28</td>
                </tr>
                <tr>
                  <td style="text-align:center;">Tweets</td>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:center;">90.69</td>
                  <td style="text-align:center;">94.51</td>
                  <td style="text-align:center;">
                  <strong>92.56</strong></td>
                  <td style="text-align:center;">93.52</td>
                  <td style="text-align:center;">97.47</td>
                  <td><strong>95.45</strong></td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BIO
                  <sub><em>trad</em></sub></td>
                  <td style="text-align:center;">89.16</td>
                  <td style="text-align:center;">93.67</td>
                  <td style="text-align:center;">91.36</td>
                  <td style="text-align:center;">92.37</td>
                  <td style="text-align:center;">97.05</td>
                  <td>94.65</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BIO
                  <sub><em>nono</em></sub></td>
                  <td style="text-align:center;">90.24</td>
                  <td style="text-align:center;">93.67</td>
                  <td style="text-align:center;">91.93</td>
                  <td style="text-align:center;">93.50</td>
                  <td style="text-align:center;">97.05</td>
                  <td>95.24</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BILOU
                  <sub><em>trad</em></sub></td>
                  <td style="text-align:center;">89.37</td>
                  <td style="text-align:center;">
                  <strong>95.78</strong></td>
                  <td style="text-align:center;">92.46</td>
                  <td style="text-align:center;">92.13</td>
                  <td style="text-align:center;">
                  <strong>98.73</strong></td>
                  <td>95.32</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">BILOU
                  <sub><em>nono</em></sub></td>
                  <td style="text-align:center;">90.65</td>
                  <td style="text-align:center;">94.09</td>
                  <td style="text-align:center;">92.34</td>
                  <td style="text-align:center;">93.50</td>
                  <td style="text-align:center;">97.06</td>
                  <td>95.24</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">− PreTag</td>
                  <td style="text-align:center;">
                  <strong>92.41</strong></td>
                  <td style="text-align:center;">61.60</td>
                  <td style="text-align:center;">73.92</td>
                  <td style="text-align:center;">
                  <strong>98.10</strong></td>
                  <td style="text-align:center;">65.40</td>
                  <td>78.48</td>
                </tr>
                <tr>
                  <td style="text-align:center;"></td>
                  <td style="text-align:center;">− Lemma</td>
                  <td style="text-align:center;">90.69</td>
                  <td style="text-align:center;">94.51</td>
                  <td style="text-align:center;">
                  <strong>92.56</strong></td>
                  <td style="text-align:center;">93.52</td>
                  <td style="text-align:center;">97.47</td>
                  <td><strong>95.45</strong></td>
                </tr>
              </tbody>
            </table>
          </div>
          <p><strong>Impact of TOMN Labeling Tags.</strong> To
          analyze the impact of the TOMN scheme as labeling tags,
          we keep all the features unchanged except change the
          labeling tags from TOMN scheme to BIO scheme to get a BIO
          system and to BILOU scheme to get a BILOU system. The BIO
          and BILOU systems use the same TOMN pre-tag features and
          lemma features that are used in TOMN.<a class="fn" href=
          "#fn11" id="foot-fn11"><sup>11</sup></a></p>
          <p>The tag assignment of BIO and BILOU schemes during
          feature extraction in the training stage follows their
          traditional use; for example, a unit-word time expression
          is assigned with B under BIO scheme while it is assigned
          with U under BILOU scheme. When extracting time
          expressions from tagged sequence in the test stage, we
          adopt two strategies. One strategy follows their
          traditional use in which time expressions are extracted
          according to the tags of words; for example, a U word
          under BILOU scheme is extracted as a time expression. The
          other strategy follows the one used for TOMN in which the
          non-O words that appear together are extracted as a time
          expression. The traditional strategy is denoted by
          ‘<em>trad</em>’ while the non-O strategy is by
          ‘<em>nono</em>.’ The results of the BIO and BILOU systems
          are reported as ‘BIO’ and ‘BILOU’ in Table <a class="tbl"
          href="#tab9">9</a>. We can see that the non-O strategy
          performs almost the same as the traditional strategy, and
          the BIO systems achieve comparable or slightly better
          results compared with the BILOU systems. The reason is
          that time expressions on average contain about two words
          (see Property <a class="enc" href="#enc3">1</a>); in that
          case, BILOU scheme is reduced approximately to BLOU
          scheme and BIO scheme is changed approximately to BLO
          scheme. Between BLOU scheme and BLO scheme there is only
          slight difference; and under the impact of inconsistent
          tag assignment and TOMN pre-tag features, this slight
          difference affects slightly to the performance. Following
          we do not distinguish BILOU scheme from BIO scheme and do
          not distinguish non-O strategy from traditional strategy;
          the four methods of BIO <sub><em>trad</em></sub> , BIO
          <sub><em>nono</em></sub> , BILOU <sub><em>trad</em></sub>
          , and BILOU <sub><em>nono</em></sub> are simply
          represented by ‘BILOU.’</p>
          <p>On TE-3 and WikiWars, TOMN significantly outperforms
          BILOU. TOMN achieves the recalls that are 7.0% to 14.5%
          absolute higher than those of BILOU and achieves the
          <em>F</em> <sub>1</sub> that are 5.0% to 11.4% absolute
          higher than those of BILOU. The reason is that the loose
          collocations and exchangeable order in time expressions
          lead BILOU scheme to suffer from the problem of
          inconsistent tag assignment; TOMN scheme instead
          overcomes that problem.</p>
          <p>On Tweets, TOMN and BILOU achieve similar performance;
          the difference between their performance ranges within 1%
          in most measures. The reason is that 62.9% of time
          expressions in Tweets are one-word time expressions and
          96.0% of time expressions contain time tokens (see
          Property <a class="enc" href="#enc3">1</a>); which means
          the one-word time expressions contain only the time
          tokens. In that case, TOMN scheme is reduced
          approximately to TO scheme and BILOU scheme is reduced
          approximately to UO scheme. Then UO scheme becomes a
          constituent-based tagging scheme in which U indicates the
          time token. It is equivalent to TO scheme. (BIO scheme is
          reduced approximately to BO scheme in which B indicates
          the time token. Then BO scheme is equivalent to TO scheme
          as well as UO scheme.)</p>
          <p><strong>Impact of TOMN Pre-tag Features.</strong> To
          analyze the impact of TOMN pre-tag features, we remove
          them from TOMN. After they are removed, although most of
          the precisions increase and even reach highest scores,
          all the recalls and <em>F</em> <sub>1</sub> drop
          dramatically, with absolute decreases of 10.4% to 32.9%
          in recall and 4.8% to 19.1% in <em>F</em> <sub>1</sub>.
          That means TOMN pre-tag features significantly improve
          the performance and confirms the predictive power of time
          tokens. The results also validate that pre-tag is a good
          way to use those lexicon.</p>
          <p><strong>Impact of Lemma Features.</strong> When lemma
          features are removed, the performance in relaxed match on
          all the datasets is affected slightly. The reason is that
          the TOMN pre-tag features provide useful information to
          recognize time tokens. The strict match on TE-3 and
          WikiWars decreases dramatically, which indicates that the
          lemma features heavily affect the recognition of
          modifiers and numerals. The strict match on Tweets is
          affected little because tweets tend not to use modifiers
          and numerals in time expressions.</p>
        </section>
        <section id="sec-19">
          <header>
            <div class="title-info">
              <h4><span class="section-number">5.2.4</span>
              Computational Efficiency</h4>
            </div>
          </header>
          <div class="table-responsive" id="tab10">
            <div class="table-caption">
              <span class="table-number">Table 10:</span>
              <span class="table-title">Running time that TOMN and
              the learning-based methods cost to go through a whole
              process (unit: seconds).</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:center;">
                  <strong>Method</strong></th>
                  <th style="text-align:right;">
                  <strong>TE-3</strong></th>
                  <th style="text-align:right;">
                  <strong>WikiWars</strong></th>
                  <th><strong>Tweets</strong></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:center;">ClearTK</td>
                  <td style="text-align:right;">152</td>
                  <td style="text-align:right;">223</td>
                  <td>86</td>
                </tr>
                <tr>
                  <td style="text-align:center;">UWTime</td>
                  <td style="text-align:right;">864</td>
                  <td style="text-align:right;">1,050</td>
                  <td>160</td>
                </tr>
                <tr>
                  <td style="text-align:center;">TOMN</td>
                  <td style="text-align:right;">36</td>
                  <td style="text-align:right;">48</td>
                  <td>42</td>
                </tr>
              </tbody>
            </table>
          </div>
          <p>HeidelTime and SUTime run nearly in real time; SynTime
          in real time. Table <a class="tbl" href="#tab10">10</a>
          reports the running time that TOMN and the learning-based
          methods cost to go through a whole process (including
          training and test) on the three datasets on a Mac OS
          laptop (1.4GHz Processor and 8GB Memory). We can see that
          TOMN is much more efficient than ClearTK and UWTime.
          Consider only the test, TOMN runs in real time.</p>
        </section>
      </section>
    </section>
    <section id="sec-20">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Discussion</h2>
        </div>
      </header>
      <p>The analysis of time expressions can explain a lot of
      empirical observations reported in other works about time
      expression recognition. UzZaman et al. report that using an
      extra large dataset does not improve the performance
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0042">42</a>]; Bethard
      reports that using TimeBank alone performs better than using
      TimeBank and AQUAINT datasets together [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0004">4</a>]; and Filannino et al.
      report that features of gazetteers, shallow parsing, and
      propositional noun phrases do not contribute significant
      improvement [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0015">15</a>].
      These observations can be explained by the findings and
      properties illustrated in Section <a class="sec" href=
      "#sec-4">3</a>. Finding <a class="enc" href="#enc1">1</a>,
      <a class="enc" href="#enc2">2</a> and Property <a class="enc"
      href="#enc4">2</a>, <a class="enc" href="#enc5">3</a>
      together suggest that additional gazetteers, large corpus,
      and more datasets provide no further useful information but
      repeated time tokens and their loose combinations, and that
      those syntactic features cannot provide extra useful
      information for a CRFs-based learning method to model time
      expressions.</p>
      <p>The analysis of tagging schemes can explain the empirical
      observations reported in other works about the impact of the
      BIO (or IOB2) and BILOU (or IOBES) schemes in named entity
      recognition (NER). Ratinov and Roth report that BILOU scheme
      outperforms BIO scheme on MUC-7 and CoNLL03 NER datasets
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0033">33</a>]; Dai et
      al. report that IOBES scheme performs better than IOB2 scheme
      in drug name recognition [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0013">13</a>]. When looking at their results,
      however, we find that the improvements are rather slight,
      most of them are within 1%; and in some cases, BIO scheme
      performs better than BILOU scheme. Lample et al. confirm that
      they do not observe significant improvement of IOBES scheme
      over IOB2 scheme on CoNLL03 NER dataset [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0020">20</a>]. These observations can
      be explained by our analysis of tagging schemes in Section
      <a class="sec" href="#sec-8">4.1</a> and <a class="sec" href=
      "#sec-18">5.2.3</a>. Basically, BIO and BILOU schemes are
      based on the position within the chunk and implicitly assume
      that target entities should be formed by fixed structure and
      even fixed collocations. But entities as part of language are
      actually flexible. When applied to entity recognition, the
      BIO and BILOU schemes would more or less suffer from the
      problem of <em>inconsistent tag assignment</em>. We analyze
      the named entities in CoNLL03 (English NER) dataset
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0034">34</a>] as an
      example. We find that for each of the CoNLL03 training,
      development, and test sets, more than 53.7% of distinct words
      appear in different positions within named entities; more
      than 93.7% of named entities each has at least one word not
      appearing in common text; and the named entities on average
      contain 1.45 words, with 63.2% one-word named entities. The
      percentage 53.7% is similar to the one of distinct time
      tokens in time expressions (53.5%; see Finding <a class="enc"
      href="#enc1">1</a>); the 93.7% is similar to the one of time
      expressions that contain time tokens (91.8%; see Finding
      <a class="enc" href="#enc2">2</a>); and the length
      distribution is similar to the one of time expressions in
      Tweets (see Property <a class="enc" href="#enc3">1</a>). That
      means named entities demonstrate common characteristics
      similar to time expressions. When modeling named entities,
      like modeling time expressions, the BIO and BILOU schemes
      would either suffer from the problem of inconsistent tag
      assignment or be roughly equivalent if they were reduced to
      the constituent-based BO and UO schemes. In either case, the
      difference between the two schemes impacts slightly.</p>
      <p>When analyzing the CoNLL03 dataset (which contains four
      entity types: PER, LOC, ORG, and MISC), we find that some
      named entities are annotated with different entity types. In
      the training set, for example, ‘Wimbledon’ is annotated 4
      times with LOC, 8 times with ORG, and 18 times with MISC.
      Such named entities (including several polysemy) in the
      training set, development set, and test set reach relatively
      high percentage of respective 6.9%, 4.4%, and 6.5%. The
      inconsistent annotation and inconsistent tag assignment may
      be able to explain why most state-of-the-art NER methods
      achieve the <em>F</em> <sub>1</sub> at around 94.5% on the
      development set and around 91.5% on the test set [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0012">12</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0020">20</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0024">24</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0025">25</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0029">29</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0033">33</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0046">46</a>], and why
      more than 10 years’ effort improves the <em>F</em>
      <sub>1</sub> by only 0.8% on the development set (from 2003’s
      93.9% [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0016">16</a>]
      to current 94.7% [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0025">25</a>]) and by only 2.9% on the test set
      (from 2003’s 88.7% [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0016">16</a>] to current 91.6% [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0012">12</a>]). The two inconsistency
      problems seem to limit the upper bound of the performance on
      development set at near 94.5% and the one on test set at near
      91.5%. This suggests that to further improve the performance
      on current CoNLL03 dataset with current methods is difficult
      and unreliable. Instead of continuing to fine-tune current
      methods, we should try to correct the inconsistent annotation
      and address the problem of inconsistent tag assignment.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Omar Alonso, Jannik
        Strotgen, Ricardo Baeza-Yates, and Michael Gertz. 2011.
        Temporal Information Retrieval: Challenges and
        Opportunities. In <em><em>Proceedings of 1st International
        Temporal Web Analytics Workshop</em></em> . 1–8.</li>
        <li id="BibPLXBIB0002" label="[2]">Gabor Angeli,
        Christopher&nbsp;D. Manning, and Daniel Jurafsky. 2012.
        Parsing Time: Learning to Interpret Time Expressions. In
        <em><em>Proceedings of 2012 Conference of the North
        American Chapter of the Association for Computational
        Linguistics: Human Language Technologies</em></em> .
        446–455.</li>
        <li id="BibPLXBIB0003" label="[3]">Gabor Angeli and Jakob
        Uszkoreit. 2013. Language-Independent Discriminative
        Parsing of Temporal Expressions. In <em><em>Proceedings of
        the 51st Annual Meeting of the Association for
        Computational Linguistics</em></em> . 83–92.</li>
        <li id="BibPLXBIB0004" label="[4]">Steven Bethard. 2013.
        ClearTK-TimeML: A minimalist approach to TempEval 2013. In
        <em><em>Proceedings of the 7th International Workshop on
        Semantic Evaluation</em></em> . 10–14.</li>
        <li id="BibPLXBIB0005" label="[5]">Steven Bethard, Leon
        Derczynski, Guergana Savova, James Pustejovsky, and Marc
        Verhagen. 2015. SemEval-2015 Task 6: Clinical TempEval. In
        <em><em>Proceedings of the 9th International Workshop on
        Semantic Evaluation</em></em> . 806–814.</li>
        <li id="BibPLXBIB0006" label="[6]">Steven Bethard, Guergana
        Savova, Wei-Te Chen, Leon Derczynski, James Pustejovsky,
        and Marc Verhagen. 2016. SemEval-2016 Task 12: Clinical
        TempEval. In <em><em>Proceedings of SemEval-2016</em></em>
        . 1052–1062.</li>
        <li id="BibPLXBIB0007" label="[7]">Steven Bethard, Guergana
        Savova, Martha Palmer, and James Pustejovsky. 2017.
        SemEval-2017 Task 12: Clinical TempEval. In
        <em><em>Proceedings of the 11th International Workshop on
        Semantic Evaluation</em></em> . 565–572.</li>
        <li id="BibPLXBIB0008" label="[8]">Ricardo Campos, Gael
        Dias, Alipio&nbsp;M. Jorge, and Adam Jatowt. 2014. Survey
        of temporal information retrieval and related applications.
        <em><em>Comput. Surveys</em></em> 47, 2 (2014),
        15:1–41.</li>
        <li id="BibPLXBIB0009" label="[9]">Angel&nbsp;X. Chang and
        Christopher&nbsp;D. Manning. 2012. SUTime: A Library for
        Recognizing and Normalizing Time Expressions. In
        <em><em>Proceedings of 8th International Conference on
        Language Resources and Evaluation</em></em> .
        3735–3740.</li>
        <li id="BibPLXBIB0010" label="[10]">Angel&nbsp;X. Chang and
        Christopher&nbsp;D. Manning. 2013. SUTime: Evaluation in
        TempEval-3. In <em><em>Proceedings of the Second Joint
        Conference on Lexical and Computational Semantics
        (SEM)</em></em> . 78–82.</li>
        <li id="BibPLXBIB0011" label="[11]">Nancy&nbsp;A. Chinchor.
        1997. MUC-7 Named Entity Task Definition. In
        <em><em>Proceedings of the 7th Message Understanding
        Conference</em></em> , Vol.&nbsp;29.</li>
        <li id="BibPLXBIB0012" label="[12]">Jason&nbsp;P.C. Chiu
        and Eric Nichols. 2016. Named Entity Recognition with
        Bidirectional LSTM-CNNs. <em><em>Transactions of the
        Association for Computational Linguistics</em></em> 4
        (2016), 357–370.</li>
        <li id="BibPLXBIB0013" label="[13]">Hong-Jie Dai, Po-Ting
        Lai, Yung-Chun Chang, and Richard Tzong-Han Tsai. 2015.
        Enhancing of chemical compound and drug name recognition
        using representative tag scheme and fine-grained
        tokenization. <em><em>Journal of Cheminformatics</em></em>
        7.S1, S14 (2015), 1–10.</li>
        <li id="BibPLXBIB0014" label="[14]">Lisa Ferro, L. Gerber,
        I. Mani, Beth Sundheim, and G. Wilson. 2005. <em><em>TIDES
        2005 Standard for the Annotation of Temporal
        Expressions</em></em> . Technical Report. MITRE.</li>
        <li id="BibPLXBIB0015" label="[15]">Michele Filannino,
        Gavin Brown, and Goran Nenadic. 2013. ManTIME: Temporal
        expression identification and normalization in the
        TempEval-3 challenge. In <em><em>Proceedings of the 7th
        International Workshop on Semantic Evaluation</em></em> .
        53–57.</li>
        <li id="BibPLXBIB0016" label="[16]">Radu Florian, Abe
        Ittycheriah, Hongyan Jing, and Tong Zhang. 2003. Named
        Entity Recognition through Classifier Combination. In
        <em><em>Proceedings of the 7th Conference on Natural
        Language Learning</em></em> . 168–171.</li>
        <li id="BibPLXBIB0017" label="[17]">Kadri Hacioglu, Ying
        Chen, and Benjamin Douglas. 2005. Automatic Time Expression
        Labeling for English and Chinese Text. In
        <em><em>Proceedings of the 6th International Conference on
        Intelligent Text Processing and Computational
        Linguistics</em></em> . 548–559.</li>
        <li id="BibPLXBIB0018" label="[18]">William F.&nbsp;Styler
        IV, Steven Bethard, Sean Finan, Martha Palmer, Sameer
        Pradhan, Piet&nbsp;C de Groen, Brad Erickson, Timothy
        Miller, Chen Lin, Guergana Savova, and James Pustejovsky.
        2014. Temporal Annotation in the Clinical Domain.
        <em><em>Transactions of the Association for Computational
        Linguistics</em></em> 2 (2014), 143–154.</li>
        <li id="BibPLXBIB0019" label="[19]">John Lafferty, Andrew
        McCallum, and Fernando Pereira. 2001. Conditional Random
        Fields: Probabilistic Models for Segmenting and Labeling
        Sequence Data. In <em><em>Proceedings of the 18th
        International Conference on Machine Learning</em></em> .
        281–289.</li>
        <li id="BibPLXBIB0020" label="[20]">Guillaume Lample,
        Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami,
        and Chris Dyer. 2016. Neural Architecture for Named Entity
        Recognition. In <em><em>Proceedings of the 15th Annual
        Conference of the North American Chapter of the Association
        for Computational Linguistics</em></em> . 260–270.</li>
        <li id="BibPLXBIB0021" label="[21]">Kenton Lee, Yoav Artzi,
        Jesse Dodge, and Luke Zettlemoyer. 2014. Context-dependent
        Semantic Parsing for Time Expressions. In
        <em><em>Proceedings of the 52th Annual Meeting of the
        Association for Computational Linguistics</em></em> .
        1437–1447.</li>
        <li id="BibPLXBIB0022" label="[22]">Hector Llorens, Leon
        Derczynski, Robert Gaizauskas, and Estela Saquete. 2012.
        TIMEN: An Open Temporal Expression Normalisation Resource.
        In <em><em>Proceedings of the 8th International Conference
        on Language Resources and Evaluation</em></em> .
        3044–3051.</li>
        <li id="BibPLXBIB0023" label="[23]">Hector Llorens, Estela
        Saquete, and Borja Navarro. 2010. TIPSem (English and
        Spanish): Evaluating CRFs and Semantic Roles in TempEval-2.
        In <em><em>Proceedings of the 5th International Workshop on
        Semantic Evaluation</em></em> . 284–291.</li>
        <li id="BibPLXBIB0024" label="[24]">Gang Luo, Xiaojiang
        Huang, Chin-Yew Lin, and Zaiqing Nie. 2015. Joint Named
        Entity Recognition and Disambiguation. In
        <em><em>Proceedings of the 2005 Conference on Empirical
        Methods in Natural Language Processing</em></em> .
        879–888.</li>
        <li id="BibPLXBIB0025" label="[25]">Xuezhe Ma and Eduard
        Hovy. 2016. End-to-end Sequence Labeling via Bi-directional
        LSTM-CNNs-CRF. In <em><em>Proceedings of the 54th Annual
        Meeting of the Association for Computational Linguistics
        (Volume 1: Long Papers)</em></em> . 1064–1074.</li>
        <li id="BibPLXBIB0026" label="[26]">Inderjeet Mani and
        George Wilson. 2000. Robust Temporal Processing of News. In
        <em><em>Proceedings of the 38th annual meeting on
        Association for Computational Linguistics.</em></em>
        69–76.</li>
        <li id="BibPLXBIB0027" label="[27]">Pawel Mazur and Robert
        Dale. 2010. WikiWars: A New Corpus for Research on Temporal
        Expressions. In <em><em>Proceedings of the 2010 Conference
        on Empirical Methods in Natural Language
        Processing</em></em> . 913–922.</li>
        <li id="BibPLXBIB0028" label="[28]">Robert Parker, David
        Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2011.
        Engilish Gigaword Fifth Edition. (2011).</li>
        <li id="BibPLXBIB0029" label="[29]">Alexandre Passos,
        Vineet Kumar, and Andrew McCallum. 2014. Lexicon Infused
        Phrase Embeddings for Named Entity Resolution. In
        <em><em>Proceedings of the 8th Conference on Computational
        Language Learning</em></em> . 78–86.</li>
        <li id="BibPLXBIB0030" label="[30]">James Pustejovsky, Jose
        Castano, Robert Ingria, Roser Sauri, Robert Gaizauskas,
        Andrea Setzer, Graham Katz, and Dragomir Radev. 2003.
        TimeML: Robust Specification of Event and Temporal
        Expressions in Text. <em><em>New Directions in Question
        Answering</em></em> 3 (2003), 28–34.</li>
        <li id="BibPLXBIB0031" label="[31]">James Pustejovsky,
        Patrick Hanks, Roser Sauri, Andrew See, Robert Gaizauskas,
        Andrea Setzer, Beth Sundheim, Dragomir Radev, David Day,
        Lisa Ferro, and Marcia Lazo. 2003. The TIMEBANK Corpus.
        <em><em>Corpus Linguistics</em></em> 2003(2003),
        647–656.</li>
        <li id="BibPLXBIB0032" label="[32]">James Pustejovsky,
        Kiyong Lee, Harry Bunt, and Laurent Romary. 2010.
        ISO-TimeML: An International Standard for Semantic
        Annotation. In <em><em>Proceedings of the Seventh
        conference on International Language Resouces and
        Evaluation (LREC’10)</em></em> . 394–397.</li>
        <li id="BibPLXBIB0033" label="[33]">Lev Ratinov and Dan
        Roth. 2009. Design Challenges and Misconceptions in Named
        Entity Recognition. In <em><em>Proceedings of the
        Thirteenth Conference on Computational Natural Language
        Learning</em></em> . 147–155.</li>
        <li id="BibPLXBIB0034" label="[34]">Erik F. Tjong&nbsp;Kim
        Sang and Fien&nbsp;De Meulder. 2003. Introduction to the
        CoNLL-2003 Shared Task: Language-Independent Named Entity
        Recognition. In <em><em>Proceedings of the 7th Conference
        on Natural Language Learning</em></em> . 142–147.</li>
        <li id="BibPLXBIB0035" label="[35]">Erik F. Tjong&nbsp;Kim
        Sang and Jorn Veenstra. 1999. Representing Text Chunks. In
        <em><em>Proceedings of the ninth Conference on European
        Chapter of the Association for Computational
        Linguistics</em></em> . 173–179.</li>
        <li id="BibPLXBIB0036" label="[36]">Mark Steedman. 1996.
        <em><em>Surface Structure and Interpretation</em></em> .
        The MIT Press.</li>
        <li id="BibPLXBIB0037" label="[37]">S.&nbsp;S. Stevens.
        1946. On the Theory of Scales of Measurement.
        <em><em>Science</em></em> 103, 2684 (1946), 677–680.</li>
        <li id="BibPLXBIB0038" label="[38]">Jannik Strötgen, Thomas
        Bogel, Julian Zell, Ayser Armiti, Tran&nbsp;Van Canh, and
        Michael Gertz. 2014. Extending HeidelTime for Temporal
        Expressions Referring to Historic Dates. In
        <em><em>Proceedings of the 9th International Conference on
        Language Resources and Evaluation</em></em> .
        2390–2397.</li>
        <li id="BibPLXBIB0039" label="[39]">Jannik Strötgen and
        Michael Gertz. 2010. HeidelTime: High Quality Rule-based
        Extraction and Normalization of Temporal Expressions. In
        <em><em>Proceedings of the 5th International Workshop on
        Semantic Evaluation (SemEval’10)</em></em> . Association
        for Computational Linguistics, Stroudsburg, PA, USA,
        321–324.</li>
        <li id="BibPLXBIB0040" label="[40]">Jannik Strötgen, Julian
        Zell, and Michael Gertz. 2013. HeidelTime: Tuning English
        and Developing Spanish Resources. In <em><em>Proceedings of
        the Second Joint Conference on Lexical and Computational
        Semantics (SEM)</em></em> . 15–19.</li>
        <li id="BibPLXBIB0041" label="[41]">Naushad UzZaman and
        James&nbsp;F. Allen. 2010. TRIPS and TRIOS System for
        TempEval-2: Extracting Temporal Information from Text. In
        <em><em>Proceedings of the 5th International Workshop on
        Semantic Evaluation</em></em> . 276–283.</li>
        <li id="BibPLXBIB0042" label="[42]">Naushad UzZaman, Hector
        Llorens, Leon Derczynski, Marc Verhagen, James Allen, and
        James Pustejovsky. 2013. SemEval-2013 Task 1: TempEval-3:
        Evaluating Time Expressions, Events, and Temporal
        Relations. In <em><em>Proceedings of the 7th International
        Workshop on Semantic Evaluation</em></em> . 1–9.</li>
        <li id="BibPLXBIB0043" label="[43]">Marc Verhagen, Robert
        Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz, and
        James Pustejovsky. 2007. SemEval-2007 Task 15: TempEval
        Temporal Relation Identification. In <em><em>Proceedings of
        the 4th International Workshop on Semantic
        Evaluation</em></em> . 75–80.</li>
        <li id="BibPLXBIB0044" label="[44]">Marc Verhagen,
        Inderjeet Mani, Roser Sauri, Robert Knippen, Seok&nbsp;Bae
        Jang, Jessica Littman, Anna Rumshisky, John Phillips,
        Inderjeet Mani, Roser Sauri, Robert Knippen, Seok&nbsp;Bae
        Jang, Jessica Littman, Anna Rumshisky, John Phillips, and
        James Pustejovsky. 2005. Automating Temporal Annotation
        with TARQI. In <em><em>Proceedings of the ACL Interactive
        Poster and Demonstration Sessions.</em></em> 81–84.</li>
        <li id="BibPLXBIB0045" label="[45]">Marc Verhagen, Roser
        Sauri, Tommaso Caselli, and James Pustejovsky. 2010.
        SemEval-2010 Task 13: TempEval-2. In <em><em>Proceedings of
        the 5th International Workshop on Semantic
        Evaluation</em></em> . 57–62.</li>
        <li id="BibPLXBIB0046" label="[46]">Mingbin Xu, Hui Jiang,
        and Sedtawut Watcharawittayakul. 2017. A Local Detection
        Approach for Named Entity Recognition and Mention
        Detection. In <em><em>Proceedings of the 55th Annual
        Meeting of the Association for Computational
        Linguistics</em></em> . 1237–1247.</li>
        <li id="BibPLXBIB0047" label="[47]">Xiaoshi Zhong, Aixin
        Sun, and Erik Cambria. 2017. Time Expression Analysis and
        Recognition Using Syntactic Token Types and General
        Heuristic Rules. In <em><em>Proceedings of the 55th Annual
        Meeting of the Association for Computational
        Linguistics</em></em> . 420–429.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>‘TOMN’ denotes
    our method and ‘TOMN scheme’ denotes the tagging scheme that
    TOMN defines.</p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>The definition
    of inconsistent tag assignment can be generalized as that
    during training, a unit in different labeled instances is
    assigned with different tags for some reason while the unit
    should be consistently assigned with the same tag. The unit of
    interest can be a word, a relation, a webpage, or a group of
    words as a whole, etc.</p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>We follow
    [<a class="bib" data-trigger="hover" data-toggle="popover"
    data-placement="top" href="#BibPLXBIB0047">47</a>] not to use
    the Gigaword dataset in our experiments because its labels are
    automatically generated by other taggers but not the ground
    truth.</p>
    <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>One of Zhong et
    al. concluded properties is incorporated into our Finding
    <a class="enc" href="#enc2">2</a>.</p>
    <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>The BIO scheme
    in this paper denotes the standard IOB2 scheme described in
    [<a class="bib" data-trigger="hover" data-toggle="popover"
    data-placement="top" href="#BibPLXBIB0035">35</a>].</p>
    <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a>The BILOU
    scheme is also widely known as the IOBES scheme.</p>
    <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a><a class=
    "link-inline force-break" href=
    "https://github.com/stanfordnlp/CoreNLP/tree/master/src/edu/stanford/nlp/time/rules">https://github.com/stanfordnlp/CoreNLP/tree/master/src/edu/stanford/nlp/time/rules</a></p>
    <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a><a class=
    "link-inline force-break" href=
    "http://nlp.stanford.edu/software/tagger.shtml">http://nlp.stanford.edu/software/tagger.shtml</a></p>
    <p id="fn9"><a href="#foot-fn9"><sup>9</sup></a><a class=
    "link-inline force-break" href=
    "http://www.chokkan.org/software/crfsuite/">http://www.chokkan.org/software/crfsuite/</a></p>
    <p id="fn10"><a href="#foot-fn10"><sup>10</sup></a><a class=
    "link-inline force-break" href=
    "http://www.cs.rochester.edu/~naushad/tempeval3/tools.zip">http://www.cs.rochester.edu/~naushad/tempeval3/tools.zip</a></p>
    <p id="fn11"><a href="#foot-fn11"><sup>11</sup></a>The BIO and
    BILOU schemes can be extracted with other features, but we
    using the BIO and BILOU schemes here is to conduct controlled
    experiments to analyze the impact of TOMN scheme as labeling
    tags. So we extract the same features in TOMN to the BIO and
    BILOU schemes.</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3178876.3185997">https://doi.org/10.1145/3178876.3185997</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
