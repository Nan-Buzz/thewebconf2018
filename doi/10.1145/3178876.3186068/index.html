<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Query Suggestion with Feedback Memory Network</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186068'>https://doi.org/10.1145/3178876.3186068</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186068'>https://w3id.org/oa/10.1145/3178876.3186068</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Query Suggestion with Feedback
          Memory Network</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Bin</span> <span class=
          "surName">Wu<a class="fn" href="#fn1" id=
          "foot-fn1"><sup>⁎</sup></a></span>, Tsinghua University,
          <a href=
          "mailto:wub16@mails.tsinghua.edu.cn">wub16@mails.tsinghua.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Chenyan</span> <span class=
          "surName">Xiong<a class="fn" href="#fn1" id=
          "foot-fn1"><sup>⁎</sup></a></span>, Carnegie Mellon
          University, <a href=
          "mailto:cx@cs.cmu.edu">cx@cs.cmu.edu</a>
        </div>
        <div class="author">
          <span class="givenName">Maosong</span> <span class=
          "surName">Sun<a class="fn" href="#fn2" id=
          "foot-fn2"><sup>†</sup></a></span>, Tsinghua University,
          <a href=
          "mailto:sms@mail.tsinghua.edu.cn">sms@mail.tsinghua.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Zhiyuan</span> <span class=
          "surName">Liu</span>, Tsinghua University, <a href=
          "mailto:liuzy@tsinghua.edu.cn">liuzy@tsinghua.edu.cn</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.3186068"
        target=
        "_blank">https://doi.org/10.1145/3178876.3186068</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>This paper presents Feedback Memory Network
        (<tt>FMN</tt>) which models user interactions with the
        search engine for query suggestion. Besides modeling the
        queries issued by the user, <tt>FMN</tt> also considers
        user feedback on the search results. It converts user
        browsing and click actions to the attention over the
        top-ranked documents and combines them into the feedback
        memories of the query, thus better models the underlying
        information needs. The feedback memories and the query
        sequence are then combined to suggest queries by the
        sequence-to-sequence neural network. Modeling user feedback
        makes it possible to suggest diverse queries for the same
        query sequence, if users have preferred different search
        results that indicate different information needs. Our
        experiments on the search log from a Chinese commercial
        search engine showed the stable and robust advantages of
        <tt>FMN</tt>. Especially when the feedback is richer or
        more informative, <tt>FMN</tt> provides more diverse and
        accurate suggestions, which is exceptionally helpful for
        ambiguous sessions where more information is required to
        infer the search intents.</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Query
          Suggestion</small>,</span> <span class=
          "keyword"><small>Feedback Memory Network</small>,</span>
          <span class="keyword"><small>User Modeling</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Bin Wu*, Chenyan Xiong, Maosong Sun, and Zhiyuan Liu.
          2018. Query Suggestion with Feedback Memory Network. In
          <em>WWW 2018: The 2018 Web Conference,</em> <em>April
          23–27, 2018,</em> <em>Lyon, France. ACM, New York, NY,
          USA</em> 9 Pages. <a href=
          "https://doi.org/10.1145/3178876.3186068" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3178876.3186068</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>In modern information retrieval, a session of multiple
      queries is often required to complete a search task:
      precisely expressing the information need in a short ad hoc
      query sometimes can be tricky; the search engine may fail to
      provide relevant search results for the query; the user may
      decide to further explore the topic after browsing the
      initial search results. Query suggestion techniques, which
      provide query auto-completion, refinements, and related
      queries, have been widely adopted by search engines to
      facilitate this information seeking process and improve user
      satisfaction&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>].</p>
      <p>A successful query suggestion depends on modeling the
      user's information needs accurately. The information needs
      are reflected by the user's interactions with the search
      engine in the session: the <em>query sequence</em> she
      issued, and the <em>feedback</em> she provided on the search
      results. Previous context-aware query suggestions have
      modeled the query sequence efficiently, but the user
      feedbacks are merely treated as a secondary resource to help
      model the query sequence or even overlooked&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0008">8</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0025">25</a>].</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186068/images/www2018-77-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">Information needs reflexed by user
          feedbacks.</span>
        </div>
      </figure>
      <p>However, user feedbacks sometimes are necessary for search
      engines to infer the precise search intent behind queries.
      For example, as shown in Figure&nbsp;<a class="fig" href=
      "#fig1">1</a>, the query “Apple” itself is ambiguous, but the
      user's preference on ‘Apple.com’ or ‘Apple Juice’ reflexes
      the search intent more precisely.</p>
      <p>This paper presents a neural query suggestion method that
      models both the query sequence and the user feedback in the
      session, named as <strong>F</strong>eedback
      <strong>M</strong>emory <strong>N</strong>etwork
      (<tt>FMN</tt>). <tt>FMN</tt> embeds the search results of a
      query using a memory network, which converts the contents of
      ranked documents to distributed representations by recurrent
      neural networks, and calculates the attention over these
      documents according to the similarity between the query and
      those documents and also user's preference on those
      documents. <tt>FMN</tt> then produces the ‘feedback memories’
      for the query by combining the content embeddings via their
      attention scores. In the query suggestion task, the feedback
      memories of queries in a session is easily integrated to a
      sequence-to-sequence model to produce <em>feedback-aware</em>
      query suggestions.</p>
      <p><tt>FMN</tt> is trained end-to-end using user behaviors in
      search logs. Given the correct query suggestions,
      <tt>FMN</tt> learns the query sequence model and the feedback
      model simultaneously. The feedback model helps distinguish
      the different query suggestions following the same input
      query sequence but with different click patterns, which would
      confuse the sequence-to-sequence model without feedback
      awareness. It also propagates the training signals across
      different sessions with shared search results, reducing the
      sparsity of the query sequence. The
      <em>feedback-awareness</em> introduced by <tt>FMN</tt> thus
      influences not only the predicting behavior of the query
      suggestion model, but also the learning of the model
      itself.</p>
      <p>Our experiments on the search log from Sogou, a major
      Chinese commercial search engine, demonstrated <tt>FMN</tt>’s
      robust effectiveness. Stable improvements have been observed
      over an unsupervised method, feature-based methods, and
      state-of-the-art neural methods that do not consider user
      feedbacks. <tt>FMN</tt>’s advantages are more significant in
      more extreme scenarios: On sessions that contain too little
      information or more noisy signals, the additional feedback
      signals make <tt>FMN</tt>’s performance more stable; on more
      ambivalent queries where context-aware query suggestion
      systems may get confused, <tt>FMN</tt> are more accurate
      because its feedback awareness helps locate more fine-grained
      search intents. Our analyses further revealed that the
      successful modeling of the feedback signal is the source of
      <tt>FMN</tt>’s effectiveness: <tt>FMN</tt> produces more
      accurate suggestions when more feedback signals are made
      available, or the feedback signal is more informative.</p>
      <p>The next section discusses the related work. The
      architecture of <tt>FMN</tt> and its application in query
      suggestion are in Section&nbsp;<a class="sec" href=
      "#sec-7">3</a>. Experiment settings and evaluation results
      are presented in Section&nbsp;<a class="sec" href=
      "#sec-10">4</a> and&nbsp;<a class="sec" href="#sec-11">5</a>.
      The last section concludes and discusses future work.</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related
          Work</h2>
        </div>
      </header>
      <p>Query suggestion systems utilize the ‘wisdom of crowds’ to
      suggest semantically related queries for the input session.
      The semantic relatedness can be modeled by the Query Flow
      Graph which connects queries by their session
      co-occurrences&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>]. It can also be described by the
      similarities between queries’ search results&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0003">3</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0028">28</a>]. The
      query-click bipartite graph is another widely studied
      resource to connect queries through their shared
      clicks&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0001">1</a>],
      for example, the relatedness can be described by the distance
      (hit time) in the bipartite graph&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0018">18</a>].</p>
      <figure id="fig2">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186068/images/www2018-77-fig2.jpg"
        class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class=
          "figure-title">The architecture of Feedback Memory
          Network. The clicked (left) and skipped (right) search
          results are encoded into the positive and negative
          feedback memories by FMN's content encoding and position
          encoding. They are combined by the attention mechanism to
          produce the positive (<em>F</em> <sup>+</sup>) and
          negative (<em>F</em> <sup>−</sup>) feedback
          memories.</span>
        </div>
      </figure>
      <p></p>
      <p>A lot of techniques have been developed to address the
      sparsity of the ‘wisdom of crowds’—a major challenge in query
      suggestion. The Term Query Graph enriches the Query Flow
      Graph with term nodes; the connections between query nodes
      and term nodes smooth the query flow and help find
      suggestions for tail queries&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0004">4</a>]. The query-click graph and
      the Query Flow Graph can be united to combine the strengths
      of both sides&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0014">14</a>]. The sparse signals in query
      suggestion can also be smoothed by clustering queries using
      search results&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>] or the Query Flow
      Graph&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0022">22</a>],
      and sharing information within clusters. Another line of
      research is to build additional connections between queries
      using external semantic resources, for example, templates
      generated from WordNet&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0027">27</a>], shared entity
      annotations&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0006">6</a>], and knowledge graph
      relations&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0013">13</a>].</p>
      <p>Cao et al. proposed the context-aware query suggestion
      framework &nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0008">8</a>] which considers the whole query
      sequence in the session, instead of only the last query. They
      used query clusters to build a concept sequence suffix tree,
      for efficient and effective context-aware query suggestions.
      The query sequence can also be modeled by the Mixture
      Variable Memory Markov Model&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0012">12</a>]. Context-aware query
      suggestion considers more user actions in the session and
      thus better models the information needs. Hence, the idea is
      also effective in query classification&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0007">7</a>] and
      ranking&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0029">29</a>].</p>
      <p>The rich signals developed in previous research have also
      been combined for query suggestion by machine learning
      techniques. For example, finding the right query substations
      or rewritings was considered as a classification
      problem&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0016">16</a>]. Ozertem et al.&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0021">21</a>] developed a ranking
      framework that learns to suggest queries directly from user's
      search behaviors in the search log. It utilizes the
      large-scale search logs and avoids the requirement of human
      labels. Supervised suggestion systems are in general more
      accurate than unsupervised ones while also being more
      flexible. Their suggested results can also improve
      diversified and personalized search&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0023">23</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0024">24</a>].</p>
      <p>The sparse signals and large-scale training data make
      query suggestion a natural fit for deep learning approaches.
      Sordoni et al.&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0025">25</a>] developed a hierarchical
      encoder-decoder model (HRED) for context-aware query
      suggestion. The encoder first uses a two-level recurrent
      neural network (RNN) to encode the query words to the query
      embedding and then the query sequence to the session
      embedding. It then decodes the session embedding to target
      suggestions. HRED avoids sparsity using smoothly distributed
      representations and better utilizes large-scale training data
      available in search logs. It achieves better accuracy than
      feature-based systems. A more recent work upgraded HRED's
      sequence-to-sequence model with the attention and coping
      mechanism to model the varying query importances and
      repeating terms in sessions&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0011">11</a>].</p>
      <p>This paper introduces memory network to model user
      feedbacks. Memory network has provided an effective way to
      incorporate external information into neural
      models&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0026">26</a>].
      A memory cell in the memory network can be considered as a
      key-value pair: the key generates the attention weight on the
      memory cell, and the value is the external information to
      incorporate&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0020">20</a>]. Memory networks have been
      successfully adopted in many tasks, for example, reading
      comprehension&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0020">20</a>] and task-oriented dialog
      system&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>].</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Feedback Memory
          Network</h2>
        </div>
      </header>
      <p>This section first describes the architecture of Feedback
      Memory Network (<tt>FMN</tt>), which models the user
      feedbacks on the search results and produces <em>feedback
      memories</em> for the corresponding query. Then it discusses
      how <tt>FMN</tt> is incorporated in a query suggestion system
      and makes it <em>feedback-aware</em>.</p>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Model
            Architecture</h3>
          </div>
        </header>
        <p>User's preference on search results reflects more
        fine-grained information needs. It has been used as a
        static resource to infer document's
        relevance&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0010">10</a>] and to train ranking
        models&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0015">15</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0030">30</a>]. <tt>FMN</tt> models the feedback
        signals more dynamically with neural networks. As shown in
        Figure&nbsp;<a class="fig" href="#fig2">2</a>, <tt>FMN</tt>
        takes the user's interactions with the search engine as
        inputs and converts them to distributed representations.
        The distributed representations are the <em>feedback
        memories</em> of the query and encode the information needs
        reflected by user's preferences, for example, the
        preferences on ‘iPhone’ or ‘Apple pie’ for the query
        ‘apple’.</p>
        <p>Given a query <em>q</em>, its search results <em>D</em>
        = {<em>d</em> <sub>1</sub>, ...<em>d<sub>i</sub></em> ...,
        <em>d<sub>n</sub></em> }, and the clicked positions
        <em>C</em> =
        {<em>p</em>|User clicked on <em>d<sub>p</sub></em> .},
        <tt>FMN</tt> considers the clicked documents as positive
        feedback documents <em>D</em> <sup>+</sup>, and the skipped
        documents as negative <em>D</em> <sup>−</sup>:</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{align*} D^+ =&amp;
            \lbrace d_p | p \in C\rbrace , \\D^- =&amp; \lbrace d_p
            | p {\lt}= \text{max}(C) + 1, p \notin C \rbrace
            .\end{align*}</span><br />
          </div>
        </div>It uses the cascade assumption&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0010">10</a>]: The user prefers
        documents she clicked over those she skipped that are
        ranked higher or one position lower than clicked ones, if
        no search result got clicked, it indicates the user is not
        satisfied with the first search result: <em>D</em>
        <sup>+</sup> = ∅ and <em>D</em> <sup>−</sup> = {<em>d</em>
        <sub>1</sub>}.
        <p></p>
        <p><tt>FMN</tt> encodes <em>D</em> <sup>+</sup> and
        <em>D</em> <sup>−</sup> to the positive feedback memory
        <em>F</em> <sup>+</sup> and the negative feedback memory
        <em>F</em> <sup>−</sup>, two continuous vectors
        representing user's preferences. It is conducted by three
        components: the document content encoding, the position
        encoding, and the attention mechanism that combines
        them.</p>
        <p><strong>Document Content Encoding:</strong> In
        <tt>FMN</tt>, a document's content is a sequence of its
        words <span class="inline-equation"><span class="tex">$d_p
        =\lbrace
        w_1^p,...w_j^p...,w_{|d_p|}^p\rbrace$</span></span> . As in
        standard sequence-to-sequence (seq2seq) learning,
        <tt>FMN</tt> embeds the document's words and uses a
        recurrent neural network (RNN) to encode it to a continuous
        vector <span class="inline-equation"><span class=
        "tex">$\vec{c}_{d_p}$</span></span> .</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \vec{w}_j &amp; =
            \text{Emb}_c(w_j^p), \end{align}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \vec{c}_{d_p}
            &amp; =
            \text{GRU}_c(\vec{w}_1^p,...,\vec{w}_j^p...,\vec{w}_{|d_p|}^p).
            \end{align}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>Emb <sub><em>c</em></sub> is the word embedding
        matrix for document contents. |Emb <sub><em>c</em></sub> |
        = <em>V</em> × <em>l</em>, where <em>V</em> is the size of
        the vocabulary, and <em>l</em> is the embedding dimension.
        GRU <sub><em>c</em></sub> is the GRU model, a widely used
        RNN in seq2seq learning. <span class=
        "inline-equation"><span class=
        "tex">$\vec{c}_{d_p}$</span></span> is the output vector
        (the last hidden state) of the GRU. The contents of all
        documents in <em>D</em> <sup>+</sup> and <em>D</em>
        <sup>−</sup> are encoded by the same Emb
        <sub><em>c</em></sub> and GRU <sub><em>c</em></sub> .
        <p></p>
        <p><strong>Position Encoding:</strong> The ranking position
        of a document in the search results conveys the search
        engine's judgment about the document's relevancy. It also
        influences user's perception of the documents. To cover its
        effect, <tt>FMN</tt> includes the ranking position of a
        document as the position embedding:</p>
        <div class="table-responsive" id="eq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \vec{pos}_p
            &amp;= \text{Emb}_{pos}(p). \end{align}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>Emb <sub><em>pos</em></sub> is the position embedding
        matrix to be learned. Each of its rows is the embedding of
        a position (p).
        <p></p>
        <p><strong>Attention Mechanism:</strong> <tt>FMN</tt> uses
        an attention mechanism to weight-combine document content
        embedding and position embedding to feedback memories. It
        captures the importances of documents in <em>D</em>
        <sup>+</sup> and <em>D</em> <sup>−</sup> when inferring the
        search intent. For example, if <em>d<sub>p</sub></em>
        corresponds to a rare intent of the query, clicking it is
        more informative; if <em>d<sub>p</sub></em> is a
        navigational result, skipping it indicates more unexpected
        intent.</p>
        <p>Specifically, given the query <em>q</em>, positive
        documents <em>D</em> <sup>+</sup> and negative documents
        <em>D</em> <sup>−</sup>, <tt>FMN</tt> learns the attention
        scores <em>A</em> <sup>+</sup> on <em>D</em> <sup>+</sup>
        and <em>A</em> <sup>−</sup> on <em>D</em> <sup>−</sup> from
        the interactions between the query and the documents.</p>
        <p>The query <span class="inline-equation"><span class=
        "tex">$q=\lbrace
        w_1^q,...w_j^q,...,w_{|q|}^q\rbrace$</span></span> is
        encoded to an attention vector <span class=
        "inline-equation"><span class=
        "tex">$\vec{a}_q$</span></span> :</p>
        <div class="table-responsive" id="eq4">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \vec{w}_j^q
            &amp;= \text{Emb}_{q}(w_j^q), \end{align}</span><br />
            <span class="equation-number">(4)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq5">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \vec{a}_q &amp;=
            \text{GRU}_{q}(\vec{w}_1^q,...,\vec{w}_j^q...,\vec{w}_{|q|}^q),
            \end{align}</span><br />
            <span class="equation-number">(5)</span>
          </div>
        </div>where Emb <sub><em>q</em></sub> and GRU
        <sub><em>q</em></sub> are the query embedding matrix and
        GRU models of the attention mechanism.
        <p></p>
        <p>The documents <em>d<sub>p</sub></em> is encoded in the
        same way with another set of document attention
        parameters:</p>
        <div class="table-responsive" id="eq6">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \vec{w}_j^p
            &amp;= \text{Emb}_{a_d}(w_j^p),
            \end{align}</span><br />
            <span class="equation-number">(6)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq7">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \vec{a}_{d_p}
            &amp;=
            \text{GRU}_{a_d}(\vec{w}_1^p,...,\vec{w}_j^p...,\vec{w}_{|d_p|}^p),
            \end{align}</span><br />
            <span class="equation-number">(7)</span>
          </div>
        </div>
        <p></p>
        <p>The attention weights of the query <em>q</em> on the
        documents in <em>D</em> <sup>+</sup> and <em>D</em>
        <sup>−</sup> are the normalized dot products of their
        attention embedding to the query's:</p>
        <div class="table-responsive" id="eq8">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} A_p &amp;=
            \vec{a}_q^T \vec{a}_{d_p}, \end{align}</span><br />
            <span class="equation-number">(8)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq9">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} A^+ &amp;=
            \text{softmax}\lbrace A_p | d_p \in D^+ \rbrace ,
            \end{align}</span><br />
            <span class="equation-number">(9)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq10">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} A^- &amp;=
            \text{softmax}\lbrace A_p | d_p \in D^- \rbrace .
            \end{align}</span><br />
            <span class="equation-number">(10)</span>
          </div>
        </div>Note that the attention scores are normalized
        separately in <em>D</em> <sup>+</sup> and <em>D</em>
        <sup>−</sup>; the user feedback signal is covered by the
        belonging of documents in the positive and negative sets.
        <p></p>
        <p><strong>Feedback Memories:</strong> The attention
        scores, document embedding, and position embedding together
        produce the positive and negative feedback memories for the
        query:</p>
        <div class="table-responsive" id="eq11">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} F^+ &amp;= \sum
            _{d_p \in D^+} A_p^+
            (M(\vec{c}_{d_p}||\vec{pos}_p)+b_F),
            \end{align}</span><br />
            <span class="equation-number">(11)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq12">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} F^- &amp;= \sum
            _{d_p \in D^-} A_p^-
            (M(\vec{c}_{d_p}||\vec{pos}_p)+b_F).
            \end{align}</span><br />
            <span class="equation-number">(12)</span>
          </div>
        </div>The position embedding and the content embedding are
        concatenated (||) and then projected by the to-be-learned
        matrix <em>M</em> and bias <em>b<sub>F</sub></em> .
        <em>F</em> <sup>+</sup> and <em>F</em> <sup>−</sup> are the
        output vectors of <tt>FMN</tt>, representing the positive
        and negative preferences reflected by user feedbacks.
        Besides the projections, <tt>FMN</tt>’s parameters include
        the embeddings for document content Emb
        <sub><em>c</em></sub> , the query attention Emb
        <sub><em>q</em></sub> , and the document attention
        <span class="inline-equation"><span class=
        "tex">$\text{Emb}_{a_d}$</span></span> , as long as the
        corresponding GRU unites: GRU <sub><em>c</em></sub> , GRU
        <sub><em>q</em></sub> , and <span class=
        "inline-equation"><span class=
        "tex">$\text{GRU}_{a_d}$</span></span> .
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186068/images/www2018-77-fig3.jpg"
          class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">Feedback-Aware Query
            Suggestion. The feedback memories <em>F</em>
            <sup>+</sup> and <em>F</em> <sup>−</sup> introduce the
            feedback signals to the encoder-decoder neural
            network.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span>
            Feedback-Aware Query Suggestion</h3>
          </div>
        </header>
        <p><tt>FMN</tt>’s feedback memories <em>F</em> <sup>+</sup>
        and <em>F</em> <sup>−</sup> encode the information needs
        reflected by user's preferences. It can be integrated as
        the external memories of the query in neural query
        suggestion systems and then trained end-to-end using
        back-propagation. The integrated query suggestions are
        <em>feedback-aware</em>: Both query sequences and user
        feedbacks are considered; different queries can be
        suggested for the same query sequence if the click patterns
        are different.</p>
        <p>This work chooses a previous state-of-the-art neural
        model, HRED&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0025">25</a>], to integrate with <tt>FMN</tt>.
        HRED is a sequence-to-sequence model. It first encodes the
        query sequence <em>S</em> = {<em>q</em> <sub>1</sub>,
        ...<em>q<sub>k</sub></em> , .., <em>q<sub>K</sub></em> } to
        a hidden vector, and then decodes the candidate query
        suggestions from the vector. <tt>FMN</tt> is plugged in to
        enrich context-aware query representations for the encoder,
        using the architecture shown in Figure&nbsp;<a class="fig"
        href="#fig3">3</a>. The rest of this section describes the
        integration architecture, the candidate query suggestion
        scoring process, and the model training using search
        logs.</p>
        <p><strong>Encoding with</strong>
        <tt><strong>FMN</strong></tt> <strong>:</strong> The query
        sequence and feedback memories are encoded by a two-level
        encoder:</p>
        <p>The first level encodes each query
        <em>q<sub>k</sub></em> by the standard seq2seq model:</p>
        <div class="table-responsive" id="eq13">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} q_k \xrightarrow
            [\text{Emb}_{q}]{\text{GRU}_{q}} \vec{q}_k,
            \end{align}</span><br />
            <span class="equation-number">(13)</span>
          </div>
        </div>which is similar to Equation&nbsp;<a class="eqn"
        href="#eq4">4</a> and&nbsp;<a class="eqn" href="#eq5">5</a>
        and has the same parameters Emb <sub><em>q</em></sub> and
        GRU <sub><em>q</em></sub> . The resulted query content
        embedding <span class="inline-equation"><span class=
        "tex">$\vec{q}_k$</span></span> conveys the information
        needs reflected by the query string.
        <p></p>
        <p>The second level encodes the session's query contents
        and feedback memories to the session embedding <span class=
        "inline-equation"><span class="tex">$\vec{S}$</span></span>
        . It first combines each query's content embedding with its
        feedback memories:</p>
        <div class="table-responsive" id="eq14">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \vec{v}_{q_k} =
            \vec{q}_k + F_{q_k}^+ - F_{q_k}^-.
            \end{align}</span><br />
            <span class="equation-number">(14)</span>
          </div>
        </div><span class="inline-equation"><span class=
        "tex">$\vec{v}_{q_k}$</span></span> is the query ‘intent’
        representation and contains signals from the query content
        and the user preferences on the search results.
        <p></p>
        <p>The intent representations of the query sequence are
        combined by the session level GRU <sub><em>s</em></sub>
        :</p>
        <div class="table-responsive" id="eq15">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \vec{S} &amp;=
            \text{GRU}_{s}
            (\vec{v}_{q_1},...\vec{v}_{q_k},...\vec{v}_{q_K}).
            \end{align}</span><br />
            <span class="equation-number">(15)</span>
          </div>
        </div>The session embedding <span class=
        "inline-equation"><span class="tex">$\vec{S}$</span></span>
        includes information from the query sequence and the user
        feedbacks.
        <p></p>
        <p><strong>Decoding:</strong> The decoder decodes the
        session embedding <span class=
        "inline-equation"><span class="tex">$\vec{S}$</span></span>
        to the target query suggestion. This part is the same with
        HRED&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0025">25</a>], except that <span class=
        "inline-equation"><span class="tex">$\vec{S}$</span></span>
        is enriched with the feedback-awareness.</p>
        <p>HRED first transforms <span class=
        "inline-equation"><span class="tex">$\vec{S}$</span></span>
        to the initial state of the decoder:</p>
        <div class="table-responsive" id="eq16">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} h_0 &amp;=
            \text{tanh}(D\vec{S} + b_0). \end{align}</span><br />
            <span class="equation-number">(16)</span>
          </div>
        </div><span class="inline-equation"><span class="tex">$|D|
        = |h_0| \times |\vec{S}|$</span></span> is the projection
        and <em>b</em> <sub>0</sub> is the bias. tanh() is the
        activation function.
        <p></p>
        <p>The target query suggestion <span class=
        "inline-equation"><span class="tex">$q_s=\lbrace
        w^s_1,..,w_j^s,...,w_{|q_s|}^s\rbrace$</span></span> is
        decoded by another GRU:</p>
        <div class="table-responsive" id="eq17">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} h_j &amp;=
            \text{GRU}_{dec}(h_{j-1}, w_{j-1}^s),
            \end{align}</span><br />
            <span class="equation-number">(17)</span>
          </div>
        </div>and the probability of generating the next word
        <em>w<sub>j</sub></em> is:
        <div class="table-responsive" id="eq18">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} p(w_j |
            w_1:w_{j-1}, \vec{S}) &amp;= \text{softmax}(\vec{w}_j^T
            f(h_{j-1}, \vec{w}_{j-1})), \end{align}</span><br />
            <span class="equation-number">(18)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq19">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} f(h_{j-1},
            \vec{w}_{j-1}) &amp;= Hh_{j-1} + E \vec{w}_{j-1} +
            b_{prob}, \end{align}</span><br />
            <span class="equation-number">(19)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq20">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \vec{w}_0 &amp;=
            \vec{0}. \end{align}</span><br />
            <span class="equation-number">(20)</span>
          </div>
        </div><em>f</em> is a dense layer with parameters
        <em>H</em>, <em>E</em>, <em>b<sub>prob</sub></em> :
        <span class="inline-equation"><span class="tex">$|H| =
        |\vec{w}_j||h_0|$</span></span> , <span class=
        "inline-equation"><span class="tex">$|E| =
        |\vec{w}_j|^2$</span></span> and <span class=
        "inline-equation"><span class=
        "tex">$b_{prob}=|\vec{w}_j|$</span></span> . The softmax is
        taken over all possible candidate words, for example, those
        appeared in candidate queries or the entire vocabulary.
        <span class="inline-equation"><span class=
        "tex">$\vec{0}$</span></span> is an all-zero vector.
        <p></p>
        <p><strong>Scoring Candidate Suggestions:</strong> Instead
        of directly generating a query, a more conservative choice
        is to rank candidate query suggestions using the decoder.
        The score of a candidate query <em>q<sub>s</sub></em> is
        the probability of it being decoded given the session
        embedding:</p>
        <div class="table-responsive" id="eq21">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} s(q_s) &amp;=
            \prod _j p(w_j | w_1:w_{j-1}, \vec{S}).
            \end{align}</span><br />
            <span class="equation-number">(21)</span>
          </div>
        </div>The score can be integrated into a feature-based
        query suggestion system, as in HRED&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0025">25</a>].
        <p></p>
        <p><strong>Model Training:</strong> The whole model,
        including the feedback memory network and the hierarchical
        encoder-decoder, are trained end-to-end using sessions in
        the search log.</p>
        <p>Given the queries, search results, and user feedbacks in
        a training session, the last query of the session is
        treated as the correct query suggestion
        <em>q<sub>s</sub></em> &nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0021">21</a>]. The training is conducted by
        maximizing the likelihood of <em>q<sub>s</sub></em> given
        the other part of the training session:</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{align*} l = \sum _{w_j
            \in q_s} \log p(w_j | w_1:w_{j-1},
            \vec{S}).\end{align*}</span><br />
          </div>
        </div>Standard back propagation is used to send the
        gradients from the likelihood to the decoder, the encoder,
        and then to <tt>FMN</tt>. The query sequence model and the
        memory networks are optimized jointly for better query
        suggestion accuracy.
        <p></p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Statistics of the dataset used in the
            experiments.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">
                <strong>Training</strong></th>
                <th style="text-align:center;">
                <strong>Development</strong></th>
                <th><strong>Testing</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Number of
                Sessions</td>
                <td style="text-align:center;">7,978,441</td>
                <td style="text-align:center;">3,989,220</td>
                <td>36,519</td>
              </tr>
              <tr>
                <td style="text-align:left;">Number of Queries</td>
                <td style="text-align:center;">27,191,564</td>
                <td style="text-align:center;">13,551,903</td>
                <td>117,225</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Experiment</h2>
        </div>
      </header>
      <p>This section discusses the dataset, baselines,
      implementation details, and evaluation metrics in our
      experiments.</p>
      <p><strong>Dataset:</strong> Our experiments are conducted on
      a large scale Chinese search log from Sogou, a Chinese
      commercial search engine. The search log includes queries,
      the titles and URL's of displayed documents, and clicks.
      Standard 30-minutes gap is used to split the queries into
      sessions. As a query suggestion task, only sessions with more
      than one query are used; the last query in a session is
      treated as the correct suggestion&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0021">21</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0025">25</a>]. The content of a
      document is its title, because we are not able to obtain the
      body text for enough documents by crawling or from the
      Sogou-T corpus&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0009">9</a>]. All the queries and document titles
      are in Chinese. We segmented them using the THULAC open
      source software&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0017">17</a>]. The first 90,000 most frequent
      Chinese words are used, the rest are replaced by
      <em>UNK</em>. After the segmentation, everything is treated
      the same as in English.</p>
      <p>The sessions are randomly split into three parts: training
      (60%), development (30%), and testing (10%). The training
      fold trains the neural baselines and our method; the
      development fold trains the supervised feature-based systems;
      the testing fold evaluates all methods&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0025">25</a>]. The statistics of the
      three folds are listed in Table&nbsp;<a class="tbl" href=
      "#tab1">1</a>.</p>
      <p>The re-ranking setting in prior work&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0025">25</a>] is used in our
      experiments, in which the query suggestion systems are
      evaluated by their ability to re-rank the candidate
      suggestions. The candidates are the top-20 most frequent
      follow-ups in the search log for the input query sequence. We
      chose this conservative setting because it performs better
      than the generation-based setting&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0025">25</a>] and to focus on
      evaluating the effectiveness of <tt>FMN</tt> in modeling user
      feedbacks.</p>
      <div class="table-responsive" id="tab2">
        <div class="table-caption">
          <span class="table-number">Table 2:</span> <span class=
          "table-title">Parameters to learn in the neural methods.
          The <strong>USE</strong> column marks the models that use
          the corresponding parameters: H refers to HRED, P refers
          to PRFMN, and F refers to FMN. The bracketed numbers
          (<em>d</em> <sub>1</sub>, <em>d</em> <sub>2</sub>,
          <em>d</em> <sub>3</sub>) are the input size, hidden state
          size, and the number of layers of GRU's, or the dimension
          of the matrix parameters. The vocabulary is the
          90<em>k</em> most frequent words in the search
          log.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:left;">
              <strong>Parameter</strong></th>
              <th style="text-align:center;">
              <strong>Dimension</strong></th>
              <th style="text-align:left;">
              <strong>USE</strong></th>
              <th><strong>Description</strong></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:left;">Emb
              <sub><em>q</em></sub></td>
              <td style="text-align:center;">(90k, 256)</td>
              <td style="text-align:left;">HPF</td>
              <td>Query Content</td>
            </tr>
            <tr>
              <td style="text-align:left;">GRU
              <sub><em>q</em></sub></td>
              <td style="text-align:center;">(256,256,1)</td>
              <td style="text-align:left;">HPF</td>
              <td>Query Content</td>
            </tr>
            <tr>
              <td style="text-align:left;">GRU
              <sub><em>s</em></sub></td>
              <td style="text-align:center;">(256,512,1)</td>
              <td style="text-align:left;">HPF</td>
              <td>Session Encoder</td>
            </tr>
            <tr>
              <td style="text-align:left;">GRU
              <sub><em>dec</em></sub></td>
              <td style="text-align:center;">(256, 512, 1)</td>
              <td style="text-align:left;">HPF</td>
              <td>Decoder</td>
            </tr>
            <tr>
              <td style="text-align:left;"><em>D</em></td>
              <td style="text-align:center;">(512,256)</td>
              <td style="text-align:left;">HPF</td>
              <td>Decoder Projection</td>
            </tr>
            <tr>
              <td style="text-align:left;"><em>b</em>
              <sub>0</sub></td>
              <td style="text-align:center;">256</td>
              <td style="text-align:left;">HPF</td>
              <td>Decoder Bias</td>
            </tr>
            <tr>
              <td style="text-align:left;"><em>H</em></td>
              <td style="text-align:center;">(256, 512)</td>
              <td style="text-align:left;">HPF</td>
              <td>Decoder Probability</td>
            </tr>
            <tr>
              <td style="text-align:left;"><em>E</em></td>
              <td style="text-align:center;">(256, 256)</td>
              <td style="text-align:left;">HPF</td>
              <td>Decoder Probability</td>
            </tr>
            <tr>
              <td style="text-align:left;">
              <em>b<sub>prob</sub></em></td>
              <td style="text-align:center;">256</td>
              <td style="text-align:left;">HPF</td>
              <td>Decoder Probability</td>
            </tr>
            <tr>
              <td style="text-align:left;"><span class=
              "inline-equation"><span class=
              "tex">$\text{Emb}_{a_d}$</span></span></td>
              <td style="text-align:center;">(90k, 256)</td>
              <td style="text-align:left;">PF</td>
              <td>Document Attention</td>
            </tr>
            <tr>
              <td style="text-align:left;"><span class=
              "inline-equation"><span class=
              "tex">$\text{GRU}_{a_d}$</span></span></td>
              <td style="text-align:center;">(256, 256, 1)</td>
              <td style="text-align:left;">PF</td>
              <td>Document Attention</td>
            </tr>
            <tr>
              <td style="text-align:left;"><span class=
              "inline-equation"><span class=
              "tex">$\text{Emb}_{c_d}$</span></span></td>
              <td style="text-align:center;">(90k, 256)</td>
              <td style="text-align:left;">PF</td>
              <td>Document Content</td>
            </tr>
            <tr>
              <td style="text-align:left;"><span class=
              "inline-equation"><span class=
              "tex">$\text{GRU}_{c_d}$</span></span></td>
              <td style="text-align:center;">(256, 256, 1)</td>
              <td style="text-align:left;">PF</td>
              <td>Document Content</td>
            </tr>
            <tr>
              <td style="text-align:left;">Emb
              <sub><em>P</em></sub></td>
              <td style="text-align:center;">(15, 4)</td>
              <td style="text-align:left;">F</td>
              <td>Position Embedding</td>
            </tr>
            <tr>
              <td style="text-align:left;"><em>M</em></td>
              <td style="text-align:center;">(256,260)</td>
              <td style="text-align:left;">F</td>
              <td>Feedback Projection</td>
            </tr>
            <tr>
              <td style="text-align:left;">
              <em>b<sub>F</sub></em></td>
              <td style="text-align:center;">256</td>
              <td style="text-align:left;">F</td>
              <td>Feedback Bias</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="table-responsive" id="tab3">
        <div class="table-caption">
          <span class="table-number">Table 3:</span> <span class=
          "table-title">Overall accuracy of the query suggestions
          systems. All methods starting with “+” are evaluated as
          additional features in <tt>LeToR</tt>.
          <strong>MISS@K</strong> are the fraction of sessions
          whose correct suggestions are not ranked in top K by the
          corresponding method, the lower the better. Relative
          performances over <tt>LeToR</tt> are shown in
          percentages. Win/Tie/Loss are the number of sessions a
          method improved, did not change, or hurt, compared with
          <tt>LeToR</tt>. The superscripts<sup>1, 2, 3, 4, 5</sup>
          mark the statistical significant improvements over
          <tt>LeToR</tt> <sup>1</sup>, <tt>+PRF Feature</tt>
          <sup>2</sup>, <tt>+Feedback Feature</tt> <sup>3</sup>,
          <tt>+HRED</tt> <sup>4</sup> and <tt>+PRFMN</tt>
          <sup>5</sup>. Best results of each metric are marked
          <strong>Bold</strong>.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:left;">
              <strong>Method</strong></th>
              <th colspan="2" style="text-align:center;">
                <strong>MRR</strong>
                <hr />
              </th>
              <th colspan="2" style="text-align:center;">
                <strong>MISS@3</strong>
                <hr />
              </th>
              <th colspan="2" style="text-align:center;">
                <strong>MISS@5</strong>
                <hr />
              </th>
              <th><strong>Win/Tie/Loss</strong></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:left;"><tt>ADJ</tt></td>
              <td style="text-align:right;">0.4928</td>
              <td style="text-align:left;">-.5.43%</td>
              <td style="text-align:right;">0.3165</td>
              <td style="text-align:left;">10.7%</td>
              <td style="text-align:right;">0.1484</td>
              <td style="text-align:center;">1.69%</td>
              <td>7,232/18,038/11,249</td>
            </tr>
            <tr>
              <td style="text-align:left;"><tt>LeToR</tt></td>
              <td style="text-align:right;">0.5211</td>
              <td style="text-align:left;">–</td>
              <td style="text-align:right;">0.2859</td>
              <td style="text-align:left;">–</td>
              <td style="text-align:right;">0.1361</td>
              <td style="text-align:center;">–</td>
              <td>–/–/–</td>
            </tr>
            <tr>
              <td style="text-align:left;"><tt>+PRF
              Feature</tt></td>
              <td style="text-align:right;">0.5285<sup>1</sup></td>
              <td style="text-align:left;">1.42%</td>
              <td style="text-align:right;">0.2799<sup>1</sup></td>
              <td style="text-align:left;">-2.10%</td>
              <td style="text-align:right;">0.1295<sup>1</sup></td>
              <td style="text-align:center;">-4.85%</td>
              <td>9,871/17,875/8,773</td>
            </tr>
            <tr>
              <td style="text-align:left;"><tt>+Feedback
              Feature</tt></td>
              <td style="text-align:right;">0.534<sup>1,
              2</sup></td>
              <td style="text-align:left;">2.48%</td>
              <td style="text-align:right;">0.2675<sup>1,
              2</sup></td>
              <td style="text-align:left;">-6.43%</td>
              <td style="text-align:right;">0.1121<sup>1,
              2</sup></td>
              <td style="text-align:center;">-17.63%</td>
              <td>11,869/14,607/10,043</td>
            </tr>
            <tr>
              <td style="text-align:left;"><tt>+HRED</tt></td>
              <td style="text-align:right;">0.537<sup>1,
              2</sup></td>
              <td style="text-align:left;">3.05%</td>
              <td style="text-align:right;">0.2367<sup>1, 2,
              3</sup></td>
              <td style="text-align:left;">-17.20%</td>
              <td style="text-align:right;">0.1175<sup>1, 2,
              3</sup></td>
              <td style="text-align:center;">-13.67%</td>
              <td>12,961/12,709/10,849</td>
            </tr>
            <tr>
              <td style="text-align:left;"><tt>+PRFMN</tt></td>
              <td style="text-align:right;">0.5358<sup>1,
              2</sup></td>
              <td style="text-align:left;">2.82%</td>
              <td style="text-align:right;">0.2628<sup>1,
              2</sup></td>
              <td style="text-align:left;">-8.08%</td>
              <td style="text-align:right;">0.1207<sup>1, 2,
              3</sup></td>
              <td style="text-align:center;">-11.32%</td>
              <td>12,343/13,804/10,372</td>
            </tr>
            <tr>
              <td style="text-align:left;"><tt>+FMN</tt></td>
              <td style="text-align:right;"><strong>0.5812</strong>
              <sup>1, 2, 3, 4, 5</sup></td>
              <td style="text-align:left;">11.53%</td>
              <td style="text-align:right;"><strong>0.1921</strong>
              <sup>1, 2, 3, 4, 5</sup></td>
              <td style="text-align:left;">-32.80%</td>
              <td style="text-align:right;"><strong>0.1085</strong>
              <sup>1, 2, 3, 4, 5</sup></td>
              <td style="text-align:center;">-20.28%</td>
              <td>13,146/17,528/5,845</td>
            </tr>
          </tbody>
        </table>
      </div>
      <p><strong>Baselines:</strong> The baselines compared include
      frequency-based, feature-based, and neural-based methods.</p>
      <p><em>Frequency-based:</em>. The <tt>ADJ</tt> baseline ranks
      the candidate queries solely by their frequencies following
      the original query sequence in the search log&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0025">25</a>].</p>
      <p><em>Feature-based:</em>. We implemented the feature-based
      baseline method in previous work&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0025">25</a>]. It is a learning-to-rank
      model using state-of-the-art query suggestion features. One
      can consider it as the combination of conventional query
      suggestion systems. This paper refers to it as
      <tt>LeToR</tt>. It is also the base query suggestion
      system—all the other methods except <tt>ADJ</tt> are
      evaluated by their effectiveness when serving as additional
      ranking features in <tt>LeToR</tt>&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0025">25</a>].</p>
      <p>For more fair comparisons, we implemented another two
      groups of features to model the feedback information. The
      first is <tt>PRF-Feature</tt>, which models the connections
      between the candidate query and the displayed documents in
      the session. The second is <tt>Feedback-</tt>
      <tt>Feature</tt>, which models the connections between the
      candidate query and the clicked documents. Three features are
      extracted for either of them: the query-document
      co-occurrence in the search log, their contents’ Levenshtein
      (edit) distance, and the average embedding distance between
      their word embeddings from word2vec&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0019">19</a>].</p>
      <p><em>Neural-based:</em>. The main neural baseline is
      <tt>HRED</tt>&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0025">25</a>], the previous state-of-the-art and
      the query sequence model used with <tt>FMN</tt>. We also
      compare with a degraded version of <tt>FMN</tt> which treats
      all displayed results as positive documents (Pseudo Relevance
      Feedback), named as <tt>PRFMN</tt>.</p>
      <p><strong>Implementation Details:</strong> LambdaMart is the
      ranking model of <tt>LeToR</tt>, <tt>PRF-Feature</tt>, and
      <tt>Feedback-Feature</tt>. They are trained on the
      development fold&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0025">25</a>]. The neural models are first trained
      on the training fold, and then combined with <tt>LeToR</tt>
      by LambdaMart using the development fold. Their parameters
      include the word embeddings, GRU, and the projection weights
      used in their components, as listed in Table&nbsp;<a class=
      "tbl" href="#tab2">2</a>.</p>
      <p>All neural methods are trained using the Adadelta
      optimizer, with mini-batch size 64, learning rate 0.01, and
      anneals every 25 epochs by <em>η</em>/2 until 100 epochs were
      reached. The weights were initialized randomly from a
      Gaussian distribution with zero mean and <em>σ</em> = 0.1. On
      a common GPU machine and our PyTorch based implementation,
      <tt>FMN</tt> takes about two and half days to converge and
      <tt>HRED</tt> takes about one day and a half.</p>
      <p><strong>Evaluation Metrics:</strong> Our main evaluation
      metric is MRR, the standard metric in query suggestion. We
      also include MISS@3,5 which is the fraction of those test
      sessions whose correct suggestions are not ranked in top3, 5.
      Statistical significances are tested using the permutation
      (Fisher's Randomization) test with <em>p</em> &lt; 0.05.</p>
      <figure id="fig4">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186068/images/www2018-77-fig4.jpg"
        class="img-responsive" alt="Figure 4" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 4:</span> <span class=
          "figure-title">Performance on difficult scenarios.
          Fig&nbsp;4a and Fig&nbsp;4b illustrate the distributions
          of testing sessions at different length, and the systems’
          accuracies on each group. Fig&nbsp;4c shows the
          Cumulative Distribution Function of query's click
          entropy. The three jumps in the CDF divides the click
          entropies into three groups. Fig&nbsp;4d is the
          evaluation results on the sessions grouped by their last
          query's entropy.</span>
        </div>
      </figure>
      <p></p>
    </section>
    <section id="sec-11">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Evaluation
          Results</h2>
        </div>
      </header>
      <p>This section first evaluates the overall accuracy of
      <tt>FMN</tt> and its performances in difficult scenarios.
      Then it analyzes the effectiveness of the feedback signals in
      <tt>FMN</tt>.</p>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.1</span> Overall
            Accuracy</h3>
          </div>
        </header>
        <p>The overall evaluation results are in
        Table&nbsp;<a class="tbl" href="#tab3">3</a>. The
        feature-based system, <tt>LeToR</tt>, performs about 5%
        better than the frequency-based <tt>ADJ</tt>, similar to
        the relative improvement in prior research&nbsp;[<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0025">25</a>]. The two
        additional feature groups, <tt>+PRF Feature</tt> and
        <tt>+Feedback Feature</tt>, provided some additional gains
        but in rather small margins. <tt>HRED</tt> significantly
        outperforms <tt>LeToR</tt> and <tt>+PRF Feature</tt>, and
        performs better than <tt>+Feedback Feature</tt> on earlier
        positions. It benefits from the large amount of training
        data available in the search log, and is able to learn
        different semantic relations that might not be covered by
        the manual features&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0025">25</a>].</p>
        <p><tt>FMN</tt> outperforms all baselines on all metrics.
        It provides more improvements than all other features: With
        17 manually extracted features, <tt>LeToR</tt> improves
        <tt>ADJ</tt> by 6%, while <tt>FMN</tt> itself improved
        <tt>LeToR</tt> by more than 11%. The improvements are also
        stable. Compared with the base system <tt>LeToR</tt>, only
        16% sessions are hurt and more than twice are improved,
        both the best among all the methods. The feedback awareness
        greatly improves the neural query suggestion. Compared with
        <tt>HRED</tt>, which uses the same query sequence modeling
        but without feedback-awareness, <tt>FMN</tt> improves the
        MRR by 8%, and reduces the missed hit in the top 3 by 19%.
        Knowing user's preference is essential to utilize the
        search results. <tt>PRFMN</tt> uses the search results and
        encodes them by memory networks, but treats all search
        results as (pseudo) relevant. The PRF signals are too noisy
        to be useful: <tt>PRFMN</tt> performs worse than
        <tt>HRED</tt> which completely ignores the search
        results.</p>
        <p><tt>FMN</tt> models user preferences more effectively.
        It produces much more accurate suggestions than
        <tt>Feedback Feature</tt>. It is not easy to design rich
        features to model the feedback information. On the
        contrary, <tt>FMN</tt>’s distributed representations and
        neural networks learn user's preferences from the large
        scale search log directly and effectively.</p>
      </section>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.2</span>
            Robustness</h3>
          </div>
        </header>
        <p>On the queries where the ‘wisdom of the crowd’ is
        reliable, all query suggestion systems can provide
        reasonably accurate results. What makes a query suggestion
        system more desirable in real production system is its
        ability to handle more difficult scenarios, where the
        ‘wisdom of the crowd’ is not as effective. This experiment
        evaluates the <tt>FMN</tt>’s accuracy in two such hard
        scenarios.</p>
        <p><strong>Short and Long Sessions:</strong> In
        context-aware query suggestion, the varying session
        length—the number of original queries—imposes challenges to
        the suggestion system. A too short session may have too few
        signal to infer the information needs. A too long session,
        on the other hand, may include noisy queries and drifted
        search intents. A robust query suggestion system should be
        able to provide accurate suggestions for sessions at
        variant lengths.</p>
        <p>We group the testing sessions by their lengths and
        evaluate <tt>FMN</tt> in each group. The groups are short
        sessions (1 original query), medium sessions (2-3 original
        queries), and long sessions (4+ original queries). The
        distribution of testing sessions at each length group and
        corresponding evaluation results are plotted in
        Figure&nbsp;<a class="fig" href="#fig4">4</a>a and&nbsp;4b
        .</p>
        <p>As sessions become longer, <tt>ADJ</tt> performs worse.
        The frequency-based method suffers from the noisy and
        sparse signals on longer sessions. On short sessions,
        <tt>HRED</tt> only provides slight improvements; its
        advantages are more on sessions with 2-3 original queries,
        where its two-level sequence learning model has more
        leverage. On the other end, when there are more than 3
        input queries, <tt>HRED</tt>’s vanilla sequence-to-sequence
        learning may be misled by background queries, intend drift,
        or perhaps also the gradient vanishing problem. More
        advanced sequence modeling technique such as the attention
        mechanism may be required&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0011">11</a>].</p>
        <p><tt>FMN</tt> performs the best on all three groups.
        Compared to <tt>HRED</tt>, the advantages of modeling user
        feedbacks are actually more remarkably observed in more
        extreme cases. On long sessions, user clicks help
        <tt>FMN</tt> stay on track and its effectiveness stays the
        same as on medium sessions. On short sessions, the
        additional information from user feedbacks help reflect the
        information needs of the sole input query. <tt>FMN</tt> is
        the only method that outperforms <tt>ADJ</tt> by a large
        margin.</p>
        <p><strong>Ambivalent Queries:</strong> One advantage of
        feedback-aware query suggestion is that the feedback
        signals can help infer the information needs for ambivalent
        queries. For example, the query ‘apple’ can refer to the
        company or the fruit; the search target can be Apple's
        homepage or recent products. Without additional
        information, the best search engines can do is to bet on
        the most popular intent or to diversify. But with the
        feedback signals, the information need becomes much more
        clear: the user's preference on ‘Apple.com’, ‘apple pie’,
        or ‘iPhone’ points out what she wanted.</p>
        <p>This experiment evaluates <tt>FMN</tt> on ambivalent
        queries. The ambivalence of a query is described by the
        entropy of user clicks on its search results. A more
        scattered click (high entropy) indicates more ambivalent
        search intents, while if all users clicked on the same
        result, it might be an easy query for query suggestion
        systems.</p>
        <figure id="fig5">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186068/images/www2018-77-fig5.jpg"
          class="img-responsive" alt="Figure 5" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span>
            <span class="figure-title">Performance with different
            amounts of feedback information. Fig&nbsp;5a
            and&nbsp;5c show the distribution of test sessions in
            corresponding groups. Their x-axises mark the range of
            each group, and y-axises are the fractions in the
            corresponding group. Fig&nbsp;5b and&nbsp;5d are the
            evaluation results of the query suggestion systems in
            each group. The absolute MRR's of <tt>ADJ</tt> are
            bared by their left y-axes; the relative improvements
            of other methods are on the right y-axes.</span>
          </div>
        </figure>
        <p></p>
        <p>Figure&nbsp;<a class="fig" href="#fig4">4</a>c plots the
        Cumulative Distribution Function (CDF) of the testing
        queries’ click entropy. There are three main jumps in the
        CDF, which divide the click entropy into three groups: low
        (entropy &lt;=0.6, 4.33% queries), medium (entropy in
        between 0.6-1, 83.11% queries), and high (entropy &gt; 1.2,
        12.56% queries). We grouped the testing sessions based on
        their last query's entropy, and evaluated the performances
        in each group. The results are in Figure&nbsp;<a class=
        "fig" href="#fig4">4</a>d .</p>
        <p>The frequency-based method suffered on ambivalent
        queries: <tt>ADJ</tt>’s MRR drops 30% from low entropy to
        high entropy sessions. <tt>HRED</tt>’s accuracy also drops,
        though slightly less than <tt>ADJ</tt> because
        <tt>HRED</tt> considers the entire sequence as a context
        which can disambiguate the last query. However, the query
        sequence alone may not be sufficient to reflect the
        information needs. There is still more than 10% difference
        on <tt>HRED</tt>’s MRR's between the low and high entropy
        sessions. <tt>FMN</tt>’s performances are very stable in
        the three groups. The feedback signals greatly reduce the
        ambiguity of the query sequence. The feedback-aware system
        can provide accurate query suggestions even on high entropy
        sessions, with which the context-aware systems is difficult
        to deal.</p>
      </section>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.3</span> Source of
            Effectiveness</h3>
          </div>
        </header>
        <p>This experiment analyzes the influence of feedback
        signals in <tt>FMN</tt>.</p>
        <p><strong>Feedback Strengths:</strong> We first analyze
        the influence of feedback signals’ strength in suggestion
        accuracy. We present two ways to describe the signal
        strength: number of clicks and the average click depths in
        the session.</p>
        <p><em>Number of Clicks.</em>. More clicks in a session
        provide more feedback signals and could improve
        <tt>FMN</tt>’s accuracy. We divide the testing sessions
        into four groups based on their numbers of clicks: no
        click, one click, two clicks, and three plus. The
        distribution of the four groups are shown in
        Figure&nbsp;<a class="fig" href="#fig5">5</a>a . The
        majority of sessions have zero or one click. Those sessions
        with more than two clicks are less common. The MRR of
        <tt>ADJ</tt>, and the relative improvements of
        <tt>HRED</tt>, <tt>PRFMN</tt> and <tt>FMN</tt> over
        <tt>ADJ</tt> in the fours groups are plotted in
        Figure&nbsp;<a class="fig" href="#fig5">5</a>b .</p>
        <p><tt>ADJ</tt>, <tt>HRED</tt>, and <tt>PRFMN</tt> perform
        similarly across the four groups as none of them uses the
        feedback signals. The relative improvement from
        <tt>FMN</tt> receives a slight jump from zero click to one
        click. It performs about <span class=
        "inline-equation"><span class="tex">$1-2\%$</span></span>
        better when relevance feedback signals are available. Note
        that on no click sessions, <tt>FMN</tt> still outperforms
        <tt>HRED</tt> by a large margin. The reason is that no
        click indicates that the user is unsatisfied with the first
        search result, which is the negative feedback signal used
        by <tt>FMN</tt>—it is still better than no feedback and can
        be effectively utilized by <tt>FMN</tt>.</p>
        <p><em>Click Depths.</em>. A click on a lower ranked result
        implies that the user has skipped the top ranked ones. Her
        information need is more unexpected by the search engine.
        It might be a stronger feedback signal than click on the
        top ranked results. We divided the testing sessions by
        their average click depths into four groups: [0, 1], (1,
        2], (2, 3], and (3, ∞). Their fractions and corresponding
        model performances are shown in Figure&nbsp;<a class="fig"
        href="#fig5">5</a>c and&nbsp;5d .</p>
        <p>The <tt>ADJ</tt>’s MRR negatively correlates with the
        click depth: a lower click indicates more ambivalent search
        intent. In comparison, <tt>FMN</tt>’s relative improvement
        is positively correlated with the click depth. <tt>FMN</tt>
        has more leverage with the stronger feedback signal, which
        is also more useful for more ambivalent search intents as
        indicated by the deeper clicks.</p>
        <figure id="fig6">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186068/images/www2018-77-fig6.jpg"
          class="img-responsive" alt="Figure 6" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 6:</span>
            <span class="figure-title">Performance of FMN with
            different amounts of user feedbacks. The x-axis is the
            fractions of feedbacks provided to <tt>FMN</tt> when
            testing; the Y-axis is MMR.</span>
          </div>
        </figure>
        <p></p>
        <p><strong>Feedback Fraction:</strong> The second analysis
        studies <tt>FMN</tt>’s performance with different amounts
        of feedback signals. When testing, we randomly discard a
        certain fraction of user clicks and evaluate <tt>FMN</tt>
        accuracy accordingly. The results are plotted in
        Figure&nbsp;<a class="fig" href="#fig6">6</a>. The x-axis
        is the fraction of clicks used, from none of them are used
        (0%) to all of them (100%). The straight line is
        <tt>HRED</tt>.</p>
        <p>Figure&nbsp;<a class="fig" href="#fig6">6</a> confirms
        that the source of <tt>FMN</tt> effectiveness is its
        feedback-awareness. Without feedback signal, <tt>FMN</tt>
        performs worse than <tt>HRED</tt>. Recall that the no click
        session's negative feedback signal is helpful for
        <tt>FMN</tt>. However, if all feedback signals are
        discarded, the positive and negative feedbacks are mixed,
        which confuses <tt>FMN</tt>. As more feedback signals are
        included, <tt>FMN</tt>’s accuracy becomes better and
        better. This strong positive correlation is another
        evidence for the effectiveness of feedback-aware query
        suggestion.</p>
        <div class="table-responsive" id="tab4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class=
            "table-title">Examples of <tt>FMN</tt>’s query
            suggestions. The clicked documents reflect the variant
            information needs behind the same query. <tt>FMN</tt>
            incorporates the feedback signals and produces
            feedback-aware query suggestions.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">
                <strong>Query</strong></th>
                <th style="text-align:left;"><strong>Clicked
                Document</strong></th>
                <th><strong>Suggested Query</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">Apple</td>
                <td style="text-align:left;">Apple serial number
                lookup</td>
                <td>Apple serial number</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">Apple 110 official
                website</td>
                <td>Apple official website</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">Apple (China) -
                Official Website</td>
                <td>Apple China official website</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">Apple club serial
                number query</td>
                <td>Apple serial number</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">Man VS machine war,
                tencent.com</td>
                <td>Lee Sedol man VS machine war</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">Lee Sedol, Sogou
                Encyclopedia</td>
                <td>Lee Sedol</td>
              </tr>
              <tr>
                <td style="text-align:center;">Lee Sedol</td>
                <td style="text-align:left;">Google AI AlphaGo
                crack chess game - the era of science and
                technology</td>
                <td>AlphaGo VS Lee Sedol on live</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">Who is the best go
                player, Lee Sedol or Lee Chang-Ho? Chinese player
                Ke Jie beat Lee Sedol to win the championship</td>
                <td>Ke Jie beat Lee Sedol</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">Beautiful pictures of
                the 2018 FIFA world cup.</td>
                <td>2018 FIFA world cup pictures</td>
              </tr>
              <tr>
                <td style="text-align:center;">2018 FIFA world
                cup</td>
                <td style="text-align:left;">2018 where is the FIFA
                World Cup held ?</td>
                <td>2018 FIFA world cup host city</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:left;">2018 Russia FIFA world
                cup, Sogou Encyclopedia</td>
                <td>2018 Russia FIFA world cup</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p><strong>Examples:</strong> Table&nbsp;<a class="tbl"
        href="#tab4">4</a> provides some examples of feedback-aware
        query suggestion. For the same original query, we select
        the sessions where different search results were clicked,
        and list the queries suggested by <tt>FMN</tt>. These
        example queries can refer to various possible information
        needs, but the clicked documents reflect the search intents
        more clearly. Without additional contexts, the same query
        suggestion would be produced for the original query and
        miss the diverse search intents, but <tt>FMN</tt>
        successfully leveraged the feedback signal and produced
        proper query suggestions.</p>
      </section>
    </section>
    <section id="sec-15">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Conclusions and
          Future Work</h2>
        </div>
      </header>
      <p>This paper proposes the Feedback Memory Network
      (<tt>FMN</tt>) to model user feedbacks during a search. The
      clicked and skipped search results are more fine-grained
      reflections of the information needs behind the original
      query. <tt>FMN</tt> encodes the clicked and skipped documents
      as the positive and negative feedback memories to represent
      user's preference in the query. These feedback memories
      encode the feedback signals provided by the user when
      interacting with the search results.</p>
      <p>This paper integrates <tt>FMN</tt> with the hierarchical
      sequence-to-sequence neural query suggestion
      model&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0025">25</a>].
      It enriches the query representations in the sequence models
      with the feedback memories of <tt>FMN</tt>. The feedback
      memory network, and the sequence-to-sequence modeling of the
      query sequences are trained end-to-end using the search log.
      It leads to a systematic data-driven approach for
      feedback-aware query suggestion.</p>
      <p>Our experiments on a large scale search log from Sogou, a
      major Chinese search engine, demonstrated the robust
      advantages of <tt>FMN</tt>. Significant improvements are
      consistently observed over a frequency-based method,
      feature-based methods, and neural methods that do not
      consider user feedback. <tt>FMN</tt>’s advantages are more
      remarkably observed in more difficult scenarios. On too short
      or too long sessions where the information needs are less
      clear, <tt>FMN</tt>’s improvements are larger as the user
      preferences provide additional signals. On ambivalent
      queries, <tt>FMN</tt> also performs better because user
      preferences on the search results conveyed more fine-grained
      information and helped infer the information needs.</p>
      <p>Our analyses further demonstrate the influence of the
      feedback signals on query suggestion. When sessions have more
      clicks or when the user clicked on lower ranked search
      results, the feedback signals are richer and more
      informative, and <tt>FMN</tt> performs better. The feedback
      awareness also improves the query sequence modeling. They
      help the neural model fit the search behavior better and
      improve the suggestion accuracy, even when some feedback
      signals are omitted during testing.</p>
      <p><tt>FMN</tt> aims to provide a general approach to model
      user's interactions with the search engine. In the future
      work, we plan to integrate feedback memory network to other
      query suggestion models as well in other information
      retrieval tasks.</p>
    </section>
    <section id="sec-16">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span>
          ACKNOWLEDGEMENT</h2>
        </div>
      </header>
      <p>This work is supported by the National 973 Program
      (No.2014CB340501) and the Major Project of the National
      Social Science Foundation of China (No.13&amp;ZD190). Chenyan
      Xiong is supported by National Science Foundation (NSF) grant
      IIS-1422676. We thank Sogou for providing free access to the
      search log. Any opinions, findings, and conclusions in this
      paper are the authors’ and do not necessarily reflect those
      of the sponsors.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Ricardo Baeza-Yates and
        Alessandro Tiberi. 2007. Extracting Semantic Relations from
        Query Logs. In <em>Proceedings of KDD</em>. 76–85.</li>
        <li id="BibPLXBIB0002" label="[2]">Ricardo&nbsp;A
        Baeza-Yates, Carlos&nbsp;A Hurtado, Marcelo Mendoza, <em>et
        al.</em> 2004. Query Recommendation Using Query Logs in
        Search Engines. In <em>Proceedings of EDBT</em>.</li>
        <li id="BibPLXBIB0003" label="[3]">Paolo Boldi, Francesco
        Bonchi, Carlos Castillo, Debora Donato, Aristides Gionis,
        and Sebastiano Vigna. 2008. The Query-flow Graph: Model and
        Applications. In <em>Proceedings of CIKM</em>.
        609–618.</li>
        <li id="BibPLXBIB0004" label="[4]">Francesco Bonchi,
        Raffaele Perego, Fabrizio Silvestri, Hossein Vahabi, and
        Rossano Venturini. 2012. Efficient Query Recommendations in
        The Long Tail via Center-piece Subgraphs. In
        <em>Proceedings of SIGIR</em>. 345–354.</li>
        <li id="BibPLXBIB0005" label="[5]">Antoine Bordes and Jason
        Weston. 2016. Learning End-to-end Goal-oriented Dialog.
        <em>arXiv preprint arXiv:1605.07683</em> (2016).</li>
        <li id="BibPLXBIB0006" label="[6]">Ilaria Bordino,
        Gianmarco De&nbsp;Francisci&nbsp;Morales, Ingmar Weber, and
        Francesco Bonchi. 2013. From Machu_Picchu to Rafting the
        Urubamba River: Anticipating Information Needs via The
        Entity-query Graph. In <em>Proceedings of WSDM</em>.
        275–284.</li>
        <li id="BibPLXBIB0007" label="[7]">Huanhuan Cao,
        Derek&nbsp;Hao Hu, Dou Shen, Daxin Jiang, Jian-Tao Sun,
        Enhong Chen, and Qiang Yang. 2009. Context-aware Query
        Classification. In <em>Proceedings of SIGIR</em>.
        3–10.</li>
        <li id="BibPLXBIB0008" label="[8]">Huanhuan Cao, Daxin
        Jiang, Jian Pei, Qi He, Zhen Liao, Enhong Chen, and Hang
        Li. 2008. Context-aware Query Suggestion by Mining
        Click-through and Session Data. In <em>Proceedings of
        KDD</em>. 875–883.</li>
        <li id="BibPLXBIB0009" label="[9]">Luo Cheng, Zheng Yukun,
        Liu Yiqun, Xu Jingfang, Zhang Min, and Ma Shaoping. 2017.
        SogouT-16: A New Web Corpus to Embrace IR Research. In
        <em>Proceedings of SIGIR</em>.</li>
        <li id="BibPLXBIB0010" label="[10]">Aleksandr Chuklin, Ilya
        Markov, and Maarten&nbsp;de Rijke. 2015. Click Models for
        Web Search. <em>Synthesis Lectures on Information Concepts,
        Retrieval, and Services</em> 7, 3(2015), 1–115.</li>
        <li id="BibPLXBIB0011" label="[11]">Mostafa Dehghani,
        Sascha Rothe, Enrique Alfonseca, and Pascal Fleury. 2017.
        Learning to Attend, Copy, and Generate for Session-Based
        Query Suggestion. <em>arXiv preprint arXiv:1708.03418</em>
        (2017).</li>
        <li id="BibPLXBIB0012" label="[12]">Qi He, Daxin Jiang,
        Zhen Liao, Steven C.&nbsp;H. Hoi, Kuiyu Chang, Ee&nbsp;Peng
        Lim, and Hang Li. 2009. Web Query Recommendation via
        Sequential Query Prediction. In <em>Proceedings of
        ICDE</em>. 1443–1454.</li>
        <li id="BibPLXBIB0013" label="[13]">Zhipeng Huang, Bogdan
        Cautis, Reynold Cheng, and Yudian Zheng. 2016. KB-Enabled
        Query Recommendation for Long-Tail Queries. In
        <em>Proceedings of CIKM</em>. 2107–2112.</li>
        <li id="BibPLXBIB0014" label="[14]">Alpa Jain, Umut
        Ozertem, and Emre Velipasaoglu. 2011. Synthesizing High
        Utility Suggestions for Rare Web Search Queries. In
        <em>Proceedings of SIGIR</em>. 805–814.</li>
        <li id="BibPLXBIB0015" label="[15]">Thorsten Joachims,
        Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased
        Learning-to-rank with Biased Feedback. In <em>Proceedings
        of WSDM</em>. 781–789.</li>
        <li id="BibPLXBIB0016" label="[16]">Rosie Jones, Benjamin
        Rey, Omid Madani, and Wiley Greiner. 2006. Generating Query
        Substitutions. In <em>Proceedings of WWW</em>.
        387–396.</li>
        <li id="BibPLXBIB0017" label="[17]">Zhongguo Li and Maosong
        Sun. 2009. Punctuation as Implicit Annotations for Chinese
        Word Segmentation. <em>Computational Linguistics</em> 35, 4
        (2009), 505–512.</li>
        <li id="BibPLXBIB0018" label="[18]">Qiaozhu Mei, Dengyong
        Zhou, and Kenneth Church. 2008. Query Suggestion Using
        Hitting Time. In <em>Proceedings of CIKM</em>.
        469–478.</li>
        <li id="BibPLXBIB0019" label="[19]">Tomas Mikolov, Ilya
        Sutskever, Kai Chen, Greg&nbsp;S Corrado, and Jeff Dean.
        2013. Distributed representations of Words and Phrases and
        Their Compositionality. In <em>Proceedings of
        NIPS</em>.</li>
        <li id="BibPLXBIB0020" label="[20]">Alexander Miller, Adam
        Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes,
        and Jason Weston. 2016. Key-value Memory Networks for
        Directly Reading Documents. In <em>Proceedings of
        EMNLP</em>.</li>
        <li id="BibPLXBIB0021" label="[21]">Umut Ozertem, Olivier
        Chapelle, Pinar Donmez, and Emre Velipasaoglu. 2012.
        Learning to Suggest: a Machine Learning Framework for
        Ranking Query Suggestions. In <em>Proceedings of
        SIGIR</em>. 25–34.</li>
        <li id="BibPLXBIB0022" label="[22]">Eldar Sadikov, Jayant
        Madhavan, Lu Wang, and Alon Halevy. 2010. Clustering Query
        Refinements by User Intent. In <em>Proceedings of WWW</em>.
        841–850.</li>
        <li id="BibPLXBIB0023" label="[23]">Rodrygo&nbsp;LT Santos,
        Craig Macdonald, and Iadh Ounis. 2013. Learning to Rank
        Query Suggestions for Adhoc and Diversity Search.
        <em>Information Retrieval</em> 16, 4 (2013), 429–451.</li>
        <li id="BibPLXBIB0024" label="[24]">Milad Shokouhi. 2013.
        Learning to Personalize Query Auto-completion. In
        <em>Proceedings of SIGIR</em>. 103–112.</li>
        <li id="BibPLXBIB0025" label="[25]">Alessandro Sordoni,
        Yoshua Bengio, Hossein Vahabi, Christina Lioma,
        Jakob&nbsp;Grue Simonsen, and Jian-Yun Nie. 2015. A
        Hierarchical Recurrent Encoder-Decoder For Generative
        Context-Aware Query Suggestion. In <em>Proceedings of
        CIKM</em>.</li>
        <li id="BibPLXBIB0026" label="[26]">Sainbayar Sukhbaatar,
        Jason Weston, Rob Fergus, <em>et al.</em> 2015. End-to-end
        Memory Networks. In <em>Proceedings of NIPS</em>.
        2440–2448.</li>
        <li id="BibPLXBIB0027" label="[27]">Idan Szpektor,
        Aristides Gionis, and Yoelle Maarek. 2011. Improving
        Recommendation for Long-tail Queries via Templates. In
        <em>Proceedings of WWW</em>. 47–56.</li>
        <li id="BibPLXBIB0028" label="[28]">Hossein Vahabi,
        Margareta Ackerman, David Loker, Ricardo Baeza-Yates, and
        Alejandro Lopez-Ortiz. 2013. Orthogonal Query
        Recommendation. In <em>Proceedings of RecSys</em>.
        33–40.</li>
        <li id="BibPLXBIB0029" label="[29]">Biao Xiang, Daxin
        Jiang, Jian Pei, Xiaohui Sun, Enhong Chen, and Hang Li.
        2010. Context-aware Ranking in Web Search. In
        <em>Proceedings of SIGIR</em>. 451–458.</li>
        <li id="BibPLXBIB0030" label="[30]">Chenyan Xiong, Zhuyun
        Dai, Jamie Callan, Zhiyuan Liu, and Russell Power. 2017.
        End-to-End Neural Ad-hoc Ranking with Kernel Pooling. In
        <em>Proceedings of SIGIR</em>.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>⁎</sup></a>Bin Wu and
    Chenyan Xiong contributed equally to this work.</p>
    <p id="fn2"><a href="#foot-fn2"><sup>†</sup></a>corresponding
    author</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3178876.3186068">https://doi.org/10.1145/3178876.3186068</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
