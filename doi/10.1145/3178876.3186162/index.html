<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>The Effect of Ad Blocking on User Engagement with the Web</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
  <link rel="cite-as" href="https://doi.org/10.1145/3178876.3186162"/>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186162'>https://doi.org/10.1145/3178876.3186162</a>.
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186162'>https://w3id.org/oa/10.1145/3178876.3186162</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">The Effect of Ad Blocking on User Engagement with the Web</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <a href="https://orcid.org/1234-5678-9012" ref="author"><span class="givenName">Ben</span> <span class="surName">Miroglio</span></a>, Mozilla Corporation, Mountain View, CA, USA, <a href="mailto:bmiroglio@mozilla.com">bmiroglio@mozilla.com</a>
        </div>
        <div class="author">
          <span class="givenName">David</span> <span class="surName">Zeber</span>, Mozilla Corporation, Mountain View, CA, USA, <a href="mailto:dzeber@mozilla.com">dzeber@mozilla.com</a>
        </div>
        <div class="author">
          <span class="givenName">Jofish</span> <span class="surName">Kaye</span>, Mozilla Corporation, Mountain View, CA, USA, <a href="mailto:jkaye@mozilla.com">jkaye@mozilla.com</a>
        </div>
        <div class="author">
          <span class="givenName">Rebecca</span> <span class="surName">Weiss</span>, Mozilla Corporation, Mountain View, CA, USA, <a href="mailto:rweiss@mozilla.com">rweiss@mozilla.com</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.3186162" target="_blank">https://doi.org/10.1145/3178876.3186162</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Web users are increasingly turning to ad blockers to avoid ads, which are often perceived as annoying or an invasion of privacy. While there has been significant research into the factors driving ad blocker adoption and the detrimental effect to ad publishers on the Web, the resulting effects of ad blocker usage on Web users’ browsing experience is not well understood. To approach this problem, we conduct a retrospective natural field experiment using Firefox browser usage data, with the goal of estimating the effect of adblocking on user engagement with the Web. We focus on new users who installed an ad blocker after a baseline observation period, to avoid comparing different populations. Their subsequent browser activity is compared against that of a control group, whose members do not use ad blockers, over a corresponding observation period, controlling for prior baseline usage. In order to estimate causal effects, we employ propensity score matching on a number of other features recorded during the baseline period. In the group that installed an ad blocker, we find significant increases in both active time spent in the browser (+28% over control) and the number of pages viewed (+15% over control), while seeing no change in the number of searches. Additionally, by reapplying the same methodology to other popular Firefox browser extensions, we show that these effects are specific to ad blockers. We conclude that ad blocking has a positive impact on user engagement with the Web, suggesting that any costs of using ad blockers to users’ browsing experience are largely drowned out by the utility that they offer.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS Concepts:</span> • <strong>Information systems</strong> → <strong>Online advertising;</strong> <strong>Browsers;</strong> • <strong>General and reference</strong> → <em>Empirical studies;</em></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style="font-weight:bold;"><small>Keywords:</small></span> <span class="keyword"><small>Ad Blocking; Propensity Scoring; Matching; Natural Field Experiment; User Studies</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Ben Miroglio, David Zeber, Jofish Kaye, and Rebecca Weiss. 2018. The Effect of Ad Blocking on User Engagement with the Web. In <em>WWW 2018: The 2018 Web Conference,</em> <em>April 23–27, 2018 (WWW 2018),</em> <em>Lyon, France. ACM, New York, NY, USA</em> 9 Pages. <a href="https://doi.org/10.1145/3178876.3186162" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3178876.3186162</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <p>For an average user, a typical day on the Web involves exposure to ads. Indeed, advertising has become the primary revenue model for many popular websites, most notably search engines, media outlets and streaming services. There has been substantial research into user perception of online ads and the steps taken to avoid them. Ads are often seen as annoying, or lead to a negative Web browsing experience [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>], and the prevalence of behavioral or retargeted ads raises concerns about privacy [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0049">49</a>]. This in turn leads to reduced effectiveness from the point of view of ad publishers [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>].</p>
      <p>As a result, Web users are increasingly turning to ad blocking to mitigate the negative effects of online ads. A recent study estimates that over 600M devices worldwide were using ad blocking by the end of 2016, of which over half were mobile; this represents a 30% increase since 2015 [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0042">42</a>]. Furthermore, ad blockers top the list of most popular Firefox extensions, with at least 18M installs [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0034">34</a>].</p>
      <section id="sec-6">
        <header>
          <div class="title-info">
            <h3><span class="section-number">1.1</span> The effect of ad blocking on the Web ecosystem</h3>
          </div>
        </header>
        <p>Ad blocking is, understandably, very unpopular among ad publishers, with the IAB recently labelling the practice a “potential existential threat” [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>]. This is quantified by a recent industry study which found that the use of ad blocking leads to significant worsening in the traffic rank of sites that depend on ads [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0048">48</a>], a compound effect of the revenue loss. Ad publishers’ attempts to combat ad blockers by limiting site access to ad blocker users has lead to an “arms race” [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0039">39</a>], although the net effect is that users generally abandon such sites [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0042">42</a>].</p>
        <p>On the other hand, there are a number of ways that employing ad blockers improves users’ experience on the Web, beyond avoiding the annoyance of ads. For one thing, the amount of data loaded when visiting pages with ads is significantly reduced [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0045">45</a>], leading to savings in both load times and data costs on mobile. In fact, among a selection of popular news sites, over half the data loaded (in aggregate) was found to be ad-related [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>]. In addition to boosting site performance, blocking ads reduces exposure to privacy and security threats associated with ads such as behavioral tracking and malvertising [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>]. As well as being measurable quantitatively, these benefits are understood by users, as demonstrated by a number of user research studies on this topic [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0042">42</a>].</p>
      </section>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">1.2</span> What is the effect of ad blocking on Web engagement?</h3>
          </div>
        </header>
        <p>Although much of the recent research has focused on the specific mechanisms by which ad blockers impact user experience or the economic impact to ad publishers, the overall effect of users’ choice to use an ad blocker on their general Web usage has not been well studied. This is the contribution we make in this work, by addressing the question: how different is user engagement with the Web for users who installed an ad blocker in their browser from those who did not? If ad blocking is ultimately detrimental to the Web ecosystem as a whole, we expect to see a drop in Web usage among ad blocker users. On the other hand, if alleviating the negative experience caused by ads actually outweighs the potential breakage, we hypothesize that Web usage would be increased.</p>
        <p>We tackle this problem by studying Firefox usage data. The Firefox browser reports daily aggregate statistics on Web usage, such as total active time in the browser and number of pages loaded, as well as currently installed browser extensions (“add-ons”). Drawing on a historical dataset of Firefox usage, we frame the question as a natural experiment [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>].</p>
        <p>Restricting to new users who installed Firefox during a specific time period, we select a test group of users who installed an ad blocker, and a control group that did not. The selection is performed using a matching technique applied to baseline user features, which allows us to infer a degree of causality from the observed effects. We then compare test group Web usage after installing the ad blocker to control group usage over a comparable period, controlling for baseline usage levels. This is sometimes referred to as analysis of covariance, and is closely related to difference-in-difference analysis.</p>
        <p>There are many benefits afforded by this approach. By working with usage data as reported by the browser from a large set of users, we obtain a large-scale, “objective” view that doesn't depend on the specific ways in which blocking ads modifies users’ experience on the Web or on subjective user responses. Additionally, all of the required data is already collected by the Firefox browser as a part of normal operation. This means that there are no additional costs in terms of participant recruitment or data collection. Furthermore, the design can be revised and the analysis rerun as needed with little additional overhead. In fact, we make use of this feature to run placebo studies for the usage effects of other Firefox add-ons, to further bolster the causality claim.</p>
        <p>Moreover, designing the study as a natural experiment allows us to estimate the effect of actually making the choice to use an ad blocker. In contrast, a randomized experiment where users are randomly assigned to use an ad blocker, while offering the strongest guarantee of causality, can only measure the consequences of blocking ads on the Web; users’ discovery of ad blocking technology and their choice to use it plays no role. For this reason, natural experiment designs are commonly used when studying the effects of users’ choices or behaviors, such as in the context of social media and online communities [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>], or online advertising [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>].</p>
      </section>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Experimental Design</h2>
        </div>
      </header>
      <p>The goal of our study is to quantify the causal effect of ad blocking usage on user engagement with the Web via the Firefox browser. The preferred methodology for causal inference, the so-called “gold standard”, is a randomized experiment, where users are randomly assigned to test and contol groups. In our context, that would mean that a random subset of users get an ad blocker installed in their browser.</p>
      <p>However, there are two main reasons why this approach is infeasible in our setting. For one thing, forcibly installing an ad blocker, or any other extension which would substantially change browsing experience, in users’ browsers raises ethical concerns for Mozilla, as it may not respect users’ preferences and may adversely affect their browsing experience.</p>
      <p>The other issue is that a randomized design lacks <em>ecological validity</em>, i.e. it does not reflect the way ad blocking is generally used. In most cases, a user comes to learn about ad blocking technology, often via word of mouth [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0042">42</a>], and then makes a decision to install an ad blocker to address a bad Web experience. Additionally, there are likely systemic differences between users who learn about ad blockers (or browser extensions in general) and further choose to act on that knowledge, and those who never do. Also, because of the prevalence of ads, the Web experience after installing the ad blocker becomes noticeably different from the user's point of view, which they may associate with their choice to use an ad blocker. This in turn may affect their subsequent usage. A randomized experiment cannot take these effects into account. Instead, the randomization “removes” any implicit differences in the population groups by ensuring that they are balanced.</p>
      <p>Phrasing our research question in more general terms, we are interested in the value to users of having ad blockers available as part of the browser extension ecosystem, measured in terms of browser usage. To this end, we opt for causal inference via a natural experiement (i.e. an observational study [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0046">46</a>]). It is important to note that the causality we are seeking to assert is not that <em>ad blocking will affect any Firefox user's Web usage in the observed way</em> but rather that <em>the effects we observe among the test group are due to their installation of an ad blocker and not other implicit factors</em>. Any fundamental differences between ad blocker users and the rest of the population are not addressed in these findings.</p>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Data</h3>
          </div>
        </header>
        <p>In this study, we analyze usage data reported by users of the desktop Firefox Web browser. During the course of typical browser usage, Firefox sends usage data to Mozilla using a data collection system referred to as Telemetry [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0036">36</a>]. The exclusive data source for this study is a Telemetry data record known as the <em>“main”ping</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0035">35</a>], which is sent at least once a day for each active user, and contains a range of activity and environmental measurements such as:</p>
        <ul class="list-no-style">
          <li id="list1" label="•">overall and active browser session time<br /></li>
          <li id="list2" label="•">numbers of searches (initiated from the UI search bars) and pages loaded<br /></li>
          <li id="list3" label="•">numbers of tabs and windows opened<br /></li>
          <li id="list4" label="•">whether Firefox is the default browser<br /></li>
          <li id="list5" label="•">the current default search engine<br /></li>
          <li id="list6" label="•">date of Firefox installation<br /></li>
          <li id="list7" label="•">app information, e.g. version and distribution channel<br /></li>
          <li id="list8" label="•">system information, e.g. OS and version, memory size<br /></li>
          <li id="list9" label="•">the list of current browser add-ons.<br /></li>
        </ul>
        <p>Each record is annotated with a unique user ID and submission date, which allows for user-level longitudinal analysis.</p>
        <p>This study is purely retrospective, in the sense that all the data we use had already been collected prior to its inception as a part of normal operation of the native client. We do not perform any kind of recruitment or specialized data collection.</p>
      </section>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Study periods</h3>
          </div>
        </header>
        <p>Among the users represented in the Telemetry dataset, we restrict to those located in the United States who installed the standard English-language (en-US locale) build of Firefox during the month of February 2017. This choice of population segment helps to reduce extraneous variability due to regional differences in Web browsing behaviour and seasonality in browser usage, which is generally consistent from February up until the summer months.</p>
        <p>For each of these users, we then segment their first 70 calendar days since installation into three consecutive periods:</p>
        <ul class="list-no-style">
          <li id="list10" label="•">a <em>baseline period</em> covering the first 28 days<br /></li>
          <li id="list11" label="•">a <em>treatment period</em> consisting of the next 14 days<br /></li>
          <li id="list12" label="•">an <em>observation period</em> lasting the remaining 28 days.<br /></li>
        </ul>
        <p>We restrict to users who installed no add-ons during their baseline period, and require that they submitted at least 5 Telemetry records during each of the baseline and observation periods, to ensure that we have sufficient data. We then select a <em>test</em> group of users who installed any add-on at some point during the treatment period, and a <em>control</em> group who installed no add-ons during any of their three periods. We will further segment test users according to which add-on it was that they installed, with a primary focus on ad blockers, as described in Section <a class="sec" href="#sec-20">3.2</a>.</p>
        <p>We adopt a non-equivalent groups design, in which we compare browser usage during the observation period between the groups, controlling for features recorded during the baseline period. We allow 28 days for both baselining and observation so that we can assess users’ established browser patterns both before and after installing the add-on.</p>
        <p>Note that, because each user's timescale begins when they install Firefox, their periods may span different calendar dates. Nonetheless, any two users’ time periods are offset by no more than 27 days, since they are constrained to have installed Firefox during February 1-28. These relationships are illustrated in Figure <a class="fig" href="#fig1">1</a>.</p>
        <figure id="fig1">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186162/images/www2018-171-fig1.jpg" class="img-responsive" alt="Figure 1" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span> <span class="figure-title">Illustration of overlapping user study periods.</span>
          </div>
        </figure>
        <p></p>
        <p>Selected in this way, our dataset contains 16,414 test users and 342,528 control users—our test group being much smaller due to the additional restrictions we imposed. We now proceed to select an appropriate subset of the control group via matching.</p>
      </section>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.3</span> Matching procedure</h3>
          </div>
        </header>
        <p>Since group membership is based on observed behaviour and not assigned by randomization, it may be the case that users in the test group are just more engaged to begin with, rather than their experience being affected by the use of an ad blocker. To remove this contingency and to reinforce the causality in our results, we seek to ensure that the groups are <em>a priori</em> balanced on any observable features, i.e. that there are no systematic differences between them. This is achieved using matching. Each test group member is paired with a similar member of the control group, where similarity is determined based on features observed during the baseline period. This ensures that the groups start off “more or less the same”, e.g. that one group is not biased towards more engaged users.</p>
        <section id="sec-12">
          <p><em>2.3.1 Propensity scoring.</em> Similarity between users is assessed using propensity scores, which represent a user's likelihood to install an add-on. Such a score can be computed using a logistic regression model which predicts the probability a user will install an add-on, given what we observe about them in the baseline period.</p>
          <p>More formally, for each user <em>i</em>, let <em>X<sub>i</sub></em> = (<em>X</em> <sub><em>i</em>1</sub>, <em>X</em> <sub><em>i</em>2</sub>, …, <em>X<sub>ik</sub></em> ) denote a vector of <em>k</em> features observed during the baseline period, and let <em>T<sub>i</sub></em> indicate group membership:</p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation*} T_i = \left\lbrace \begin{array}{@{}l@{\quad }l@{}}1 &amp; \text{if user $i$ is in the test group}\\ 0 &amp; \text{otherwise} \end{array}\right.\end{equation*}</span><br />
            </div>
          </div>The propensity score for user <em>i</em> is defined as
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation*} \pi _i := \pi (X_i) = Pr(T_i = 1 \,|\, X_i).\end{equation*}</span><br />
            </div>
          </div>Scores are computed by fitting a logistic regression model
          <div class="table-responsive" id="eq1">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} \log \bigg (\frac{\pi _i}{1-\pi _i}\bigg) = X_i\beta + \epsilon _i, \quad i = 1,\dots ,n \end{equation}</span><br />
              <span class="equation-number">(1)</span>
            </div>
          </div>to yield estimates <span class="inline-equation"><span class="tex">$\hat{\pi }_i = g(X_i\hat{\beta })$</span></span> , where <em>g</em> is the inverse of the logit function used in the LHS of (<a class="eqn" href="#eq1">1</a>). The list of features used in propensity scoring is provided in Table <a class="tbl" href="#tab1">1</a>.
          <p></p>
        </section>
        <section id="sec-13">
          <p><em>2.3.2 Correction for class imbalance.</em> From a modeling perspective, we have a class imbalance problem, which can bias our model by heavily weighting majority (control) class features, dwarfing any separable features in the minority (test) class. To mitigate this, we undersample from the control group, drawing a random sample of control users equal in size to the test group to create a balanced dataset. However, in the process, we risk losing valuable information due to the exclusion of the majority of the control group.</p>
          <p>We correct for this by means of a bootstrap aggregation approach. Let <em>n<sub>T</sub></em> be the number of test users. We draw <em>m</em> samples of size <em>n<sub>T</sub></em> from the control group. Each sample is combined with the full test group to create a dataset of size 2<em>n<sub>T</sub></em> , and the logistic model (<a class="eqn" href="#eq1">1</a>) is fit to this reduced dataset to obtain propensity score estimates <span class="inline-equation"><span class="tex">$\hat{\pi }_{ij}$</span></span> , <em>i</em> = 1, …, <em>n</em>, <em>j</em> = 1, …, <em>m</em>. The final propensity score we use in matching is obtained by averaging across the replicate model fits:</p>
          <div class="table-responsive" id="Xeq1">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} \hat{\pi }_i := \frac{1}{m}\sum _{j=1}^{m} \hat{\pi }_{ij}. \end{equation}</span><br />
              <span class="equation-number">(2)</span>
            </div>
          </div>
          <p></p>
          <p>Figure <a class="fig" href="#fig2">2</a> shows that the test group, on average, was assigned higher propensity scores than the control group, meaning that the baseline features <em>X<sub>i</sub></em> do in fact contain information about a user's eventual decision to install an add-on. This distributional difference between the propensity scores of our two groups justifies the need for the matching procedure, since the groups are not directly comparable otherwise.</p>
          <figure id="fig2">
            <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186162/images/www2018-171-fig2.jpg" class="img-responsive" alt="Figure 2" longdesc="" />
            <div class="figure-caption">
              <span class="figure-number">Figure 2:</span> <span class="figure-title">Distribution of propensity scores by group (<em>m</em> = 1000).</span>
            </div>
          </figure>
          <p></p>
          <div class="table-responsive" id="tab1">
            <div class="table-caption">
              <span class="table-number">Table 1:</span> <span class="table-title">Features used for propensity scoring (<em>X</em>).</span>
            </div>
            <table class="table">
              <tbody>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Is default</strong></td>
                  <td>Boolean indicating if Firefox is the user's default browser</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Operating system</strong></td>
                  <td>Windows, MacOS, Linux</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Browser version</strong></td>
                  <td>Firefox version string</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Memory MB</strong></td>
                  <td>Memory size on a user's machine</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Sync configured</strong></td>
                  <td>Boolean indicating if a user set up a sync account</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Active hours</strong></td>
                  <td>Total time the user spent interacting with the browser</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Session length</strong></td>
                  <td>Total browser session time</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Number of subsessions</strong></td>
                  <td>Total Telemetry reports</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Total tab open events</strong></td>
                  <td>Number of tabs opened</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Total URI count</strong></td>
                  <td>Total number of pages loaded</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Unique URI count</strong></td>
                  <td>Number of unique websites (TLD+1) visited</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Address bar searches</strong></td>
                  <td>Number of searches initiated from the address bar</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Search bar searches</strong></td>
                  <td>Number of searches initiated from the dedicated search bar</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Total Yahoo searches</strong></td>
                  <td>Number of searches made using the Yahoo search engine</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Total Google searches</strong></td>
                  <td>Number of searches made using the Google search engine</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Total searches</strong></td>
                  <td>Total number of searches overall initiated from one of the Firefox search bars</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Number of bookmarks</strong></td>
                  <td>Total bookmarks added</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Length of history</strong></td>
                  <td>Total number of pages visited</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>Quantum ready</strong></td>
                  <td>Boolean indicating if a client qualifies for the Firefox Quantum Project</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>E10s enabled</strong></td>
                  <td>Whether multiprocess is enabled</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;"><strong>E10s cohort</strong></td>
                  <td>Branch assignment for the multiprocess experiment</td>
                </tr>
              </tbody>
            </table>
          </div>
        </section>
        <section id="sec-14">
          <p><em>2.3.3 Matching.</em> Each test user is matched to the control user whose propensity score is closest to its own, provided the difference is less than a set threshold <em>δ</em>, otherwise that test user is dropped from the dataset. In other words, given a test user <em>u<sub>t</sub></em> , we find the set of candidate matches</p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\[ C(u_t) = \big \lbrace u_c \in \text{control} \,:\, |\hat{\pi }_{u_c} - \hat{\pi }_{u_t}| \le \delta \big \rbrace . \]</span><br />
            </div>
          </div>If |<em>C</em>(<em>u<sub>t</sub></em> )| = 0, <em>u<sub>t</sub></em> is not matched, and is excluded from further consideration. Otherwise, we select the control user <em>u<sub>c</sub></em> satisfying
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\[ \text{argmin}_{u_c \in C(u_t)}\, |\hat{\pi }_{u_c} - \hat{\pi }_{u_t}|, \]</span><br />
            </div>
          </div>and retain the pair of users.
          <p></p>
          <p>Note that reducing <em>δ</em> improves the balance of the dataset at the cost of reducing its size. We ran matching for various values of <em>δ</em>, and found that setting <em>δ</em> = 0.0001 retains over 99% of the test group. This is the value we use in the following.</p>
          <p>Also, it is important to note that a single control user can be matched to multiple test users using the procedure described above. We account for this in subsequent modeling by weighting each record by the inverse of its frequency (i.e. if a control user occurs 3 times in the matched dataset, we assign it a weight of <span class="inline-equation"><span class="tex">$\frac{1}{3}$</span></span> ). In the final matched dataset, duplication is rare: approximately 2% of control users occur twice, and less that 1% occur three times. The final dataset contains 32,825 records (16,414 and 15,724 <strong>distinct</strong> test and control users, respectively).</p>
        </section>
      </section>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.4</span> Match evaluation</h3>
          </div>
        </header>
        <p>After applying the matching procedure, it is important to validate that the groups are indeed indistinguishable in terms of the <em>k</em> covariates observed in the baseline period, as this will influence the selection of the final model. We treat categorical and continuous features separately in this evaluation.</p>
        <section id="sec-16">
          <p><em>2.4.1 Categorical features.</em> If matching was successful, categorical variables should have approximately the same relative frequencies between the test and control groups. In other words, the distribution of the categorical variable should be independent of the group label. For each categorical feature listed in Table <a class="tbl" href="#tab1">1</a>, we test independence between the groups using a Chi-square Test of Independence. We apply the test to the dataset both before and after matching, for comparison purposes.</p>
          <p>Table <a class="tbl" href="#tab2">2</a> lists the P-values resulting from each test run. Recall that a small P-value indicates there is dependence between the groups (relative frequencies are different). At the 5% significance level (<em>α</em> = 0.05), we fail to find dependence on the group label for any categorical feature observed in the matched dataset. However, prior to matching, each P-value is very close to 0, implying that the baseline period frequency distributions do differ between the groups.</p>
          <div class="table-responsive" id="tab2">
            <div class="table-caption">
              <span class="table-number">Table 2:</span> <span class="table-title">Chi-square test P-values before/after matching.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:right;border-right:1px solid #000;">Feature</th>
                  <th style="text-align:center;">Before</th>
                  <th>After</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Is default</td>
                  <td style="text-align:center;">0</td>
                  <td>0.3242</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Operating system</td>
                  <td style="text-align:center;">0</td>
                  <td>0.3124</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Browser version</td>
                  <td style="text-align:center;">0</td>
                  <td>0.9908</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Sync configured</td>
                  <td style="text-align:center;">0</td>
                  <td>0.1237</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Quantum ready</td>
                  <td style="text-align:center;">0</td>
                  <td>0.5410</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">E10s enabled</td>
                  <td style="text-align:center;">0</td>
                  <td>0.6606</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">E10s cohort</td>
                  <td style="text-align:center;">0</td>
                  <td>0.6138</td>
                </tr>
              </tbody>
            </table>
          </div>
        </section>
        <section id="sec-17">
          <p><em>2.4.2 Continuous features.</em> Similarly, we check for distributional differences between the test and control groups for the continuous features. As these distributions tend to be highly skewed and suffer from discreteness, we apply two nonparametric tests, which in conjunction give us good sense of the “balance” in the dataset. We compare ECDFs using a bootstrapped Kolmogorov-Smirnov (KS) test, for which the P-value is computed empirically over 1000 bootstrapped samples, to provide coverage for discreteness [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>]. Additionally, we use the Quadratic-Chi Histogram Distance (QCHD) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0043">43</a>] to compare the raw histograms, again bootstrapping the P-value (as a permutation test).</p>
          <p>Table <a class="tbl" href="#tab3">3</a> shows the resulting P-values for both tests applied to the data before and after matching. Again, a small P-value indicates lack of independence between the groups. As evidenced by the low P-values, we have not balanced the continuous features as well as the categorical features. We will handle this imbalance by controlling for a user's baseline activity in the final models.</p>
          <div class="table-responsive" id="tab3">
            <div class="table-caption">
              <span class="table-number">Table 3:</span> <span class="table-title">Bootstrap KS test and QCDH permutation test P-values before/after matching.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:right;border-right:1px solid #000;">Feature</th>
                  <th style="text-align:center;" colspan="2">
                    KS
                    <hr />
                  </th>
                  <th style="text-align:center;" colspan="2">
                    QCDH
                    <hr />
                  </th>
                </tr>
                <tr>
                  <th style="text-align:right;border-right:1px solid #000;"></th>
                  <th style="text-align:center;">Before</th>
                  <th style="text-align:center;">After</th>
                  <th style="text-align:center;">Before</th>
                  <th>After</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Memory MB</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Active hours</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Session length</td>
                  <td style="text-align:center;">0.001</td>
                  <td style="text-align:center;">0.016</td>
                  <td style="text-align:center;">0.228</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Number of subsessions</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td>0</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Total tab open events</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td>0.561</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Total URI count</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0.007</td>
                  <td style="text-align:center;">0</td>
                  <td>0.037</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Unique URI count</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td>0.019</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Address bar searches</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0.006</td>
                  <td style="text-align:center;">1</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Search bar searches</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">1</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Total Yahoo searches</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0.014</td>
                  <td style="text-align:center;">1</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Total Google searches</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">1</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Total searches</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">1</td>
                  <td>1</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Number of bookmarks</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0.008</td>
                  <td style="text-align:center;">0</td>
                  <td>0.01</td>
                </tr>
                <tr>
                  <td style="text-align:right;border-right:1px solid #000;">Length of history</td>
                  <td style="text-align:center;">0</td>
                  <td style="text-align:center;">0.002</td>
                  <td style="text-align:center;">0</td>
                  <td>0.215</td>
                </tr>
              </tbody>
            </table>
          </div>
        </section>
      </section>
    </section>
    <section id="sec-18">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Modeling and results</h2>
        </div>
      </header>
      <p>We now estimate the effect of installing an ad blocker on observation period Web engagement.</p>
      <section id="sec-19">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Engagement response measures</h3>
          </div>
        </header>
        <p>User engagement is an abstract concept described in terms of users’ cognitive involvement with a technology, which generally relates to the quality of their experience [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0024">24</a>]. While the direct study of user engagement typically employs qualitative research methodology [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0040">40</a>], it is common to quantify engagement with a product or website using proxy measurements that capture the amount in which users interact with the technology, such as usage or dwell time, page loads, clicks, etc [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0044">44</a>]. In this study, we consider three such measures of Web engagement.</p>
        <p><strong>Active hours</strong> roughly captures the amount of mouse and keyboard interaction with the browser. It is based on a Telemetry measurement called <em>active ticks</em>. The browser session is split into 5-second intervals, and each interval which saw key presses or mouse movements is counted as an active tick. <a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> We consider this measurement an indicator of Web usage in cases where a given website or Web application demands interactivity from the user.</p>
        <p><strong>Total URIs</strong> is a counter that reflects the total amount of requests that the browser makes in a given session. We consider this variable to serve as an indicator of Web navigation, regardless of the interactivity of the websites a particular client visits.</p>
        <p>Finally, we also consider <strong>Search Volume</strong> made using the search bars embedded in the Firefox UI (also referred to as <em>search access points</em>). We included this variable as an enagement measure since we assert that search is a fundamental part of modern Web navigation for most users today.</p>
        <p>The combination of these variables allow for us to analyze engagement across a broad array of usage patterns on the Web. For example, the active hours response might be very useful for users who tend to visit highly interactive websites, but would underestimate Web usage for users who primarily consume streaming content.</p>
      </section>
      <section id="sec-20">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Model specification</h3>
          </div>
        </header>
        <p>We estimate differences in Web enagement by fitting linear regression models of the form</p>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \log (Y_{obs}) = \beta _0 + \beta _1\log (Y_{base}) + \beta _2 T + X\gamma + \epsilon , \end{equation}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>where:
        <p></p>
        <ul class="list-no-style">
          <li id="list13" label="•"><em>Y<sub>obs</sub></em> is one of Active Hours, Total URI Count, or Search Volume as measured during the observation period,<br /></li>
          <li id="list14" label="•"><em>Y<sub>base</sub></em> is the baseline value for the same measure,<br /></li>
          <li id="list15" label="•"><em>T</em> is a treatment indicator (taking the value 1 if the user belongs to the treatment group and 0 otherwise), and<br /></li>
          <li id="list16" label="•"><em>X</em> = (<em>X</em> <sub>1</sub>, <em>X</em> <sub>2</sub>, …, <em>X<sub>v</sub></em> ) is a vector of continuous features recorded during the baseline period.<br /></li>
        </ul>
        <p>Each of the engagement measures is log-transformed in order to correct for high skewness, a common characteristic of such Web-related measurements. The continuous features <em>X</em> are included in the model as controlling factors, since these were not fully balanced during the matching process as noted in Section <a class="sec" href="#sec-17">2.4.2</a>.</p>
        <p>It is important to note that, although our matching procedure incorporates the baseline measures <em>Y<sub>base</sub></em> , none of these is adequately balanced after the process. Nonetheless, since we are modelling relative differences per user along these measures, an imbalance for <em>Y<sub>base</sub></em> between treatment and control is acceptable since it is explicitly controlled for. Additionally, continuous features <em>X</em> are included in the model (<a class="eqn" href="#eq2">3</a>) to ensure that any imbalances unresolved by matching do not skew the estimate for <em>β</em> <sub>2</sub>. For example, when <em>Y</em> = <em>Active Hours</em>, we include all continuous features to better isolate the true effect that <em>T</em> has on <em>Y<sub>obs</sub></em> . In fact, the rounded estimates in Table <a class="tbl" href="#tab5">5</a> remain unchanged if <em>X</em> is excluded from the model, however we include it to bring attention to its role in the model design.</p>
        <p>Although the primary focus of this study is the installation of ad blockers, we can redefine the test group to contain users who installed any specific set of Firefox add-ons, maintaining the control group of users who did not install any add-on. We can then rerun the entire procedure outlined in previous sections and refit model (<a class="eqn" href="#eq2">3</a>) with the updated treatment indicator <em>T</em>. Following this approach, we consider four distinct test groups, determined by which add-on was installed during the treatment period (defined in Section <a class="sec" href="#sec-10">2.2</a>). The add-ons for each group are laid out in Table <a class="tbl" href="#tab4">4</a>.</p>
        <div class="table-responsive" id="tab4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class="table-title">Add-ons for test groups.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:right;border-right:1px solid #000;">Test group</th>
                <th>Add-ons installed</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:right;border-right:1px solid #000;"><em>adblocker</em></td>
                <td>
                  either AdBlock Plus (ABP) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0032">32</a>] or uBlock Origin [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0037">37</a>], the two most popular ad-blocking Firefox add-ons
                </td>
              </tr>
              <tr>
                <td style="text-align:right;border-right:1px solid #000;"><em>any_addon</em></td>
                <td>
                  any Firefox add-on [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0033">33</a>]
                </td>
              </tr>
              <tr>
                <td style="text-align:right;border-right:1px solid #000;"><em>vdh</em></td>
                <td>
                  Video DownloadHelper (VDH), a popular add-on for downloading videos from streaming sites [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0038">38</a>]
                </td>
              </tr>
              <tr>
                <td style="text-align:right;border-right:1px solid #000;"><em>msa</em></td>
                <td>
                  McAfee WebAdvisor (MSA), a security focused add-on that blocks malicious sites and downloads [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0031">31</a>]
                </td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>The <em>adblocker</em> group is the test of primary interest. The additional test groups, still compared against a control group with no add-ons, serve as placebo tests to verify that the effect we observe for ad blockers is indeed distinguishable from the act of installing add-ons in general, a popular add-on, or a security-focused add-on. Given the breadth of the Firefox add-on ecosystem, it would be desirable to perform a number of other such placebo tests for different types of add-ons. However, because of the restictions imposed by the study design, a user belongs to a given treatment group only if we observe an group-specific add-on installation in the treatment period <em>after</em> a 28-day baseline period. Such specificity limits the range of viable placebo candidate add-ons present in our study sample. Among the available placebo candidates, we selected VDH as the most popular general-interest add-on, and MSA as the top security-focused add-on (noting that “Privacy &amp; Security” is the most popular “specialized” category of add-ons).</p>
      </section>
      <section id="sec-21">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span> Results</h3>
          </div>
        </header>
        <p>For each response measure for Web engagement, and each test group listed in Table <a class="tbl" href="#tab4">4</a>, we fit model (<a class="eqn" href="#eq2">3</a>). The main parameter of interest is <em>β</em> <sub>2</sub>, which represents the change in the response measure due to installing the relevant add-ons, given similar baseline usage levels. In particular, inverting the log transformation, exp (<em>β</em> <sub>2</sub>) − 1 gives the relative change in the average value of the engagement measure during the observation period, relative to the control group, controlling for baseline period activity. The fitted values of <em>β</em> <sub>2</sub> for each of the models are presented graphically in Figure <a class="fig" href="#fig3">3</a>, together with 95% confidence intervals.</p>
        <figure id="fig3">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186162/images/www2018-171-fig3.jpg" class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span> <span class="figure-title">Estimates and 95% confidence intervals for <em>β</em> <sub>2</sub>, the change in log-transformed engagement due to installing add-ons.</span>
          </div>
        </figure>
        <p></p>
        <p>Similarly, the estimated relative changes in the engagement measures are summarized in Table <a class="tbl" href="#tab5">5</a>.</p>
        <div class="table-responsive" id="tab5">
          <div class="table-caption">
            <span class="table-number">Table 5:</span> <span class="table-title">Estimated relative changes in engagement due to installing add-ons compared to control group (exp (<em>β</em> <sub>2</sub>) − 1).</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;border-right:1px solid #000;">Measure</th>
                <th style="text-align:center;"><em>adblocker</em></th>
                <th style="text-align:center;"><em>any_addon</em></th>
                <th style="text-align:center;"><em>vdh</em></th>
                <th><em>msa</em></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;border-right:1px solid #000;">Active Hours</td>
                <td style="text-align:center;">28%</td>
                <td style="text-align:center;">11%</td>
                <td style="text-align:center;">14%</td>
                <td>0%</td>
              </tr>
              <tr>
                <td style="text-align:center;border-right:1px solid #000;">Total URIs</td>
                <td style="text-align:center;">15%</td>
                <td style="text-align:center;">10%</td>
                <td style="text-align:center;">0%</td>
                <td>5%</td>
              </tr>
              <tr>
                <td style="text-align:center;border-right:1px solid #000;">Search Volume</td>
                <td style="text-align:center;">0%</td>
                <td style="text-align:center;">− 12%</td>
                <td style="text-align:center;">0%</td>
                <td>− 5%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>Taking into account the matching and adjustments made to ensure comparability between the groups, we find that installing an ad blocker does in fact have a strong effect on average Web engagement. Users who installed an ad blocker were active in the browser for around 28% more time on average, and loaded 15% more pages (URIs), controlling for baseline activity.</p>
        <p>These results are reinforced by comparing them against the other test groups. Indeed, the notable differences in the estimates reflect the diversity present in the add-ons ecosystem, and highlight the sensitivity of our engagement measures to the specific interactions of users with each individual add-on, beyond any common baseline effect of just “having an add-on”. In particular, users who installed <em>any</em> add-on saw an average increase of around 10% in both active hours and page loads. This may be explained in part by the fact that the user took steps to personalize their browser, and consequently remains more engaged. However, the effect on page loads for ad blocker users is stronger, and considerably so for active hours, taking into account the margins of error indicated by the confidence intervals. This suggests that there is something inherent to the experience of using an ad blocker that proves beneficial to the user, increasing their engagement with the Web via the browser.</p>
        <p>This conclusion is further borne out by the effects for the VDH and MSA tests, which, while both involving popular add-ons that provide a specific beneficial functionality, fail to affect engagement to the degree observed for ad blockers. One plausible explanation is that the use of an ad blocker provides a noticeably enhanced experience for users in that group as they navigate their favorite Web pages, leading to increased engagement in terms of both active time and page views. On the other hand, Video DownloadHelper provides a specialized utility on specific Web sites (downloading videos from streaming sites), and the presence of McAfee WebAdvisor only surfaces in rare occasions (visits to malicious sites). The results for these test groups show little to no increase in Web engagement, and certainly not more than the baseline case of installing any add-on. An interesting direction for future research would be to investigate whether the principle holds in general: how well is an individual add-on's effect on Web engagement via the browser explained by the specific way in which it interacts with the user experience?</p>
        <p>There are a few additional observations worth highlighting. None of the test groups for specific add-ons appears to have a significant effect on search volumes, whereas the overall effect of installing a general add-on is to reduce search volumes by around 10%. This is not surprising considering that the specific add-ons we tested do not generally interact with search functionality, whereas there are a number of general add-ons related to search that likely draw searches away from the search bars in the browser UI. Additionally, Figure <a class="fig" href="#fig3">3</a> shows notable differences in the margins of error between the different test groups. This is also not surprising, and is largely explained by the differences in sample sizes between the groups. The distribution of add-on popularity, as measured by their number of users, is highly skewed [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0034">34</a>]. As a result, among the top few most popular add-ons, popularity drops by an order magnitude between consecutive ranks, and there is a long tail of numerous add-ons with very few users at the other end of the list.</p>
      </section>
    </section>
    <section id="sec-22">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Discussion</h2>
        </div>
      </header>
      <p>We now address some of the limitations inherent in this experimental approach, and describe some interesting directions for future investigation.</p>
      <section id="sec-23">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Methodological limitations</h3>
          </div>
        </header>
        <p>While the results are substantially significant from a statistical perspective, we note that this approach is not without limitations. Perhaps the most obvious issue is that our study only incorporates usage data from Firefox users. Thus, while the results generalize to the population of Firefox users, they may not apply to users of other browsers, such as Chrome. However, Firefox users would have to be substantially different from other browser users in their usage of the Web in order to challenge the generalizability of our findings. While this may be the case, it seems unlikely in light of the contemporary state of the Web. The majority of Web traffic goes to a limited set of popular websites, and the nature of Web standards entails that there are limited differences between browsers in terms of core Web browsing operations. Therefore, if there are in fact differences between Firefox and Chrome users, say, they are more likely related to latent user-level preferences and beliefs rather than typical Web usage. In other words, the choice of Firefox over Chrome is more likely explained by brand preference than the likelihood to use popular websites.</p>
        <p>Another limitation is that in order to allow a sufficiently long baseline period, we only consider users that installed an ad blocker after their first 28 days as a Firefox user. This selection process introduces certain biases into the applicable population. In our internal anlyses, we observe that Firefox users who install add-ons generally do so within their first week of using the browser. Requiring that users install an ad-blocker at least a month after their first usage instance means restricting to a specific subpopulation, and may introduce bias in terms of other features (e.g. lower than average general activity levels). On the other hand, we have also observed that Firefox users who eventually stop using the browser tend to do so during their first few weeks. This suggests that our study results are biased towards users more likely to use Firefox consistently.</p>
        <p>We also must consider that, although this is a retrospective study, it is not long-term, in the sense that we are not observing users longer than about 2 months. We are not able to take into account long-term activity, and the effects we observe may be related to the novelty of the experience. To elaborate, it may be entirely possible that over a longer period of observation, user engagement with the Web eventually dwindles back down to pre-treatment levels or worse. However, this limitation can be empirically addressed through future research where we adjust the observation period lengths.</p>
        <p>Finally, matching according to propensity scores allows for the approximation of random assignment for observational studies. There is an assumption, however, that features not included in the propensity scoring model do not possess explanatory power for response variables of interest. In other words, it is possible that there are potentially unobserved variables that we either failed to include or that the browser is not in a position to measure (e.g. latent variables endogenous to users) that could factor into the likelihood of installing extensions. That being said, this limitation is standard for natural field experiments, which are ultimately not a true replacement for randomized controlled trials.</p>
      </section>
      <section id="sec-24">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Future research directions</h3>
          </div>
        </header>
        <p>There are a number of ways we may consider expanding on this current work and addressing some of the limitations described above. For one thing, the design of the study depends on parametrized assumptions, such as the lengths of the periods described in Section <a class="sec" href="#sec-10">2.2</a>. To strengthen the results, it would be valuable to assess their robustness to changes in these parameters.</p>
        <p>One question to investigate is how the results change over time. In the current study, we observe users over 28 days after the add-on installation and aggregate their usage measurements over this period. Alternatively, we could extend the observation period to span several months, and adopt a more sophisticated modeling approach that would take into account changes over time as well as user churn.</p>
        <p>Another issue raised above is that the fixed baseline period length requires restricting the population to users who install an add-on during a specific time window in their lifetime. We could instead shrink the baseline period and extend the treatment period, in order to capture a broader segment of the user population. However, a shorter baseline period may reduce the effectiveness of matching and diminish the causal claims. This tradeoff will need to be considered carefully in order to arrive at an optimal result.</p>
        <p>Additionally, we may derive more detailed insights by further developing the models describe in Section <a class="sec" href="#sec-20">3.2</a>. In the current work we opted for relatively simple models for ease of interpretability and presentation. However, it would be of interest to allow for more sophisticated relationships between the features, such as an interaction between the treatment effect and baseline period engagement (i.e. does the difference during the observation period depend on how engageed the users started off as during the baseline period?). Another improvement would be to combine the separate models into a single, larger model, which would let us pool variance between different test groups and potentially analyze multivariate relationships between the engagement measures. However, as this type of data is typically not “well-behaved” in a traditional statistical sense (it suffers from skewness and discreteness), this may require additional transformations or adjustments to yield a meaningful result.</p>
        <p>Finally, as discussed in Section <a class="sec" href="#sec-8">2</a>, a randomized experiment will always allow for stronger causal claims, although it may be difficult to implement, and may in fact address a somewhat different research question. That said, it would be very interesting to run such an experiment to see how the results compare to our current findings. As noted in Section <a class="sec" href="#sec-8">2</a>, there may be ethical implications to requiring study participants to use an ad blocker, although this could be resolved by making the study opt-in, for example. Of course, this again incurs a tradeoff in that the stronger degree of causality comes at the expense of population bias. Alternatively, we could consider targeting users in the current study with surveys in order to understand their actual motivations and experiences around ad blocker usage. Tied back to their reported Telemetry data, this would provide an additional verification on the sensitivity of our causal results.</p>
      </section>
    </section>
    <section id="sec-25">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Conclusion</h2>
        </div>
      </header>
      <p>While the impact of ad blocking on the ecosystem of the Web has been substantially investigated and documented, there has been little research into the impact of ad blocking on engagement with the Web. Opponents of ad blocking have asserted that ad blocking results in substantial breakage of modern websites and Web applications, which results in poor user experience and decreased Web engagement. This outcome, they suggest, could threaten the future growth of the Web. On the other hand, proponents of ad blocking have argued that ads are such a detriment to the browsing experience that users are willing to make the tradeoff by removing ads from their browsing experience entirely.</p>
      <p>In this paper, we present a natural field experiment that addresses this tension directly by estimating the causal effect of installing ad blocking extensions on various measures of Web engagement. We find that installing ad blocking extensions substantially increases both active time spent in the browser and the number of pages viewed. This empirical evidence supports the position of ad blocking supporters and refutes the claim that ad blocking will diminish user engagement with the Web.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Alberto Abadie. 2002. Bootstrap Tests for Distributional Treatment Effects in Instrumental Variable Models. <em><em>J. Amer. Statist. Assoc.</em></em> 97, 457 (2002), 284–292. 01621459</li>
        <li id="BibPLXBIB0002" label="[2]">Gregor Aisch, Wilson Andrews, and Josh Keller. 2015. The Cost of Mobile Ads on 50 News Websites. (October 2015). Retrieved October 26, 2017 from <a href="https://www.nytimes.com/interactive/2015/10/01/business/cost-of-mobile-ads.html" target="_blank">https://www.nytimes.com/interactive/2015/10/01/business/cost-of-mobile-ads.html</a>
        </li>
        <li id="BibPLXBIB0003" label="[3]">Tim Althoff, Pranav Jindal, and Jure Leskovec. 2017. Online Actions with Offline Impact: How Online Social Networks Influence Online and Offline User Behavior. In <em><em>Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</em></em> (WSDM ’17). ACM, New York, NY, USA, 537–546. <a class="link-inline force-break" href="https://doi.org/10.1145/3018661.3018672" target="_blank">https://doi.org/10.1145/3018661.3018672</a>
        </li>
        <li id="BibPLXBIB0004" label="[4]">Mimi An. 2016. Why People Block Ads (And What It Means for Marketers and Advertisers). (July 2016). Retrieved October 27, 2017 from <a href="https://research.hubspot.com/reports/why-people-block-ads-and-what-it-means-for-marketers-and-advertisers" target="_blank">https://research.hubspot.com/reports/why-people-block-ads-and-what-it-means-for-marketers-and-advertisers</a>
        </li>
        <li id="BibPLXBIB0005" label="[5]">Sinan Aral and Christos Nicolaides. 2017. Exercise contagion in a global social network. <em><em>Nature Communications</em></em> 8(2017), 14753.</li>
        <li id="BibPLXBIB0006" label="[6]">Simon Attfield, Gabriella Kazai, Mounia Lalmas, and Benjamin Piwowarski. 2011. Towards a science of user engagement (position paper). In <em><em>WSDM workshop on user modelling for Web applications</em></em> . 9–12.</li>
        <li id="BibPLXBIB0007" label="[7]">Giorgio Brajnik and Silvia Gabrielli. 2010. A review of online advertising effects on the user experience. <em><em>International Journal of Human-Computer Interaction</em></em> 26, 10(2010), 971–997.</li>
        <li id="BibPLXBIB0008" label="[8]">Interactive&nbsp;Advertising Bureau. 2017. IAB Believes Ad Blocking Is Wrong. (2017). Retrieved October 25, 2017 from <a href="https://www.iab.com/iab-believes-ad-blocking-is-wrong/" target="_blank">https://www.iab.com/iab-believes-ad-blocking-is-wrong/</a>
        </li>
        <li id="BibPLXBIB0009" label="[9]">David Chan, Rong Ge, Ori Gershony, Tim Hesterberg, and Diane Lambert. 2010. Evaluating Online Ad Campaigns in a Pipeline: Causal Models at Scale. In <em><em>Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em></em> (KDD ’10). ACM, New York, NY, USA, 7–16. <a class="link-inline force-break" href="https://doi.org/10.1145/1835804.1835809" target="_blank">https://doi.org/10.1145/1835804.1835809</a>
        </li>
        <li id="BibPLXBIB0010" label="[10]">Chang-Hoan Cho and Hongsik&nbsp;John Cheon. 2004. Why do people avoid advertising on the internet? <em><em>Journal of Advertising</em></em> 33, 4 (2004), 89–97.</li>
        <li id="BibPLXBIB0011" label="[11]">Tiago Cunha, Ingmar Weber, and Gisele Pappa. 2017. A Warm Welcome Matters!: The Link Between Social Feedback and Weight Loss in /R/Loseit. In <em><em>Proceedings of the 26th International Conference on World Wide Web Companion</em></em> (WWW ’17 Companion). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 1063–1072. <a class="link-inline force-break" href="https://doi.org/10.1145/3041021.3055131" target="_blank">https://doi.org/10.1145/3041021.3055131</a>
        </li>
        <li id="BibPLXBIB0012" label="[12]">Stylianos Despotakis, R Ravi, and Kannan Srinivasan. 2017. The Beneficial Effects of Ad Blockers. (2017). <a href="http://stedes.com/pdfs/DRS%20-%20The%20Beneficial%20Effects%20of%20Ad%20Blockers%20-%202017.pdf" target="_blank">http://stedes.com/pdfs/DRS%20-%20The%20Beneficial%20Effects%20of%20Ad%20Blockers%20-%202017.pdf</a>
        </li>
        <li id="BibPLXBIB0013" label="[13]">Thad Dunning. 2012. <em><em>Natural experiments in the social sciences: a design-based approach</em></em> . Cambridge University Press. <a class="link-inline force-break" href="https://doi.org/10.1017/CBO9781139084444" target="_blank">https://doi.org/10.1017/CBO9781139084444</a>
        </li>
        <li id="BibPLXBIB0014" label="[14]">Catherine Dwyer and Ameet Kanguri. 2017. Malvertising - A Rising Threat To The Online Ecosystem. <em><em>Journal of Information Systems Applied Research</em></em> 10, 3(2017), 29–37.</li>
        <li id="BibPLXBIB0015" label="[15]">Steven&nbsp;M Edwards, Hairong Li, and Joo-Hyun Lee. 2002. Forced exposure and psychological reactance: Antecedents and consequences of the perceived intrusiveness of pop-up ads. <em><em>Journal of Advertising</em></em> 31, 3 (2002), 83–95.</li>
        <li id="BibPLXBIB0016" label="[16]">Seyed Amin&nbsp;Mirlohi Falavarjani, Hawre Hosseini, Zeinab Noorian, and Ebrahim Bagheri. 2017. Estimating the Effect of Exercising on Users’ Online Behavior. In <em><em>The Workshops of the Eleventh International AAAI Conference on Web and Social Media</em></em> . AAAI Technical Report WS-17-16.</li>
        <li id="BibPLXBIB0017" label="[17]">Gian&nbsp;M Fulgoni and Marie&nbsp;Pauline Mörn. 2009. Whither the click? How online advertising works. <em><em>Journal of Advertising Research</em></em> 49, 2 (2009), 134–142.</li>
        <li id="BibPLXBIB0018" label="[18]">Kiran Garimella, Orestis Kostakis, and Michael Mathioudakis. 2017. Ad-blocking: A Study on Performance, Privacy and Counter-measures. In <em><em>Proceedings of the 2017 ACM on Web Science Conference</em></em> (WebSci ’17). ACM, New York, NY, USA, 259–262. 978-1-4503-4896-6</li>
        <li id="BibPLXBIB0019" label="[19]">Arthur Gervais, Alexandros Filios, Vincent Lenders, and Srdjan Capkun. 2017. Quantifying web adblocker privacy. In <em><em>European Symposium on Research in Computer Security</em></em> . Springer, 21–42.</li>
        <li id="BibPLXBIB0020" label="[20]">Avi Goldfarb and Catherine Tucker. 2011. Online display advertising: Targeting and obtrusiveness. <em><em>Marketing Science</em></em> 30, 3 (2011), 389–404.</li>
        <li id="BibPLXBIB0021" label="[21]">Daniel&nbsp;G Goldstein, Siddharth Suri, R&nbsp;Preston McAfee, Matthew Ekstrand-Abueg, and Fernando Diaz. 2014. The economic and cognitive costs of annoying display advertisements. <em><em>Journal of Marketing Research</em></em> 51, 6 (2014), 742–752.</li>
        <li id="BibPLXBIB0022" label="[22]">James&nbsp;J. Higgins. 2003. <em><em>Introduction to Modern Nonparametric Statistics</em> (1 ed.)</em>. Cengage Learning. 0534387756</li>
        <li id="BibPLXBIB0023" label="[23]">Frank J.&nbsp;Massey Jr.1951. The Kolmogorov-Smirnov Test for Goodness of Fit. <em><em>J. Amer. Statist. Assoc.</em></em> 46, 253 (1951), 68–78.</li>
        <li id="BibPLXBIB0024" label="[24]">Mounia Lalmas, Heather O'Brien, and Elad Yom-Tov. 2014. <em><em>Measuring User Engagement</em></em> . Morgan &amp; Claypool Publishers. 1627052615, 9781627052610</li>
        <li id="BibPLXBIB0025" label="[25]">Anja Lambrecht and Catherine Tucker. 2013. When does retargeting work? Information specificity in online advertising. <em><em>Journal of Marketing Research</em></em> 50, 5 (2013), 561–576.</li>
        <li id="BibPLXBIB0026" label="[26]">Janette Lehmann, Mounia Lalmas, Elad Yom-Tov, and Georges Dupret. 2012. Models of User Engagement. In <em><em>Proceedings of the 20th International Conference on User Modeling, Adaptation, and Personalization</em></em> (UMAP’12). Springer-Verlag, Berlin, Heidelberg, 164–175. <a class="link-inline force-break" href="https://doi.org/10.1007/978-3-642-31454-4_14" target="_blank">https://doi.org/10.1007/978-3-642-31454-4_14</a>
        </li>
        <li id="BibPLXBIB0027" label="[27]">Wen Li and Ziying Huang. 2016. The Research of Influence Factors of Online Behavioral Advertising Avoidance. <em><em>American Journal of Industrial and Business Management</em></em> 6, 09(2016), 947.</li>
        <li id="BibPLXBIB0028" label="[28]">Zhou Li, Kehuan Zhang, Yinglian Xie, Fang Yu, and XiaoFeng Wang. 2012. Knowing Your Enemy: Understanding and Detecting Malicious Web Advertising. In <em><em>Proceedings of the 2012 ACM Conference on Computer and Communications Security</em></em> (CCS ’12). ACM, New York, NY, USA, 674–686. <a class="link-inline force-break" href="https://doi.org/10.1145/2382196.2382267" target="_blank">https://doi.org/10.1145/2382196.2382267</a>
        </li>
        <li id="BibPLXBIB0029" label="[29]">Akhil Mathur, Nicholas&nbsp;D. Lane, and Fahim Kawsar. 2016. Engagement-aware Computing: Modelling User Engagement from Mobile Contexts. In <em><em>Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing</em></em> (UbiComp ’16). ACM, New York, NY, USA, 622–633. <a class="link-inline force-break" href="https://doi.org/10.1145/2971648.2971760" target="_blank">https://doi.org/10.1145/2971648.2971760</a>
        </li>
        <li id="BibPLXBIB0030" label="[30]">Jens Mattke, Lea&nbsp;Katharina Müller, and Christian Maier. 2017. Why do individuals block online ads? An explorative study to explain the use of ad blockers. In <em><em>23rd Americas Conference on Information Systems, AMCIS 2017, Boston, MA, USA, August 10-12, 2017</em></em> . Association for Information Systems.</li>
        <li id="BibPLXBIB0031" label="[31]">McAfee. 2017. McAfee WebAdvisor. (2017). Retrieved October 26, 2017 from <a href="https://home.mcafee.com/root/landingpage.aspx?lpname=get-it-nowaffid=0culture=en-sg" target="_blank">https://home.mcafee.com/root/landingpage.aspx?lpname=get-it-nowaffid=0culture=en-sg</a>
        </li>
        <li id="BibPLXBIB0032" label="[32]">Mozilla. 2017. Adblock Plus. (2017). Retrieved October 31, 2017 from <a href="https://addons.mozilla.org/en-US/firefox/addon/adblock-plus/" target="_blank">https://addons.mozilla.org/en-US/firefox/addon/adblock-plus/</a>
        </li>
        <li id="BibPLXBIB0033" label="[33]">Mozilla. 2017. Firefox Add-ons: Extensions. (2017). Retrieved October 31, 2017 from <a href="https://addons.mozilla.org/en-US/firefox/extensions/" target="_blank">https://addons.mozilla.org/en-US/firefox/extensions/</a>
        </li>
        <li id="BibPLXBIB0034" label="[34]">Mozilla. 2017. Firefox Add-ons: Most Popular Extensions. (2017). Retrieved October 31, 2017 from <a href="https://addons.mozilla.org/en-US/firefox/search/?sort=userstype=extension" target="_blank">https://addons.mozilla.org/en-US/firefox/search/?sort=userstype=extension</a>
        </li>
        <li id="BibPLXBIB0035" label="[35]">Mozilla. 2017. Mozilla Source Tree Docs: ”main” ping. (2017). Retrieved October 23, 2017 from <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html" target="_blank">https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html</a>
        </li>
        <li id="BibPLXBIB0036" label="[36]">Mozilla. 2017. Mozilla Source Tree Docs: Telemetry. (2017). Retrieved October 27, 2017 from <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/index.html" target="_blank">https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/index.html</a>
        </li>
        <li id="BibPLXBIB0037" label="[37]">Mozilla. 2017. uBlock Origin. (2017). Retrieved October 31, 2017 from <a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/" target="_blank">https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/</a>
        </li>
        <li id="BibPLXBIB0038" label="[38]">Mozilla. 2017. Video Download Helper. (2017). Retrieved October 26, 2017 from <a href="https://addons.mozilla.org/en-US/firefox/addon/video-downloadhelper/" target="_blank">https://addons.mozilla.org/en-US/firefox/addon/video-downloadhelper/</a>
        </li>
        <li id="BibPLXBIB0039" label="[39]">Rishab Nithyanand, Sheharbano Khattak, Mobin Javed, Narseo Vallina-Rodriguez, Marjan Falahrastegar, Julia&nbsp;E Powles, Emiliano De&nbsp;Cristofaro, Hamed Haddadi, and Steven&nbsp;J Murdoch. 2016. Adblocking and Counter Blocking: A Slice of the Arms Race. In <em><em>6th USENIX Workshop on Free and Open Communications on the Internet (FOCI 16)</em></em> . USENIX Association.</li>
        <li id="BibPLXBIB0040" label="[40]">Heather&nbsp;L. O'Brien and Elaine&nbsp;G. Toms. 2008. What is user engagement? A conceptual framework for defining user engagement with technology. <em><em>Journal of the American Society for Information Science and Technology</em></em> 59, 6 (2008), 938–955. <a class="link-inline force-break" href="https://doi.org/10.1002/asi.20801" target="_blank">https://doi.org/10.1002/asi.20801</a>
        </li>
        <li id="BibPLXBIB0041" label="[41]">Future of Privacy&nbsp;Forum. 2016. <em><em>Consumer Views Regarding Ad Blocking Technology</em></em> . Technical Report&nbsp;65. Federal Trade Commission Public Comments: Consumer Privacy and Security Issues.</li>
        <li id="BibPLXBIB0042" label="[42]">PageFair. 2017. The state of the blocked web: 2017 Global Adblock Report. (2017). Retrieved October 26, 2017 from <a href="https://pagefair.com/downloads/2017/01/PageFair-2017-Adblock-Report.pdf" target="_blank">https://pagefair.com/downloads/2017/01/PageFair-2017-Adblock-Report.pdf</a>
        </li>
        <li id="BibPLXBIB0043" label="[43]">Ofir Pele and Michael Werman. 2010. The Quadratic-Chi Histogram Distance Family. In <em><em>Computer Vision – ECCV 2010: 11th European Conference on Computer Vision, Heraklion, Crete, Greece, September 5-11, 2010, Proceedings, Part II</em></em> , Kostas Daniilidis, Petros Maragos, and Nikos Paragios (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 749–762.</li>
        <li id="BibPLXBIB0044" label="[44]">Eric&nbsp;T Peterson and Joseph Carrabis. 2008. <em><em>Measuring the immeasurable: Visitor engagement</em></em> . Technical Report. Web Analytics Demystified.</li>
        <li id="BibPLXBIB0045" label="[45]">Enric Pujol, Oliver Hohlfeld, and Anja Feldmann. 2015. Annoyed Users: Ads and Ad-Block Usage in the Wild. In <em><em>Proceedings of the 2015 Internet Measurement Conference</em></em> (IMC ’15). ACM, New York, NY, USA, 93–106. <a class="link-inline force-break" href="https://doi.org/10.1145/2815675.2815705" target="_blank">https://doi.org/10.1145/2815675.2815705</a>
        </li>
        <li id="BibPLXBIB0046" label="[46]">Paul&nbsp;R. Rosenbaum. 2010. <em><em>Design of Observational Studies</em>(1 ed.)</em>. Springer-Verlag, New York, NY. 9781441912138</li>
        <li id="BibPLXBIB0047" label="[47]">Zahra Seyedghorban, Hossein Tahernejad, and Margaret&nbsp;Jekanyika Matanda. 2016. Reinquiry into advertising avoidance on the internet: A conceptual replication and extension. <em><em>Journal of Advertising</em></em> 45, 1 (2016), 120–129.</li>
        <li id="BibPLXBIB0048" label="[48]">Ben Shiller, Joel Waldfogel, and Johnny Ryan. 2017. <em><em>Will Ad Blocking Break the Internet?</em></em> Technical Report. National Bureau of Economic Research.</li>
        <li id="BibPLXBIB0049" label="[49]">Catherine&nbsp;E. Tucker. 2014. Social Networks, Personalized Advertising, and Privacy Controls. <em><em>Journal of Marketing Research</em></em> 51, 5 (2014), 546–562.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>For example, a user that moves the mouse in the browser for 60 consecutive seconds will register 12 active ticks.</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&nbsp;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3178876.3186162">https://doi.org/10.1145/3178876.3186162</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
