<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Exploring Entity-centric Networks in Entangled News
  Streams</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3188726'>https://doi.org/10.1145/3184558.3188726</a> 
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3188726'>https://w3id.org/oa/10.1145/3184558.3188726</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Exploring Entity-centric Networks
          in Entangled News Streams</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Andreas</span> <span class=
          "surName">Spitz</span> Institute of Computer Science,
          Heidelberg University, Im Neuenheimer Feld 205
          69120Heidelberg, Germany, <a href=
          "mailto:spitz@informatik.uni-heidelberg.de">spitz@informatik.uni-heidelberg.de</a>
        </div>
        <div class="author">
          <span class="givenName">Michael</span> <span class=
          "surName">Gertz</span> Institute of Computer Science,
          Heidelberg University, Im Neuenheimer Feld 205
          69120Heidelberg, Germany, <a href=
          "mailto:gertz@informatik.uni-heidelberg.de">gertz@informatik.uni-heidelberg.de</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3188726"
        target=
        "_blank">https://doi.org/10.1145/3184558.3188726</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>The increasing number of news outlets and the
        frequency of the news cycle have made it all but impossible
        to obtain the full picture from online news. Consolidating
        news from different sources has thus become a necessity in
        online news processing. Despite the amount of research that
        has been devoted to different aspects of new event
        detection and tracking in news streams, solid solutions for
        such entangled streams of full news articles are still
        lacking. Many existing works focus on streams of microblogs
        since the analysis of news articles raises the additional
        problem of summarizing or extracting the relevant sections
        of articles. For the consolidation of identified news
        snippets, schemes along numerous different dimensions have
        been proposed, including publication time, temporal
        expressions, geo-spatial references, named entities, and
        topics. The granularity of aggregated news snippets then
        includes such diverse aspects as events, incidents,
        threads, or topics for various subdivisions of news
        articles. To support this variety of granularity levels, we
        propose a comprehensive network model for the
        representation of multiple entangled streams of news
        documents. Unlike previous methods, the model is geared
        towards entity-centric explorations and enables the
        consolidation of news along all dimensions, including the
        context of entity mentions. Since the model also serves as
        a reverse index, it supports explorations along the
        dimensions of sentences or documents for an encompassing
        view on news events. We evaluate the performance of our
        model on a large collection of entangled news streams from
        major news outlets of English speaking countries and a
        ground truth that we generate from event summaries in the
        Wikipedia Current Events portal.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS
        Concepts:</span> • <strong>Computing methodologies</strong>
        → <em>Information extraction;</em> • <strong>Information
        systems</strong> → <em>Document
        representation;</em></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>entity network; implicit
          network; news stream; document indexing</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Andreas Spitz and Michael Gertz. 2018. Exploring
          Entity-centric Networks in Entangled News Streams. In
          <em>WWW '18 Companion: The 2018 Web Conference
          Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon,
          France. ACM, New York, NY, USA</em> 9 Pages. <a href=
          "https://doi.org/10.1145/3184558.3188726" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3188726</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p><em>Reading it in the paper in the morning</em> is a
      common idiom for catching up with the news that is becoming
      increasingly less applicable. Putting aside the obvious
      departure from printed news, both the temporal aspect and the
      grammatical singular are less and less accurate. News are not
      reported and consumed in the morning but in a constant news
      cycle throughout the day, published by a multitude of news
      outlets with varying degrees of reliability, political bias,
      and overlapping content. It is these <em>entangled streams of
      news</em> that the reader has to wade through to stay
      informed. Despite similarities between the news cycle and
      streams of microblogs, social media cannot take on the mantle
      of investigative journalism, which relies on argumentative
      texts and is less focused on the instant than it is on the
      evolution of stories. In this context, the so called <em>Five
      Ws</em> of <em>Who?</em>, <em>When?</em>, <em>Where?</em>,
      <em>What?</em>, and <em>Why?</em> are questions of central
      importance that serve the journalist and the reader in
      uncovering news. Naturally, these questions put an emphasis
      on entities as pivotal components of news. In information
      retrieval, this is reflected in the definition of an event as
      <em>something that happens at a given place and time between
      a group of actors</em>&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>], originating in topic detection and
      tracking and highlighting the central role of entities for
      inducing structure in the unstructured texts of news
      articles.</p>
      <p>In large entangled news streams, far more than one news
      article tends to be required to retrieve the full
      picture&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0032">32</a>]. However, a lot of information is
      replicated between or even within individual news streams and
      thus redundant. Intuitively, this motivates two major
      subtasks in automated news analysis: identifying event
      mentions in unstructured texts, and aggregating them across
      documents. These tasks are referred to as <em>new event
      detection</em> and <em>event tracking</em>&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0003">3</a>], and can be
      augmented by detecting <em>topics</em>&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0007">7</a>] that put individual
      documents into context. To make identified events accessible
      to users, a central step is thus their aggregation into
      threads of events along some dimension(s). Many different
      approaches have been proposed to this end. Some focus on a
      geographic aggregation and visualization of news
      sources&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0033">33</a>], while others focus on the temporal
      aggregation&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0012">12</a>], or both&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0038">38</a>]. Alternative approaches
      use the participating entities directly&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0009">9</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0016">16</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0030">30</a>]. In the case of a
      temporal aggregation, different temporal dimensions can be
      considered, such as the dates in the
      documents&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0021">21</a>], or external information such as the
      publishing date&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>] and edit histories&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0015">15</a>]. With
      regard to timelines, another important aspect is then the
      temporal order, as the SemEval-2015 task for cross-document
      event ordering shows&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0020">20</a>]. Beyond the above dimensions, more
      recent approaches include aggregation on a topic
      level&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0001">1</a>]
      or based on word embeddings&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0022">22</a>].</p>
      <p>When considered for contrastive explorations of content,
      the above approaches suffer from two critical drawbacks: the
      limited number of <em>aggregation dimensions</em> and the
      <em>aggregation granularity</em> level. No existing approach
      covers the entirety of available dimensions and it is indeed
      questionable whether an aggregation along all dimensions at
      once is realistically possible. Perhaps even more critically,
      the results are always coarse structures due to an
      aggregation either on the document, event, or topic level.
      However, events are commonly defined as composite mentions of
      (named) entities, which form the stitching points between
      individual news streams. After all, we consume news about
      people, organizations, or locations of interest and follow
      them over time and in different contexts. Is it then not a
      more reasonable approach to retain this entity-centric
      structure of news in a suitable document representation for
      subsequent analyses, and aggregate only where necessary and
      in exactly the dimensions that fit the exploratory task?</p>
      <p>As a first step towards addressing this shortcoming, we
      introduce <em>entity-centric implicit networks</em> as a
      representation of entangled news streams. Based on the
      concept of implicit entity networks for static document
      collections&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0030">30</a>], we include entity relation
      information, a spatial and two temporal dimensions (temporal
      expressions and publication metadata), and the context of
      mentions in a comprehensive framework for entity-centric
      analyses. On the technical side, our model addresses the
      inherent scaling issues of entangled news streams by
      utilizing efficient entity-centric queries to localized graph
      substructures, and the streaming graph updates take advantage
      of incremental adjustments to relevance measures for queries
      against the data&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0036">36</a>]. Furthermore, the implicit
      representation serves as an (inverse) index for retrieval
      tasks without requiring the storage of proprietary news
      article content. On the application side, our model provides
      a more fine-grained and versatile representation of entangled
      news streams than any previous approach. Instead of utilizing
      document- or event-centric indexing, we focus on the level of
      entities and contexts and use them as stitching points
      between individual news threads. The model supports a wide
      range of tasks, including entity-centric topic and event
      extraction and tracking, contextual search, contrastive
      source comparison, and exploratory visualizations of the
      underlying streams.</p>
      <p><strong>Contributions.</strong> Our contributions are
      fourfold. <strong>(i)</strong> We propose a comprehensive
      model for entity-centric exploration and retrieval tasks on
      large entangled news streams. <strong>(ii)</strong> We
      discuss graph-based context-sensitive clustering of joint
      entity mentions in both static and streaming applications.
      <strong>(iii)</strong> We introduce a clustering of entities
      along naturally evolving topics that does not suffer from a
      pre-defined number of topics or topic degradation at low
      ranks like traditional topic models. <strong>(iv)</strong> We
      evaluate our model on a large entangled stream of news from
      international outlets. We provide the resulting network data,
      including links to the original articles<a class="fn" href=
      "#fn1" id="foot-fn1"><sup>1</sup></a>.</p>
    </section>
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related
          Work</h2>
        </div>
      </header>
      <p>To our knowledge, no previous work supports the
      comprehensive, entity-centric exploration of entangled news
      streams. Thus, we give an overview of works that cover some
      of these aspects.</p>
      <p><strong>Entity-centric Exploration and Analysis.</strong>
      A fundamental result in entity-centric document analysis with
      strong emphasis on the detection of event descriptions is by
      Feng and Allan, who formalize the concepts of <em>incident
      threading</em> and <em>event threading</em>&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0011">11</a>]. While
      event threading captures the internal structure of news
      topics by adding causal or temporal relations, incident
      threading merges mentions of identical entity cooccurrences.
      Later works utilize similar concepts. Kanhabua et al. assess
      the importance of temporal expressions based on the
      cooccurrences of entities and temporal anchor texts within
      individual sentences&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0015">15</a>]. Gupta et al. present EventMiner, a
      framework for extracting events from collections of
      documents&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0013">13</a>] that is very comprehensive in its
      use of temporal expressions and named entities, but does not
      scale. Mishra and Berberich link coarse-grained events from
      news articles to corresponding Wikipedia
      pages&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0021">21</a>].
      Similarly, Ceroni et al. use entity mentions and temporal
      information to confirm the occurrence of events in a document
      collection&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0009">9</a>]. Although the above works focus on
      entities, they only consider static document collections and
      do not support entity-centric exploration or streaming
      news.</p>
      <p><strong>Analysis of Articles in News Streams.</strong> A
      number of frameworks offer comprehensive analyses of
      streaming news. Lydia is a large-scale aggregation tool for
      news articles&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0017">17</a>] with numerous subsequent
      publications. The European Media Monitor builds and processes
      a repository of multilingual European news
      articles&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>]. News Stand monitors and retrieves
      RSS feeds to extract geographic content from articles for
      spatial clustering and visualization&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0033">33</a>]. The enBlogue system
      allows the identification of emerging topics from news
      streams in real time&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>], but has so far been applied with a
      focus on blogs and microblogs. A shortcoming of the above
      approaches is the lacking support for entity-centric
      explorations.</p>
      <p>Ahmed et al. combine topic modeling, clustering and named
      entity recognition to distinguish topics, story lines, and
      entities in streaming news articles&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0001">1</a>], but do not include the
      effects of entity cooccurrences. To support ad-hoc tracing of
      news streams, Vuurens et al. utilize the clustering and
      qualification of titles and sentences in news
      articles&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0035">35</a>]. Moran et al. introduce the use of
      word embeddings to enhance first story detection in
      microblogs&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0022">22</a>].</p>
      <p>Many further approaches to streaming news analysis exist,
      but few of them consider temporal information, and none of
      them include temporal information along with entities, terms,
      and topics.</p>
      <p><strong>Network-based Document Models.</strong> Yang et
      al. classify news documents into topics and measure topic
      novelty by using both keywords and named entities with
      relative weighting for event-level novelty
      detection&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0037">37</a>]. For a similar purpose, Das Sarma et
      al. build entity dynamic relation graphs to identify entities
      participating in trending events, but exclude
      locations&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0026">26</a>]. More generally, Blanco and Lioma
      explore a network-based approach that models terms as nodes
      in a graph with edges weighted by cooccurrence
      counts&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0006">6</a>].
      Rousseau and Vazirgiannis use an unweighted but directed
      graph to account for term order in a document's
      text&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0025">25</a>].
      They focus on the sentence level and do not include entities,
      thus limiting the capability of the model for entity
      exploration.</p>
      <p>All of these approaches use graphs to answer
      <em>specific</em> questions about a document collection or
      stream. Here, we focus on a <em>comprehensive</em> network
      representation that supports a multitude of subsequent
      analyses. A similar approach was recently presented by Spitz
      and Gertz&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0030">30</a>], who construct an implicit network
      of entity mentions from a static document collection to
      support exploratory tasks. While their model could be adapted
      to support efficient streaming updates, an exploration along
      the dimension of publication dates or the context of entities
      is not included. In the following, we thus describe how a
      more general implicit network model can be realized in a
      streaming environment.</p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Entity Network
          Model</h2>
        </div>
      </header>
      <p>Based on the intuition that entity relations can be
      derived from joint entity mentions, we construct a network of
      entity relations from the named entity classes
      <em>locations</em>, <em>organizations</em>, <em>actors</em>,
      and <em>dates</em>. Together, these form the basis of the
      LOAD model for implicit networks&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0030">30</a>], which we improve from a
      static to a streaming model by adding (i) term embeddings to
      encode the context of entity mentions for refined queries,
      (ii) an adaptation to the news domain by considering
      publication times as a second temporal dimension beyond
      temporal expressions in the documents, and (iii) an
      adaptation to entangled news streams and concurrent events by
      using a multigraph model with (partial) edge aggregation
      schemes.</p>
      <section id="sec-6">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Entity
            Multigraph Model</h3>
          </div>
        </header>
        <p>Let <em>N</em> be a collection of news articles. Each
        document <em>n</em> ∈ <em>N</em> consists of sentences
        <em>s</em> ∈ <em>n</em>. We denote the set of all sentences
        in all documents as <span class=
        "inline-equation"><span class="tex">$S:=\bigcup _{n \in
        N}\lbrace s \in n\rbrace$</span></span> . To consecutively
        number the sentences, let <span class=
        "inline-equation"><span class="tex">$\sigma : S \rightarrow
        \mathbb {N}$</span></span> map a sentence to its index in
        the document in which it occurs. We then consider each
        sentence to be a collection of words, which we partition
        into entity classes.</p>
        <p><strong>Graph Nodes.</strong> In the following, we
        consider words to be units within a text that has been
        tagged for named entities. We distinguish between the named
        entity classes <em>locations L</em>, <em>organizations
        O</em>, <em>actors A</em>, and <em>dates D</em>, according
        to the LOAD model. All remaining words constitute the set
        of terms <em>T</em>, which is defined as</p>
        <div class="table-responsive" id="Xeq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} T:=\bigcup
            _{s\in S} \lbrace w\in s \; | \; w\notin L \cup O \cup
            A \cup D\rbrace , \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>Thus, a sentence is a multiset of entities <em>s</em>
        ∈
        (<em>L</em>∪<em>O</em>∪<em>A</em>∪<em>D</em>∪<em>T</em>)<sup>*</sup>.
        In the following, we refer to the set of actors, locations,
        organizations, dates and terms as <em>entities</em>. We
        define the union of the aforementioned seven classes
        <em>V</em> ≔
        <em>L</em>∪<em>O</em>∪<em>A</em>∪<em>D</em>∪<em>T</em>∪<em>S</em>∪<em>N</em>
        as the nodes of the graph and employ a function <em>η</em>:
        <em>V</em> → {<em>L</em>, <em>O</em>, <em>A</em>,
        <em>D</em>, <em>T</em>, <em>S</em>, <em>N</em>} that maps
        each node <em>v</em> ∈ <em>V</em> to the corresponding
        class <em>η</em>(<em>v</em>).
        <p></p>
        <p><strong>Graph Edges.</strong> To obtain a graph
        representation <em>G</em> = (<em>V</em>, <em>E</em>), we
        construct a set of edges <em>E</em> ≔
        <em>E<sub>C</sub></em> ∪<em>E<sub>P</sub></em> based on two
        criteria: <em>containment</em> and <em>proximity</em>.
        Containment represents edges <em>E<sub>C</sub></em> between
        entities and sets, such that an entity is connected to a
        set that contains the entity. This type of edge provides
        provenance and context information for entities. Proximity
        edges <em>E<sub>P</sub></em> encode the cooccurrence of
        entities within at least one common document and represent
        implicit entity relations. Edges of the proximity type
        introduce parallel edges in the graph since one edge is
        induced whenever two entities cooccur. To distinguish
        between parallel edges, we rely on <em>instances</em>
        <span class="inline-equation"><span class="tex">$I
        \subseteq \mathbb {N}$</span></span> of entity
        cooccurrences, along with an injective mapping <em>ι</em>:
        <em>V</em> × <em>V</em> → <em>I</em>. Here, <em>i</em> =
        <em>ι</em>(<em>v</em>, <em>w</em>) ∈ <em>I</em> represents
        an instance of the cooccurrence of two entities <em>v</em>
        and <em>w</em> in some unique ordering, such that the tuple
        <em>e</em> = (<em>v</em>, <em>w</em>, <em>i</em>) denotes
        an edge between <em>v</em> and <em>w</em>. For example, if
        entities <em>v</em> and <em>w</em> cooccur in a document,
        this induces an edge (<em>v</em>, <em>w</em>, <em>i</em>).
        If they later cooccur again, we obtain a new edge
        (<em>v</em>, <em>w</em>, <em>j</em>). Note that a document
        may contain multiple instances of the same entities.
        Formally, we obtain</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} E_C &amp;:=
            \lbrace (v,w,i) \; | \; v \in w \wedge i = \iota
            (v,w)\rbrace \end{align}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} E_P &amp;:=
            \lbrace (v,w,i) \; | \; \exists n \in N : v, w \in n
            \wedge i = \iota (v,w) \rbrace \end{align}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>Thus, containment edges occur between entities and
        sentences or sentences and documents, while proximity edges
        connect entities. Since there is a surjection from
        <em>S</em> to <em>N</em>, edges between entities and
        documents can be reconstructed from edges between entities
        and sentences. The resulting graph is undirected and we
        therefore do not distinguish between edges (<em>v</em>,
        <em>w</em>, <em>i</em>) and (<em>w</em>, <em>v</em>,
        <em>i</em>) where this is clear from context. We denote
        with <span class="inline-equation"><span class=
        "tex">$\mathcal {N}(v)$</span></span> the neighbourhood of
        a node <em>v</em>, i.e., all nodes that are connected to
        <em>v</em> by at least one edge.
        <p></p>
      </section>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Edge
            Weights and Edge Attributes</h3>
          </div>
        </header>
        <p>To assign weights and attributes, we distinguish between
        edges of the containment type <em>E<sub>C</sub></em> and
        edges of the proximity type <em>E<sub>P</sub></em> .</p>
        <p><strong>Set Containment Edges.</strong> Edges of the
        containment type are binary relations. Therefore, the
        resulting edges are essentially unweighted, although
        parallel edges may occur in rare cases. To simplify the
        subsequent notation, we define a distance function
        <span class="inline-equation"><span class="tex">$\delta :
        E_C \rightarrow \mathbb {N}$</span></span> for edges
        between an entity <em>v</em> and a sentence <em>s</em> as
        <em>δ</em>(<em>v</em>, <em>s</em>, <em>i</em>) ≔ 0 if
        <em>v</em> ∈ <em>s</em>, and <em>δ</em>(<em>v</em>,
        <em>s</em>, <em>i</em>) ≔ ∞ if <em>v</em>∉<em>s</em>. The
        distance between sentences and documents is defined
        analogously.</p>
        <p><strong>Occurrence Proximity Edges.</strong> Edges of
        the proximity type are more complex due to more finely
        nuanced distances and parallel edges caused by multiple
        cooccurrences. Since it is this entity cooccurrence
        information that encodes the relevant information for later
        analyses, we want to preserve these multiple edges and
        enrich them with additional information for later
        aggregation (see Section&nbsp;<a class="sec" href=
        "#sec-9">3.4</a>). We consider three fundamental concepts,
        namely (1) the publication time, (2) the textual distance
        between the mentions of two entities, and (3) the context
        of the mentions.</p>
        <p><strong>Publication Time.</strong> We assume that a
        publication time or retrieval date is known for each news
        article. Let <span class="inline-equation"><span class=
        "tex">$\tau : N \rightarrow \mathbb {N}$</span></span> map
        each document <em>n</em> ∈ <em>N</em> to its publication
        time <em>τ</em>(<em>n</em>). Let <em>n<sub>i</sub></em> be
        the document that contains an instance <em>i</em> inducing
        an edge <em>e</em> = (<em>v</em>, <em>w</em>, <em>i</em>)
        between two entities. We then assign <em>τ</em>(<em>e</em>)
        ≔ <em>τ</em>(<em>n<sub>i</sub></em> ) to edge
        <em>e</em>.</p>
        <p><strong>Textual Distance.</strong> By overloading the
        function <em>σ</em>, we can map each entity of an instance
        to the index of the sentence in which this entity occurs.
        Thus, let <em>σ</em>(<em>v</em>, <em>i</em>) denote the
        number of the sentence in which entity <em>v</em> occurs in
        instance <em>i</em>. For example, if entity <em>v</em> in
        instance <em>i</em> occurs in the first sentence of a
        document, then we have <em>σ</em>(<em>v</em>, <em>i</em>) =
        1. In analogy to the LOAD model, the textual sentence
        distance <span class="inline-equation"><span class=
        "tex">$\delta : E_P \rightarrow \mathbb {N}$</span></span>
        of two entities can then be written as</p>
        <div class="table-responsive" id="Xeq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \delta
            (v,w,i):=|\sigma (v,i)-\sigma (w,i)|
            \end{equation}</span><br />
            <span class="equation-number">(4)</span>
          </div>
        </div>For example, if entities <em>v</em> and <em>w</em>
        cooccur in a document such that <em>v</em> is contained in
        the first sentence and <em>w</em> is contained in the
        fourth sentence, then <em>δ</em>(<em>v</em>, <em>w</em>,
        <em>i</em>) = 3. Thus, if two entities occur in the same
        sentence, their distance is 0. If <em>v</em> and <em>w</em>
        never occur in the same document, we set
        <em>δ</em>(<em>v</em>, <em>w</em>) ≔ ∞. To include the
        distance of entity cooccurrences in the graph, we assign to
        each edge <em>e</em> = (<em>v</em>, <em>w</em>, <em>i</em>)
        the corresponding distance <em>δ</em>(<em>v</em>,
        <em>w</em>, <em>i</em>) as an edge attribute
        <em>δ</em>(<em>e</em>).
        <p></p>
        <p><strong>Context Embeddings.</strong> To conserve the
        context of joint entity mentions, we use a vector embedding
        of terms in the context window of two entities. Formally,
        an embedding is a function <span class=
        "inline-equation"><span class="tex">$\varepsilon : T
        \rightarrow \mathbb {R}^k$</span></span> that maps a term
        to a point in a <em>k</em>-dimensional vector space. To
        obtain the context of two entities in a cooccurrence
        instance, we define a context window as a function of those
        entities. Let <em>ω</em>: <em>E<sub>P</sub></em> → 2
        <sup><em>S</em></sup> , such that <em>ω</em> maps an
        instance to a set of sentences. Specifically, let
        <em>n<sub>i</sub></em> be the document containing an
        instance <em>i</em>, then</p>
        <div class="table-responsive" id="Xeq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \omega
            (v,w,i):=\lbrace s\in S \; | \; s\in n_i \wedge \sigma
            (v,i) \le \sigma (s) \le \sigma (w,i)\rbrace
            \end{equation}</span><br />
            <span class="equation-number">(5)</span>
          </div>
        </div>where w.l.o.g. <em>σ</em>(<em>v</em>, <em>i</em>) ≤
        <em>σ</em>(<em>w</em>, <em>i</em>). Thus,
        <em>ω</em>(<em>v</em>, <em>w</em>, <em>i</em>) consists of
        the sentences containing <em>v</em> and <em>w</em>, and all
        sentences inbetween. Based on this, we define the context
        of an edge <em>e</em> = (<em>v</em>, <em>w</em>,
        <em>i</em>) as the normalized sum of all embeddings of the
        terms in the context window <em>ω</em>(<em>v</em>,
        <em>w</em>, <em>i</em>). Thus, let <span class=
        "inline-equation"><span class="tex">$\kappa : E_P
        \rightarrow \mathbb {R}^k$</span></span> denote the context
        function
        <div class="table-responsive" id="Xeq4">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \kappa
            (v,w,i):=\sum _{s\in \omega (v,w,i)}\sum _{t\in s}
            \frac{\varepsilon (t)}{|\omega (v,w,i)|}
            \end{equation}</span><br />
            <span class="equation-number">(6)</span>
          </div>
        </div>where |<em>ω</em>(<em>v</em>, <em>w</em>,
        <em>i</em>)| denotes the number of terms in the context
        window. The removal of stop words and the limitation to
        content words is feasible in this step to reduce noise. For
        each edge <em>e</em> = (<em>v</em>, <em>w</em>,
        <em>i</em>), we store <em>κ</em>(<em>e</em>) as an
        attribute to identify pairs of entities that appear in
        similar contexts. For an overview of the model, see
        Figure&nbsp;<a class="fig" href="#fig1">1</a>.
        <figure id="fig1">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3188726/images/www18companion-234-fig1.jpg"
          class="img-responsive" alt="Figure 1" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 1:</span>
            <span class="figure-title">Schematic view of the model.
            Edges between entities <em>v</em> and <em>w</em> are
            extracted with context <em>κ</em>, distance <em>δ</em>
            and timestamp <em>τ</em>. If edges with a similar
            context between the same entities re-occur, they may be
            aggregated.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span> Aggregated
            Graph Attributes</h3>
          </div>
        </header>
        <p>We now lay the foundations for the entity-centric
        exploration of news in their context. A shortcoming of the
        LOAD model is the aggregation of all parallel edges to
        obtain a simple graph. While such an aggregation makes
        graph representations of large document collections
        feasible, it does not distinguish between mentions in
        different contexts. In news analysis, however, the number
        of contexts in which two entities cooccur is limited. Thus,
        aggregating edges by context still results in a stark
        reduction of the number of edges, while also preserving the
        context of entity cooccurrences for later analyses. Here,
        we argue that such an approach should be flexible enough to
        handle arbitrary numbers of contexts. Furthermore, an
        aggregation by context partially preserves the multiplicity
        of edges, while simultaneously collapsing unjustifiably
        duplicate edges to enable a more focused extraction of
        information from the resulting graph. In particular for
        entangled streams of news articles with redundant
        information, such an approach is clearly beneficial.</p>
        <p>To obtain an aggregated graph <em>G<sub>A</sub></em> =
        (<em>V</em>, <em>A</em>), we require a new set of
        aggregated edges <em>A</em> with aggregated attributes. Let
        <em>v</em> and <em>w</em> denote two entities and let
        <em>I<sub>a</sub></em> denote a set of instances that
        induce parallel edges <em>E<sub>a</sub></em> ≔
        {(<em>v</em>, <em>w</em>, <em>i</em>) ∈
        <em>E</em> | <em>i</em> ∈ <em>I<sub>a</sub></em> } between
        them. In the following, we discuss how to derive the
        aggregated edge features.</p>
        <p><strong>Aggregated Edge Importance.</strong> This weight
        derives an overall strength of the relation between two
        entities from the sentence distances of individual edges.
        Here, the dissimilarity of a sentence distance is
        transformed into a similarity by a decaying exponentiation.
        The individual similarities are then added over all
        aggregated edges. Thus, we compute a weight for the
        aggregated edge <em>a</em> = (<em>v</em>, <em>w</em>,
        <em>j</em>) as</p>
        <div class="table-responsive" id="Xeq5">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \chi (a):=\sum
            _{e\in E_a}\exp (-\delta (e))
            \end{equation}</span><br />
            <span class="equation-number">(7)</span>
          </div>
        </div>
        <p></p>
        <p><strong>Aggregated Publication Dates.</strong> For a
        temporal analysis, we store the set of all publication
        dates, which we assume to be distinct as long as the
        granularity of time is fine enough. For lower
        granularities, this attribute is effectively a multiset of
        dates. Formally,</p>
        <div class="table-responsive" id="Xeq6">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} T(a):=\bigcup
            _{e\in E_a} \lbrace \tau (e)\rbrace
            \end{equation}</span><br />
            <span class="equation-number">(8)</span>
          </div>
        </div>
        <p></p>
        <p><strong>Aggregated Context.</strong> The context is the
        primary component of the edge aggregation (see
        Section&nbsp;<a class="sec" href="#sec-9">3.4</a>).
        However, once edges are aggregated, a single context vector
        is sufficient to represent an edge and facilitate
        context-sensitive queries. Therefore, the contexts of
        individual edges can be aggregated as the mean of the
        context vectors. Since the context of two entities whose
        mentions are separated by a couple of sentences is likely
        less important than two mentions within the same sentence,
        we normalize individual contributions by the distance of
        the mentions <em>δ</em>. Thus,</p>
        <div class="table-responsive" id="Xeq7">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \kappa
            (a):=\frac{1}{|E_a|}\sum _{e\in E_a}\frac{\kappa
            (e)}{\delta (e)+1} \end{equation}</span><br />
            <span class="equation-number">(9)</span>
          </div>
        </div>
        <p></p>
        <p><strong>Number of Aggregated Edges.</strong> To maintain
        the context centroid in the streaming aggregation model, we
        store for each edge the number of individual edges that
        were aggregated. Thus, we define an attribute function
        <span class="inline-equation"><span class="tex">$\lambda :
        A \rightarrow \mathbb {N}$</span></span> with
        <em>λ</em>(<em>a</em>) ≔ |<em>E<sub>a</sub></em> |.</p>
        <p>Based on these four attributes, parallel edges in
        <em>G</em> = (<em>V</em>, <em>E</em>) can be combined to
        create the aggregated graph <em>G<sub>A</sub></em> =
        (<em>V</em>, <em>A</em>) as we describe in the following.
        For containment edges, only the importance and the number
        of aggregated edges are meaningful. For the importance of
        containment edges, note that the exponentiation turns the
        distances into a value of 1 for existing edges and 0 for
        missing edges. An overview of edge attributes is shown in
        Table&nbsp;<a class="tbl" href="#tab1">1</a>.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Overview of edge attributes in the
            graphs.</span>
          </div>
          <table class="table">
            <tbody>
              <tr>
                <td style="text-align:center;"><em>τ</em></td>
                <td style="text-align:left;">publication time</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"><em>ω</em></td>
                <td style="text-align:left;">context window</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>δ</em></td>
                <td style="text-align:left;">textual sentence
                distance</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"><em>κ</em></td>
                <td style="text-align:left;">context embedding</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>σ</em></td>
                <td style="text-align:left;">sentence index</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"><em>λ</em></td>
                <td style="text-align:left;"># aggregated
                edges</td>
              </tr>
              <tr>
                <td style="text-align:center;"><em>ι</em></td>
                <td style="text-align:left;">instance of
                cooccurrence</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"><em>η</em></td>
                <td style="text-align:left;">node type</td>
              </tr>
              <tr>
                <td style="text-align:center;">ɛ</td>
                <td style="text-align:left;">term embedding</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;"><em>χ</em></td>
                <td style="text-align:left;">edge importance</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.4</span> Edge
            Aggregation Schemes</h3>
          </div>
        </header>
        <p>For edge aggregation, two settings are possible. If
        real-time queries on streaming data are of interest, a
        streaming aggregation can be used to process news articles
        as they come in, and merge new edges to existing ones.
        Conceptually, this resembles streaming first story
        detection for microblogs&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0023">23</a>] but retains the entire contextual
        information. Extracted edges are treated as information
        fragments that can be merged with existing edges (if the
        context is sufficiently similar) or treated as new edges
        (if the context is sufficiently different). We refer to
        this as the <em>streaming approach</em>. Alternatively, all
        edges of all articles can be stored to retain the
        unaggregated information. In this case, the edges are
        aggregated locally between pairs of nodes at query time. We
        refer to this as the <em>static approach</em>.</p>
        <p><strong>Streaming Edge Aggregation.</strong> Streaming
        aggregation supports a real-time analysis of news articles
        as they become available and utilizes a <em>similarity
        threshold</em> parameter <em>t</em>. As new articles
        <em>n</em> are added to the collection, multigraph
        representations <em>G<sub>n</sub></em> =
        (<em>V<sub>n</sub></em> , <em>E<sub>n</sub></em> ) are
        constructed. Each edge in <em>G<sub>n</sub></em> is
        inserted into the collection graph <em>G<sub>A</sub></em>
        by aggregating it with existing edges based on context
        similarity. Here, any suitable vector similarity measure
        can be used to compare the embeddings. We distinguish
        between three cases for a new edge <em>e</em> =
        (<em>v</em>, <em>w</em>, <em>i</em>) ∈
        <em>E<sub>n</sub></em> . (1) If <em>e</em> is a containment
        edge, it is added to the set of aggregated edges
        <em>A</em>. (2) If <em>v</em> and <em>w</em> are
        disconnected in <em>G<sub>A</sub></em> , then e is added to
        <em>A</em>. (3) Otherwise, if <em>G<sub>A</sub></em>
        already contains edges between <em>v</em> and <em>w</em>,
        we check if <em>e</em> is sufficiently similar to the
        centroid context vector of an existing edge and aggregate
        it with the existing edge <em>a</em> ∈ <em>A</em> that is
        the best fit and update the edge attributes accordingly. If
        no existing edge is similar enough, <em>e</em> is inserted
        into <em>A</em>. For a detailed description, see
        Algorithm&nbsp;1 .</p>
        <p><img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3188726/images/www18companion-234-img2.svg"
        class="img-responsive" alt="" longdesc="" /> <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3188726/images/www18companion-234-img2.svg"
        class="img-responsive" alt="" longdesc="" /></p>
        <p><img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3188726/images/www18companion-234-img4.svg"
        class="img-responsive" alt="" longdesc="" /> <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3188726/images/www18companion-234-img4.svg"
        class="img-responsive" alt="" longdesc="" /></p>
        <p><strong>Static Edge Aggregation.</strong> The static
        aggregation of edges is a post-hoc processing of the
        collected news stream, in which parallel edges are
        clustered. Here, a clustering approach without a fixed
        number of clusters is required, as the optimal number of
        aggregated edges per pair of nodes is unknown and highly
        varying for different pairs of nodes. Additionally,
        outliers and noise should be kept separate from the
        clusters since many news articles do not belong to major
        news stories. After clustering, edges within each cluster
        are aggregated into a single edge. See also
        Algorithm&nbsp;2 .</p>
        <p><strong>Complexity.</strong> The complexity of the
        streaming approach is in <span class=
        "inline-equation"><span class="tex">$\mathcal {O}(I \cdot
        \langle p \rangle)$</span></span> , where ⟨<em>p</em>⟩ is
        the average multiplicity of parallel <em>aggregated</em>
        edges between node pairs. The number of instances
        <em>I</em> scales linearly with the number of articles
        <em>N</em> for a given cooccurrence window size, and
        ⟨<em>p</em>⟩ is small enough to support similar edge
        detection by linear scans, as we show in
        Section&nbsp;<a class="sec" href="#sec-17">5.4</a>. The
        complexity of the static approach is higher with
        <span class="inline-equation"><span class="tex">$\mathcal
        {O}(I\cdot C)$</span></span> , where <em>C</em> is the
        complexity of the selected clustering algorithm, which is
        likely at least quadratic in the edge multiplicity of
        <em>unaggregated</em> edges. However, due to the localized
        clustering, the approach is parallelizable by node
        pairs.</p>
        <p><strong>Stability.</strong> Both approaches produce
        deterministic results, although this depends on the
        temporal order of articles in the streaming approach.
        Obviously, the aggregated graphs differ between the two
        approaches. In Section&nbsp;<a class="sec" href=
        "#sec-13">5</a>, we compare their efficacy. In practice,
        the static approach can be applied in a streaming setting
        if sufficient memory is available to cluster edges locally
        at query time.</p>
      </section>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Network
          Creation and Exploration</h2>
        </div>
      </header>
      <p>Based on the above model, we consider application
      scenarios in which such a representation supports the
      exploration of news, and show exploratory results on a large
      stream of news articles.</p>
      <figure id="fig2">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3188726/images/www18companion-234-fig2.jpg"
        class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class=
          "figure-title">Evolution of contextual topics (i.e., edge
          contexts) for selected entity pairs with streaming
          aggregation (<em>t</em> = 0.65). Shown is the relative
          aggregated frequency of publication dates. Contexts are
          derived from the <em>k</em> = 5 terms in the
          neighbourhood of both entities whose context is most
          similar to the edge context. Q identifiers denote
          Wikidata IDs. Left: relation between Brazil and the
          International Olympic Committee. Right: relation between
          David Cameron and the United Kingdom.</span>
        </div>
      </figure>
      <p></p>
      <p><strong>Exploration Focus.</strong> Using an implicit
      network representation, any task that can be formulated as
      entity or term rankings or the extraction of weighted entity
      graph patterns is viable. In particular, events as dyadic or
      triadic structures of entities can be queried
      efficiently&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0027">27</a>]. Due to the transitivity of edge
      aggregation (edges can always be aggregated further), all
      entity-centric exploration methods designed for LOAD also
      work on our context-enriched model. We thus focus
      specifically on novel exploration methods that utilize
      temporal data and the context of entity mentions to extract
      evolving entity-centric topics from entangled news
      streams.</p>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> News
            Document Data</h3>
          </div>
        </header>
        <p>In the following, we describe the acquisition and
        preparation of the news data as well as the construction of
        the graph representation.</p>
        <p><strong>Data Collection.</strong> Since we require
        entangled news streams from multiple outlets, standard
        corpora such as the New York Times corpus cannot be used.
        Instead, we collect articles from the RSS feeds of
        international outlets with a focus on quality news. For
        content extraction, we use manually created rules since
        these allow a clean extraction of article contents
        (including multi-page articles) at a level that automatic
        boilerplate removal does not support&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0029">29</a>].</p>
        <p>Specifically, we use articles from 14 English speaking
        news outlets located in the U.S. (CNN, LA Times, NY Times,
        USA Today, CBS News, The Washington Post, IBTimes), Great
        Britain (BBC, The Independent, Reuters, SkyNews, The
        Telegraph, The Guardian), and Australia (Sidney Morning
        Herald). The RSS feeds of these outlets differ, but we
        focus on feeds related to political news. The time frame
        for our data collection is June 1 to November 30, 2016. We
        remove articles that have less than 200 or over 20,000
        characters (due to NER limitations) or more than 100
        disambiguated entities per article (i.e., lists). The final
        collection contains 127,485 articles over a period of six
        months, with a total of 5.4M sentences.</p>
        <p><strong>Data Preparation.</strong> Data preparation
        consists of five steps: recognition of named entities,
        entity linking, entity classification, part-of-speech and
        sentence tagging, and temporal tagging. For the recognition
        and disambiguation of named entities to Wikidata IDs, we
        use the Ambiverse API<a class="fn" href="#fn2" id=
        "foot-fn2"><sup>2</sup></a>. To classify named entities
        into actors, locations, and organizations, it is possible
        to use Wikidata hierarchies directly, but this can be
        problematic due to their constantly evolving
        structure&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0028">28</a>]. Therefore, we map Wikidata IDs to
        YAGO3 entities&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0018">18</a>] and classify them according to the
        YAGO hierarchy. For actors, we use the class
        <tt>wordnet_person_100007846</tt>, and for organizations
        <tt>wordnet_social_group_107950920</tt>. For locations, no
        comprehensive WordNet class exists, so we use
        <tt>yagoGeoEntity</tt>, which was designed for this
        purpose&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0014">14</a>]. For the extraction and
        normalization of temporal expressions we run HeidelTime in
        the news domain setting&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0031">31</a>]. Finally, for sentence splitting
        and part-of-speech tagging, we use the Stanford POS
        tagger&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0034">34</a>].</p>
        <p><strong>Network Construction.</strong> We proceed as
        described in Section&nbsp;<a class="sec" href=
        "#sec-5">3</a>. Terms are stemmed with the Porter stemming
        algorithm&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0024">24</a>], and we impose a minimum word
        length of 4 characters for terms. The window size for
        entity cooccurrence extraction is set to 5. As context
        embeddings, we use Google's pre-trained 300-dimensional
        word2vec&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0019">19</a>] word embeddings. The resulting
        networks has 5.7K dates, 27.7K locations, 72.0K actors,
        19.6K organizations, and 351K terms, which are connected by
        83.4M edges (before aggregation).</p>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Contextual
            Topic Evolution</h3>
          </div>
        </header>
        <p>To highlight an exploratory application, we demonstrate
        the extraction of contextual topics. We extract topics that
        best describe the individual contexts in which two entities
        are mentioned together and consider their evolution over
        time. Naturally, multiple such contexts may exist, which is
        reflected by the multiple parallel edges.</p>
        <p><strong>Contextual Topics.</strong> Recall that a
        context vector <em>κ</em>(<em>a</em>) is associated with
        each aggregated edge <em>a</em> = (<em>v</em>, <em>w</em>).
        We define a <em>contextual topic</em> of edge <em>a</em> as
        a weighted list of terms that describe the context in which
        entities <em>v</em> and <em>w</em> occur in instances
        included in <em>a</em>. To extract the contextual topics
        for all aggregated edges between these entities, we
        retrieve all terms <span class=
        "inline-equation"><span class="tex">$T_x = \mathcal {N}(v)
        \cap \mathcal {N}(w) \cap T$</span></span> in the joint
        neighbourhood of the two nodes along with all edges that
        connect them to <em>v</em> or <em>w</em>. We aggregate
        these edges such that each term <em>x</em> is connected to
        both <em>v</em> and <em>w</em> by exactly one edge, which
        we denote with <em>a<sub>v</sub></em> and
        <em>a<sub>w</sub></em> . Based on these triangular
        structures, we obtain a ranking score for each term
        <em>x</em> ∈ <em>T<sub>x</sub></em> in relation to edge
        <em>a</em> as</p>
        <div class="table-responsive" id="Xeq8">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            r_t(x|a=(v,w)):=\min \lbrace \textrm {sim}(\kappa
            (a),\kappa (a_v)), \textrm {sim}(\kappa (a),\kappa
            (a_w))\rbrace \end{equation}</span><br />
            <span class="equation-number">(10)</span>
          </div>
        </div>Intuitively, we are ranking terms by how closely the
        context in which they occur with an entity matches the
        context in which the entities occur together. We create
        such a ranking of terms for all aggregated edges between
        <em>v</em> and <em>w</em>. For each such edge, we select
        the <em>k</em> top-ranked terms to describe the topic.
        Thus, we obtain a natural language description for each of
        the edges between the two entities. Since edges are
        aggregated based on context similarity, the assumption is
        that the terms then describe the context of an edge and
        that each edge in turn represents a topic.
        <p></p>
        <p><strong>Results.</strong> To demonstrate the
        expressiveness of contextual topics, we show a timeline
        visualization of topics for pairs of entities. To extract
        these, we use a cosine similarity of the context vectors
        and rank the terms as described above. Then, we assign to
        each edge between the two entities the <em>k</em> = 5
        top-ranked terms as descriptors. We select the three top
        edges by multiplicity (i.e., the aggregated edges with the
        highest <em>λ</em> values). Since each such edge is
        associated with a set of publication times, we can plot the
        evolution of the topics over time. The results for two
        entity pairs are shown in Figure&nbsp;<a class="fig" href=
        "#fig2">2</a>. On the left, we see the evolution of topics
        for Brazil and the IOC (i.e., the Olympic Games). One can
        easily identify contexts as dealing with corruption,
        sports, and the awarding of medals. Specifically, the award
        topic spikes precisely at the date of the games. The second
        example shows the relation of David Cameron to the United
        Kingdom during the Brexit crisis. While all three topics
        are related to this issue, the referendum topic spikes at
        the proper date and the shift between the remaining topics
        towards Cameron's resignation only after the referendum is
        pronounced.</p>
        <p>In summary, the intuitive notion of aggregated edges as
        contexts corresponds well with our observations. Thus,
        term-based topic descriptors assign meaning to such edges,
        and their extraction serves to facilitate exploratory
        analyses of the news stream. Since the extraction utilizes
        only a localized substructure of the network around the
        focus entities, the process is efficient and allows a near
        real-time exploration of the entire entangled news stream.
        Alternatively, a subset of news outlets and focus entities
        can be selected by the user for a contrastive analysis
        between outlets, or context terms can be employed as
        additional input to quantify <em>how</em> a given news
        outlet reports about a specific group of entities.</p>
      </section>
    </section>
    <section id="sec-13">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Evaluation</h2>
        </div>
      </header>
      <p>To demonstrate the validity of our model beyond
      exploration, we evaluate the streaming and static approach on
      a set of news events.</p>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.1</span> Event
            Completion Task</h3>
          </div>
        </header>
        <p>We evaluate against LOAD as the only comparable implicit
        network model. The event completion task can be defined as
        follows: Given <em>k</em> − 1 out of <em>k</em> entities
        participating in an event, predict the remaining entity
        based on the data. We briefly describe the scheme used by
        LOAD for this task, before we present our improved version
        that includes the context. Both schemes rank entities
        <em>x</em> in the target set <em>X</em> ∈ {<em>L</em>,
        <em>O</em>, <em>A</em>, <em>D</em>} based on a set of query
        entities
        <em>Q</em>⊆<em>L</em>∪<em>O</em>∪<em>A</em>∪<em>D</em>.</p>
        <p><strong>LOAD Ranking (Baseline).</strong> This scheme
        applies a <em>tf-idf</em>-like scoring to the edges of the
        graph to rank entities <em>x</em> ∈ <em>X</em> based on a
        query entity <em>q</em> by computing a normalized
        importance score <em>r<sub>L</sub></em> as</p>
        <div class="table-responsive" id="Xeq9">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} r_L(x |
            q):=\left(\log \frac{|Q|}{|\mathcal {N}(x)\cap
            Q|}\right)\sum _{e=(x,q,\cdot)\in E}\exp (-\delta (e))
            \end{equation}</span><br />
            <span class="equation-number">(11)</span>
          </div>
        </div>Note that this scheme aggregates <em>all</em>
        parallel edges into a single edge, which is weighted by the
        sum of individual edge importances. Thus, the context is
        lost in this step. To generate a ranking based on multiple
        input entities, LOAD sums over the contributions of
        individual query entities. As an added feature, it includes
        the notion of <em>coherence</em>, requiring that each
        target entity is linked to at least min {<em>coh</em>,
        |<em>Q</em>|} query entities, with <em>coh</em> = 2 as a
        suggested value&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0030">30</a>].
        <p></p>
        <p><strong>Context-based Ranking.</strong> In the
        context-sensitive model, two entities may be connected by
        more than one edge, which we use to differentiate between
        target candidates. Let <em>E<sub>a</sub></em> (<em>x</em>)
        denote this set of aggregated edges between a query entity
        <em>q</em> and an entity <em>x</em> in the target set.
        Furthermore, where available, we can include the context of
        the event description in the query to match the context of
        candidate entities. Let <em>κ</em>(<em>q</em>) denote the
        context of query entities in the event, which we include in
        the improved ranking</p>
        <div class="table-responsive" id="Xeq10">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} r_C(x |
            q):=\max _{a\in E_a(x)}\left[\mathrm{sim}(\kappa
            (a),\kappa (q)) \left(\log \frac{|Q|}{|\mathcal
            {N}(x)\cap Q|}\right)\chi (a)\right]
            \end{equation}</span><br />
            <span class="equation-number">(12)</span>
          </div>
        </div>Intuitively, we normalize the importance of a
        candidate with the similarity <em>sim</em> to the query
        context, before using the best contribution as a ranking
        score. While any suitable vector similarity function can be
        used, we use the cosine similarity in the following since
        it works well for vector embeddings. To obtain a ranking by
        multiple query entities, we improve the notion of coherence
        and rank candidates first by the number of neighbours in
        the query set <span class="inline-equation"><span class=
        "tex">$|\mathcal {N}(x)\cap Q|$</span></span> , and break
        ties by the sum of ranking scores <em>r<sub>C</sub></em> .
        <p></p>
      </section>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.2</span> Evaluation
            Setup</h3>
          </div>
        </header>
        <p><strong>Static Clustering.</strong> We require a
        clustering algorithm without fixed clusters since it is
        impossible to divine a reasonable number of clusters that
        applies equally to all pairs of nodes. Thus, we select
        DBSCAN&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0010">10</a>] with cosine as a distance measure.
        To obtain the necessary parameters ϵ and <em>minPts</em>,
        we conduct a number of preparatory tests and find that the
        result quality suffers for high values of <em>minPts</em>,
        while <em>minPts</em> = 5 works well. Since a value of
        <em>minPts</em> &gt; |<em>E<sub>a</sub></em> | would be
        meaningless for edge aggregation, we use the scheme
        <span class="inline-equation"><span class="tex">$minPts =
        \min \lbrace 5, \frac{|E_a|}{5}\rbrace$</span></span> ,
        which performs best in our experiments. We then employ the
        min-points heuristic to obtain a reasonable value of ϵ =
        0.3 as a starting point for the evaluation.</p>
        <p><strong>Context Extraction Schemes.</strong> To derive
        contexts for entity cooccurrences, we consider two schemes
        according to the definition in Section&nbsp;<a class="sec"
        href="#sec-7">3.2</a>. For the <em>complete</em> context,
        we use the weighted average embedding of all non-stopwords
        inside the context window. Based on the importance of verbs
        for traditional event extraction, we also consider the
        <em>verb</em> context, for which we utilize only the
        embeddings of verbs inside the context window (we exclude
        all forms of the auxiliary verbs <em>be</em> and
        <em>have</em>). Both schemes are applied separately during
        network and ground truth construction.</p>
        <p><strong>Ground Truth Data.</strong> To extract ground
        truth events, we use the Wikipedia Current Events
        portal<a class="fn" href="#fn3" id=
        "foot-fn3"><sup>3</sup></a>, which contains manually
        maintained summarizations of news events. We crawl the
        pages for the months of June 2016 to November 2016 to
        extract each item as a news event. For NER and
        disambiguation, we use Wikipedia links in the text. Since
        the Wikipedia summaries contain references to news article
        sources, we match the references to articles in our input
        stream. We exclude all events that consist of less than two
        entities or have no reference to an article in our network.
        We obtain 97 individual events that correspond to at least
        one article in our collection. For each such event, we
        generate a query from each contained entity by using the
        remaining entities as query input and the removed entity as
        ground truth (i.e., an event with <em>k</em> entities
        induces <em>k</em>(<em>k</em> − 1) queries). We manually
        annotate the verbs in these event summaries. In total, we
        obtain 293 queries for the evaluation.</p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Evaluation results of the streaming edge
            aggregation. Shown is the precision@1 for the complete
            context embedding as well as a context derived only
            from verbs.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;" colspan="4">
                  aggregation threshold
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;"><em>t</em> =
                0.3</th>
                <th style="text-align:center;"><em>t</em> =
                0.4</th>
                <th style="text-align:center;"><em>t</em> =
                0.5</th>
                <th style="text-align:center;"><em>t</em> =
                0.6</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">complete</td>
                <td style="text-align:center;">0.218</td>
                <td style="text-align:center;">0.218</td>
                <td style="text-align:center;">0.232</td>
                <td style="text-align:center;">
                <strong>0.253</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">verb</td>
                <td style="text-align:center;">0.225</td>
                <td style="text-align:center;">0.222</td>
                <td style="text-align:center;">0.215</td>
                <td style="text-align:center;">0.208</td>
              </tr>
              <tr>
                <td style="text-align:left;">LOAD</td>
                <td colspan="4" style="text-align:center;">
                  0.157
                  <hr />
                </td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class=
            "table-title">Performance comparison of the static and
            streaming (<em>t</em> = 0.6) edge aggregation
            approaches on a subset of the evaluation data. We show
            the correct predictions at rank one (cor@1),
            precision@1, and recall.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">LOAD</th>
                <th style="text-align:center;" colspan="2">
                  stream aggr.
                  <hr />
                </th>
                <th style="text-align:center;" colspan="3">
                  static clustering
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">complete</th>
                <th style="text-align:center;">verb</th>
                <th style="text-align:center;">ϵ = 0.2</th>
                <th style="text-align:center;">ϵ = 0.3</th>
                <th style="text-align:center;">ϵ = 0.4</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">cor@1</td>
                <td style="text-align:center;">44</td>
                <td style="text-align:center;">71</td>
                <td style="text-align:center;">61</td>
                <td style="text-align:center;">35</td>
                <td style="text-align:center;">27</td>
                <td style="text-align:center;">25</td>
              </tr>
              <tr>
                <td style="text-align:left;">prc@1</td>
                <td style="text-align:center;">0.165</td>
                <td style="text-align:center;">
                <strong>0.266</strong></td>
                <td style="text-align:center;">0.228</td>
                <td style="text-align:center;">0.131</td>
                <td style="text-align:center;">0.101</td>
                <td style="text-align:center;">0.094</td>
              </tr>
              <tr>
                <td style="text-align:left;">recall</td>
                <td style="text-align:center;">0.655</td>
                <td style="text-align:center;">0.955</td>
                <td style="text-align:center;">0.955</td>
                <td style="text-align:center;">0.955</td>
                <td style="text-align:center;">0.955</td>
                <td style="text-align:center;">0.955</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-16">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.3</span> Evaluation
            Results</h3>
          </div>
        </header>
        <p>Each evaluation query has exactly one correct answer.
        Therefore, suitable evaluation metrics are precision@1,
        i.e., the fraction of queries in which the top ranked
        prediction is correct, and recall@k, i.e., the number of
        correct predictions among the top <em>k</em>
        predictions.</p>
        <p><strong>Streaming Aggregation.</strong> We first compare
        the two approaches for context generation over varying
        aggregation thresholds and show the resulting precision in
        Table&nbsp;<a class="tbl" href="#tab2">2</a>. Threshold
        values of <em>t</em> &lt; 0.3 are omitted since no further
        changes occur. Both methods outperform the LOAD baseline by
        a large margin (up to 61% improvement). The verb context
        aggregation shows a slight decline in performance with
        increasing threshold. The precision of the complete context
        increases with the threshold value and it performs better
        overall. In Figure&nbsp;<a class="fig" href="#fig3">3</a>
        (top), we show the corresponding recall values of the
        complete context approach. Varying thresholds show little
        influence on recall, which makes low thresholds attractive
        in settings where a compact representation is important and
        recall@5 is sufficient.</p>
        <p><strong>Static Aggregation.</strong> In
        Table&nbsp;<a class="tbl" href="#tab3">3</a>, we show the
        performance of the static aggregation for a subset of 267
        evaluation queries (the remaining 26 clusterings did not
        finish within 48 hours). Due to this smaller evaluation
        set, the values for the static aggregation vary slightly.
        For some of the ϵ settings, the clustering performs better
        than the LOAD baseline, but not by a large margin, and
        higher values of ϵ decrease the performance. The recall
        values shown in Figure&nbsp;<a class="fig" href=
        "#fig3">3</a> support this observation. While static
        aggregation outperforms LOAD, it does not rival the
        streaming aggregation.</p>
        <p>In summary, we find that streaming edge aggregation is
        superior to static aggregation in this setting. While other
        clustering algorithms may perform better, our tests were
        extensive and the ease of use for the streaming method is
        much higher. While the optimal parameter settings for
        clustering approaches are usually difficult to obtain, in
        the streaming approach there is a direct correlation
        between the threshold and the prediction quality. What
        remains is the issue of performance depending on the
        threshold selection, which we discuss in the following.</p>
      </section>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.4</span> Edge
            Deflation in Streaming Aggregation</h3>
          </div>
        </header>
        <p>The streaming model is designed to reduce the number of
        aggregated edges that are stored in the graph to a
        manageable size and avoid redundancy. Especially for
        entangled news streams, many parallel edges with highly
        similar context are to be expected. In
        Figure&nbsp;<a class="fig" href="#fig4">4</a>, we show the
        number of aggregated edges as a function of the number of
        unaggregated edges for different threshold values applied
        to the complete context embeddings. We find that for
        thresholds <em>t</em> ≤ 0.3, aggregation is almost complete
        and there are never more than three parallel edges. For
        higher thresholds, this number increases but is still
        easily manageable. Since higher thresholds are favorable
        with regard to the extraction of information from the
        graph, the threshold thus has to be tuned to the data
        throughput in an application scenario. For the real-time
        processing of streams of news articles, this is
        unproblematic due to the relatively low volume of documents
        in the news domain. For higher frequency streams such as
        the entire blogosphere, more sophisticated data structures
        or similarity approximations may be desirable.</p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3188726/images/www18companion-234-fig3.jpg"
          class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">Recall of the edge
            aggregation methods for the event completion task. Top:
            values for different thresholds of the streaming
            aggregation approach with the complete context. Bottom:
            Comparison of the recall of the static aggregation
            DBSCAN clustering for <em>minPts</em> = 5 and varying
            ϵ.</span>
          </div>
        </figure>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3188726/images/www18companion-234-fig4.jpg"
          class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">Deflation of parallel edges
            for streaming aggregation with complete context as a
            linear fit to the average number of edges after
            aggregation with a 3<em>σ</em> confidence
            interval.</span>
          </div>
        </figure>
        <p></p>
      </section>
    </section>
    <section id="sec-18">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Conclusion
          &amp; Ongoing Work</h2>
        </div>
      </header>
      <p>In this paper, we discussed the problem of entity-centric
      explorations of large entangled streams of news articles.
      Based on the intuition that entity mentions can serve as
      stitching points between potentially biased news streams and
      as focal points of news retrieval tasks, we introduced
      contextual implicit entity networks as a comprehensive and
      versatile tool for the representation of such entangled news
      streams. The model can be constructed faster than the
      publication speed of news articles by several orders of
      magnitude and thus efficiently facilitates a multitude of
      subsequent entity-centric information retrieval tasks from
      the underlying streams in near real-time, such as topic and
      event extraction and tracking, contextual search, descriptive
      sentence extraction, or document retrieval. Furthermore, it
      supports the interactive contrastive exploration and
      contextual aggregation of news published by multiple news
      outlets as well as their change over time. We evaluated the
      model's performance for different parameter settings on a
      large collection of news streams, and found that the
      streaming aggregation approach outperforms existing
      alternatives for the task of entity-centric event completion.
      Finally, we discussed an application of the model to the
      extraction of contextual and entity-centric topic detection
      and tracking as one example of news exploration in entangled
      news streams. Our implementation of the model along with all
      used data is available for further studies.</p>
      <p><strong>Ongoing Work.</strong> We are currently
      researching the extraction of evolving document topics from
      entity-centric topics, in a step towards the comparison of
      contents between news streams. Furthermore, we are working on
      a generalization of the model to settings with more versatile
      requirements for (named) entity annotations.</p>
      <p><strong>Acknowledgements.</strong> The authors would like
      to thank Satya Almasian for her assistance in preparing the
      ground truth data, and the Ambiverse Ambinauts for kindly
      providing access to their named entity linking and
      disambiguation API.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Amr Ahmed, Qirong Ho,
        Jacob Eisenstein, Eric&nbsp;P. Xing, Alexander&nbsp;J.
        Smola, and Choon&nbsp;Hui Teo. 2011. Unified Analysis of
        Streaming News. <em><em>In WWW</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/1963405.1963445" target="_blank">
          https://doi.org/10.1145/1963405.1963445</a>
        </li>
        <li id="BibPLXBIB0002" label="[2]">James Allan. 2012. <em>
          <em>Topic Detection and Tracking: Event-based Information
          Organization</em></em> . Vol.&nbsp;12. Springer.
          <a class="link-inline force-break" href=
          "https://doi.org/10.1007/978-1-4615-0933-2" target=
          "_blank">https://doi.org/10.1007/978-1-4615-0933-2</a>
        </li>
        <li id="BibPLXBIB0003" label="[3]">James Allan, Ron Papka,
        and Victor Lavrenko. 1998. On-Line New Event Detection and
        Tracking. In <em><em>SIGIR</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/290941.290954" target=
        "_blank">https://doi.org/10.1145/290941.290954</a>
        </li>
        <li id="BibPLXBIB0004" label="[4]">Foteini Alvanaki,
        Sebastian Michel, Krithi Ramamritham, and Gerhard Weikum.
        2012. See What's enBlogue: Real-time Emergent Topic
        Identification in Social Media. <em><em>In EDBT</em></em> .
        <a class="link-inline force-break" href=
        "https://doi.org/10.1145/2247596.2247636" target="_blank">
          https://doi.org/10.1145/2247596.2247636</a>
        </li>
        <li id="BibPLXBIB0005" label="[5]">Martin Atkinson and
        Erik&nbsp;Van der Goot. 2009. Near Real Time Information
        Mining in Multilingual News. <em><em>In WWW</em></em> .
        1153–1154. <a class="link-inline force-break" href=
        "https://doi.org/10.1145/1526709.1526903" target="_blank">
          https://doi.org/10.1145/1526709.1526903</a>
        </li>
        <li id="BibPLXBIB0006" label="[6]">Roi Blanco and Christina
        Lioma. 2012. Graph-based Term Weighting for Information
        Retrieval. <em><em>Inf. Retr.</em></em> 15, 1 (2012),
        54–92. <a class="link-inline force-break" href=
        "https://doi.org/10.1007/s10791-011-9172-x" target=
        "_blank">https://doi.org/10.1007/s10791-011-9172-x</a>
        </li>
        <li id="BibPLXBIB0007" label="[7]">David&nbsp;M Blei. 2012.
        Probabilistic Topic Models. <em><em>Commun. ACM</em></em>
        55, 4 (2012), 77–84. <a class="link-inline force-break"
        href="https://doi.org/10.1145/2133806.2133826" target=
        "_blank">https://doi.org/10.1145/2133806.2133826</a>
        </li>
        <li id="BibPLXBIB0008" label="[8]">James&nbsp;P. Callan.
        1996. Document Filtering With Inference Networks. In
        <em><em>SIGIR</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/243199.243273" target=
        "_blank">https://doi.org/10.1145/243199.243273</a>
        </li>
        <li id="BibPLXBIB0009" label="[9]">Andrea Ceroni, Ujwal
        Gadiraju, Jan Matschke, Simon Wingert, and Marco
        Fisichella. 2016. Where the Event Lies: Predicting Event
        Occurrence in Textual Documents. <em><em>In SIGIR</em></em>
        . <a class="link-inline force-break" href=
        "https://doi.org/10.1145/2911451.2911452" target="_blank">
          https://doi.org/10.1145/2911451.2911452</a>
        </li>
        <li id="BibPLXBIB0010" label="[10]">Martin Ester,
        Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. A
        Density-Based Algorithm for Discovering Clusters in Large
        Spatial Databases with Noise. <em><em>In KDD</em></em> .
        <a class="link-inline force-break" href=
        "http://www.aaai.org/Library/KDD/1996/kdd96-037.php"
          target="_blank">http://www.aaai.org/Library/KDD/1996/kdd96-037.php</a>
        </li>
        <li id="BibPLXBIB0011" label="[11]">Ao Feng and James
        Allan. 2007. Finding and Linking Incidents in News. In <em>
          <em>CIKM</em></em> . <a class="link-inline force-break"
          href="https://doi.org/10.1145/1321440.1321554" target=
          "_blank">https://doi.org/10.1145/1321440.1321554</a>
        </li>
        <li id="BibPLXBIB0012" label="[12]">Dhruv Gupta and Klaus
        Berberich. 2014. Identifying Time Intervals of Interest to
        Queries. <em><em>In CIKM</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/2661829.2661927" target="_blank">
          https://doi.org/10.1145/2661829.2661927</a>
        </li>
        <li id="BibPLXBIB0013" label="[13]">Dhruv Gupta, Jannik
        Strötgen, and Klaus Berberich. 2016. EventMiner: Mining
        Events from Annotated Documents. <em><em>In ICTIR</em></em>
        . <a class="link-inline force-break" href=
        "https://doi.org/10.1145/2970398.2970411" target="_blank">
          https://doi.org/10.1145/2970398.2970411</a>
        </li>
        <li id="BibPLXBIB0014" label="[14]">Johannes Hoffart,
        Fabian&nbsp;M. Suchanek, Klaus Berberich, Edwin
        Lewis-Kelham, Gerard de Melo, and Gerhard Weikum. 2011.
        YAGO2: Exploring and Querying World Knowledge in Time,
        Space, Context, and many Languages. <em><em>In WWW
        Companion</em></em> . <a class="link-inline force-break"
        href="https://doi.org/10.1145/1963192.1963296" target=
        "_blank">https://doi.org/10.1145/1963192.1963296</a>
        </li>
        <li id="BibPLXBIB0015" label="[15]">Nattiya Kanhabua, Sara
        Romano, and Avaré Stewart. 2012. Identifying Relevant
        Temporal Expressions for Real-world Events. <em><em>In
        TAIA@SIGIR</em></em> .</li>
        <li id="BibPLXBIB0016" label="[16]">Andrey Kutuzov and
        Elizaveta Kuzmenko. 2016. Cross-Lingual Trends Detection
        for Named Entities in News Texts with Dynamic Neural
        Embedding Models. In <em><em>NewsIR@ECIR</em></em> .
        <a class="link-inline force-break" href=
        "http://ceur-ws.org/Vol-1568/paper5.pdf" target=
        "_blank">http://ceur-ws.org/Vol-1568/paper5.pdf</a>
        </li>
        <li id="BibPLXBIB0017" label="[17]">Levon Lloyd, Dimitrios
        Kechagias, and Steven Skiena. 2005. Lydia: A System for
        Large-Scale News Analysis. <em><em>In SPIRE</em></em> .
        <a class="link-inline force-break" href=
        "https://doi.org/10.1007/11575832_18" target=
        "_blank">https://doi.org/10.1007/11575832_18</a>
        </li>
        <li id="BibPLXBIB0018" label="[18]">Farzaneh Mahdisoltani,
        Joanna Biega, and Fabian&nbsp;M. Suchanek. 2015. YAGO3: A
        Knowledge Base from Multilingual Wikipedias. <em><em>In
        CIDR</em></em> . <a class="link-inline force-break" href=
        "http://cidrdb.org/cidr2015/Papers/CIDR15_Paper1.pdf"
        target=
        "_blank">http://cidrdb.org/cidr2015/Papers/CIDR15_Paper1.pdf</a>
        </li>
        <li id="BibPLXBIB0019" label="[19]">Tomas Mikolov, Ilya
        Sutskever, Kai Chen, Gregory&nbsp;S. Corrado, and Jeffrey
        Dean. 2013. Distributed Representations of Words and
        Phrases and their Compositionality. <em><em>In
        NIPS</em></em> . <a class="link-inline force-break" href=
        "http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality"
          target=
          "_blank">http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality</a>
        </li>
        <li id="BibPLXBIB0020" label="[20]">Anne-Lyse Minard,
        Manuela Speranza, Eneko Agirre, Itziar Aldabe, Marieke van
        Erp, Bernardo Magnini, German Rigau, and Ruben Urizar.
        2015. SemEval-2015 Task 4: TimeLine: Cross-Document Event
        Ordering. <em><em>In SemEval@NAACL-HLT</em></em> .
          <a class="link-inline force-break" href=
          "http://aclweb.org/anthology/S/S15/S15-2132.pdf" target=
          "_blank">http://aclweb.org/anthology/S/S15/S15-2132.pdf</a>
        </li>
        <li id="BibPLXBIB0021" label="[21]">Arunav Mishra and Klaus
        Berberich. 2016. Event Digest: A Holistic View on Past
        Events. <em><em>In SIGIR</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/2911451.2911526" target="_blank">
          https://doi.org/10.1145/2911451.2911526</a>
        </li>
        <li id="BibPLXBIB0022" label="[22]">Sean Moran, Richard
        McCreadie, Craig Macdonald, and Iadh Ounis. 2016. Enhancing
        First Story Detection using Word Embeddings. <em><em>In
        SIGIR</em></em> . <a class="link-inline force-break"
          href="https://doi.org/10.1145/2911451.2914719" target=
          "_blank">https://doi.org/10.1145/2911451.2914719</a>
        </li>
        <li id="BibPLXBIB0023" label="[23]">Sasa Petrovic, Miles
        Osborne, and Victor Lavrenko. 2010. Streaming First Story
        Detection with Application to Twitter. <em><em>In
        NAACL-HLT</em></em> . <a class="link-inline force-break"
        href="http://www.aclweb.org/anthology/N10-1021" target=
        "_blank">http://www.aclweb.org/anthology/N10-1021</a>
        </li>
        <li id="BibPLXBIB0024" label="[24]">Martin&nbsp;F. Porter.
        1980. An Algorithm for Suffix Stripping.
        <em><em>Program</em></em> 14, 3 (1980), 130–137.
          <a class="link-inline force-break" href=
          "https://doi.org/10.1108/eb046814" target=
          "_blank">https://doi.org/10.1108/eb046814</a>
        </li>
        <li id="BibPLXBIB0025" label="[25]">François Rousseau and
        Michalis Vazirgiannis. 2013. Graph-of-word and TW-IDF: New
        Approach to Ad Hoc IR. <em><em>In CIKM</em></em> .
          <a class="link-inline force-break" href=
          "https://doi.org/10.1145/2505515.2505671" target=
          "_blank">https://doi.org/10.1145/2505515.2505671</a>
        </li>
        <li id="BibPLXBIB0026" label="[26]">Anish&nbsp;Das Sarma,
        Alpa Jain, and Cong Yu. 2011. Dynamic Relationship and
        Event Discovery. In <em><em>WSDM</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/1935826.1935867" target="_blank">
          https://doi.org/10.1145/1935826.1935867</a>
        </li>
        <li id="BibPLXBIB0027" label="[27]">Andreas Spitz, Satya
        Almasian, and Michael Gertz. 2017. EVELIN: Exploration of
        Event and Entity Links in Implicit Networks. <em><em>In WWW
        Companion</em></em> . <a class="link-inline force-break"
        href="https://doi.org/10.1145/3041021.3054721" target=
        "_blank">https://doi.org/10.1145/3041021.3054721</a>
        </li>
        <li id="BibPLXBIB0028" label="[28]">Andreas Spitz, Vaibhav
        Dixit, Ludwig Richter, Michael Gertz, and Johanna Geiß.
        2016. State of the Union: A Data Consumer's Perspective on
        Wikidata and Its Properties for the Classification and
        Resolution of Entities. <em><em>In Wiki@ICWSM</em></em> .
        <a class="link-inline force-break" href=
        "http://aaai.org/ocs/index.php/ICWSM/ICWSM16/paper/view/13200"
          target=
          "_blank">http://aaai.org/ocs/index.php/ICWSM/ICWSM16/paper/view/13200</a>
        </li>
        <li id="BibPLXBIB0029" label="[29]">Andreas Spitz and
        Michael Gertz. 2015. Breaking the News: Extracting the
        Sparse Citation Network Backbone of Online News Articles.
        In <em><em>ASONAM</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/2808797.2809380" target="_blank">
          https://doi.org/10.1145/2808797.2809380</a>
        </li>
        <li id="BibPLXBIB0030" label="[30]">Andreas Spitz and
        Michael Gertz. 2016. Terms over LOAD: Leveraging Named
        Entities for Cross-Document Extraction and Summarization of
        Events. <a class="link-inline force-break" href=
        "https://doi.org/10.1145/2911451.2911529" target="_blank">
          https://doi.org/10.1145/2911451.2911529</a>
        </li>
        <li id="BibPLXBIB0031" label="[31]">Jannik Strötgen and
        Michael Gertz. 2013. Multilingual and Cross-domain Temporal
        Tagging. <em><em>Language Resources and
        Evaluation</em></em> 47, 2 (2013), 269–298. <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1007/s10579-012-9179-y" target=
        "_blank">https://doi.org/10.1007/s10579-012-9179-y</a>
        </li>
        <li id="BibPLXBIB0032" label="[32]">Chenhao Tan, Adrien
        Friggeri, and Lada&nbsp;A. Adamic. 2016. Lost in
        Propagation? Unfolding News Cycles from the Source.
        <em><em>In ICWSM</em></em> . <a class=
        "link-inline force-break" href=
        "http://www.aaai.org/ocs/index.php/ICWSM/ICWSM16/paper/view/13011"
          target=
          "_blank">http://www.aaai.org/ocs/index.php/ICWSM/ICWSM16/paper/view/13011</a>
        </li>
        <li id="BibPLXBIB0033" label="[33]">Benjamin&nbsp;E.
        Teitler, Michael&nbsp;D. Lieberman, Daniele Panozzo, Jagan
        Sankaranarayanan, Hanan Samet, and Jon Sperling. 2008.
        NewsStand: A New View on News. In <em><em>ACM-GIS</em></em>
        . <a class="link-inline force-break" href=
        "https://doi.org/10.1145/1463434.1463458" target="_blank">
          https://doi.org/10.1145/1463434.1463458</a>
        </li>
        <li id="BibPLXBIB0034" label="[34]">Kristina Toutanova, Dan
        Klein, Christopher&nbsp;D. Manning, and Yoram Singer. 2003.
        Feature-Rich Part-of-Speech Tagging with a Cyclic
        Dependency Network. <em><em>In NAACL-HLT</em></em> .
        <a class="link-inline force-break" href=
        "http://aclweb.org/anthology/N/N03/N03-1033.pdf" target=
        "_blank">http://aclweb.org/anthology/N/N03/N03-1033.pdf</a>
        </li>
        <li id="BibPLXBIB0035" label="[35]">Jeroen B.&nbsp;P.
        Vuurens, Arjen&nbsp;P. de Vries, Roi Blanco, and Peter
        Mika. 2015. Online News Tracking for Ad-Hoc Queries. In
        <em><em>SIGIR</em></em> . <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/2766462.2767872" target="_blank">
          https://doi.org/10.1145/2766462.2767872</a>
        </li>
        <li id="BibPLXBIB0036" label="[36]">Yiming Yang, Thomas
        Pierce, and Jaime&nbsp;G. Carbonell. 1998. A Study of
        Retrospective and On-Line Event Detection. <em><em>In
        SIGIR</em></em> . <a class="link-inline force-break"
          href="https://doi.org/10.1145/290941.290953" target=
          "_blank">https://doi.org/10.1145/290941.290953</a>
        </li>
        <li id="BibPLXBIB0037" label="[37]">Yiming Yang, Jian
        Zhang, Jaime&nbsp;G. Carbonell, and Chun Jin. 2002.
        Topic-conditioned Novelty Detection. In
        <em><em>KDD</em></em> . <a class="link-inline force-break"
          href="https://doi.org/10.1145/775047.775150" target=
          "_blank">https://doi.org/10.1145/775047.775150</a>
        </li>
        <li id="BibPLXBIB0038" label="[38]">Kaiqi Zhao, Lisi Chen,
        and Gao Cong. 2016. Topic Exploration in Spatio-Temporal
        Document Collections. <em><em>In SIGMOD</em></em> .
        <a class="link-inline force-break" href=
        "https://doi.org/10.1145/2882903.2882921" target="_blank">
          https://doi.org/10.1145/2882903.2882921</a>
        </li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>News graph,
    evaluation data, and code are available for download at our
    website:</p>
    <p><a class="link-inline force-break" href=
    "https://dbs.ifi.uni-heidelberg.de/resources/newsstream/">https://dbs.ifi.uni-heidelberg.de/resources/newsstream/</a></p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>
    <tt>https://www.ambiverse.com/</tt></p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>
    <tt>https://en.wikipedia.org/wiki/Portal:Current_events</tt></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3188726">https://doi.org/10.1145/3184558.3188726</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
