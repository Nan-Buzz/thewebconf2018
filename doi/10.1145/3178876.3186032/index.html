<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>Attack under Disguise: An Intelligent Data Poisoning Attack Mechanism in Crowdsourcing</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main">  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">Attack under Disguise: An Intelligent Data Poisoning Attack Mechanism in Crowdsourcing</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author">     <span class="givenName">Chenglin</span>     <span class="surName">Miao</span>,     State University of New York at Buffalo, NY, USA, <a href="mailto:cmiao@buffalo.edu">cmiao@buffalo.edu</a>    </div>    <div class="author">     <span class="givenName">Qi</span>     <span class="surName">Li</span>,     University of Illinois at Urbana-Champaign, IL, USA, <a href="mailto:qili5@illinois.edu">qili5@illinois.edu</a>    </div>    <div class="author">     <span class="givenName">Lu</span>     <span class="surName">Su</span><a class="fn" href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>,     State University of New York at Buffalo, NY, USA, <a href="mailto:lusu@buffalo.edu">lusu@buffalo.edu</a>    </div>    <div class="author">     <span class="givenName">Mengdi</span>     <span class="surName">Huai</span>,     State University of New York at Buffalo, NY, USA, <a href="mailto:mengdihu@buffalo.edu">mengdihu@buffalo.edu</a>    </div>    <div class="author">     <span class="givenName">Wenjun</span>     <span class="surName">Jiang</span>,     State University of New York at Buffalo, NY, USA, <a href="mailto:wenjunji@buffalo.edu">wenjunji@buffalo.edu</a>    </div>    <div class="author">     <span class="givenName">Jing</span>     <span class="surName">Gao</span>,     State University of New York at Buffalo, NY, USA, <a href="mailto:jing@buffalo.edu">jing@buffalo.edu</a>    </div>                            </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3178876.3186032" target="_blank">https://doi.org/10.1145/3178876.3186032</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>As an effective way to solicit useful information from the crowd, crowdsourcing has emerged as a popular paradigm to solve challenging tasks. However, the data provided by the participating workers are not always trustworthy. In real world, there may exist malicious workers in crowdsourcing systems who conduct the data poisoning attacks for the purpose of sabotage or financial rewards. Although data aggregation methods such as majority voting are conducted on workers&#x2019; labels in order to improve data quality, they are vulnerable to such attacks as they treat all the workers equally. In order to capture the variety in the reliability of workers, the Dawid-Skene model, a sophisticated data aggregation method, has been widely adopted in practice. By conducting maximum likelihood estimation (MLE) using the expectation maximization (EM) algorithm, the Dawid-Skene model can jointly estimate each worker&#x0027;s reliability and conduct weighted aggregation, and thus can tolerate the data poisoning attacks to some degree. However, the Dawid-Skene model still has weakness. In this paper, we study the data poisoning attacks against such crowdsourcing systems with the Dawid-Skene model empowered. We design an intelligent attack mechanism, based on which the attacker can not only achieve maximum attack utility but also disguise the attacking behaviors. Extensive experiments based on real-world crowdsourcing datasets are conducted to verify the desirable properties of the proposed mechanism.</small>    </p>    </div>    <div class="CCSconcepts">    <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Security and privacy </strong>&#x2192; <strong>Systems security;</strong> &#x2022;<strong> Human-centered computing </strong>&#x2192; <strong>Collaborative and social computing;</strong></small> </p>    </div>    <div class="classifications">    <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Crowdsourcing</small>, </span>     <span class="keyword">      <small> data poisoning</small>, </span>     <span class="keyword">      <small> expectation maximization</small>     </span>    </div>    <br/>    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Chenglin Miao, Qi Li, Lu Su, Mengdi Huai, Wenjun Jiang, and Jing Gao. 2018. Attack under Disguise: An Intelligent Data Poisoning Attack Mechanism in Crowdsourcing. In <em>WWW 2018: The 2018 Web Conference,</em>       <em>April 23&#x2013;27, 2018 (WWW 2018),</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 10 Pages. <a href="https://doi.org/10.1145/3178876.3186032" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3178876.3186032</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-7">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>    </div>    </header>    <p>With the proliferation of online crowdsourcing services such as Amazon Mechanical Turk (AMT)<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a> and CrowdFlower<a class="fn" href="#fn3" id="foot-fn3"><sup>2</sup></a>, crowdsourcing has emerged as a popular, fast and cheap problem-solving paradigm for various data analysis tasks, such as image annotation&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0052">52</a>], entity resolution&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0047">47</a>] and sentiment analysis&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>]. Through the power of the crowd, the data requesters can obtain large amounts of data at extremely low cost. In a typical crowdsourcing system, the data requester posts the tasks that require human intelligence onto a crowdsourcing service platform, and then a large crowd of people (usually referred to as <em>workers</em>) participate in the tasks that they are interested in. In crowdsourcing systems, to reduce the errors made by individual workers, a common practice is to query an item (e.g., a picture or a question) to multiple workers and then aggregate their labels on the items.</p>    <p>Although crowdsourcing brings substantial advantages, the openness of the crowdsourcing systems and the potential value of the collected data offer both opportunities and incentives for malicious parties to launch attacks. In this paper, we investigate crowdsourcing in adversarial environments and study an important attack form, called <em>data poisoning</em>. In this attack, the attacker aims to maximize the error of the final results and render the crowdsourcing results useless through creating or recruiting a group of malicious workers and letting them provide manipulated data. This attack goal can be easily achieved if the attacker has the capability of creating or recruiting an overwhelming number of malicious workers. However, in practice, the attacker usually has limited resources and he can only control a few malicious workers. In such cases, the attack strategy plays an important role.</p>    <p>A naive attack strategy is to let the malicious workers always disagree with the normal workers. If some straightforward aggregation methods, such as majority voting, are used to aggregate the data, this naive attack model may be the optimal choice, since every malicious worker exerts the most influence in the aggregation. However, the story would become much more complicated when some more sophisticated aggregation methods that can capture the reliability (i.e., data quality) of each worker are employed. A representative method in this category is the <em>Dawid-Skene</em> model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>], which has been widely adopted in crowdsourcing to aggregate the conflicting data from different workers. In the Dawid-Skene model, each worker is associated with an underlying confusion matrix, which can reflect the reliability degree of this worker. After the labels are collected from the workers, the final results and the workers&#x2019; confusion matrices are jointly estimated based on the maximum likelihood principle. As a result, workers with low reliability degrees will have low impact in the aggregation. In this case, if an attacker adopts the aforementioned naive attack, in which the malicious workers always disagree with the normal workers, the malicious workers are very likely to be assigned a significantly low reliability degree by the Dawid-Skene model, and thus will not be able to make any difference in the final aggregated results.</p>    <p>To attack a crowdsourcing system with the Dawid-Skene model empowered, we propose an intelligent data poisoning attack mechanism that takes into account the malicious workers&#x2019; reliability degrees. In this mechanism, the malicious workers behave more &#x201C;intelligently&#x201D;, i.e., try to improve their reliability degrees by agreeing with the normal workers on some items whose values are unlikely to be overturned. Compared with the aforementioned naive strategy, the proposed intelligent attack model can not only disguise the malicious workers, but also enable them to launch more effective attacks on the items that are more vulnerable to attack.</p>    <p>Towards this end, we formulate a bi-level optimization problem. The objective in the optimization problem is to maximize the attacker&#x0027;s utility, which is the combination of the number of the successfully attacked items and the malicious workers&#x2019; reliability degrees. Since the number of the successfully attacked items is discrete, it is hard to directly solve the optimization problem. To address this challenge, a continuous and differentiable sigmoid function is adopted to approximate the discrete component in the objective function. We solve the bi-level optimization problem by iteratively solving the upper-level and lower-level subproblems, which are solved by the projected gradient ascent and expectation-maximization (EM) methods, respectively.</p>    <p>In summary, the main contributions of this paper are:</p>    <ol class="list-no-style">    <li id="list1" label="&bull;">We identify the pitfalls and challenges in attacking a crowdsourcing system empowered with the Dawid-Skene model, which is able to incorporate the workers&#x2019; reliability degrees into the aggregation procedure and thus can tolerate the naive malicious attacks.<br/></li>    <li id="list2" label="&bull;">We design an intelligent data poisoning attack mechanism, based on which the attacker can achieve the optimal attack goal by intelligently disguising the malicious workers&#x2019; behaviors.<br/></li>    <li id="list3" label="&bull;">Extensive experiments based on real-world crowdsourcing datasets are conducted to verify the advantages of the proposed mechanism.<br/></li>    </ol>   </section>   <section id="sec-8">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> Problem Setting</h2>    </div>    </header>    <p>In this paper, we consider a crowdsourcing scenario in which a cloud server and some participating workers are involved. The cloud server is a platform which can outsource the crowdsourcing tasks to the participating workers. The crowdsourcing task is to collect labels for a pool of items, each of which belongs to one of two possible categories (e.g., duchenne smile/non-duchenne smile; same/different; positive/negative; etc.). To ensure the quality of the final result, each item will be queried to multiple participating workers, who are the individuals that carry out the crowdsourcing tasks, and each worker will provide labels for a number of items. After collecting the labels from the participating workers, the cloud server aggregates these labels to derive the true label of each item.</p>    <p>The security threats considered in this paper mainly come from an attacker who aims to attack the crowdsourcing system for malicious purposes. <em>The goal of the attacker is to maximize the error of the derived true labels, and meanwhile disguise his malicious behaviors so that the attack cannot be detected easily</em>. We assume that the attacker can recruit or create multiple participating workers (called <em>malicious workers</em>) and arbitrarily manipulate their labels, but he cannot influence the behaviors of the <em>normal workers</em> who carry out the crowdsourcing tasks without any malicious purpose. If there is no limitation on the ability of the attacker, he can achieve the attack goal easily through creating a large number of malicious workers. However, in practice, the attacker usually has limited resources and can only recruit or create a few malicious workers. In such cases, it is essential for the attacker to design a sophisticated <em>attack strategy</em> (i.e., the labels provided by the malicious workers) such that the attack goal can be maximally achieved. In order to assess the vulnerability of the crowdsourcing system in the worst case, we also assume that the attacker has full knowledge of the aggregation method and the labels from normal workers. This assumption is reasonable as it is possible for the attacker to learn the labels of normal workers through eavesdropping the communications between the cloud server and the normal workers. Figure&#x00A0;<a class="fig" href="#fig1">1</a> shows the crowdsourcing framework with malicious workers. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186032/images/www2018-41-fig1.jpg" class="img-responsive" alt="Figure 1"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Crowdsourcing framework with malicious workers.</span>     </div>    </figure>    </p>    <p>    <strong>Problem formulation</strong>. Suppose the cloud server releases a crowdsourcing task which contains a set of items <em>O</em> = {<em>o</em>    <sub>1</sub>, <em>o</em>    <sub>2</sub>, ..., <em>o<sub>M</sub>    </em>}, and these items are queried to <em>K</em> normal workers which are represented as <em>U</em> = {<em>u</em>    <sub>1</sub>, <em>u</em>    <sub>2</sub>, ..., <em>u<sub>K</sub>    </em>}. The labels provided by these normal workers are denoted as <span class="inline-equation"><span class="tex">$X=\lbrace x_m^k\rbrace _{m,k=1}^{M,K}$</span>    </span>, in which <span class="inline-equation"><span class="tex">$x_m^k$</span>    </span> is the label provided by worker <em>u<sub>k</sub>    </em> for item <em>o<sub>m</sub>    </em>. For each item <em>o<sub>m</sub>    </em>, there is a true label <span class="inline-equation"><span class="tex">$x_m^*$</span>    </span> which is unknown <em>a priori</em> and needs to be estimated by the cloud server based on the labels collected from all the workers. We use <span class="inline-equation"><span class="tex">$X^*=\lbrace x_m^*\rbrace _{m=1}^M$</span>    </span> to denote the set of true labels for all items. Assume that the attacker can create <em>K</em>&#x2032; malicious workers represented as <span class="inline-equation"><span class="tex">$\widetilde{U}=\lbrace \widetilde{u}_1,\widetilde{u}_2,...,\widetilde{u}_{K^{\prime }}\rbrace$</span>    </span>. The set of labels provided by all the malicious workers is denoted as <span class="inline-equation"><span class="tex">$\widetilde{X}=\lbrace \widetilde{x}_m^{k^{\prime }}\rbrace _{m,k^{\prime }=1}^{M,K^{\prime }}$</span>    </span>, and <span class="inline-equation"><span class="tex">$\widetilde{x}_m^{k^{\prime }}$</span>    </span> is the label provided by malicious worker <span class="inline-equation"><span class="tex">$\widetilde{u}_{k^{\prime }}$</span>    </span> for item <em>o<sub>m</sub>    </em>. <em>Our goal in this paper is to find an optimal attack strategy (i.e., an optimal </em>    <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>    </span>    <em>) from the perspective of the attacker such that the attack goal can be maximally achieved</em>.</p>   </section>   <section id="sec-9">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> Preliminary</h2>    </div>    </header>    <p>As a low-cost problem-solving paradigm utilizing the wisdom of crowds, crowdsourcing has been widely adopted to collect labels for various tasks. The items are distributed to multiple participating workers, and then the labels are collected from them to estimate the true label of each item in the task. Due to the variety in the quality of the participating workers, it is a common practice to query each item to several workers and then aggregate their labels in order to get a more reliable result. A straightforward aggregation method is majority voting. However, this method cannot distinguish the reliability degrees of the workers. In order to take the workers&#x2019; quality into account and obtain more accurate results, the Dawid-Skene model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>] has been widely adopted in crowdsourcing systems.</p>    <p>In the Dawid-Skene model, each participating worker is associated with an unknown confusion matrix which reflects the worker&#x0027;s ability (or reliability degree) when carrying out the crowdsourcing task. Each diagonal element in this matrix represents the probability that the worker provides the true label for a particular item, while each off-diagonal element represents the probability that a particular wrong label is provided. After the labels are collected from all the workers, the maximum likelihood estimation method is adopted to jointly estimate each item&#x0027;s true label and each worker&#x0027;s confusion matrix.</p>    <p>In this paper, we consider the binary case, i.e., we assume that each item has only two possible labels: 0 and 1. Based on the Dawid-Skene model, each worker <em>u<sub>k</sub>    </em> provides label for item <em>o<sub>m</sub>    </em> according to parameters <span class="inline-equation"><span class="tex">$\alpha _k=\mathrm{Pr}(x_m^k=1|x_m^*=1)$</span>    </span> and <span class="inline-equation"><span class="tex">$\beta _k=\mathrm{Pr}(x_m^k=0|x_m^*=0)$</span>    </span>, where <em>&#x03B1;<sub>k</sub>    </em> and <em>&#x03B2;<sub>k</sub>    </em> are the diagonal elements in worker <em>u<sub>k</sub>    </em>&#x2019;s confusion matrix. They are also treated as <em>u<sub>k</sub>    </em>&#x2019;s ability parameters or reliability degrees. The larger <em>&#x03B1;<sub>k</sub>    </em> and <em>&#x03B2;<sub>k</sub>    </em> are, the higher the probability that worker <em>u<sub>k</sub>    </em> provides a true label. Additionally, this model assumes that the probability that an item drawn at random has true label 1 is <em>p</em>, which is usually unknown <em>a priori</em>. Denote <span class="inline-equation"><span class="tex">$\Theta =\lbrace p,\lbrace \alpha _k,\beta _k\rbrace _{k=1}^{K}\rbrace$</span>    </span> as the set of all the model parameters. The Dawid-Skene model adopts the maximum likelihood estimation method to estimate <em>&#x0398;</em>. However, due to the latent variables <em>X</em>    <sup>*</sup> are unknown <em>a priori</em>, it is hard to directly conduct the estimation.</p>    <p>To address the above challenge, the Dawid-Skene model adopts the EM algorithm&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>] which contains an expectation step (E-step) and a maximization step (M-step). In the E-step, the items&#x2019; true labels are derived based on the estimated model parameters <em>&#x0398;</em>, and in the M-step, the parameters <em>&#x0398;</em> are calculated based on the derived true labels. The details of the two steps are described as follows.</p>    <p>    <strong>E-step</strong>: In this step, the model parameters <em>&#x0398;</em> are fixed. For each item <em>o<sub>m</sub>    </em>, we calculate <span class="inline-equation"><span class="tex">$\omega _m=\mathrm{Pr}\lbrace x_m^*=1|X\rbrace$</span>    </span> based on the Bayes theorem: <div class="table-responsive" id="eq1">     <div class="display-equation">      <span class="tex mytex">\begin{align} \begin{split} \omega _m&#x0026;=\mathrm{Pr}\lbrace x_m^*=1|X; \Theta \rbrace =\frac{\mathrm{Pr}\lbrace X|x_m^*=1\rbrace \cdot p}{\mathrm{Pr}\lbrace X|x_m^*=1\rbrace \cdot p+\mathrm{Pr}\lbrace X|x_m^*=0\rbrace \cdot (1-p)}\\ &#x0026;=\frac{\prod _{k\in U_m}\alpha _k^{x_m^k}(1-\alpha _k)^{1-x_m^k}\cdot p}{\prod _{k\in U_m}\alpha _k^{x_m^k}(1-\alpha _k)^{1-x_m^k}\cdot p+\prod _{k\in U_m}\beta _k^{1-x_m^k}(1-\beta _k)^{x_m^k}\cdot (1-p)}, \end{split} \end{align} </span>      <br/>      <span class="equation-number">(1)</span>     </div>    </div> where <em>U<sub>m</sub>    </em> represents the set of normal workers who provide labels for item <em>o<sub>m</sub>    </em>.</p>    <p>Here <em>&#x03C9;<sub>m</sub>    </em> is the posterior probability that the true label of the item <em>o<sub>m</sub>    </em> is 1. With the calculated <span class="inline-equation"><span class="tex">$\Omega =\lbrace \omega _m\rbrace _{m=1}^M$</span>    </span>, the expected value of the log likelihood function can be expressed as <div class="table-responsive" id="eq2">     <div class="display-equation">      <span class="tex mytex">\begin{align} \begin{split} Q(\Theta)=&#x0026;E[\log L(\Theta ;X,X^*)]=E[\log \prod _{m=1}^{M} L(\Theta ;X_m,x_m^*)]\\ =&#x0026;\sum _{m=1}^{M}\lbrace \omega _m\log [\prod _{k\in U_m}\alpha _k^{x_m^k}(1-\alpha _k)^{1-x_m^k}\cdot p]\\ &#x0026;+(1-\omega _m)\log [\prod _{k\in U_m}\beta _k^{1-x_m^k}(1-\beta _k)^{x_m^k}\cdot (1-p)]\rbrace , \end{split} \end{align} </span>      <br/>      <span class="equation-number">(2)</span>     </div>    </div> where <em>X<sub>m</sub>    </em> represents the set of labels for item <em>o<sub>m</sub>    </em>.</p>    <p>    <strong>M-step</strong>: In this step, the posterior probabilities <span class="inline-equation"><span class="tex">$\lbrace \omega _m\rbrace _{m=1}^M$</span>    </span> are fixed. The model parameters <em>&#x0398;</em> are estimated by maximizing the expected value of the log likelihood function <em>Q</em>(<em>&#x0398;</em>), and they are updated as follows: <div class="table-responsive" id="eq3">     <div class="display-equation">      <span class="tex mytex">\begin{align} p=\frac{\sum _{m=1}^{M}\omega _m}{M}, \end{align} </span>      <br/>      <span class="equation-number">(3)</span>     </div>    </div>    <div class="table-responsive" id="eq4">     <div class="display-equation">      <span class="tex mytex">\begin{align} \alpha _k=\frac{\sum _{m\in O_k}\omega _m\cdot x_m^k}{\sum _{m\in O_k}\omega _m}, \end{align} </span>      <br/>      <span class="equation-number">(4)</span>     </div>    </div>    <div class="table-responsive" id="eq5">     <div class="display-equation">      <span class="tex mytex">\begin{align} \beta _k=\frac{\sum _{m\in O_k}(1-\omega _m)\cdot (1-x_m^k)}{\sum _{m\in O_k}(1-\omega _m)}, \end{align} </span>      <br/>      <span class="equation-number">(5)</span>     </div>    </div> where <em>O<sub>k</sub>    </em> represents the set of items queried to <em>u<sub>k</sub>    </em>.</p>    <p>The above two steps are iteratively conducted until the convergence criterion is satisfied. Finally, if <em>&#x03C9;<sub>m</sub>    </em> is larger than 0.5, the true label of the item <em>o<sub>m</sub>    </em> is assigned as 1, otherwise, it is assigned as 0.</p>   </section>   <section id="sec-10">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> The Intelligent Attack Mechanism</h2>    </div>    </header>    <p>In order to achieve the attack goal as much as possible, it is essential for the attacker to find an optimal attack strategy with the limited resources (i.e., the number of created or recruited malicious workers and the number of queried items). We first investigate the Dawid-Skene crowdsourcing model under the adversarial environment in section&#x00A0;<a class="sec" href="#sec-11">4.1</a>, and then discuss how to design an optimal attack strategy from the perspective of the attacker in section&#x00A0;<a class="sec" href="#sec-12">4.2</a>.</p>    <section id="sec-11">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Dawid-Skene Crowdsourcing Model with Malicious Workers</h3>     </div>    </header>    <p>In the adversarial environment, the malicious workers may blend into the crowdsourcing system and provide manipulated labels to the cloud server in order to distort the final aggregated results. In this section, we decompose the participating workers into normal and malicious ones, and investigate the relationship between the final aggregation results and the labels provided by malicious workers. Please note that the cloud server in the crowdsourcing system cannot differentiate the two types of participating workers when aggregating the collected labels.</p>    <p>As described in the problem setting, we assume that the attacker creates <em>K</em>&#x2032; malicious workers to conduct the data poisoning attacks against the crowdsourcing system. The attacker cannot influence the behaviors of the normal workers, but he can arbitrarily manipulate the labels of malicious workers. We denote the ability parameters of malicious worker <span class="inline-equation"><span class="tex">$\widetilde{u}_{k^{\prime }}$</span>     </span> in the Dawid-Skene model as <span class="inline-equation"><span class="tex">$\widetilde{\alpha }_{k^{\prime }}=\mathrm{Pr}(\widetilde{x}_m^{k^{\prime }}=1|x_m^*=1)$</span>     </span> and <span class="inline-equation"><span class="tex">$\widetilde{\beta }_{k^{\prime }}=\mathrm{Pr}(\widetilde{x}_m^{k^{\prime }}=0|x_m^*=0)$</span>     </span>. We use <span class="inline-equation"><span class="tex">$\widetilde{\Theta }=\lbrace p,\lbrace \alpha _k,\beta _k\rbrace _{k=1}^{K},\lbrace \widetilde{\alpha }_{k^{\prime }},\widetilde{\beta }_{k^{\prime }}\rbrace _{k^{\prime }=1}^{K^{\prime }}\rbrace$</span>     </span> to denote the set of the model parameters and <span class="inline-equation"><span class="tex">$\lbrace \alpha _k,\beta _k\rbrace _{k=1}^{K}$</span>     </span> are the ability parameters of the normal workers. Suppose <span class="inline-equation"><span class="tex">$\widehat{X}$</span>     </span> is the set of the labels provided by all the participating workers, including the normal and malicious ones. The E-step and M-step in the Dawid-Skene model after data poisoning attacks can be described as follows:</p>    <p>     <strong>E-step</strong>: For each item <em>o<sub>m</sub>     </em>, we calculate <span class="inline-equation"><span class="tex">$\widetilde{\omega }_m=\mathrm{Pr}\lbrace x_m^*=1|\widehat{X}\rbrace$</span>     </span> based on the Bayes theorem: <div class="table-responsive" id="eq6">      <div class="display-equation">       <span class="tex mytex">\begin{align} \begin{split} \widetilde{\omega }_m&#x0026;=\mathrm{Pr}\lbrace x_m^*=1|\widehat{X}; \widetilde{\Theta }\rbrace \\ &#x0026;=\frac{\mathrm{Pr}\lbrace \widehat{X}|x_m^*=1\rbrace \cdot p}{\mathrm{Pr}\lbrace \widehat{X}|x_m^*=1\rbrace \cdot p+\mathrm{Pr}\lbrace \widehat{X}|x_m^*=0\rbrace \cdot (1-p)}\\ &#x0026;=\frac{\widetilde{A}_{m1}}{\widetilde{A}_{m1}+\widetilde{A}_{m0}}, \end{split} \end{align} </span>       <br/>       <span class="equation-number">(6)</span>      </div>     </div> where <div class="table-responsive" id="eq7">      <div class="display-equation">       <span class="tex mytex">\begin{align} \widetilde{A}_{m1}=\prod _{k\in U_m}\alpha _k^{x_m^k}(1-\alpha _k)^{1-x_m^k}\cdot \prod _{k^{\prime }\in \widetilde{U}_m}\widetilde{\alpha }_{k^{\prime }}^{\widetilde{x}_m^{k^{\prime }}}(1-\widetilde{\alpha }_{k^{\prime }})^{1-\widetilde{x}_m^{k^{\prime }}}\cdot p \end{align} </span>       <br/>       <span class="equation-number">(7)</span>      </div>     </div>     <div class="table-responsive" id="eq8">      <div class="display-equation">       <span class="tex mytex">\begin{align} \widetilde{A}_{m0}=\prod _{k\in U_m}\beta _k^{1-x_m^k}(1-\beta _k)^{x_m^k}\cdot \prod _{k^{\prime }\in \widetilde{U}_m}\widetilde{\beta }_{k^{\prime }}^{1-\widetilde{x}_m^{k^{\prime }}}(1-\widetilde{\beta }_{k^{\prime }})^{\widetilde{x}_m^{k^{\prime }}}\cdot (1-p). \end{align} </span>       <br/>       <span class="equation-number">(8)</span>      </div>     </div> Here we use <span class="inline-equation"><span class="tex">$\widetilde{U}_m$</span>     </span> to denote the set of malicious workers who provide labels for item <em>o<sub>m</sub>     </em>. <span class="inline-equation"><span class="tex">$\widetilde{\omega }_m$</span>     </span> represents the posterior probability that the true label of item <em>o<sub>m</sub>     </em> is 1 after the data poisoning attacks.</p>    <p>     <strong>M-step</strong>: In this step, we fix the the posterior probabilities <span class="inline-equation"><span class="tex">$\lbrace \widetilde{\omega }_m\rbrace _{m=1}^M$</span>     </span> and update the model parameters <span class="inline-equation"><span class="tex">$\widetilde{\Theta }=\lbrace p,\lbrace \alpha _k,\beta _k\rbrace _{k=1}^{K},\lbrace \widetilde{\alpha }_{k^{\prime }},\widetilde{\beta }_{k^{\prime }}\rbrace _{k^{\prime }=1}^{K^{\prime }}\rbrace$</span>     </span> as follows: <div class="table-responsive" id="eq9">      <div class="display-equation">       <span class="tex mytex">\begin{align} p=\frac{\sum _{m=1}^{M}\widetilde{\omega }_m}{M} \end{align} </span>       <br/>       <span class="equation-number">(9)</span>      </div>     </div>     <div class="table-responsive" id="eq10">      <div class="display-equation">       <span class="tex mytex">\begin{align} \alpha _k=\frac{\sum _{m\in O_k}\widetilde{\omega }_m\cdot x_m^k}{\sum _{m\in O_k}\widetilde{\omega }_m},\quad \beta _k=\frac{\sum _{m\in O_k}(1-\widetilde{\omega }_m)\cdot (1-x_m^k)}{\sum _{m\in O_k}(1-\widetilde{\omega }_m)}, \end{align} </span>       <br/>       <span class="equation-number">(10)</span>      </div>     </div>     <div class="table-responsive" id="eq11">      <div class="display-equation">       <span class="tex mytex">\begin{align} \widetilde{\alpha }_{k^{\prime }}=\frac{\sum _{m\in \widetilde{O}_{k^{\prime }}}\widetilde{\omega }_m\cdot \widetilde{x}_m^{k^{\prime }}}{\sum _{m\in \widetilde{O}_{k^{\prime }}}\widetilde{\omega }_m},\quad \widetilde{\beta }_{k^{\prime }}=\frac{\sum _{m\in \widetilde{O}_{k^{\prime }}}(1-\widetilde{\omega }_m)\cdot (1-\widetilde{x}_m^{k^{\prime }})}{\sum _{m\in \widetilde{O}_{k^{\prime }}}(1-\widetilde{\omega }_m)}, \end{align} </span>       <br/>       <span class="equation-number">(11)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$\widetilde{O}_{k^{\prime }}$</span>     </span> represents the set of items queried to <span class="inline-equation"><span class="tex">$\widetilde{u}_{k^{\prime }}$</span>     </span>.</p>    <p>The above equations show that once the labels of normal workers (i.e., <em>X</em>) are given, the final estimated true labels of the items and the ability parameters (i.e., <span class="inline-equation"><span class="tex">$\lbrace \alpha _k,\beta _k\rbrace _{k=1}^{K},\lbrace \widetilde{\alpha }_{k^{\prime }},\widetilde{\beta }_{k^{\prime }}\rbrace _{k^{\prime }=1}^{K^{\prime }}$</span>     </span>) of the participating workers are only dependent on the malicious workers&#x2019; data. Different values of the malicious workers&#x2019; labels can lead to different estimated results. Based on this fact, the attacker can conduct data poisoning attacks through carefully designing the malicious workers&#x2019; labels such that the goal of the attacker can be optimally achieved.</p>    </section>    <section id="sec-12">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Optimal Attack Strategy</h3>     </div>    </header>    <p>In this paper, the attacker conducts the data poisoning attacks for the purpose of maximizing the error of the final aggregated results, and at the same time tries to disguise his attack behaviors as much as possible. We can understand the goal of the attacker in two aspects. On one hand, the attacker aims to maximize the deviation between the outputs of the Dawid-Skene crowdsourcing model before and after the data poisoning attacks. In other words, the attacker wants to maximize the number of the successfully attacked items, where we say an item is attacked successfully if the estimated true label is changed from one label to the other after taking the malicious workers&#x2019; labels into account. On the other hand, the attacker wants to disguise the malicious workers as normal workers in the crowdsourcing system such that the attack behaviors cannot be detected easily. One way to achieve the disguise is to get high values on the malicious workers&#x2019; ability parameters (or reliability degrees), i.e., <span class="inline-equation"><span class="tex">$\lbrace \widetilde{\alpha }_{k^{\prime }}\rbrace _{k^{\prime }=1}^{K^{\prime }}$</span>     </span> and <span class="inline-equation"><span class="tex">$\lbrace \widetilde{\beta }_{k^{\prime }}\rbrace _{k^{\prime }=1}^{K^{\prime }}$</span>     </span>. Since the workers with large ability parameters will be treated as high-quality workers in the Dawid-Skene model, the crowdsourcing system then cannot distinguish the malicious workers from the normal workers. In this section, we stand on the attacker&#x0027;s position and discuss how to find an optimal attack strategy so that the goal of the attacker can be achieved as much as possible.</p>    <p>Suppose the attacker is able to create or recruit <em>K</em>&#x2032; malicious workers, and for each malicious worker, the queried items are given. When conducting the data poisoning attacks to break the crowdsourcing system, the attacker needs to find the optimal assignments for the malicious workers&#x2019; labels. An intuitive strategy is let the malicious workers provide the label which is not likely to be true for each queried item. This strategy may work well when the aggregation method is majority voting. But for the Dawid-Skene model, it is not the optimal choice, especially when only a few malicious workers are created or recruited. Due to the fact that malicious workers always disagree with the majority, the Dawid-Skene model will assign low ability values to these malicious workers, and consequently, their impact will also be decreased. In such way, the malicious workers can be detected easily and the attack may fail on all the items. Thus the ability parameters of malicious workers (i.e., <span class="inline-equation"><span class="tex">$\lbrace \widetilde{\alpha }_{k^{\prime }}\rbrace _{k^{\prime }=1}^{K^{\prime }}$</span>     </span> and <span class="inline-equation"><span class="tex">$\lbrace \widetilde{\beta }_{k^{\prime }}\rbrace _{k^{\prime }=1}^{K^{\prime }}$</span>     </span>) should be taken into account when finding the optimal attack strategy.</p>    <p>In order to address the above challenge, we formulate the goal of the attacker as the following optimization problem:</p>    <p>     <div class="table-responsive" id="eq12">      <div class="display-equation">       <span class="tex mytex">\begin{align} \max \limits _{\widetilde{X}}\quad &#x0026;\sum _{m=1}^{M}{&#x1D7D9;}(x_{m}^{*a}\ne x_{m}^{*b})+\lambda \sum _{k^{\prime }=1}^{K^{\prime }}(\widetilde{\alpha }_{k^{\prime }}+\widetilde{\beta }_{k^{\prime }})\\&#x0026;\text{s.t.}\quad \lbrace X^{*a},\widetilde{\Theta }\rbrace =\mathop{\arg\,\max}\limits _{X^{*a},\widetilde{\Theta }}\ \log L(\widetilde{\Theta };\widehat{X},X^{*a})\nonumber \\ &#x0026;\quad \quad \ \lbrace \widetilde{x}_m^{k^{\prime }}\rbrace _{m,k^{\prime }=1}^{M,K^{\prime }}\in \lbrace 0,1\rbrace \nonumber\end{align} </span>       <br/>       <span class="equation-number">(12)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$X^{*a}=\lbrace x_{m}^{*a}\rbrace _{m=1}^M$</span>     </span> denotes the set of the estimated true labels after the data poisoning attacks and <span class="inline-equation"><span class="tex">$x_{m}^{*b}$</span>     </span> denotes the estimated true label for item <em>o<sub>m</sub>     </em> before the attacks (i.e., calculated based on the labels of normal workers). Once the normal workers&#x2019; labels are given, <span class="inline-equation"><span class="tex">$x_{m}^{*b}$</span>     </span> is a constant. The objective function contains two components. The first component, i.e., <span class="inline-equation"><span class="tex">$\sum _{m=1}^{M}{&#x1D7D9;}(x_{m}^{*a}\ne x_{m}^{*b})$</span>     </span>, where 1(&#x00B7;) is the indicator function, represents the number of the successfully attacked items. In the second component, <span class="inline-equation"><span class="tex">$\sum _{k^{\prime }=1}^{K^{\prime }}(\widetilde{\alpha }_{k^{\prime }}+\widetilde{\beta }_{k^{\prime }})$</span>     </span> is the summation of the malicious workers&#x2019; ability parameters, and <em>&#x03BB;</em> is a parameter used to trade off the two components. The summation of the two components can also be treated as the utility of the attacker. The intuition of the objective function is to maximize the number of the successfully attacked items and the malicious workers&#x2019; ability values simultaneously, where the first component is the goal of the attack and the latter ensures that the malicious workers cannot be detected easily. In this optimization problem, the Dawid-Skene model becomes a constraint. This is a bi-level optimization problem&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>]. The optimization over the labels of the malicious workers (i.e., <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span>) is the upper-level problem, and the optimization over <span class="inline-equation"><span class="tex">$\lbrace X^{*a},\widetilde{\Theta }\rbrace$</span>     </span> is the lower-level problem.</p>    <p>In the Dawid-Skene model, the final estimated true labels of the items are dependent on the posterior probabilities <span class="inline-equation"><span class="tex">$\Omega =\lbrace \omega _m\rbrace _{m=1}^M$</span>     </span> or <span class="inline-equation"><span class="tex">$\widetilde{\Omega }=\lbrace \widetilde{\omega }_m\rbrace _{m=1}^M$</span>     </span>: if <em>&#x03C9;<sub>m</sub>     </em> (or <span class="inline-equation"><span class="tex">$\widetilde{\omega }_m$</span>     </span>) is larger than 0.5, <span class="inline-equation"><span class="tex">$x_{m}^{*b}$</span>     </span> (or <span class="inline-equation"><span class="tex">$x_{m}^{*a}$</span>     </span>) is assigned as 1, otherwise, it is assigned as 0. Thus we can reformulate optimization problem&#x00A0;(<a class="eqn" href="#eq12">12</a>) as follows: <div class="table-responsive" id="eq13">      <div class="display-equation">       <span class="tex mytex">\begin{align} \max \limits _{\widetilde{X}}\quad &#x0026;\sum _{m=1}^{M} \frac{1}{2}\lbrace 1-\mathop {\rm sgn}[(\omega _m-0.5)\cdot (\widetilde{\omega }_m-0.5)]\rbrace +\lambda \sum _{k^{\prime }=1}^{K^{\prime }}(\widetilde{\alpha }_{k^{\prime }}+\widetilde{\beta }_{k^{\prime }})\nonumber \\ &#x0026;\text{s.t.}\quad \lbrace \widetilde{\Omega },\widetilde{\Theta }\rbrace =\mathop{\arg\,\max}\limits _{\widetilde{\Omega },\widetilde{\Theta }}\ \log L(\widetilde{\Theta };\widehat{X},\widetilde{\Omega })\\&#x0026;\quad \quad \ \lbrace \widetilde{x}_m^{k^{\prime }}\rbrace _{m,k^{\prime }=1}^{M,K^{\prime }}\in \lbrace 0,1\rbrace ,\nonumber\end{align} </span>       <br/>       <span class="equation-number">(13)</span>      </div>     </div> where <div class="table-responsive" id="eq14">      <div class="display-equation">       <span class="tex mytex">\begin{align} \mathop {\rm sgn}[(\omega _m-0.5)\cdot (\widetilde{\omega }_m-0.5)] =\left\lbrace \begin{aligned} &#x0026;\ \ \ 1 \quad \quad if\; (\omega _m-0.5)\cdot (\widetilde{\omega }_m-0.5){\gt}0\\ &#x0026;\ \ \ 0 \quad \quad if\; (\omega _m-0.5)\cdot (\widetilde{\omega }_m-0.5)=0\\ &#x0026;-1 \quad \ \ if\; (\omega _m-0.5)\cdot (\widetilde{\omega }_m-0.5){\lt}0. \end{aligned} \right. \end{align} </span>       <br/>       <span class="equation-number">(14)</span>      </div>     </div> Once the labels of normal workers are given, the posterior probability <em>&#x03C9;<sub>m</sub>     </em> for item <em>o<sub>m</sub>     </em> is a constant. <span class="inline-equation"><span class="tex">$\widetilde{\omega }_m$</span>     </span>, <span class="inline-equation"><span class="tex">$\widetilde{\alpha }_{k^{\prime }}$</span>     </span> and <span class="inline-equation"><span class="tex">$\widetilde{\beta }_{k^{\prime }}$</span>     </span> are dependent on the labels of the malicious workers (i.e., the attack strategy <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span>) and they can be different when the malicious workers vary their labels. In this way, <span class="inline-equation"><span class="tex">$\widetilde{\omega }_m$</span>     </span>, <span class="inline-equation"><span class="tex">$\widetilde{\alpha }_{k^{\prime }}$</span>     </span> and <span class="inline-equation"><span class="tex">$\widetilde{\beta }_{k^{\prime }}$</span>     </span> can be expressed as the functions of <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span> according to Eqn.&#x00A0;(<a class="eqn" href="#eq6">6</a>) and Eqn.&#x00A0;(<a class="eqn" href="#eq11">11</a>). Then problem&#x00A0;(<a class="eqn" href="#eq13">13</a>) becomes: <div class="table-responsive" id="eq15">      <div class="display-equation">       <span class="tex mytex">\begin{align} \max \limits _{\widetilde{X}}\quad &#x0026;\sum _{m=1}^{M} \frac{1}{2}\lbrace 1-\mathop {\rm sgn}[(\omega _m-0.5)\cdot (\frac{\widetilde{A}_{m1}}{\widetilde{A}_{m1}+\widetilde{A}_{m0}}-0.5)]\rbrace \nonumber \\ &#x0026;+\lambda \sum _{k^{\prime }=1}^{K^{\prime }}(\frac{\sum _{m\in \widetilde{O}_{k^{\prime }}}\widetilde{\omega }_m\cdot \widetilde{x}_m^{k^{\prime }}}{\sum _{m\in \widetilde{O}_{k^{\prime }}}\widetilde{\omega }_m}+\frac{\sum _{m\in \widetilde{O}_{k^{\prime }}}(1-\widetilde{\omega }_m)\cdot (1-\widetilde{x}_m^{k^{\prime }})}{\sum _{m\in \widetilde{O}_{k^{\prime }}}(1-\widetilde{\omega }_m)})\nonumber \\ &#x0026;\text{s.t.}\quad \lbrace \widetilde{\Omega },\widetilde{\Theta }\rbrace =\mathop{\arg\,\max}\limits _{\widetilde{\Omega },\widetilde{\Theta }}\ \log L(\widetilde{\Theta };\widehat{X},\widetilde{\Omega })\\&#x0026;\quad \quad \ \lbrace \widetilde{x}_m^{k^{\prime }}\rbrace _{m,k^{\prime }=1}^{M,K^{\prime }}\in \lbrace 0,1\rbrace .\nonumber\end{align} </span>       <br/>       <span class="equation-number">(15)</span>      </div>     </div>    </p>    <p>Since the objective function in problem&#x00A0;(<a class="eqn" href="#eq15">15</a>) is not continuous, it is hard to directly solve this optimization problem. In order to address this challenge, we approximate the objective function in problem&#x00A0;(<a class="eqn" href="#eq15">15</a>) by the following one: <div class="table-responsive" id="eq16">      <div class="display-equation">       <span class="tex mytex">\begin{align} \max \limits _{\widetilde{X}}\quad &#x0026;\sum _{m=1}^{M}\lbrace 1-\frac{1}{1+\exp [-\theta (\omega _m-0.5)\cdot (\frac{\widetilde{A}_{m1}}{\widetilde{A}_{m1}+\widetilde{A}_{m0}}-0.5)]}\rbrace \nonumber \\ &#x0026;+\lambda \sum _{k^{\prime }=1}^{K^{\prime }}(\frac{\sum _{m\in \widetilde{O}_{k^{\prime }}}\widetilde{\omega }_m\cdot \widetilde{x}_m^{k^{\prime }}}{\sum _{m\in \widetilde{O}_{k^{\prime }}}\widetilde{\omega }_m}+\frac{\sum _{m\in \widetilde{O}_{k^{\prime }}}(1-\widetilde{\omega }_m)\cdot (1-\widetilde{x}_m^{k^{\prime }})}{\sum _{m\in \widetilde{O}_{k^{\prime }}}(1-\widetilde{\omega }_m)}). \end{align} </span>       <br/>       <span class="equation-number">(16)</span>      </div>     </div> The basic idea behind the approximation is that function <span class="inline-equation"><span class="tex">$h_1(x)=\frac{1}{2}(1-\mathop {\rm sgn}x)$</span>     </span> can be approximated by function <span class="inline-equation"><span class="tex">$h_2(x)=1-\frac{1}{1+\exp (-\theta x)}$</span>     </span> when <em>x</em> &#x2208; (&#x2212; 1, 1). The parameter <em>&#x03B8;</em> in <em>h</em>     <sub>2</sub>(<em>x</em>) represents the steepness of the curve. The curves of the two functions when <em>&#x03B8;</em> = 100 are shown in Figure&#x00A0;<a class="fig" href="#fig2">2</a>. We can see <em>h</em>     <sub>2</sub>(<em>x</em>) is a good approximation of <em>h</em>     <sub>1</sub>(<em>x</em>). Additionally, the continuous property of <em>h</em>     <sub>2</sub>(<em>x</em>) allows us to solve the optimization problem based on the objective function&#x00A0;(<a class="eqn" href="#eq16">16</a>). <figure id="fig2">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186032/images/www2018-41-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Curves of <em>h</em>       <sub>1</sub>(<em>x</em>) and <em>h</em>       <sub>2</sub>(<em>x</em>).</span>      </div>     </figure>    </p>    <p>Another challenge when solving the above optimization problem is that each element in <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span> has a categorical value (0 or 1). This introduces difficulties when solving the upper-level problem. In this paper, we relax the values of the elements in <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span> to the range [0, 1] such that the optimization problem can be solved according to the gradient-based methods. In other words, we treat <span class="inline-equation"><span class="tex">$\widetilde{x}_m^{k^{\prime }}$</span>     </span> as the probability that malicious worker <span class="inline-equation"><span class="tex">$\widetilde{u}_{k^{\prime }}$</span>     </span> provides label 1 for item <em>o<sub>m</sub>     </em>. Finally, the value of <span class="inline-equation"><span class="tex">$\widetilde{x}_m^{k^{\prime }}$</span>     </span> will be transformed to categorical data: if the probability is larger than 0.5, <span class="inline-equation"><span class="tex">$\widetilde{x}_m^{k^{\prime }}$</span>     </span> is assigned as 1, otherwise, it is assigned as 0. Then the attacker needs to solve the following optimization problem in order to get the optimal attack strategy: <div class="table-responsive" id="eq17">      <div class="display-equation">       <span class="tex mytex">\begin{align} \max \limits _{\widetilde{X}}\quad &#x0026;f(\widetilde{X})=\sum _{m=1}^{M}\lbrace 1-\frac{1}{1+\exp [-\theta (\omega _m-0.5)\cdot (\frac{\widetilde{A}_{m1}}{\widetilde{A}_{m1}+\widetilde{A}_{m0}}-0.5)]}\rbrace \nonumber \\ &#x0026;+\lambda \sum _{k^{\prime }=1}^{K^{\prime }}(\frac{\sum _{m\in \widetilde{O}_{k^{\prime }}}\widetilde{\omega }_m\cdot \widetilde{x}_m^{k^{\prime }}}{\sum _{m\in \widetilde{O}_{k^{\prime }}}\widetilde{\omega }_m}+\frac{\sum _{m\in \widetilde{O}_{k^{\prime }}}(1-\widetilde{\omega }_m)\cdot (1-\widetilde{x}_m^{k^{\prime }})}{\sum _{m\in \widetilde{O}_{k^{\prime }}}(1-\widetilde{\omega }_m)})\nonumber \\ &#x0026;\text{s.t.}\quad \lbrace \widetilde{\Omega },\widetilde{\Theta }\rbrace =\mathop{\arg\,\max}\limits _{\widetilde{\Omega },\widetilde{\Theta }}\ \log L(\widetilde{\Theta };\widehat{X},\widetilde{\Omega })\\&#x0026;\quad \quad \ \lbrace \widetilde{x}_m^{k^{\prime }}\rbrace _{m,k^{\prime }=1}^{M,K^{\prime }}\in [0,1]. \nonumber\end{align} </span>       <br/>       <span class="equation-number">(17)</span>      </div>     </div>    </p>    <p>Next, we discuss how to solve the above optimization problem. The solution we adopted here is a two-step iterative procedure.</p>    <p>     <strong>Step 1</strong>: In this step, we first fix the labels of malicious workers, i.e., <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span>, which are estimated in the previous iteration. If it is the first iteration, the elements in <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span> can be initialized randomly or be set as some particular values. Then we solve the lower-level problem through conducting the E-step and M-step described in section&#x00A0;<a class="sec" href="#sec-11">4.1</a> to get the optimal parameters <span class="inline-equation"><span class="tex">$\lbrace \widetilde{\Omega },\widetilde{\Theta }\rbrace$</span>     </span>. Please note that all the elements in <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span> need to be transformed to the categorical values (i.e., 1 or 0) before solving the lower-level problem.</p>    <p>     <strong>Step 2</strong>: In this step, we fix the parameters <span class="inline-equation"><span class="tex">$\lbrace \widetilde{\Omega },\widetilde{\Theta }\rbrace$</span>     </span> calculated in Step 1, and then adopt the projected gradient ascent method to solve the upper-level problem. More specifically, in iteration <em>t</em>, we update <span class="inline-equation"><span class="tex">$\widetilde{x}_m^{k^{\prime }}$</span>     </span> as follows: <div class="table-responsive" id="eq18">      <div class="display-equation">       <span class="tex mytex">\begin{align} \widetilde{x}_m^{k^{\prime }(t+1)}\leftarrow \mathrm{Proj_{[0,1]}}(\widetilde{x}_m^{k^{\prime }(t)}+s_t\cdot \triangledown _{\widetilde{x}_{m}^{k^{\prime }}}f(\widetilde{X})) \end{align} </span>       <br/>       <span class="equation-number">(18)</span>      </div>     </div> where <em>s<sub>t</sub>     </em> is the step size in iteration <em>t</em> and Proj<sub>[0, 1]</sub>(&#x00B7;) is the projection operator onto the range [0, 1]. The gradient <span class="inline-equation"><span class="tex">$\triangledown _{\widetilde{x}_{m}^{k^{\prime }}}f(\widetilde{X})$</span>     </span> is calculated as follows: <div class="table-responsive" id="eq19">      <div class="display-equation">       <span class="tex mytex">\begin{align} \triangledown _{\widetilde{x}_m^{k^{\prime }}}f(\widetilde{X})=&#x0026;-\frac{\exp (\theta d_1 d_2)}{[1+\exp (\theta d_1 d_2)]^2}\cdot \theta d_1\cdot \frac{\partial d_2}{\partial \widetilde{x}_m^{k^{\prime }}}\\&#x0026;+\lambda (\frac{\widetilde{\omega }_m}{\sum _{\bar{m}\in \widetilde{O}_{k^{\prime }}}\widetilde{\omega }_{\bar{m}}}+\frac{\widetilde{\omega }_m-1}{\sum _{\bar{m}\in \widetilde{O}_{k^{\prime }}}(1-\widetilde{\omega }_{\bar{m}})})\nonumber\end{align} </span>       <br/>       <span class="equation-number">(19)</span>      </div>     </div>    </p>    <p>where <em>d</em>     <sub>1</sub> = <em>&#x03C9;<sub>m</sub>     </em> &#x2212; 0.5, <span class="inline-equation"><span class="tex">$d_2=\frac{\widetilde{A}_{m1}}{\widetilde{A}_{m1}+\widetilde{A}_{m0}}-0.5$</span>     </span>. Through combining with Eqn.&#x00A0;(<a class="eqn" href="#eq7">7</a>) and Eqn.&#x00A0;(<a class="eqn" href="#eq8">8</a>), we can calculate <span class="inline-equation"><span class="tex">$\frac{\partial d_2}{\partial \widetilde{x}_m^{k^{\prime }}}$</span>     </span> as <div class="table-responsive" id="eq20">      <div class="display-equation">       <span class="tex mytex">\begin{align} \frac{\partial d_2}{\partial \widetilde{x}_m^{k^{\prime }}}=\frac{\frac{\partial \widetilde{A}_{m1}}{\partial \widetilde{x}_m^{k^{\prime }}}\cdot \widetilde{A}_{m0}-\frac{\partial \widetilde{A}_{m0}}{\partial \widetilde{x}_m^{k^{\prime }}}\cdot \widetilde{A}_{m1}}{(\widetilde{A}_{m1}+\widetilde{A}_{m0})^2} \end{align} </span>       <br/>       <span class="equation-number">(20)</span>      </div>     </div> where <div class="table-responsive" id="eq21">      <div class="display-equation">       <span class="tex mytex">\begin{align} \frac{\partial \widetilde{A}_{m1}}{\partial \widetilde{x}_m^{k^{\prime }}}=p\prod _{k\in U_m}\alpha _k^{x_m^k}(1-\alpha _k)^{1-x_m^k}\prod _{\bar{k}^{\prime }\in \widetilde{U}_m\setminus \lbrace k^{\prime }\rbrace }\widetilde{\alpha }_{\bar{k}^{\prime }}^{\widetilde{x}_m^{\bar{k}^{\prime }}}(1-\widetilde{\alpha }_{\bar{k}^{\prime }})^{1-\widetilde{x}_m^{\bar{k}^{\prime }}}\cdot \nonumber \\ {} [\widetilde{\alpha }_{k^{\prime }}^{\widetilde{x}_m^{k^{\prime }}}(1-\widetilde{\alpha }_{k^{\prime }})^{1-\widetilde{x}_m^{k^{\prime }}}\log (\widetilde{\alpha }_{k^{\prime }})-\widetilde{\alpha }_{k^{\prime }}^{\widetilde{x}_m^{k^{\prime }}}(1-\widetilde{\alpha }_{k^{\prime }})^{1-\widetilde{x}_m^{k^{\prime }}}\log (1-\widetilde{\alpha }_{k^{\prime }})], \end{align} </span>       <br/>       <span class="equation-number">(21)</span>      </div>     </div>     <div class="table-responsive" id="eq22">      <div class="display-equation">       <span class="tex mytex">\begin{align} \frac{\partial \widetilde{A}_{m0}}{\partial \widetilde{x}_m^{k^{\prime }}}=(1-p)\prod _{k\in U_m}\beta _k^{1-x_m^k}(1-\beta _k)^{x_m^k}\prod _{\bar{k}^{\prime }\in \widetilde{U}_m\setminus \lbrace k^{\prime }\rbrace }\widetilde{\beta }_{\bar{k}^{\prime }}^{1-\widetilde{x}_m^{\bar{k}^{\prime }}}(1-\widetilde{\beta }_{\bar{k}^{\prime }})^{\widetilde{x}_m^{\bar{k}^{\prime }}}\cdot \nonumber \\ {} [-\widetilde{\beta }_{k^{\prime }}^{1-\widetilde{x}_m^{k^{\prime }}}(1-\widetilde{\beta }_{k^{\prime }})^{\widetilde{x}_m^{k^{\prime }}}\log (\widetilde{\beta }_{k^{\prime }})+\widetilde{\beta }_{k^{\prime }}^{1-\widetilde{x}_m^{k^{\prime }}}(1-\widetilde{\beta }_{k^{\prime }})^{\widetilde{x}_m^{k^{\prime }}}\log (1-\widetilde{\beta }_{k^{\prime }})]. \end{align} </span>       <br/>       <span class="equation-number">(22)</span>      </div>     </div>    </p>    <p>The above two steps will be iteratively conducted until the convergence criterion is satisfied. In this paper, we define the convergence criterion as <span class="inline-equation"><span class="tex">$\sqrt {\sum _{k^{\prime }=1}^{K^{\prime }}\sum _{m=1}^{M}(\widetilde{x}_m^{k^{\prime }(t+1)}-\widetilde{x}_m^{k^{\prime }(t)})^2}\ {\lt}\ \delta$</span>     </span>, which represents the change of <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span> in two consecutive iterations being less than a threshold <em>&#x03B4;</em>. After the attacker get the final <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span>, the elements in <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span> will be transformed to 0 or 1 and then provided to the cloud server as the labels of the malicious workers. The submitted labels <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>     </span> will be treated as the optimal attack strategy of the attacker. The optimization procedure is summarized as Algorithm&#x00A0;1 .</p>    <p>     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186032/images/www2018-41-img1.svg" class="img-responsive" alt="" longdesc=""/></p>    </section>   </section>   <section id="sec-13">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Attack with Limited Knowledge</h2>    </div>    </header>    <p>In order to assess the vulnerability of the crowdsourcing system in the worst case, we consider the full knowledge scenario in the above mechanism and assume that the attacker has complete knowledge of the labels from the normal workers (i.e., normal labels) for all items. In fact, the proposed mechanism can also be employed to implement an effective attack even when the attacker only has limited knowledge of the items&#x2019; normal labels.</p>    <p>Suppose the attacker only knows the normal labels for <em>M</em>&#x2032; (<em>M</em>&#x2032; < <em>M</em>) items represented as <span class="inline-equation"><span class="tex">$O^{\prime }=\lbrace o^{\prime }_1, o^{\prime }_2, ...,o^{\prime }_{M^{\prime }}\rbrace$</span>    </span>. We denote the set of the normal labels for the <em>M</em>&#x2032; items as <span class="inline-equation"><span class="tex">$X^{\prime }=\lbrace {x^{\prime }}_{m}^k\rbrace _{m,k=1}^{M^{\prime },K}$</span>    </span>, which is a subset of <em>X</em>. Since the attacker has no knowledge of the items except those in <em>O</em>&#x2032;, a good choice for him in such a scenario is to let the malicious workers only provide manipulated labels for the items in <em>O</em>&#x2032; and try to maximize the error of the final results for the <em>M</em>&#x2032; items. In order to achieve the goal, the attacker could treat <em>X</em>&#x2032; as the surrogate data of <em>X</em> and employ the above proposed mechanism to derive the attack strategy. In other words, the attack strategy in such a scenario can be derived by solving the following optimization problem:</p>    <p>     <div class="table-responsive" id="eq23">     <div class="display-equation">      <span class="tex mytex">\begin{align} \max \limits _{\widetilde{X^{\prime }}}\quad &#x0026;\sum _{m=1}^{M^{\prime }}{&#x1D7D9;}({x^{\prime }}_{m}^{*a}\ne {x^{\prime }}_{m}^{*b})+\lambda \sum _{k^{\prime }=1}^{K^{\prime }}(\widetilde{\alpha }_{k^{\prime }}+\widetilde{\beta }_{k^{\prime }})\\&#x0026;\text{s.t.}\quad \lbrace {X^{\prime }}^{*a},\widetilde{\Theta }\rbrace =\mathop{\arg\,\max}\limits _{{X^{\prime }}^{*a},\widetilde{\Theta }}\ \log L(\widetilde{\Theta };\widehat{X}^{\prime },{X^{\prime }}^{*a})\nonumber \\ &#x0026;\quad \quad \ \lbrace \widetilde{x^{\prime }}_m^{k^{\prime }}\rbrace _{m,k^{\prime }=1}^{M^{\prime },K^{\prime }}\in \lbrace 0,1\rbrace ,\nonumber\end{align} </span>      <br/>      <span class="equation-number">(23)</span>     </div>    </div>    </p>    <p>where <span class="inline-equation"><span class="tex">$\widetilde{X^{\prime }}=\lbrace \widetilde{x^{\prime }}_m^{k^{\prime }}\rbrace _{m,k^{\prime }=1}^{M^{\prime },K^{\prime }}$</span>    </span> is the attack strategy, i.e., the labels provided by the malicious workers for the items in <em>O</em>&#x2032;. <span class="inline-equation"><span class="tex">${X^{\prime }}^{*a}=\lbrace {x^{\prime }}_{m}^{*a}\rbrace _{m=1}^{M^{\prime }}$</span>    </span> and <span class="inline-equation"><span class="tex">${X^{\prime }}^{*b}=\lbrace {x^{\prime }}_{m}^{*b}\rbrace _{m=1}^{M^{\prime }}$</span>    </span> represent the estimated true labels for the <em>M</em>&#x2032; items based on <span class="inline-equation"><span class="tex">$\widehat{X}^{\prime }=X^{\prime }\cup \widetilde{X^{\prime }}$</span>    </span> and <em>X</em>&#x2032; respectively. Although the attack strategy <span class="inline-equation"><span class="tex">$\widetilde{X^{\prime }}$</span>    </span> derived based on Eqn.&#x00A0;(<a class="eqn" href="#eq23">23</a>) may not be as good as <span class="inline-equation"><span class="tex">$\widetilde{X}$</span>    </span> based on the full knowledge <em>X</em>, it is the optimal choice for the attacker in the limited knowledge scenario. The performance of the proposed mechanism with limited knowledge is evaluated in Section&#x00A0;<a class="sec" href="#sec-22">6.5</a>.</p>   </section>   <section id="sec-14">    <header>    <div class="title-info">     <h2>      <span class="section-number">6</span> Experiments</h2>    </div>    </header>    <p>We conduct experiments based on real-world crowdsourcing datasets to verify the performance of the proposed intelligent attack mechanism.</p>    <section id="sec-15">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.1</span> Experiment Setup</h3>     </div>    </header>    <p>In this section, we introduce the adopted real-world crowdsourcing datasets, the baseline methods which are compared with the proposed mechanism, and the performance measure.</p>    <section id="sec-16">     <p><em>6.1.1 Datasets.</em> To verify the advantages of the proposed intelligent attack mechanism, we adopt the following real-world crowdsourcing datasets.</p>     <p>      <strong>Duchenne Smile Dataset</strong>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0053">53</a>]. In this dataset, the task is to judge whether the simile in a face image (an item) is Duchenne (enjoyment smile) or Non-Duchenne. The authors in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0053">53</a>] create tasks on the Amazon Mechanical Turk platform, and collect the labels from the participating workers. The number of the items in this dataset is 2,134. Totally, there are 64 normal workers and they provide 17,729 labels.</p>     <p>      <strong>Product Dataset</strong>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0051">51</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0058">58</a>]. Each item in this dataset contains two products (with descriptions), the task is to judge whether the two products are the same or not. The participating workers need to identify whether the two descriptions describe the same product or not, and then provide their labels. In this dataset, there are 8,315 items which are observed by 176 normal workers. Totally, these participating workers provide 24,945 labels.</p>     <p>      <strong>Sentiment Dataset</strong>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0058">58</a>]. Each item in the dataset is a tweet related to a company. The participating workers need to identify whether the tweet has positive sentiment or not to the company. The authors in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0058">58</a>] create 1,000 items and collect labels from 85 normal workers through the AMT platform. Totally, there are 20,000 labels in this dataset.</p>    </section>    <section id="sec-17">     <p><em>6.1.2 Baseline Methods.</em> We compare the proposed attack mechanism with two baseline methods: <em>Baseline_rand</em> and <em>Baseline_inversion</em>.</p>     <p>In the <em>Baseline_rand</em> method, the attacker does not consider any strategy, and he just randomly sets the labels of each malicious worker on a given item. This method introduce less overhead to the attacker, as he does not need to take effort to obtain and analyze the crowdsouring data collected from the normal workers.</p>     <p>In the <em>Baseline_inversion</em> method, the attacker first conducts the Dawid-Skene model on the labels provided by the normal workers and get the estimated true label for each item. Then he sets each malicious worker&#x0027;s label on a given item as the candidate answer which is different from the estimated true label. This method is an intuitive attack strategy, in which the attacker tries to maximize the number of bad labels injected into the crowdsourcing data.</p>    </section>    <section id="sec-18">     <p><em>6.1.3 Performance Measure.</em> In order to evaluate the performance of the proposed attack mechanism, we compare the aggregation results before and after the data poisoning attacks, and adopt the <em>change rate</em> as the measure metric. The <em>change rate</em> is defined as <span class="inline-equation"><span class="tex">$\frac{||X^{*a}-X^{*b}||}{M}$</span>      </span>, where <span class="inline-equation"><span class="tex">$X^{*a}=\lbrace x_{m}^{*a}\rbrace _{m=1}^M$</span>      </span> and <span class="inline-equation"><span class="tex">$X^{*b}=\lbrace x_{m}^{*b}\rbrace _{m=1}^M$</span>      </span> are the estimations for the items&#x2019; true labels after and before the data poisoning attacks. Since the goal of the attacker is to maximize the error of the aggregation results and meanwhile maximally raise the reliability degrees of the malicious workers, thus, the larger the <em>change rate</em>, the better the method.</p>    </section>    </section>    <section id="sec-19">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.2</span> The Effect of the Percentage of the Malicious Workers</h3>     </div>    </header>    <p>When conducting the data poisoning attack, we assume that the attacker cannot manipulate the labels of normal workers, but he can create or recruit multiple malicious workers. Thus, the number of the malicious workers created or recruited by the attacker plays an important role in the attack. If the attacker is able to create or recruit overwhelming number of malicious workers, the goal of the attacker can be easily achieved with the intuitive attack strategy, i.e., the <em>Baseline_inversion</em> method. However, in practice, the attacker can only create or recruit a limited number of malicious workers due to the limitation of his ability. In this experiment, we consider the scenarios where the percentage of malicious workers is low, and evaluate the performance of the proposed mechanism when the percentage is varying.</p>    <p>Suppose <em>N</em> is the number of labels provided by the normal workers for all items. Here we assume that each malicious worker can observe <em>N</em>/<em>K</em> items, which is the average number of the items observed by each normal worker. For each malicious worker, the <em>N</em>/<em>K</em> observed items are randomly selected. In this paper, we set the parameters <em>&#x03B8;</em> and <em>&#x03BB;</em> as 100 and 1, respectively. Then we vary the percentage of the malicious workers from 0.03 to 0.27. All the experiments are conducted 50 times and we report the average results. The <em>change rate</em> for the three real-world crowdsourcing datasets is shown in Figure&#x00A0;<a class="fig" href="#fig3">3</a>, in which we represent the proposed mechanism as <em>The intelligent attack</em>. From this figure, we can see the proposed attack mechanism performs better than the baseline methods in all cases. When the percentage of the malicious workers is very low (e.g., 3%), since the malicious workers are too few to change the final aggregation results much, the advantage of the proposed mechanism is small. However, when the percentage of the malicious workers increases, the advantage of the proposed attack scheme becomes bigger. For example, when the percentage of malicious workers is 27%, the proposed mechanism successfully attacks nearly 50% of the items in the Duchenne Smile datasets while the baseline methods only obtain marginal utility. <figure id="fig3">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186032/images/www2018-41-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 3:</span>       <span class="figure-title">Change rate w.r.t. the percentage of the malicious workers. (a): Duchenne Smile Dataset. (b): Product Dataset. (c): Sentiment Dataset.</span>      </div>     </figure>    </p>    </section>    <section id="sec-20">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.3</span> The Effect of the Number of the Queried Items</h3>     </div>    </header>    <p>When the percentage of the malicious workers is given, the number of the items queried to each malicious worker is another important factor in the attack. In this experiment, we study the performance of the proposed mechanism when the number of the items queried to each malicious worker varies.</p>    <p>Here we consider a scenario where the percentage of the malicious workers is very low and we set the value as 3%, i.e., the attacker creates or recruits 2, 6 and 3 malicious workers to the three datasets, respectively. For the Duchenne Smile dataset and the Product dataset, we vary the number of items queried to each malicious worker from 50 to 500, and for the Sentiment dataset, the number of the queried items varies from 100 to 700. The <em>change rate</em> for the three datasets is shown in Figure&#x00A0;<a class="fig" href="#fig4">4</a>. The results in this figure clearly verify that the proposed attack mechanism outperforms the baseline methods in all cases. When the number of the items queried to each malicious worker increases, the advantage of the proposed attack mechanism also increases. The reason is that with the increment of the number of the queried items, the malicious workers can exert more impact on the final aggregation results based on the proposed mechanism. Additionally, this figure also shows that the proposed mechanism can achieve good utility even with very few malicious workers. Take the Duchenne Smile dataset as an example, when each malicious worker provides 250 labels (less than the average number of that from normal workers), the proposed mechanism can successfully attack more than 10% of the items with only 2 malicious workers. <figure id="fig4">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186032/images/www2018-41-fig4.jpg" class="img-responsive" alt="Figure 4"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 4:</span>       <span class="figure-title">Change rate w.r.t. the number of the items queried to each malicious worker. (a): Duchenne Smile Dataset. (b): Product Dataset. (c): Sentiment Dataset.</span>      </div>     </figure>    </p>    </section>    <section id="sec-21">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.4</span> Comparison on the Ability Parameters of the Malicious Workers</h3>     </div>    </header>    <p>Besides maximizing the error of the aggregation results, the attacker also tries to maximize the malicious workers&#x2019; reliability degrees (or ability) such that they can be treated as high-quality workers and thus be disguised well. In fact, the proposed mechanism outperforms the baseline methods mainly because we take the effect of the malicious workers&#x2019; reliability degrees into account. The malicious workers can disguise themselves as good workers on some items to enhance their reliability degrees. For the baseline methods, since the malicious workers always disagree with the normal ones or randomly provide their labels, the attack behaviors may be detected by the Dawid-Skene model and the malicious workers will be assigned with low reliability degrees.</p>    <p>In this experiment, we investigate the distribution of the participating workers&#x2019; ability parameters, i.e., <span class="inline-equation"><span class="tex">$\alpha =\lbrace \alpha _k,\widetilde{\alpha }_{k^{\prime }}\rbrace _{k,k^{\prime }=1}^{K,K^{\prime }}$</span>     </span> and <span class="inline-equation"><span class="tex">$\beta =\lbrace \beta _k,\widetilde{\beta }_{k^{\prime }}\rbrace _{k,k^{\prime }=1}^{K,K^{\prime }}$</span>     </span>, which can be treated as the reliability degrees of these workers based on the Dawid-Skene model. For each dataset, the percentage of the malicious workers is fixed as 5%. We report the results of the parameters <em>&#x03B1;</em> and <em>&#x03B2;</em> for the three datasets after the data poisoning attacks in Figure&#x00A0;<a class="fig" href="#fig5">5</a>, Figure&#x00A0;<a class="fig" href="#fig6">6</a> and Figure&#x00A0;<a class="fig" href="#fig7">7</a>, respectively. The results show that the malicious workers from the proposed mechanism have high reliability degrees (both <em>&#x03B1;</em> and <em>&#x03B2;</em>) comparing with the normal workers. This means that the malicious workers blend into the normal workers successfully and they will be treated as high-quality workers according to the Dawid-Skene model. This also verifies that the proposed mechanism can well disguise the malicious behaviors of the attacker while maximizing the error of the aggregated results. In contrast, in the <em>Baseline_inversion</em> method, since the malicious workers always disagree with the normal workers, they will be assigned significantly low reliability degrees, which not only limit the performance of the malicious workers, but also make them easy to be detected. As for the <em>Baseline_rand</em> method, since the malicious workers randomly select their labels, the values of the ability parameters will be around 0.5. Although the malicious workers from the <em>Baseline_rand</em> method can disguise themselves to some extent, their reliability degrees are not large enough to impact the aggregated results. <figure id="fig5">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186032/images/www2018-41-fig5.jpg" class="img-responsive" alt="Figure 5"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 5:</span>       <span class="figure-title">The ability parameters of the normal and malicious workers for the Duchenne Smile dataset.</span>      </div>     </figure>     <figure id="fig6">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186032/images/www2018-41-fig6.jpg" class="img-responsive" alt="Figure 6"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 6:</span>       <span class="figure-title">The ability parameters of the normal and malicious workers for the Product dataset.</span>      </div>     </figure>     <figure id="fig7">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186032/images/www2018-41-fig7.jpg" class="img-responsive" alt="Figure 7"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 7:</span>       <span class="figure-title">The ability parameters of the normal and malicious workers for the Sentiment dataset.</span>      </div>     </figure>    </p>    </section>    <section id="sec-22">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.5</span> The Effect of the Attacker&#x0027;s Knowledge</h3>     </div>    </header>    <p>As described in Section&#x00A0;<a class="sec" href="#sec-13">5</a>, the proposed mechanism can also be employed to implement an effective attack when the attacker only has limited knowledge of the items&#x2019; normal labels. In this experiment, we evaluate the performance of the proposed mechanism with respect to the value of <em>M</em>&#x2032;/<em>M</em>, i.e., the percentage of the items whose labels from the normal workers can be known by the attacker. Here we still consider a scenario where the percentage of the malicious workers is very low (3%). We also assume that each malicious worker can observe <em>N</em>/<em>K</em> items, which are randomly selected from <em>O</em>&#x2032;. Then we vary the value of <em>M</em>&#x2032;/<em>M</em> from 0.3 to 1 and calculate the <em>change rate</em> for the three real-world datasets. We conduct the experiment for 50 times and report the average results in Figure&#x00A0;<a class="fig" href="#fig8">8</a>, from which we can see the proposed mechanism outperforms the baseline methods in all cases, and the advantage of the proposed mechanism becomes bigger when the attacker&#x0027;s knowledge increases. These results verify that the proposed mechanism can still achieve good utility when the attacker only has limited knowledge of the items&#x2019; normal labels. <figure id="fig8">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186032/images/www2018-41-fig8.jpg" class="img-responsive" alt="Figure 8"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 8:</span>       <span class="figure-title">Change rate w.r.t. the percentage of the knowledge known by the attacker (i.e., <em>M</em>&#x2032;/<em>M</em>). (a): Duchenne Smile Dataset. (b): Product Dataset. (c): Sentiment Dataset.</span>      </div>     </figure>    </p>    <p>To further evaluate the performance of the proposed mechanism in the limited knowledge scenarios, we investigate the distribution of the workers&#x2019; ability parameters when the attacker only has partial knowledge of the normal labels. Here we consider three cases in which the percentage of the known items (i.e., <em>M</em>&#x2032;/<em>M</em>) is set as 0.3, 0.5 and 0.7, respectively. In Figure&#x00A0;<a class="fig" href="#fig9">9</a> we report the results of the parameters <em>&#x03B1;</em> and <em>&#x03B2;</em> derived from the proposed mechanism on the the Duchenne Smile Dataset. The results show that the malicious workers keep the high reliability degrees, which means that the proposed mechanism can well disguise the attack behaviors in the limited knowledge scenarios. As for the baseline methods, the results of them on the Duchenne Smile dataset are similar to those in Figure&#x00A0;<a class="fig" href="#fig5">5</a>. <figure id="fig9">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186032/images/www2018-41-fig9.jpg" class="img-responsive" alt="Figure 9"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 9:</span>       <span class="figure-title">The workers&#x2019; ability parameters calculated by the intelligent attack mechanism in the limited knowledge scenarios for the Duchenne Smile Dataset.</span>      </div>     </figure>    </p>    </section>   </section>   <section id="sec-23">    <header>    <div class="title-info">     <h2>      <span class="section-number">7</span> Related Work</h2>    </div>    </header>    <p>As an effective and low-cost way to solve challenging problems, crowdsourcing, which utilizes the wisdom of crowds, has become more and more popular&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0040">40</a>]. One important issue for crowdsourcing is that the participating workers are non-experts, so they are likely to provide noisy labels. To address this problem, the researchers have proposed many aggregation methods to estimate the true labels. Among these methods, the Dawid-Skene model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>] has been widely adopted in practice. Compared with the naive aggregation methods such as majority voting, the Dawid-Skene model takes the reliability degrees of workers into account, and it can jointly estimate the items&#x2019; true labels and each worker&#x0027;s reliability degree. Although different variants have been developed and the theoretical analysis has been conducted for the Dawid-Skene model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0044">44</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0046">46</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0057">57</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0059">59</a>], these works do not take into consideration the sophisticated data poisoning attacks against this model in crowdsourcing. In this paper, we propose an effective data poisoning attack mechanism which can maximize the error of the final results estimated based on the Dawid-Skene model in crowdsourcing. With the spirit of disguising the malicious workers, the above methods cannot defend against this attack effectively.</p>    <p>There are also some crowdsourcing methods which are proposed to eliminate the spammers when collecting labels or conducting aggregation&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>]. However, the spammers discussed in these papers are usually the workers who uniformly and/or randomly provide labels in crowdsourcing, which is similar to the <em>Baseline_rand</em> attack mechanism. As shown in various experiments, the proposed mechanism can launch significantly more effective attacks than the <em>Baseline_rand</em>. Since the malicious workers can disguise themselves well by providing labels intelligently, they will not be detected as spammers.</p>    <p>The importance of the data poisoning attacks has recently been recognized in many crowdsourcing and crowdsensing scenarios&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0049">49</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0050">50</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0055">55</a>]. Additionally, there also has been existing work that investigates the data poisoning attacks and related defense schemes in the applications of Internet of Things&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0056">56</a>], electric power grids&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>] and machine learning algorithms&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0054">54</a>]. However, the attacked algorithms discussed in these papers are different from ours. In our designed mechanism, we study the optimal data poisoning attacks against the crowdsourcing systems empowered with the Dawid-Skene model. Compared with the naive aggregation methods such as majority voting, the Dawid-Skene model can defend against the naive malicious workers to some degree, which makes the attack more difficult. The most relevant papers to this work are &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>], in which the proposed schemes can identify the malicious workers who conduct the sophisticated data poisoning attacks. However, based on these schemes, the workers who agree with the majority will be classified as normal ones. Since the malicious workers in our proposed mechanism can disguise themselves by agreeing with the majority on some items, these methods will fail to detect them.</p>   </section>   <section id="sec-24">    <header>    <div class="title-info">     <h2>      <span class="section-number">8</span> Conclusions</h2>    </div>    </header>    <p>In this paper, we investigate crowdsourcing in adversarial environments and study the data poisoning attacks against the crowdsourcing systems with the Dawid-Skene model empowered. In order to find an effective attack strategy for the attacker who aims to maximize the error of the aggregated results, we design an intelligent attack mechanism, based on which an optimal attack strategy can be derived by solving a bi-level optimization problem. With the derived optimal attack strategy, the attacker can not only achieve maximum attack utility but also intelligently disguise the introduced malicious workers as normal ones or even good ones. The experimental results based on real-world datasets demonstrate that the proposed attack mechanism can achieve higher attack utility with very few malicious workers and at the same time, is harder to be detected by the defense mechanisms.</p>   </section>  </section>  <section class="back-matter">   <section id="sec-25">    <header>    <div class="title-info">     <h2>ACKNOWLEDGMENTS</h2>    </div>    </header>    <p>We thank Dr. Niao He from the University of Illinois at Urbana-Champaign for her valuable suggestions. This work was supported in part by the US National Science Foundation under grants CNS-1566374, CNS-1652503, IIS-1553411 and CNS-1742845.</p>   </section>   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">Scott Alfeld, Xiaojin Zhu, and Paul Barford. 2016. Data Poisoning Attacks against Autoregressive Models. In <em>      <em>Proc. of AAAI</em>     </em>. 1452&#x2013;1458.</li>    <li id="BibPLXBIB0002" label="[2]">Jonathan&#x00A0;F Bard. 1998. <em>      <em>Practical bilevel optimization: algorithms and applications</em>     </em>. Kluwer Academic Publishers.</li>    <li id="BibPLXBIB0003" label="[3]">Marco Barreno, Blaine Nelson, Russell Sears, Anthony&#x00A0;D Joseph, and J&#x00A0;Doug Tygar. 2006. Can machine learning be secure?. In <em>      <em>Proc. of ASIACCS</em>     </em>. 16&#x2013;25.</li>    <li id="BibPLXBIB0004" label="[4]">Battista Biggio, Blaine Nelson, and Pavel Laskov. 2012. Poisoning attacks against support vector machines. In <em>      <em>Proc. of ICML</em>     </em>.</li>    <li id="BibPLXBIB0005" label="[5]">Marco Brambilla, Stefano Ceri, Andrea Mauri, and Riccardo Volonterio. 2014. Community-based crowdsourcing. In <em>      <em>Proc. of WWW</em>     </em>. 891&#x2013;896.</li>    <li id="BibPLXBIB0006" label="[6]">Shih-Hao Chang and Zhi-Rong Chen. 2016. Protecting Mobile Crowd Sensing against Sybil Attacks Using Cloud Based Trust Management System. <em>      <em>Mobile Information Systems</em>     </em>2016 (2016).</li>    <li id="BibPLXBIB0007" label="[7]">Xi Chen, Qihang Lin, and Dengyong Zhou. 2013. Optimistic knowledge gradient policy for optimal budget allocation in crowdsourcing. In <em>      <em>Proc. of ICML</em>     </em>. 64&#x2013;72.</li>    <li id="BibPLXBIB0008" label="[8]">Nilesh Dalvi, Anirban Dasgupta, Ravi Kumar, and Vibhor Rastogi. 2013. Aggregating crowdsourced binary ratings. In <em>      <em>Proc. of WWW</em>     </em>. 285&#x2013;294.</li>    <li id="BibPLXBIB0009" label="[9]">Alexander&#x00A0;Philip Dawid and Allan&#x00A0;M Skene. 1979. Maximum likelihood estimation of observer error-rates using the EM algorithm. <em>      <em>Applied statistics</em>     </em> (1979).</li>    <li id="BibPLXBIB0010" label="[10]">Luca de Alfaro, Vassilis Polychronopoulos, and Michael Shavlovsky. 2015. Reliable aggregation of boolean crowdsourced tasks. In <em>      <em>Proc. of HCOMP</em>     </em>.</li>    <li id="BibPLXBIB0011" label="[11]">Arthur&#x00A0;P Dempster, Nan&#x00A0;M Laird, and Donald&#x00A0;B Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. <em>      <em>Journal of the royal statistical society</em>     </em>(1977), 1&#x2013;38.</li>    <li id="BibPLXBIB0012" label="[12]">Djellel&#x00A0;Eddine Difallah, Gianluca Demartini, and Philippe Cudr&#x00E9;-Mauroux. 2012. Mechanical Cheat: Spamming Schemes and Adversarial Techniques on Crowdsourcing Platforms.. In <em>      <em>CrowdSearch</em>     </em>. 26&#x2013;30.</li>    <li id="BibPLXBIB0013" label="[13]">Djellel&#x00A0;Eddine Difallah, Gianluca Demartini, and Philippe Cudr&#x00E9;-Mauroux. 2016. Scheduling human intelligence tasks in multi-tenant crowd-powered systems. In <em>      <em>Proc. of WWW</em>     </em>. 855&#x2013;865.</li>    <li id="BibPLXBIB0014" label="[14]">Carsten Eickhoff and Arjen&#x00A0;P de Vries. 2013. Increasing cheat robustness of crowdsourcing tasks. <em>      <em>Information retrieval</em>     </em>16, 2 (2013), 121&#x2013;137.</li>    <li id="BibPLXBIB0015" label="[15]">Ju Fan, Guoliang Li, Beng&#x00A0;Chin Ooi, Kian-lee Tan, and Jianhua Feng. 2015. icrowd: An adaptive crowdsourcing framework. In <em>      <em>Proc. of SIGMOD</em>     </em>. 1015&#x2013;1030.</li>    <li id="BibPLXBIB0016" label="[16]">Ujwal Gadiraju, Gianluca Demartini, Ricardo Kawase, and Stefan Dietze. 2015. Human beyond the machine: Challenges and opportunities of microtask crowdsourcing. <em>      <em>IEEE Intelligent Systems</em>     </em>30, 4 (2015), 81&#x2013;85.</li>    <li id="BibPLXBIB0017" label="[17]">Ujwal Gadiraju, Ricardo Kawase, Stefan Dietze, and Gianluca Demartini. 2015. Understanding malicious behavior in crowdsourcing platforms: The case of online surveys. In <em>      <em>Proc. of CHI</em>     </em>. 1631&#x2013;1640.</li>    <li id="BibPLXBIB0018" label="[18]">Matthias Hirth, Tobias Ho&#x00DF;feld, and Phuoc Tran-Gia. 2010. Cheat-detection mechanisms for crowdsourcing. <em>      <em>University of W&#x00FC;rzburg, Tech. Rep</em>     </em>4 (2010).</li>    <li id="BibPLXBIB0019" label="[19]">Ling Huang, Anthony&#x00A0;D Joseph, Blaine Nelson, Benjamin&#x00A0;IP Rubinstein, and JD Tygar. 2011. Adversarial machine learning. In <em>      <em>Proc. of AISec</em>     </em>. 43&#x2013;58.</li>    <li id="BibPLXBIB0020" label="[20]">Nguyen Quoc&#x00A0;Viet Hung, Duong&#x00A0;Chi Thang, Matthias Weidlich, and Karl Aberer. 2015. Minimizing efforts in validating crowd answers. In <em>      <em>Proc. of SIGMOD</em>     </em>. 999&#x2013;1014.</li>    <li id="BibPLXBIB0021" label="[21]">Vittorio&#x00A0;P Illiano and Emil&#x00A0;C Lupu. 2015. Detecting malicious data injections in wireless sensor networks: A survey. <em>      <em>ACM Computing Surveys (CSUR)</em>     </em>(2015).</li>    <li id="BibPLXBIB0022" label="[22]">Panagiotis&#x00A0;G Ipeirotis, Foster Provost, and Jing Wang. 2010. Quality management on amazon mechanical turk. In <em>      <em>Proc. of the ACM SIGKDD workshop on human computation</em>     </em>. 64&#x2013;67.</li>    <li id="BibPLXBIB0023" label="[23]">Srikanth Jagabathula, Lakshminarayanan Subramanian, and Ashwin Venkataraman. 2014. Reputation-based worker filtering in crowdsourcing. In <em>      <em>Proc. of NIPS</em>     </em>. 2492&#x2013;2500.</li>    <li id="BibPLXBIB0024" label="[24]">Srikanth Jagabathula, Lakshminarayanan Subramanian, and Ashwin Venkataraman. 2016. Identifying Unreliable and Adversarial Workers in Crowdsourced Labeling Tasks. (2016).</li>    <li id="BibPLXBIB0025" label="[25]">David&#x00A0;R Karger, Sewoong Oh, and Devavrat Shah. 2014. Budget-optimal task allocation for reliable crowdsourcing systems. <em>      <em>Operations Research</em>     </em>62, 1 (2014), 1&#x2013;24.</li>    <li id="BibPLXBIB0026" label="[26]">Walter&#x00A0;S Lasecki, Jaime Teevan, and Ece Kamar. 2014. Information extraction and manipulation threats in crowd-powered systems. In <em>      <em>Proc. of CSCW</em>     </em>. 248&#x2013;256.</li>    <li id="BibPLXBIB0027" label="[27]">Edith Law, Ming Yin, Joslin Goh, Kevin Chen, Michael&#x00A0;A Terry, and Krzysztof&#x00A0;Z Gajos. 2016. Curiosity killed the cat, but makes crowdwork better. In <em>      <em>Proc. of CHI</em>     </em>. 4098&#x2013;4110.</li>    <li id="BibPLXBIB0028" label="[28]">Bo Li, Yining Wang, Aarti Singh, and Yevgeniy Vorobeychik. 2016. Data poisoning attacks on factorization-based collaborative filtering. In <em>      <em>Proc. of NIPS</em>     </em>. 1885&#x2013;1893.</li>    <li id="BibPLXBIB0029" label="[29]">Guoliang Li, Jiannan Wang, Yudian Zheng, and Michael&#x00A0;J Franklin. 2016. Crowdsourced data management: A survey. <em>      <em>IEEE Transactions on Knowledge and Data Engineering</em>     </em>28, 9(2016), 2296&#x2013;2319.</li>    <li id="BibPLXBIB0030" label="[30]">Hongwei Li, Bin Yu, and Dengyong Zhou. 2013. Error rate analysis of labeling by crowdsourcing. In <em>      <em>ICML Workshop: Machine Learning Meets Crowdsourcing</em>     </em>.</li>    <li id="BibPLXBIB0031" label="[31]">Qi Li, Fenglong Ma, Jing Gao, Lu Su, and Christopher&#x00A0;J Quinn. 2016. Crowdsourcing high quality labels with a tight budget. In <em>      <em>Proc. of WSDM</em>     </em>. 237&#x2013;246.</li>    <li id="BibPLXBIB0032" label="[32]">Yaliang Li, Jing Gao, Patrick&#x00A0;PC Lee, Lu Su, Caifeng He, Cheng He, Fan Yang, and Wei Fan. 2017. A weighted crowdsourcing approach for network quality measurement in cellular data networks. <em>      <em>IEEE Transactions on Mobile Computing</em>     </em>16, 2 (2017), 300&#x2013;313.</li>    <li id="BibPLXBIB0033" label="[33]">Bing Liu. 2012. Sentiment analysis and opinion mining. <em>      <em>Synthesis lectures on human language technologies</em>     </em>5, 1(2012), 1&#x2013;167.</li>    <li id="BibPLXBIB0034" label="[34]">Qiang Liu, Jian Peng, and Alexander&#x00A0;T Ihler. 2012. Variational inference for crowdsourcing. In <em>      <em>Proc. of NIPS</em>     </em>. 692&#x2013;700.</li>    <li id="BibPLXBIB0035" label="[35]">Yao Liu, Peng Ning, and Michael&#x00A0;K Reiter. 2011. False data injection attacks against state estimation in electric power grids. <em>      <em>ACM Transactions on Information and System Security</em>     </em>14, 1 (2011), 13.</li>    <li id="BibPLXBIB0036" label="[36]">Fenglong Ma, Yaliang Li, Qi Li, Minghui Qiu, Jing Gao, Shi Zhi, Lu Su, Bo Zhao, Heng Ji, and Jiawei Han. 2015. Faitcrowd: Fine grained truth discovery for crowdsourced data aggregation. In <em>      <em>Proc. of KDD</em>     </em>. 745&#x2013;754.</li>    <li id="BibPLXBIB0037" label="[37]">Shike Mei and Xiaojin Zhu. 2015. Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners. In <em>      <em>Proc. of AAAI</em>     </em>. 2871&#x2013;2877.</li>    <li id="BibPLXBIB0038" label="[38]">Chuishi Meng, Wenjun Jiang, Yaliang Li, Jing Gao, Lu Su, Hu Ding, and Yun Cheng. 2015. Truth discovery on crowd sensing of correlated entities. In <em>      <em>Proc. of SenSys</em>     </em>. 169&#x2013;182.</li>    <li id="BibPLXBIB0039" label="[39]">Chenglin Miao, Wenjun Jiang, Lu Su, Yaliang Li, Suxin Guo, Zhan Qin, Houping Xiao, Jing Gao, and Kui Ren. 2015. Cloud-enabled privacy-preserving truth discovery in crowd sensing systems. In <em>      <em>Proc. of SenSys</em>     </em>. 183&#x2013;196.</li>    <li id="BibPLXBIB0040" label="[40]">Quoc Viet&#x00A0;Hung Nguyen, Tam Nguyen&#x00A0;Thanh, Ngoc&#x00A0;Tran Lam, Son&#x00A0;Thanh Do, and Karl Aberer. 2013. A Benchmark for Aggregation Techniques in Crowdsourcing. In <em>      <em>Proc. of SIGIR</em>     </em>.</li>    <li id="BibPLXBIB0041" label="[41]">Jungseul Ok, Sewoong Oh, Jinwoo Shin, and Yung Yi. 2016. Optimality of belief propagation for crowdsourced classification. In <em>      <em>Proc. of ICML</em>     </em>. 535&#x2013;544.</li>    <li id="BibPLXBIB0042" label="[42]">Zhengrui Qin, Qun Li, and George Hsieh. 2013. Defending against cooperative attacks in cooperative spectrum sensing. <em>      <em>IEEE Transactions on Wireless Communications</em>     </em>12, 6(2013), 2680&#x2013;2687.</li>    <li id="BibPLXBIB0043" label="[43]">Vikas&#x00A0;C Raykar and Shipeng Yu. 2012. Eliminating spammers and ranking annotators for crowdsourced labeling tasks. <em>      <em>Journal of Machine Learning Research</em>     </em>13, Feb (2012), 491&#x2013;518.</li>    <li id="BibPLXBIB0044" label="[44]">Vikas&#x00A0;C Raykar, Shipeng Yu, Linda&#x00A0;H Zhao, Gerardo&#x00A0;Hermosillo Valadez, Charles Florin, Luca Bogoni, and Linda Moy. 2010. Learning from crowds. <em>      <em>Journal of Machine Learning Research</em>     </em>11, Apr (2010), 1297&#x2013;1322.</li>    <li id="BibPLXBIB0045" label="[45]">Mohsen Rezvani, Aleksandar Ignjatovic, Elisa Bertino, and Sanjay Jha. 2015. Secure data aggregation technique for wireless sensor networks in the presence of collusion attacks. <em>      <em>IEEE Transactions on Dependable and Secure Computing</em>     </em>12, 1 (2015), 98&#x2013;110.</li>    <li id="BibPLXBIB0046" label="[46]">Rion Snow, Brendan O&#x0027;Connor, Daniel Jurafsky, and Andrew&#x00A0;Y Ng. 2008. Cheap and fast&#x2014;but is it good?: evaluating non-expert annotations for natural language tasks. In <em>      <em>Proc. of the EMNLP</em>     </em>. 254&#x2013;263.</li>    <li id="BibPLXBIB0047" label="[47]">Norases Vesdapunt, Kedar Bellare, and Nilesh Dalvi. 2014. Crowdsourcing algorithms for entity resolution. <em>      <em>Proceedings of the VLDB Endowment</em>     </em>7, 12 (2014), 1071&#x2013;1082.</li>    <li id="BibPLXBIB0048" label="[48]">Jeroen Vuurens, Arjen&#x00A0;P de Vries, and Carsten Eickhoff. 2011. How much spam can you take? an analysis of crowdsourcing results to increase accuracy. In <em>      <em>Proc. of CIR</em>     </em>. 21&#x2013;26.</li>    <li id="BibPLXBIB0049" label="[49]">Gang Wang, Bolun Wang, Tianyi Wang, Ana Nika, Haitao Zheng, and Ben&#x00A0;Y Zhao. 2016. Defending against sybil devices in crowdsourced mapping services. In <em>      <em>Proc. of MobiSys</em>     </em>. 179&#x2013;191.</li>    <li id="BibPLXBIB0050" label="[50]">Gang Wang, Tianyi Wang, Haitao Zheng, and Ben&#x00A0;Y Zhao. 2014. Man vs. Machine: Practical Adversarial Detection of Malicious Crowdsourcing Workers.. In <em>      <em>USENIX Security Symposium</em>     </em>. 239&#x2013;254.</li>    <li id="BibPLXBIB0051" label="[51]">Jiannan Wang, Tim Kraska, Michael&#x00A0;J Franklin, and Jianhua Feng. 2012. Crowder: Crowdsourcing entity resolution. <em>      <em>Proc. of the VLDB Endowment</em>     </em>5, 11 (2012), 1483&#x2013;1494.</li>    <li id="BibPLXBIB0052" label="[52]">Peter Welinder and Pietro Perona. 2010. Online crowdsourcing: rating annotators and obtaining cost-effective labels. In <em>      <em>Proc. of CVPRW</em>     </em>. 25&#x2013;32.</li>    <li id="BibPLXBIB0053" label="[53]">Jacob Whitehill, Ting-fan Wu, Jacob Bergsma, Javier&#x00A0;R Movellan, and Paul&#x00A0;L Ruvolo. 2009. Whose vote should count more: Optimal integration of labels from labelers of unknown expertise. In <em>      <em>Proc. of NIPS</em>     </em>. 2035&#x2013;2043.</li>    <li id="BibPLXBIB0054" label="[54]">Huang Xiao, Battista Biggio, Gavin Brown, Giorgio Fumera, Claudia Eckert, and Fabio Roli. 2015. Is feature selection secure against training data poisoning?. In <em>      <em>Proc. of ICML</em>     </em>. 1689&#x2013;1698.</li>    <li id="BibPLXBIB0055" label="[55]">Dong Yuan, Guoliang Li, Qi Li, and Yudian Zheng. 2017. Sybil Defense in Crowdsourcing Platforms. In <em>      <em>Proc. of CIKM</em>     </em>. 1529&#x2013;1538.</li>    <li id="BibPLXBIB0056" label="[56]">Kuan Zhang, Xiaohui Liang, Rongxing Lu, and Xuemin Shen. 2014. Sybil attacks and their defenses in the internet of things. <em>      <em>IEEE Internet of Things Journal</em>     </em>1, 5 (2014), 372&#x2013;383.</li>    <li id="BibPLXBIB0057" label="[57]">Yuchen Zhang, Xi Chen, Denny Zhou, and Michael&#x00A0;I Jordan. 2014. Spectral methods meet EM: A provably optimal algorithm for crowdsourcing. In <em>      <em>Proc. of NIPS</em>     </em>. 1260&#x2013;1268.</li>    <li id="BibPLXBIB0058" label="[58]">Yudian Zheng, Guoliang Li, Yuanbing Li, Caihua Shan, and Reynold Cheng. 2017. Truth inference in crowdsourcing: is the problem solved?<em>      <em>Proc. of the VLDB Endowment</em>     </em>10, 5 (2017), 541&#x2013;552.</li>    <li id="BibPLXBIB0059" label="[59]">Denny Zhou, Sumit Basu, Yi Mao, and John&#x00A0;C Platt. 2012. Learning from the wisdom of crowds by minimax entropy. In <em>      <em>Proc. of NIPS</em>     </em>. 2195&#x2013;2203.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>L. Su is the corresponding author.</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a><a class="link-inline force-break" href="https://www.mturk.com">https://www.mturk.com</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a><a class="link-inline force-break" href="https://www.crowdflower.com">https://www.crowdflower.com</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186032">https://doi.org/10.1145/3178876.3186032</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
