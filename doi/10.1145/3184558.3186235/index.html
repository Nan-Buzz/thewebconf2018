<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>DL-Learner – Structured Machine Learning on Semantic Web
  Data</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3186235'>https://doi.org/10.1145/3184558.3186235</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3186235'>https://w3id.org/oa/10.1145/3184558.3186235</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">DL-Learner – Structured Machine
          Learning on Semantic Web Data</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Lorenz</span> <span class=
          "surName">Bühmann</span>, SDA Research Group, Institute
          for Applied Informatics, University of Leipzig, Leipzig,
          Germany, <a href=
          "mailto:buehmann@informatik.uni-leipzig.de">buehmann@informatik.uni-leipzig.de</a>
        </div>
        <div class="author">
          <span class="givenName">Jens</span> <span class=
          "surName">Lehmann</span>, Enterprise Information Systems,
          Fraunhofer IAIS; Institute of Computer Science,
          University of Bonn, Sankt Augustin, Germany and Bonn
          Germany, <a href=
          "mailto:jens.lehmann@cs.uni-bonn.de">jens.lehmann@cs.uni-bonn.de</a>
        </div>
        <div class="author">
          <span class="givenName">Patrick</span> <span class=
          "surName">Westphal</span>, SDA Research Group, Institute
          for Applied Informatics, University of Leipzig, Leipzig,
          Germany, <a href=
          "mailto:patrick.westphal@informatik.uni-leipzig.de">patrick.westphal@informatik.uni-leipzig.de</a>
        </div>
        <div class="author">
          <span class="givenName">Simon</span> <span class=
          "surName">Bin</span>, SDA Research Group, Institute for
          Applied Informatics, University of Leipzig, Leipzig,
          Germany, <a href=
          "mailto:sbin@informatik.uni-leipzig.de">sbin@informatik.uni-leipzig.de</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186235"
        target=
        "_blank">https://doi.org/10.1145/3184558.3186235</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>The following paper is an extended summary of the
        journal paper&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0005">5</a>]. In this system paper, we describe
        the DL-Learner framework. It is beneficial in various data
        and schema analytic tasks with applications in different
        standard machine learning scenarios, e.g. life sciences, as
        well as Semantic Web specific applications such as ontology
        learning and enrichment. Since its creation in 2007, it has
        become the main OWL and RDF-based software framework for
        supervised structured machine learning and includes several
        algorithm implementations, usage examples and has
        applications building on top of the framework.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS
        Concepts:</span> • <strong>Information systems</strong> →
        <strong>Web Ontology Language (OWL);</strong> <em>Resource
        Description Framework (RDF);</em> • <strong>Computing
        methodologies</strong> → <strong>Structured
        outputs;</strong> <strong>Inductive logic
        learning;</strong> <em>Supervised learning by
        classification;</em> <em>Statistical relational
        learning;</em> <em>Rule learning;</em> <em>Instance-based
        learning;</em></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>System
          Description</small>,</span> <span class=
          "keyword"><small>Machine Learning</small>,</span>
          <span class="keyword"><small>Supervised
          Learning</small>,</span> <span class=
          "keyword"><small>Semantic Web</small>,</span>
          <span class="keyword"><small>OWL</small>,</span>
          <span class="keyword"><small>RDF</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Lorenz Bühmann, Jens Lehmann, Patrick Westphal, and Simon
          Bin. 2018. DL-Learner – Structured Machine Learning on
          Semantic Web Data. In <em>WWW '18 Companion: The 2018 Web
          Conference Companion,</em> <em>April 23–27, 2018 (WWW ’18
          Companion),</em> <em>Lyon, France. ACM, New York, NY,
          USA</em> 5 Pages. <a href=
          "https://doi.org/10.1145/3184558.3186235" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3186235</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Over the past two decades, data and knowledge have become
      more important in our society. A major challenge that
      research faces today is to analyse this growing amount of
      information to obtain insights into the underlying problems,
      e.g.&nbsp;in&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0007">7</a>] and&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0018">18</a>]. In many cases, in
      particular in the life sciences, it is beneficial to employ
      methods that are able to use the complex structure of
      available background knowledge when learning hypotheses.
      DL-Learner<a class="fn" href="#fn1" id=
      "foot-fn1"><sup>1</sup></a> is an open software framework,
      which contains several such methods. It has the primary goal
      to serve as a platform for facilitating the implementation
      and evaluation of supervised structured machine learning
      methods using semantic background knowledge.</p>
      <p>A previous system paper on DL-Learner appeared in 2009 in
      the Journal of Machine Learning Research&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0012">12</a>]. Compared to that system
      description, the major changes are:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">Framework design: The framework
        has been generalised from being focused on learning OWL
        class expressions using OWL ontologies as background
        knowledge to a more generic supervised structured machine
        learning framework. Components are integrated via Java
        Beans and the Java Spring framework, which allows more
        fine-grained and more flexible interaction between them.
        Moreover, algorithms are continuously extended with options
        based on received feature requests. In the same manner, new
        APIs and reasoners are continuously upgraded.<br /></li>
        <li id="list2" label="•">New algorithms for learning SPARQL
        queries (as feedback component in question answering),
        fuzzy description logic expressions, parallel OWL class
        expression learning, a special purpose algorithm for the
        <span class="inline-equation"><span class="tex">$\mathcal
        {EL}$</span></span> description logic, two algorithms for
        knowledge base enrichment of almost all OWL 2 axioms from
        SPARQL endpoints as well as an algorithm combining
        inductive learning with natural language processing have
        been integrated.<br /></li>
        <li id="list3" label="•">Scalability enhancements: There
        are now statistical sampling methods available for dealing
        with a large number of examples as well as different
        knowledge base fragment selection methods for handling
        large knowledge bases in general.<br /></li>
      </ul>
      <p>The article is structured as follows: In
      Section&nbsp;<a class="sec" href="#sec-7">2</a>, we give a
      description of the problems DL-Learner aims to solve.
      Subsequently, in Section&nbsp;<a class="sec" href=
      "#sec-8">3</a>, the software framework is described. We
      summarise core algorithms implemented in DL-Learner in
      Section&nbsp;<a class="sec" href="#sec-9">4</a>. Use cases of
      DL-Learner in different problem areas are covered in
      Section&nbsp;<a class="sec" href="#sec-11">5</a>. Notes
      regarding implementation and extension, as well as related
      and future work are discussed in the journal
      article&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>].</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Learning
          Problems</h2>
        </div>
      </header>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186235/images/www18companion-88-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">General learning workflow.</span>
        </div>
      </figure>
      <p>The process of learning in logics, i.e.&nbsp;trying to
      find high-level explanations for given data, is also called
      <em>inductive reasoning</em> as opposed to <em>inference</em>
      or <em>deductive reasoning</em>. Learning problems which are
      similar to the one we will analyse, have been investigated in
      <em>Inductive Logic Programming</em>&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0019">19</a>].</p>
      <p>The goal of DL-Learner is to provide a structural
      framework and reusable components for solving those induction
      problems. Figure&nbsp;<a class="fig" href="#fig1">1</a>
      depicts a typical workflow from a user's perspective. On the
      left hand side, there are several knowledge bases which
      together form the <em>background knowledge</em> for a given
      task. Within that background knowledge, some resources are
      selected as positive and some others as negative examples. In
      a medical setting, the resources could be patients reacting
      to a treatment (positive examples) and patients not reacting
      to a treatment (negative examples). Those are then processed
      by a supervised machine learning algorithm and return (in
      most cases in DL-Learner) a <em>symbolic classifier</em>.
      This classifier is human readable and expressed in a logical
      form, e.g.&nbsp;as a complex description logic concept or a
      SPARQL query. It serves two purposes: First, due to its
      logical representation it should give insights into the
      underlying problem, showing which concepts are relevant to
      distinguish positive and negative examples. Furthermore, the
      result can also be used to classify unseen resources.</p>
      <p>In DL-Learner, the following learning problems are
      relevant:</p>
      <p><strong>Standard Supervised Learning</strong> Let the name
      of the back-ground ontology be <span class=
      "inline-equation"><span class="tex">$\mathcal
      {O}$</span></span> . The goal in this learning problem is to
      find an OWL class expression <em>C</em> such that all/many
      positive examples are instances of <em>C</em>
      w.r.t.&nbsp;<span class="inline-equation"><span class=
      "tex">$\mathcal {O}$</span></span> and none/few negative
      examples are instances of <em>C</em> w.r.t.&nbsp;<span class=
      "inline-equation"><span class="tex">$\mathcal
      {O}$</span></span> .</p>
      <p><strong>Positive Only Learning</strong> In case only
      positive examples are available, it is desirable to find a
      class expression that covers the positive examples while
      still generalising sufficiently well (usually measured on
      unlabelled data).</p>
      <p><strong>Class Learning</strong> In class learning, you are
      given an existing class <em>A</em> within an ontology
      <span class="inline-equation"><span class="tex">$\mathcal
      {O}$</span></span> and want to describe it. This is similar
      to the previous problem in that you can use the instances of
      the class as positive examples. However, you can make use of
      existing knowledge about <em>A</em> in the ontology and
      (obviously) <em>A</em> itself should not be a solution. In
      addition, there are different nuances of the above learning
      problems which depend on how negative knowledge should be
      treated (related to the open world assumption in description
      logics).</p>
      <p>DL-Learner implements standard binary measures, e.g.
      predictive accuracy, F-measure, and all ternary measures
      described in&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0006">6</a>]. Obviously, in most cases, we will
      not find a perfect solution to the learning problem, but
      rather an approximation, the degree of which is managed by
      setting suitable thresholds representing the tolerance to
      noise/errors, i.e. the fraction of uncovered positive resp.
      covered negative examples.</p>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Overview of the
          Framework</h2>
        </div>
      </header>
      <figure id="fig2">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186235/images/www18companion-88-fig2.jpg"
        class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class=
          "figure-title">Overview of core DL-Learner
          components.</span>
        </div>
      </figure>
      <p>The DL-Learner framework provides means to flexibly build
      concept learning algorithms. Several (Java) interfaces,
      adaptors and external API connectors are part of the
      implementation. Figure&nbsp;<a class="fig" href="#fig2">2</a>
      shows the main parts of this structure:</p>
      <ol class="list-no-style">
        <li id="list4" label="(1)">
          <em>Knowledge sources</em> specify where and how to
          retrieve data. Currently, most RDF and OWL serialisation
          formats are supported. Data can be retrieved locally or
          remotely. Retrieving data from SPARQL endpoints is also
          supported, including various options to extract
          fragments, filter and pre-process data&nbsp;[<a class=
          "bib" data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0008">8</a>] as well
          as several retrieval strategies differing in performance.
          A single learning problem can have multiple knowledge
          sources including mixtures of different types of
          sources.<br />
        </li>
        <li id="list5" label="(2)"><em>Reasoners</em> perform
        inference over knowledge sources. DL-Learner supports
        connecting reasoners via the OWL API, OWLlink as well as
        direct access to e.g.&nbsp;Pellet if advanced features not
        covered in the standard interfaces are needed. DL-Learner
        also implements own approximate reasoners (not sound and/or
        incomplete) for high performance hypothesis testing. Note
        that learning algorithms are not required to use reasoning,
        i.e. can also work only on the asserted knowledge, but
        indeed can benefit from inferred knowledge – there is a
        trade-off between computational complexity and
        expressivity.<br /></li>
        <li id="list6" label="(3)">
          <em>Learning problems</em> define the task to solve
          (see&nbsp;Sec. <a class="sec" href="#sec-7">2</a>).
          Learning problems are typically used by learning
          algorithms for hypothesis testing. DL-Learner provides
          statistical sampling methods which allow efficient
          hypothesis testing even in the presence of a high number
          of examples&nbsp;[<a class="bib" data-trigger="hover"
          data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0013">13</a>]. Those methods approximate
          objective functions, such as F-measure, by iteratively
          sampling from the given examples until the confidence
          interval around the approximated objective function value
          is sufficiently small.<br />
        </li>
        <li id="list7" label="(4)"><em>Refinement Operators</em>
        are used to traverse through the space of possible
        hypotheses. DL-Learner implements a set of refinement
        operators, which can be configured towards particular
        fragments of OWL as well as an efficient operator for the
        <span class="inline-equation"><span class="tex">$\mathcal
        {EL}$</span></span> language specifically.<br /></li>
        <li id="list8" label="(5)"><em>Learning algorithms</em>
        implement the core learning strategy.<br /></li>
      </ol>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Learning
          Algorithms</h2>
        </div>
      </header>
      <p>In early work, we provided theoretical foundations for the
      field on top of which we developed algorithms derived from
      Inductive Logic Programming and genetic
      programming&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0011">11</a>]. This was extended to very
      expressive schemata&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0017">17</a>] and learning problems with a lot of
      instance data&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0008">8</a>]. Later, we extended the theoretical
      and algorithmic foundations for a) learning complex
      definitions in ontologies&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0013">13</a>], b) generic schema
      enrichment&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>], c) fuzzy description
      logics&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0009">9</a>],
      d) the light-weight <span class=
      "inline-equation"><span class="tex">$\mathcal
      {EL}$</span></span> -description logic&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0016">16</a>] and e) combinations of
      natural language processing and concept
      learning&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>]. We will briefly describe the
      algorithms resulting from those lines of research.</p>
      <figure id="fig3">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186235/images/www18companion-88-fig3.jpg"
        class="img-responsive" alt="Figure 3" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 3:</span> <span class=
          "figure-title">Search tree used in OCEL and CELOE
          algorithm.</span>
        </div>
      </figure>
      <p></p>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3>Refinement Operator Algorithms</h3>
          </div>
        </header>
        <p>The first category of algorithms is based on so-called
        <em>refinement operators</em>. The design of those
        algorithms is motivated by the fact that, generally,
        learning can be seen as the search for a correct concept
        definition in an ordered space (<em>Σ</em>, ⪯). In such a
        setting, one can define suitable operators to traverse the
        search space.</p>
        <div class="definition" id="enc1">
          <label>Definition 4.1 (refinement operator).</label>
          <p>Given a quasi-ordered<a class="fn" href="#fn2" id=
          "foot-fn2"><sup>2</sup></a> search space (<em>Σ</em>,
          ⪯)</p>
          <p></p>
          <ul class="list-no-style">
            <li id="list9" label="•">a <em>downward refinement
            operator</em> is a mapping <span class=
            "inline-equation"><span class="tex">$\rho :\Sigma
            \rightarrow 2^\Sigma$</span></span> such that
            ∀<em>α</em> ∈ <em>Σ</em> 
            <em>ρ</em>(<em>α</em>)⊆{<em>β</em> ∈
            <em>Σ</em>∣<em>β</em>⪯<em>α</em>}<br /></li>
            <li id="list10" label="•">an <em>upward refinement
            operator</em> is a mapping <span class=
            "inline-equation"><span class="tex">$\delta :\Sigma
            \rightarrow 2^\Sigma$</span></span> such that
            ∀<em>α</em> ∈ <em>Σ</em> 
            <em>δ</em>(<em>α</em>)⊆{<em>β</em> ∈
            <em>Σ</em>∣<em>α</em>⪯<em>β</em>}<br /></li>
          </ul>
          <p></p>
        </div>
        <p>Intuitively, a downward (resp. upward) refinement
        operator returns a set of more specific (resp. general)
        concepts.</p>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186235/images/www18companion-88-fig4.jpg"
          class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">The general workflow of
            knowledge base enrichment and its pattern based
            extension: Frequent axiom patterns in various ontology
            portals are detected and converted into SPARQL query
            patterns (upper part). Those are then applied to other
            data-sets to enrich them with further axioms (lower
            part).</span>
          </div>
        </figure>
        <p></p>
        <p><em>OCEL</em> (OWL Class Expression Learner) was
        initially devised for learning in the description logic
        <span class="inline-equation"><span class="tex">$\mathcal
        {ALC}$</span></span> , but was later extended to cover
        other parts of OWL as well, e.g.&nbsp;nominals. The general
        idea is to use a proper and complete refinement operator to
        build a search tree while using heuristics which control
        how the search tree is traversed. The algorithm uses
        techniques to cope with redundancy and infinity, in
        particular, infinity is handled by the ability to revisit
        nodes in the search tree several times and perform
        incremental applications of the refinement operator.
        Figure&nbsp;<a class="fig" href="#fig3">3</a> visualises a
        search tree of OCEL, starting from the most general concept
        <tt>owl:Thing</tt> as the root node to more specific
        concepts like <tt>Person</tt> or <tt>Person</tt>
        <strong>that</strong> <tt>attends</tt>
        <strong>some</strong> <tt>talk</tt>. Nodes are annotated
        with their score and the number of times they have been
        expanded (denoted by the HE value). Some nodes are too weak
        to eventually lead to competitive learning problem
        solutions, i.e. the number of uncovered positive examples
        is above a given threshold. They are never visited, which
        allows the algorithm to ignore those parts of the search
        space resulting in improved efficiency.</p>
        <p>A summary of the <em>CELOE</em> (Class Expression
        Learning for Ontology Engineering)&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0013">13</a>], <em>ELTL</em> (EL Tree
        Learner)&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0016">16</a>] and <em>ISLE</em> (Inductive
        Statistical Learning of Expressions)&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0002">2</a>], as well as <em>OWL
        Schema Learning Algorithms</em>&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0003">3</a>] and <em>axiom pattern
        enrichment</em>&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0004">4</a>], <em>QTL</em> (Query Tree
        Learning), <em>PARCEL</em>&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0022">22</a>], <em>Fuzzy
        DLL</em>&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0009">9</a>] and genetic
        algorithms&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0011">11</a>] can be found in the journal
        version&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0005">5</a>].</p>
      </section>
    </section>
    <section id="sec-11">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Use case:
          Knowledge Base Enrichment</h2>
        </div>
      </header>
      <p>A standard use case for the learning algorithms contained
      in DL-Learner is <em>knowledge base enrichment</em>,
      i.e.&nbsp;the semi-automation of schemata creation and
      revision based on the available instance data. The
      combination of instance data and schemata allows improved
      querying, inference and consistency checking. As an example,
      consider a knowledge base containing a property
      <tt>birthPlace</tt> and subjects in triples of this property,
      e.g.&nbsp;Brad Pitt, Angela Merkel, Albert Einstein, etc. Our
      enrichment algorithms could, then, suggest that the property
      <tt>birthPlace</tt> may be functional and has the domain
      <tt>Person</tt> as it is encoded via the following axioms in
      Manchester OWL syntax<a class="fn" href="#fn3" id=
      "foot-fn3"><sup>3</sup></a>:</p>
      <p><img src=
      "../../../data/deliveryimages.acm.org/10.1145/3190000/3186235/images/www18companion-88-img1.svg"
      class="img-responsive" alt="" longdesc="" /> Adding such
      axioms to a knowledge base can have several benefits: 1.) The
      axioms serve as documentation for the purpose and correct
      usage of schema elements. 2.) They improve the application of
      schema debugging techniques. For instance, after adding the
      above axioms the knowledge base would become inconsistent if
      a person has two different birth places (explicitly stated to
      be not the same) due to the functionality axiom. Specifically
      for the DBpedia knowledge base we observed an erroneous
      statement asserting that a person was born in Lacrosse, the
      game, instead of Lacrosse, the city in the United States.
      Such errors can be automatically detected when schema
      information such as the range restriction is present
      (assuming disjointness of the classes <tt>Place</tt> and
      <tt>Game</tt>). 3.) Additional implicit information can be
      inferred. As an example in the above case it can be inferred
      that the birth place of a person is one of the places she
      stayed at. The main purpose of our research is to reduce the
      effort of creating and maintaining such schema
      information.</p>
      <p>We have shown in&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>] that the whole enrichment process can
      be described as illustrated in the lower part of
      Figure&nbsp;<a class="fig" href="#fig4">4</a> and also be
      applied to large scale knowledge bases accessible via SPARQL.
      The general workflow proceeds in three steps:</p>
      <ol class="list-no-style">
        <li id="list11" label="(1)">In the optional first step,
        SPARQL queries are used to obtain existing information
        about the schema of the knowledge base. In particular we
        retrieve axioms which allow to construct the class
        hierarchy. It can be configured whether to use an OWL
        reasoner for inferencing over the schema or just taking
        explicit knowledge into account.<a class="fn" href="#fn4"
        id="foot-fn4"><sup>4</sup></a>Naturally, the schema only
        needs to be obtained once per knowledge base and can then
        be re-used by all algorithms and all entities in subsequent
        steps.<br />
        </li>
        <li id="list12" label="(2)">The second step consists of
        obtaining data via SPARQL which is relevant for learning
        the considered axiom. This results in a set of axiom
        candidates, configured via a threshold.<br /></li>
        <li id="list13" label="(3)">In the third step, the score of
        axiom candidates is computed and the results are
        returned.<br /></li>
      </ol>
      <p>In&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0004">4</a>],
      patterns for frequent axioms are mined from more than one
      thousand ontologies and then used to learn on the DBpedia
      data-set. As one would expected, the most frequent axiom
      pattern was [language=manchester]A SubClassOf B, but in the
      top 15 we found also patterns like</p>
      <p><img src=
      "../../../data/deliveryimages.acm.org/10.1145/3190000/3186235/images/www18companion-88-img2.svg"
      class="img-responsive" alt="" longdesc="" /> Those patterns
      have been applied to search for promising instantiations on
      DBpedia and resulted in axioms like</p>
      <p><img src=
      "../../../data/deliveryimages.acm.org/10.1145/3190000/3186235/images/www18companion-88-img3.svg"
      class="img-responsive" alt="" longdesc="" /></p>
      <p>or</p>
      <p><img src=
      "../../../data/deliveryimages.acm.org/10.1145/3190000/3186235/images/www18companion-88-img4.svg"
      class="img-responsive" alt="" longdesc="" /> A manual
      evaluation with non-author experts judging the 2154 proposed
      axioms showed that 48.2% of these axioms were useful for
      extending the knowledge base. This shows promise, but also
      clearly indicates that a human expert is required in loop to
      ensure high quality.</p>
      <p>Many more use cases such as Life-Science
      Problems&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0021">21</a>] like <em>carcinogenesis
      prediction</em>, <em>Ontology Repair</em>
      (ORE&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0014">14</a>],
      RDFUnit&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0010">10</a>]), Suggestions for Ontology
      Editors<a class="fn" href="#fn5" id=
      "foot-fn5"><sup>5</sup></a>, <em>Knowledge
      Exploration</em>&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0015">15</a>], <em>sentiment
      analysis</em>&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0020">20</a>], or hospital workflow
      management&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0001">1</a>] are summarised in the journal
      version&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>].</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="sec-12">
      <header>
        <div class="title-info">
          <h2>ACKNOWLEDGMENTS</h2>
        </div>
      </header>
      <p>This work was supported by grants from the EU FP7
      Programme for the project GeoKnow (GA no. 318159) as well as
      for the German Research Foundation project GOLD and the
      German Ministry for Economic Affairs and Energy project SAKE
      (GA no. 01MD15006E) and the European Union's Horizon 2020
      research and innovation programme for the project SLIPO (GA
      no. 731581).</p>
    </section>
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Pieter Bonte, Femke
        Ongenae, and Filip&nbsp;De Turck. 2016. Learning Semantic
        Rules for Intelligent Transport Scheduling in Hospitals. In
        <em><em>Proc. of the 5th Workshop on Data Mining and
        Knowledge Discovery meets Linked Open Data</em></em> .</li>
        <li id="BibPLXBIB0002" label="[2]">Lorenz Bühmann, Daniel
        Fleischhacker, Jens Lehmann, Andre Melo, and Johanna
        Völker. 2014. Inductive Lexical Learning of Class
        Expressions. In <em><em>Knowledge Engineering and Knowledge
        Management</em></em> (<em>LNCS</em>), Vol.&nbsp;8876.
        Springer International Publishing, 42–53.</li>
        <li id="BibPLXBIB0003" label="[3]">Lorenz Bühmann and Jens
        Lehmann. 2012. Universal OWL Axiom Enrichment for Large
        Knowledge Bases. In <em><em>Proc. of EKAW 2012</em></em> .
        57–71.</li>
        <li id="BibPLXBIB0004" label="[4]">Lorenz Bühmann and Jens
        Lehmann. 2013. Pattern Based Knowledge Base Enrichment. In
        <em><em>12th International Semantic Web Conference, 21–25
        October 2013, Sydney, Australia</em></em> . 33–48.</li>
        <li id="BibPLXBIB0005" label="[5]">Lorenz Bühmann, Jens
        Lehmann, and Patrick Westphal. 2016. DL-Learner – A
        framework for inductive learning on the Semantic Web.
        <em><em>Web Semantics: Science, Services and Agents on the
        World Wide Web</em></em> 39 (2016), 15–24.</li>
        <li id="BibPLXBIB0006" label="[6]">Claudia d'Amato, Nicola
        Fanizzi, and Floriana Esposito. 2008. A Note on the
        Evaluation of Inductive Concept Classification Procedures.
        In <em><em>Proc. of the 5th Workshop on Semantic Web
        Applications and Perspectives (SWAP2008), Rome, Italy,
        2008</em></em> , Vol.&nbsp;426. CEUR-WS.org.</li>
        <li id="BibPLXBIB0007" label="[7]">Thomas Dietterich, Pedro
        Domingos, Lise Getoor, Stephen Muggleton, and Prasad
        Tadepalli. 2008. Structured machine learning: the next ten
        years. <em><em>Machine Learning</em></em> 73, 1 (October
        2008), 3–23.</li>
        <li id="BibPLXBIB0008" label="[8]">Sebastian Hellmann, Jens
        Lehmann, and Sören Auer. 2011. Learning of OWL Class
        Expressions on Very Large Knowledge Bases and its
        Applications.In <em><em>Semantic Services, Interoperability
        and Web Applications: Emerging Concepts</em></em> . IGI
        Global, 104–130.</li>
        <li id="BibPLXBIB0009" label="[9]">Josué Iglesias and Jens
        Lehmann. 2011. Towards Integrating Fuzzy Logic Capabilities
        into an Ontology-based Inductive Logic Programming
        Framework. In <em><em>Proc. of the 11th International
        Conference on Intelligent Systems Design and Applications
        (ISDA)</em></em> . 1323–1328.</li>
        <li id="BibPLXBIB0010" label="[10]">Dimitris Kontokostas,
        Patrick Westphal, Sören Auer, Sebastian Hellmann, Jens
        Lehmann, Roland Cornelissen, and Amrapali Zaveri. 2014.
        Test-driven Evaluation of Linked Data Quality. In
        <em><em>Proc. of the 23rd International Conference on World
        Wide Web</em></em> (<em>WWW’14</em>). 747–758.</li>
        <li id="BibPLXBIB0011" label="[11]">Jens Lehmann. 2007.
        Hybrid Learning of Ontology Classes. In <em><em>Proc. of
        the 5th Int. Conference on Machine Learning and Data Mining
        MLDM</em></em> (<em>LNCS</em>), Vol.&nbsp;4571. Springer,
        883–898.</li>
        <li id="BibPLXBIB0012" label="[12]">Jens Lehmann. 2009.
        DL-Learner: Learning Concepts in Description Logics.
        <em><em>Journal of Machine Learning Research
        (JMLR)</em></em> 10 (2009), 2639–2642.</li>
        <li id="BibPLXBIB0013" label="[13]">Jens Lehmann, Sören
        Auer, Lorenz Bühmann, and Sebastian Tramp. 2011. Class
        expression learning for ontology engineering.
        <em><em>Journal of Web Semantics</em></em> 9 (2011),
        71–81.</li>
        <li id="BibPLXBIB0014" label="[14]">Jens Lehmann and Lorenz
        Bühmann. 2010. ORE – A Tool for Repairing and Enriching
        Knowledge Bases. In <em><em>Proc. of the 9th International
        Semantic Web Conference (ISWC2010)</em></em>
        (<em>LNCS</em>). Springer, 177–193.</li>
        <li id="BibPLXBIB0015" label="[15]">Jens Lehmann and Lorenz
        Bühmann. 2011. AutoSPARQL: Let Users Query Your Knowledge
        Base. In <em><em>Proc. of ESWC 2011</em></em> . 63–79.</li>
        <li id="BibPLXBIB0016" label="[16]">Jens Lehmann and
        Christoph Haase. 2009. Ideal Downward Refinement in the EL
        Description Logic. In <em><em>Inductive Logic Programming,
        19th International Conference, ILP 2009, Leuven,
        Belgium</em></em> . 73–87.</li>
        <li id="BibPLXBIB0017" label="[17]">Jens Lehmann and Pascal
        Hitzler. 2010. Concept Learning in Description Logics Using
        Refinement Operators. <em><em>Machine Learning
        journal</em></em> 78, 1–2 (2010), 203–250.</li>
        <li id="BibPLXBIB0018" label="[18]">Stephen Muggleton, Luc
        De&nbsp;Raedt, David Poole, Ivan Bratko, Peter Flach,
        Katsumi Inoue, and Ashwin Srinivasan. 2012. ILP turns 20.
        <em><em>Machine Learning</em></em> 86, 1 (2012), 3–23.</li>
        <li id="BibPLXBIB0019" label="[19]">Shan-Hwei
        Nienhuys-Cheng and Ronald de Wolf (Eds.). 1997.
        <em><em>Foundations of Inductive Logic
        Programming</em></em> . <em>LNCS</em>, Vol.&nbsp;1228.
        Springer.</li>
        <li id="BibPLXBIB0020" label="[20]">Alberto Salguero and
        Macarena Espinilla. 2016. <em><em>Sentiment Analysis and
        Ontology Engineering: An Environment of Computational
        Intelligence</em></em> . Chapter Description Logic Class
        Expression Learning Applied to Sentiment Analysis,
        93–111.</li>
        <li id="BibPLXBIB0021" label="[21]">A. Srinivasan,
        R.&nbsp;D. King, and D.&nbsp;W. Bristol. 1999. An
        Assessment of Submissions Made to the Predictive Toxicology
        Evaluation Challenge. In <em><em>Proc. of the 16th
        International Joint Conference on Artifical Intelligence –
        Volume 1</em></em> (<em>IJCAI’99</em>). 270–275.</li>
        <li id="BibPLXBIB0022" label="[22]">An&nbsp;C. Tran, Jens
        Dietrich, Hans&nbsp;W. Guesgen, and Stephen Marsland. 2012.
        An Approach to Parallel Class Expression Learning. In
        <em><em>Proc. of the 6th International Conference on Rules
        on the Web: Research and Applications</em></em>
        (<em>RuleML’12</em>). Springer-Verlag, Berlin, Heidelberg,
        302–316.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class=
    "link-inline force-break" href=
    "http://dl-learner.org">http://dl-learner.org</a>, <a class=
    "link-inline force-break" href=
    "https://github.com/SmartDataAnalytics/DL-Learner">https://github.com/SmartDataAnalytics/DL-Learner</a></p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>A
    quasi-ordering is a reflexive and transitive relation.</p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>For details on
    Manchester OWL syntax (e.g. used in Protégé, OntoWiki) see
    <a class="link-inline force-break" href=
    "http://www.w3.org/TR/owl2-manchester-syntax/">http://www.w3.org/TR/owl2-manchester-syntax/</a>.</p>
    <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>Note that the
    OWL reasoner only loads the schema of the knowledge base and,
    therefore, this option worked even in case with several hundred
    thousand classes in our experiments using the HermiT
    reasoner.</p>
    <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a><a class=
    "link-inline force-break" href=
    "http://dl-learner.org/community/protege-plugin/">http://dl-learner.org/community/protege-plugin/</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3186235">https://doi.org/10.1145/3184558.3186235</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
