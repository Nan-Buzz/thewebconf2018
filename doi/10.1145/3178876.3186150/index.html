<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Variational Autoencoders for Collaborative
  Filtering</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186150'>https://doi.org/10.1145/3178876.3186150</a> 
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186150'>https://w3id.org/oa/10.1145/3178876.3186150</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Variational Autoencoders for
          Collaborative Filtering</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Dawen</span> <span class=
          "surName">Liang</span>, Netflix, Los Gatos, CA, <a href=
          "mailto:dliang@netflix.com">dliang@netflix.com</a>
        </div>
        <div class="author">
          <span class="givenName">Rahul G.</span> <span class=
          "surName">Krishnan</span>, MIT, Cambridge, MA, <a href=
          "mailto:rahulgk@mit.edu">rahulgk@mit.edu</a>
        </div>
        <div class="author">
          <span class="givenName">Matthew D.</span> <span class=
          "surName">Hoffman</span>, Google AI, San Francisco, CA,
          <a href=
          "mailto:mhoffman@google.com">mhoffman@google.com</a>
        </div>
        <div class="author">
          <span class="givenName">Tony</span> <span class=
          "surName">Jebara</span>, Netflix, Los Gatos, CA, <a href=
          "mailto:tjebara@netflix.com">tjebara@netflix.com</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.3186150"
        target=
        "_blank">https://doi.org/10.1145/3178876.3186150</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>We extend VAE to collaborative filtering for
        implicit feedback. This non-linear probabilistic model
        enables us to go beyond the limited modeling capacity of
        linear factor models which still largely dominate
        collaborative filtering research. We introduce a generative
        model with multinomial likelihood and use Bayesian
        inference for parameter estimation. Despite widespread use
        in language modeling and economics, the multinomial
        likelihood receives less attention in the recommender
        systems literature. We introduce a different regularization
        parameter for the learning objective, which proves to be
        crucial for achieving competitive performance. Remarkably,
        there is an efficient way to tune the parameter using
        annealing. The resulting model and learning algorithm has
        information-theoretic connections to maximum entropy
        discrimination and the information bottleneck principle.
        Empirically, we show that the proposed approach
        significantly outperforms several state-of-the-art
        baselines, including two recently-proposed neural network
        approaches, on several real-world datasets. We also provide
        extended experiments comparing the multinomial likelihood
        with other commonly used likelihood functions in the latent
        factor collaborative filtering literature and show
        favorable results. Finally, we identify the pros and cons
        of employing a principled Bayesian inference approach and
        characterize settings where it provides the most
        significant improvements.</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Recommender
          systems</small>,</span> <span class=
          "keyword"><small>collaborative filtering</small>,</span>
          <span class="keyword"><small>implicit
          feedback</small>,</span> <span class=
          "keyword"><small>variational autoencoder</small>,</span>
          <span class="keyword"><small>Bayesian
          models</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and
          Tony Jebara. 2018. Variational Autoencoders for
          Collaborative Filtering. In <em>WWW 2018: The 2018 Web
          Conference,</em> <em>April 23–27, 2018,</em> <em>Lyon,
          France. ACM, New York, NY, USA</em> 10 Pages. <a href=
          "https://doi.org/10.1145/3178876.3186150" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3178876.3186150</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Recommender systems are an integral component of the web.
      In a typical recommendation system, we observe how a set of
      users interacts with a set of items. Using this data, we seek
      to show users a set of previously unseen items they will
      like. As the web grows in size, good recommendation systems
      will play an important part in helping users interact more
      effectively with larger amounts of content.</p>
      <p>Collaborative filtering is among the most widely applied
      approaches in recommender systems. Collaborative filtering
      predicts what items a user will prefer by discovering and
      exploiting the similarity patterns across users and items.
      Latent factor models [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0038">38</a>] still largely dominate the
      collaborative filtering research literature due to their
      simplicity and effectiveness. However, these models are
      inherently linear, which limits their modeling capacity.
      Previous work [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0027">27</a>] has demonstrated that adding
      carefully crafted non-linear features into the linear latent
      factor models can significantly boost recommendation
      performance. Recently, a growing body of work involves
      applying neural networks to the collaborative filtering
      setting with promising results [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0051">51</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0054">54</a>].</p>
      <p>Here, we extend VAE [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0024">24</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0037">37</a>] to collaborative filtering for
      implicit feedback. VAE generalize linear latent-factor models
      and enable us to explore non-linear probabilistic
      latent-variable models, powered by neural networks, on
      large-scale recommendation datasets. We propose a neural
      generative model with multinomial conditional likelihood.
      Despite being widely used in language modeling and economics
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0005">5</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0030">30</a>],
      multinomial likelihoods appear less studied in the
      collaborative filtering literature, particularly within the
      context of latent-factor models. Recommender systems are
      often evaluated using ranking-based measures, such as mean
      average precision and normalized discounted cumulative gain
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0021">21</a>].
      Top-<em>N</em> ranking loss is difficult to optimize directly
      and previous work on direct ranking loss minimization resorts
      to relaxations and approximations [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0049">49</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0050">50</a>]. Here, we show that the
      multinomial likelihoods are well-suited for modeling implicit
      feedback data, and are a closer proxy to the ranking loss
      relative to more popular likelihood functions such as
      Gaussian and logistic.</p>
      <p>Though recommendation is often considered a big-data
      problem (due to the huge numbers of users and items typically
      present in a recommender system), we argue that, in contrast,
      it represents a uniquely challenging “small-data” problem:
      most users only interact with a tiny proportion of the items
      and our goal is to collectively make informed inference about
      each user's preference. To make use of the sparse signals
      from users and avoid overfitting, we build a probabilistic
      latent-variable model that shares statistical strength among
      users and items. Empirically, we show that employing a
      principled Bayesian approach is more robust regardless of the
      scarcity of the data.</p>
      <p>Although VAE have been extensively studied for image
      modeling and generation, there is surprisingly little work
      applying VAE to recommender systems. We find that two
      adjustments are essential to getting state-of-the-art results
      with VAE on this task:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">First, we use a multinomial
        likelihood for the data distribution. We show that this
        simple choice realizes models that outperform the more
        commonly used Gaussian and logistic likelihoods.<br /></li>
        <li id="list2" label="•">Second, we reinterpret and adjust
        the standard VAE objective, which we argue is
        over-regularized. We draw connections between the learning
        algorithm resulting from our proposed regularization and
        the information-bottleneck principle and maximum-entropy
        discrimination.<br /></li>
      </ul>
      <p>The result is a recipe that makes VAE practical solutions
      to this important problem. Empirically, our methods
      significantly outperform state-of-the-art baselines on
      several real-world datasets, including two recently proposed
      neural-network approaches.</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Method</h2>
        </div>
      </header>
      <p>We use <em>u</em> ∈ {1, …, <em>U</em>} to index users and
      <em>i</em> ∈ {1, …, <em>I</em>} to index items. In this work,
      we consider learning with implicit feedback [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0019">19</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0034">34</a>]. The user-by-item
      interaction matrix is the click<a class="fn" href="#fn1" id=
      "foot-fn1"><sup>1</sup></a> matrix <span class=
      "inline-equation"><span class="tex">$\mathbf {X}\in \mathbb
      {N}^{U \times I}$</span></span> . The lower case <span class=
      "inline-equation"><span class="tex">$\mathbf {x}_u = [x_{u1},
      \dots , x_{uI}]^\top \in \mathbb {N}^I$</span></span> is a
      bag-of-words vector with the number of clicks for each item
      from user <em>u</em>. For simplicity, we binarize the click
      matrix. It is straightforward to extend it to general count
      data.</p>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Model</h3>
          </div>
        </header>
        <p>The generative process we consider in this paper is
        similar to the deep latent Gaussian model [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0037">37</a>]. For each user
        <em>u</em>, the model starts by sampling a
        <em>K</em>-dimensional latent representation
        <strong>z</strong> <sub><em>u</em></sub> from a standard
        Gaussian prior. The latent representation
        <strong>z</strong> <sub><em>u</em></sub> is transformed via
        a non-linear function <span class=
        "inline-equation"><span class="tex">$f_\theta (\cdot) \in
        \mathbb {R}^I$</span></span> to produce a probability
        distribution over <em>I</em> items
        <em>π</em>(<strong>z</strong> <sub><em>u</em></sub> ) from
        which the click history <strong>x</strong>
        <sub><em>u</em></sub> is assumed to have been drawn:</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            \mathbf {z}_u \sim \mathcal {N}(&amp;0, \mathbf {I}_K),
            \quad \pi (\mathbf {z}_u) \propto \exp \lbrace f_\theta
            (\mathbf {z}_u)\rbrace ,\\ &amp;\mathbf {x}_u \sim
            \mathrm{Mult}(N_u, \pi (\mathbf {z}_u)). \end{split}
            \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>The non-linear function <em>f<sub>θ</sub></em> (·) is
        a multilayer perceptron with parameters <em>θ</em>. The
        output of this transformation is normalized via a softmax
        function to produce a probability vector <span class=
        "inline-equation"><span class="tex">$\pi (\mathbf {z}_u)
        \in \mathbb {S}^{I-1}$</span></span> (an (<em>I</em> −
        1)-simplex) over the entire item set. Given the total
        number of clicks <em>N<sub>u</sub></em> = ∑
        <sub><em>i</em></sub> <em>x<sub>ui</sub></em> from user
        <em>u</em>, the observed bag-of-words vector
        <strong>x</strong> <sub><em>u</em></sub> is assumed to be
        sampled from a multinomial distribution with probability
        <em>π</em>(<strong>z</strong> <sub><em>u</em></sub> ). This
        generative model generalizes the latent-factor model — we
        can recover classical matrix factorization [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0038">38</a>] by setting
        <em>f<sub>θ</sub></em> (·) to be linear and using a
        Gaussian likelihood.
        <p></p>
        <p>The log-likelihood for user <em>u</em> (conditioned on
        the latent representation) is:</p>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \log p_\theta
            (\mathbf {x}_u \,\vert \,\mathbf {z}_u) \overset{c}{=}
            \sum _i x_{ui} \log \pi _i(\mathbf {z}_u).
            \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>This multinomial likelihood is commonly used in
        language models, e.g., latent Dirichlet allocation
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0005">5</a>], and
        economics, e.g., multinomial logit choice model [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0030">30</a>]. It is
        also used in the cross-entropy loss<a class="fn" href=
        "#fn2" id="foot-fn2"><sup>2</sup></a> for multi-class
        classification. For example, it has been used in recurrent
        neural networks for session-based sequential recommendation
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0008">8</a>, <a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0015">15</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0016">16</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0042">42</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0045">45</a>] and in
        feedward neural networks applied to Youtube recommendation
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0009">9</a>]. The
        multinomial likelihood is less well studied in the context
        of latent-factor models such as matrix factorization and
        autoencoders. A notable exception is the collaborative
        competitive filtering (CCF) model [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0053">53</a>] and its successors,
        which take advantage of more fine-grained information about
        what options were presented to which users. (If such
        information is available, it can also be incorporated into
        our VAE-based approach.)
        <p></p>
        <p>We believe the multinomial distribution is well suited
        to modeling click data. The likelihood of the click matrix
        (Eq. <a class="eqn" href="#eq2">2</a>) rewards the model
        for putting probability mass on the non-zero entries in
        <strong>x</strong> <sub><em>u</em></sub> . But the model
        has a limited budget of probability mass, since
        <em>π</em>(<strong>z</strong> <sub><em>u</em></sub> ) must
        sum to 1; the items must compete for this limited budget
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0053">53</a>]. The
        model should therefore assign more probability mass to
        items that are more likely to be clicked. To the extent
        that it can, it will perform well under the top-<em>N</em>
        ranking loss that recommender systems are commonly
        evaluated on.</p>
        <p>By way of comparison, we present two popular choices of
        likelihood functions used in latent-factor collaborative
        filtering: Gaussian and logistic likelihoods. Define
        <em>f<sub>θ</sub></em> (<strong>z</strong>
        <sub><em>u</em></sub> ) ≡ [<em>f</em>
        <sub><em>u</em>1</sub>, …, <em>f<sub>uI</sub></em>
        ]<sup>⊤</sup> as the output of the generative function
        <em>f<sub>θ</sub></em> (·). The Gaussian log-likelihood for
        user <em>u</em> is</p>
        <div class="table-responsive" id="eq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \log p_\theta
            (\mathbf {x}_u \,\vert \,\mathbf {z}_u) \overset{c}{=}
            -\sum _i \frac{c_{ui}}{2} (x_{ui} - f_{ui})^2.
            \end{equation}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>We adopt the convention in Hu et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0019">19</a>] and
        introduce a “confidence” weight <span class=
        "inline-equation"><span class="tex">$c_{x_{ui}} \equiv
        c_{ui}$</span></span> where <em>c</em> <sub>1</sub> &gt;
        <em>c</em> <sub>0</sub> to balance the unobserved 0’s which
        far outnumber the observed 1’s in most click data. This is
        also equivalent to training the model with unweighted
        Gaussian likelihood and negative sampling. The logistic
        log-likelihood<a class="fn" href="#fn3" id=
        "foot-fn3"><sup>3</sup></a> for user <em>u</em> is
        <div class="table-responsive" id="eq4">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \log p_\theta
            (\mathbf {x}_u \,\vert \,\mathbf {z}_u) = \sum _i
            x_{ui} \log \sigma (f_{ui}) + (1 - x_{ui}) \log (1 -
            \sigma (f_{ui})), \end{equation}</span><br />
            <span class="equation-number">(4)</span>
          </div>
        </div>where <em>σ</em>(<em>x</em>) = 1/(1 + exp (−
        <em>x</em>)) is the logistic function. We compare
        multinomial likelihood with Gaussian and logistic in
        Section <a class="sec" href="#sec-15">4</a>.
        <p></p>
      </section>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Variational
            inference</h3>
          </div>
        </header>
        <p>To learn the generative model in Eq. <a class="eqn"
        href="#eq1">1</a>, we are interested in estimating
        <em>θ</em> (the parameters of <em>f<sub>θ</sub></em> (·)).
        To do so, for each data point we need to approximate the
        intractable posterior distribution
        <em>p</em>(<strong>z</strong> <sub><em>u</em></sub>
         | <strong>x</strong> <sub><em>u</em></sub> ). We resort to
        variational inference [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0022">22</a>]. Variational inference
        approximates the true intractable posterior with a simpler
        variational distribution <em>q</em>(<strong>z</strong>
        <sub><em>u</em></sub> ). We set
        <em>q</em>(<strong>z</strong> <sub><em>u</em></sub> ) to be
        a fully factorized (diagonal) Gaussian distribution:</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\[ q(\mathbf {z}_u) = \mathcal
            {N}(\mathbf {\mu }_u, \mathrm{diag}\lbrace \mathbf
            {\sigma }_u^2\rbrace). \]</span><br />
          </div>
        </div>The objective of variational inference is to optimize
        the free variational parameters <span class=
        "inline-equation"><span class="tex">$\lbrace \mathbf {\mu
        }_u, \mathbf {\sigma }_u^2\rbrace$</span></span> so that
        the Kullback-Leiber divergence
        KL(<em>q</em>(<strong>z</strong> <sub><em>u</em></sub>
        )‖<em>p</em>(<strong>z</strong> <sub><em>u</em></sub>
        |<strong>x</strong> <sub><em>u</em></sub> )) is minimized.
        <p></p>
        <section id="sec-9">
          <p><em>2.2.1 Amortized inference and the variational
          autoencoder:.</em> With variational inference the number
          of parameters to optimize <span class=
          "inline-equation"><span class="tex">$\lbrace \mathbf {\mu
          }_u, \mathbf {\sigma }_u^2\rbrace$</span></span> grows
          with the number of users and items in the dataset. This
          can become a bottleneck for commercial recommender
          systems with millions of users and items. The VAE
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0024">24</a>, <a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0037">37</a>] replaces individual variational
          parameters with a data-dependent function (commonly
          called an <em>inference model</em>):</p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\[ g_\phi (\mathbf {x}_u)
              \equiv [\mu _\phi (\mathbf {x}_u), \sigma _\phi
              (\mathbf {x}_u)] \in \mathbb {R}^{2K} \]</span><br />
            </div>
          </div>parametrized by <em>ϕ</em> with both
          <em>μ<sub>ϕ</sub></em> (<strong>x</strong>
          <sub><em>u</em></sub> ) and <em>σ<sub>ϕ</sub></em>
          (<strong>x</strong> <sub><em>u</em></sub> ) being
          <em>K</em>-vectors and sets the variational distribution
          as follows:
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\[ q_\phi (\mathbf {z}_u
              \,\vert \,\mathbf {x}_u) = \mathcal {N}(\mu _\phi
              (\mathbf {x}_u), \mathrm{diag}\lbrace \sigma _\phi
              ^2(\mathbf {x}_u)\rbrace). \]</span><br />
            </div>
          </div>That is, using the observed data <strong>x</strong>
          <sub><em>u</em></sub> as input, the inference model
          outputs the corresponding variational parameters of
          variational distribution <em>q<sub>ϕ</sub></em>
          (<strong>z</strong> <sub><em>u</em></sub>
           | <strong>x</strong> <sub><em>u</em></sub> ), which,
          when optimized, approximates the intractable posterior
          <em>p</em>(<strong>z</strong> <sub><em>u</em></sub>
           | <strong>x</strong> <sub><em>u</em></sub> ).<a class=
          "fn" href="#fn4" id="foot-fn4"><sup>4</sup></a>Putting
          <em>q<sub>ϕ</sub></em> (<strong>z</strong>
          <sub><em>u</em></sub>  | <strong>x</strong>
          <sub><em>u</em></sub> ) and the generative model
          <em>p<sub>θ</sub></em> (<strong>x</strong>
          <sub><em>u</em></sub>  | <strong>z</strong>
          <sub><em>u</em></sub> ) together in Figure <a class="fig"
          href="#fig2">2</a> c, we end up with a neural
          architecture that resembles an autoencoder — hence the
          name variational autoencoder.
          <p></p>
          <p>VAE make use of amortized inference [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0012">12</a>]: they
          flexibly reuse inferences to answer related new problems.
          This is well aligned with the ethos of collaborative
          filtering: analyze user preferences by exploiting the
          similarity patterns inferred from past experiences. In
          Section <a class="sec" href="#sec-13">2.4</a>, we discuss
          how this enables us to perform prediction
          efficiently.</p>
          <p><strong>Learning VAE:</strong> &nbsp; As is standard
          when learning latent-variable models with variational
          inference [<a class="bib" data-trigger="hover"
          data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0004">4</a>], we can lower-bound the log
          marginal likelihood of the data. This forms the objective
          we seek to maximize for user <em>u</em> (the objective
          function of the dataset is obtained by averaging the
          objective function over all the users):</p>
          <div class="table-responsive" id="eq5">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation}
              \begin{split} \log p(\mathbf {x}_u; \theta) &amp;\ge
              \mathbb {E}_{q_\phi (\mathbf {z}_u \,\vert \,\mathbf
              {x}_u)}\left[\log p_\theta (\mathbf {x}_u \,\vert
              \,\mathbf {z}_u)\right] - \mathrm{KL}(q_\phi (\mathbf
              {z}_u \,\vert \,\mathbf {x}_u) \Vert p(\mathbf
              {z}_u))\\ &amp;\equiv \mathcal {L}(\mathbf {x}_u;
              \theta , \phi) \end{split}
              \end{equation}</span><br />
              <span class="equation-number">(5)</span>
            </div>
          </div>This is commonly known as the ELBO. Note that the
          ELBO is a function of both <em>θ</em> and <em>ϕ</em>. We
          can obtain an unbiased estimate of ELBO by sampling
          <strong>z</strong> <sub><em>u</em></sub> ∼
          <em>q<sub>ϕ</sub></em> and perform stochastic gradient
          ascent to optimize it. However, the challenge is that we
          cannot trivially take gradients with respect to
          <em>ϕ</em> through this sampling process. The
          <em>reparametrization trick</em> [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0024">24</a>,
          <a class="bib" data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0037">37</a>]
          sidesteps this issue: we sample <span class=
          "inline-equation"><span class="tex">$\mathbf {\epsilon
          }\sim \mathcal {N}(0, \mathbf {I}_K)$</span></span> and
          reparametrize <strong>z</strong> <sub><em>u</em></sub> =
          <em>μ<sub>ϕ</sub></em> (<strong>x</strong>
          <sub><em>u</em></sub> ) +
          <strong>ϵ</strong>⊙<em>σ<sub>ϕ</sub></em>
          (<strong>x</strong> <sub><em>u</em></sub> ). By doing so,
          the stochasticity in the sampling process is isolated and
          the gradient with respect to <em>ϕ</em> can be
          back-propagated through the sampled <strong>z</strong>
          <sub><em>u</em></sub> . The VAE training procedure is
          summarized in Algorithm 1.
          <p></p>
          <p><img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186150/images/www2018-159-img1.svg"
          class="img-responsive" alt="" longdesc="" /></p>
        </section>
        <section id="sec-10">
          <p><em>2.2.2 Alternative interpretation of ELBO.</em> We
          can view ELBO defined in Eq. <a class="eqn" href=
          "#eq5">5</a> from a different perspective: the first term
          can be interpreted as (negative) reconstruction error,
          while the second KL term can be viewed as regularization.
          It is this perspective we work with because it allows us
          to make a trade-off that forms the crux of our method.
          From this perspective, it is natural to extend the ELBO
          by introducing a parameter <em>β</em> to control the
          strength of regularization:</p>
          <div class="table-responsive" id="eq6">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation}
              \begin{split} \mathcal {L}_\beta (\mathbf {x}_u;
              \theta , \phi) \equiv \mathbb {E}_{q_\phi (\mathbf
              {z}_u \,\vert \,\mathbf {x}_u)}[&amp;\log p_\theta
              (\mathbf {x}_u \,\vert \,\mathbf {z}_u)] \\ -&amp;
              \beta \cdot \mathrm{KL}(q_\phi (\mathbf {z}_u \,\vert
              \,\mathbf {x}_u) \Vert p(\mathbf {z}_u)). \end{split}
              \end{equation}</span><br />
              <span class="equation-number">(6)</span>
            </div>
          </div>
          <p></p>
          <p>While the original VAE (trained with ELBO in Eq.
          <a class="eqn" href="#eq5">5</a>) is a powerful
          generative model; we might ask whether we need
          <em>all</em> the statistical properties of a generative
          model for tackling problems in recommender systems. In
          particular, if we are willing to sacrifice the ability to
          perform ancestral sampling, can we improve our
          performance? The regularization view of the ELBO (Eq.
          <a class="eqn" href="#eq6">6</a>) introduces a trade-off
          between how well we can fit the data and how close the
          approximate posterior stays to the prior during
          learning.</p>
          <p>We propose using <em>β</em> ≠ 1. This means we are no
          longer optimizing a lower bound on the log marginal
          likelihood. If <em>β</em> &lt; 1, then we are also
          weakening the influence of the prior constraint
          <span class="inline-equation"><span class=
          "tex">$\frac{1}{U}\sum _u q(\mathbf {z}\,\vert \,\mathbf
          {x}_u)\approx p(\mathbf {z}) = \mathcal {N}(\mathbf {z};
          0, \mathbf {I}_K)$</span></span> [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0018">18</a>]; this
          means that the model is less able to generate novel user
          histories by ancestral sampling.</p>
          <p>But ultimately our goal is to make good
          recommendations, not to maximize likelihood or generate
          imagined user histories. Treating <em>β</em> as a free
          regularization parameter therefore costs us nothing, and,
          as we will see, yields significant improvements in
          performance.</p>
          <p><strong>Selecting <em>β</em>:</strong>&nbsp; We
          propose a simple heuristic for setting <em>β</em>: we
          start training with <em>β</em> = 0, and gradually
          increase <em>β</em> to 1. We linearly anneal the KL term
          slowly over a large number of gradient updates to
          <em>θ</em>, <em>ϕ</em> and record the best <em>β</em>
          when its performance reaches the peak. We found this
          method to work well and it does not require the need for
          training multiple models with different values of
          <em>β</em>, which can be time-consuming. Our procedure is
          inspired by KL annealing [<a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0007">7</a>], a common heuristic used for
          training VAE when there is concern that the model is
          being underutilized.</p>
          <p>Figure <a class="fig" href="#fig1">1</a> illustrates
          the basic idea (we observe the same trend consistently
          across datasets). Here we plot the validation ranking
          metric without KL annealing (blue solid) and with KL
          annealing all the way to <em>β</em> = 1 (green dashed,
          <em>β</em> reaches 1 at around 80 epochs). As we can see,
          the performance is poor without any KL annealing. With
          annealing, the validation performance first increases as
          the training proceeds and then drops as <em>β</em> gets
          close to 1 to a value that is only slightly better than
          doing no annealing at all.</p>
          <p>Having identified the best <em>β</em> based on the
          peak validation metric, we can retrain the model with the
          same annealing schedule, but stop increasing <em>β</em>
          after reaching that value (shown as red dot-dashed in
          Figure <a class="fig" href="#fig1">1</a>).<a class="fn"
          href="#fn5" id="foot-fn5"><sup>5</sup></a> This might be
          sub-optimal compared to a thorough grid search. However,
          it is much more efficient, and gives us competitive
          empirical performance. If the computational budget is
          scarce, then within a single run, we can stop increasing
          <em>β</em> when we notice the validation metric dropping.
          Such a procedure incurs no additional runtime to learning
          a standard VAE. We denote this partially regularized VAE
          with multinomial likelihood as Mult-<span class=
          "inline-equation"><span class="tex">${\rm\small
          VAE}^{\rm\small PR}$</span></span> .</p>
          <figure id="fig1">
            <img src=
            "../../../data/deliveryimages.acm.org/10.1145/3190000/3186150/images/www2018-159-fig1.jpg"
            class="img-responsive" alt="Figure 1" longdesc="" />
            <div class="figure-caption">
              <span class="figure-number">Figure 1:</span>
              <span class="figure-title">Validation ranking metrics
              with different annealing configurations. For the
              green dashed curve, <em>β</em> reaches 1 at around 80
              epochs.</span>
            </div>
          </figure>
          <p></p>
        </section>
        <section id="sec-11">
          <p><em>2.2.3 Computational Burden.</em> Previous
          collaborative filtering models with neural networks
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0014">14</a>, <a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0051">51</a>] are trained with stochastic
          gradient descent where in each step a single (user, item)
          entry from the click matrix is randomly sampled to
          perform a gradient update. In Algorithm 1 we subsample
          users and take their entire click history (complete rows
          of the click matrix) to update model parameters. This
          eliminates the necessity of negative sampling (and
          consequently the hyperparameter tuning for picking the
          number of negative examples), commonly used in the (user,
          item) entry subsampling scheme.</p>
          <p>A computational challenge that comes with our
          approach, however, is that when the number of items is
          huge, computing the multinomial probability
          <em>π</em>(<strong>z</strong> <sub><em>u</em></sub> )
          could be computationally expensive, since it requires
          computing the predictions for all the items for
          normalization. This is a common challenge for language
          modeling where the size of the vocabulary is in the order
          of millions or more [<a class="bib" data-trigger="hover"
          data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0032">32</a>]. In our experiments on some
          medium-to-large datasets with less than 50K items
          (Section <a class="sec" href="#sec-16">4.1</a>), this has
          not yet come up as a computational bottleneck. If this
          becomes a bottleneck when working with larger item sets,
          one can easily apply the simple and effective method
          proposed by Botev et&nbsp;al. [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0006">6</a>] to
          approximate the normalization factor for
          <em>π</em>(<strong>z</strong> <sub><em>u</em></sub>
          ).</p>
        </section>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.3</span> A taxonomy
            of autoencoders</h3>
          </div>
        </header>
        <p>In Section <a class="sec" href="#sec-8">2.2</a>, we
        introduced maximum marginal likelihood estimation of VAE
        using approximate Bayesian inference under a non-linear
        generative model (Eq. <a class="eqn" href="#eq1">1</a>). We
        now describe our work from the perspective of learning
        autoencoders. Maximum-likelihood estimation in a regular
        autoencoder takes the following form:</p>
        <div class="table-responsive" id="eq7">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            \theta ^{\mathrm{AE}}, \phi ^{\mathrm{AE}}
            =&amp;\mathop{arg\,max}_{\theta , \phi } \sum _u
            \mathbb {E}_{\delta (\mathbf {z}_u - g_\phi (\mathbf
            {x}_u))}\left[\log p_\theta (\mathbf {x}_u \,\vert
            \,\mathbf {z}_u)\right]\\ =
            &amp;\mathop{arg\,max}_{\theta , \phi } \sum _u \log
            p_\theta (\mathbf {x}_u \,\vert \,g_\phi (\mathbf
            {x}_u)) \end{split} \end{equation}</span><br />
            <span class="equation-number">(7)</span>
          </div>
        </div>There are two key distinctions of note: (1) The
        autoencoder (and denoising autoencoder) effectively
        optimizes the first term in the VAE objective (Eq.
        <a class="eqn" href="#eq5">5</a> and Eq. <a class="eqn"
        href="#eq6">6</a>) using a delta variational distribution
        <em>q<sub>ϕ</sub></em> (<strong>z</strong>
        <sub><em>u</em></sub>  | <strong>x</strong>
        <sub><em>u</em></sub> ) = <em>δ</em>(<strong>z</strong>
        <sub><em>u</em></sub> − <em>g<sub>ϕ</sub></em>
        (<strong>x</strong> <sub><em>u</em></sub> )) — it does not
        regularize <em>q<sub>ϕ</sub></em> (<strong>z</strong>
        <sub><em>u</em></sub>  | <strong>x</strong>
        <sub><em>u</em></sub> ) towards any prior distribution as
        the VAE does. (2) the <em>δ</em>(<strong>z</strong>
        <sub><em>u</em></sub> − <em>g<sub>ϕ</sub></em>
        (<strong>x</strong> <sub><em>u</em></sub> )) is a
        <em>δ</em> distribution with mass only at the output of
        <em>g<sub>ϕ</sub></em> (<strong>x</strong>
        <sub><em>u</em></sub> ). Contrast this to the VAE, where
        the learning is done using a variational
        <em>distribution</em>, i.e., <em>g<sub>ϕ</sub></em>
        (<strong>x</strong> <sub><em>u</em></sub> ) outputs the
        parameters (mean and variance) of a Gaussian distribution.
        This means that VAE has the ability to capture
        per-data-point variances in the latent state
        <strong>z</strong> <sub><em>u</em></sub> .
        <p></p>
        <p>In practice, we find that learning autoencoders is
        extremely prone to overfitting as the network learns to put
        all the probability mass to the non-zero entries in
        <strong>x</strong> <sub><em>u</em></sub> . By introducing
        dropout [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0043">43</a>] at the input layer, the DAE is
        less prone to overfitting and we find that it also gives
        competitive empirical results. In addition to the
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> , we
        also study a denoising autoencoder with a multinomial
        likelihood. We denote this model Mult-DAE. In Section
        <a class="sec" href="#sec-15">4</a> we characterize the
        tradeoffs in what is gained and lost by explicitly
        parameterizing the per-user variance with Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp;versus using a
        point-estimation in Mult-DAE.</p>
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186150/images/www2018-159-fig2.jpg"
          class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">A taxonomy of autoencoders.
            The dotted arrows denote a sampling operation.</span>
          </div>
        </figure>
        <p></p>
        <p>To provide a unified view of different variants of
        autoencoders and clarify where our work stands, we depict
        variants of autoencoders commonly found in the literature
        in Figure <a class="fig" href="#fig2">2</a>. For each one,
        we specify the model (dotted arrows denote a sampling
        operation) and describe the training objective used in
        parameter estimation.</p>
        <p>In Figure <a class="fig" href="#fig2">2</a> a we have
        autoencoder. It is trained to reconstruct input with the
        same objective as in Eq. <a class="eqn" href="#eq7">7</a>.
        Adding noise to the input (or the intermediate hidden
        representation) of an autoencoder yields the denoising
        autoencoder in Figure <a class="fig" href="#fig2">2</a> b.
        The training objective is the same as that of an
        autoencoder. Mult-DAE&nbsp;belongs to this model class.
        CDAE [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0051">51</a>] is a variant of this model class.
        The VAE is depicted in Figure <a class="fig" href=
        "#fig2">2</a> c. Rather than using a delta variational
        distribution, it uses an inference model parametrized by
        <em>ϕ</em> to produce the mean and variance of the
        approximating variational distribution. The training
        objective of the VAE is given in Eq. <a class="eqn" href=
        "#eq6">6</a>. Setting <em>β</em> to 1 recovers the original
        VAE formulation [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0024">24</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0037">37</a>]. Higgins et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0017">17</a>] study
        the case where <em>β</em> &gt; 1. Our model,
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        corresponds to learning VAE with <em>β</em> ∈ [0, 1].</p>
      </section>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.4</span>
            Prediction</h3>
          </div>
        </header>
        <p>We now describe how we make predictions given a trained
        generative model of the form Eq. <a class="eqn" href=
        "#eq1">1</a>. For both, Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; (Section
        <a class="sec" href="#sec-8">2.2</a>) or Mult-DAE&nbsp;
        (Section <a class="sec" href="#sec-12">2.3</a>), we make
        predictions in the same way. Given a user's click history
        <strong>x</strong>, we rank all the items based on the
        un-normalized predicted multinomial probability
        <em>f<sub>θ</sub></em> (<strong>z</strong>). The latent
        representation <strong>z</strong> for <strong>x</strong> is
        constructed as follows: For Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> , we simply take the
        mean of the variational distribution <strong>z</strong> =
        <em>μ<sub>ϕ</sub></em> (<strong>x</strong>); for Mult-DAE,
        we take the output <strong>z</strong> =
        <em>g<sub>ϕ</sub></em> (<em>x</em>).</p>
        <p>It is easy to see the advantage of using autoencoders.
        We can effectively make predictions for users by evaluating
        two functions – the inference model (encoder)
        <em>g<sub>ϕ</sub></em> (·) and the generative model
        (decoder) <em>f<sub>θ</sub></em> (·). For most of the
        latent factor collaborative filtering model, e.g., matrix
        factorization [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0013">13</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0019">19</a>], when given the click history of a
        user that is not present in the training data, normally we
        need to perform some form of optimization to obtain the
        latent factor for this user. This makes the use of
        autoencoders particularly attractive in industrial
        applications, where it is important that predictions be
        made cheaply and with low latency.</p>
      </section>
    </section>
    <section id="sec-14">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Related
          work</h2>
        </div>
      </header>
      <p><strong>VAE on sparse data.</strong>&nbsp; VAE VAE
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0024">24</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0037">37</a>] have seen
      much application to images since their inception. Doersch
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0010">10</a>] presents a
      review on different applications of VAE to image data. Miao
      et&nbsp;al. [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0031">31</a>]
      study VAEs on text data. More recent results from Krishnan
      et&nbsp;al. [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0025">25</a>]
      find that VAE (trained with Eq. <a class="eqn" href=
      "#eq5">5</a>) suffer from underfitting when modeling large,
      sparse, high-dimensional data. We notice similar issues when
      fitting VAE without annealing (Figure <a class="fig" href=
      "#fig1">1</a>) or annealing to <em>β</em> = 1. By giving up
      the ability to perform ancestral sampling in the model, and
      setting <em>β</em> ≤ 1, the resulting model is no longer a
      proper <em>generative</em> model though for collaborative
      filtering tasks we always make predictions <em>conditional
      on</em> users’ click history.</p>
      <p><strong>Information-theoretic connection with
      VAE.</strong>&nbsp; The regularization view of the ELBO in
      Eq. <a class="eqn" href="#eq6">6</a> resembles
      maximum-entropy discrimination [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0020">20</a>]. Maximum-entropy discrimination
      attempts to combine discriminative estimation with Bayesian
      inference and generative modeling. In our case, in Eq.
      <a class="eqn" href="#eq6">6</a>, <em>β</em> acts as a knob
      to balance discriminative and generative aspects of the
      model.</p>
      <p>The procedure in Eq. <a class="eqn" href="#eq6">6</a> has
      information-theoretic connections described in Alemi
      et&nbsp;al. [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0001">1</a>].
      The authors propose the deep variational information
      bottleneck, which is a variational approximation to the
      information bottleneck principle [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0046">46</a>]. They show that as a
      special case they can recover the learning objective used by
      VAE. They report more robust supervised classification
      performance with <em>β</em> &lt; 1. This is consistent with
      our findings as well. Higgins et&nbsp;al. [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0017">17</a>] proposed <em>β</em>-VAE,
      which leads to the same objective as Eq. <a class="eqn" href=
      "#eq6">6</a>. They motivate <em>β</em>-VAE for the goal of
      learning disentangled representations from images (basic
      visual concepts, such as shape, scale, and color). Their
      work, however, sets <em>β</em> ≫ 1, effectively imposing a
      stronger independent prior assumption on the latent code
      <strong>z</strong>. While their motivations are quite
      different from ours, it is interesting to note orthogonal
      lines of research emerging from exploring the full spectrum
      of values for <em>β</em>.</p>
      <p><strong>Neural networks for collaborative
      filtering.</strong>&nbsp; Early work on neural-network-based
      collaborative filtering models focus on explicit feedback
      data and evaluates on the task of rating predictions
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0011">11</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0039">39</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0041">41</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0054">54</a>]. The
      importance of implicit feedback has been gradually
      recognized, and consequently most recent research, such as
      this work, has focused on it. The two papers that are most
      closely related to our approaches are CDAE [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0051">51</a>] and NCF [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0014">14</a>].</p>
      <p>CDAE [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0051">51</a>]
      augments the standard denoising autoencoder, described in
      Section <a class="sec" href="#sec-12">2.3</a>, by adding a
      per-user latent factor to the input. The number of parameters
      of the CDAE model grows linearly with both the number of
      users as well as the number of items, making it more prone to
      overfitting. In contrast, the number of parameters in the VAE
      grows linearly with the number of items. The CDAE also
      requires additional optimization to obtain the latent factor
      for unseen users to make predicion. In the paper, the authors
      investigate the Gaussian and logistic likelihood loss
      functions — as we show, the multinomial likelihood is
      significantly more robust for use in recommender systems. NCF
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0014">14</a>] explore a
      model with non-linear interactions between the user and item
      latent factors rather than the commonly used dot product. The
      authors demonstrate improvements of NCF over standard
      baselines on two small datasets. Similar to CDAE, the number
      of parameters of NCF also grows linearly with both the number
      of users as well as items. We find that this becomes
      problematic for much larger datasets. We compare with both
      CDAE and NCF in Section <a class="sec" href=
      "#sec-15">4</a>.</p>
      <p>Asymmetric matrix factorization [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0035">35</a>] may also be interpreted
      as an autoencoder, as elaborated in Steck [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0044">44</a>]. We can recover this work
      by setting both <em>f<sub>θ</sub></em> (·) and
      <em>g<sub>ϕ</sub></em> (·) to be linear.</p>
      <p>Besides being applied in session-based sequential
      recommendation (see Section <a class="sec" href=
      "#sec-7">2.1</a>), various approaches [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0002">2</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0028">28</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0047">47</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0048">48</a>] have applied neural
      networks to incorporate <em>side information</em> into
      collaborative filtering models to better handle the
      cold-start problem. These approaches are complementary to
      ours.</p>
    </section>
    <section id="sec-15">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Empirical
          Study</h2>
        </div>
      </header>
      <p>We evaluate the performance of Mult-<span class=
      "inline-equation"><span class="tex">${\rm\small
      VAE}^{\rm\small PR}$</span></span> &nbsp;and Mult-DAE. We
      provide insights into their performance by exploring the
      resulting fits. We highlight the following results:</p>
      <ul class="list-no-style">
        <li id="list3" label="•">Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp;achieves
        state-of-the-art results on three real-world datasets when
        compared with various baselines, including recently
        proposed neural-network-based collaborative filtering
        models.<br /></li>
        <li id="list4" label="•">For the denoising and variational
        autoencoder, the multinomial likelihood compares favorably
        over the more common Gaussian and logistic
        likelihoods.<br /></li>
        <li id="list5" label="•">Both Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; and
        Mult-DAE&nbsp; produce competitive empirical results. We
        identify when parameterizing the uncertainty explicitly as
        in Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        does better/worse than the point estimate used by
        Mult-DAE&nbsp; and list pros and cons for both
        approaches.<br /></li>
      </ul>
      <p>The source code to reproduce the experimental results is
      available on GitHub<a class="fn" href="#fn6" id=
      "foot-fn6"><sup>6</sup></a>.</p>
      <section id="sec-16">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span>
            Datasets</h3>
          </div>
        </header>
        <p>We study three medium- to large-scale user-item
        consumption datasets from various domains:</p>
        <p><strong>MovieLens-20M (ML-20M):</strong>&nbsp; These are
        user-movie ratings collected from a movie recommendation
        service. We binarize the explicit data by keeping ratings
        of four or higher and interpret them as implicit feedback.
        We only keep users who have watched at least five
        movies.</p>
        <p><strong>Netflix Prize (Netflix):</strong>&nbsp; This is
        the user-movie ratings data from the Netflix Prize<a class=
        "fn" href="#fn7" id="foot-fn7"><sup>7</sup></a>. Similar to
        ML-20M, we binarize explicit data by keeping ratings of
        four or higher. We only keep users who have watched at
        least five movies.</p>
        <p><strong>Million Song Dataset (MSD):</strong>&nbsp; This
        data contains the user-song play counts released as part of
        the Million Song Dataset [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0003">3</a>]. We binarize play counts and
        interpret them as implicit preference data. We only keep
        users with at least 20 songs in their listening history and
        songs that are listened to by at least 200 users.</p>
        <p>Table <a class="tbl" href="#tab1">1</a> summarizes the
        dimensions of all the datasets after preprocessing.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Attributes of datasets after
            preprocessing. Interactions are non-zero entries. % of
            interactions refers to the density of the user-item
            click matrix <strong>X</strong>. # of the held-out
            users is the number of validation/test users out of the
            total number of users in the first row.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">
                <strong>ML-20M</strong></th>
                <th style="text-align:center;">
                <strong>Netflix</strong></th>
                <th style="text-align:center;">
                <strong>MSD</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;"># of users</td>
                <td style="text-align:center;">136,677</td>
                <td style="text-align:center;">463,435</td>
                <td style="text-align:center;">571,355</td>
              </tr>
              <tr>
                <td style="text-align:left;"># of items</td>
                <td style="text-align:center;">20,108</td>
                <td style="text-align:center;">17,769</td>
                <td style="text-align:center;">41,140</td>
              </tr>
              <tr>
                <td style="text-align:left;"># of interactions</td>
                <td style="text-align:center;">10.0M</td>
                <td style="text-align:center;">56.9M</td>
                <td style="text-align:center;">33.6M</td>
              </tr>
              <tr>
                <td style="text-align:left;">% of interactions</td>
                <td style="text-align:center;">0.36%</td>
                <td style="text-align:center;">0.69%</td>
                <td style="text-align:center;">0.14%</td>
              </tr>
              <tr>
                <td style="text-align:left;"># of held-out
                users</td>
                <td style="text-align:center;">10,000</td>
                <td style="text-align:center;">40,000</td>
                <td style="text-align:center;">50,000</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span>
            Metrics</h3>
          </div>
        </header>
        <p>We use two ranking-based metrics: Recall@<em>R</em> and
        the truncated normalized discounted cumulative gain
        (NDCG@<em>R</em>). For each user, both metrics compare the
        predicted rank of the held-out items with their true rank.
        For both Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        and Mult-DAE, we get the predicted rank by sorting the
        un-normalized multinomial probability
        <em>f<sub>θ</sub></em> (<strong>z</strong>). While
        Recall@<em>R</em> considers all items ranked within the
        first <em>R</em> to be equally important, NDCG@<em>R</em>
        uses a monotonically increasing discount to emphasize the
        importance of higher ranks versus lower ones. Formally,
        define <em>ω</em>(<em>r</em>) as the item at rank
        <em>r</em>, <span class="inline-equation"><span class=
        "tex">$\mathbb {I}[\cdot ]$</span></span> is the indicator
        function, and <em>I<sub>u</sub></em> is the set of held-out
        items that user <em>u</em> clicked on.</p>
        <p>Recall@<em>R</em> for user <em>u</em> is</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\[ \textrm {Recall@}R(u,
            \omega) := \frac{\sum _{r=1}^R \mathbb {I}[\omega (r)
            \in I_u]}{\min (M, |I_u|)}. \]</span><br />
          </div>
        </div>
        <p></p>
        <p>The expression in the denominator is the minimum of
        <em>R</em> and the number of items clicked on by user u.
        This normalizes Recall@<em>R</em> to have a maximum of 1,
        which corresponds to ranking all relevant items in the top
        <em>R</em> positions.</p>
        <p>Truncated discounted cumulative gain (DCG@<em>R</em>)
        is</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\[ \textrm {DCG@}R(u, \omega)
            := \sum _{r=1}^R \frac{2^{\mathbb {I}[\omega (r) \in
            I_u]} - 1}{\log (r+1)}. \]</span><br />
          </div>
        </div>
        <p></p>
        <p>NDCG@<em>R</em> is the DCG@<em>R</em> linearly
        normalized to [0, 1] after dividing by the best possible
        DCG@<em>R</em>, where all the held-out items are ranked at
        the top.</p>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span>
            Experimental setup</h3>
          </div>
        </header>
        <p>We study the performance of various models under strong
        generalization [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0029">29</a>]: We split all users into
        training/validation/test sets. We train models using the
        entire click history of the training users. To evaluate, we
        take part of the click history from held-out (validation
        and test) users to learn the necessary user-level
        representations for the model and then compute metrics by
        looking at how well the model ranks the rest of the unseen
        click history from the held-out users.</p>
        <p>This is relatively more difficult than weak
        generalization where the user's click history can appear
        during both training and evaluation. We consider it more
        realistic and robust as well. In the last row of Table
        <a class="tbl" href="#tab1">1</a>, we list the number of
        held-out users (we use the same number of users for
        validation and test). For each held-out user, we randomly
        choose 80% of the click history as the “fold-in” set to
        learn the necessary user-level representation and report
        metrics on the remaining 20% of the click history.</p>
        <p>We select model hyperparameters and architectures by
        evaluating NDCG@100 on the validation users. For both
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        and Mult-DAE, we keep the architecture for the generative
        model <em>f<sub>θ</sub></em> (·) and the inference model
        <em>g<sub>ϕ</sub></em> (·) symmetrical and explore MLP with
        0, 1, and 2 hidden layers. We set the dimension of the
        latent representation <em>K</em> to 200 and any hidden
        layer to 600. As a concrete example, recall <em>I</em> is
        the total number of items, the overall architecture for a
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span>
        /Mult-DAE&nbsp; with 1-hidden-layer MLP generative model
        would be [<em>I</em> → 600 → 200 → 600 → <em>I</em>]. We
        find that going deeper does not improve performance. The
        best performing architectures are MLP with either 0 or 1
        hidden layers. We use a tanh non-linearity as the
        activation function between layers. Note that for
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> ,
        since the output of <em>g<sub>ϕ</sub></em> (·) is used as
        the mean and variance of a Gaussian random variable, we do
        not apply an activation function to it. Thus, the
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        with 0-hidden-layer MLP is effectively a log-linear model.
        We tune the regularization parameter <em>β</em> for
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        following the procedure described in Section <a class="sec"
        href="#sec-10">2.2.2</a>. We anneal the Kullback-Leibler
        term linearly for 200,000 gradient updates. For both
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        and Mult-DAE, we apply dropout at the input layer with
        probability 0.5. We apply a weight decay of 0.01 for
        Mult-DAE. We do not apply weight decay for any VAE models.
        We train both Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; and
        Mult-DAE&nbsp; using Adam [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0023">23</a>] with batch size of 500 users. For
        ML-20M, we train for 200 epochs. We train for 100 epochs on
        the other two datasets. We keep the model with the best
        validation NDCG@100 and report test set metrics with
        it.</p>
      </section>
      <section id="sec-19">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.4</span>
            Baselines</h3>
          </div>
        </header>
        <p>We compare results with the following standard
        state-of-the-art collaborative filtering models, both
        linear and non-linear:</p>
        <p>Weighted matrix factorization
        (<strong>WMF</strong>)&nbsp; [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0019">19</a>]: a linear low-rank factorization
        model. We train WMF with alternating least squares; this
        generally leads to better performance than with SGD. We set
        the weights on all the 0’s to 1 and tune the weights on all
        the 1’s in the click matrix among {2, 5, 10, 30, 50, 100},
        as well as the latent representation dimension <em>K</em> ∈
        {100, 200} by evaluating NDCG@100 on validation users.</p>
        <p><font style=
        "font-variant: small-caps"><strong>Slim</strong></font>
        &nbsp; [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0033">33</a>]: a linear model which learns a
        sparse item-to-item similarity matrix by solving a
        constrained ℓ<sub>1</sub>-regularized optimization problem.
        We grid-search both of the regularization parameters over
        {0.1, 0.5, 1, 5} and report the setting with the best
        NDCG@100 on validation users. We did not evaluate
        <font style="font-variant: small-caps">Slim</font> on MSD
        because the dataset is too large for it to finish in a
        reasonable amount of time (for the Netflix dataset, the
        parallelized grid search took about two weeks). We also
        found that the faster approximation of <font style=
        "font-variant: small-caps">Slim</font> [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0026">26</a>] did not yield
        competitive performance.</p>
        <p>Collaborative denoising autoencoder
        (<strong>CDAE</strong>)&nbsp; [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0051">51</a>]: augments the standard denoising
        autoencoder by adding a per-user latent factor to the
        input. We change the (user, item) entry subsampling
        strategy in SGD training in the original paper to the
        user-level subsampling as we did with Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; and Mult-DAE. We
        generally find that this leads to more stable convergence
        and better performance. We set the dimension of the
        bottleneck layer to 200, and use a weighted square loss,
        equivalent to what the square loss with negative sampling
        used in the original paper. We apply tanh activation at
        both the bottleneck layer as well as the output
        layer.<a class="fn" href="#fn8" id=
        "foot-fn8"><sup>8</sup></a> We use Adam with a batch size
        of 500 users. As mentioned in Section <a class="sec" href=
        "#sec-14">3</a>, the number of parameters for CDAE grows
        linearly with the number of users and items. Thus, it is
        crucial to control overfitting by applying weight decay. We
        select the weight decay parameter over {0.01, 0.1, ⋅⋅⋅,
        100} by examining the validation NDCG@100.</p>
        <p>Neural collaborative filtering
        (<strong>NCF</strong>)&nbsp; [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0014">14</a>]: explores non-linear interactions
        (via a neural network) between the user and item latent
        factors. Similar to CDAE, the number of parameters for NCF
        grows linearly with the number of users and items. We use
        the publicly available source code provided by the authors,
        yet cannot obtain competitive performance on the datasets
        used in this paper — the validation metrics drop within the
        first few epochs over a wide range of regularization
        parameters. The authors kindly provided the two datasets
        (ML-1M and Pinterest) used in the original paper, as well
        as the training/test split, therefore we separately compare
        with NCF on these two relatively smaller datasets in the
        empirical study. In particular, we compare with the hybrid
        NeuCF model which gives the best performance in He
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0014">14</a>], both with and without
        pre-training.</p>
        <p>We also experiment with BPR [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0036">36</a>]. However, the
        performance is not on par with the other baselines above.
        This is consistent with some other studies with similar
        baselines [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0040">40</a>]. Therefore, we do not include BPR
        in the following results and analysis.</p>
      </section>
      <section id="sec-20">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.5</span>
            Experimental results and analysis</h3>
          </div>
        </header>
        <p>In this section, we quantitatively compare our proposed
        methods with various baselines. In addition, we aim to
        answer the following two questions:</p>
        <ol class="list-no-style">
          <li id="list6" label="1.">How does multinomial likelihood
          compare with other commonly used likelihood models for
          collaborative filtering?<br /></li>
          <li id="list7" label="2.">When does Mult-<span class=
          "inline-equation"><span class="tex">${\rm\small
          VAE}^{\rm\small PR}$</span></span> &nbsp; perform
          better/worse than Mult-DAE?<br /></li>
        </ol>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Comparison between various baselines and
            our proposed methods. Standard errors are around 0.002
            for ML-20M and 0.001 for Netflix and MSD. Both
            Mult-<span class="inline-equation"><span class=
            "tex">${\rm\small VAE}^{\rm\small PR}$</span></span>
            &nbsp; and Mult-DAE&nbsp; significantly outperform the
            baselines across datasets and metrics. We could not
            finish <font style=
            "font-variant: small-caps">Slim</font> within a
            reasonable amount of time on MSD.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th colspan="4" style="text-align:center;">
                  (a) ML-20M
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">Recall@20</th>
                <th style="text-align:center;">Recall@50</th>
                <th style="text-align:center;">NDCG@100</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Mult-<span class=
                "inline-equation"><span class="tex">${\rm\small
                VAE}^{\rm\small PR}$</span></span></td>
                <td style="text-align:center;">
                <strong>0.395</strong></td>
                <td style="text-align:center;">
                <strong>0.537</strong></td>
                <td style="text-align:center;">
                <strong>0.426</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">Mult-DAE</td>
                <td style="text-align:center;">0.387</td>
                <td style="text-align:center;">0.524</td>
                <td style="text-align:center;">0.419</td>
              </tr>
              <tr>
                <td style="text-align:left;">WMF</td>
                <td style="text-align:center;">0.360</td>
                <td style="text-align:center;">0.498</td>
                <td style="text-align:center;">0.386</td>
              </tr>
              <tr>
                <td style="text-align:left;"><font style=
                "font-variant: small-caps">Slim</font></td>
                <td style="text-align:center;">0.370</td>
                <td style="text-align:center;">0.495</td>
                <td style="text-align:center;">0.401</td>
              </tr>
              <tr>
                <td style="text-align:left;">CDAE</td>
                <td style="text-align:center;">0.391</td>
                <td style="text-align:center;">0.523</td>
                <td style="text-align:center;">0.418</td>
              </tr>
            </tbody>
            <thead>
              <tr>
                <th colspan="4" style="text-align:center;">
                  (b) Netflix
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">Recall@20</th>
                <th style="text-align:center;">Recall@50</th>
                <th style="text-align:center;">NDCG@100</th>
              </tr>
            </thead>
            <tbody>
              <tr style="border-top: solid 2px">
                <td style="text-align:left;">Mult-<span class=
                "inline-equation"><span class="tex">${\rm\small
                VAE}^{\rm\small PR}$</span></span></td>
                <td style="text-align:center;">
                <strong>0.351</strong></td>
                <td style="text-align:center;">
                <strong>0.444</strong></td>
                <td style="text-align:center;">
                <strong>0.386</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">Mult-DAE</td>
                <td style="text-align:center;">0.344</td>
                <td style="text-align:center;">0.438</td>
                <td style="text-align:center;">0.380</td>
              </tr>
              <tr>
                <td style="text-align:left;">WMF</td>
                <td style="text-align:center;">0.316</td>
                <td style="text-align:center;">0.404</td>
                <td style="text-align:center;">0.351</td>
              </tr>
              <tr>
                <td style="text-align:left;"><font style=
                "font-variant: small-caps">Slim</font></td>
                <td style="text-align:center;">0.347</td>
                <td style="text-align:center;">0.428</td>
                <td style="text-align:center;">0.379</td>
              </tr>
              <tr>
                <td style="text-align:left;">CDAE</td>
                <td style="text-align:center;">0.343</td>
                <td style="text-align:center;">0.428</td>
                <td style="text-align:center;">0.376</td>
              </tr>
            </tbody>
            <thead>
              <tr>
                <th colspan="4" style="text-align:center;">
                  MSD
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">Recall@20</th>
                <th style="text-align:center;">Recall@50</th>
                <th style="text-align:center;">NDCG@100</th>
              </tr>
            </thead>
            <tbody>
              <tr style="border-top: solid 2px">
                <td style="text-align:left;">Mult-<span class=
                "inline-equation"><span class="tex">${\rm\small
                VAE}^{\rm\small PR}$</span></span></td>
                <td style="text-align:center;">
                <strong>0.266</strong></td>
                <td style="text-align:center;">
                <strong>0.364</strong></td>
                <td style="text-align:center;">
                <strong>0.316</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">Mult-DAE</td>
                <td style="text-align:center;">
                <strong>0.266</strong></td>
                <td style="text-align:center;">
                <strong>0.363</strong></td>
                <td style="text-align:center;">0.313</td>
              </tr>
              <tr>
                <td style="text-align:left;">WMF</td>
                <td style="text-align:center;">0.211</td>
                <td style="text-align:center;">0.312</td>
                <td style="text-align:center;">0.257</td>
              </tr>
              <tr>
                <td style="text-align:left;"><font style=
                "font-variant: small-caps">Slim</font></td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">—</td>
                <td style="text-align:center;">—</td>
              </tr>
              <tr>
                <td style="text-align:left;">CDAE</td>
                <td style="text-align:center;">0.188</td>
                <td style="text-align:center;">0.283</td>
                <td style="text-align:center;">0.237</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p><strong>Quantitative results.</strong>&nbsp; Table
        <a class="tbl" href="#tab2">2</a> summarizes the results
        between our proposed methods and various baselines. Each
        metric is averaged across all test users. Both
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        and Mult-DAE&nbsp; significantly outperform the baselines
        across datasets and metrics. Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; significantly
        outperforms Mult-DAE&nbsp; on ML-20M and Netflix data-sets.
        In most of the cases, non-linear models (Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> , Mult-DAE, and CDAE)
        prove to be more powerful collaborative filtering models
        than state-of-the-art linear models. The inferior results
        of CDAE on MSD are possibly due to overfitting with the
        huge number of users and items, as validation metrics drop
        within the first few epochs even though the training
        objective continues improving.</p>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class=
            "table-title">Comparison between NCF and Mult-DAE&nbsp;
            with [<em>I</em> → 200 → <em>I</em>] architecture. We
            take the results of NCF from He et&nbsp;al. [<a class=
            "bib" data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0014">14</a>].
            Mult-DAE&nbsp; model significantly outperforms NCF
            without pre-training on both datasets and further
            improves on Pinterest even comparing with pre-trained
            NCF.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th colspan="4" style="text-align:center;">
                  ML-1M
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">NCF</th>
                <th style="text-align:center;">NCF (pre-train)</th>
                <th style="text-align:center;">Mult-DAE</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">Recall@10</td>
                <td style="text-align:center;">0.705</td>
                <td style="text-align:center;">
                <strong>0.730</strong></td>
                <td style="text-align:center;">0.722</td>
              </tr>
              <tr>
                <td style="text-align:center;">NDCG@10</td>
                <td style="text-align:center;">0.426</td>
                <td style="text-align:center;">
                <strong>0.447</strong></td>
                <td style="text-align:center;">0.446</td>
              </tr>
            </tbody>
            <thead>
              <tr>
                <th colspan="4" style="text-align:center;">
                  Pinterest
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">NCF</th>
                <th style="text-align:center;">NCF (pre-train)</th>
                <th style="text-align:center;">Mult-DAE</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">Recall@10</td>
                <td style="text-align:center;">0.872</td>
                <td style="text-align:center;">0.880</td>
                <td style="text-align:center;">
                <strong>0.886</strong></td>
              </tr>
              <tr>
                <td style="text-align:center;">NDCG@10</td>
                <td style="text-align:center;">0.551</td>
                <td style="text-align:center;">0.558</td>
                <td style="text-align:center;">
                <strong>0.580</strong></td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td></td>
                <td></td>
                <td></td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>We compare with NCF on the two relatively smaller
        datasets used in Hu et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0019">19</a>]: ML-1M (6,040 users,
        3,704 items, 4.47% density) and Pinterest (55,187 users,
        9,916 items, 0.27% density). Because of the size of these
        two datasets, we use Mult-DAE&nbsp; with a 0-hidden-layer
        MLP generative model — the overall architecture is
        [<em>I</em> → 200 → <em>I</em>]. (Recall Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; with a
        0-hidden-layer MLP generative model is effectively a
        log-linear model with limited modeling capacity.) Table
        <a class="tbl" href="#tab3">3</a> summarizes the results
        between Mult-DAE&nbsp; and NCF. Mult-DAE&nbsp;
        significantly outperforms NCF without pre-training on both
        datasets. On the larger Pinterest dataset, Mult-DAE&nbsp;
        even improves over the pre-trained NCF model by a big
        margin.</p>
        <p><strong>How well does multinomial likelihood
        perform?</strong>&nbsp; Despite being commonly used in
        language models, multinomial likelihoods have typically
        received less attention in the collaborative filtering
        literature, especially with latent-factor models. Most
        previous work builds on Gaussian likelihoods (square loss,
        Eq. <a class="eqn" href="#eq3">3</a>) [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0019">19</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0033">33</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0051">51</a>] or logistic likelihood
        (log loss, Eq. <a class="eqn" href="#eq4">4</a>) [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0014">14</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0051">51</a>] instead.
        We argue in Section <a class="sec" href="#sec-7">2.1</a>
        that multinomial likelihood is in fact a good proxy for the
        top-<em>N</em> ranking loss and is well-suited for implicit
        feedback data. To demonstrate the effectiveness of
        multinomial likelihood, we take the best-performing
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        and Mult-DAE&nbsp; model on each dataset and swap the
        likelihood distribution model for the data while keeping
        everything else exactly the same.</p>
        <div class="table-responsive" id="tab4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class=
            "table-title">Comparison of Mult-<span class=
            "inline-equation"><span class="tex">${\rm\small
            VAE}^{\rm\small PR}$</span></span> &nbsp; and
            Mult-DAE&nbsp; with different likelihood functions at
            the output layer on ML-20M. The standard error is
            around 0.002 (the results on the other two datasets are
            similar.) The multinomial likelihood performs better
            than the other two commonly-used likelihoods from the
            collaborative filtering literature.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">Recall@20</th>
                <th style="text-align:center;">Recall@50</th>
                <th style="text-align:center;">NDCG@100</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Mult-<span class=
                "inline-equation"><span class="tex">${\rm\small
                VAE}^{\rm\small PR}$</span></span></td>
                <td style="text-align:center;">
                <strong>0.395</strong></td>
                <td style="text-align:center;">
                <strong>0.537</strong></td>
                <td style="text-align:center;">
                <strong>0.426</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">Gaussian-<span class=
                "inline-equation"><span class="tex">${\rm\small
                VAE}^{\rm\small PR}$</span></span></td>
                <td style="text-align:center;">0.383</td>
                <td style="text-align:center;">0.523</td>
                <td style="text-align:center;">0.415</td>
              </tr>
              <tr>
                <td style="text-align:left;">Logistic-<span class=
                "inline-equation"><span class="tex">${\rm\small
                VAE}^{\rm\small PR}$</span></span></td>
                <td style="text-align:center;">0.388</td>
                <td style="text-align:center;">0.523</td>
                <td style="text-align:center;">0.419</td>
              </tr>
              <tr>
                <td style="text-align:left;">Mult-DAE</td>
                <td style="text-align:center;">
                <strong>0.387</strong></td>
                <td style="text-align:center;">
                <strong>0.524</strong></td>
                <td style="text-align:center;">
                <strong>0.419</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">Gaussian-DAE</td>
                <td style="text-align:center;">0.376</td>
                <td style="text-align:center;">0.515</td>
                <td style="text-align:center;">0.409</td>
              </tr>
              <tr>
                <td style="text-align:left;">Logistic-DAE</td>
                <td style="text-align:center;">0.381</td>
                <td style="text-align:center;">0.516</td>
                <td style="text-align:center;">0.414</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>Table <a class="tbl" href="#tab4">4</a> summarizes the
        results of different likelihoods on ML-20M (the results on
        the other two datasets are similar.) We tune the
        hyperparameters for each likelihood separately.<a class=
        "fn" href="#fn9" id="foot-fn9"><sup>9</sup></a> The
        multinomial likelihood performs better than the other
        likelihoods. The gap between logistic and multinomial
        likelihood is closer — this is understandable since
        multinomial likelihood can be approximated by individual
        binary logistic likelihood, a strategy commonly adopted in
        language modeling [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0032">32</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0052">52</a>].</p>
        <p>We wish to emphasize that the choice of likelihood
        remains data-dependent. For the task of collaborative
        filtering, the multinomial likelihood achieves excellent
        empirical results. The methodology behind the partial
        regularization in Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> , however, is a
        technique we hypothesize will generalize to other
        domains.</p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186150/images/www2018-159-fig3.jpg"
          class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">NDCG@100 breakdown for users
            with increasing levels of activity (starting from 0%),
            measured by how many items a user clicked on in the
            fold-in set. The error bars represents one standard
            error. For each subplot, a paired t-test is performed
            and * indicates statistical significance at <em>α</em>
            = 0.05 level, ** at <em>α</em> = 0.01 level, and *** at
            <em>α</em> = 0.001 level. Although details vary across
            datasets, Mult-<span class=
            "inline-equation"><span class="tex">${\rm\small
            VAE}^{\rm\small PR}$</span></span> &nbsp; consistently
            improves recommendation performance for users who have
            only clicked on a small number of items.</span>
          </div>
        </figure>
        <p></p>
        <p><strong>When does Mult-</strong> <span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> <strong>&nbsp; perform
        better/worse than Mult-DAE?</strong>&nbsp; In Table
        <a class="tbl" href="#tab2">2</a> we can see that both
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        and Mult-DAE&nbsp; produce competitive empirical results
        with Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        being comparably better. It is natural to wonder when a
        variational Bayesian inference approach (Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> ) will win over using a
        point estimate (Mult-DAE) and vice versa.</p>
        <p>Intuitively, Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; imposes stronger
        modeling assumptions and therefore could be more robust
        when user-item interaction data is scarce. To study this,
        we considered two datasets: ML-20M where Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; has the largest
        margin over Mult-DAE&nbsp; and MSD where Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; and
        Mult-DAE&nbsp; have roughly similar performance. The
        results on the Netflix dataset are similar to ML-20M. We
        break down test users into quintiles based on their
        activity level in the fold-in set which is provided as
        input to the inference model <em>g<sub>ϕ</sub></em> (·) to
        make prediction. The activity level is simply the number of
        items each user has clicked on. We compute NDCG@100 for
        each group of users using both Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; and
        Mult-DAE&nbsp; and plot results in Figure <a class="fig"
        href="#fig3">3</a>. This summarizes how performance differs
        across users with various levels of activity.</p>
        <p>In Figure <a class="fig" href="#fig3">3</a>, we show
        performance across increasing user activity. Error bars
        represents one standard error. For each subplot, a paired
        t-test is performed and statistical significance is marked.
        Although there are slight variations across datasets,
        Mult-<span class="inline-equation"><span class=
        "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
        consistently improves recommendation performance for users
        who have only clicked on a small number of items. This is
        particularly prominent for ML-20M (Figure). Interestingly,
        Mult-DAE&nbsp; actually outperforms Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; on the most
        active users. This indicates the stronger prior assumption
        could potentially hurt the performance when a lot of data
        is available for a user. For MSD (Figure), the least-active
        users have similar performance under both Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp;and Mult-DAE.
        However, as we described in Section <a class="sec" href=
        "#sec-16">4.1</a>, MSD is pre-processed so that a user has
        at least listened to 20 songs. Meanwhile for ML-20M, each
        user has to watch at least 5 movies. This means that the
        first bin of ML-20M has much lower user activity than the
        first bin of MSD.</p>
        <p>Overall, we find that Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> , which may be viewed
        under the lens of a principled Bayesian inference approach,
        is more robust than the point estimate approach of
        Mult-DAE, regardless of the scarcity of the data. More
        importantly, the Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; is less sensitive
        to the choice of hyperparameters – weight decay is
        important for Mult-DAE&nbsp; to achieve competitive
        performance, yet it is not required for Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> . On the other hand,
        Mult-DAE&nbsp; also has advantages: it requires fewer
        parameters in the bottleneck layer — Mult-<span class=
        "inline-equation"><span class="tex">${\rm\small
        VAE}^{\rm\small PR}$</span></span> &nbsp; requires two sets
        of parameters to obtain the latent representation
        <strong>z</strong>: one set for the variational mean
        <em>μ<sub>ϕ</sub></em> (·) and another for the variational
        variance <em>σ<sub>ϕ</sub></em> (·) — and Mult-DAE&nbsp; is
        conceptually simpler for practitioners.</p>
      </section>
    </section>
    <section id="sec-21">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Conclusion</h2>
        </div>
      </header>
      <p>In this paper, we develop a variant of VAE for
      collaborative filtering on implicit feedback data. This
      enables us to go beyond linear factor models with limited
      modeling capacity.</p>
      <p>We introduce a generative model with a multinomial
      likelihood function parameterized by neural network. We show
      that multinomial likelihood is particularly well suited to
      modeling user-item implicit feedback data.</p>
      <p>Based on an alternative interpretation of the VAE
      objective, we introduce an additional regularization
      parameter to partially regularize a VAE (Mult-<span class=
      "inline-equation"><span class="tex">${\rm\small
      VAE}^{\rm\small PR}$</span></span> ). We also provide a
      practical and efficient way to tune the additional parameter
      introduced using KL annealing. We compare the results
      obtained against a denoising autoencoder (Mult-DAE).</p>
      <p>Empirically, we show that the both Mult-<span class=
      "inline-equation"><span class="tex">${\rm\small
      VAE}^{\rm\small PR}$</span></span> &nbsp;and
      Mult-DAE&nbsp;provide competitive performance with
      Mult-<span class="inline-equation"><span class=
      "tex">${\rm\small VAE}^{\rm\small PR}$</span></span> &nbsp;
      significantly outperforming the state-of-the-art baselines on
      several real-world datasets, including two recently proposed
      neural-network-based approaches. Finally, we identify the
      pros and cons of both Mult-<span class=
      "inline-equation"><span class="tex">${\rm\small
      VAE}^{\rm\small PR}$</span></span> &nbsp; and Mult-DAE&nbsp;
      and show that employing a principled Bayesian approach is
      more robust.</p>
      <p>In future work, we would like to futher investigate the
      trade-off introduced by the additional regularization
      parameter <em>β</em> and gain more theoretical insight into
      why it works so well. Extending Mult-<span class=
      "inline-equation"><span class="tex">${\rm\small
      VAE}^{\rm\small PR}$</span></span> &nbsp;by
      <em>condition</em> on side information might also be a way to
      improve performance.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Alexander Alemi, Ian
        Fischer, Joshua Dillon, and Kevin Murphy. 2017. Deep
        Variational Information Bottleneck. In <em>5th
        International Conference on Learning
        Representations</em>.</li>
        <li id="BibPLXBIB0002" label="[2]">Amjad Almahairi, Kyle
        Kastner, Kyunghyun Cho, and Aaron Courville. 2015. Learning
        distributed representations from reviews for collaborative
        filtering. In <em>Proceedings of the 9th ACM Conference on
        Recommender Systems</em>. ACM, 147–154.</li>
        <li id="BibPLXBIB0003" label="[3]">Thierry Bertin-Mahieux,
        Daniel&nbsp;P.W. Ellis, Brian Whitman, and Paul Lamere.
        2011. The Million Song Dataset. In <em>ISMIR</em> ,
        Vol.&nbsp;2. 10.</li>
        <li id="BibPLXBIB0004" label="[4]">David&nbsp;M. Blei, Alp
        Kucukelbir, and Jon&nbsp;D. McAuliffe. 2017. Variational
        Inference: A Review for Statisticians. <em>J. Amer.
        Statist. Assoc.</em> 112, 518 (2017), 859–877.</li>
        <li id="BibPLXBIB0005" label="[5]">David&nbsp;M. Blei,
        Andrew&nbsp;Y. Ng, and Michael&nbsp;I. Jordan. 2003. Latent
        dirichlet allocation. <em>Journal of Machine Learning
        Research</em> 3, Jan (2003), 993–1022.</li>
        <li id="BibPLXBIB0006" label="[6]">Aleksandar Botev, Bowen
        Zheng, and David Barber. 2017. Complementary Sum Sampling
        for Likelihood Approximation in Large Scale Classification.
        In <em>Proceedings of the 20th International Conference on
        Artificial Intelligence and Statistics</em>.
        1030–1038.</li>
        <li id="BibPLXBIB0007" label="[7]">Samuel&nbsp;R. Bowman,
        Luke Vilnis, Oriol Vinyals, Andrew&nbsp;M. Dai, Rafal
        Jozefowicz, and Samy Bengio. 2015. Generating sentences
        from a continuous space. <em>arXiv preprint
        arXiv:1511.06349</em> (2015).</li>
        <li id="BibPLXBIB0008" label="[8]">Sotirios Chatzis,
        Panayiotis Christodoulou, and Andreas&nbsp;S. Andreou.
        2017. Recurrent Latent Variable Networks for Session-Based
        Recommendation. In <em>Proceedings of the 2nd Workshop on
        Deep Learning for Recommender Systems</em>.</li>
        <li id="BibPLXBIB0009" label="[9]">Paul Covington, Jay
        Adams, and Emre Sargin. 2016. Deep neural networks for
        youtube recommendations. In <em>Proceedings of the 10th ACM
        Conference on Recommender Systems</em>. ACM, 191–198.</li>
        <li id="BibPLXBIB0010" label="[10]">Carl Doersch. 2016.
        Tutorial on variational autoencoders. <em>arXiv preprint
        arXiv:1606.05908</em> (2016).</li>
        <li id="BibPLXBIB0011" label="[11]">Kostadin Georgiev and
        Preslav Nakov. 2013. A non-IID Framework for Collaborative
        Filtering with Restricted Boltzmann Machines. In
        <em>Proceedings of the 30th International Conference on
        Machine Learning</em>. 1148–1156.</li>
        <li id="BibPLXBIB0012" label="[12]">Samuel Gershman and
        Noah Goodman. 2014. Amortized inference in probabilistic
        reasoning. In <em>Proceedings of the Cognitive Science
        Society</em>, Vol.&nbsp;36.</li>
        <li id="BibPLXBIB0013" label="[13]">Prem Gopalan,
        Jake&nbsp;M. Hofman, and David&nbsp;M. Blei. 2015. Scalable
        Recommendation with Hierarchical Poisson Factorization. In
        <em>Uncertainty in Artificial Intelligence</em>.</li>
        <li id="BibPLXBIB0014" label="[14]">Xiangnan He, Lizi Liao,
        Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua.
        2017. Neural collaborative filtering. In <em>Proceedings of
        the 26th International Conference on World Wide Web</em>.
        173–182.</li>
        <li id="BibPLXBIB0015" label="[15]">Balázs Hidasi and
        Alexandros Karatzoglou. 2017. Recurrent Neural Networks
        with Top-k Gains for Session-based Recommendations.
        <em>arXiv preprint arXiv:1706.03847</em> (2017).</li>
        <li id="BibPLXBIB0016" label="[16]">Balázs Hidasi,
        Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.
        2015. Session-based recommendations with recurrent neural
        networks. <em>arXiv preprint arXiv:1511.06939</em>
        (2015).</li>
        <li id="BibPLXBIB0017" label="[17]">Irina Higgins, Loic
        Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
        Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
        2017. <em>β</em>-VAE: Learning Basic Visual Concepts with a
        Constrained Variational Framework. In <em>5th International
        Conference on Learning Representations</em>.</li>
        <li id="BibPLXBIB0018" label="[18]">Matthew&nbsp;D. Hoffman
        and Matthew&nbsp;J. Johnson. 2016. ELBO surgery: yet
        another way to carve up the variational evidence lower
        bound. In <em>Workshop in Advances in Approximate Bayesian
        Inference, NIPS</em>.</li>
        <li id="BibPLXBIB0019" label="[19]">Yifan Hu, Yehuda Koren,
        and Chris Volinsky. 2008. Collaborative filtering for
        implicit feedback datasets. In <em>Data Mining, 2008.
        ICDM’08. Eighth IEEE International Conference on</em>.
        263–272.</li>
        <li id="BibPLXBIB0020" label="[20]">Tommi Jaakkola, Marina
        Meila, and Tony Jebara. 2000. Maximum entropy
        discrimination. In <em>Advances in Neural Information
        Processing Systems</em>. 470–476.</li>
        <li id="BibPLXBIB0021" label="[21]">Kalervo Järvelin and
        Jaana Kekäläinen. 2002. Cumulated gain-based evaluation of
        IR techniques. <em>ACM Transactions on Information Systems
        (TOIS)</em> 20, 4 (2002), 422–446.</li>
        <li id="BibPLXBIB0022" label="[22]">Michael&nbsp;I. Jordan,
        Zoubin Ghahramani, Tommi&nbsp;S. Jaakkola, and
        Lawrence&nbsp;K. Saul. 1999. An introduction to variational
        methods for graphical models. <em>Machine learning</em> 37,
        2 (1999), 183–233.</li>
        <li id="BibPLXBIB0023" label="[23]">Diederik Kingma and
        Jimmy Ba. 2014. Adam: A method for stochastic optimization.
        <em>arXiv preprint arXiv:1412.6980</em> (2014).</li>
        <li id="BibPLXBIB0024" label="[24]">Diederik&nbsp;P. Kingma
        and Max Welling. 2013. Auto-encoding variational bayes.
        <em>arXiv preprint arXiv:1312.6114</em> (2013).</li>
        <li id="BibPLXBIB0025" label="[25]">Rahul&nbsp;G. Krishnan,
        Dawen Liang, and Matthew&nbsp;D. Hoffman. 2017. On the
        challenges of learning with inference networks on sparse,
        high-dimensional data. <em>arXiv preprint
        arXiv:1710.06085</em> (2017).</li>
        <li id="BibPLXBIB0026" label="[26]">Mark Levy and Kris
        Jack. 2013. Efficient top-n recommendation by linear
        regression. In <em>RecSys Large Scale Recommender Systems
        Workshop</em>.</li>
        <li id="BibPLXBIB0027" label="[27]">Dawen Liang, Jaan
        Altosaar, Laurent Charlin, and David&nbsp;M. Blei. 2016.
        Factorization meets the item embedding: Regularizing matrix
        factorization with item co-occurrence. In <em>Proceedings
        of the 10th ACM conference on recommender systems</em>.
        59–66.</li>
        <li id="BibPLXBIB0028" label="[28]">Dawen Liang, Minshu
        Zhan, and Daniel&nbsp;P.W. Ellis. 2015. Content-Aware
        Collaborative Music Recommendation Using Pre-trained Neural
        Networks. In <em>ISMIR</em>. 295–301.</li>
        <li id="BibPLXBIB0029" label="[29]">Benjamin Marlin. 2004.
        <em>Collaborative filtering: A machine learning
        perspective</em>. University of Toronto.</li>
        <li id="BibPLXBIB0030" label="[30]">Daniel McFadden <em>et
        al.</em> 1973. Conditional logit analysis of qualitative
        choice behavior. (1973), 105–142&nbsp;pages.</li>
        <li id="BibPLXBIB0031" label="[31]">Yishu Miao, Lei Yu, and
        Phil Blunsom. 2016. Neural variational inference for text
        processing. In <em>International Conference on Machine
        Learning</em>. 1727–1736.</li>
        <li id="BibPLXBIB0032" label="[32]">Tomas Mikolov, Ilya
        Sutskever, Kai Chen, Greg&nbsp;S. Corrado, and Jeff Dean.
        2013. Distributed representations of words and phrases and
        their compositionality. In <em>Advances in neural
        information processing systems</em>. 3111–3119.</li>
        <li id="BibPLXBIB0033" label="[33]">Xia Ning and George
        Karypis. 2011. Slim: Sparse linear methods for top-n
        recommender systems. In <em>Data Mining (ICDM), 2011 IEEE
        11th International Conference on</em>. 497–506.</li>
        <li id="BibPLXBIB0034" label="[34]">Rong Pan, Yunhong Zhou,
        Bin Cao, Nathan&nbsp;N. Liu, Rajan Lukose, Martin Scholz,
        and Qiang Yang. 2008. One-class collaborative filtering. In
        <em>Data Mining, 2008. ICDM’08. Eighth IEEE International
        Conference on</em>. 502–511.</li>
        <li id="BibPLXBIB0035" label="[35]">Arkadiusz Paterek.
        2007. Improving regularized singular value decomposition
        for collaborative filtering. In <em>Proceedings of KDD cup
        and workshop</em>, Vol.&nbsp;2007. 5–8.</li>
        <li id="BibPLXBIB0036" label="[36]">Steffen Rendle,
        Christoph Freudenthaler, Zeno Gantner, and Lars
        Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking
        from implicit feedback. In <em>Proceedings of the
        twenty-fifth conference on uncertainty in artificial
        intelligence</em>. 452–461.</li>
        <li id="BibPLXBIB0037" label="[37]">Danilo&nbsp;Jimenez
        Rezende, Shakir Mohamed, and Daan Wierstra. 2014.
        Stochastic Backpropagation and Approximate Inference in
        Deep Generative Models. In <em>Proceedings of the 31st
        International Conference on Machine Learning</em>.
        1278–1286.</li>
        <li id="BibPLXBIB0038" label="[38]">Ruslan Salakhutdinov
        and Andriy Mnih. 2008. Probabilistic matrix factorization.
        <em>Advances in neural information processing systems</em>
        (2008), 1257–1264.</li>
        <li id="BibPLXBIB0039" label="[39]">Ruslan Salakhutdinov,
        Andriy Mnih, and Geoffrey Hinton. 2007. Restricted
        Boltzmann machines for collaborative filtering. In
        <em>Proceedings of the 24th International Conference on
        Machine Learning</em>. 791–798.</li>
        <li id="BibPLXBIB0040" label="[40]">Suvash Sedhain,
        Aditya&nbsp;Krishna Menon, Scott Sanner, and Darius
        Braziunas. 2016. On the Effectiveness of Linear Models for
        One-Class Collaborative Filtering. In <em>AAAI</em>.</li>
        <li id="BibPLXBIB0041" label="[41]">Suvash Sedhain,
        Aditya&nbsp;Krishna Menon, Scott Sanner, and Lexing Xie.
        2015. Autorec: Autoencoders meet collaborative filtering.
        In <em>Proceedings of the 24th International Conference on
        World Wide Web</em>. 111–112.</li>
        <li id="BibPLXBIB0042" label="[42]">Elena Smirnova and
        Flavian Vasile. 2017. Contextual Sequence Modeling for
        Recommendation with Recurrent Neural Networks. In
        <em>Proceedings of the 2nd Workshop on Deep Learning for
        Recommender Systems</em>.</li>
        <li id="BibPLXBIB0043" label="[43]">Nitish Srivastava,
        Geoffrey&nbsp;E. Hinton, Alex Krizhevsky, Ilya Sutskever,
        and Ruslan Salakhutdinov. 2014. Dropout: a simple way to
        prevent neural networks from overfitting. <em>Journal of
        machine learning research</em> 15, 1 (2014),
        1929–1958.</li>
        <li id="BibPLXBIB0044" label="[44]">Harald Steck. 2015.
        Gaussian ranking by matrix factorization. In
        <em>Proceedings of the 9th ACM Conference on Recommender
        Systems</em>. ACM, 115–122.</li>
        <li id="BibPLXBIB0045" label="[45]">Yong&nbsp;Kiam Tan,
        Xinxing Xu, and Yong Liu. 2016. Improved recurrent neural
        networks for session-based recommendations. In
        <em>Proceedings of the 1st Workshop on Deep Learning for
        Recommender Systems</em>. 17–22.</li>
        <li id="BibPLXBIB0046" label="[46]">Naftali Tishby,
        Fernando Pereira, and William Bialek. 2000. The information
        bottleneck method. <em>arXiv preprint physics/0004057</em>
        (2000).</li>
        <li id="BibPLXBIB0047" label="[47]">Aaron van&nbsp;den
        Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep
        content-based music recommendation. In <em>Advances in
        Neural Information Processing Systems 26</em>.
        2643–2651.</li>
        <li id="BibPLXBIB0048" label="[48]">Hao Wang, Naiyan Wang,
        and Dit-Yan Yeung. 2015. Collaborative deep learning for
        recommender systems. In <em>Proceedings of the 21th ACM
        SIGKDD International Conference on Knowledge Discovery and
        Data Mining</em>. ACM, 1235–1244.</li>
        <li id="BibPLXBIB0049" label="[49]">Markus Weimer,
        Alexandros Karatzoglou, Quoc&nbsp;V Le, and Alex&nbsp;J
        Smola. 2008. Cofi rank-maximum margin matrix factorization
        for collaborative ranking. In <em>Advances in neural
        information processing systems</em>. 1593–1600.</li>
        <li id="BibPLXBIB0050" label="[50]">Jason Weston, Samy
        Bengio, and Nicolas Usunier. 2011. Wsabie: Scaling up to
        large vocabulary image annotation. In <em>IJCAI</em>,
        Vol.&nbsp;11. 2764–2770.</li>
        <li id="BibPLXBIB0051" label="[51]">Yao Wu, Christopher
        DuBois, Alice&nbsp;X. Zheng, and Martin Ester. 2016.
        Collaborative denoising auto-encoders for top-n recommender
        systems. In <em>Proceedings of the Ninth ACM International
        Conference on Web Search and Data Mining</em>.
        153–162.</li>
        <li id="BibPLXBIB0052" label="[52]">Puyang Xu, Asela
        Gunawardana, and Sanjeev Khudanpur. 2011. Efficient
        subsampling for training complex language models. In
        <em>Proceedings of the Conference on Empirical Methods in
        Natural Language Processing</em>. Association for
        Computational Linguistics, 1128–1136.</li>
        <li id="BibPLXBIB0053" label="[53]">Shuang-Hong Yang, Bo
        Long, Alexander&nbsp;J. Smola, Hongyuan Zha, and Zhaohui
        Zheng. 2011. Collaborative competitive filtering: learning
        recommender using context of user choice. In
        <em>Proceedings of the 34th international ACM SIGIR
        conference on Research and development in Information
        Retrieval</em>. ACM, 295–304.</li>
        <li id="BibPLXBIB0054" label="[54]">Yin Zheng, Bangsheng
        Tang, Wenkui Ding, and Hanning Zhou. 2016. A Neural
        Autoregressive Approach to Collaborative Filtering. In
        <em>Proceedings of The 33rd International Conference on
        Machine Learning</em>. 764–773.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>We use the verb
    “click” for concreteness; this can be any type of interaction,
    including “watch”, “purchase”, or “listen”.</p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>The
    cross-entropy loss for multi-class classification is a
    multinomial likelihood under a single draw from the
    distribution.</p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>Logistic
    likelihood is also cross-entropy loss for binary
    classification.</p>
    <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>In the
    implementation, the inference model will output the log of the
    variance of the variational distribution. We continue to use
    <em>σ<sub>ϕ</sub></em> (<strong>x</strong>
    <sub><em>u</em></sub> ) for notational brevity.</p>
    <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>We found this
    to give slightly better results than keeping <em>β</em> at the
    best value throughout the training.</p>
    <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a><a class=
    "link-inline force-break" href=
    "https://github.com/dawenl/vae_cf">https://github.com/dawenl/vae_cf</a></p>
    <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a><a class=
    "link-inline force-break" href=
    "http://www.netflixprize.com/">http://www.netflixprize.com/</a></p>
    <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a>Wu et&nbsp;al.
    [<a class="bib" data-trigger="hover" data-toggle="popover"
    data-placement="top" href="#BibPLXBIB0051">51</a>] used sigmoid
    activation function but mentioned tanh gave similar results. We
    use tanh to be consistent with our models.</p>
    <p id="fn9"><a href="#foot-fn9"><sup>9</sup></a>Surprisingly,
    partial regularization seems less effective for Gaussian and
    logistic.</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution-NonCommercial-NoDerivs 4.0 International
      (CC-BY-NC-ND&nbsp;4.0) license. Authors reserve their rights
      to disseminate the work on their personal and corporate Web
      sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons
      CC-BY-NC-ND&nbsp;4.0 License. ACM ISBN
      978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3178876.3186150">https://doi.org/10.1145/3178876.3186150</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
