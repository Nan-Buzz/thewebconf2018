<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>CredEye: A Credibility Lens for Analyzing and Explaining Misinformation</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">CredEye: A Credibility Lens for Analyzing and Explaining Misinformation</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Kashyap</span>      <span class="surName">Popat</span>     Max Planck Institute for Informatics, Saarbr&#x00FC;cken, Germany, <a href="mailto:kpopat@mpi-inf.mpg.de">kpopat@mpi-inf.mpg.de</a>     </div>     <div class="author">     <span class="givenName">Subhabrata</span>      <span class="surName">Mukherjee</span>     Amazon Inc., Seattle, USA<a class="fn" href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>, <a href="mailto:subhomj@amazon.com">subhomj@amazon.com</a>     </div>     <div class="author">     <span class="givenName">Jannik</span>      <span class="surName">Str&#x00F6;tgen</span>     Max Planck Institute for Informatics, Saarbr&#x00FC;cken, Germany, <a href="mailto:jstroetge@mpi-inf.mpg.de">jstroetge@mpi-inf.mpg.de</a>     </div>     <div class="author">     <span class="givenName">Gerhard</span>      <span class="surName">Weikum</span>     Max Planck Institute for Informatics, Saarbr&#x00FC;cken, Germany, <a href="mailto:weikum@mpi-inf.mpg.de">weikum@mpi-inf.mpg.de</a>     </div>                     </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3186967" target="_blank">https://doi.org/10.1145/3184558.3186967</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Rapid increase of misinformation online has emerged as one of the biggest challenges in this post-truth era. This has given rise to many fact-checking websites that manually assess doubtful claims. However, the speed and scale at which misinformation spreads in online media inherently limits manual verification. Hence, the problem of automatic credibility assessment has attracted great attention. In this work, we present CredEye, a system for automatic credibility assessment. It takes a natural language claim as input from the user and automatically analyzes its credibility by considering relevant articles from the Web. Our system captures joint interaction between language style of articles, their stance towards a claim and the trustworthiness of the sources. In addition, extraction of supporting evidence in the form of enriched snippets makes the verdicts of CredEye transparent and interpretable.</small>     </p>    </div>    <div class="CCSconcepts">     <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Computing methodologies </strong>&#x2192; <strong>Natural language processing;</strong> <em>Machine learning;</em> &#x2022;<strong> Information systems </strong>&#x2192; World Wide Web;</small> </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Fact Checking; Credibility Analysis; Interpretable Learning</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Kashyap Popat, Subhabrata Mukherjee, Jannik Str&#x00F6;tgen, and Gerhard Weikum. 2018. CredEye: A Credibility Lens for Analyzing and Explaining Misinformation. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018 (WWW &#x2019;18 Companion),</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 4 Pages. <a href="https://doi.org/10.1145/3184558.3186967" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3186967</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <figure id="fig1">    <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186967/images/www18companion-207-fig1.jpg" class="img-responsive" alt="Figure 1"     longdesc=""/>    <div class="figure-caption">     <span class="figure-number">Figure 1:</span>     <span class="figure-title">Credibility analysis pipeline of CredEye.</span>    </div>   </figure>   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>The explosive growth of the Web, online news and social media has led to a proliferation of misinformation. These range from posting fake reviews in e-commerce portals, propagating rumors and hoaxes in social networks to erroneous quoting of celebrities and politicians. Misinformation can have disastrous consequences: for example, rumors during hurricane Irma forced the US government to start a rumor control website<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a> to avoid panic.</p>    <p>     <strong>State-of-the-art and its Limitations:</strong> Prior works in credibility analysis and truth-finding primarily focus on structured data, typically in the form of subject-predicate-object statements [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>]. Works on detecting fake statements in social media&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>] leverage social network metadata like user-user interactions and social links as well as profiles, reputation features based on votes or likes, and demographic information. Most importantly, all these prior approaches provide black-box techniques and lack the ability to <em>explain</em> why a certain statement is classified as true or false.</p>    <p>In our own prior work&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>], we address these limitations by considering user-provided <em>natural language claims</em>, and develop a general framework which does not make any assumptions about the structure of the claim or characteristics of the community or website where the claim is reported. Our method is based on distantly supervised learning with joint inference over the language style of relevant articles, their stance towards the claim (support or refute), and the trustworthiness of the underlying Web sources. In addition to the automatic assessment, our method extracts interpretable evidence and identifies crucial features to explain its verdicts (see Figure&#x00A0;<a class="fig" href="#fig2">2</a>, discussed later). Two recent systems along similar lines are ClaimBuster [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] and ClaimVerif [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>]. However, neither of these consider the language style of the articles that serve as evidence or counter-evidence. Also, neither provides feature-level explanations of their assessment scores; rather they merely list online articles related to the claim.</p>    <p>     <strong>Contributions:</strong> In this paper, we demonstrate CredEye, an automatic credibility analyzer based on our prior work. Its unique point is that it considers language style as a key component of its assessments, and also provides explanations in terms of automatically extracted snippets from supporting and refuting articles enriched with language features.</p>    <p>Given an input claim in arbitrary textual form on an arbitrary topic, CredEye automatically retrieves relevant articles from the Web, using a search engine. It analyzes the credibility of each text by language features, the stance of the text, and the trustworthiness of the source, aggregating all these into an overall verdict. The UI of CredEye (see Figure&#x00A0;<a class="fig" href="#fig2">2</a>) enables users to dissect and drill down into the assessment by browsing through judiciously and automatically selected snippets with markup of indicative words. The latter capture linguistic features that express bias and subjectivity (decreasing credibility) or neutral and objective language (increasing credibility). Details of the analysis are shown in the form of per-article and per-source scores. CredEye is available at <a class="link-inline force-break" href="https://gate.d5.mpi-inf.mpg.de/credeye/">https://gate.d5.mpi-inf.mpg.de/credeye/</a>. </p>    <div class="table-responsive" id="tab1">     <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Different configurations of CredEye.</span>     </div>     <table class="table">     <thead>      <tr>       <th style="text-align:left;">        <strong>Method</strong>       </th>       <th style="text-align:center;">        <strong>True-Claims</strong>       </th>       <th style="text-align:center;">        <strong>False-Claims</strong>       </th>       <th>        <strong>Macro-Avg.</strong>       </th>      </tr>      <tr>       <th style="text-align:left;"/>       <th style="text-align:center;">        <strong>Accuracy (%)</strong>       </th>       <th style="text-align:center;">        <strong>Accuracy (%)</strong>       </th>       <th>        <strong>Accuracy (%)</strong>       </th>      </tr>     </thead>     <tbody>      <tr>       <td style="text-align:left;">Pipeline</td>       <td style="text-align:center;">83.20</td>       <td style="text-align:center;">80.78</td>       <td>82.00</td>      </tr>      <tr>       <td style="text-align:left;">CRF</td>       <td style="text-align:center;">71.26</td>       <td style="text-align:center;">88.74</td>       <td>80.00</td>      </tr>      <tr>       <td style="text-align:left;">LSTM</td>       <td style="text-align:center;">77.90</td>       <td style="text-align:center;">78.27</td>       <td>78.09</td>      </tr>     </tbody>     </table>    </div>   </section>   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Credibility Assessment Pipeline</h2>     </div>    </header>    <p>CredEye takes a <em>natural language claim</em> as input from the user, and computes its credibility assessment along with enriched evidence as output. Its core is the analysis of the credibility of the claim, based on the overall evidence or counter-evidence from a set of automatically retrieved Web articles. We have developed three methods to this end: a pipeline of classifiers and scoring models, a joint-inference model in the form of a Conditional Random Field, and a deep-learning neural network based on a bidirectional LSTM. In our experiments (see below) &#x2013; with limited training data &#x2013; the pipeline architecture performed best. Hence, we focus on this configuration. Note that the scarceness of training samples is typical in coping with misinformation, not just a limitation of our experiments.</p>    <p>Figure&#x00A0;<a class="fig" href="#fig1">1</a> gives an overview of the system architecture. The pipeline consists of the following stages: (i) <em>Retrieval</em> of articles from diverse Web sources by sending the claim text to a search engine, (ii) <em>Stance Detection</em> to understand the stance of each article, (iii) <em>Content Analysis</em> to understand the credibility of each article by utilizing the language style and stance-related features, (iv) <em>Credibility Aggregation</em> to merge these per-article assessments to compute the overall scoring of the claim being <em>true</em> or <em>false</em>, and (v) <em>Evidence Extraction</em> to extract supporting evidence in the form of informative snippets from the relevant web articles.</p>    <p>The classifiers are trained by distant supervision using data from <a class="link-inline force-break" href="http://snopes.com">snopes.com</a>, a popular fact-checking website that <em>manually</em> validates Internet rumors, hoaxes, urban legends, and other stories of unknown or questionable origin. We used 5,000 claims from Snopes, each labeled true or false, and retrieved 30 relevant Web articles for each of them. By assuming that the unlabeled Web articles should predominantly inherit the claim&#x0027;s label (hence <em>distant</em> supervision), we could train logistic-regression classifiers for per-article stance and per-article credibility. Table <a class="tbl" href="#tab1">1</a> shows accuracy results for the Snopes data, using 10-fold cross-validation.<a class="fn" href="#fn3" id="foot-fn3"><sup>2</sup></a>    </p>    <section id="sec-7">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Querying the Web</h3>     </div>     </header>     <p>To extract Web articles relevant to the input claim, we use the Bing search API, which allows us to restrict results to specific types (e.g., entire Web, only news, only social media etc.) and geo locations. Our system supports five such configurations for selecting articles from: (i) the entire web (no restrictions), (ii)&#x00A0;all news websites, (iii)&#x00A0;popular US news websites, (iv) popular UK news websites, and (v) social media websites (like Quora, Twitter, Facebook, blogs etc.). For this demo, we focus on English language articles, without further restrictions.</p>     <p>     <strong>Knowledge Base Lookup:</strong> Before moving to the next stage of the pipeline, we determine if the credibility of an input claim can be easily assessed by a Knowledge Base (KB) lookup. To this end, we first check if a representative <em><subject, verb, object></em> triplet could be extracted from the input claim. If yes, we query for the corresponding &#x201C;subject+verb&#x201D; and &#x201C;object+verb&#x201D;, and check if the claim can be assessed from the retrieved instant answer. For instance, given the claim <em>&#x201C;Obama was born in Kenya&#x201D;</em>, the system queries for &#x201C;obama+born&#x201D; in Bing, and assesses the claim as false based on the retrieved instant answer. Instead of relying on Bing&#x0027;s internal KB, it is also possible to use any other KB for this lookup. <figure id="fig2">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186967/images/www18companion-207-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">CredEye interface.</span>      </div>     </figure>     </p>    </section>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Stance Detection</h3>     </div>     </header>     <p>False claims are refuted by articles from trusted Web sources. Therefore, it is necessary to understand an article&#x0027;s stance towards the claim. To this end, we divide each retrieved article into a set of overlapping snippets, and extract snippets that are strongly related to the claim in terms of unigram and bigram overlap. We use the qualifying snippets to compute support and refute scores, using logistic regression classifiers trained on claims and evidence articles from Snopes. The scores are fed as features into the subsequent content analysis.</p>    </section>    <section id="sec-9">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.3</span> Content Analysis</h3>     </div>     </header>     <p>The content analysis of the articles is the core part and distinguishing characteristic of CredEye. It assesses the credibility of each article based on a suite of linguistic features (see [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0010">10</a>] for more details).</p>     <p>     <strong>Features</strong>: Our hypothesis is that true and thus credible claims are reported in an objective and unbiased language. On the other hand, subjective or sensational style of reporting a claim decreases its credibility. To capture the language style of the article, we derive features from a predefined set of lexicons (e.g., assertive and factive verbs, hedges, report verbs, subjective and biased words etc.). In addition, the support and refute scores from the stance detection step are used as features.</p>     <p>     <strong>Classifier</strong>: The credibility assessment model is a logistic regression classifier with L1-regularization, distantly trained on Snopes samples.</p>    </section>    <section id="sec-10">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.4</span> Credibility Aggregation</h3>     </div>     </header>     <p>Not all Web sources are trustworthy. Hence, to aggregate per-article credibility scores, it is essential to determine the trustworthiness of each article&#x0027;s source.</p>     <p>     <strong>Source Trustworthiness</strong>: Computing the trustworthiness of a source hinges on the following hypothesis: a Web source is trustworthy if it <em>refutes</em> non-credible claims and <em>supports</em> credible ones. We calculate the trustworthiness <em>tw</em>(<em>s</em>) of source <em>s</em> as : <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} tw(s) = \frac{\#articles\_support\_true + \#articles\_refute\_false}{\#total\_articles} \end{equation} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div> where, <span class="inline-equation"><span class="tex">$\#articles\_support\_true$</span>     </span> is the number of articles from <em>s</em> that support credible claims, <span class="inline-equation"><span class="tex">$\#articles\_refute\_false$</span>     </span> represents the number of articles from <em>s</em> that refute non-credible claims, and <span class="inline-equation"><span class="tex">$\#total\_articles$</span>     </span> is the total number of articles from <em>s</em>. We use the Snopes training data to pre-compute these trustworthiness scores for a wide variety of sources, including news sites, online communities, Wikipedia, and more. When we encounter a new source which is not present in our training data, we assign a default trustworthiness score of 0.1 (as used in our experiments).</p>     <p>     <strong>Claim Credibility</strong>: Given a claim <em>c</em> and a set of relevant articles {<em>a<sub>i</sub>     </em>} from sources {<em>s<sub>i</sub>     </em>}, we aggregate the per-article credibility scores as: <div class="table-responsive" id="Xeq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} P(c=credible) = \frac{\sum _{i}{tw(s_i) * p_{a_i}(c=credible)}}{\sum _i{tw(s_i)}} \end{equation} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div> Here, <em>P</em>(<em>c</em> = <em>credible</em>) denotes the aggregated score for the claim being credible, <span class="inline-equation"><span class="tex">$p_{a_i}(c=credible)$</span>     </span> is the credibility score of <em>a<sub>i</sub>     </em>, and <em>tw</em>(<em>s<sub>i</sub>     </em>) is the trustworthiness of <em>s<sub>i</sub>     </em>. This aggregation penalizes the credibility scores from non-trustworthy sources.</p>    </section>    <section id="sec-11">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.5</span> Evidence Extraction</h3>     </div>     </header>     <p>To present users with comprehensible evidence for credibility verdicts, we utilize the snippets of articles extracted in the stance detection step. From each article, CredEye selects the snippet that is most related to the claim and has a support or refute score that is above a threshold and agrees with the overall verdict.</p>     <p>In addition, CredEye enriches the presented snippets by highlighting salient words and bigrams. Words that are also present in the claim are highlighted in <em>yellow</em>. Words which contribute most towards the aggregated credibility score are highlighted in different shades of <em>green</em> (signaling credibility) and <em>red</em> (signaling non-credibility). The intensity of colors reflects the words&#x2019; importance for the assessment (based on feature weights from the classifier). The highlighted words and bigrams are judiciously selected from the features of the stance detection step, and also from various lexicons of subjective and emotional language (e.g., OpinionFinder MPQA).</p>    </section>   </section>   <section id="sec-12">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Demonstration</h2>     </div>    </header>    <p>CredEye can be accessed at <a class="link-inline force-break" href="https://gate.d5.mpi-inf.mpg.de/credeye/">https://gate.d5.mpi-inf.mpg.de/credeye/</a> (a recorded screencast available at <a class="link-inline force-break" href="https://youtu.be/t0SKDjovJiU">https://youtu.be/t0SKDjovJiU</a>). We encourage readers to try it out with their own inputs; we also offer some sample claims for illustration. Here, we consider two scenarios: (i) a false rumor <em>&#x201C;The use of solar panels drains the sun of energy&#x201D;</em> with &#x2018;entire web&#x2019; configuration (see Figure&#x00A0;2a) and (ii) a true statement <em>&#x201C;Italy misses the next football world cup&#x201D;</em> with &#x2018;all news&#x2019; configuration (see Figure&#x00A0;2b).</p>    <p>As shown in Figure&#x00A0;<a class="fig" href="#fig2">2</a>, the <em>input area</em> of CredEye contains a text box where the user can enter any natural language text as an input claim for assessment along with a specific configuration to restrict the article sources. Upon submitting the claim, the back-end server of CredEye carries out its analysis and returns its verdict along with evidence snippets, displayed in the <em>output area</em>. The output includes the overall assessment, displayed in the form of green (true) and red (false) bars. There are also buttons for providing feedback.</p>    <p>The most interesting part of the output is the explanation of the assessment, in the form of enriched text snippets from the Web articles that were retrieved during the analysis. As shown in Figure&#x00A0;<a class="fig" href="#fig2">2</a>, salient words in the snippets are highlighted in different colors (see Section <a class="sec" href="#sec-11">2.5</a>). Phrases present in the articles like <em>&#x201C;fake&#x201D;</em>, <em>&#x201C;satirical website&#x201D;</em>, <em>&#x201C;supposed&#x201D;</em> etc. in Figure&#x00A0;2a reduce the credibility of the claim which helps our credibility assessment pipeline to classify it as false. On the other hand, absence of biased and subjective words (decreasing credibility) in addition to objective words like <em>&#x201C;follow&#x201D;</em>, <em>&#x201C;keep&#x201D;</em>, <em>&#x201C;games&#x201D;</em>, etc. in Figure&#x00A0;2b increase the credibility of the claim. Hence, our pipeline assesses this factual statement as credible. In addition, CredEye shows the sub-scores from the various stages of its pipeline: the per-article credibility score, the refute score from the stance detection, and the trustworthiness of the source.</p>   </section>   <section id="sec-13">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Conclusion</h2>     </div>    </header>    <p>The CredEye system is a step towards coping with misinformation. One of its limitations is the lack of in-depth understanding of the exact scope and finer tone of claims. For instance, in a claim like &#x201C;the US Civil War ended slavery world-wide&#x201D; &#x2013; it is challenging for the system to understand its finer scope &#x2018;world-wide&#x2019;. Retrieving sufficient evidence or counter-evidence is another bottleneck where we hinge on search-engine results.</p>   </section>   <section id="sec-14">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Creators</h2>     </div>    </header>    <p>     <figure id="fig3">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186967/images/www18companion-207-fig3.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>     <strong>Kashyap Popat</strong> is a PhD candidate at the Max Planck Institute for Informatics. The focus of his research is on analyzing and explaining credibility of textual content. His research interests span text mining, natural language processing and deep learning.</p>    <p>     <figure id="fig4">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186967/images/www18companion-207-fig4.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>     <strong>Subhabrata Mukherjee</strong> is a scientist at Amazon building its product knowledge graph. He obtained his PhD from the Max Planck Institute for Informatics. His research interests span graphical models, deep learning, information extraction and recommender systems.</p>    <p>     <figure id="fig5">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186967/images/www18companion-207-fig5.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>     <strong>Jannik Str&#x00F6;tgen</strong> is a senior researcher at the Max Planck Institute for Informatics. He is the lead researcher of the multilingual, domain-sensitive tool HeidelTime and his research interests are in natural language processing and information retrieval.</p>    <p>     <figure id="fig6">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186967/images/www18companion-207-fig6.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>     <strong>Gerhard Weikum</strong> is a scientific director at the Max Planck Institute for Informatics. His research spans transactional and distributed systems, self-tuning database systems, data and text integration, and the automatic construction of knowledge bases.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information Credibility on Twitter. In <em>      <em>WWW 2011</em>     </em>.</li>     <li id="BibPLXBIB0002" label="[2]">Xin&#x00A0;Luna Dong, Evgeniy Gabrilovich, <em>et al.</em> 2015. Knowledge-based Trust: Estimating the Trustworthiness of Web Sources. <em>      <em>PVLDB 2015</em>     </em> (2015).</li>     <li id="BibPLXBIB0003" label="[3]">Naeemul Hassan <em>et al.</em> 2017. ClaimBuster: The First-ever End-to-end Fact-checking System. <em>      <em>PVLDB 2017</em>     </em> (2017).</li>     <li id="BibPLXBIB0004" label="[4]">Srijan Kumar, Robert West, and Jure Leskovec. 2016. Disinformation on the Web: Impact, Characteristics, and Detection of Wikipedia Hoaxes. In <em>      <em>WWW 2016</em>     </em>.</li>     <li id="BibPLXBIB0005" label="[5]">Yaliang Li, Jing Gao, Chuishi Meng, Qi Li, Lu Su, Bo Zhao, Wei Fan, and Jiaweix Han. 2015. A Survey on Truth Discovery. <em>      <em>SIGKDD Explorations 17(2), 2015</em>     </em>(2015).</li>     <li id="BibPLXBIB0006" label="[6]">Subhabrata Mukherjee, Gerhard Weikum, and Cristian Danescu-Niculescu-Mizil. 2014. People on Drugs: Credibility of User Statements in Health Communities. In <em>      <em>KDD 2014</em>     </em>.</li>     <li id="BibPLXBIB0007" label="[7]">Ndapandula Nakashole and Tom&#x00A0;M. Mitchell. 2014. Language-Aware Truth Assessment of Fact Candidates. In <em>      <em>ACL 2014</em>     </em>.</li>     <li id="BibPLXBIB0008" label="[8]">Jeff Pasternack and Dan Roth. 2013. Latent Credibility Analysis. In <em>      <em>WWW 2013</em>     </em>.</li>     <li id="BibPLXBIB0009" label="[9]">Kashyap Popat, Subhabrata Mukherjee, Jannik Str&#x00F6;tgen, and Gerhard Weikum. 2016. Credibility Assessment of Textual Claims on the Web. In <em>      <em>CIKM 2016</em>     </em>.</li>     <li id="BibPLXBIB0010" label="[10]">Kashyap Popat, Subhabrata Mukherjee, Jannik Str&#x00F6;tgen, and Gerhard Weikum. 2017. Where the Truth Lies: Explaining the Credibility of Emerging Claims on the Web and Social Media. In <em>      <em>WWW 2017</em>     </em>.</li>     <li id="BibPLXBIB0011" label="[11]">Vahed Qazvinian, Emily Rosengren, Dragomir&#x00A0;R. Radev, and Qiaozhu Mei. 2011. Rumor has it: Identifying Misinformation in Microblogs. In <em>      <em>EMNLP 2011</em>     </em>.</li>     <li id="BibPLXBIB0012" label="[12]">Xiaoxin Yin, Jiawei Han, and Philip&#x00A0;S. Yu. 2008. Truth Discovery with Multiple Conflicting Information Providers on the Web. <em>      <em>TKDE 20(6), 2008</em>     </em> (2008).</li>     <li id="BibPLXBIB0013" label="[13]">Shi Zhi <em>et al.</em> 2017. ClaimVerif: A Real-time Claim Verification System Using the Web and Fact Databases. In <em>      <em>CIKM 2017</em>     </em>.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>Work done at the Max Planck Institute for Informatics prior to joining Amazon.</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a><a class="link-inline force-break"     href="https://www.fema.gov/hurricane-irma-rumor-control">https://www.fema.gov/hurricane-irma-rumor-control</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a>Data available at&#x00A0;<a class="link-inline force-break" href="http://bit.ly/web-credibility-analysis">http://bit.ly/web-credibility-analysis</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186967">https://doi.org/10.1145/3184558.3186967</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
