<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Hierarchical Variational Memory Network for Dialogue
  Generation</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a HTML copy of <a href='https://doi.org/10.1145/3178876.3186077'>https://doi.org/10.1145/3178876.3186077</a> 
originally published by ACM, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML accessability, compatibility, 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186077'>https://w3id.org/oa/10.1145/3178876.3186077</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Hierarchical Variational Memory
          Network for Dialogue Generation</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Hongshen</span> <span class=
          "surName">Chen</span><a class="fn" href="#fn1" id=
          "foot-fn1"><sup>*</sup></a>, Data Science Lab, JD.com,
          <a href=
          "mailto:chenhongshen@jd.com">chenhongshen@jd.com</a>
        </div>
        <div class="author">
          <span class="givenName">Zhaochun</span> <span class=
          "surName">Ren</span><a class="fn" href="#fn1" id=
          "foot-fn1"><sup>*</sup></a>, Data Science Lab, JD.com,
          <a href=
          "mailto:renzhaochun@jd.com">renzhaochun@jd.com</a>
        </div>
        <div class="author">
          <span class="givenName">Jiliang</span> <span class=
          "surName">Tang</span>, Data Science and Engineering Lab
          Michigan State University, <a href=
          "mailto:tangjili@msu.edu">tangjili@msu.edu</a>
        </div>
        <div class="author">
          <span class="givenName">Yihong Eric</span> <span class=
          "surName">Zhao</span>, JD.com, <a href=
          "mailto:ericzhao@jd.com">ericzhao@jd.com</a>
        </div>
        <div class="author">
          <span class="givenName">Dawei</span> <span class=
          "surName">Yin</span><a class="fn" href="#fn2" id=
          "foot-fn2"><sup>†</sup></a>, Data Science Lab, JD.com,
          <a href="mailto:yindawei@acm.org">yindawei@acm.org</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.3186077"
        target=
        "_blank">https://doi.org/10.1145/3178876.3186077</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Dialogue systems help various real applications
        interact with humans in an intelligent natural way. In
        dialogue systems, the task of dialogue generation aims to
        generate utterances given previous utterances as contexts.
        Among various spectrums of dialogue generation approaches,
        end-to-end neural generation models have received an
        increase of attention. These end-to-end neural generation
        models are capable of generating natural-sounding sentences
        with a unified neural encoder-decoder network structure.
        The end-to-end structure sequentially encodes each word in
        an input context and generates the response word-by-word
        deterministically during decoding. However, lack of
        variation and limited ability in capturing long-term
        dependencies between utterances still challenge existing
        approaches. In this paper, we propose a novel
        <em>hierarchical variational memory network</em> (HVMN), by
        adding the hierarchical structure and the variational
        memory network into a neural encoder-decoder network. By
        emulating human-to-human dialogues, our proposed method can
        capture both the high-level abstract variations and
        long-term memories during dialogue tracking, which enables
        the random access of relevant dialogue histories. Extensive
        experiments conducted on three large real-world datasets
        verify a significant improvement of our proposed model
        against state-of-the-art baselines for dialogue
        generation.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS
        Concepts:</span> • <strong>Information systems</strong> →
        <strong>Retrieval tasks and goals;</strong>
        <strong>Question answering;</strong></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Dialogue
          generation</small>,</span> <span class=
          "keyword"><small>Hierarchical Variational Memory
          Network</small>,</span> <span class=
          "keyword"><small>Recurrent Encoder-Decoder
          Model</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Hongshen Chen, Zhaochun Ren, Jiliang Tang, Yihong Eric
          Zhao, and Dawei Yin. 2018. Hierarchical Variational
          Memory Network for Dialogue Generation. In <em>WWW 2018:
          The 2018 Web Conference,</em> <em>April 23–27, 2018,</em>
          <em>Lyon, France. ACM, New York, NY, USA</em>, 11 Pages.
          <a href="https://doi.org/10.1145/3178876.3186077" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3178876.3186077</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Dialogue generation aims to generate natural-sounding
      replies automatically to exchange information (e.g.,
      knowledge, sentiments, etc.) and complete a variety of
      specific tasks in a conversation interaction
      process&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0035">35</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0044">44</a>]. In recent years, automatic dialogue
      generation has received increasing attention in numerous
      applications from e-commerce technical support to personal
      assistant tools&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0036">36</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0044">44</a>]. Among all these approaches,
      end-to-end neural generation models&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0020">20</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0021">21</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0033">33</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0034">34</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0038">38</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0041">41</a>] have been proved to be
      capable in multiple dialogue system applications with
      promising performance. Most of these end-to-end neural
      generation models apply encoder-decoder architecture based on
      recurrent neural network, which directly maps an input
      context to the output response.</p>
      <p>However, challenging problems still exist in current
      neural models for dialogue generation&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0006">6</a>]: (1) Meaningless
      responses: Given a wide range of contexts, dialogue systems
      trained via neural generation models are still likely to
      generate short but pointless responses, such as “ha-ha” and
      “I don't know”. Since these neural generation models are
      deterministic and shorter responses often have higher
      likelihood in posterior inference, these models inject no
      variation during the generation of reply&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0006">6</a>]; (2) Memory decay:
      Vanishing memory is always a challenging problem in the task
      of dialogue generation. A dialogue session usually contains
      multiple turns, the longer the conversation moves forward,
      the harder to capture the long-term memorial dependencies. In
      particular, the injection of variability exacerbates the
      difficulty to capture the long-term memory. As a consequence,
      the response generation for long utterance context is
      extremely hard, which determines the response generation for
      long utterance context a rather difficult problem.</p>
      <p>In this paper, we aim at developing methods that can
      tackle challenges of meaningless response and long-term
      memory dependencies, simultaneously. As an example, consider
      a dialogue session in Figure&nbsp;<a class="fig" href=
      "#fig1">1</a>. Compared with Response 1, although both
      responses are suitable for the context, Response 2 is more
      meaningful than its counterpart. With the dialogue session
      moving forward, modeling the utterance dependencies becomes
      more and more difficult. As a result, the system generates
      tedious but reasonable responses. Three obstacles hinder the
      diversification of the response, and long-term dependencies
      in response generation: (1) utterance sequence modeling is
      difficult, as a dialogue session consists of multiple
      utterances; (2) conversation informativeness should be
      considered not only within an utterance but also across the
      utterances; and (3) as the conversation goes on, it is
      important to learn the long-term dependencies.</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186077/images/www2018-86-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">Two different responses for the same
          context.</span>
        </div>
      </figure>
      <p></p>
      <p>Our attempt to tackle above obstacles leads to a novel
      framework, i.e., HVMN, a <strong>H</strong>ierarchical
      <strong>V</strong>ariational <strong>M</strong>emory
      <strong>N</strong>etwork (<strong>HVMN</strong>). It combines
      the spirits of variational autoencoder [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0019">19</a>] and memory networks
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0039">39</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0040">40</a>] in a
      hierarchical recurrent neural network setting and aims to
      memorize the dialogue histories while retrieving the memory
      with a bit of randomness. The hierarchical structure encodes
      the utterance sequences, while the variational memory samples
      a latent variable for each utterance, conditioned on all the
      previous information, and then memory cells are retrieved by
      the latent variable. The memory cells keep updated to
      memorize the new utterance and the response generation
      decoder is guided by the variational memory block. We conduct
      extensive experiments on two benchmark datasets and an
      e-commerce custom-service dataset. Experimental results show
      that HVMN outperforms state-of-the-art baselines and
      generates more informative responses.</p>
      <p>Our main contributions can be summarized as follows:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">We identify the problems of
        response informativeness, and long-term utterance
        dependencies in dialogue generation.<br /></li>
        <li id="list2" label="•">We build a hierarchical
        variational memory network model to generate reasonable,
        informative, and diversified responses by bridging the
        hierarchical architecture and variational memory
        network.<br /></li>
        <li id="list3" label="•">The proposed framework is
        validated by the extensive experiments and outperforms the
        state-of-the-arts on both metric-based and human
        evaluations.<br /></li>
      </ul>
      <p>The remaining of the paper is organized as follows. We
      formulate our research problem in §<a class="sec" href=
      "#sec-7">2</a> and describe our approach in §<a class="sec"
      href="#sec-10">3</a>. Then, §<a class="sec" href=
      "#sec-15">4</a> details our experimental setup and results.
      Related work is presented in §<a class="sec" href=
      "#sec-24">5</a>. Finally, §<a class="sec" href=
      "#sec-27">6</a> concludes the paper.</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span>
          Preliminaries</h2>
        </div>
      </header>
      <p>In this section, we first formulate the dialogue
      generation task formally, and then introduce preliminaries of
      sequence to sequence models.</p>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Task
            Definition</h3>
          </div>
        </header>
        <p>Before getting into the dialogue generation task, We
        introduce our key notations and concepts. Table
        &nbsp;<a class="tbl" href="#tab1">1</a> lists the main
        notation we use.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Glossary.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;">Symbol</th>
                <th style="text-align:left;">Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;"><em>D</em></td>
                <td style="text-align:left;">a dialogue
                session</td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>U</em></td>
                <td style="text-align:left;">an utterance</td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>w</em></td>
                <td style="text-align:left;">a word in an
                utterance</td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>M</em></td>
                <td style="text-align:left;">number of utterances
                in <em>D</em></td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>m</em></td>
                <td style="text-align:left;"><em>m</em>’th
                utterance in <em>D</em></td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>N</em></td>
                <td style="text-align:left;">length of an
                utterance</td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>V</em></td>
                <td style="text-align:left;">vocabulary</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                <strong>e</strong></td>
                <td style="text-align:left;">embedding mapping
                function</td>
              </tr>
              <tr>
                <td style="text-align:left;"><span class=
                "inline-equation"><span class="tex">$\mathbf
                {h}_{t}^{enc}$</span></span></td>
                <td style="text-align:left;">encoder hidden state
                at time step <em>t</em></td>
              </tr>
              <tr>
                <td style="text-align:left;"><span class=
                "inline-equation"><span class="tex">$\mathbf
                {h}_{t}^{dec}$</span></span></td>
                <td style="text-align:left;">decoder hidden state
                at time step <em>t</em></td>
              </tr>
              <tr>
                <td style="text-align:left;"><strong>h</strong>
                <sup><em>u</em></sup></td>
                <td style="text-align:left;">hidden state of the
                utterance encoder</td>
              </tr>
              <tr>
                <td style="text-align:left;"><strong>h</strong>
                <sup><em>con</em></sup></td>
                <td style="text-align:left;">hidden state of the
                context encoder</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                <strong>M</strong></td>
                <td style="text-align:left;">memory cells</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                <strong>b</strong></td>
                <td style="text-align:left;">variational memory
                output</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                <strong>z</strong></td>
                <td style="text-align:left;">latent variable</td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>P</em></td>
                <td style="text-align:left;">prior
                distribution</td>
              </tr>
              <tr>
                <td style="text-align:left;"><em>Q</em></td>
                <td style="text-align:left;">posterior
                distribution</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                <strong>F</strong></td>
                <td style="text-align:left;">forget gate</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                <strong>U</strong></td>
                <td style="text-align:left;">update gate</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>A dialogue session consists of a sequence of <em>M</em>
        turns of utterances <em>D</em> = <em>U</em> <sub>1</sub>,
        .., <em>U<sub>M</sub></em> between two interlocutors. At
        <em>m</em>-th turn, given previous utterances <em>U</em>
        <sub>1</sub>, ..., <em>U</em> <sub><em>m</em> − 1</sub>,
        the dialogue generation model aims to calculate the
        probability of <em>U<sub>m</sub></em> given <em>U</em>
        <sub>1</sub>, ..., <em>U</em> <sub><em>m</em> − 1</sub>,
        i.e., <em>P</em>(<em>U<sub>m</sub></em> |<em>U</em>
        <sub>1</sub>, .., <em>U</em> <sub><em>m</em> −
        1</sub>).</p>
        <p>Each utterance <em>U<sub>m</sub></em> is a
        variable-length sequence of words, i.e., <em>w</em>
        <sub><em>m</em>, 1</sub>, ... <span class=
        "inline-equation"><span class=
        "tex">$,w_{m,N_{m}}$</span></span> , where <em>w</em>
        <sub><em>m</em>, <em>n</em></sub> is the <em>n</em>th word
        of the utterance <em>U<sub>m</sub></em> , and
        <em>N<sub>m</sub></em> is the length of utterance.
        <em>P</em>(<em>U<sub>m</sub></em> |<em>U</em> <sub>1</sub>,
        .., <em>U</em> <sub><em>m</em> − 1</sub>) is modeled by
        decomposing the probability distribution over both the
        previous utterances and the previously generated words:</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \nonumber
            P(w_{m,1},&amp;...,w_{m,N_{m}}|U_{1},...,U_{m-1})=\\
            &amp;\prod
            _{n=1}^{N_{m}}P(w_{m,n}|U_{1},...,U_{m-1},w_{{\lt}n}).
            \end{align}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>
        <p></p>
      </section>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Sequence to
            Sequence Models</h3>
          </div>
        </header>
        <p>Our work is based on sequence-to-sequence (SEQ2SEQ)
        models. Sequence-to-sequence models prevail in natural
        language modeling and machine translation tasks [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0009">9</a>]. Shang
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0034">34</a>], Sordoni et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0038">38</a>] and
        Vinyals and Le [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0041">41</a>] introduced it into conversation
        modeling. It composed of an encoder, which takes in words
        sequence of previous utterances and outputs a fix-sized
        context vector which summarizes all previous utterances. It
        also provides a decoder to generate the next utterance
        word-by-word based on the context vector and the recurrent
        hidden state through the prediction over a discrete
        vocabulary <em>V</em>.</p>
        <p>The encoder and decoder process the input sequence and
        output sequence based on recurrent neural network (RNN). At
        each step, the encoder RNN unit takes in a word and updates
        its hidden state:</p>
        <div class="table-responsive" id="Xeq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf
            {h}_{t}^{enc}=\sigma (\mathbf {h}_{t-1}^{enc},\mathbf
            {e}_{w_{t}}), \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>while decoder RNN is computed by
        <div class="table-responsive" id="Xeq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf
            {h}_{t}^{dec}=\sigma (\mathbf {h}_{t-1}^{dec},\mathbf
            {e}_{w_{t}},\mathbf {c}), \end{equation}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>where <em>σ</em> is a nonlinear activation function.
        It can be as simple as an element-wise logistic sigmoid
        function and more complex ones like long short-term memory
        (LSTM)[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0016">16</a>] or Gated Recurrent Unit (GRU)
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0009">9</a>].
        <em>e</em> is a word embedding mapping function.
        <strong>c</strong> is the last hidden state of encoder RNN,
        which is the summary of the whole input sequence.
        <p></p>
        <p>The output distribution of the decoder is used to
        predict the next token and is parameterized by a softmax
        function over an affine transformation of the decoder RNN
        hidden state <span class="inline-equation"><span class=
        "tex">$\mathbf {h}_{t}^{dec}$</span></span> :</p>
        <div class="table-responsive" id="Xeq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} P_{\theta
            }(w_{t+1}=v|w_{1},...,w_{t})=\\ \frac{\exp (g(\mathbf
            {h}_{t}^{dec},v))}{\Sigma _{{v}^{\prime }}\exp
            (g(\mathbf {h}_{t}^{dec},{v}^{\prime }))}.
            \end{equation}</span><br />
            <span class="equation-number">(4)</span>
          </div>
        </div>, where <em>g</em> is the affine-transformation
        function. The model parameters are turned by maximizing the
        log-likelihood over the training instances by stochastic
        gradient descent.
        <p></p>
      </section>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Hierarchical
          Variational Memory Network</h2>
        </div>
      </header>
      <p>In this section, we propose a hierarchical variational
      memory network (HVMN) to model the dialogue generation
      process. The model employs a hierarchical RNN to model the
      dialogue utterances in both the utterance level and the
      context level. In particular, a dialogue consisting of
      utterance sequence <em>U</em> <sub>1</sub>, ...,
      <em>U<sub>m</sub></em> is modeled as:</p>
      <div class="table-responsive" id="Xeq4">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation}
          P(U_{1},...,U_{M})= \prod _{m=1}^{M}P(U_{m}|U_{{\lt}m}),
          \end{equation}</span><br />
          <span class="equation-number">(5)</span>
        </div>
      </div>As each utterance <em>U<sub>m</sub></em> is a sequence
      of words <span class="inline-equation"><span class=
      "tex">$w_{m,1},...,w_{m,N_{m}}$</span></span> , a dialogue is
      then formulated as:
      <div class="table-responsive" id="Xeq5">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation}
          P(U_{1},...,U_{M})= \prod _{m=1}^{M}\prod
          _{n=1}^{N_{m}}P(w_{m,n}|U_{{\lt}m},w_{m,{\lt}n}).
          \end{equation}</span><br />
          <span class="equation-number">(6)</span>
        </div>
      </div>A variational memory network then utilizes a latent
      variable and a memory block to capture the abstract and
      concrete details and complex long-term dependencies during
      the dialogue tracing. When decoding, the previous generated
      words of response are also given as the input to the decoder.
      The whole architecture is shown in Figure <a class="fig"
      href="#fig2">2</a>. HVMN learns to generate sequences in four
      steps:
      <p></p>
      <figure id="fig2">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186077/images/www2018-86-fig2.jpg"
        class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class=
          "figure-title">Structure of the hierarchical variational
          memory network. Orange lines indicate the part of memory
          reading. Red line is the part of memory updating. Dashed
          line denotes our posterior approximation.</span>
        </div>
      </figure>
      <ol class="list-no-style">
        <li id="list4" label="(1)">The utterance <em>encoder</em>
        RNN encodes each turn of utterance word-by-word into a
        fixed-size vector, which is then sequentially given as
        input to the <em>context</em> RNN.<br /></li>
        <li id="list5" label="(2)">The <em>context</em> RNN
        computes a hidden state <span class=
        "inline-equation"><span class="tex">$\mathbf
        {h}_{m}^{con}$</span></span> for <em>m</em>’th
        utterance.<br /></li>
        <li id="list6" label="(3)">Then at <em>variational
        memory</em> block, a latent variable is sampled to retrieve
        the memory cells as <strong>b</strong>
        <sub><em>m</em></sub> , meanwhile the memory is also
        updated with <span class="inline-equation"><span class=
        "tex">$\mathbf {h}_{m}^{con}$</span></span> to
        accumulatively memorize the current utterance.<br /></li>
        <li id="list7" label="(4)">The <em>decoder</em> RNN takes
        <span class="inline-equation"><span class="tex">$\mathbf
        {h}_{m}^{con}$</span></span> and <strong>b</strong>
        <sub><em>m</em></sub> as input to generate the
        response.<br /></li>
      </ol>
      <p>Next, we will first introduce the hierarchical utterance
      encoding process through <em>encoder</em> RNN and
      <em>context</em> RNN in §<a class="sec" href=
      "#sec-11">3.1</a>. Then, we detail the variational memory
      reading and updating mechanism in §<a class="sec" href=
      "#sec-12">3.2</a>. Finally, the response decoding is depicted
      in §<a class="sec" href="#sec-13">3.3</a>.</p>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Utterance
            Encoding</h3>
          </div>
        </header>
        <p>The hierarchical recurrent neural network [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0037">37</a>] regards
        the utterance sequence in two levels: each utterance is
        composed of a sequence of words, and a dialogue is a
        sequence of utterances.</p>
        <p>Based on such observation, for an utterance <span class=
        "inline-equation"><span class=
        "tex">$U_{m}=w_{m,1},...,w_{m,N_{m}}$</span></span> , the
        utterance <em>encoder</em> RNN maps it to an utterance
        vector, which is the hidden state after <span class=
        "inline-equation"><span class=
        "tex">$w_{m,N_{m}}$</span></span> is processed. A word
        <em>w</em> <sub><em>m</em>, <em>n</em></sub> is encoded
        by:</p>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf
            {h}_{m,n}^{u}=\sigma (\mathbf {h}_{m,n-1}^{u}, \mathbf
            {e}_{w_{m,n}}), \end{equation}</span><br />
            <span class="equation-number">(7)</span>
          </div>
        </div>where <em>σ</em> is the nonlinear activation function
        like LSTM or GRU, <span class=
        "inline-equation"><span class="tex">$\mathbf
        {e}_{w_{m,n}}$</span></span> is the embedding of word
        <em>w</em> <sub><em>m</em>, <em>n</em></sub> , and
        <span class="inline-equation"><span class="tex">$\mathbf
        {h}^{u}_{m,n}$</span></span> is the hidden state after
        processing <em>w</em> <sub><em>m</em>, <em>n</em></sub> .
        <span class="inline-equation"><span class="tex">$\mathbf
        {h}_{m,N_{m}}^{u}$</span></span> is the utterance vector
        <span class="inline-equation"><span class="tex">$\mathbf
        {h}_{m}^{u}$</span></span> of utterance
        <em>U<sub>m</sub></em> , which can be viewed as the
        summarization of current utterance.
        <p></p>
        <p>Then, the <em>context</em> RNN records the utterance
        sequence by:</p>
        <div class="table-responsive" id="Xeq6">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf
            {h}_{m}^{con}=\sigma (\mathbf {h}_{m-1}^{con}, \mathbf
            {h}_{m}^{u}), \end{equation}</span><br />
            <span class="equation-number">(8)</span>
          </div>
        </div>where <span class="inline-equation"><span class=
        "tex">$\mathbf {h}_{m}^{con}$</span></span> is the hidden
        state of context RNN given utterance vector <span class=
        "inline-equation"><span class="tex">$\mathbf
        {h}_{m}^{u}$</span></span> , and <em>σ</em> is the same
        non-linear activation function in Eq.<a class="eqn" href=
        "#eq2">7</a>. <span class="inline-equation"><span class=
        "tex">$\mathbf {h}_{m}^{con}$</span></span> is the summary
        of all the observed previous utterances.
        <p></p>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Variational
            Memory Network</h3>
          </div>
        </header>
        <p><strong>Variational Memory Reading
        Mechanism.</strong></p>
        <p>The model draws <strong>b</strong> <sub><em>m</em></sub>
        from memory <strong>M</strong> using a continuous
        stochastic latent variable <strong>z</strong>
        <sub><em>m</em></sub> :</p>
        <div class="table-responsive" id="Xeq7">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf
            {b}_{m}=\prod _{i}^{I}\mathbf {M}_{m}^{i} \odot \mathbf
            {z}^{i}_{m}, \end{equation}</span><br />
            <span class="equation-number">(9)</span>
          </div>
        </div>where <span class="inline-equation"><span class=
        "tex">$\mathbf {M}_{m}\in \mathbb {R}^{d_{i}\times
        d_{z}}$</span></span> , <span class=
        "inline-equation"><span class="tex">$\mathbf {z}_{m}\in
        \mathbb {R}^{d_{i}}$</span></span> , and ⊙ is Hadamard
        product function. Figure <a class="fig" href="#fig3">3</a>
        illustrates the variational memory reading mechanism.
        <p></p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186077/images/www2018-86-fig3.jpg"
          class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">Variational memory reading
            mechanism.</span>
          </div>
        </figure>
        <p>The latent variable <strong>z</strong>
        <sub><em>m</em></sub> is conditioned on all the previous
        observed tokens, namely the output of <em>context</em> RNN
        <span class="inline-equation"><span class="tex">$\mathbf
        {h}_{m}^{con}$</span></span> , and is computed for each
        utterance:</p>
        <div class="table-responsive" id="Xeq8">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} P(\mathbf
            {z}_{m}|U_{{\lt}m})=N(\mu _{prior}(U_{{\lt}m}),\Sigma
            _{prior}(U_{{\lt}m})), \end{equation}</span><br />
            <span class="equation-number">(10)</span>
          </div>
        </div>where <em>N</em>(<em>μ</em>, <em>Σ</em>) is the
        multivariate normal distribution with mean <span class=
        "inline-equation"><span class="tex">$\mu \in \mathbb
        {R}^{d_{i}}$</span></span> and a constrained diagonal
        covariance matrix <span class=
        "inline-equation"><span class="tex">$\Sigma \in \mathbb
        {R}^{d_{i} \times d_{i}}$</span></span> .
        <strong>z</strong> <sub><em>m</em></sub> is inferred by
        maximizing the lower-bound for each utterance:
        <div class="table-responsive" id="eq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \nonumber \log
            P(U_{1},...,U_{m}) &amp; \ge \sum _{m=1}^{M}-KL[Q_{\psi
            }(\mathbf {z}_{m}|U_{1},...,U_{m})||P(\mathbf
            {z}_{m}|U_{{\lt}m})]\\ &amp;+\mathbb {E}_{Q_{\psi
            }(\mathbf {z}_{m}|U_{1},...,U_{m})}[\log
            P(U_{m}|\mathbf {z}_{m},U_{{\lt}m})],
            \end{align}</span><br />
            <span class="equation-number">(11)</span>
          </div>
        </div>where <em>KL</em>(<em>Q</em>||<em>P</em>) is the
        Kullback-Leibler (KL) divergence between distributions
        <em>Q</em> and <em>P</em>. The posterior distribution
        <em>Q<sub>ψ</sub></em> approximates the intractable true
        posterior distribution:
        <div class="table-responsive" id="eq4">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \nonumber
            &amp;Q_{\psi }(\mathbf {z}_{m}|U_{1},...,U_{m})\\
            &amp;=N(\mu _{posterior}(U_{1},...,U_{m}),\Sigma
            _{posterior}(U_{1},...,U_{m}))\end{align}</span><br />
            <span class="equation-number">(12)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq5">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} &amp;\approx
            P_{\psi }(\mathbf {z}_{m}|U_{1},...,U_{m}),
            \end{align}</span><br />
            <span class="equation-number">(13)</span>
          </div>
        </div>where <em>μ<sub>posterior</sub></em> is the
        approximate posterior mean, and
        <em>Σ<sub>posterior</sub></em> is the posterior covariance
        diagonal matrix conditioned on previous utterances
        <em>U</em> <sub>1</sub>, ..., <em>U</em> <sub><em>m</em> −
        1</sub> and current utterance <em>U<sub>m</sub></em> .
        <p></p>
        <p>The approximate prior and posterior mean and covariance
        are computed through a feedforward network, respectively.
        The former is conditioned on <span class=
        "inline-equation"><span class="tex">$\mathbf
        {h}_{m}^{con}$</span></span> and the latter is conditioned
        on both <span class="inline-equation"><span class=
        "tex">$\mathbf {h}_{m}^{con}$</span></span> and
        <span class="inline-equation"><span class="tex">$\mathbf
        {h}_{m+1}^{enc}$</span></span> . A matrix multiplication is
        performed to compute mean, and a matrix multiplication
        function followed by a softplus function is implemented to
        output the diagonal covariance matrix:</p>
        <div class="table-responsive" id="eq6">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \mathbf
            {z}_{m}^{prior}&amp;=\mu _{prior}+\Sigma _{prior}\odot
            \epsilon _{prior},\end{align}</span><br />
            <span class="equation-number">(14)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq7">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \mathbf
            {z}_{m}^{posterior}&amp;=\mu _{posterior}+\Sigma
            _{posterior}\odot \epsilon _{posterior},
            \end{align}</span><br />
            <span class="equation-number">(15)</span>
          </div>
        </div>where ϵ <sub><em>prior</em></sub> and ϵ
        <sub><em>posterior</em></sub> are standard Gaussian
        variables. <strong>Variational Memory Updating</strong>
        <p></p>
        <p>Figure <a class="fig" href="#fig4">4</a> illustrates the
        variational memory updating mechanism. For each utterance,
        the memory <strong>M</strong> <sub><em>m</em></sub> is
        updated with <span class="inline-equation"><span class=
        "tex">$\mathbf {h}_{m}^{con}$</span></span> in order to
        capture details for long-term dependencies. Inspired by the
        writing mechanism of neural turing machines [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0014">14</a>], we utilize a
        <em>Forget</em> and an <em>Update</em> operation. In
        particular, the forget gate <span class=
        "inline-equation"><span class="tex">$\mathbf {F}_{m}\in
        \mathbb {R}^{d_{i}}$</span></span> defines to what extent
        the value of each memory cell to be erased, and the update
        gate <span class="inline-equation"><span class=
        "tex">$\mathbf {U}_{m} \in \mathbb
        {R}^{d_{i}}$</span></span> specializes how much information
        of <span class="inline-equation"><span class="tex">$\mathbf
        {h}_{m}^{con}$</span></span> can be written to the memory.
        Typically, the memory is updated by:</p>
        <div class="table-responsive" id="Xeq9">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf
            {M}_{m}=\mathbf {F}_{m} \odot \mathbf {M}_{m-1}+
            \mathbf {U}_{m} \odot \mathbf {h}_{m}^{update},
            \end{equation}</span><br />
            <span class="equation-number">(16)</span>
          </div>
        </div>where <strong>F</strong> <sub><em>m</em></sub> and
        <strong>U</strong> <sub><em>m</em></sub> are computed by a
        <em>sigmoid</em> function parameterized with a linear
        combination of <span class="inline-equation"><span class=
        "tex">$\mathbf {h}_{m}^{con}, \mathbf {b}_{m}, \mathbf
        {M}_{m}$</span></span> :
        <div class="table-responsive" id="eq8">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \mathbf
            {F}_{m}=sigmoid(\mathbf {h}_{m}^{con}, \mathbf {b}_{m},
            \mathbf {M}_{m})\end{align}</span><br />
            <span class="equation-number">(17)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq9">
          <div class="display-equation">
            <span class="tex mytex">\begin{align} \mathbf
            {U}_{m}=sigmoid(\mathbf {h}_{m}^{con}, \mathbf {b}_{m},
            \mathbf {M}_{m}) \end{align}</span><br />
            <span class="equation-number">(18)</span>
          </div>
        </div><span class="inline-equation"><span class=
        "tex">$\mathbf {h}_{m}^{update}$</span></span> is defined
        as:
        <div class="table-responsive" id="Xeq10">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf
            {h}_{m}^{update}=\sigma (\mathbf {h}_{m}^{con}, \mathbf
            {b}_{m}), \end{equation}</span><br />
            <span class="equation-number">(19)</span>
          </div>
        </div>where <em>σ</em> is a non-linear activation function
        like <em>sigmoid</em> or <em>tanh</em>.
        <p></p>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186077/images/www2018-86-fig4.jpg"
          class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">Variational memory updating
            mechanism. The left memory block is the old memory and
            the right one is the updated block.</span>
          </div>
        </figure>
      </section>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span> Dialogue
            Decoding</h3>
          </div>
        </header>
        <p>During dialogue generation, given the observed
        utterances, the latent variable <strong>z</strong>
        <sub><em>m</em></sub> is drawn from the prior
        <em>N</em>(<em>μ</em>, <em>Σ</em>). Then,
        <strong>z</strong> <sub><em>m</em></sub> retrieves
        <strong>b</strong> <sub><em>m</em></sub> from the memory
        cells. Finally, the embedding of last predicted word
        <span class="inline-equation"><span class="tex">$\mathbf
        {e}_{w_{t-1}}$</span></span> , <strong>b</strong>
        <sub><em>m</em></sub> , and the output of context RNN
        <span class="inline-equation"><span class="tex">$\mathbf
        {h}_{m}^{con}$</span></span> are given as input to the
        decoder RNN. In particular, the recurrent unit of decoder
        is defined as:</p>
        <div class="table-responsive" id="Xeq11">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \mathbf
            {h}_{t}^{dec}=\sigma (\mathbf {h}_{t-1}^{dec}, \mathbf
            {e}_{w_{t-1}}, \mathbf {h}_{m}^{con},\mathbf {b}_{m}),
            \end{equation}</span><br />
            <span class="equation-number">(20)</span>
          </div>
        </div>where <em>σ</em> can be a simple <em>sigmoid</em>
        function or GRU, LSTM.
        <p></p>
        <p>The probability distribution of the next token is given
        by a softmax function over <span class=
        "inline-equation"><span class="tex">$\mathbf
        {h}_{t}^{dec}$</span></span> :</p>
        <div class="table-responsive" id="Xeq12">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} P_{\theta
            }(w_{t+1}=v|\mathbf {h}_{t}^{dec})=\frac{\exp
            (g(\mathbf {h}_{t}^{dec},v))}{\Sigma _{{v}^{\prime
            }}\exp (g(\mathbf {h}_{t}^{dec},{v}^{\prime }))}.
            \end{equation}</span><br />
            <span class="equation-number">(21)</span>
          </div>
        </div>, where <em>g</em> is the affine-transformation
        function.
        <p></p>
      </section>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.4</span>
            Discussions</h3>
          </div>
        </header>
        <p>The conditional prior distribution over variable
        <strong>z</strong> <sub><em>m</em></sub> injects variation
        for dialogue generation at the utterance-level, while the
        conditional distribution over word tokens performs
        variation at the word-level. As <strong>z</strong>
        <sub><em>m</em></sub> is constrained by the KL divergence
        between the prior and posterior, <strong>z</strong>
        <sub><em>m</em></sub> varies slowly along the utterances,
        and makes higher-level decisions about what to generate,
        like the conversation topic, speaker goals or sentiment of
        the utterance, which helps model long-term output
        trajectories [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0032">32</a>]. In Serban et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0032">32</a>],
        <strong>z</strong> <sub><em>m</em></sub> directly guides
        the decoder, which increases the response diversity,
        however, the response appropriateness is weakened due to
        the lack of long-term memories. As <strong>z</strong>
        <sub><em>m</em></sub> is a single vector conditioned on all
        previous observed tokens and injected with Gaussian noise,
        details of the utterances are unable to be well
        managed.</p>
        <p>In HVMN, the latent variable <strong>z</strong>
        <sub><em>m</em></sub> incorporates with the memory cells,
        which mimics the random access of relevant histories, where
        <strong>z</strong> <sub><em>m</em></sub> focuses on
        higher-level abstraction, like topics, sentiments, and
        personalites[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0022">22</a>], in the meantime the memory cells
        specialize in maintaining the long-term details of the
        observed utterances.Memory cells are retrieved by the
        stochastic latent variable <strong>z</strong>
        <sub><em>m</em></sub> , and then updated deterministically
        with the new utterance.</p>
      </section>
    </section>
    <section id="sec-15">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span>
          Experiments</h2>
        </div>
      </header>
      <p>To evaluate the effectiveness of the hierarchical
      variational memory neural model, we list the following
      questions to guide the reminder of our experiments:</p>
      <ul class="list-no-style">
        <li id="list8" label="•"><strong>RQ1</strong>: Is our model
        effective for generating dialogues? Dose it outperforms
        state-of-the-art baselines?<br /></li>
        <li id="list9" label="•"><strong>RQ2</strong>: How does our
        proposed method perform in human evaluation
        experiments?<br /></li>
        <li id="list10" label="•"><strong>RQ3</strong>: What is the
        effect of context length for generating dialogues in our
        method?<br /></li>
      </ul>
      <p>Next, we introduce the datasets in §<a class="sec" href=
      "#sec-16">4.1</a>. The baselines are listed in §<a class=
      "sec" href="#sec-17">4.2</a> and evaluation metrics are
      described in §<a class="sec" href="#sec-18">4.3</a>. Details
      of the training setting are described in §<a class="sec"
      href="#sec-19">4.4</a>.</p>
      <section id="sec-16">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span>
            Datasets</h3>
          </div>
        </header>
        <p>In order to assess the performance of our methods, we
        conduct experiments on three datasets with different
        styles. Two of them have been used in previous
        work&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0026">26</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0043">43</a>], and another one is extracted from
        JD.com&nbsp;<a class="fn" href="#fn3" id=
        "foot-fn3"><sup>1</sup></a>. Table&nbsp;<a class="tbl"
        href="#tab2">2</a> provides descriptive statistics about
        our datasets.</p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Corpus statistics including number of
            dialogues in training, validation and test sets,
            average number of turns, utterances, words per
            dialogue, and vocabulary size.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;">Corpus</th>
                <th style="text-align:left;">#Train</th>
                <th style="text-align:left;">#Validation</th>
                <th style="text-align:left;">#Test</th>
                <th style="text-align:left;">#Avg. Turns</th>
                <th style="text-align:left;">#Avg. Utterances</th>
                <th style="text-align:left;">#Avg. Words</th>
                <th>#Vocab</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Ubuntu</td>
                <td style="text-align:left;">448833</td>
                <td style="text-align:left;">19584</td>
                <td style="text-align:left;">18920</td>
                <td style="text-align:left;">4.94</td>
                <td style="text-align:left;">7.48</td>
                <td style="text-align:left;">102.21</td>
                <td>268487</td>
              </tr>
              <tr>
                <td style="text-align:left;">Douban</td>
                <td style="text-align:left;">501186</td>
                <td style="text-align:left;">20000</td>
                <td style="text-align:left;">5001</td>
                <td style="text-align:left;">7.69</td>
                <td style="text-align:left;">-</td>
                <td style="text-align:left;">130.66</td>
                <td>304988</td>
              </tr>
              <tr>
                <td style="text-align:left;">JD</td>
                <td style="text-align:left;">415000</td>
                <td style="text-align:left;">15000</td>
                <td style="text-align:left;">5005</td>
                <td style="text-align:left;">11.83</td>
                <td style="text-align:left;">20.43</td>
                <td style="text-align:left;">266.09</td>
                <td>600739</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p><strong>Ubuntu Technical Corpus</strong></p>
        <p>Our first dataset, the <em>Ubuntu Dialogue
        Corpus</em>&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0026">26</a>], is an English multi-turn dialogue
        corpus, containing about 500,000 dialogues extracted from
        the Ubuntu Internet Relayed Chat channel. A conversation
        begins with an Ubuntu-related technical problem, and
        follows by the responses to the questions. We use the
        preprocessed dataset. The corpus consists of 448,833,
        19,584, 18,920 dialogues of training, validation, testing,
        respectively. The corpus is a large and typically goal
        driven dataset.</p>
        <p><strong>Douban Conversation Corpus</strong></p>
        <p>Different from the domain specific Ubuntu corpus, our
        second dataset, the <em>Douban Conversation
        Corpus</em>&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0043">43</a>], is a Chinese multi-turn open
        domain conversation corpus collected from Douban
        groups&nbsp;<a class="fn" href="#fn4" id=
        "foot-fn4"><sup>2</sup></a>, a popular social networking
        service in China. There exist multiple responses for one
        context. The corpus contains 0.5 million dialogues for
        training, more than 20,000 dialogues for validation, and
        5,001 dialogues for test.</p>
        <p><strong>JD Customer Service Corpus</strong></p>
        <p>We collect customer service dialogues from JD.com, named
        the <em>JD Customer Service Corpus</em>. The JD customer
        service corpus consists of online retailing customer
        service dialogues&nbsp;<a class="fn" href="#fn5" id=
        "foot-fn5"><sup>3</sup></a>. In JD corpus, each
        conversation is between a customer and a customer service
        staff. The corpus contains 415,000 dialogues for training,
        1,5000 dialogues for validation, and 5,005 for the test.
        The average number of turns and utterances in a dialogue
        session are much larger than the above two corpus.</p>
      </section>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span>
            Baselines</h3>
          </div>
        </header>
        <p>To evaluate the effectiveness of <strong>HVMN</strong>,
        we make comparisons between the proposed HVMN and the
        following state-of-the-art neural dialogue generation
        models in our experiments:</p>
        <ul class="list-no-style">
          <li id="list11" label="•">
            <strong>SEQ2SEQ</strong>: It is a sequence-to-sequence
            dialogue model, also known as the recurrent
            encoder-decoder model&nbsp;[<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0034">34</a>,
            <a class="bib" data-trigger="hover" data-toggle=
            "popover" data-placement="top" href=
            "#BibPLXBIB0041">41</a>]. As a widely-used neural
            machine translation approach, SEQ2SEQ has been
            successfully applied to dialogue
            generation&nbsp;[<a class="bib" data-trigger="hover"
            data-toggle="popover" data-placement="top" href=
            "#BibPLXBIB0041">41</a>].<br />
          </li>
          <li id="list12" label="•">
            <strong>HRED</strong>: It is a hierarchical
            encoder-decoder model for dialogue
            generation&nbsp;[<a class="bib" data-trigger="hover"
            data-toggle="popover" data-placement="top" href=
            "#BibPLXBIB0033">33</a>].<br />
          </li>
          <li id="list13" label="•">
            <strong>VHRED</strong>: It is a latent variable
            hierarchical recurrent encoder-decoder
            model&nbsp;[<a class="bib" data-trigger="hover"
            data-toggle="popover" data-placement="top" href=
            "#BibPLXBIB0032">32</a>].<br />
          </li>
        </ul>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Evaluation
            Methods</h3>
          </div>
        </header>
        <p>We divide our evaluation metrics into automatic
        evaluation metrics and human evaluation metrics.</p>
        <p><strong>Automatic Evaluation Metrics</strong></p>
        <p>Evaluating dialogue system is not a trivial problem
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0025">25</a>]. Liu
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0025">25</a>] disclosed that word-overlap
        automatic metrics like BLEU [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0028">28</a>] or ROUGE[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0024">24</a>] are not well correlate
        with human evaluations regarding response quality. To
        evaluate the semantic relevance between the candidate
        response and target response, we adopt three
        embedding-based topic similarity metrics proposed by Liu
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0025">25</a>]: <em>Embedding Average</em>
        (Average), <em>Embedding Extrema</em> (Extrema) and
        <em>Embedding Greedy</em> (Greedy) [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0011">11</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0027">27</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0031">31</a>]. The embedding-based
        metrics actually calculate the similarity between the
        generated response and the actual response in the embedding
        space, which are alternatives to word-overlap based metrics
        and actually take the meaning of each word into
        consideration.</p>
        <p>We use the publicly available Word2Vec<a class="fn"
        href="#fn6" id="foot-fn6"><sup>4</sup></a> to train word
        embedding. For English, we train word embeddings on Google
        News Corpus, while for Chinese, the word embeddings are
        approximated on Chinese Giga-word corpus&nbsp;<a class="fn"
        href="#fn7" id="foot-fn7"><sup>5</sup></a>&nbsp;[<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0013">13</a>],
        segmented by <em>zpar</em><a class="fn" href="#fn8" id=
        "foot-fn8"><sup>6</sup></a> [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0045">45</a>]. Sentence-level embedding is
        approximated by aggregating the individual embeddings of
        words in the sentence. With the sentence-level embedding,
        the candidate response and target response can be measured
        by standard similarity metrics, e.g. cosine similarity.</p>
        <p>To evaluate the informativeness of the response
        (contrast with the general dull and ’safe’ responses), we
        propose an average trigram word entropy metric. In
        particular, for a word <em>w<sub>n</sub></em> in a response
        <em>U</em>, the trigram word entropy is defined as:</p>
        <div class="table-responsive" id="Xeq13">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            H(w_{n})=-p(w_{n}|w_{n-2},w_{n-1})\log
            (p(w_{n}|w_{n-2},w_{n-1})). \end{equation}</span><br />
            <span class="equation-number">(22)</span>
          </div>
        </div>The trigram model is trained on the training set of
        each corpus.
        <p></p>
        <p><strong>Human Evaluation</strong></p>
        <p>To further validate the effectiveness of our model, we
        compare the responses from different models on Ubuntu
        corpus by human evaluations. We choose Ubuntu corpus
        because it is a large public available domain specific
        technical dataset. It is much more convenient to
        discriminate a better response regarding whether a
        technical problem is well understood and tackled. For each
        sequence of utterances, the responses generated by all the
        systems are listed in a random order. The system IDs are
        also anonymized. Each dialogue sequence is allocated to an
        evaluator randomly. Evaluators are requested to choose the
        responses on two dimensions: appropriateness to the
        context, and informativeness. They first choose a response
        that is more appropriate than other responses given the
        previous dialogue histories fro a dialogue session. Then,
        they select a response that is more informative and useful
        than other responses. By utilizing the two dimensions, we
        hope to discriminate whether a response is reasonable for a
        dialogue session and whether it is informative enough
        compared with a generic safe dull response. If the
        evaluators disagree all listed responses, or if they cannot
        understand the dialogue context, they can make no choice
        and skip.</p>
      </section>
      <section id="sec-19">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.4</span> Training
            Procedures</h3>
          </div>
        </header>
        <p>All the models are optimized using Adam&nbsp;[<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0017">17</a>] with a
        learning rate of 0.0002 and a batch size of 80. The
        hyperparameters and early stop patience are chosen
        according to the variational lower-bound. During testing,
        we apply beam search with five beams to generate responses.
        For VHRED, we set the dimensions of the latent variable
        <em>d<sub>i</sub></em> = 100. For HVMN, a memory block
        <span class="inline-equation"><span class="tex">$\mathbf
        {M} \in \mathbb {R}^{d_{i}\times d_{z}}$</span></span> is
        augmented with <strong>z</strong> <sub><em>m</em></sub> ,
        <em>d<sub>i</sub></em> is set to 10 and
        <em>d<sub>z</sub></em> to 100. The baseline SEQ2SEQ employs
        LSTM as the recurrent unit with 1000 hidden units, while
        other models utilize 500 hidden units, and the
        dimensionality of other parameters are set accordingly. We
        set the vocabulary size of Ubuntu corpus as 20000; while we
        set the vocabulary size of both Douban and JD as 50000. For
        all baselines and HVMN, we apply the truncated
        back-propagation and the gradient clipping.</p>
        <p>In the following subsections, we first look at the
        overall model performance on metric-based evaluations.
        Then, the human-based evaluations are discussed. Last, we
        present the response examples for qualitatively
        evaluation.</p>
      </section>
      <section id="sec-20">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.5</span>
            Metric-based Evaluation Results</h3>
          </div>
        </header>
        <p>Table <a class="tbl" href="#tab3">3</a> lists the
        performance of each model. HVMN consistently outperforms
        almost all the baselines on three corpora, in terms of both
        the embedding-based topic-similarity metrics and the
        average trigram word entropy metric (except the word
        entropy metric on Ubuntu technical corpus). The
        improvements on Douban dataset are statistically
        significant (t-test with <em>p</em> ≤ 0.01) on embedding
        average and greedy. Not surprised, the performance of
        SEQ2SEQ is the worst among all methods on all metric-based
        evaluations. VHRED performs better than HRED on all three
        topic-similarity metrics on Douban dataset, while HRED
        actually works better on both Ubuntu and JD dataset. This
        is consistent with the fact that Douban is an open domain
        social networking conversation dataset, which is of higher
        response diversity, while Ubuntu and JD are domain specific
        dataset. The better performance of VHRED on Douban corpus
        clearly verifies its ability of increasing the response
        diversity when comparing with HRED.</p>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class=
            "table-title">Evaluations on embedding-based metrics.
            “*” denotes significantly better than VHRED with
            <em>p</em> ≤ 0.01.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;">Model</th>
                <th style="text-align:left;">Average</th>
                <th style="text-align:left;">Greedy</th>
                <th style="text-align:left;">Extrema</th>
                <th>H(w)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="5" style="text-align:center;">
                  <strong>Ubuntu</strong>
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:left;">SEQ2SEQ</td>
                <td style="text-align:left;">0.215603</td>
                <td style="text-align:left;">0.168833</td>
                <td style="text-align:left;">0.126480</td>
                <td>0.2638</td>
              </tr>
              <tr>
                <td style="text-align:left;">HRED</td>
                <td style="text-align:left;">0.541548</td>
                <td style="text-align:left;">0.411681</td>
                <td style="text-align:left;">0.319299</td>
                <td><strong>0.3082</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">VHRED</td>
                <td style="text-align:left;">0.534103</td>
                <td style="text-align:left;">0.402670</td>
                <td style="text-align:left;">0.306242</td>
                <td>0.2878</td>
              </tr>
              <tr>
                <td style="text-align:left;">HVMN</td>
                <td style="text-align:left;">
                <strong>0.558392*</strong></td>
                <td style="text-align:left;">
                <strong>0.422914*</strong></td>
                <td style="text-align:left;">
                <strong>0.322032</strong></td>
                <td>0.3002</td>
              </tr>
              <tr>
                <td colspan="5" style="text-align:center;">
                  <strong>Douban</strong>
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:left;">SEQ2SEQ</td>
                <td style="text-align:left;">0.024255</td>
                <td style="text-align:left;">0.002961</td>
                <td style="text-align:left;">0.023805</td>
                <td>1.2253</td>
              </tr>
              <tr>
                <td style="text-align:left;">HRED</td>
                <td style="text-align:left;">0.030904</td>
                <td style="text-align:left;">0.003817</td>
                <td style="text-align:left;">0.029889</td>
                <td>1.5116</td>
              </tr>
              <tr>
                <td style="text-align:left;">VHRED</td>
                <td style="text-align:left;">0.042774</td>
                <td style="text-align:left;">0.005147</td>
                <td style="text-align:left;">0.041703</td>
                <td>1.3671</td>
              </tr>
              <tr>
                <td style="text-align:left;">HVMN</td>
                <td style="text-align:left;">
                <strong>0.053293</strong></td>
                <td style="text-align:left;">
                <strong>0.006507</strong></td>
                <td style="text-align:left;">
                <strong>0.051560</strong></td>
                <td><strong>3.1042</strong></td>
              </tr>
              <tr>
                <td colspan="5" style="text-align:center;">
                  <strong>JD</strong>
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:left;">SEQ2SEQ</td>
                <td style="text-align:left;">0.309752</td>
                <td style="text-align:left;">0.204973</td>
                <td style="text-align:left;">0.279654</td>
                <td>0.3219</td>
              </tr>
              <tr>
                <td style="text-align:left;">HRED</td>
                <td style="text-align:left;">0.737606</td>
                <td style="text-align:left;">0.500789</td>
                <td style="text-align:left;">0.675900</td>
                <td>0.3286</td>
              </tr>
              <tr>
                <td style="text-align:left;">VHRED</td>
                <td style="text-align:left;">0.609605</td>
                <td style="text-align:left;">0.413422</td>
                <td style="text-align:left;">0.558891</td>
                <td>0.3473</td>
              </tr>
              <tr>
                <td style="text-align:left;">HVMN</td>
                <td style="text-align:left;">
                <strong>0.752574*</strong></td>
                <td style="text-align:left;">
                <strong>0.511170*</strong></td>
                <td style="text-align:left;">
                <strong>0.691818</strong></td>
                <td><strong>0.3555</strong></td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>For all tested methods, their performance on Douban
        conversation corpus is much lower than Ubuntu technical
        corpus and JD e-commerce conversation corpus, while the
        entropies are much higher. It indicates that the dialogues
        in Douban corpus are more informative and much harder for
        dialogue generation task, which agrees with the fact that
        each context in Douban corpus usually consists of multiple
        responses. Intuitively, as introduced previously, Douban
        corpus is an open domain social networking conversation
        corpus, while Ubuntu technical corpus and JD customer
        service corpus are more domain specific. The response
        diversity differs among open domain and domain specific
        corpus. The higher response entropies on Douban corpus
        clearly verify such fact.</p>
      </section>
      <section id="sec-21">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.6</span> Effect of
            Context Length</h3>
          </div>
        </header>
        <p>Figure <a class="fig" href="#fig5">5</a> lists the
        number of contexts of Ubuntu corpus. Most contexts are of
        lengths 0-50 and 50-100. Figures <a class="fig" href=
        "#fig6">6</a>-<a class="fig" href="#fig8">8</a> show the
        performance on different lengths of contexts for three
        embedding-based evaluation metrics on Ubuntu corpus. Note
        that we do not show results in other datasets since we have
        similar observations. We can see that HVMN performs better
        than other baselines at most different lengths, while HRED
        perform the second best. Comparing with HRED, for the
        contexts with length less than 50, HVMN performs noticeable
        better on Embedding Average and Embedding Greedy metrics.
        One possible reason is that, it is harder for short
        contexts to generate reasonable responses than regular
        ones, due to the lack of effective information. Through
        manually examining the results, we observed that baseline
        models even fail to make meaningful decisions when
        predicting the response word-by-word, while with the
        variational memory, HVMN is capable of injecting variation
        for short contexts. When we looking at the main baseline
        VHRED, the performance gap between HVMN and VHRED increases
        when the contexts become longer, which demonstrates that
        HVMN works better for long contexts than VHRED. It confirms
        that variational memory in HVMN is able to provide more
        power for long term dependencies.</p>
        <figure id="fig5">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186077/images/www2018-86-fig5.jpg"
          class="img-responsive" alt="Figure 5" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span>
            <span class="figure-title">Statistics of number of with
            respect to different contexts length.</span>
          </div>
        </figure>
        <figure id="fig6">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186077/images/www2018-86-fig6.jpg"
          class="img-responsive" alt="Figure 6" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 6:</span>
            <span class="figure-title">Comparison of embedding
            average for different length.</span>
          </div>
        </figure>
        <figure id="fig7">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186077/images/www2018-86-fig7.jpg"
          class="img-responsive" alt="Figure 7" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 7:</span>
            <span class="figure-title">Comparison of embedding
            greedy for different length.</span>
          </div>
        </figure>
        <figure id="fig8">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186077/images/www2018-86-fig8.jpg"
          class="img-responsive" alt="Figure 8" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 8:</span>
            <span class="figure-title">Comparison of embedding
            extrema for different length.</span>
          </div>
        </figure>
      </section>
      <section id="sec-22">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.7</span> Human
            Evaluation Performance</h3>
          </div>
        </header>
        <p>To further validate the performance, we conduct the
        human evaluation on Ubuntu dataset. We choose Ubuntu
        corpus, because it is easy to specify whether a response is
        appropriate, and whether a response is informative enough
        in technical problem discussing.</p>
        <p>Table <a class="tbl" href="#tab4">4</a> lists the
        comparison results. Line 1 and line 4 suggest that HVMN
        outperforms its counterparts, namely 77.07: 22.93 and
        53.97: 46: 03 on appropriateness, and 84.46: 15.54 and
        58.41: 44.44 on informativeness. We also notice that VHRED
        works better than HRED in terms of informativeness (line 3,
        52.91: 47.09) and performs worse than HRED with respect to
        appropriateness (44.57: 55.43). This suggests that,
        although Ubuntu is a domain specific technical dataset,
        VHRED still improves response informativeness with a bit
        loss of appropriateness and HRED tends to make generic safe
        and meaningless responses. A straightforward observation is
        that a more informative and longer response tends to make
        more mistakes comparing with a short and dull response.
        Therefore, the appropriateness of VHRED decreases compared
        with HRED, while the informativeness increases a lot.</p>
        <div class="table-responsive" id="tab4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class=
            "table-title">Average differences on human
            evaluation.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Comparison</th>
                <th style="text-align:center;">
                Appropriateness(%)</th>
                <th>Informativeness(%)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">HVMN <em>vs</em>
                SEQ2SEQ</td>
                <td style="text-align:center;">77.07 : 22.93</td>
                <td>84.46 : 15.54</td>
              </tr>
              <tr>
                <td style="text-align:center;">HVMN <em>vs</em>
                HRED</td>
                <td style="text-align:center;">48.52 : 51.48</td>
                <td>58.41 : 41.59</td>
              </tr>
              <tr>
                <td style="text-align:center;">VHRED <em>vs</em>
                HRED</td>
                <td style="text-align:center;">44.57 : 55.43</td>
                <td>52.91 : 47.09</td>
              </tr>
              <tr>
                <td style="text-align:center;">HVMN <em>vs</em>
                VHRED</td>
                <td style="text-align:center;">53.97 : 46.03</td>
                <td>55.56 : 44.44</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>In line 2, HVMN achieves comparable performance on
        appropriateness compared with HRED (48.52: 51.48). However,
        HVMN remarkably outperforms HRED with respect to
        informativeness (58.41: 41.59). This suggests that HVMN
        maintains its appropriateness while increasing the
        informativeness. By utilizing the variational memory, HVMN
        performs better at generate a diversified and “right”
        response in contrast with VHRED.</p>
      </section>
      <section id="sec-23">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.8</span> Qualitative
            Evaluation</h3>
          </div>
        </header>
        <p>Table <a class="tbl" href="#tab5">5</a> presents
        examples of generated responses for different models. It is
        clear that HVMN performs better at understanding contexts.
        The responses of HVMN are not only more appropriate but
        also more informative and useful.</p>
        <div class="table-responsive" id="tab5">
          <div class="table-caption">
            <span class="table-number">Table 5:</span> <span class=
            "table-title">Examples of dialogues generated by
            various models on Ubuntu corpus. Column 1 lists the
            context of a dialogue, whereas Column 2 lists the
            generated response by different models. “ → ” denotes a
            turn exchange.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Contexts</th>
                <th>Response</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">hello , I'am using
                ubunutu 12.04 and have black screen It seems that I
                have graphical system X loggeed as root user , but
                not as my user . Can someone to end up my problem ?
                I have ubuntu 12.04 → are you logged on ? and do
                you have a text prompt ?</td>
                <td><strong>HVMN</strong>: yes , I can log in as
                root , but I am not able to log in as root</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>LSTM</strong>: **unknown**</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>HRED</strong>: yes</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>VHRED</strong>: yes</td>
              </tr>
              <tr>
                <td style="text-align:left;">hey what command would
                I use to extract a gz file tar . gz → in which part
                ? document , assignment , labs ? → sorry labs →
                wait a second, my connection gets slow connection →
                oh sorry , can you not see it ? do you know if I
                have to extract that . tar . gz → not yet finish :D
                skydrive was suck → lol its the only option I had ,
                i could just send you my onenote linke → okey just
                for your link I get slower connections :D</td>
                <td><strong>HVMN</strong>: I am trying to get it to
                work , but I can't find it anywhere</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>LSTM</strong>: ?</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>HRED</strong>: yeah I know , but I have
                to go to bed , I have to go to bed :)</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>VHRED</strong>: ok</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td></td>
              </tr>
              <tr>
                <td style="text-align:left;">I've been told that du
                doesn't count hidden files/directories size toward
                their parent directory size , yet in practice it
                seems du still does it → well read the manual .
                because it always did and always will ?</td>
                <td><strong>HVMN</strong>: that ’s what I thought ,
                but I don't think it ’s possible to do that</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>LSTM</strong>: ?</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>HRED</strong>: I know , but I don't
                know how to do that , I just want to know if there
                is a way to do it</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>VHRED</strong>: df -h returns nothing
                ?</td>
              </tr>
              <tr>
                <td style="text-align:left;">Hello . I want to
                access a ubuntu desktop from windows 7 to know what
                the client is doing . How can i do that ? Hello . I
                want to access a ubuntu desktop from windows 7 to
                know what the client is doing . How can i do that ?
                → Try Teamviewer → I want to do without the
                knowledge of client</td>
                <td><strong>HVMN</strong> You'll need to set up a
                VNC server on the Ubuntu machine .</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>LSTM</strong>: ?</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>HRED</strong>: Sorry , I don't know how
                to do that .</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>VHRED</strong>: Then I don't know ,
                sorry .</td>
              </tr>
              <tr>
                <td style="text-align:left;">Hi there , i'm doing
                an rsync on a server , ive just looked at it
                remotely and its showing as 3 occurrences of it
                running(via ps aux | grep rsync) is that normal ? →
                Do they all look exactly the same or is there any
                destingueal be difference → all look exactly the
                same : s whats that mean then ?</td>
                <td><strong>HVMN</strong> The rsync command will
                tell you if the rsync daemon is running .</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>LSTM</strong>: **unknown**</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>HRED</strong>: I don't know what you
                mean by ” **unknown** ”</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td><strong>VHRED</strong>: grep ” **unknown** .
                **unknown** ”</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>Comparing LSTM and HRED, both systems tend to make
        generic, “safe” and dull response. LSTM makes short and
        meaningless responses for all the cases, while HRED outputs
        longer responses and performs slightly better and is more
        likely to admit that it does not understand the discussion
        and fails to give detailed solutions. Comparing HRED and
        VHRED, line 3 and 5 in Table <a class="tbl" href=
        "#tab5">5</a> indicate that VHRED tends to output more
        specific answers. It gives an appropriate linux command for
        line 3, however, it fails to generate a proper and
        effective response for line 5. Generally, HVMN doesn't make
        a generic “yes/no” response but provides detailed and
        appropriate operations, especially for line 1 and line
        4.</p>
      </section>
    </section>
    <section id="sec-24">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Related
          Work</h2>
        </div>
      </header>
      <p>Our related work can be classified into two categories:
      variational neural model and memory network.</p>
      <section id="sec-25">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.1</span> Variational
            Neural Model</h3>
          </div>
        </header>
        <p>Kingma and Welling [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0019">19</a>] and Kingma et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0018">18</a>]
        introduce variational neural networks to perform efficient
        inference and learning in directed probabilities models on
        a large-scale dataset. They approximate the posterior by a
        neural inference model. The model parameters are optimized
        jointly with a reparameterized variational lower bound
        using the standard stochastic gradient descent. Bayer and
        Osendorfer [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0003">3</a>] propose stochastic recurrent
        networks for music generation and motion capture modeling.
        Chung et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0010">10</a>] incorporate latent variables into
        the hidden state of a recurrent neural network. They use
        the latent variables in token level and apply for speech
        and handwriting synthesis. Gregor et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0015">15</a>] use it
        in images generation, which combines a novel spatial
        attention mechanism that mimics the foveation of human
        eyes, with a sequential variational auto-encoding framework
        that allows the iterative construction of complex images.
        Bowman et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0005">5</a>] develop a variational auto-encoder
        for unsupervised generative language modeling. Cao and
        Clark [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href="#BibPLXBIB0006">6</a>]
        tackle the boring output issue of deterministic dialogue
        models by introducing a latent variable model for one-shot
        dialogue response. Serban et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0032">32</a>] directly utilize the
        latent variable at the sub-sequence level in a hierarchical
        setting. Li et&nbsp;al. [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0023">23</a>] employ a variational auto-encoder
        to describe the observed sentences and the corresponding
        latent semantic representations for multi-document
        summarization.</p>
        <p>Unlike previous models, which directly utilize the
        latent variable to guide the generation, the latent
        variable in our model is used as a key to read from the
        memory block and learn to make abstract high-level
        decisions during dialogue tracing.</p>
      </section>
      <section id="sec-26">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.2</span> Memory
            Network</h3>
          </div>
        </header>
        <p>Memory Network model is first proposed by Sukhbaatar
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0039">39</a>] and Sukhbaatar et&nbsp;al.
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0040">40</a>]. Cheng
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0008">8</a>] equip the machine reader with a
        memory tape, which enables the model to read all the
        previous hidden state directly. Wang et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0042">42</a>] use an
        interactive memory to enhance the long distance memory
        ability of the decoder in neural machine translation.
        Bordes and Weston [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0004">4</a>] employ memory networks to handle
        restaurant reservations, using a small number of keywords
        to handle entity types in a knowledge base (cuisine type,
        location, price range, party size, rating, phone number,
        and address). Ghazvininejad et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0012">12</a>] adapt it to memorize
        the relevant grounded facts for a neural conversation
        model.</p>
        <p>However, all these models read the memories in somewhat
        a deterministic way, while we inject the variability for
        memory reading through the latent variable. Another
        difference is that the memory is augmented in a
        hierarchical setting, and is updated to memorize each
        utterance.</p>
      </section>
    </section>
    <section id="sec-27">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Conclusion</h2>
        </div>
      </header>
      <p>In this paper, we have studied the dialogue generation
      problem and have identified the main challenges: the
      long-term dependency and the informativeness. To tackle these
      problems, we have utilized the hierarchical structure,
      together with the variational memory to enhance the utterance
      modeling for dialogues generation. The two-level hierarchical
      structure naturally encodes the dialogue utterances within an
      utterance and across the utterance sequence. The variational
      memory tracks the high level abstraction, memorize the
      long-term details of the observed utterances, and randomly
      access the dialogue histories. Extensive experiments
      conducted on two benchmark datasets and a real-world
      e-commerce dataset have verified the effectiveness of our
      proposed method by showing significant improvements over
      multiple baselines in terms of metric-based evaluations and
      human evaluations.</p>
      <p>Note that, our model is not only limited to dialogue
      generation task, it can also be applied to other tasks like
      machine reading and summarization. We would like to make
      further studies in our future work. Also, we would like to
      integrate external knowledge base into the memory block to
      make the dialogue generation capable of handling enormous
      structured knowledge.</p>
    </section>
    <section id="sec-28">
      <header>
        <div class="title-info">
          <h2>Acknowledgements</h2>
        </div>
      </header>
      <p>The authors wish to thank the anonymous reviewers for
      their helpful comments. The authors wish to thank Xi Xiong
      for preprocessing the JD customer service corpus. Jiliang
      Tang is supported by the National Science Foundation (NSF)
      under grant number IIS-1714741 and IIS-1715940.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">David Ameixa, Luisa
        Coheur, Pedro Fialho, and Paulo Quaresma. 2014.
        <em><em>Luke, I am Your Father: Dealing with Out-of-Domain
        Requests by Using Movies Subtitles</em></em> . Springer
        International Publishing. 13–21 pages.</li>
        <li id="BibPLXBIB0002" label="[2]">Rafael&nbsp;E. Banchs
        and Haizhou Li. 2013. IRIS: a chat-oriented dialogue system
        based on the vector space model. In <em><em>Proceedings of
        the 50th Annual Meeting of the Association for
        Computational Linguistics</em></em> . 37–42.</li>
        <li id="BibPLXBIB0003" label="[3]">Justin Bayer and
        Christian Osendorfer. 2014. Learning Stochastic Recurrent
        Networks. In <em><em>NIPS, Workshop on Advances in
        Variational Inference</em></em> .</li>
        <li id="BibPLXBIB0004" label="[4]">Antoine Bordes and Jason
        Weston. 2017. Learning end-to-end goal-oriented dialog. In
        <em><em>Proceedings of the 5th International Conference on
        Learning Representations</em></em> .</li>
        <li id="BibPLXBIB0005" label="[5]">Samuel&nbsp;R Bowman,
        Luke Vilnis, Oriol Vinyals, Andrew&nbsp;M Dai, Rafal
        Jozefowicz, and Samy Bengio. 2015. Generating Sentences
        from a Continuous Space. In <em><em>Proceedings of 20th
        SIGNLL Conference on Computational Natural Language
        Learning</em></em> . 10–21.</li>
        <li id="BibPLXBIB0006" label="[6]">Kris Cao and Stephen
        Clark. 2017. Latent Variable Dialogue Models and their
        Diversity. In <em><em>Proceedings of the 15th Conference of
        the European Chapter of the Association for Computational
        Linguistics</em></em> . 182–187.</li>
        <li id="BibPLXBIB0007" label="[7]">Hongshen Chen, Xiaorui
        Liu, Dawei Yin, and Jiliang Tang. 2017. A Survey on
        Dialogue Systems: Recent Advances and New Frontiers.
        <em><em>ACM SIGKDD Explorations Newsletter</em></em> 19, 2
        (2017).</li>
        <li id="BibPLXBIB0008" label="[8]">Jianpeng Cheng, Li Dong,
        and Mirella Lapata. 2016. Long short-term memory-networks
        for machine reading. In <em><em>Proceedings of the 2016
        Conference on Empirical Methods in Natural Language
        Processing</em></em> . 551–561.</li>
        <li id="BibPLXBIB0009" label="[9]">Kyunghyun Cho, Bart van
        Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi
        Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning
        Phrase Representations using RNN Encoder–Decoder for
        Statistical Machine Translation. In <em><em>Proceedings of
        the 2014 Conference on Empirical Methods in Natural
        Language Processing (EMNLP)</em></em> . Association for
        Computational Linguistics, Doha, Qatar, 1724–1734.</li>
        <li id="BibPLXBIB0010" label="[10]">Junyoung Chung, Kyle
        Kastner, Laurent Dinh, Kratarth Goel, Aaron&nbsp;C
        Courville, and Yoshua Bengio. 2015. A Recurrent Latent
        Variable Model for Sequential Data. In <em><em>Advances in
        Neural Information Processing Systems 28</em></em> ,
        C.&nbsp;Cortes, N.&nbsp;D. Lawrence, D.&nbsp;D. Lee,
        M.&nbsp;Sugiyama, and R.&nbsp;Garnett (Eds.).
        2980–2988.</li>
        <li id="BibPLXBIB0011" label="[11]">Gabriel Forgues, Joelle
        Pineau, Jean-Marie Larchevêque, and Réal Tremblay. 2014.
        Bootstrapping dialog systems with word embeddings. In
        <em><em>NIPS, Modern Machine Learning and Natural Language
        Processing Workshop</em></em> .</li>
        <li id="BibPLXBIB0012" label="[12]">Marjan Ghazvininejad,
        Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao,
        Wen-tau Yih, and Michel Galley. 2017. A Knowledge-Grounded
        Neural Conversation Model. <em><em>arXiv preprint
        arXiv:1702.01932</em></em> (2017).</li>
        <li id="BibPLXBIB0013" label="[13]">David Graff and Ke
        Chen. 2005. Chinese gigaword. <em><em>LDC Catalog No.:
        LDC2003T09, ISBN</em></em> 1 (2005), 58563–58230.</li>
        <li id="BibPLXBIB0014" label="[14]">Alex Graves, Greg
        Wayne, and Ivo Danihelka. 2014. Neural turing machines.
        <em><em>arXiv preprint arXiv:1410.5401</em></em>
        (2014).</li>
        <li id="BibPLXBIB0015" label="[15]">Karol Gregor, Ivo
        Danihelka, Alex Graves, Danilo&nbsp;Jimenez Rezende, and
        Daan Wierstra. 2015. DRAW: A Recurrent Neural Network for
        Image Generation. In <em><em>Proceedings of the 32nd
        International Conference on International Conference on
        Machine Learning</em></em> . 1462–1471.</li>
        <li id="BibPLXBIB0016" label="[16]">Sepp Hochreiter and
        Jurgen Schmidhuber. 1997. Long Short-Term Memory.
        <em><em>Neural Computation</em></em> 9, 8 (1997),
        1735–1780.</li>
        <li id="BibPLXBIB0017" label="[17]">Diederik&nbsp;P Kingma
        and Jimmy Ba. 2015. Adam: A Method for Stochastic
        Optimization. <em><em>ICLR</em></em> (2015).</li>
        <li id="BibPLXBIB0018" label="[18]">Diederik&nbsp;P Kingma,
        Danilo&nbsp;J Rezende, Shakir Mohamed, and Max Welling.
        2014. Semi-Supervised Learning with Deep Generative Models.
        <em><em>Advances in Neural Information Processing
        Systems</em></em> 4 (2014), 3581–3589.</li>
        <li id="BibPLXBIB0019" label="[19]">Diederik&nbsp;P Kingma
        and Max Welling. 2014. Auto-Encoding Variational Bayes.
        <em><em>ICLR</em></em> (2014).</li>
        <li id="BibPLXBIB0020" label="[20]">Jiwei Li, Michel
        Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016.
        A Diversity-Promoting Objective Function for Neural
        Conversation Models. In <em><em>Proceedings of the 2016
        Conference of the North American Chapter of the Association
        for Computational Linguistics</em></em> . 110–119.</li>
        <li id="BibPLXBIB0021" label="[21]">Jiwei Li, Michel
        Galley, Chris Brockett, Georgios Spithourakis, Jianfeng
        Gao, and Bill Dolan. 2016. A Persona-Based Neural
        Conversation Model. In <em><em>Proceedings of the 54th
        Annual Meeting of the Association for Computational
        Linguistics</em></em> . 994–1003.</li>
        <li id="BibPLXBIB0022" label="[22]">Jiwei Li, Michel
        Galley, Chris Brockett, Georgios Spithourakis, Jianfeng
        Gao, and Bill Dolan. 2016. A Persona-Based Neural
        Conversation Model. In <em><em>Proceedings of the 54th
        Annual Meeting of the Association for Computational
        Linguistics</em></em> . 994–1003.</li>
        <li id="BibPLXBIB0023" label="[23]">Piji Li, Zihao Wang,
        Wai Lam, Zhaochun Ren, and Lidong Bing. 2017. Salience
        Estimation via Variational Auto-Encoders for Multi-Document
        Summarization.. In <em><em>Proceedings of the 31st AAAI
        Conference on Artificial Intelligence</em></em> .
        3497–3503.</li>
        <li id="BibPLXBIB0024" label="[24]">Chin-Yew Lin. 2004.
        ROUGE: A Package for Automatic Evaluation of Summaries. In
        <em><em>Text Summarization Branches Out: Proceedings of the
        ACL-04 Workshop</em></em> , Stan&nbsp;Szpakowicz
        Marie-Francine&nbsp;Moens (Ed.). Association for
        Computational Linguistics, Barcelona, Spain, 74–81.</li>
        <li id="BibPLXBIB0025" label="[25]">Chia&nbsp;Wei Liu, Ryan
        Lowe, Iulian Serban, Mike Noseworthy, Laurent Charlin, and
        Joelle Pineau. 2016. How NOT To Evaluate Your Dialogue
        System: An Empirical Study of Unsupervised Evaluation
        Metrics for Dialogue Response Generation. In
        <em><em>Conference on Empirical Methods in Natural Language
        Processing</em></em> . 2122–2132.</li>
        <li id="BibPLXBIB0026" label="[26]">Ryan Lowe, Nissan Pow,
        Iulian Serban, and Joelle Pineau. 2015. The Ubuntu Dialogue
        Corpus: A Large Dataset for Research in Unstructured
        Multi-Turn Dialogue Systems. In <em><em>Proceedings of the
        16th Annual Meeting of the Special Interest Group on
        Discourse and Dialogue</em></em> . 285–294.</li>
        <li id="BibPLXBIB0027" label="[27]">Jeff Mitchell and
        Mirella Lapata. 2008. Vector-based Models of Semantic
        Composition. In <em><em>Proceedings of The 46th Annual
        Meeting of the Association for Computational
        Linguistics</em></em> . 236–244.</li>
        <li id="BibPLXBIB0028" label="[28]">Kishore Papineni, Salim
        Roukos, Todd Ward, and Wei&nbsp;Jing Zhu. 2002. BLEU: a
        method for automatic evaluation of machine translation. In
        <em><em>Meeting on Association for Computational
        Linguistics</em></em> . 311–318.</li>
        <li id="BibPLXBIB0029" label="[29]">Zhaochun Ren, Hongya
        Song, Piji Li, Shangsong Liang, Jun Ma, and Maarten de
        Rijke. 2016. Using sparse coding for answer summarization
        in non-factoid community question-answering. In
        <em><em>SIGIR Workshop: Web Question Answering, Beyond
        Factoids</em></em> .</li>
        <li id="BibPLXBIB0030" label="[30]">Alan Ritter, Colin
        Cherry, and William&nbsp;B. Dolan. 2011. Data-driven
        response generation in social media. In <em><em>Proceedings
        of the 2011 Conference on Empirical Methods in Natural
        Language Processing</em></em> . 583–593.</li>
        <li id="BibPLXBIB0031" label="[31]">Vasile Rus and Mihai
        Lintean. 2012. A comparison of greedy and optimal
        assessment of natural language student input using
        word-to-word similarity metrics. In <em><em>Proceedings of
        the Seventh Workshop on Building Educational Applications
        Using NLP</em></em> . 157–162.</li>
        <li id="BibPLXBIB0032" label="[32]">Iulian Serban,
        Alessandro Sordoni, Ryan Lowe, Laurent Charlin, Joelle
        Pineau, Aaron Courville, and Yoshua Bengio. 2017. A
        Hierarchical Latent Variable Encoder-Decoder Model for
        Generating Dialogues. In <em><em>Proceedings of the 31st
        AAAI Conference on Artificial Intelligence</em></em> .</li>
        <li id="BibPLXBIB0033" label="[33]">Iulian&nbsp;Vlad
        Serban, Alessandro Sordoni, Yoshua Bengio, Aaron&nbsp;C
        Courville, and Joelle Pineau. 2016. Building End-To-End
        Dialogue Systems Using Generative Hierarchical Neural
        Network Models. In <em><em>Proceedings of the 30th AAAI
        Conference on Artificial Intelligence</em></em> .
        3776–3784.</li>
        <li id="BibPLXBIB0034" label="[34]">Lifeng Shang, Zhengdong
        Lu, and Hang Li. 2015. Neural Responding Machine for
        Short-Text Conversation. In <em><em>Proceedings of the 53rd
        Annual Meeting of the Association for Computational
        Linguistics and the 7th International Joint Conference on
        Natural Language Processing</em></em> . 1577–1586.</li>
        <li id="BibPLXBIB0035" label="[35]">B&nbsp;Abu Shawar and
        Eric Atwell. 2007. Chatbots: are they really useful?
        <em><em>Ldv Forum</em></em> 22, 1 (2007), 29–49.</li>
        <li id="BibPLXBIB0036" label="[36]">Hongya Song, Zhaochun
        Ren, Shangsong Liang, Piji Li, Jun Ma, and Maarten de
        Rijke. 2017. Summarizing answers in non-factoid community
        question-answering. In <em><em>Proceedings of the 10th ACM
        International Conference on Web Search and Data
        Mining</em></em> . 405–414.</li>
        <li id="BibPLXBIB0037" label="[37]">Alessandro Sordoni,
        Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob
        Grue&nbsp;Simonsen, and Jian-Yun Nie. 2015. A Hierarchical
        Recurrent Encoder-Decoder for Generative Context-Aware
        Query Suggestion. In <em><em>Proceedings of the 24th ACM
        International on Conference on Information and Knowledge
        Management</em></em> . 553–562.</li>
        <li id="BibPLXBIB0038" label="[38]">Alessandro Sordoni,
        Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji,
        Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill
        Dolan. 2015. A Neural Network Approach to Context-Sensitive
        Generation of Conversational Responses. In
        <em><em>Proceedings of the 2015 Conference of the North
        American Chapter of the Association for Computational
        Linguistics</em></em> . 196–205.</li>
        <li id="BibPLXBIB0039" label="[39]">Sainbayar Sukhbaatar,
        Jason Weston, Rob Fergus, <em>et al.</em> 2015. End-to-end
        memory networks. In <em><em>Advances in neural information
        processing systems</em></em> . 2440–2448.</li>
        <li id="BibPLXBIB0040" label="[40]">Sainbayar Sukhbaatar,
        Jason Weston, Rob Fergus, <em>et al.</em> 2015. End-to-end
        memory networks. In <em><em>Advances in neural information
        processing systems</em></em> . 2440–2448.</li>
        <li id="BibPLXBIB0041" label="[41]">Oriol Vinyals and Quoc
        Le. 2015. A neural conversational model. In <em><em>ICML
        Deep Learning Workshop</em></em> .</li>
        <li id="BibPLXBIB0042" label="[42]">Mingxuan Wang,
        Zhengdong Lu, Hang Li, and Qun Liu. 2016. Memory-enhanced
        Decoder for Neural Machine Translation. In
        <em><em>Proceedings of the 2016 Conference on Empirical
        Methods in Natural Language Processing</em></em> .
        Association for Computational Linguistics, Austin, Texas,
        278–286.</li>
        <li id="BibPLXBIB0043" label="[43]">Yu Wu, Wei Wu, Chen
        Xing, Ming Zhou, and Zhoujun Li. 2017. Sequential matching
        network: A new architecture for multi-turn response
        selection in retrieval-based chatbots. In
        <em><em>Proceedings of the 55th Annual Meeting of the
        Association for Computational Linguistics</em></em> .
        496–505.</li>
        <li id="BibPLXBIB0044" label="[44]">Steve Young, Milica
        Gašić, Blaise Thomson, and Jason&nbsp;D Williams. 2013.
        Pomdp-based statistical spoken dialog systems: A review.
        <em><em>Proc. IEEE</em></em> 101, 5 (2013), 1160–1179.</li>
        <li id="BibPLXBIB0045" label="[45]">Yue Zhang and Stephen
        Clark. 2011. Syntactic processing using the generalized
        perceptron and beam search. <em><em>Computational
        linguistics</em></em> 37, 1 (2011), 105–151.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>*</sup></a>These two
    authors contributed equally to the paper.</p>
    <p id="fn2"><a href="#foot-fn2"><sup>†</sup></a>Corresponding
    author</p>
    <p id="fn3"><a href="#foot-fn3"><sup>1</sup></a><a class=
    "link-inline force-break" href=
    "https://www.jd.com">https://www.jd.com</a></p>
    <p id="fn4"><a href="#foot-fn4"><sup>2</sup></a><a class=
    "link-inline force-break" href=
    "https://www.douban.com/group">https://www.douban.com/group</a></p>
    <p id="fn5"><a href="#foot-fn5"><sup>3</sup></a>We release the
    corpus at <a class="link-inline force-break" href=
    "https://github.com/chenhongshen/HVMN">https://github.com/chenhongshen/HVMN</a>.</p>
    <p id="fn6"><a href="#foot-fn6"><sup>4</sup></a><a class=
    "link-inline force-break" href=
    "https://code.google.com/archive/p/word2vec/">https://code.google.com/archive/p/word2vec/</a></p>
    <p id="fn7"><a href="#foot-fn7"><sup>5</sup></a>We use version
    5 in our work.</p>
    <p id="fn8"><a href="#foot-fn8"><sup>6</sup></a><a class=
    "link-inline force-break" href=
    "https://github.com/SUTDNLP/ZPar">https://github.com/SUTDNLP/ZPar</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23–27, 2018, Lyon, France</em></p>
      <p>© 2018 IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License.<br />
      ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3178876.3186077">https://doi.org/10.1145/3178876.3186077</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
