<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Deep Modeling of the Evolution of User Preferences and Item Attributes in Dynamic Social Networks</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Deep Modeling of the Evolution of User Preferences and Item Attributes in Dynamic Social Networks</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Peizhi</span>      <span class="surName">Wu*</span>     CCCE, Nankai University, Tianjin, China, <a href="mailto:wupz@mail.nankai.edu.cn">wupz@mail.nankai.edu.cn</a>     </div>     <div class="author">     <span class="givenName">Yi</span>      <span class="surName">Tu</span>     George Washington University, Washington, DC, USA 22202, <a href="mailto:niklaus_yi@gwu.edu">niklaus_yi@gwu.edu</a>     </div>     <div class="author">     <span class="givenName">Zhenglu</span>      <span class="surName">Yang*</span>     CCCE, Nankai University, Tianjin, China, <a href="mailto:yangzl@nankai.edu.cn">yangzl@nankai.edu.cn</a>     </div>     <div class="author">     <span class="givenName">Adam</span>      <span class="surName">Jatowt</span>     Kyoto University, Kyoto, Japan, <a href="mailto:adam@dl.kuis.kyoto-u.ac.jp">adam@dl.kuis.kyoto-u.ac.jp</a>     </div>     <div class="author">     <span class="givenName">Masato</span>      <span class="surName">Odagaki</span>     Maebashi Institute of Technology, Maebashi, Japan, <a href="mailto:odagaki@maebashiit.ac.jp">odagaki@maebashiit.ac.jp</a>     </div>                         </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3186956" target="_blank">https://doi.org/10.1145/3184558.3186956</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Modeling the evolution of user preferences and item attributes in a dynamic social network is important because it is the basis for many applications, including recommendation systems and user behavior analysis. This study introduces a comprehensive general neural framework with several optimal strategies to jointly model the evolution of user preferences and item attributes in dynamic social networks. Preliminary experimental results conducted on real-world datasets demonstrate that our model performs better than the state-of-the-art methods.</small>     </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>user modeling; social networks; MLP; RNN</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Peizhi Wu*, Yi Tu, Zhenglu Yang*, Adam Jatowt, and Masato Odagaki. 2018. Deep Modeling of the Evolution of User Preferences and Item Attributes in Dynamic Social Networks. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 3 Pages. <a href="https://doi.org/10.1145/3184558.3186956" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3186956</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>In the era of information explosion, determining how to model user preferences plays a pivotal role in helping users discover the items that interest them. Collaborative filtering (CF) is the key to modeling user preferences on items based on their past interactions, and one of the most traditional CF techniques is matrix factorization (MF)&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>]. Recently, deep learning based techniques have been widely leveraged for MF in modeling user preferences&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>].</p>    <p>In the real world, user preferences are not static but instead drift over time. Item attributes also often change as time passes, affected by dynamic user inclinations, and other factors&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>].&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] proposed recurrent recommender networks that can model user and item dynamics. However,&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] did not combine side information or clearly explain the reasons for the drifts in user preferences.</p>    <p>Another issue is data sparsity, which is caused by the purchase behavior of users, i.e. buying only a few items. To address this problem, many studies have integrated the users&#x2019; friendship context with the rating data&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>].&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>] leveraged friendship context as a user attribute embedding in semi-supervised learning. However, the authors failed to deeply understand the friendship influence on users and only modeled the static preferences and attributes of users and items, respectively, in static social networks.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>] inferred the dynamic preferences of users via probability modeling but assumed that items were constant. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186956/images/www18companion-196-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Model Structure</span>     </div>     </figure>    </p>    <p>This work addresses the aforementioned issues by formalizing a principled deep learning based framework. One main contribution is exploring the use of neural networks to model the evolution of user preferences and item attributes in dynamic social networks deeply. The results conducted on real-world datasets demonstrate that our model performs better than the state-of-the-art method.</p>   </section>   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Our Model</h2>     </div>    </header>    <p>The framework consists of two modules: (1) user preference model (Fig.&#x00A0;<a class="fig" href="#fig1">1</a>, bottom), which quantifies the users&#x2019; historical preferences and social influences via user embedding and leverages multilayer perceptron (MLP) to integrate them; and (2) item attribute model (Fig.&#x00A0;<a class="fig" href="#fig1">1</a>, top), which employs LSTM to capture dynamic states of items. The two modules are combined to predict ratings.</p>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> User Preference Model</h3>     </div>     </header>     <p>We use the one-hot vector for user ID input, and use <span class="inline-equation"><span class="tex">$f_i^t \in {F^t}$</span>     </span> to denote the trust score vector input of user i&#x0027;s friends at time t. Specifically, the j-th element in <span class="inline-equation"><span class="tex">$f_i^t$</span>     </span> is user i&#x0027;s trust score to user j at time t. We adapt the <em>Adamic/Adar</em> metric into a time-dependent version to represent <span class="inline-equation"><span class="tex">$f_i^t$</span>     </span>. The new preferences of each user will be affected by the users&#x2019; historical preferences and social influences.</p>     <p>     <strong>Impact factors of user preference.</strong> We use <span class="inline-equation"><span class="tex">$u_i^t \in U^t$</span>     </span> to denote the time-dependent latent preference of user i which represents the users&#x2019; historical preference. Meanwhile, we use <span class="inline-equation"><span class="tex">$\tilde{u}_{fi}^t \in U_f^t$</span>     </span> to denote the time-dependent latent influence of user i on other users.</p>     <p>In most previous works&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>], <span class="inline-equation"><span class="tex">$u_i^t$</span>     </span> and <span class="inline-equation"><span class="tex">$\tilde{u}_{fi}^t$</span>     </span> are regarded as equal. This current work argues that <span class="inline-equation"><span class="tex">$u_i^t$</span>     </span> and <span class="inline-equation"><span class="tex">$\tilde{u}_{fi}^t$</span>     </span> are not equal and thus proposes an effective strategy to correlate them.</p>     <p>We use the recommendation transformation factor to capture the change from users&#x2019; preferences to users&#x2019; influences on others. We introduce the transformation matrix <em>W<sub>trans</sub>     </em> to describe the recommendation transformation factor. Each row in <em>W<sub>trans</sub>     </em> reflects to what extent the corresponding user will exaggerate or diminish at each feature. The time-dependent latent influence by the friendships of user i is: <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \tilde{u}_{i}^{t-1} = f_i^{t-1} U_f^{t-1} = f_i^{t-1} (U^{t-1} \circ W_{trans}), \end{equation} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div>     </p>     <p>where &#x25CB; denotes the Hadamard product operation.</p>     <p>     <strong>Integrating impact factors of user preference.</strong> In&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>], user&#x0027;s embedding <span class="inline-equation"><span class="tex">$u_i^{t-1}$</span>     </span> and the user&#x0027;s embedding influence by friendships <span class="inline-equation"><span class="tex">$\tilde{u}_{i}^{t-1}$</span>     </span> are integrated by linear combination. Inspired by &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>], we believe that the simple linear combination of <span class="inline-equation"><span class="tex">$u_i^{t-1}$</span>     </span> and <span class="inline-equation"><span class="tex">$\tilde{u}_{i}^{t-1}$</span>     </span> will limit the model&#x0027;s representation ability.</p>     <p>We propose to use a standard MLP to identify the non-linearity interaction between <span class="inline-equation"><span class="tex">$u_i^{t-1}$</span>     </span> and <span class="inline-equation"><span class="tex">$\tilde{u}_{i}^{t-1}$</span>     </span>. The output of the user hidden layer is the latent preference prediction of user i at time t, <span class="inline-equation"><span class="tex">$ \hat{u}_i^t \in \hat{U}^t$</span>     </span>.</p>    </section>    <section id="sec-9">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Item Attribute Model</h3>     </div>     </header>     <p>Our model assumes the item attributes will change over time (e.g., a restaurant will serve different food in different seasons). We utilize the LSTM recurrent neural networks that can address the vanishing gradient problem to determine the inherent item dynamics instead of the states of items.</p>     <p>An item&#x0027;s parameters are dependent on the users who have consumed it and its popularity. Accordingly, the input of the item attribute model is the items with ratings from users at a previous time interval. We then use a transformation matrix to learn how to project this information into an embedding space and get item latent vector <span class="inline-equation"><span class="tex">$y_j^t$</span>     </span>, which serves as the input to the LSTM. The output of item attribute model <span class="inline-equation"><span class="tex">$i_j^t$</span>     </span> is the latent state of item j at time t.</p>    </section>    <section id="sec-10">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.3</span> Rating Prediction</h3>     </div>     </header>     <p>The output of the user preference model and the item attribute model serve as the input of the recommendation output layer. The states of user i and item j change with time, but we assume that some stationary components still remain, such as the item genre or user gender. We propose the dynamic vectors <span class="inline-equation"><span class="tex">$\hat{u}_i^t$</span>     </span> and <span class="inline-equation"><span class="tex">$i_j^t$</span>     </span> with stationary components <em>u<sub>i</sub>     </em> and <em>i<sub>j</sub>     </em>: <span class="inline-equation"><span class="tex">$\hat{r}_{ij}^t = sigmoid({\lt}\hat{u}_i^t,\bar{i}_j^t{\gt}+{\lt}u_i,i_j{\gt})$</span>     </span>, where <span class="inline-equation"><span class="tex">$\bar{i}_j^t$</span>     </span> is the affine function of <span class="inline-equation"><span class="tex">$i_j^t$</span>     </span>. The whole framework is trained to find parameters that minimize the optimization objective: <div class="table-responsive" id="Xeq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathop {\min }\limits _\theta \sum _{(i,j,t) \in train} (r_{ij}^t - \hat{r} _{ij}^t)^2 + \lambda \sum _{t=2}^T \sum _{a=1}^N\Vert \hat{U}_a^t - U_a^t\Vert _F ^2 + R(\theta), \end{equation} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div> where <em>&#x03B8;</em> denotes all parameters to be learned, <em>R</em> denotes the regulation function, and <em>&#x03BB;</em> regularizes the evolution of users&#x2019; latent preferences over time. <figure id="fig2">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186956/images/www18companion-196-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Performance comparison on RMSE</span>      </div>     </figure>     <figure id="fig3">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186956/images/www18companion-196-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 3:</span>       <span class="figure-title">Performance with the impact of <em>&#x03BB;</em>       </span>      </div>     </figure>     </p>    </section>   </section>   <section id="sec-11">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Experimental Evaluation</h2>     </div>    </header>    <p>We conduct experiments on two real-world datasets: <em>Epinions</em> and <em>Gowalla</em>. In all the experiments, we follow the same procedures, including data preprocessing and splitting process, as those in previous work&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>].</p>    <p>Fig.&#x00A0;<a class="fig" href="#fig2">2</a> illustrates the prediction results of various models with different latent dimension sizes D on the two datasets. The figure reveals that our proposed model performs the best among all the models and is better than the previous best model by up to 4.5% on <em>Epinions</em> and 5.1% on <em>Gowalla</em> in terms of the average RMSE per dimension. We argue that one reason for the superiority of our proposed model is the in-depth study of the formation process of user preferences with social influences in a dynamic social network. Meanwhile, the item LSTM helps us accurately capture the dynamic attributes of items.</p>    <p>To evaluate the impact of <em>&#x03BB;</em>, we conduct experiments with various <em>&#x03BB;</em>. As shown in figure.&#x00A0;<a class="fig" href="#fig3">3</a>, the prediction performance increases as <em>&#x03BB;</em> increases until <em>&#x03BB;</em> reaches 0.01 on <em>Epinons</em> and 0.1 on <em>Gowalla</em>.</p>   </section>   <section id="sec-12">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> conclusions</h2>     </div>    </header>    <p>This study proposed a general end-to-end neural framework for modeling the evolution of user preferences and item attributes in dynamic social networks. The experimental evaluation demonstrated the effectiveness of the introduced model.</p>    <p>     <strong>Acknowledgements.</strong> This work was supported in part by the National Natural Science Foundation of China under Grant No.U1636116, 11431006, and the Research Fund for International Young Scientists under Grant No. 61650110510 and 61750110530.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In <em>      <em>WWW</em>     </em>. 173&#x2013;182.</li>     <li id="BibPLXBIB0002" label="[2]">Andriy Mnih and Ruslan&#x00A0;R Salakhutdinov. 2008. Probabilistic matrix factorization. In <em>      <em>Advances in neural information processing systems</em>     </em>. 1257&#x2013;1264.</li>     <li id="BibPLXBIB0003" label="[3]">Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander&#x00A0;J Smola, and How Jing. 2017. Recurrent recommender networks. In <em>      <em>WSDM</em>     </em>. 495&#x2013;503.</li>     <li id="BibPLXBIB0004" label="[4]">Le Wu, Yong Ge, Qi Liu, Enhong Chen, Richang Hong, Junping Du, and Meng Wang. 2017. Modeling the Evolution of Users&#x2019; Preferences and Social Links in Social Networking Services. <em>      <em>IEEE TKDE</em>     </em>29, 6, 1240&#x2013;1253.</li>     <li id="BibPLXBIB0005" label="[5]">Carl Yang, Lanxiao Bai, Chao Zhang, Quan Yuan, and Jiawei Han. 2017. Bridging Collaborative Filtering and Semi-Supervised Learning: A Neural Approach for POI Recommendation. In <em>      <em>SIGKDD</em>     </em>. 1245&#x2013;1254.</li>     <li id="BibPLXBIB0006" label="[6]">Yin Zheng, Bangsheng Tang, Wenkui Ding, and Hanning Zhou. 2016. A neural autoregressive approach to collaborative filtering. In <em>      <em>ICML</em>     </em>. 764&#x2013;773.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186956">https://doi.org/10.1145/3184558.3186956</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
