<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>User Fairness in Recommender Systems</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3186949'>https://doi.org/10.1145/3184558.3186949</a> 
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3186949'>https://w3id.org/oa/10.1145/3184558.3186949</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">User Fairness in Recommender Systems</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Jurek</span> <span class="surName">Leonhardt</span> L3S Research Center, Appelstraße 4Hannover, Germany, <a href="mailto:leonhardt@l3s.de">leonhardt@l3s.de</a>
        </div>
        <div class="author">
          <span class="givenName">Avishek</span> <span class="surName">Anand</span> L3S Research Center, Appelstraße 4Hannover, Germany, <a href="mailto:anand@l3s.de">anand@l3s.de</a>
        </div>
        <div class="author">
          <span class="givenName">Megha</span> <span class="surName">Khosla</span> L3S Research Center, Appelstraße 4Hannover, Germany, <a href="mailto:khosla@l3s.de">khosla@l3s.de</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186949" target="_blank">https://doi.org/10.1145/3184558.3186949</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Recent works in recommendation systems have focused on diversity in recommendations as an important aspect of recommendation quality. In this work we argue that the post-processing algorithms aimed at only improving diversity among recommendations lead to discrimination among the users. We introduce the notion of <em>user fairness</em> which has been overlooked in literature so far and propose measures to quantify it. Our experiments on two diversification algorithms show that an increase in aggregate diversity results in increased disparity among the users.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS Concepts:</span> • <strong>Information systems</strong> → <strong>Recommender systems;</strong></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style="font-weight:bold;"><small>Keywords:</small></span> <span class="keyword"><small>user satisfaction</small>,</span> <span class="keyword"><small>fairness</small>,</span> <span class="keyword"><small>recommender systems</small>,</span> <span class="keyword"><small>diversity</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Jurek Leonhardt, Avishek Anand, and Megha Khosla. 2018. User Fairness in Recommender Systems. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New York, NY, USA</em> 3 Pages. <a href="https://doi.org/10.1145/3184558.3186949" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3184558.3186949</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <p>Most recommender systems typically learn from past user interactions and preferences to recommend items (movies, products etc.) to users. The success of a recommender algorithm is generally evaluated with the accuracy of its recommendations, that is, how well the algorithm predicts whether a user will like an item or not – its utility. The aspect of user fairness arises when the task requires to consider the disparate impacts of recommendations on some user classes. On the one hand it might be unfair to ignore wishes of a certain class of users while trying to improve diversity in recommendations, on the other hand it is equally unfair to users if there is a lack of newness in the items which are recommended to them. A more dire situation can be seen in a job recommendation site, where a slightly under-confident person might always click on jobs with lower salary and is consequently always recommended jobs with lower salary distributions irrespective of his qualifications.</p>
      <p>The utility-fairness conundrum is central to all fairness based measures. Specifically, making the recommendations fair will always result in a certain decrease in utility of the system. From the fairness perspective we recognize two major sources of unfair distributions in recommender systems. The first, and more obvious, is the skewed distribution caused by the recommendations of items to users. This causes unfairness in the marketplace where certain items are recommended only very infrequently or not at all. The second and more subtle source of skew is caused by post-processing algorithms that address marketplace unfairness. Much of the previous work relates to improving (1) <em>individual diversity</em>, in which the focus lies on providing diverse recommendations to the users, and (2) <em>aggregate diversity</em>, which focuses on improving item diversity across all users. Though individual and aggregate diversity can be interpreted as improving fairness for users and items respectively, they do not explore other aspects of fairness like differential treatment of two users or two items. For example, in order to improve aggregate diversity, an online store might recommend highly rated items to a set of users who are potential buyers, say the rich users, while new items (whose quality cannot be judged) are only recommended to poor users. On the one hand the recommender system might be unfair to the set of poor users, on the other hand it introduces item disparity by recommending new items only to users who might not actually buy them. Consequently, in designing fairness measures one needs to consider fairness criteria that should not unfairly discriminate against a certain set of users.</p>
      <p>In this work we quantify the user unfairness or discrimination caused by the post-processing algorithms which have the original goal of improving diversity in recommendations. We perform experimental analysis on MovieLens and provide evidence that diversity improving algorithms can lead to discrimination among users.</p>
      <p><strong>Related Work.</strong> There have been recent, though limited, works on fairness aspects of recommender systems. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>] the authors examine fairness issues in <em>package-to-group</em> recommendations. Specifically, when they recommend a package to a group of people, they posit that this recommendation is fair, i.e. every group member is satisfied by a certain number of items in their package. Notions of novelty and diversity in recommender systems, as well as measures to quantify them and methods to improve them have been described by various authors&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>].</p>
      <p>Optimizing only for diversity can adversely affect accuracy, resulting in irrelevant recommendations. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>] the authors describe a hybrid approach that combines the ranking of an accurate algorithm with the ranking of a diverse algorithm.</p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Measuring User Fairness</h2>
        </div>
      </header>
      <p>For the present work we restrict our attention to the movie recommendation task and show that post-processing algorithms that only optimize for diversity improvement among recommendations cause discrimination among users. We will need the following notations.</p>
      <p><strong>Notations</strong>: Let <em>I</em> denote the set of <em>m</em> items which need to be recommended to the user set <em>U</em> of <em>n</em> users such that each user is recommended <em>k</em> items. We aim to understand the fairness aspects of the procedures followed for post processing recommendations. Let <em>G</em> = (<em>U</em>∪<em>I</em>, <em>E</em>) be the weighted bipartite graph representing <em>n</em> users by the vertices in <em>U</em> and <em>m</em> items by the vertices in <em>I</em>. Let, for each edge (<em>u</em>, <em>i</em>) ∈ <em>E</em>, <em>w</em>(<em>u</em>, <em>i</em>) represent the preference score (predicted) of user <em>u</em> with respect to item <em>i</em>. For any <em>u</em> ∈ <em>U</em>, let <em>R</em>(<em>u</em>) be the set of recommended items. Let <em>R<sup>top</sup></em> (<em>u</em>) be the set of top-<em>k</em> items for user <em>u</em> with the highest preference scores. We assume that <em>R<sup>top</sup></em> (<em>u</em>) ≠ ∅ for all <em>u</em> ∈ <em>U</em>.</p>
      <p>Below we propose two measures for estimating user discrimination caused by the diversity improving algorithms. We first define <em>user satisfaction</em> as a function of the relative gain achieved by the user due to the actual recommendation with respect to the optimal recommendation strategy (from the user perspective) where only the items with the top scores are recommended. Our first measure then computes the Gini coefficient for user satisfaction. Similarly, for our second measure we compute the user gain in terms of how many of the the recommended items match the top-<em>k</em> items. We again compute the Gini coefficient of these user gains.</p>
      <p><strong>Score Disparity</strong>: First, we define user satisfaction for a user <em>u</em> as the ratio of the sum of the preference scores for the items recommended to <em>u</em> to the sum of the preference scores for the top-<em>k</em> items, i.e. <span class="inline-equation"><span class="tex">$\mathcal {A}(u) = {\sum _{j\in R(u)} w(u,j) \over {\sum _{j\in R^{top}(u)} w(u,j)}}$</span></span> . Note that <span class="inline-equation"><span class="tex">$0 \le \mathcal {A}(u) \le 1$</span></span> for all <em>u</em> ∈ <em>U</em>. Now, similar to how the Gini coefficient is used to measure disparity among populations, we define <em>Score Disparity</em> as</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\[ S={\sum _{u_1, u_2\in U} |\mathcal {A}(u_1) - \mathcal {A}(u_2)| \over 2n \sum _{u \in U}\mathcal {A}(u)}. \]</span><br />
        </div>
      </div>
      <p></p>
      <p><strong>Recommendation Disparity</strong>: We first compute the similarity among the recommended items to users and their top-<em>k</em> items with respect to preference scores as <span class="inline-equation"><span class="tex">$sim(u)= {|R(u) \cap R^{top}(u)| \over k}$</span></span> . We then compute the user disparity which we refer to as <em>Recommendation Disparity</em> based on the above computed similarity scores as</p>
      <div class="table-responsive">
        <div class="display-equation">
          <span class="tex mytex">\[ R={\sum _{u_1, u_2\in U} |sim(u_1) - sim(u_2)| \over 2n \sum _{u \in U} sim(u)}. \]</span><br />
        </div>
      </div>
      <p></p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Experimental Results</h2>
        </div>
      </header>
      <p>The MovieLens<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> dataset that we use for our experiments contains 100&nbsp;000 ratings on 1700 movies from 1000 users. We use traditional collaborative filtering algorithms to obtain a list of predictions for each user. We then apply the standard ranking algorithm to obtain every user's top-<em>k</em> predictions. Our experiments aim to illustrate the trade-off between recommendation diversity and user fairness. We run two post-processing algorithms (for recommendation diversity) on a set of predictions obtained from traditional CF algorithms (<em>k</em>-nearest neighbors and non-negative matrix factorization).</p>
      <p>The first post-processing algorithm, referred to as <em>Random</em>, takes a parameter ℓ and works by randomly sampling recommendations: To obtain a set of <em>k</em> recommendations for a user, we simply employ the standard ranking algorithm to get the top-ℓ recommendations and then sample <em>k</em> items uniformly from the result (<em>k</em> ≤ ℓ). This introduces some randomness to the final recommended items. The second algorithm, also referred to as <em>Greedy</em> (see Algorithm 1 from [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>]), aims to increase the aggregate diversity among the recommendations by a value <em>θ</em> by replacing the top recommendations for a user with new recommendations (each having a preference score above a given threshold). We recall that aggregate diversity is defined as the fraction of total items which have been recommended at least once. The results of both algorithms are illustrated in Figures <a class="fig" href="#fig1">2</a> and 1 . The plots clearly show an increase in the two defined user disparity measures when aggregate diversity increases. For example, applying the <em>Greedy</em> algorithm to KNN-based recommendations (see Figure&nbsp;1) causes an improvement in the aggregate diversity from 1.6% to 60.5% along with increases from 0.01% to 3.6% in Score Disparity and from 0.2% to 20.1% in Recommendation Disparity. This implies that there is indeed a trade-off between recommendation diversity and user fairness.</p>
      <figure id="fig1">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186949/images/www18companion-189-fig1.jpg" class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class="figure-title">Applying the <em>Greedy</em> post-processing algorithm (<em>k</em> = 5) to predictions from CF algorithms. Each data point resembles a value of <em>θ</em> ∈ {10, 100, 200, 500, 1000}.</span>
        </div>
      </figure>
      <p></p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Acknowledgements</h2>
        </div>
      </header>
      <p>This work is partially funded by ALEXANDRIA (ERC 339233).</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Gediminas Adomavicius and YoungOk Kwon. 2014. Optimization-based approaches for maximizing aggregate recommendation diversity. <em><em>INFORMS Journal on Computing</em></em> 26, 2 (2014), 351–369.</li>
        <li id="BibPLXBIB0002" label="[2]">Arda Antikacioglu and R Ravi. 2017. Post Processing Recommender Systems for Diversity. In <em><em>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em></em> . ACM, 707–716.</li>
        <li id="BibPLXBIB0003" label="[3]">Christian Matt, Thomas Hess, and Christian Weiß. 2013. The differences between recommender technologies in their impact on sales diversity. In <em><em>International Conference on Information Systems</em></em> .</li>
        <li id="BibPLXBIB0004" label="[4]">Bibek Paudel, Fabian Christoffel, Chris Newell, and Abraham Bernstein. 2016. Updatable, Accurate, Diverse, and Scalable Recommendations for Interactive Applications. <em><em>ACM Trans. Interact. Intell. Syst.</em></em> 7, 1, Article 1 (Dec. 2016), 34&nbsp;pages.</li>
        <li id="BibPLXBIB0005" label="[5]">Dimitris Serbos, Shuyao Qi, Nikos Mamoulis, Evaggelia Pitoura, and Panayiotis Tsaparas. 2017. Fairness in package-to-group recommendations. In <em><em>Proceedings of the 26th International Conference on World Wide Web</em></em> . International World Wide Web Conferences Steering Committee, 371–379.</li>
        <li id="BibPLXBIB0006" label="[6]">Zoltán Szlávik, Wojtek Kowalczyk, and Martijn&nbsp;C Schut. 2011. Diversity Measurement of Recommender Systems under Different User Choice Models. In <em><em>ICWSM</em></em> .</li>
        <li id="BibPLXBIB0007" label="[7]">Tao Zhou, Zoltán Kuscsik, Jian-Guo Liu, Matúš Medo, Joseph&nbsp;Rushton Wakeling, and Yi-Cheng Zhang. 2010. Solving the apparent diversity-accuracy dilemma of recommender systems. <em><em>Proceedings of the National Academy of Sciences</em></em> 107, 10(2010), 4511–4515.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>available at <a class="link-inline force-break" href="http://www.grouplens.org">www.grouplens.org</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&nbsp;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3184558.3186949">https://doi.org/10.1145/3184558.3186949</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
