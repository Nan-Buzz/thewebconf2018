<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>API Learning: Applying Machine Learning to Managethe Rise of API Economy</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3186966'>https://doi.org/10.1145/3184558.3186966</a> 
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3186966'>https://w3id.org/oa/10.1145/3184558.3186966</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">API Learning: Applying Machine Learning to Managethe Rise of API Economy</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Mehdi</span> <span class="surName">Bahrami</span> Fujitsu Laboratories of America, Inc., Sunnyvale, California 94085
        </div>
        <div class="author">
          <span class="givenName">Junhee</span> <span class="surName">Park</span> Fujitsu Laboratories of America, Inc., Sunnyvale, California 94085
        </div>
        <div class="author">
          <span class="givenName">Lei</span> <span class="surName">Liu</span> Fujitsu Laboratories of America, Inc., Sunnyvale, California 94085
        </div>
        <div class="author">
          <span class="givenName">Wei-Peng</span> <span class="surName">Chen</span> Fujitsu Laboratories of America, Inc., Sunnyvale, California 94085, <a href="mailto:mbahrami;jpark;lliu;wchen@us.fujitsu.com">mbahrami;jpark;lliu;wchen@us.fujitsu.com</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186966" target="_blank">https://doi.org/10.1145/3184558.3186966</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Application Programming Interface (API) exposes data and functions of a software application to third-party users. In digital business, API economy is one of the key component for determining the value of provided services. With the rise in number of publicly available APIs, understanding each API endpoint manually is not only labor intensive but it is also an error prone task for software engineers. Due to the complexity of understanding the sheer number of APIs, it is difficult for software developers to find the best possible API combinations (i.e. API Mashups). In this demonstration, we introduce API Learning platform which employs machine-learning based technologies to efficiently search APIs, validate APIs, and generate API mashups. These technologies enable a machine to automatically generate machine-readable API specification from API documentations, understand variety of APIs, validate extracted information through automated API validation, and finally recommend API mashups for a specific purpose. As of now, API Learning platform collected over 14,000 API documentations and generates a machine readable format for REST APIs with an accuracy of 84%. The proposed demo prototype shows how it enables users to quickly find relevant APIs, automatically verify API availability, and get the best possible API mashup recommendations.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS Concepts:</span> • <strong>Information systems</strong> → <strong>RESTful web services;</strong> <em>Web services;</em> Mashups; • <strong>Computing methodologies</strong> → <strong>Supervised learning;</strong> • <strong>Software and its engineering</strong> → <strong>API languages;</strong> <strong>Specification languages;</strong></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style="font-weight:bold;"><small>Keywords:</small></span> <span class="keyword"><small>API; Machine Learning; REST; Mashup; Automation</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Mehdi Bahrami, Junhee Park, Lei Liu, and Wei-Peng Chen. 2018. API Learning: Applying Machine Learning to Managethe Rise of API Economy. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New York, NY, USA</em> 4 Pages. <a href="https://doi.org/10.1145/3184558.3186966" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3184558.3186966</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-2">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <p>Web APIs or RESTful (REpresentational State Transfer) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>] APIs have been widely used in cloud-based services due to its inherent flexibility and low overhead. API functions or data from APIs can be efficiently integrated into a software application. In the era of digital business, employing APIs is the key element of various successful businesses. With the rise in number of APIs in the market, manual understanding of each API functionality is not only labor intensive but also it is an error prone task for software engineers. Finally, due to the complexity of heterogeneous structure of API documentations and the sheer number of APIs, it is a burdensome task for software engineers to find the most suitable API Mashups.</p>
      <p><strong>Motivation.</strong> The process of utilizing APIs in a software application is not a trivial task for developers. According to <em>ProgrammableWeb</em> there are more than 18,503 public APIs. Understanding a large number of APIs with heterogeneous structures is a significant challenge for software engineers to select the best APIs for their software projects. By having a machine-readable API specification, software engineers can efficiently utilize and compare API capabilities without reading API documentations. It also opens door to a set of new artifacts, such as API mashup service recommendations that combines multiple APIs together. To the best of our knowledge, only limited APIs offer machine-readable API specifications and this is the first study that generates machine-readable API specifications from API documentations. Although some initial discussions have been started on Swagger and WebSchema as an extension proposal at W3C, a dominant standard for machine-readable API specifications have not existed yet.</p>
      <p><strong>Contribution.</strong> In this demonstration<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>, we proposed a platform that uses various machine learning and Natural Language Processing (NLP) algorithms to produce machine-readable API Specifications. The proposed platform has developed an ensemble of novel technologies which enables software engineers to easily use and retrieve information about heterogeneous API documentations. The proposed approach understands a variety of API documentations and produces a machine-readable API specification based on OpenAPI Specification (OAS)<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>. We collected a large annotated dataset of information extraction evaluation. In addition to this manual annotation, we also automated the process of validating the extracted information, generated from the proposed <em>API Learning</em> methods. Finally, the output of the proposed platform has been processed by an API mashup service recommendation that list the best possible API combinations based on their input/output similarity.</p>
    </section>
    <section id="sec-3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Proposed Approach</h2>
        </div>
      </header>
      <p>Our goal is to extract information from API documentations that are published by API providers. Figure <a class="fig" href="#fig1">1</a> shows the key components of the proposed approach. In this figure, we have several components for both data collection and data processing as follows. <strong>Web Crawler</strong>.This component collects a large number of API documentations from the web as described in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>]. First, the volume of data allows the proposed platform to learn heterogeneous structures in a large number of API documentations from various data sources. Second, it improves the accuracy of information extraction by learning a variety of data. The collection of the text content of all HTML pages which are collected by web-crawler produces <em>API Corpus</em>. The <em>API Corpus</em> consist of a large clean text file (e.g., without HTML and script codes) for each API. <strong>REST API Filter</strong>. This component to filter out some pages which are irrelevant to the target APIs (RESTful APIs in this study). The REST API filter employs a logistic regression model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>] to detect REST category APIs. We use <em>REST Keyword Frequency</em> to train the model, and we use this component to generate a set of features for each API documentation in <em>API Corpus</em>. We consider major REST keywords, such as <em>POST, GET, DELETE, endpoint</em> and etc, to extract a set of term frequency of these keywords <em>TF</em>(<em>keyword</em>) from each page. Therefore, we generate an array of <em>X</em> REST keywords for each web page, where <span class="inline-equation"><span class="tex">$X_i^T$</span></span> represents the term frequency of <em>i</em>th REST keyword in <em>T</em>th API documentation page and the cost function of the logistic regression can be defined as follows.</p>
      <figure id="fig1">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186966/images/www18companion-206-fig1.jpg" class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class="figure-title">The proposed platform of API Learning</span>
        </div>
      </figure>
      <div class="table-responsive" id="Xeq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} {\underset{w, c}{min\,} \frac{1}{2}w^T w + C \sum _{i=1}^n \log (\exp (- y_i (X_i^T w + c)) + 1) } \end{equation}</span><br />
          <span class="equation-number">(1)</span>
        </div>
      </div><strong>REST API Language Model</strong>.This component reads <em>API Corpus</em> and it generates a language model of API documentations. The model allows the platform to understand the semantic definition of each word in <em>API Corpus</em>. <em>API Language Model</em> is a statistical model which is defined as a neural language model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>] that shows probability distribution on all sentences in <em>API Corpus</em>. It uses embedding of words to predict word sequences. The cosine similarity of two words, <em>W</em> <sub>1</sub> and <em>W</em> <sub>2</sub>, in word to vector provides a semantic definition of <em>n</em> words in <em>API Corpus</em>, which is defined as follows.
      <div class="table-responsive" id="Xeq2">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} {\text{Sim}}={{W_1} \cdot {W_2}\over \Vert {W_1} \Vert _{2}\Vert {W_2} \Vert _{2}}={\frac{\sum \limits _{i=1}^{n}{W_{1,i}W_{2,i}}}{{\sqrt {\sum \limits _{i=1}^{n}{{W_{1,i}}^{2}}}}{\sqrt {\sum \limits _{i=1}^{n}{{W_{2,i}}^{2}}}}}} \end{equation}</span><br />
          <span class="equation-number">(2)</span>
        </div>
      </div>This function extends a <em>pattern</em> in each iteration. <strong>API Learning</strong>.We define a set of rule-based regular expression tasks for extracting information from <em>API Corpus</em>. Each task includes an initial regular expression <em>pattern</em> which is defined by an expert (i.e., a software developer who can define a simple pattern to extract endpoint) . For example, a task may consists of API endpoints extraction, and another task may consist of a pattern that extracts API endpoint's parameters. Each <em>pattern</em> can be improved based on a new approach which is inspired by transformation-based learning algorithm [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>], [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>]. The proposed approach extends acceptance of information (<em>extended pattern</em>, and then shrink it to find the best <em>pattern</em> to extract variety of information. In addition, the proposed approach uses <em>REST API Language Model</em> to extend each word in a <em>pattern</em> based on a semantic definition of a word. Each task in <em>Tasks</em> has an initial regular expression. For instance, an expert recommends an initial regular expression to extract the information (e.g., <em>pattern</em> <sub>1</sub>) for extracting API endpoints and another task (e.g., <em>pattern</em> <sub>2</sub>) for detecting a table that describes a list of input parameters. Different API descriptions may need different <em>pattern</em>s to extract the same concept. For instance, Facebook uses the terminology of <em>fields</em> to describe the input parameters of an endpoint<a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>; but Google uses <em>parameters</em> to describe the input parameters of an endpoint <a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a>. The <em>REST API Language Model</em> enables the platform to understand semantic definition of each word in each <em>pattern</em>. For example, the semantic definition of <em>fields</em> can be <em>parameter</em>, and a <em>pattern</em> that consist of <em>field</em> (<em>pattern</em> <sub>1</sub> = <em>field</em>) can be extended to <em>pattern</em> <sub>2</sub> = <em>field</em>|<em>parameter</em>. In addition, we need to learn different regular expression to extract the same information with different structures. The proposed approach i) expends the acceptance of initial <em>RE</em>, and then ii) it reduces the <em>RE</em> pattern to match only positive cases sample cases. The following tasks are the major <em>IE Tasks</em>, such as <em>host address</em>, <em>base path address</em>, <em>endpoint URI</em>, and <em>parameters attribute</em>. The concatenation of the host address, base path and endpoint address provide a unique URL that provide a specific function. For example, <em>”POST https://api.twitter.com/1.1/statuses/update.json”</em> is a unique URL to update user's current status as known as Tweeting. In this API endpoint function, <em>POST</em> is the <em>http function</em> and it shows how to call the endpoint, <em>”https://api.twitter.com/”</em> is the <em>host address</em>, ”1.1/” is the <em>path base address</em> and <em>”statuses/update.json”</em> is the endpoint address. In order to solve the optimization problem, we have to compute the total number of acceptance cases and sample rejection cases from samples <em>S</em> in respect to each API, <span class="inline-equation"><span class="tex">$\mathcal {A}$</span></span> .
      <div class="table-responsive" id="eq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} \max _{x\in \mathbb {D} }\;f_P({|s_p(x_\mathcal {A})|-|s_n(x_\mathcal {A})|}) \end{equation}</span><br />
          <span class="equation-number">(3)</span>
        </div>
      </div><span class="inline-equation"><span class="tex">$\mathbb {D}$</span></span> denotes API documentations that can be retrieved from <em>API Corpus</em>. <em>s<sub>p</sub></em> denotes a set of positive examples of language <span class="inline-equation"><span class="tex">$L_{\mathcal {A}}$</span></span> in respect to the target API, <span class="inline-equation"><span class="tex">$\mathcal {A}$</span></span> ; and <span class="inline-equation"><span class="tex">$s_n\notin L_{\mathcal {A}}$</span></span> where <em>s<sub>n</sub></em> denotes negative examples of language <em>L</em> in respect to the target API, <span class="inline-equation"><span class="tex">$\mathcal {A}$</span></span> . <em>f<sub>P</sub></em> defines a function that uses set of regular expression rule patterns <em>P</em>, that accepts <em>s<sub>p</sub></em> and rejects <em>s<sub>n</sub></em> in <span class="inline-equation"><span class="tex">$L_{\mathcal {A}}$</span></span> . In the proposed approach our goal is to maximize <span class="inline-equation"><span class="tex">$f_{P_i}$</span></span> . In the proposed approach, each <em>pattern</em> is improved by learning from different positive and negative cases. The proposed approach extends acceptance of information (<em>extended pattern</em>, and then shrink it to find the best <em>pattern</em> to extract variety of information. In addition, the proposed approach uses <em>REST API Language Model</em> to extend each word to semantic definition of a word of a <em>pattern</em> of <em>RE</em>. In the proposed approach our goal is to maximize <span class="inline-equation"><span class="tex">$f_{P_i}$</span></span> as shown in Equation <a class="eqn" href="#eq1">3</a>. Unlike Li et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>] and Bartoli et al.[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>] the proposed approach takes <span class="inline-equation"><span class="tex">$f_{P_i}$</span></span> and it generates a new <em>pattern</em> (<span class="inline-equation"><span class="tex">$f_{P_{i+1}}$</span></span> ) where <span class="inline-equation"><span class="tex">$f_{P_i} \subseteq f_{P_{i+1}}$</span></span> or <span class="inline-equation"><span class="tex">$f_{P_i} \not\subseteq f_{P_{i+1}}$</span></span> . In another word, the new generation may improve the acceptance rate and decrease the rejection rate, even if the new <em>pattern</em> is not a subset of previous <em>pattern</em>. The final output of the platform is a machine-readable format of API documentation as a JSON file based on the OAS. <strong>Automated API Connectivity Validation</strong>. In order to evaluate our information extraction result, we incorporated automated API validation service where we send native API call for each endpoint and validate its availability. By utilizing OAS-based API learning results, automated API validation service extracts information, such as host, base-path, endpoint, and parameter requirement for each API. This information is used to formulate native API calls. Once the request is generated, we send the request to the corresponding API host server and retrieve its response. Based on HTTP status code, we separate all 5xx errors and select 4xx errors, such as 404, and 408 (i.e., Not Found, and Request Timeout, respectively), denote as <em>error</em>, for all other responses, we indicate as <em>passed validation</em>. <strong>API Mashup.</strong>. Based on the OAS-based API learning results, we firstly parse the information from the JSON file of each API, and then based on the category keywords and API descriptions, we cluster 1,991 APIs into different groups. Compared to our previous work which only considers APIs in the health care domain, in this work, the APIs and mashups covers multiple and different vertical domains. After clusting, APIs within a same group are similar, which are not involved for mashup computation. In order words, the mashup only considers the combination of dissimilar APIs that are clustered in different groups. For those APIs, we obtain input/output parameter descriptions from API Learning results, and then we measure the similarity score of the input/output parameter descriptions. APIs with higher similarity are more likely to be combined as a mashup because their inputs or outputs are similar.
      <figure id="fig2">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186966/images/www18companion-206-fig2.jpg" class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class="figure-title">Automated API validation results</span>
        </div>
      </figure>
      <p></p>
    </section>
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Demonstration</h2>
        </div>
      </header>
      <p>The first component is web-crawler that collects a large number of API documentation web-pages. We used several sources, such as ProgrammableWeb, API Harmony, RapidAPI, and etc to collect a comprehensive list of APIs as a pointer list to API Documentations. The pointer list consists of more than 14,000 API links. In this demonstration, we target REST APIs. We used <em>Scrapy</em> <a class="fn" href="#fn5" id="foot-fn5"><sup>5</sup></a> for implementation of the parallel web-crawler. Each agent crawls a web-page from the pointer list and collects all subsequent pages. We collected 256,583 web-pages with the size of 15<em>GB</em> for more than 14,000 public APIs. However, not all of the public APIs categorized as REST API group; therefore according to <em>REST API Filter</em>, we have 5,320 REST API which represents 37.25% APIs from <em>API Corpus</em>.</p>
      <p><strong>API Language Model</strong>. We used a Continuous Bag of Words (CBOW) as known as Word2Vec model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>] and [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>] to generate <em>API Language Model</em> which is an unsupervised learning method. By providing a set of positive and/or negative words, we can inquiry the model to find similar words. The parameter of Word2Vec is described by Rong in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>] which we chose 300 for the window size which represents the maximum windows distance between a selected word and a predicted word within a sentence. We considered the min frequency of 5 for considering a word for training purpose.</p>
      <p><strong>API Learning</strong>. We defined several tasks with initial pattern of <em>RE</em> as described in Section <a class="sec" href="#sec-3">2</a>. After a task learns a pattern (<em>P<sub>final</sub></em> ), then we apply the task to API documentations. After applying <em>P<sub>final</sub></em> of each task to the <em>API Corpus</em>, the proposed platform generates a set of extracted information as a JSON file for each API based on OAS format which includes: i) API metadata, ii) API endpoints, and iii) different types of tables (e.g., a table may consist of parameters of an endpoint). We evaluated the correctness of extracted information manually for 2,929 API endpoints and 1,780 extracted tables. The evaluation is a comparison between original HTML API documentation and the generated JSON file as output to mark correctness of information extraction. We compare extracted information against original source and annotate them as correct or incorrect extracted information. In this evaluation, we considered extracted table from 200 APIs that consist of 1,780 extracted different tables (e.g., parameter table that shows parameter information), and extracted endpoints for 350 APIs that consist of 2,929 endpoints. To the best of our knowledge, we produced a number of annotation of extracted information with a practical use case of API documentation for the first time. Our evaluation results shows that we have extracted 86.75% of API endpoints and 81.29% of table correctly. The average of information extraction accuracy <a class="fn" href="#fn6" id="foot-fn6"><sup>6</sup></a> is 84.02%.</p>
      <p><strong>API Validation</strong>. As shown in Figure&nbsp;<a class="fig" href="#fig2">2</a>, we have evaluated 1,923 APIs and 54,873 Endpoints. Among those APIs, 1,453 APIs (76%) are active (at least an API has one active endpoint), 470 APIs (24%) are inactive. From those active APIs, 53,451 endpoints (82%) has active endpoints and 11,451 endpoints (18%) are inactive. This evaluation result is incorporated into our platform as shown in Figure&nbsp;3c . Endpoints that passed the evaluation would have green check marks whereas others would indicate their failure with the reason (e.g., Connection Timeout, Not Found, etc.).</p>
      <p><strong>API Mashup</strong>. As shown in Figure&nbsp;3b, the platform provides a set of API mashups as well as multiple metrics to facilitate developers to select a desired API mashup. The metrics include (1) a similarity score which a quantitative value shows how related for the APIs in a mashup; (2) Found an API mashup record in ProgrammableWeb (Yes/No) which indicates whether the given mashup has been manually added by developers based on human knowledge; (3) Linked in API Harmony (Yes/No) which shows whether there is a record of API mashup in the API Harmony website; (4) Found in IFTTT dataset (Yes/No) which presents whether a record of API mashup found in IFTTT; and (5) Found in Github projects (Yes/No) which indicates whether there is a Github project that utilized API mashups. By using the aforementioned solution of API mashup in Section <a class="sec" href="#sec-3">2</a>, we obtained ∼ 1,500,000 possible API mashups with similarity scores larger than 50%. We also collected a large annotations of APIs which were added by human developers in ProgrammableWeb with 6,182 API mashups, 11,242 API pairs linked in API Harmony, 2,451 API mashups from IFTTT, and 2,535 API mashups from Github projects. The annotation is used as a cross-validation of API mashups against our proposed similarity scores.</p>
      <p><strong>GUI</strong>. In addition, we added a component that provides a GUI as front-end and an in-memory database (IMDB) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>] as a back-end to show the API Learning results. The GUI is a user-friendly interface that gives a suggestion list to find a machine-readable OAS based JOSN files and returns the list of search results when it searches a keyword from 4,561 OAS-based JSON files. As shown in Figure&nbsp;<a class="fig" href="#fig3">3</a>, it returns the list of APIs(Figure&nbsp;3a), shows the metadata of a selected API, the list of endpoints and parameters, the automatic validation of an endpoint, original API source documentation which is collected by the web-crawler(Figure&nbsp;3c), a live on-demand validation(Figure&nbsp;3c), and API Mashup recommendations (Figure&nbsp;3b) that offers the list of all possible API combinations.</p>
      <figure id="fig3">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186966/images/www18companion-206-fig3.jpg" class="img-responsive" alt="Figure 3" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 3:</span> <span class="figure-title">A screenshot of API Directory GUI</span>
        </div>
      </figure>
      <p></p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Conclusion</h2>
        </div>
      </header>
      <p>API documentation carries the key information of an API. More advanced APIs have more complex structure as well as more complicated API documentations. Although some machine-readable API specifications are available, such as Open API Specification and YAML, still only limited popular APIs offer a machine-readable format of their APIs. In this paper, we introduced a novel platform that processes a large amount of API documentations that consist of more than 14,000 APIs. The proposed platform processed all collected HTML page. It generates an <em>API Language Model</em> to define the semantic definition of a word which is used in a transformation-based learning algorithm to extract information from <em>API Corpus</em>. The platform generates an Open API Specification-based JSON file (machine-readable API) for a set of API documentations. It also incorporates both manual annotation and automated API validation to evaluate correctness of generated machine-readable APIs. It offers API mashup recommendation which provides a list of possible API combinations. We show multiple metrics including both the machine generated similarity scores and the existing human knowledge to evaluate the API mashup results.</p>
      <figure id="fig4">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186966/images/www18companion-206-fig4.jpg" class="img-responsive" alt="" longdesc="" />
      </figure>
      <p></p>
      <p><strong>Mehdi Bahrami</strong> received a Ph.D. in Computer Science from the University of California, Merced. His current research focuses on natural language processing for Hyperconnected and Cloud-based APIs.</p>
      <p><strong>Junhee Park</strong> received a Ph.D. in Computer Science from Georgia Institute of Technology. His research focuses on distributed systems and performance/scalability analysis.</p>
      <p><strong>Lei Liu</strong> received a Ph.D. degree from Beijing University of Posts and Telecommunications (BUPT), Beijing, China. His main research focuses on the Internet technologies.</p>
      <p><strong>Wei-Peng Chen</strong> is leading Cyber-Physical System Lab at FLA. He received a Ph.D. in Computer Science from University of Illinois at Urbana-Champaign. His research focuses on Machine Learning and IoT.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Mehdi Bahrami, Mukesh Singhal, and Zixuan Zhuang. 2015. A cloud-based web crawler architecture. In <em><em>Intelligence in Next Generation Networks (ICIN), 2015 18th International Conference on</em></em> . IEEE, 216–223.</li>
        <li id="BibPLXBIB0002" label="[2]">Alberto Bartoli, Andrea De&nbsp;Lorenzo, Eric Medvet, and Fabiano Tarlao. 2016. Inference of regular expressions for text extraction from examples. <em><em>IEEE Transactions on Knowledge and Data Engineering</em></em> 28, 5(2016), 1217–1230.</li>
        <li id="BibPLXBIB0003" label="[3]">Y. Goldberg and O. Levy. 2014. word2vec Explained: deriving Mikolov et al.’s negative-sampling word-embedding method. <em><em>preprint arXiv:1402.3722</em></em> (2014).</li>
        <li id="BibPLXBIB0004" label="[4]">David&nbsp;W Hosmer&nbsp;Jr, Stanley Lemeshow, and Rodney&nbsp;X Sturdivant. 2013. <em><em>Applied logistic regression</em></em> . Vol.&nbsp;398. John Wiley &amp; Sons.</li>
        <li id="BibPLXBIB0005" label="[5]">Tirthankar Lahiri, M. Neimat, and S. Folkman. 2013. Oracle TimesTen: An In-Memory Database for Enterprise Applications. <em><em>IEEE Data Eng. Bull.</em></em> 36, 2 (2013), 6–13.</li>
        <li id="BibPLXBIB0006" label="[6]">Yunyao Li, Rajasekar Krishnamurthy, Sriram Raghavan, Shivakumar Vaithyanathan, and HV Jagadish. 2008. Regular expression learning for information extraction. In <em><em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em></em> . Association for Computational Linguistics, 21–30.</li>
        <li id="BibPLXBIB0007" label="[7]">T. Mikolov, K. Chen, G. Corrado, and J. Dean. 2013. Efficient estimation of word representations in vector space. <em><em>preprint arXiv:1301.3781</em></em> (2013).</li>
        <li id="BibPLXBIB0008" label="[8]">Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg&nbsp;S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In <em><em>Advances in neural information processing systems</em></em> . 3111–3119.</li>
        <li id="BibPLXBIB0009" label="[9]">Lance&nbsp;A Ramshaw and Mitchell&nbsp;P Marcus. 1999. Text chunking using transformation-based learning. In <em><em>Natural language processing using very large corpora</em></em> . Springer, 157–176.</li>
        <li id="BibPLXBIB0010" label="[10]">Xin Rong. 2014. word2vec parameter learning explained. <em><em>arXiv preprint arXiv:1411.2738</em></em> (2014).</li>
        <li id="BibPLXBIB0011" label="[11]">Roy Thomas <em>et al.</em> 2000. Architectural styles and the design of network-based software architectures. <em><em>Irvine: University of California</em></em> (2000).</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>Screencast of the demo is available at:<a class="link-inline force-break" href="https://youtu.be/J6qOOF3nIG8">https://youtu.be/J6qOOF3nIG8</a></p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break" href="https://github.com/OAI/OpenAPI-Specification">https://github.com/OAI/OpenAPI-Specification</a></p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>i.e., <a class="link-inline force-break" href="https://developers.facebook.com/docs/graph-api/reference/v2.10/album">https://developers.facebook.com/docs/graph-api/reference/v2.10/album</a></p>
    <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>i.e., <a class="link-inline force-break" href="https://developers.google.com/+/web/api/rest">https://developers.google.com/+/web/api/rest</a></p>
    <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>Scrapy is an open-source project and it is available at <a class="link-inline force-break" href="https://scrapy.org">https://scrapy.org</a></p>
    <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a> <em>Accuracy</em> = <em>C</em>/<em>S</em> where <em>C</em> is the total number of correct extracted information and <em>S</em> represents the total number of extracted information .</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&nbsp;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3184558.3186966">https://doi.org/10.1145/3184558.3186966</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
