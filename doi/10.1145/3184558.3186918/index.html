<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>User Type Affinity Estimation Using Gamma-Poisson
  Model</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a HTML copy of <a href='https://doi.org/10.1145/3184558.3186918'>https://doi.org/10.1145/3184558.3186918</a> 
originally published by ACM, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML accessability, compatibility, 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3186918'>https://w3id.org/oa/10.1145/3184558.3186918</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">User Type Affinity Estimation
          Using Gamma-Poisson Model</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Fei</span> <span class=
          "surName">Wu</span> Pennsylvania State University,
          <a href=
          "mailto:fxw133@ist.psu.edu">fxw133@ist.psu.edu</a>
        </div>
        <div class="author">
          <span class="givenName">Yanen</span> <span class=
          "surName">Li</span> Snap Research, <a href=
          "mailto:Yanen.li@snap.com">Yanen.li@snap.com</a>
        </div>
        <div class="author">
          <span class="givenName">Ning</span> <span class=
          "surName">Xu</span> Snap Reserch, <a href=
          "mailto:Ning.xu@snap.com">Ning.xu@snap.com</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186918"
        target=
        "_blank">https://doi.org/10.1145/3184558.3186918</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>The affinity of a user to a type of items (e.g.,
        stories from the same publisher, and movies of the same
        genre) is an important signal reflecting the user's
        interests. Accurately estimating of the user type affinity
        has various applications in ranking and recommendation
        systems. For frequent users, simply dividing the number of
        interactions with content (e.g., clicks) by the number of
        impressions (e.g., the number of times the content is
        presented to each user) would be a good estimate. However,
        such estimates are erroneous for users who have sparse
        interaction history, (e.g., new users). To alleviate the
        problem, feature-based approaches aim to learn functions
        predicting the affinity score using only none-click
        features, such as user demographics, locations, and
        interests. Likewise, such approaches do not take full
        advantage of the interaction history of frequent
        users.</small></p>
        <p><small>Motivated by the limitations of the two
        approaches, we propose a Gamma-Poisson model that aims at
        utilizing the interaction history of frequent users, as
        well as leveraging a feature-based model for infrequent
        users. Our intuition is that we should rely more on the
        interaction history when estimating affinity for frequent
        users, and weigh more on feature-based model for infrequent
        users. We present experimental results on large-scale
        real-world data in a publisher content clicks prediction
        task to demonstrate the effectiveness of the proposed
        method in estimating user type affinity scores.</small></p>
      </div>
      <div class="classifications">
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Fei Wu, Yanen Li, and Ning Xu. 2018. User Type Affinity
          Estimation Using Gamma-Poisson Model. In <em>WWW '18
          Companion: The 2018 Web Conference Companion,</em>
          <em>April 23–27, 2018 (WWW ’18 Companion),</em> <em>Lyon,
          France. ACM, New York, NY, USA</em> 3 Pages. <a href=
          "https://doi.org/10.1145/3184558.3186918" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3186918</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Estimating affinity of a user to a type of content is a
      critical task, as the user type affinity directly signals the
      user interests. An accurate estimation of the user's type
      affinity can benefit various tasks, such as personalized news
      feed ranking, item (music, movie, and story) recommendation
      etc.</p>
      <p>For users that have sufficiently adequate interaction
      history (i.e., frequent users), a simple baseline is to
      divide the number of interactions with the content (e.g.,
      clicks or purchases) by the number impressions (e.g., the
      number of times that item of the same type is presented to
      the user). While this simple baseline could be a good
      estimation for frequent users, such an estimation is often
      erroneous for users who infrequently interact with the items
      (e.g., new users). The problem persists for more
      sophisticated methods, such as item-based collaborative
      filtering methods&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>] as they need interaction
      histories.</p>
      <p>To address these limitations, feature-based approaches
      (similar to user-based collaborative
      filtering)&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>] learn functions predicting the
      affinity score using non-click features (e.g., user
      demographics). As the prediction model does not use the
      historical interactions as the input, we can predict the
      affinity scores for users with infrequent or no interaction
      history (given sufficiently informative non-click features).
      For example, a model that learns from the purchasing
      histories of college students to recommend school supplies
      during the beginning of semesters is very effective for an
      electronic commerce platform. The model can correspondingly
      infer that new users who are colleges students may have the
      same needs, even if the platform has no interaction history
      for those users. However, one drawback of the feature-based
      approaches is that they do not take full advantage of the
      interaction history of frequent users. As a result, users
      sharing similar non-click features are considered to be
      similar, regardless of how they actually interact with
      different types of items.</p>
      <p>Motivated by addressing the drawbacks of the above
      approaches, we propose a Gamma-Poisson model that aims to
      utilize the interaction history of frequent users, as well as
      to leverage a feature-based model for infrequent users. Our
      intuition is that we should rely more on interaction (e.g.,
      clicks) histories when estimating affinity for frequent
      users, and more on the feature-based model for infrequent
      users. We conduct experiments on a large scale dataset for a
      click count prediction on publisher content and demonstrate
      the effectiveness of our proposed model.</p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Gamma-Poison
          Model</h2>
        </div>
      </header>
      <p>Estimating user type affinity is to answer how likely a
      user <em>i</em> is going to interact (e.g., click) on an item
      of type <em>j</em>. We denote such tendency as the user type
      affinity score <em>α<sub>ij</sub></em> . We define
      <em>α<sub>ij</sub></em> as:</p>
      <div class="table-responsive" id="eq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{align} \alpha _{ij} =
          f(x_{ij}; w_j) \cdot \ g_{ij} \end{align}</span><br />
          <span class="equation-number">(1)</span>
        </div>
      </div>where <span class="inline-equation"><span class=
      "tex">$x_{ij} \in \mathbb {R}^d$</span></span> is a feature
      vector of dimension <em>d</em>.
      <em>f</em>(<em>x<sub>ij</sub></em> ; <em>w<sub>j</sub></em> )
      is a feature-based prediction model that takes the feature
      vectors <em>x<sub>ij</sub></em> and output affinity scores.
      And <em>w<sub>j</sub></em> are learned parameters. Example
      features for a user could be demographic attributes (e.g.,
      age, gender, and occupation), geo location, and interests.
      Characteristics for the type can also be used as
      non-interaction features, such as the popularity of the type,
      an age range of target etc. <em>g<sub>ij</sub></em> is a
      prior correction factor on the interaction (e.g., clicks)
      histories between user and type pair &lt; <em>i</em>,
      <em>j</em> &gt; .
      <p></p>
      <p>Without loss of generality we assume that (1) one user
      interaction sequence (e.g., clicks of a user to each type)
      within a time period is a Bernoulli process, and (2) the
      interaction sequence (e.g., clicks of all users to each type)
      of all users is also a Bernoulli process. We also assume that
      the correction factor <em>g<sub>ij</sub></em> follows a Gamma
      distribution, i.e., <span class=
      "inline-equation"><span class="tex">$g_{ij} \sim Gamma(\alpha
      =1, \beta =\frac{1}{\gamma })$</span></span> . Based on these
      assumptions, we have the following of our Gamma-Poisson
      model:</p>
      <div class="table-responsive" id="eq2">
        <div class="display-equation">
          <span class="tex mytex">\begin{align} g_{ij} =
          \frac{\gamma + C_{ij}}{ \gamma + E_{ij}} = \frac{\gamma +
          C_{ij}}{ \gamma + \sum _{e\in I_{ij}}f(x_e; w_j)},
          \end{align}</span><br />
          <span class="equation-number">(2)</span>
        </div>
      </div>where <em>C<sub>ij</sub></em> is the number of
      interactions (e.g., clicks), and <em>E<sub>ij</sub></em> is
      the expected number of interactions. The interaction count
      <em>C<sub>ij</sub></em> follows a Poisson distribution
      <em>Poisson</em>(<em>E<sub>ij</sub></em> ). We can use
      <span class="inline-equation"><span class="tex">$\sum _{e\in
      I_{ij}}f(x_e; w_j)$</span></span> to estimate the expected
      number of clicks, where <em>I<sub>ij</sub></em> is the set of
      all impressions of user and type pair &lt; <em>i</em>,
      <em>j</em> &gt; . Under the assumptions, we can prove that
      <em>f</em>(<em>x<sub>ij</sub></em> ; <em>w<sub>j</sub></em> )
      takes the form of logistic regression, and
      <em>w<sub>j</sub></em> is a vector of weights on
      none-interaction features, i.e., <span class=
      "inline-equation"><span class="tex">$f(x_{ij}; w_j) =
      \frac{1}{1 + \exp (-x_{ij}^Tw_j)}$</span></span> . Also note
      that in equation (<a class="eqn" href="#eq2">2</a>)
      <em>γ</em> is a hyper-parameter that sets the initial
      psudo-counts of the personal correction factor
      <em>g<sub>ij</sub></em> .
      <p></p>
      <p>In the case of estimating <em>α<sub>ij</sub></em> for a
      new or infrequent user, both <em>C<sub>ij</sub></em> and
      <em>E<sub>ij</sub></em> are close to 0. Therefore, the
      affinity scores for such users largely depend on the model
      <em>f</em>, i.e. <em>α<sub>ij</sub></em> ≈
      <em>f</em>(<em>x<sub>ij</sub></em> ; <em>w<sub>j</sub></em>
      ). In the case of frequent user, the type affinity scores
      would be compensated as <em>C<sub>ij</sub></em> &gt;
      <em>E<sub>ij</sub></em> = &gt; <em>g<sub>ij</sub></em> &gt; 1
      (penalized as <em>C<sub>ij</sub></em> &lt;
      <em>E<sub>ij</sub></em> = &gt; <em>g<sub>ij</sub></em> &lt;
      1) when the user interact more (less) frequently with the
      type than expected.</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Learning
          Parameters</h2>
        </div>
      </header>
      <p><img src=
      "../../../data/deliveryimages.acm.org/10.1145/3190000/3186918/images/www18companion-158-img1.svg"
      class="img-responsive" alt="" longdesc="" /></p>
      <p>Algorithm&nbsp;1 outlines the iterative inference process
      for learning <em>w<sub>j</sub></em> . At first, the
      correction factors <em>g<sub>ij</sub></em> are initialized to
      1. Step 3 and 4 learn the best <em>w<sub>j</sub></em>
      (coefficient) estimate under the fixed
      <em>g<sub>ij</sub></em> . In this learning process logistic
      loss is used, as <em>f</em> takes the form of logistic
      regression. We are adapting weighting described
      in&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0003">3</a>]
      when solve for <em>w<sub>j</sub></em> . Given the new
      coefficient estimates, our algorithm updates the correction
      factors (as the expected number of clicks depends on the
      underlying feature-based model used) by equation (<a class=
      "eqn" href="#eq2">2</a>). The process iterates until desired
      number of interactions or reached convergence. In this paper,
      the stopping criteria is defined as <span class=
      "inline-equation"><span class="tex">$||(w^t_j -w^{t-1}_j)||_2
      {\lt} 1e^{-10}$</span></span> . In our experiment, the
      process takes less than 10 iterations to converge.</p>
      <p>The labels used in the training data could be the ground
      truth affinity scores estimated for frequent users.
      Alternatively, we could use a click (interaction) prediction
      model as the feature-based affinity model <em>f</em>. In this
      case, the label is a binary variable denoting whether a user
      <em>i</em> interacts (e.g., clicks) with the presented
      content or not, (e.g., predicting whether a user will click
      on one story). The non-interaction features
      (<em>x<sub>ij</sub></em> ) are extracted only from the user
      and the content themselves. In doing so, we do not need to
      explicitly define frequent and infrequent users.</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Experiment</h2>
        </div>
      </header>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">Comparison on click count prediction
          task.</span>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <td style="text-align:center;"></td>
              <td style="text-align:center;">Poisson-Gamma
              (ours)</td>
              <td style="text-align:center;">HTR (3-day)</td>
              <td style="text-align:center;">HTR (1-week)</td>
            </tr>
            <tr>
              <td style="text-align:center;">RMSE</td>
              <td style="text-align:center;">0.429</td>
              <td style="text-align:center;">0.705</td>
              <td style="text-align:center;">0.487</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="table-responsive" id="tab2">
        <div class="table-caption">
          <span class="table-number">Table 2:</span> <span class=
          "table-title">Comparison on click prediction task.</span>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <td style="text-align:center;"></td>
              <td style="text-align:center;">With affinity
              (ours)</td>
              <td style="text-align:center;">No affinity</td>
            </tr>
            <tr>
              <td style="text-align:center;">NDCG@10</td>
              <td style="text-align:center;">0.364</td>
              <td style="text-align:center;">0.325</td>
            </tr>
            <tr>
              <td style="text-align:center;">Accuracy</td>
              <td style="text-align:center;">0.87</td>
              <td style="text-align:center;">0.86</td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>We have conducted experiment on Snapchat story data.
      Snapchat is a large social network that also features a
      Discover page, where stories from numerous publishers and
      channels are shown to users. The Discover page displays the
      cover images and the titles, once clicked the body of the
      content would be shown. We evaluate the effectiveness of the
      affinity scores obtained by our model in two tasks.</p>
      <p>For click counts prediction, we aim at predicting how many
      times a user clicking on stories from a certain publisher
      using the affinity scores. We use <em>α<sub>ij</sub></em>
      |<em>I<sub>ij</sub></em> | as the prediction model (treating
      <em>α<sub>ij</sub></em> as probabilities), where
      |<em>I<sub>ij</sub></em> | is the number of impressions). We
      compare our estimated affinity scores estimated with
      historical tap ratio. The historical tap ratio (HTR) is
      defined as the number of clicks divided by the number of
      impressions within a period of time per publisher. We use
      0.25% of the all users from 7/30/2017 to 08/05/2017 for
      training, and predict the click counts for the same users on
      08/06/2017. We use Root-mean-square error (RMSE) as the
      evaluation metric. For click prediction task, we aim at
      predicting whether a user will click on a story by using
      affinity score as an extra feature. We split the same data
      into 70% training and 30% testing and use xgboost as the
      prediction model. We use NDCG@10 and accuracy as the
      metrics.</p>
      <p>Table&nbsp;<a class="tbl" href="#tab1">1</a> shows the
      result of the click count prediction task for different
      methods. We can clearly see that estimation by the proposed
      Gamma-Poisson model achieves the best result (RMSE of 0.429)
      compared with historical tap ratio (RMSE of 0.705 and 0.487
      where using 3 days’ data and one week's data respectively).
      In addition, using the affinity score can further improve the
      click prediction task as shown in Table&nbsp;<a class="tbl"
      href="#tab2">2</a>.</p>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Conclusion</h2>
        </div>
      </header>
      <p>In this paper, we propose a Gamma-Poisson model for
      accurately estimating the user type affinity scores. We
      conduct experiments on real data from Snapchat to demonstrate
      the effectiveness of our model. We plan to further evaluate
      the estimated scores on various other personalization
      tasks.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Gediminas Adomavicius
        and Alexander Tuzhilin. 2005. Toward the next generation of
        recommender systems: A survey of the state-of-the-art and
        possible extensions. <em><em>IEEE transactions on knowledge
        and data engineering</em></em> 17, 6(2005), 734–749.</li>
        <li id="BibPLXBIB0002" label="[2]">Jonathan&nbsp;L
        Herlocker, Joseph&nbsp;A Konstan, Loren&nbsp;G Terveen, and
        John&nbsp;T Riedl. 2004. Evaluating collaborative filtering
        recommender systems. <em><em>ACM Transactions on
        Information Systems (TOIS)</em></em> 22, 1 (2004),
        5–53.</li>
        <li id="BibPLXBIB0003" label="[3]">Gary King and Langche
        Zeng. 2001. Logistic regression in rare events data.
        <em><em>Political analysis</em></em> 9, 2 (2001),
        137–163.</li>
        <li id="BibPLXBIB0004" label="[4]">Greg Linden, Brent
        Smith, and Jeremy York. 2003. Amazon. com recommendations:
        Item-to-item collaborative filtering. <em><em>IEEE Internet
        computing</em></em> 7, 1 (2003), 76–80.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3186918">https://doi.org/10.1145/3184558.3186918</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
