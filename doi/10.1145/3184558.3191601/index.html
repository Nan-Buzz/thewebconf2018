<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Generating Schema Labels through Dataset Content Analysis</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Generating Schema Labels through Dataset Content Analysis</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Zhiyu</span>      <span class="surName">Chen</span>     Lehigh University, Bethlehem, PA 18015     </div>     <div class="author">     <span class="givenName">Haiyan</span>      <span class="surName">Jia</span>     Lehigh University, Bethlehem, PA 18015     </div>     <div class="author">     <span class="givenName">Jeff</span>      <span class="surName">Heflin</span>     Lehigh University, Bethlehem, PA 18015     </div>     <div class="author">     <span class="givenName">Brian D.</span>      <span class="surName">Davison</span>     Lehigh University, Bethlehem, PA 18015, <a href="mailto:zhc415 | haiyan.jia | jeh3 | davison@lehigh.edu">zhc415 | haiyan.jia | jeh3 | davison@lehigh.edu</a>     </div>        </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3191601" target="_blank">https://doi.org/10.1145/3184558.3191601</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Impoverished descriptions and convoluted schema labels are common challenges in data-centric tasks such as schema matching and data linking, especially when datasets can span domains. To address these issues, we consider the task of schema label generation. Typically, schema labels are created by dataset providers and are useful for users to understand a dataset. The motivation behind the task is that a lot of data linking systems require overlapping information between two datasets and rely on unique identifiers of schema labels. Moreover, it is common for schema labels in different datasets to have different identifiers even when they refer to the same concept. With no naming standard for schema labels, unintelligible labels are widely found in real-world datasets. For example, many schema labels contain abbreviations and compound nouns that hinder automated matching of attributes in corresponding datasets. Through schema label generation, more common (and thus understandable) schema labels can be provided to allow for broader schema matches in contexts such as dataset search and data linking. We develop a variety of features based on analysis of dataset content to enable machine learning methods to recommend useful labels. We test our approach on two real-world data collections and demonstrate that our method is able to outperform the alternative approach.</small>     </p>    </div>    <div class="CCSconcepts">     <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Information integration;</strong> <strong>Specialized information retrieval;</strong></small> </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>data linking; text normalization</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Zhiyu Chen, Haiyan Jia, Jeff Heflin, and Brian D. Davison. 2018. Generating Schema Labels through Dataset Content Analysis. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018 (WWW &#x2019;18 Companion),</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 8 Pages. <a href="https://doi.org/10.1145/3184558.3191601" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3191601</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-2">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>Organizations and individuals worldwide make datasets public and enable users to freely explore such valuable resources. An increasing number of online data sources, such as governmental data portals (e.g., data.gov<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>, data.gov.uk<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a> and data.gov.sg<a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>), and more general facilities like datahub<a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a> (alongside older sites such as the UCI machine learning repository<a class="fn" href="#fn5" id="foot-fn5"><sup>5</sup></a>), suit the diverse needs of data experts, researchers, and journalists. More data also means more challenges. It becomes a non-trivial task to effectively integrate datasets from different resources. In order to help agencies to manage their data, the U.S. government released a policy<a class="fn" href="#fn6" id="foot-fn6"><sup>6</sup></a> to instruct (government) data providers to provide metadata with their datasets. It is a great opportunity for technical communities to bring heterogeneous data together for diverse applications and also a big challenge which may require advanced approaches to manage the datasets. However, many datasets do not adopt metadata standards so that open source data management systems (e.g., CKAN<a class="fn" href="#fn7" id="foot-fn7"><sup>7</sup></a>) are unable to be utilized. Another challenge is that different agencies are likely to have different data formats and standards [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>] resulting difficulties in merging heterogeneous datasets.</p>    <p>Among all types of data, tabular data or the data table is one of the most important. It presents relational data in a compact way and is commonly used in different applications such as knowledge management and web data presentation. A data table usually has a header row, consisting of schema labels (attribute names), followed by data rows storing the actual data values of corresponding attributes. In this paper, we focus on this simple data table format although there are data tables with more complex structures where headers are nested. Tabular data is widely used in different communities because it clearly shows the relationships of different entities and facilitates data analysis. Many tools can easily work on tabular data for analysis and visualization.</p>    <p>Current data linking systems usually rely on the overlapping information in data itself or more commonly, the corresponding metadata fields such as title, tags, description and publisher. However, non-dictionary words (NDWs) commonly appear in data tables and can have a significant impact on data linking. The existence of NDWs in schema labels is also a well-known problem in schema matching systems [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>].</p>    <div class="table-responsive" id="tab1">     <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Sample from a dataset of NYC Farmers Markets.</span>     </div>     <table class="table">     <tbody>      <tr>       <td style="text-align:center;">Farmers Market Name</td>       <td style="text-align:center;">...</td>       <td style="text-align:center;">State</td>       <td style="text-align:center;">Zip Code</td>       <td style="text-align:center;">Latitude</td>       <td style="text-align:left;">Longitude</td>      </tr>      <tr>       <td style="text-align:left;">Carroll Gardens Greenmarket</td>       <td style="text-align:center;">...</td>       <td style="text-align:left;">NY</td>       <td style="text-align:left;">11231</td>       <td style="text-align:left;">41</td>       <td style="text-align:left;">-74</td>      </tr>      <tr>       <td style="text-align:left;">Cortelyou Greenmarket</td>       <td style="text-align:center;">...</td>       <td style="text-align:left;">NY</td>       <td style="text-align:left;">11226</td>       <td style="text-align:left;">41</td>       <td style="text-align:left;">-74</td>      </tr>      <tr>       <td style="text-align:left;">Cypress Hills Youthmarket</td>       <td style="text-align:center;">...</td>       <td style="text-align:left;">NY</td>       <td style="text-align:left;">11208</td>       <td style="text-align:left;">41</td>       <td style="text-align:left;">-74</td>      </tr>      <tr>       <td style="text-align:left;">East New York Farm Stand</td>       <td style="text-align:center;">...</td>       <td style="text-align:left;">NY</td>       <td style="text-align:left;">11207</td>       <td style="text-align:left;">41</td>       <td style="text-align:left;">-74</td>      </tr>      <tr>       <td style="text-align:left;">East New York Farmers&#x2019; Market</td>       <td style="text-align:center;">...</td>       <td style="text-align:left;">NY</td>       <td style="text-align:left;">11207</td>       <td style="text-align:left;">41</td>       <td style="text-align:left;">-74</td>      </tr>      <tr>       <td style="text-align:left;">Fort Greene Park Greenmarket</td>       <td style="text-align:center;">...</td>       <td style="text-align:left;">NY</td>       <td style="text-align:left;">11205</td>       <td style="text-align:left;">41</td>       <td style="text-align:left;">-74</td>      </tr>      <tr>       <td style="text-align:center;">...</td>       <td style="text-align:center;">...</td>       <td style="text-align:center;">...</td>       <td style="text-align:center;">...</td>       <td style="text-align:center;">...</td>       <td style="text-align:center;">...</td>      </tr>      <tr>       <td style="text-align:left;">Graham Avenue Farmers&#x2019; Market</td>       <td style="text-align:center;">...</td>       <td style="text-align:left;">NY</td>       <td style="text-align:left;">11206</td>       <td style="text-align:left;">41</td>       <td style="text-align:left;">-74</td>      </tr>     </tbody>     </table>    </div>    <div class="table-responsive" id="tab2">     <div class="table-caption">     <span class="table-number">Table 2:</span>     <span class="table-title">Sample from an Oceanographic dataset.</span>     </div>     <table class="table">     <tbody>      <tr>       <td style="text-align:center;">cruiseid</td>       <td style="text-align:center;">year</td>       <td style="text-align:center;">si</td>       <td style="text-align:center;">month_gmt</td>       <td style="text-align:center;">day_gmt</td>       <td style="text-align:center;">time_gmt</td>       <td style="text-align:center;">...</td>       <td style="text-align:center;">lat</td>       <td style="text-align:center;">lon</td>      </tr>      <tr>       <td style="text-align:left;">EN319</td>       <td style="text-align:left;">1999</td>       <td style="text-align:left;">T.Durbin</td>       <td style="text-align:left;">2</td>       <td style="text-align:left;">21</td>       <td style="text-align:left;">29.3</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">41.4922</td>       <td style="text-align:left;">-71.4187</td>      </tr>      <tr>       <td style="text-align:left;">EN323</td>       <td style="text-align:left;">1999</td>       <td style="text-align:left;">J.Ledwell</td>       <td style="text-align:left;">5</td>       <td style="text-align:left;">14</td>       <td style="text-align:left;">1146.88</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">41.5234</td>       <td style="text-align:left;">-70.6723</td>      </tr>      <tr>       <td style="text-align:left;">EN330</td>       <td style="text-align:left;">1999</td>       <td style="text-align:left;">C.Greene</td>       <td style="text-align:left;">10</td>       <td style="text-align:left;">23</td>       <td style="text-align:left;">140.4</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">42.5035</td>       <td style="text-align:left;">-66.8025</td>      </tr>      <tr>       <td style="text-align:left;">OC342</td>       <td style="text-align:left;">1999</td>       <td style="text-align:left;">B.Houghton</td>       <td style="text-align:left;">5</td>       <td style="text-align:left;">24</td>       <td style="text-align:left;">19.5</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">41.0683</td>       <td style="text-align:left;">-67.4617</td>      </tr>      <tr>       <td style="text-align:left;">...</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">...</td>      </tr>      <tr>       <td style="text-align:left;">OC343</td>       <td style="text-align:left;">1999</td>       <td style="text-align:left;">D.Hebert</td>       <td style="text-align:left;">6</td>       <td style="text-align:left;">25</td>       <td style="text-align:left;">731.47</td>       <td style="text-align:left;">...</td>       <td style="text-align:left;">40.9997</td>       <td style="text-align:left;">-67.6014</td>      </tr>     </tbody>     </table>    </div>    <p>To address this problem, we propose a supervised method which recommends alternative schema labels. Considering Tables <a class="tbl" href="#tab1">1</a> and <a class="tbl" href="#tab2">2</a> from different domains, though we can easily identify that the column &#x201C;latitude&#x201D; in Table <a class="tbl" href="#tab1">1</a> refers to the same concept as &#x201C;lat&#x201D; in Table <a class="tbl" href="#tab2">2</a>, it is not an easy task for data linking and schema matching systems. If we can recommend the column &#x201C;lat&#x201D; with new schema labels such as &#x201C;latitude&#x201D;, &#x201C;location&#x201D;, it can not only facilitate integrating the column of Table <a class="tbl" href="#tab2">2</a> with other columns, but also help users to better understand the meaning of this column.</p>    <p>We construct a variety of features from column content and enable machine learning models to generate alternative schema labels. To evaluate our method, we test on datasets with different heterogeneity and show that the features are effective for the schema label prediction task. Additionally, we experiment on integer columns, float columns, string columns and show that our method provides consistent performance on those different columns types.</p>    <p>We summarize our contributions as follows:</p>    <ul class="list-no-style">     <li id="list1" label="&#x2022;">We propose a domain-independent method for schema label prediction.<br/></li>     <li id="list2" label="&#x2022;">We run experiments on real world datasets with varying degrees of heterogeneity and demonstrate the effectiveness of our methods on the task of schema label prediction. Our experimental results suggest that the difficulty of the task increases with the heterogeneity of the datasets.<br/></li>     <li id="list3" label="&#x2022;">We evaluate our method on columns of three basic data types (integers, floats, and strings) and demonstrate that our method outperforms the baseline on each of them.<br/></li>    </ul>   </section>   <section id="sec-3">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>     </div>    </header>    <p>Though there is no prior work on the specific task of schema label prediction, work in the area of schema matching and data linking is related to our task and discussed below.</p>    <section id="sec-4">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Schema Matching</h3>     </div>     </header>     <p>In the database community, schema matching is a critical problem for integrating heterogeneous data sources, which aims to find pairwise-attribute correspondence in different schemas. It is similar to our task, except that they do not require that the pair of schema labels are exactly the same.</p>     <p>According to the classification of Rahm and Bernstein [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>], there are two major types of schema matchers: schema-only matchers and instance-based matchers. Schema-only matchers are limited to schema information such as schema name, description and data type. For example, Sorrentino et al.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0025">25</a>] develop a lexical annotation technique to help identify similar schema labels. However, the result of lexical annotation is strongly affected by the presence of non-dictionary words in schema labels such as abbreviations and compound words. For this reason, they expand abbreviations with the help of an online dictionary and enrich WordNet with meanings of compound nouns. The output of their system can be used as the input of another schema matching system and improve the performance of schema matching. Ratinov and Gudes [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0021">21</a>] solve the abbreviation issue by manually designing abbreviation patterns and reduce it to a supervised pattern classification problem. As we can see, the quality of schema labels have a huge impact on schema-only matchers and thus those methods put effort into the analysis of abbreviations and compound nouns in schema labels. Even for well-known schema-only matchers, such as Artemis [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>], Cupid [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>] and COMA [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0006">6</a>], they require a specified external dictionary to measure the similarity of schema labels at some steps. In real world datasets, abbreviation and compound nouns cannot cover all the complex patterns of schema labels. Sometimes the column name of a data table has no real meaning or is even missing. Moreover, available schema information of real world datasets is limited.</p>     <p>Our method is closer to instance-based methods where we give insight into the data content. Since we train a supervised model to use a set of existing schema labels to annotate other schema labels, the results are less sensitive to NDWs. Besides, the similarity between two schema labels relies on the similarity of corresponding content rather than the surface form of the label text.</p>     <p>Automatch [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>] uses machine learning techniques to automate the schema matching process. Their model acquires probabilistic knowledge stored in an attribute dictionary which characterizes different attributes by a set of possible values and their probability estimates. Actually, this method is similar to our baseline method which characterizes a column by its bag-of-Words representation. As mentioned by the authors, there could be endless possible values for a column, especially for those whose data types are continuous variables. Therefore, instead of considering each column value as a feature, we consider each character of each column value as a feature. We also explore other higher level features from column content and better characterize different schema labels.</p>    </section>    <section id="sec-5">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Data Linking</h3>     </div>     </header>     <p>In recent decades, a large number of datasets have been published in different data repositories and it becomes an infeasible task to manually link different datasets. Under this context, data linking has become an important task which aims to automatically interlink datasets and facilitate their reuse.</p>     <p>Nikolov et al.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0018">18</a>] present a keyword-based method with two main steps. In the first step, they use a subset of labels in the dataset as keywords to search for potentially relevant entities in external data sources. In the second step, they filter out irrelevant datasets by measuring semantic similarities used in ontology matching techniques. Leme et al.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>] propose a probabilistic method for Linked Data datasets. For a set of known datasets, they first construct a directed graph from the metadata to describe their connections. Then given a new dataset, they rank those datasets given a rank score function. A similar graph-based method is proposed by Lopes et al.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>] which treats dataset linking as a link prediction problem in social network. Ellefi et al.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>] propose a recommendation approach for data linking. They adopt the notion of dataset profiles, where a dataset is characterized as its textual descriptions and a set of schema labels. Therefore, given a source dataset, a cluster of comparable datasets can be retrieved based on their semantic similarities to a source dataset and each dataset can be ranked by tf-idf cosine similarity. A similar approach is proposed in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>], where a topic-dataset bipartite graph is produced during the topic modeling process; thus a dataset can be represented as a set of topics and a topic can be modeled as a set of significant datasets. Therefore a candidate dataset can be interlinked based on connectivity within the topic-profiles graph. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>], the authors propose a user feedback-based approach to incrementally identify new datasets for domain-specific linked data applications. They first filter datasets according to the application queries and then use user feedback to analyze the relevance of candidate datasets.</p>     <p>As pointed by Nikolov et al.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0017">17</a>], finding the degree of overlap among datasets is critical for data linking. Schema label prediction can be a potential solution to increase the connectivity of heterogeneous datasets by recommending a dataset with schema labels that have appeared in other datasets.</p>    </section>    <section id="sec-6">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.3</span> Semantic Table Interpretation</h3>     </div>     </header>     <p>As embedded data on web pages, Web tables take an important role in applications like knowledge base construction [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>] and question answering [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0019">19</a>]. Therefore, it becomes crucial to recover semantics of Web tables.</p>     <p>There are three main tasks in semantic table interpretation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0033">33</a>]: 1) annotate columns in a table with semantic concepts; 2) identify the semantic relations between columns; and 3) cell disambiguation by linking them to entities in a knowledge base. Among the three tasks, the first task is the closest to our work. TableMiner [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0033">33</a>] uses features from context inside and outside of the table to help annotate columns containing entity mentions. Venetis et al.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>] leverage a database to attach a class label to a column if a sufficient number of the values in the column are identified with the corresponding label in the database. Wang et al.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0030">30</a>] use Probase to annotate a Table with related concepts. Similarly, a large number of works [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>] also make use of knowledge bases to interpret Web Tables.</p>     <p>Different from Web tables, real-world datasets usually have not enough context such as surrounding paragraphs or semantic markups inserted in the Webpage. Moreover, there are few entities that can be linked to a knowledge base since the concepts contained in a dataset are usually too narrow (e.g., street names on a map) or too broad. The method proposed in this paper only uses generic features extracted from the datasets and therefore only annotates columns with labels from the datasets rather than concepts from other resources.</p>    </section>   </section>   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Problem Statement</h2>     </div>    </header>    <p>In this paper, we focus on finding alternative schema labels (column names) based on analysis of the content of the column.</p>    <p>We consider data tables with <em>n</em> columns and <em>m</em> + 1 rows with the following format: <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\[ {\left[\begin{array}{*10c}c_1 &#x0026; c_2 &#x0026; ... &#x0026; c_n \\ v_{1,1} &#x0026; v_{1,2} &#x0026; ... &#x0026; v_{1,n} \\ ...&#x0026; ... &#x0026; ... &#x0026;... \\ v_{m,1} &#x0026; v_{m,2} &#x0026; ... &#x0026; v_{m,n} \\ \end{array}\right]} \] </span>      <br/>     </div>     </div> For convenience, we use the following naming conventions in the rest of the paper:</p>    <ul class="list-no-style">     <li id="list4" label="&#x2022;"><strong>schema label</strong> (or column name): <em>c<sub>j</sub>     </em>, where <em>j</em> &#x2208; [1, ..., <em>n</em>].<br/></li>     <li id="list5" label="&#x2022;"><strong>schema content</strong> (or column content): <em>C<sub>j</sub>     </em> = {<em>v</em>     <sub>1, <em>j</em>     </sub>, ..., <em>v</em>     <sub>      <em>m</em>, <em>j</em>     </sub>}, <em>j</em> &#x2208; [1, ..., <em>n</em>]<br/></li>     <li id="list6" label="&#x2022;"><strong>column</strong>: (<em>c<sub>j</sub>     </em>, <em>C<sub>j</sub>     </em>), <em>j</em> &#x2208; [1, ..., <em>n</em>].<br/></li>    </ul>    <p>Given <em>C<sub>j</sub>     </em> and <em>k</em> target labels <em>L</em> = {<em>l</em>     <sub>1</sub>, <em>l</em>     <sub>2</sub>, ..., <em>l<sub>k</sub>     </em>}, our objective is to learn a function that models <em>P</em>(<em>l</em>|<em>f</em>(<em>C<sub>j</sub>     </em>)), (<em>l</em> &#x2208; <em>L</em>) where <em>f</em> is a function extracting features from <em>C<sub>j</sub>     </em>. The features will be introduced in the following section. A perfect prediction should satisfy: <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\[ c_j = \arg \max _{l\in L} P(l|f(C_j)) \] </span>      <br/>     </div>     </div>    </p>   </section>   <section id="sec-8">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Schema Label Prediction Features</h2>     </div>    </header>    <p>Our approach to predicting schema labels is to leverage features extracted from column content. Past research has indicated that useful features are important for table understanding [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>]. We assume that a schema label and evidence observed from the column content are highly related. One obvious example is that column contents corresponding to different data types are significantly different. Though column data types are not provided directly for the majority of public datasets, machine learning models are able to identify such features automatically [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>].</p>    <p>Our task is much more challenging than just inferring the data type, since the number of data types is small and constant while the number of possible schema labels is uncertain but large. It also means our model should be able to capture the differences among columns with the same data type. As shown in Table <a class="tbl" href="#tab1">1</a>, a column of zip codes usually have data cells consisting of five digits, while a column of latitudes usually have data cells that are real numbers ranging from -90 to 90. If there is a column in the data table without a header and we know all the values in the column are five-digit numbers, the header is more likely to be &#x201C;Zip Code&#x201D; instead of &#x201C;latitude&#x201D;. Therefore, for possible numerical columns, the <em>maximum value</em> and <em>minimal value</em> are important features to characterize them. However, not all columns are numerical columns. Then for non-numerical columns, we instead use the average maximum value and average minimal value of other columns in order to appropriately minimize the impact of these features.</p>    <p>We define <em>content unique ratio</em> and <em>content histogram</em> to describe the distribution of cell values. Content ratio [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>] is usually used as a feature to categorize the class of table where the ratio of cells containing content of a specific type is calculated. Similarly, we use content unique ratio to categorize a column where the proportion of the number of unique cells over the number of all cells is calculated. In Table <a class="tbl" href="#tab1">1</a>, the content unique ratio is 1/102 &#x2248; 0.01 for &#x201C;State&#x201D; if the table has 102 rows and all cell values under this schema label are all &#x201C;NY&#x201D;. In contrast, the content unique ratio is 102/102 = 1 for &#x201C;Farmers Market Name&#x201D; if all cell values under this schema label are different.</p>    <p>A content histogram contains more accurate information about the content distribution than the content unique ratio. To obtain the content histogram, we rank the unique cell values by frequencies (low-frequency first) and generate a vector where the <em>i<sup>th</sup>     </em> dimension is the frequency of the <em>i<sup>th</sup>     </em> ranked cell value. For different column contents, we could obtain the vectors of various lengths. For data.Gov and WikiTables which are two datasets used in our experiment, the medians are 26 and 13 respectively. Therefore, we generate the content histogram by resampling the vector to a 20-dimensional vector using FFT transformations<a class="fn" href="#fn8" id="foot-fn8"><sup>8</sup></a>. We show the content histogram of &#x201C;Farmers Market Name&#x201D; and &#x201C;Zip Code&#x201D; of Table <a class="tbl" href="#tab1">1</a> in Figures 1a and 1b, respectively. The flatter shape of estimated frequencies of &#x201C;Farmers Market Name&#x201D; indicates the content distribution is closer to a uniform distribution than &#x201C;Zip Code&#x201D;. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191601/images/www18companion-340-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Examples of content histograms.</span>     </div>     </figure>    </p>    <p>If we treat each column content as a document, then the schema label prediction can be seen as a document classification task, where classes are possible schema labels. So it is reasonable to incorporate bag-of-words (BoWs) representation as features. For column <em>c</em>, we construct the <em>BoWs features</em> as <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\[ B_c = \lbrace freq(u_1), ..., freq(u_i), ..., freq(u_n)\rbrace , \] </span>      <br/>     </div>     </div> where <em>n</em> is the vocabulary size, <em>u<sub>i</sub>     </em> is the <em>i<sup>th</sup>     </em> word in the vocabulary and <em>freq</em> represents the function calculating the frequency of <em>u<sub>i</sub>     </em> in <em>c</em>. To save memory, we only use character-level unigrams in BoWs (e.g., &#x201C;EN319&#x201D; is decomposed into &#x201C;E&#x201D;,&#x201C;N&#x201D;,&#x201C;3&#x201D;,&#x201C;1&#x201D; and &#x201C;9&#x201D;). In our experiment, we use BoWs features to construct the baseline method. The difference is that instead of considering character-level unigrams, we use TF-IDF representation of tokens extracted from column content.</p>    <p>In a study of table header detection [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>], Fang et al. showed that single row features could differentiate header rows and data rows. Inspired by their work, we extract the following <em>single column features</em> on each column instead of each row: number of characters, percentage of numeric characters, percentage of alphabetic characters, percentage of symbolic characters, percentage of numeric cells, average cell length, maximum cell length and minimum cell length. These features could be considered as an extension of the <em>BoWs features</em> which summarize the statistics of BoWs.</p>    <p>We summarize all the features in Table <a class="tbl" href="#tab3">3</a>.</p>    <div class="table-responsive" id="tab3">     <div class="table-caption">     <span class="table-number">Table 3:</span>     <span class="table-title">A list of curated features for schema label prediction</span>     </div>     <table class="table">     <tbody>      <tr>       <td style="text-align:left;">        <strong>ID</strong>       </td>       <td style="text-align:center;">        <strong>Feature length</strong>       </td>       <td style="text-align:center;">        <strong>Description</strong>       </td>      </tr>      <tr>       <td style="text-align:left;">1</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">maximum value in the column content</td>      </tr>      <tr>       <td style="text-align:left;">2</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">minimum value in the column content</td>      </tr>      <tr>       <td style="text-align:left;">3</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">content unique ratio</td>      </tr>      <tr>       <td style="text-align:left;">4</td>       <td style="text-align:center;">20</td>       <td style="text-align:center;">content histogram</td>      </tr>      <tr>       <td style="text-align:left;">5</td>       <td style="text-align:center;"># of unique unigrams<sup>9</sup>       </td>       <td style="text-align:center;">BoWs (character-level unigram)</td>      </tr>      <tr>       <td style="text-align:left;">6</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">number of characters</td>      </tr>      <tr>       <td style="text-align:left;">7</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">percentage of numeric characters</td>      </tr>      <tr>       <td style="text-align:left;">8</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">percentage of alphabetic characters</td>      </tr>      <tr>       <td style="text-align:left;">9</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">percentage of symbolic characters</td>      </tr>      <tr>       <td style="text-align:left;">10</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">percentage of numeric cells</td>      </tr>      <tr>       <td style="text-align:left;">11</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">average cell length</td>      </tr>      <tr>       <td style="text-align:left;">12</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">maximum cell length</td>      </tr>      <tr>       <td style="text-align:left;">13</td>       <td style="text-align:center;">1</td>       <td style="text-align:center;">minimum cell length</td>      </tr>      <tr>       <td colspan="3" style="text-align:left;">741 for data.Gov and 54982 for WikiTables.<hr/>       </td>      </tr>     </tbody>     </table>    </div>   </section>   <section id="sec-9">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Experimental Evaluation</h2>     </div>    </header>    <p>In this section, we first discuss the datasets used in our experiments. Then we evaluate our method from two perspectives. In exact schema label prediction and normalized schema label prediction, we evaluate performance of the model and demonstrate the usefulness of the aforementioned features.</p>    <section id="sec-10">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.1</span> Datasets</h3>     </div>     </header>     <p>For our first dataset, we collected all available comma-separated value (CSV) files (7485 in good format) from Data.gov which are contributed by more than 50 U.S. government agencies. This dataset covers a variety of topics such as agriculture, climate, economy, and health. Web tables are also tabular tables and have an important role in applications like Web Data search and knowledge base construction. Therefore, we also experiment on WikiTables [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>], which contains 1.6M tables extracted from Wikipedia. <figure id="fig2">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191601/images/www18companion-340-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Rank-sorted frequencies of column labels</span>      </div>     </figure>     </p>     <p>We observe that raw schema labels exhibit properties similar to terms in natural language, in that the rank-sorted frequencies of schema labels produce a curve which approximates the well-known Zipf&#x0027;s law and reflects the heterogeneity of schema labels.</p>    </section>    <section id="sec-11">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.2</span> Exact schema label prediction</h3>     </div>     </header>     <p>We first evaluate our method on the task of exact schema label prediction. Considering a collection of tabular datasets where many schema labels are blank, our goal is to predict the missing schema labels by the corresponding column content. Specifically, we consider two questions: 1) How useful are features extracted from dataset content for schema label prediction? and 2) Does heterogeneity of the dataset collection make the task more difficult?</p>     <p>To answer the first question, we build machine learning models using the features proposed in Section 4, and evaluate the prediction results under different metrics. We treat schema label prediction as a multiclass classification task, where each schema label in the training set represents a class. We calculate macro-averaged and micro-averaged precision, recall and F-score of predictions on the test set. Macro-average is the mean of scores of all the classes, thus giving equal weight to each class. Micro-average, giving equal weight to each prediction decision, is the score obtained by globally counting the total true positives, false negatives and false positives. Larger classes have a larger contribution to the micro-average. In the multiclass classification scenario, the micro-average precision, recall and F-score are the same, thus we only show the Micro F-score in our results. We also report the top-n accuracy which is the fraction of test data for which the correct label is among the top-n labels considered most probable by the model.</p>     <p>The second question can be implicitly answered by comparing the results of the following datasets:</p>     <ul class="list-no-style">     <li id="list7" label="&#x2022;"><strong>Gov_Rand</strong>: 300 datasets are randomly selected from Data.gov.<br/></li>     <li id="list8" label="&#x2022;"><strong>Gov_NY</strong>: 300 datasets are randomly selected from Data.gov published by NYC Open Data<a class="fn" href="#fn9" id="foot-fn9"><sup>10</sup></a>.<br/></li>     <li id="list9" label="&#x2022;"><strong>Wiki_Rand</strong>: We experiment on 554218 tables from WikiTables which have at least 4 columns and 6 rows. Since a lot of tables are in unexpected format, we further filter those columns whose schema labels appear no more than 100 times.<br/></li>     </ul>     <p>The sizes of each dataset and training and testing partitions are found in Table <a class="tbl" href="#tab4">4</a>.</p>     <p>Different data owners usually publish datasets in different domains, with different vocabularies and thus have different pattern of schema label creation. Thus, the difficulty caused by heterogeneity can also be shown by comparing the results on Gov_Rand and Gov_NY. Since there are only 327 datasets published by NYC Open Data, we randomly select 300 datasets for both Gov_Rand and Gov_NY so that the results from the models are more comparable.</p>     <div class="table-responsive" id="tab4">     <div class="table-caption">      <span class="table-number">Table 4:</span>      <span class="table-title">Statistics of extracted columns</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">        <strong>Dataset</strong>        </td>        <td style="text-align:center;">        <strong>#train</strong>        </td>        <td style="text-align:center;">        <strong>#test</strong>        </td>        <td style="text-align:center;">        <strong>#classes</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Gov_Rand</td>        <td style="text-align:center;">3833</td>        <td style="text-align:center;">1644</td>        <td style="text-align:center;">4048</td>       </tr>       <tr>        <td style="text-align:center;">Gov_Rand (freq >1)</td>        <td style="text-align:center;">1415</td>        <td style="text-align:center;">607</td>        <td style="text-align:center;">593</td>       </tr>       <tr>        <td style="text-align:center;">Gov_NY</td>        <td style="text-align:center;">2799</td>        <td style="text-align:center;">1200</td>        <td style="text-align:center;">2494</td>       </tr>       <tr>        <td style="text-align:center;">Gov_NY (freq >1)</td>        <td style="text-align:center;">1391</td>        <td style="text-align:center;">597</td>        <td style="text-align:center;">483</td>       </tr>       <tr>        <td style="text-align:center;">Wiki_Rand</td>        <td style="text-align:center;">806755</td>        <td style="text-align:center;">1882425</td>        <td style="text-align:center;">2234</td>       </tr>      </tbody>     </table>     </div>     <figure id="fig3">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191601/images/www18companion-340-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 3:</span>      <span class="figure-title">Top-n accuracy of exact schema label prediction</span>     </div>     </figure>     <div class="table-responsive" id="tab5">     <div class="table-caption">      <span class="table-number">Table 5:</span>      <span class="table-title">Micro average and Macro-average scores of exact schema label prediction</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">        <strong>Features</strong>        </td>        <td style="text-align:center;">        <strong>Dataset</strong>        </td>        <td style="text-align:center;">        <strong>Micro-F</strong>        </td>        <td style="text-align:center;">        <strong>Macro-P</strong>        </td>        <td style="text-align:center;">        <strong>Macro-R</strong>        </td>        <td style="text-align:center;">        <strong>Macro-F</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Curated</td>        <td style="text-align:center;">Wiki_Rand</td>        <td style="text-align:center;">0.42</td>        <td style="text-align:center;">0.30</td>        <td style="text-align:center;">0.21</td>        <td style="text-align:center;">0.23</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_Rand (freq >1)</td>        <td style="text-align:center;">0.85</td>        <td style="text-align:center;">0.79</td>        <td style="text-align:center;">0.83</td>        <td style="text-align:center;">0.80</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_Rand</td>        <td style="text-align:center;">0.30</td>        <td style="text-align:center;">0.13</td>        <td style="text-align:center;">0.15</td>        <td style="text-align:center;">0.14</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_NY (freq >1)</td>        <td style="text-align:center;">0.86</td>        <td style="text-align:center;">0.79</td>        <td style="text-align:center;">0.83</td>        <td style="text-align:center;">0.80</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_NY</td>        <td style="text-align:center;">0.45</td>        <td style="text-align:center;">0.18</td>        <td style="text-align:center;">0.21</td>        <td style="text-align:center;">0.19</td>       </tr>       <tr>        <td style="text-align:center;">BoWs</td>        <td style="text-align:center;">Wiki_Rand</td>        <td style="text-align:center;">0.34</td>        <td style="text-align:center;">0.34</td>        <td style="text-align:center;">0.16</td>        <td style="text-align:center;">0.19</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_Rand (freq >1)</td>        <td style="text-align:center;">0.35</td>        <td style="text-align:center;">0.23</td>        <td style="text-align:center;">0.27</td>        <td style="text-align:center;">0.23</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_Rand</td>        <td style="text-align:center;">0.11</td>        <td style="text-align:center;">0.05</td>        <td style="text-align:center;">0.06</td>        <td style="text-align:center;">0.05</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_NY (freq >1)</td>        <td style="text-align:center;">0.28</td>        <td style="text-align:center;">0.12</td>        <td style="text-align:center;">0.14</td>        <td style="text-align:center;">0.12</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_NY</td>        <td style="text-align:center;">0.13</td>        <td style="text-align:center;">0.03</td>        <td style="text-align:center;">0.04</td>        <td style="text-align:center;">0.03</td>       </tr>       <tr>        <td style="text-align:center;">Combined (Curated+ BoWs)</td>        <td style="text-align:center;">Wiki_Rand</td>        <td style="text-align:center;">0.43</td>        <td style="text-align:center;">0.30</td>        <td style="text-align:center;">0.22</td>        <td style="text-align:center;">0.24</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_Rand (freq >1)</td>        <td style="text-align:center;">0.86</td>        <td style="text-align:center;">0.84</td>        <td style="text-align:center;">0.83</td>        <td style="text-align:center;">0.82</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_Rand</td>        <td style="text-align:center;">0.37</td>        <td style="text-align:center;">0.24</td>        <td style="text-align:center;">0.25</td>        <td style="text-align:center;">0.24</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_NY (freq >1)</td>        <td style="text-align:center;">0.94</td>        <td style="text-align:center;">0.82</td>        <td style="text-align:center;">0.85</td>        <td style="text-align:center;">0.83</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Gov_NY</td>        <td style="text-align:center;">0.49</td>        <td style="text-align:center;">0.31</td>        <td style="text-align:center;">0.32</td>        <td style="text-align:center;">0.30</td>       </tr>      </tbody>     </table>     </div>     <p>For our experiment, we train random forest classifiers using the curated features introduced in Section <a class="sec" href="#sec-8">4</a>. The default parameters of scikit-learn implementation<a class="fn" href="#fn10" id="foot-fn10"><sup>11</sup></a> are used except that the number of trees in the forest is set up to 25 (to reduce memory requirements). As a <strong>baseline</strong>, we use the same classifier setting training on TF-IDF features extracted from column contents where each cell is tokenized.<a class="fn" href="#fn11" id="foot-fn11"><sup>12</sup></a> It is important to notice that a large number of numeric values appear in the datasets which result in an extremely large vocabulary size. Thus dimension reduction is helpful in order to improve the classification efficiency. Truncated SVD<a class="fn" href="#fn12" id="foot-fn12"><sup>13</sup></a> (a.k.a., LSA) is used to reduce the dimensionality of the TF-IDF representation and BoWs features to 300. We also concatenate the curated features with baseline BoWs features in order to see whether the combination of features could further improve the results. For Gov_Rand and Gov_NY, we split each of them into 70% training set and 30% testing set. Since the number of classes in Gov_Rand and Gov_NY is very large but the dataset size is relatively small, the results could be significantly affected by infrequent schema labels, especially those that only appear once. As a result, many labels in the testing set do not appear in the training set. Therefore, we also experiment on Gov_Rand and Gov_NY after filtering those columns whose schema label only appears once and we call them Gov_Rand(freq >1) and Gov_NY(freq >1) respectively.</p>     <p>Though the prediction must be wrong for the exact matching task, we still report the results of no filtering process and consider the evaluation of &#x201C;wrong&#x201D; predictions in the next section.</p>     <p>Experiment results are reported in Table <a class="tbl" href="#tab5">5</a>. We observe that our curated features approach achieves better results than the baseline on all datasets. For both methods, scores on Gov_NY are higher than scores on Gov_Rand, which suggests the heterogeneity caused by data creators indeed increases the difficulty of the task. After filtering those schema labels that only appear once, the scores of both methods significantly increase, since the cases in which a class in the testing set does not appear in the training set have decreased. However, our method has a more considerable degree of improvement than the baseline and achieves an F-score greater than 0.8 for both the Macro-average and Micro-average. This indicates that our method has decent performance on popular schema labels. When applied to WikiTables, we notice that the gap of performance between our method and baseline is narrower. It is likely that schema label prediction is more like a text classification problem with regard to WikiTables. Compared to datasets on data.Gov, WikiTables have tabular data with smaller size, since tables with thousands of rows can hardly be displayed on a web page. A lot of datasets on data.gov are statistics and it is very likely that the content of single column is occupied by numbers. As content extracted from an encyclopedia, WikiTables have more text description about entities and thus the content of a column is closer to a document.</p>     <p>Figure <a class="fig" href="#fig3">3</a> shows the top-n accuracy results. The performance on datasets from data.gov has no improvement when <em>n</em> is bigger than 3. As we discussed before, many of the labels in the testing set do not appear in the training set, and this sets an upper bound on the accuracy of exact schema label matching. For example, there are 594 columns whose labels only appear in the testing set of Gov_NY, therefore the accuracy can never exceed <span class="inline-equation"><span class="tex">$(1200-594)/1200 = 50.5\%$</span>     </span>. While for Wiki_Rand, the accuracy increases when <em>n</em> increases for both methods.</p>     <p>We calculated the gini importance of curated features of model trained on Gov_NY. For BoWs features and content histogram, we simply sum up the importance scores of all the dimensions. As a result, BoWs features and content histogram make the most contribution. If we consider each dimension as a single feature, then the most important three features are total number of characters, content unique ratio and the first dimension of content histogram.</p>     <p>From the above observations, we know that our method outperforms the baseline in all cases. Moreover, combining our method with baseline features can further improve the performance as expected. Since we only use character-level unigram features in our method and adding word-level TF-IDF features could relief this weakness. The prediction results can be significantly improved by filtering infrequent labels which means our methods can efficiently predict the schema labels especially for those popular ones. We also confirm that the difficulty of the task increases with the heterogeneity of the datasets.</p>    </section>    <section id="sec-12">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.3</span> Normalized schema label prediction</h3>     </div>     </header>     <p>Exact schema label prediction is a pretty strict evaluation, since a true-positive requires the predicted schema label to perfectly match the original label of the tested column content. However, there are thousands of classes and the distribution is imbalanced as shown in Figure <a class="fig" href="#fig2">2</a>. It is possible that a class in the training set may not appear in the testing set. However, a &#x201C;wrong&#x201D; prediction could be potentially useful if it refers to the same concept. For example, consider the target label &#x201C;Nationality&#x201D;: a semantically correct prediction from the model could be &#x201C;Country&#x201D;. Therefore, we should not consider &#x201C;Country&#x201D; as a wrong prediction since they refer to the same concept. More examples are shown in Table <a class="tbl" href="#tab6">6</a>.</p>     <div class="table-responsive" id="tab6">     <div class="table-caption">      <span class="table-number">Table 6:</span>      <span class="table-title">Examples of &#x201C;wrong&#x201D; predictions</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">        <strong>Original labels</strong>        </td>        <td style="text-align:center;">        <strong>Predictions</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Year</td>        <td style="text-align:center;">Season</td>       </tr>       <tr>        <td style="text-align:center;">Opponent</td>        <td style="text-align:center;">Team</td>       </tr>       <tr>        <td style="text-align:center;">Pos</td>        <td style="text-align:center;">Position</td>       </tr>       <tr>        <td style="text-align:center;">Score in the final</td>        <td style="text-align:center;">Score</td>       </tr>      </tbody>     </table>     </div>     <p>In order to relieve the situation, we first do case-folding on schema labels and then rank them by their frequencies in Gov_Rand and Wiki_Rand. From the top 2000 schema labels, we normalize a label by another label in this set which is a synonym of the original label and more human readable. In addition, 89 labels annotated as uninterpretable are removed.</p>     <p>Similar to Section <a class="sec" href="#sec-11">5.2</a>, we train separate models based on different features and datasets. The results of normalized schema label prediction on Gov_Rand and Wiki_Rand are reported in Figure <a class="fig" href="#fig4">4</a> and Table <a class="tbl" href="#tab7">7</a>. As expected, the scores under different metrics significantly increase. Besides, we notice that the top-n accuracy still grows when <em>n</em> is bigger than 3 on Gov_Rand, which is different from exact schema label prediction. It further indicates that our model can capture the relation between a schema label and its content. <figure id="fig4">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191601/images/www18companion-340-fig4.jpg" class="img-responsive" alt="Figure 4"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 4:</span>       <span class="figure-title">Top-n Accuracy of normalized schema label prediction</span>      </div>     </figure>     </p>     <div class="table-responsive" id="tab7">     <div class="table-caption">      <span class="table-number">Table 7:</span>      <span class="table-title">Micro average and Macro-average scores of normalized schema label prediction</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">        <strong>Features</strong>        </td>        <td style="text-align:center;">        <strong>Dataset</strong>        </td>        <td style="text-align:center;">        <strong>MicroF</strong>        </td>        <td style="text-align:center;">        <strong>MacroP</strong>        </td>        <td style="text-align:center;">        <strong>MacroR</strong>        </td>        <td style="text-align:center;">        <strong>MacroF</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">curated</td>        <td style="text-align:center;">Gov_Rand</td>        <td style="text-align:center;">0.36</td>        <td style="text-align:center;">0.21</td>        <td style="text-align:center;">0.22</td>        <td style="text-align:center;">0.20</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Wiki_Rand</td>        <td style="text-align:center;">0.62</td>        <td style="text-align:center;">0.33</td>        <td style="text-align:center;">0.29</td>        <td style="text-align:center;">0.30</td>       </tr>       <tr>        <td style="text-align:center;">BoWs</td>        <td style="text-align:center;">Gov_Rand</td>        <td style="text-align:center;">0.25</td>        <td style="text-align:center;">0.16</td>        <td style="text-align:center;">0.17</td>        <td style="text-align:center;">0.15</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Wiki_Rand</td>        <td style="text-align:center;">0.55</td>        <td style="text-align:center;">0.29</td>        <td style="text-align:center;">0.20</td>        <td style="text-align:center;">0.23</td>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec-13">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.4</span> Evaluation on different data types</h3>     </div>     </header>     <p>In this section, we evaluate schema label prediction methods on columns with different data types. We use pandas<a class="fn" href="#fn13" id="foot-fn13"><sup>14</sup></a> to automatically infer the data type of a column and only keep those columns whose data types can successfully be identified by the IO tool. 1000 columns are randomly selected for integer type, float type and string type respectively. For each type of column, we train a model on 70% of data and evaluate on the rest of data. The experiment results for our method and baseline are reported in Table <a class="tbl" href="#tab8">8</a>. As expected, our method outperforms the baseline on all the three types of columns. It is also interesting to notice that both methods perform the best on float columns while perform the worst on string columns. There could be two reasons. First,string columns have more unique labels than float columns and integer columns, which means predicting schema labels of string columns is inherently a more difficult task.Second, some of the features are based on the numeric values in the column content, while for string columns, such features are treated as missing values and calculated from average values from other columns. Such features could be useless for string columns and damage the performance of the model. This fact indicates that designing different features for different data types could further improve the performance of schema label prediction.</p>     <div class="table-responsive" id="tab8">     <div class="table-caption">      <span class="table-number">Table 8:</span>      <span class="table-title">Micro average and Macro-average scores on different data types</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">        <strong>Features</strong>        </td>        <td style="text-align:center;">        <strong>Data type</strong>        </td>        <td style="text-align:center;">        <strong>MicroF</strong>        </td>        <td style="text-align:center;">        <strong>MacroP</strong>        </td>        <td style="text-align:center;">        <strong>MacroR</strong>        </td>        <td style="text-align:center;">        <strong>MacroF</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">curated</td>        <td style="text-align:center;">integer</td>        <td style="text-align:center;">0.31</td>        <td style="text-align:center;">0.11</td>        <td style="text-align:center;">0.12</td>        <td style="text-align:center;">0.11</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">float</td>        <td style="text-align:center;">0.37</td>        <td style="text-align:center;">0.10</td>        <td style="text-align:center;">0.11</td>        <td style="text-align:center;">0.10</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">string</td>        <td style="text-align:center;">0.23</td>        <td style="text-align:center;">0.11</td>        <td style="text-align:center;">0.12</td>        <td style="text-align:center;">0.10</td>       </tr>       <tr>        <td style="text-align:center;">BoWs</td>        <td style="text-align:center;">integer</td>        <td style="text-align:center;">0.25</td>        <td style="text-align:center;">0.10</td>        <td style="text-align:center;">0.11</td>        <td style="text-align:center;">0.10</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">float</td>        <td style="text-align:center;">0.32</td>        <td style="text-align:center;">0.07</td>        <td style="text-align:center;">0.09</td>        <td style="text-align:center;">0.07</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">string</td>        <td style="text-align:center;">0.20</td>        <td style="text-align:center;">0.08</td>        <td style="text-align:center;">0.09</td>        <td style="text-align:center;">0.08</td>       </tr>      </tbody>     </table>     </div>    </section>   </section>   <section id="sec-14">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Conclusion and future work</h2>     </div>    </header>    <p>We have considered the problem of schema label prediction based on the content of a column. We treat it as a multi-class classification task, in which each class represents a schema label. A variety of features are developed to solve the problem. Our method has been evaluated on two real-world datasets: tabular data collected from data.gov and WikiTables extracted from Wikipedia. We first evaluate the approach on exact schema label prediction, which requires the predicted label to exactly match the original schema label. In this task, our method clearly outperforms the baseline on all datasets. We find that heterogeneity of the datasets likely makes the task more difficult.</p>    <p>Since the distribution of schema labels is quite imbalanced, many labels used in testing do not appear in the training set, which makes it inherently difficult to perform well. Therefore, we also experiment on top-ranked normalized schema labels. We select the most frequent 2000 schema labels across both datasets and merge labels that are synonyms. As expected, the scores under different metrics significantly increase compared with the results of exact schema label prediction. Additionally, we demonstrate that our method outperforms the baseline on columns of different data types. We notice that both methods perform the best on float columns while the worst on string columns, since some proposed features could be useless for string columns. It reminds us that using different features for different data types are necessary for schema label prediction. We will leave data type inference and schema label prediction for columns of different data types as future work.</p>    <p>One limitation of our current method is that we only consider the features from a single column, without considering its relationship with other columns co-occurring in the data table. Intuitively, if two columns are similar, then our method may give them the same schema label. However, it is unlikely for two identical columns to appear in the same data table. By considering the occurrence of other schema labels, such cases could be disambiguated.</p>    <p>One application of our method is to facilitate dataset retrieval. An existing challenge of dataset retrieval is that user queries seldom contain terms that are broadly used in schema labels, which results in low recall of related datasets. In our experiment, we find that our method often gives a prediction that are synonyms of original schema label or share the hypernym with the original schema label. Usually, the composition of NDWs schema labels is irregular and complicated but their synonyms or hyponyms could be searched by users. For example, for a column whose schema label is &#x201C;Pos&#x201D;, our method could predict the schema label as &#x201C;Position&#x201D;. However, &#x201C;Position&#x201D; is a term more preferred by users and more valuable to be indexed. We expect that using the predicted labels as possible term expansions (either for queries or at indexing time), the dataset retrieval system can have improved recall.</p>   </section>   <section id="sec-15">    <header>     <div class="title-info">     <h2>Acknowledgments</h2>     </div>    </header>    <p>This material is based upon work supported by a Lehigh University internal Collaborative Research Opportunity grant.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Mohamed Ben&#x00A0;Ellefi, Zohra Bellahsene, Stefan Dietze, and Konstantin Todorov. 2016. Dataset Recommendation for Data Linking: An Intensional Approach. In <em>      <em>The Semantic Web. Latest Advances and New Domains</em>     </em>. Springer, 36&#x2013;51.</li>     <li id="BibPLXBIB0002" label="[2]">Jacob Berlin and Amihai Motro. 2002. Database Schema Matching Using Machine Learning with Feature Selection. In <em>      <em>Advanced Information Systems Engineering</em>     </em>. Springer, 452&#x2013;466.</li>     <li id="BibPLXBIB0003" label="[3]">Chandra&#x00A0;Sekhar Bhagavatula, Thanapon Noraset, and Doug Downey. 2015. TabEL: Entity Linking in Web Tables. In <em>      <em>The Semantic Web - ISWC 2015</em>     </em>. Springer, 425&#x2013;441.</li>     <li id="BibPLXBIB0004" label="[4]">Silvana Castano and Valeria De&#x00A0;Antonellis. 2001. Global viewing of heterogeneous data sources. <em>      <em>IEEE Trans. on Knowledge and Data Eng.</em>     </em>13, 2 (2001), 277&#x2013;297.</li>     <li id="BibPLXBIB0005" label="[5]">H&#x00E9;lio&#x00A0;Rodrigues de Oliveira, Alberto&#x00A0;Trindade Tavares, and Bernadette&#x00A0;Farias L&#x00F3;scio. 2012. Feedback-based Data Set Recommendation for Building Linked Data Applications. In <em>      <em>Proc. 8th Int&#x0027;l Conf. on Semantic Systems</em>     </em>(<em>I-SEMANTICS &#x2019;12</em>). ACM, 49&#x2013;55.</li>     <li id="BibPLXBIB0006" label="[6]">Hong-Hai Do and Erhard Rahm. 2002. COMA-a system for flexible combination of schema matching approaches. In <em>      <em>Proc. 28th Int&#x0027;l Conf. on Very Large Databases</em>     </em>. Elsevier, 610&#x2013;621.</li>     <li id="BibPLXBIB0007" label="[7]">Julian Eberius, Katrin Braunschweig, Markus Hentsch, Maik Thiele, Ahmad Ahmadov, and Wolfgang Lehner. 2015. Building the resden web table corpus: A classification approach. In <em>      <em>IEEE/ACM 2nd Int&#x0027;l Symp. on Big Data Computing (BDC)</em>     </em>. 41&#x2013;50.</li>     <li id="BibPLXBIB0008" label="[8]">Mohamed&#x00A0;Ben Ellefi, Zohra Bellahsene, Stefan Dietze, and Konstantin Todorov. 2016. Beyond established knowledge graphs-recommending web datasets for data linking. In <em>      <em>Int&#x0027;l Conf. on Web Engineering</em>     </em>. Springer, 262&#x2013;279.</li>     <li id="BibPLXBIB0009" label="[9]">Jing Fang, Prasenjit Mitra, Zhi Tang, and C.&#x00A0;Lee Giles. 2012. Table Header Detection and Classification. In <em>      <em>Proc. 26th AAAI Conf. on Artificial Intelligence</em>     </em>(<em>AAAI&#x2019;12</em>). AAAI Press, 599&#x2013;605.</li>     <li id="BibPLXBIB0010" label="[10]">Matthew Hurst. 2001. Layout and Language: Challenges for Table Understanding on the Web. In <em>      <em>Proc. Int&#x0027;l Workshop on Web Document Analysis</em>     </em>. 27&#x2013;30.</li>     <li id="BibPLXBIB0011" label="[11]">Luiz Andr&#x00E9; P&#x00A0;Paes Leme, Giseli&#x00A0;Rabello Lopes, Bernardo&#x00A0;Pereira Nunes, Marco&#x00A0;Antonio Casanova, and Stefan Dietze. 2013. Identifying candidate datasets for data interlinking. In <em>      <em>Int&#x0027;l Conf. on Web Engineering</em>     </em>. Springer, 354&#x2013;366.</li>     <li id="BibPLXBIB0012" label="[12]">Jimmy Lin and Boris Katz. 2003. Question Answering from the Web Using Knowledge Annotation and Knowledge Mining Techniques. In <em>      <em>Proc. 12th Int&#x0027;l Conf. on Information and Knowledge Management</em>     </em>(<em>CIKM &#x2019;03</em>). ACM, 116&#x2013;123. <a class="link-inline force-break" href="https://doi.org/10.1145/956863.956886"      target="_blank">https://doi.org/10.1145/956863.956886</a></li>     <li id="BibPLXBIB0013" label="[13]">Giseli&#x00A0;Rabello Lopes, Luiz Andr&#x00E9; P&#x00A0;Paes Leme, Bernardo&#x00A0;Pereira Nunes, and Marco&#x00A0;A Casanova. 2014. RecLAK: Analysis and Recommendation of Interlinking Datasets.. In <em>      <em>LAK Workshops</em>     </em>.</li>     <li id="BibPLXBIB0014" label="[14]">Jayant Madhavan, Philip&#x00A0;A. Bernstein, and Erhard Rahm. 2001. Generic Schema Matching with Cupid. In <em>      <em>Proc. 27th Int&#x0027;l Conf. on Very Large Data Bases</em>     </em>(<em>VLDB &#x2019;01</em>). Morgan Kaufmann, 49&#x2013;58.</li>     <li id="BibPLXBIB0015" label="[15]">Varish Mulwad, Tim Finin, and Anupam Joshi. 2013. Semantic Message Passing for Generating Linked Data from Tables. In <em>      <em>The Semantic Web &#x2013; ISWC 2013</em>     </em>. Springer, 363&#x2013;378.</li>     <li id="BibPLXBIB0016" label="[16]">Varish Mulwad, Tim Finin, Zareen Syed, and Anupam Joshi. 2010. T2LD: Interpreting and Representing Tables as Linked Data. In <em>      <em>9th Int&#x0027;l Semantic Web Conf. (ISWC)</em>     </em>. 25.</li>     <li id="BibPLXBIB0017" label="[17]">Andriy Nikolov and Mathieu d&#x0027;Aquin. 2011. Identifying relevant sources for data linking using a semantic web index. In <em>      <em>WWW2011 Workshop: Linked Data on the Web (LDOW 2011)</em>     </em>.</li>     <li id="BibPLXBIB0018" label="[18]">Andriy Nikolov, Mathieu d&#x0027;Aquin, and Enrico Motta. 2012. What Should I Link to? Identifying Relevant Sources and Classes for Data Linking. In <em>      <em>The Semantic Web</em>     </em>. Springer, 284&#x2013;299.</li>     <li id="BibPLXBIB0019" label="[19]">Rakesh Pimplikar and Sunita Sarawagi. 2012. Answering Table Queries on the Web Using Column Keywords. <em>      <em>Proc. VLDB Endow.</em>     </em>5, 10 (June 2012), 908&#x2013;919.</li>     <li id="BibPLXBIB0020" label="[20]">Erhard Rahm and Philip&#x00A0;A. Bernstein. 2001. A survey of approaches to automatic schema matching. <em>      <em>The VLDB Journal</em>     </em>10, 4 (01 Dec 2001), 334&#x2013;350.</li>     <li id="BibPLXBIB0021" label="[21]">L Ratinov and Ehud Gudes. 2004. Abbreviation expansion in schema matching and web integration. In <em>      <em>Proc. IEEE/WIC/ACM Int&#x0027;l Conf. on Web Intelligence</em>     </em>. 485&#x2013;489.</li>     <li id="BibPLXBIB0022" label="[22]">Dominique Ritze, Oliver Lehmberg, Yaser Oulabi, and Christian Bizer. 2016. Profiling the Potential of Web Tables for Augmenting Cross-domain Knowledge Bases. In <em>      <em>Proc. 25th Int&#x0027;l Conf. on World Wide Web</em>     </em>(<em>WWW &#x2019;16</em>). 251&#x2013;261. <a class="link-inline force-break" href="https://doi.org/10.1145/2872427.2883017"      target="_blank">https://doi.org/10.1145/2872427.2883017</a></li>     <li id="BibPLXBIB0023" label="[23]">Yoones&#x00A0;A Sekhavat, Francesco Di&#x00A0;Paolo, Denilson Barbosa, and Paolo Merialdo. 2014. Knowledge Base Augmentation using Tabular Data.. In <em>      <em>LDOW</em>     </em>.</li>     <li id="BibPLXBIB0024" label="[24]">Serena Sorrentino, Sonia Bergamaschi, and Maciej Gawinecki. 2011. NORMS: an automatic tool to perform schema label normalization. In <em>      <em>Data Engineering (ICDE), 2011 IEEE 27th International Conference on</em>     </em>. IEEE, 1344&#x2013;1347.</li>     <li id="BibPLXBIB0025" label="[25]">Serena Sorrentino, Sonia Bergamaschi, Maciej Gawinecki, and Laura Po. 2009. Schema Normalization for Improving Schema Matching. In <em>      <em>Conceptual Modeling - ER 2009</em>     </em>. Springer, 280&#x2013;293.</li>     <li id="BibPLXBIB0026" label="[26]">Zareen Syed, Tim Finin, Varish Mulwad, and Anupam Joshi. 2010. Exploiting a web of semantic data for interpreting tables. In <em>      <em>Proc. 2nd Web Science Conf.</em>     </em>, Vol.&#x00A0;5.</li>     <li id="BibPLXBIB0027" label="[27]">Barbara Ubaldi. 2013. Open government data: Towards empirical analysis of open government data initiatives. <em>      <em>OECD Working Papers on Public Governance</em>     </em>22 (2013), 0_1.</li>     <li id="BibPLXBIB0028" label="[28]">Isabel Valera and Zoubin Ghahramani. 2017. Automatic Discovery of the Statistical Types of Variables in a Dataset. In <em>      <em>Proc. 34th Int&#x0027;l Conf. on Machine Learning</em>     </em>(<em>Proceedings of Machine Learning Research</em>), Vol.&#x00A0;70. PMLR, 3521&#x2013;3529.</li>     <li id="BibPLXBIB0029" label="[29]">Petros Venetis, Alon Halevy, Jayant Madhavan, Marius Pa&#x015F;ca, Warren Shen, Fei Wu, Gengxin Miao, and Chung Wu. 2011. Recovering Semantics of Tables on the Web. <em>      <em>Proc. VLDB Endow.</em>     </em>4, 9 (June 2011), 528&#x2013;538.</li>     <li id="BibPLXBIB0030" label="[30]">Jingjing Wang, Haixun Wang, Zhongyuan Wang, and Kenny&#x00A0;Q. Zhu. 2012. Understanding Tables on the Web. In <em>      <em>Conceptual Modeling</em>     </em>. Springer, 141&#x2013;155.</li>     <li id="BibPLXBIB0031" label="[31]">Yalin Wang and Jianying Hu. 2002. A Machine Learning Based Approach for Table Detection on the Web. In <em>      <em>Proc. 11th Int&#x0027;l Conf. on World Wide Web</em>     </em>(<em>WWW &#x2019;02</em>). ACM, 242&#x2013;250.</li>     <li id="BibPLXBIB0032" label="[32]">Xiaolu Zhang, Yueguo Chen, Jinchuan Chen, Xiaoyong Du, and Lei Zou. 2013. Mapping Entity-Attribute Web Tables to Web-Scale Knowledge Bases. In <em>      <em>Database Systems for Advanced Applications</em>     </em>. Springer, 108&#x2013;122.</li>     <li id="BibPLXBIB0033" label="[33]">Ziqi Zhang. 2014. Towards efficient and effective semantic table interpretation. In <em>      <em>International Semantic Web Conference</em>     </em>. Springer, 487&#x2013;502.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class="link-inline force-break" href="https://www.data.gov/">https://www.data.gov/</a>   </p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break" href="https://data.gov.uk/">https://data.gov.uk/</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a><a class="link-inline force-break" href="https://data.gov.sg/">https://data.gov.sg/</a>   </p>   <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a><a class="link-inline force-break" href="http://datahub.io/">http://datahub.io/</a>   </p>   <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a><a class="link-inline force-break" href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>   </p>   <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a><a class="link-inline force-break"     href="https://project-open-data.cio.gov/policy-memo/">https://project-open-data.cio.gov/policy-memo/</a>   </p>   <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a><a class="link-inline force-break" href="https://ckan.org">https://ckan.org</a>   </p>   <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a>We use the method from <a class="link-inline force-break"     href="https://docs.scipy.org/doc/scipy-0.17.0/reference/generated/scipy.signal.resample.html">https://docs.scipy.org/doc/scipy-0.17.0/reference/generated/scipy.signal.resample.html</a>   </p>   <p id="fn9"><a href="#foot-fn9"><sup>10</sup></a><a class="link-inline force-break" href="https://opendata.cityofnewyork.us/">https://opendata.cityofnewyork.us/</a>   </p>   <p id="fn10"><a href="#foot-fn10"><sup>11</sup></a><a class="link-inline force-break"     href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</a>   </p>   <p id="fn11"><a href="#foot-fn11"><sup>12</sup></a><a class="link-inline force-break"     href="http://www.nltk.org/_modules/nltk/tokenize/toktok.html">http://www.nltk.org/_modules/nltk/tokenize/toktok.html</a>   </p>   <p id="fn12"><a href="#foot-fn12"><sup>13</sup></a><a class="link-inline force-break"     href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html">http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html</a>   </p>   <p id="fn13"><a href="#foot-fn13"><sup>14</sup></a><a class="link-inline force-break" href="https://pandas.pydata.org/">https://pandas.pydata.org/</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3191601">https://doi.org/10.1145/3184558.3191601</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
