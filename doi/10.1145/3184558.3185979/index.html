<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>A Better Facet of Dynamic Information Flow Control</title><!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
  <link rel="cite-as" href="https://doi.org/10.1145/3184558.3185979"/>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3185979'>https://doi.org/10.1145/3184558.3185979</a>.
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3185979'>https://w3id.org/oa/10.1145/3184558.3185979</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">A Better Facet of Dynamic Information Flow Control</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Minh</span> <span class="surName">Ngo</span>, INRIA, France, <a href="mailto:nguyen-nhat-minh.ngo@inria.fr">nguyen-nhat-minh.ngo@inria.fr</a>
        </div>
        <div class="author">
          <span class="givenName">Nataliia</span> <span class="surName">Bielova</span>, INRIA, France, <a href="mailto:nataliia.bielova@inria.fr">nataliia.bielova@inria.fr</a>
        </div>
        <div class="author">
          <span class="givenName">Cormac</span> <span class="surName">Flanagan</span>, UCSC, USA, <a href="mailto:cormac@ucsc.edu">cormac@ucsc.edu</a>
        </div>
        <div class="author">
          <span class="givenName">Tamara</span> <span class="surName">Rezk</span>, INRIA, France, <a href="mailto:tamara.rezk@inria.fr">tamara.rezk@inria.fr</a>
        </div>
        <div class="author">
          <span class="givenName">Alejandro</span> <span class="surName">Russo</span>, Chalmers University of Technology, Sweden, <a href="mailto:russo@chalmers.se">russo@chalmers.se</a>
        </div>
        <div class="author">
          <span class="givenName">Thomas</span> <span class="surName">Schmitz</span>, UCSC, USA, <a href="mailto:tschmitz@ucsc.edu">tschmitz@ucsc.edu</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3185979" target="_blank">https://doi.org/10.1145/3184558.3185979</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Multiple Facets (MF) is a dynamic enforcement mechanism which has proved to be a good fit for implementing information flow security for JavaScript. It relies on multi executing the program, once per each security level or view, to achieve soundness. By looking inside programs, MF encodes the views to reduce the number of needed multi-executions.</small></p>
        <p><small>In this work, we extend Multiple Facets in three directions. First, we propose a new version of MF for arbitrary lattices, called Generalised Multiple Facets, or GMF. GMF strictly generalizes MF, which was originally proposed for a specific lattice of principals. Second, we propose a new optimization on top of GMF that further reduces the number of executions. Third, we strengthen the security guarantees provided by Multiple Facets by proposing a termination sensitive version that eliminates covert channels due to termination.</small></p>
      </div>
      <div class="classifications">
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference Format:</span><br />
          Minh Ngo, Nataliia Bielova, Cormac Flanagan, Tamara Rezk, Alejandro Russo, and Thomas Schmitz. 2018. A Better Facet of Dynamic Information Flow Control. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon, France.</em> ACM, New York, NY, USA, 9 Pages. <a href="https://doi.org/10.1145/3184558.3185979" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3184558.3185979</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span> Introduction</h2>
        </div>
      </header>
      <p>JavaScript has become the de facto programming language of the Web. Web browsers daily execute thousands of JavaScript lines which usually have access to confidential information, for example cookies that mark that the user in a web session is authenticated. It is not surprising that JavaScript is a common target for attacks. While browsers deploy security measures in the form of access control (e.g., SOP and CSP), they are insufficient [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0030">30</a>] to protect confidentiality of data.</p>
      <p>Information flow control (IFC) is a promising technology which provides a systematic solution to handle unintentional or malicious leaks of confidential information. Recently, dynamic IFC analyses have received a lot of attention&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0033">33</a>], due, in part, to its applicability to JavaScript—where static analyses are rather an awkward fit&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0029">29</a>].</p>
      <p>In order to scale, a suitable IFC technique for the web not only needs to be dynamic but also needs to reduce to the minimum the modifications required to existing JavaScript code. In this light, an interesting dynamic IFC technique which fulfills both of these requirements consists in executing several copies of a program: one execution per each security level or view. In that manner, each copy of the program (view) depends only on information observable to the corresponding security level, where no leaks are therefore possible. Secure Multi Execution (SME)&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>] and Multiple Facets (MF)&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>] are two techniques based on this idea.</p>
      <p>Both techniques have been proved to be a good fit for information flow security in the web since they have been successfully implemented as extensions of the Firefox browser&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0033">33</a>].</p>
      <p>Although both SME and MF are based on multi-executions, they present important differences [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>]. On one hand, SME is blackbox&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0024">24</a>], i.e., it is a mechanism that does not <em>look inside</em> programs but rather change the semantics of inputs and outputs to ensure security. For a moment, we assume a scenario where security levels are simply sets of principals (e.g., web origins) which denote those authorities with confidentiality concerns over data. In such a scenario, SME needs to spawn one execution for any possible set of principals—where the number of executions grows exponentially with respect to the number of principals! Instead, MF&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>] is designed to reduce the number of multi-executions and the memory footprint of SME. It does so by inspecting programs code and multi-executing instructions and multiplexing memory only when needed. While MF is more resource-friendly than SME, SME provides stronger security guarantees when it comes to leaks via abnormal termination [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>].</p>
      <p>Our broad goal is to augment the efficiency of techniques based on MF and SME to general cases. In particular, we discovered that MF might sometimes spawn more multi-executions than SME—something that is counter-intuitive when considering the purpose of MF (see Section <a class="sec" href="#sec-8">2</a>). Our first contribution consists on a novel technique to further reduce the number of multi-executions (and memory footprint) of MF. Our second contribution is to generalize MF to work for <em>arbitrary finite lattices</em> (see Section&nbsp;<a class="sec" href="#sec-9">3</a>) rather than being restricted to the security lattice of principals as in the original proposal&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>]. This becomes useful when, for instance, a program depends on 5 security levels. In such case, as stated originally, MF will need to encode them by using (at least) 3 principals (2<sup>3</sup> &gt; 5), and thus execute the program 2<sup>3</sup> = 8 times, while SME will execute it only 5 times (one per security level). Finally, we combine MF and SME into a single new dynamic IFC mechanism in order to provide security guarantees as strong as SME (i.e., termination sensitive non-interference) while avoiding multi-executions as much as our optimized version of MF allows it. All proofs can be found in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>].</p>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Background on SME and MF</h2>
        </div>
      </header>
      <p>In this section, we discuss how on one hand, the underpinning mechanism in MF reduces the number of executions compared to SME, and on the other hand, may run more multi executions than SME because of the security lattice based on principals. Our goal here is partly pedagogical and partly to motivate and provide intuition on the optimization proposed in Section&nbsp;<a class="sec" href="#sec-13">4</a>.</p>
      <p><strong>Language and Semantics</strong> To investigate the foundation of multiple facets, we use a simple, deterministic while language. Its syntax includes programs <em>P</em>, variables <em>x</em>, expressions <em>e</em>, and values <em>v</em>. We use the symbol ⊕ for binary expression operators. A value is either an integer value or a boolean value.</p>
      <p></p>
      <div class="table-responsive"><img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-display1.jpg" class="img-responsive" alt="" /></div>
      <p></p>
      <p>Figure&nbsp;<a class="fig" href="#fig1">1</a> presents standard big-step semantics of the language. Memories <em>μ</em> map variables to values; we overload the notation of memory and use <em>μ</em>(<em>e</em>) as the evaluation function for expression <em>e</em> in memory <em>μ</em>, where <em>μ</em>(<em>v</em>) = <em>v</em> and <em>μ</em>(<em>e</em> <sub>1</sub>⊕<em>e</em> <sub>2</sub>) = <em>μ</em>(<em>e</em> <sub>1</sub>)⊕<em>μ</em>(<em>e</em> <sub>2</sub>). We write (<em>P</em>, <em>μ</em>)⇓<em>μ</em>′ to mean that the evaluation of program <em>P</em> on memory <em>μ</em> terminates with memory <em>μ</em>′. We use <em>μ</em>[<em>x</em>↦<em>v</em>] for the memory <em>μ</em>′ where <em>μ</em>′(<em>y</em>) = <em>μ</em>(<em>y</em>) if <em>y</em> ≠ <em>x</em>, and <em>μ</em>′(<em>y</em>) = <em>v</em> if <em>y</em> = <em>x</em>.</p>
      <figure id="fig1">
        <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-fig1.svg" class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class="figure-title">Language semantics.</span>
        </div>
      </figure>
      <p></p>
      <p><strong>MF may use fewer resources than SME</strong> SME&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>] multi executes programs, in a blackbox manner, as many times as security levels in a lattice. Let's define an SME memory as a function that maps each variable to an array of values, one value per security level. For the sake of simplicity, let's consider first a security lattice with only two elements <em>H</em> and <em>L</em> where <span class="inline-equation"><span class="tex">$H \not\sqsubseteq L$</span></span> is the only disallowed flow. Thus, an SME memory <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> maps variables to an array of 2 (possibly different) values: one corresponding to the <em>H</em> view and one corresponding to the <em>L</em> view. Let's denote such array of values as ⟨<em>v</em> <sub>1</sub>: <em>v</em> <sub>2</sub>⟩, where <em>v</em> <sub>1</sub> is a private, <em>H</em>, view and <em>v</em> <sub>2</sub> is a public, <em>L</em>, view. Assume that <span class="inline-equation"><span class="tex">$H(\hat{\mu })$</span></span> (resp. <span class="inline-equation"><span class="tex">$L(\hat{\mu })$</span></span> ) is a memory in the standard semantics, obtained by projection of <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> , mapping variables to single values of the high view (resp. low view). Then, the SME monitoring rule<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> for such a language can be given by the relation ⇓ <sub><em>SME</em> − <em>TINI</em></sub> as follows:</p>
      <p></p>
      <div class="table-responsive"><img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-display2.jpg" class="img-responsive" alt="" /></div>
      <p></p>
      <p>where ⊙ combines two normal memories into a SME memory in such a way that <em>H</em>(<em>μ</em> <sub>1</sub>⊙<em>μ</em> <sub>2</sub>) = <em>μ</em> <sub>1</sub> and <em>L</em>(<em>μ</em> <sub>1</sub>⊙<em>μ</em> <sub>2</sub>) = <em>μ</em> <sub>2</sub>. The SME mechanism will blindly execute the program as many times as possible views (or positions of the array) may exist.</p>
      <p>Consider a program <em>h</em> ≔ <em>l</em> where initial views for variables <em>l</em> and <em>h</em> are given by: <span class="inline-equation"><span class="tex">$\hat{\mu }(h) =\langle 1:0\rangle$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }(l) =\langle 1:1\rangle$</span></span> . In SME, using the SME-TINI rule, the assignment will be executed twice: once with <span class="inline-equation"><span class="tex">$H(\hat{\mu }) = [ h \mapsto 1, l \mapsto 1]$</span></span> for the high view and once with <span class="inline-equation"><span class="tex">$L(\hat{\mu }) = [h \mapsto 0, l \mapsto 1]$</span></span> for the low view. After execution, the final SME memory will map <em>h</em> to ⟨1: 1⟩. One way to reduce the number of executions is to exploit the knowledge that the high and the low view for variable <em>l</em> are equal, i.e., <span class="inline-equation"><span class="tex">$H(\hat{\mu })(l)=L(\hat{\mu })(l)$</span></span> . Since the semantics is deterministic, there is no need to execute the program twice. We can use this knowledge by specialising SME at the granularity of commands and include the following assignment rule:</p>
      <p></p>
      <div class="table-responsive"><img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-display3.jpg" class="img-responsive" alt="" /></div>
      <p></p>
      <p>Notice that this SME optimization requires to <em>look inside</em> the shape of the program to evaluate if expression <em>e</em> of an assignment satisfies the hypothesis.</p>
      <p>In general, in order to reduce the number of executions using the multi-execution technique of SME-TINI, it is sufficient to (i) identify in an SME memory which values in the array of values are equal and (ii) remember which values correspond to which views. MF uses the multi-execution technique, implements (i) and (ii) and hence, reduces the number of executions. MF encodes values in SME memories (arrays with as many positions as lattice elements) as ordered binary trees, where the order is given by the elements of the lattice. For example, for a SME memory where <span class="inline-equation"><span class="tex">$\hat{\mu }(h) = \langle 1:0:0:0\rangle$</span></span> for a lattice of 4 elements with top element ⊤, an equivalent MF memory encodes this array as ⟨⊤?1: 0⟩ with the meaning that 1 is the view for ⊤ and 0 for the rest. Every execution that depends on that value, will multi execute twice instead of 4 times as in SME.</p>
      <p>Moreover, MF further uses the view information provided by the encoding in order to multi execute less in case of branching commands. For example, for SME-TINI with SME memory <span class="inline-equation"><span class="tex">$\hat{\mu }(h) = \langle 1:0:0:0\rangle$</span></span> the program:</p>
      <p><img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-img1.svg" class="img-responsive" alt="" longdesc="" /></p>executes 4 times (where the assignment at line 2 executes 3 times).
      <p></p>
      <p>Using the MF memory encoding <span class="inline-equation"><span class="tex">$\hat{\mu }(h) =\langle \top ? 1:0 \rangle$</span></span> , MF remembers that at line 2 there is no possible observation for the view ⊤ (because for view ⊤ the value of <em>h</em> is 1 so it doesn't take the then branch). Hence, the assignment <em>h</em> ≔ <em>h</em> + 1 only executes once with a memory where <em>h</em> is 0 (the view of variable <em>h</em> corresponding to the 3 levels which are not ⊤).</p>
      <p>For a program <em>h</em> ≔ <em>l</em>, where <span class="inline-equation"><span class="tex">$\hat{\mu }(l)$</span></span> is ⟨1: 1⟩ in SME, MF keeps only the value 1: a single value represents the fact that all views can observe the same value. Thus the assignment <em>h</em> ≔ <em>l</em> executes once (and all future executions dependent on <em>h</em> will also be reduced).</p>
      <p>Hence when encoding of an SME memory can be reduced effectively, multi executions are reduced accordingly. As shown in the following sections, preservation of MF memories encoding through execution requires: to represent arrays of values as trees called faceted values and to evaluate expressions depending on faceted values. In particular, the definition of the evaluation of expressions on faceted values depends highly on the shape of expressions and their values according to different views, and thus is contradictory to the blackbox property of a monitor.</p>
      <p><strong>MF may run more multi executions than SME</strong> Original MF has one limitation with respect to SME: it was designed only for a security lattice of principals: for <em>n</em> principals, such a lattice contains 2 <sup><em>n</em></sup> security levels. The following Ad Exchange platform&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0035">35</a>] example demonstrates that MF may be less efficient than SME in practice, when the security lattice is not based on principals.</p>
      <p></p>
      <div class="example" id="enc1">
        <label>Example 2.1.</label>
        <p>An Ad Exchange platform needs to put an advertisement on a publisher's website. For that, it implements a Real-time Bidding (RTB) system&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0036">36</a>], where advertisers can bid for the space on the publisher's website to get their ad published. The system receives as input all the bid offers from bidders and sorts them. According to the RTB algorithm, the second best offer wins.</p>
        <p>We present the lattice of 5 elements for this example in Fig.&nbsp;<a class="fig" href="#fig2">2</a>. For simplicity, we consider only 3 bidders called <em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>, and <em>B</em> <sub>3</sub>, an Ad Exchange (⊤ level) which is able to see all the bids, and a public view ⊥. Because MF is designed for a principal lattice, to encode 5 security levels, it uses 3 principals <em>k</em> <sub>1</sub>, <em>k</em> <sub>2</sub>, and <em>k</em> <sub>3</sub>, and create a lattice of 8 = 2<sup>3</sup> levels, and thus has a potential to run some parts of the program 8 times, while SME always executes the program 5 times.</p>
        <p>We consider one test that naively checks the order of bid offers and decides the winner. The encoding of the lattice is: ⊤ = {<em>k</em> <sub>1</sub>, <em>k</em> <sub>2</sub>, <em>k</em> <sub>3</sub>}, <em>B<sub>i</sub></em> = {<em>k<sub>i</sub></em> }, and ⊥ = ∅.</p>
        <figure id="fig2">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-fig2.jpg" class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span> <span class="figure-title">Lattice <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}_{\text{B}}}, \sqsubseteq \rangle$</span></span> .</span>
          </div>
        </figure>
        <p></p>
        <p><img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-img3.svg" class="img-responsive" alt="" longdesc="" /></p>
        <p>The bid values from bidders are <em>x</em> <sub>1</sub> = ⟨<em>k</em> <sub>1</sub> ? 10 :  0⟩, <em>x</em> <sub>2</sub> = ⟨<em>k</em> <sub>2</sub> ? 5 :  0⟩, and <em>x</em> <sub>3</sub> = ⟨<em>k</em> <sub>3</sub> ? 7 :  0⟩. Thus, the resulting value of <em>test</em> at line 2 is</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\[ \langle k_1 \,{?}\, \langle k_2 \,{?}\, \langle k_3 \,{?}\, {\textsf {ff}} \,{:}\, {\textsf {ff}} \rangle \,{:}\, {\langle k_3 \,{?}\, {\textsf {ff}} \,{:}\, {\textsf {ff}} \rangle } \rangle \,{:}\, \langle k_2 \,{?}\, \langle k_3 \,{?}\, {\textsf {tt} } \,{:}\, {\textsf {ff}} \rangle \,{:}\, \langle k_3 \,{?}\, {\textsf {tt} } \,{:}\, {\textsf {tt} } \rangle \rangle \rangle . \]</span><br />
          </div>
        </div>
        <p></p>
        <p>Therefore, the original MF executes the if instruction 8 times with 3 useless executions for levels {<em>k</em> <sub>1</sub>, <em>k</em> <sub>2</sub>}, {<em>k</em> <sub>2</sub>, <em>k</em> <sub>3</sub>}, and {<em>k</em> <sub>1</sub>, <em>k</em> <sub>3</sub>}.</p>
        <p>Moreover, because different views of a variable may contain the same values, MF may execute the same statement several times. For example, in the execution described above, original MF executes the then branch 3 times, while it only needs to run once since the threes executions for the then branch can be merged into one.</p>
      </div>
      <p></p>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> MF for arbitrary security lattice</h2>
        </div>
      </header>
      <p>We present an extension to the original Multiple Facets mechanism&nbsp;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>] for an arbitrary security lattice <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}}, \sqsubseteq \rangle$</span></span> , which we call Generalised Multiple Facets mechanism, or <em>GMF</em>. Similarly to Multiple Facets, GMF operates over a <em>faceted memory</em> <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> that maps variables to simple values or faceted values. A <em>faceted value</em> is of the form ⟨<em>l</em> ? <em>V</em> <sub>1</sub> :  <em>V</em> <sub>2</sub>⟩ where <span class="inline-equation"><span class="tex">$l \in {\mathcal {L}}$</span></span> is a security level, and <em>V<sub>i</sub></em> can be either a faceted value or a simple value. The first facet <em>V</em> <sub>1</sub> of ⟨<em>l</em> ? <em>V</em> <sub>1</sub> :  <em>V</em> <sub>2</sub>⟩ is called <em>private</em>, and visible to the observers at security level <em>l</em> or higher levels in the lattice; the second facet <em>V</em> <sub>2</sub> is called <em>public</em>, and visible to security levels that are lower or incomparable to <em>l</em>. We use <em>V</em> as a meta-variable for faceted values or simple values. Every evaluation in GMF (see Fig.&nbsp;<a class="fig" href="#fig6">6</a>) is marked with a set of security levels <em>pc</em>, for which the current computation is visible.</p>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Expression evaluation</h3>
          </div>
        </header>
        <p>By <span class="inline-equation"><span class="tex">$\hat{\mu }^{pc}(e)$</span></span> we denote the evaluation of expression <em>e</em> in faceted memory <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> with set of security levels <em>pc</em>. The definition of <span class="inline-equation"><span class="tex">$\hat{\mu }^{pc}(e)$</span></span> is presented in Fig.&nbsp;<a class="fig" href="#fig4">4</a>. For example, consider the evaluation of <em>x</em> when the faceted value <em>x</em> in memory <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> is ⟨<em>l</em> ? <em>V</em> <sub>1</sub> :  <em>V</em> <sub>2</sub>⟩. To define which facet is useful given a <em>pc</em>, we consider the following cases:</p>
        <ul class="list-no-style">
          <li id="list1" label="•">All the levels in <em>pc</em> are greater than or equal to <em>l</em>, denoted <em>l</em>≼<em>pc</em> (i.e. ∀<em>l</em>′ ∈ <em>pc</em>. <em>l</em>⊑<em>l</em>′): the evaluation can use the private facet <em>V</em> <sub>1</sub> because the public facet <em>V</em> <sub>2</sub> is anyway not useful for every level in this <em>pc</em>.<br /></li>
          <li id="list2" label="•">All the levels in <em>pc</em> are lower than or incomparable to <em>l</em>, denoted <span class="inline-equation"><span class="tex">$l \not\preccurlyeq pc$</span></span> (i.e. <span class="inline-equation"><span class="tex">$\forall l^{\prime } \in pc.\ l \not\sqsubseteq l^{\prime }$</span></span> ): the evaluation can only use the public facet <em>V</em> <sub>2</sub> because <em>V</em> <sub>2</sub> is a facet visible to any view that is lower than or incomparable to <em>l</em>.<br /></li>
          <li id="list3" label="•">Otherwise, we say that <em>l</em> and <em>pc</em> are <em>incomparable</em> and denote it by <span class="inline-equation"><span class="tex">$l |||pc$</span></span> (i.e. <span class="inline-equation"><span class="tex">$ \exists l^{\prime }, l^{\prime \prime } \in pc.\ l \sqsubseteq l^{\prime } \wedge l \not\sqsubseteq l^{\prime \prime }$</span></span> ): we first evaluate <em>V</em> <sub>1</sub> with <em>pc</em> <sub>1</sub> = {<em>l</em>′ ∈ <em>pc</em> | <em>l</em>⊑<em>l</em>′} – the set of all levels in <em>pc</em> which are greater than or equal to <em>l</em>. Then, we evaluate <em>V</em> <sub>2</sub> with <em>pc</em> <sub>2</sub> = <em>pc</em>∖<em>pc</em> <sub>1</sub> which is the set of all levels in <em>pc</em> which are lower than or incomparable to <em>l</em>. Finally, we combine the two results in a new faceted value.<br /></li>
        </ul>
        <figure id="fig3">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-fig3.jpg" class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span> <span class="figure-title">Lattice <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}_{\diamond }}, \sqsubseteq \rangle$</span></span> .</span>
          </div>
        </figure>
        <figure id="fig4">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-fig4.svg" class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span> <span class="figure-title">Expression evaluation.</span>
          </div>
        </figure>
        <p>To evaluate a variable <em>x</em>, we use a special unary operator <span class="inline-equation"><span class="tex">$\ominus ^{pc}(\hat{\mu }(x))$</span></span> , which returns the value that is visible to all the levels in the <em>pc</em>. Let's consider the case of ⊖ <sup><em>pc</em></sup> (⟨<em>l</em> ? <em>V</em> <sub>1</sub> :  <em>V</em> <sub>2</sub>⟩). Notice that, if <em>pc</em> and <em>l</em> are incomparable, meaning that there are some levels in <em>pc</em> that are higher than or equal to <em>l</em> and other levels in <em>pc</em> that are lower than or incomparable to <em>l</em>, denoted by <span class="inline-equation"><span class="tex">$l |||pc$</span></span> , then the evaluation returns the faceted value <span class="inline-equation"><span class="tex">$\langle l \,{?}\, \ominus ^{pc_1}(V_1) \,{:}\, \ominus ^{pc_2}(V_2) \rangle$</span></span> . The form of the result of <span class="inline-equation"><span class="tex">$\hat{\mu }^{pc}(e)$</span></span> is described in Lemma&nbsp;<a class="enc" href="#enc2">3.1</a>.</p>
        <div class="lemma" id="enc2">
          <label>Lemma 3.1.</label>
          <p>If <span class="inline-equation"><span class="tex">$\hat{\mu }^{pc}(e) = \langle l \,{?}\, V_1 \,{:}\, V_2 \rangle$</span></span> , then <span class="inline-equation"><span class="tex">$l |||pc$</span></span> .</p>
        </div>
        <div class="example" id="enc3">
          <label>Example 3.2 (Expression evaluation).</label>
          <p>Consider the lattice <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}_{\diamond }}, \sqsubseteq \rangle$</span></span> from Fig.&nbsp;<a class="fig" href="#fig3">3</a>, and the evaluation of <em>x</em> + <em>y</em> in <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\mu }(x) = \langle M_1 \,{?}\, 10 \,{:}\, 0 \rangle$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }(y) = \langle M_2 \,{?}\, 5 \,{:}\, 0 \rangle$</span></span> .</p>
          <p>Suppose that <em>pc</em> = {<em>M</em> <sub>1</sub>, <em>H</em>}. Since all the levels in <em>pc</em> are higher than or equal to <em>M</em> <sub>1</sub>, the evaluation of <em>x</em> returns <span class="inline-equation"><span class="tex">$\hat{\mu }^{pc}(x) = 10$</span></span> . Since <em>pc</em> and <em>M</em> <sub>2</sub> are incomparable, the evaluation of <em>y</em> returns <span class="inline-equation"><span class="tex">$\hat{\mu }^{pc}(y)= \langle M_2 \,{?}\, 5 \,{:}\, 0 \rangle$</span></span> . Next, the evaluation of 10 + <sup><em>pc</em></sup> ⟨<em>M</em> <sub>2</sub> ? 5 :  0⟩ is split into two: one uses a facet visible to <em>M</em> <sub>2</sub> (and hence <em>H</em>), and another one uses a public facet that will be visible to <em>M</em> <sub>1</sub>.</p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\begin{align*} \hat{\mu }^{pc}(x + y) &amp;= \hat{\mu }^{pc}(x) +^{pc} \hat{\mu }^{pc}(y)\\ &amp; = {\ominus ^{pc}(\langle M_1 \,{?}\, 10 \,{:}\, 0 \rangle) +^{pc} \ominus ^{pc}(\langle M_2 \,{?}\, 5 \,{:}\, 0 \rangle)}\\ &amp; = 10 +^{pc} \langle M_2 \,{?}\, 5 \,{:}\, 0 \rangle = \langle M_2 \,{?}\, 10 +^{\lbrace H\rbrace } 5 \,{:}\, 10 +^{\lbrace M_1\rbrace } 0 \rangle \\ &amp; = \langle M_2 \,{?}\, 15 \,{:}\, 10 \rangle\end{align*}</span><br />
            </div>
          </div>
          <p></p>
        </div>
      </section>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Semantics</h3>
          </div>
        </header>
        <p>We abuse the notation and use <em>l</em> as a <em>projection function</em> on simple values, faceted values and faceted memories. For any <em>V</em>, <em>l</em>(<em>V</em>) returns the value in <em>V</em> which is visible to users at level <em>l</em>. For any <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> , <span class="inline-equation"><span class="tex">$l(\hat{\mu })$</span></span> returns the memory in <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> which is visible to users at level <em>l</em>.</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{eqnarray*} l(v) = v \quad \quad l(\langle l_1 \,{?}\, V_1 \,{:}\, V_2 \rangle) = {\left\lbrace \begin{array}{@{}l@{\quad }l@{}}l(V_1) &amp; \text{if $l_1 \sqsubseteq l$,} \\l(V_2) &amp; \text{otherwise.} \end{array}\right.}\\l(\hat{\mu })(x) = l(\hat{\mu }(x)) \hspace{80.0pt}\end{eqnarray*}</span><br />
          </div>
        </div>The projection function <em>l</em> is used in the definition of <span class="inline-equation"><span class="tex">$\hat{\mu }|_{\Gamma }$</span></span> function that converts a faceted memory to a simple memory (see Fig.&nbsp;<a class="fig" href="#fig5">5</a>).
        <figure id="fig5">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-fig5.svg" class="img-responsive" alt="Figure 5" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span> <span class="figure-title">Functions for faceted and normal memories.</span>
          </div>
        </figure>
        <p></p>
        <p>The semantics of GMF is defined in Fig.&nbsp;<a class="fig" href="#fig6">6</a> as a big-step evaluation relation <em>Γ</em>⊢(<em>P</em>, <em>μ</em>)⇓ <sub><em>GMF</em></sub> <em>μ</em>′, where program <em>P</em> is executed in a memory <em>μ</em> and a security environment <em>Γ</em> that maps variables to security levels in a given security lattice <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}}, \sqsubseteq \rangle$</span></span> .</p>
        <figure id="fig6">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-fig6.svg" class="img-responsive" alt="Figure 6" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 6:</span> <span class="figure-title">Multiple facets for arbitrary security lattice.</span>
          </div>
        </figure>
        <p></p>
        <p>The main rule GMF first constructs a faceted memory from the standard memory using the transformation <span class="inline-equation"><span class="tex">$\mu \uparrow ^{\mathit {def}}_{\Gamma }$</span></span> from Fig.&nbsp;<a class="fig" href="#fig5">5</a>, where <span class="inline-equation"><span class="tex">$\text{glb}({\mathcal {L}})$</span></span> is the greatest lower bound of <span class="inline-equation"><span class="tex">${\mathcal {L}}$</span></span> . The resulting faceted memory keeps original value of each variable <em>x</em> in a private facet, and adds default values (defined by <em>def</em> function) in a public facet. In a special case when the level of <em>x</em> is the smallest level in a lattice, we keep only a simple value <em>μ</em>(<em>x</em>) that is visible to all security levels. We then evaluate the program with the constructed faceted memory and <span class="inline-equation"><span class="tex">$pc = {\mathcal {L}}$</span></span> . The resulting faceted memory is transformed back to a normal memory by using the projection function <span class="inline-equation"><span class="tex">$\hat{\mu }|_{\Gamma }$</span></span> .</p>
        <p>The semantics rules for skip, sequence and while loop are straightforward. The GAssign rule uses a faceted evaluation <span class="inline-equation"><span class="tex">$\hat{\mu }^{pc}(e)$</span></span> defined in Section&nbsp;<a class="sec" href="#sec-10">3.1</a>.</p>
        <p>Before describing the semantics of if instruction, we first define several auxiliary functions. Let <span class="inline-equation"><span class="tex">$\text{dom}(\hat{\mu })$</span></span> be the domain of <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> and <em>y</em> be a fresh variable, i.e. <span class="inline-equation"><span class="tex">$y \not\in \text{dom}(\hat{\mu })$</span></span> ). By <span class="inline-equation"><span class="tex">$\hat{\mu } \uplus {(y \mapsto V)}$</span></span> we denote a new memory <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime }$</span></span> , such that <span class="inline-equation"><span class="tex">$\text{dom}(\hat{\mu }^{\prime }) = \text{dom}(\hat{\mu }) \cup \lbrace y\rbrace$</span></span> , <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime }(y) = V$</span></span> and for all <span class="inline-equation"><span class="tex">$x \in \text{dom}(\hat{\mu })$</span></span> , <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime }(x) = \hat{\mu }(x)$</span></span> . By <span class="inline-equation"><span class="tex">$\hat{\mu } \setminus \!\!\!\setminus y$</span></span> , we remove <em>y</em> from the domain of <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> , that is, <span class="inline-equation"><span class="tex">$\hat{\mu } \setminus \!\!\!\setminus y$</span></span> constructs a new memory <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime }$</span></span> , where <span class="inline-equation"><span class="tex">$\text{dom}(\hat{\mu }^{\prime }) = \text{dom}(\hat{\mu }) \setminus \lbrace y\rbrace$</span></span> and for all <em>x</em> ≠ <em>y</em>, <span class="inline-equation"><span class="tex">$\hat{\mu }(x) = \hat{\mu }^{\prime }(x)$</span></span> .</p>
        <p>Consider the evaluation of the if instruction <strong>if</strong> <em>e</em> <strong>then</strong> <em>P</em> <sub>1</sub> <strong>else</strong> <em>P</em> <sub>2</sub> with <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> and <em>pc</em>. If <em>e</em> is evaluated to a constant value (<span class="inline-equation"><span class="tex">${\textsf {tt} }$</span></span> or <span class="inline-equation"><span class="tex">${\textsf {ff}}$</span></span> ), then only <span class="inline-equation"><span class="tex">$P_{{\textsf {tt} }}$</span></span> or <span class="inline-equation"><span class="tex">$P_{{\textsf {ff}}}$</span></span> is evaluated (see rule GIf-C).</p>
        <p>When <em>e</em> is evaluated to a faceted value ⟨<em>l</em> ? <em>V</em> <sub>1</sub> :  <em>V</em> <sub>2</sub>⟩, we construct a new program <strong>if</strong> <em>y</em> <strong>then</strong> <em>P</em> <sub>1</sub> <strong>else</strong> <em>P</em> <sub>2</sub>, where <em>y</em> is a fresh variable. From Lemma&nbsp;<a class="enc" href="#enc2">3.1</a>, we have that <span class="inline-equation"><span class="tex">$l |||pc$</span></span> , and hence <em>pc</em> <sub>1</sub> = {<em>l</em>′ ∈ <em>pc</em> | <em>l</em>⊑<em>l</em>′} and <em>pc</em> <sub>2</sub> = <em>pc</em>∖<em>pc</em> <sub>1</sub> are non-empty. In this case, we run the new program <strong>if</strong> <em>y</em> <strong>then</strong> <em>P</em> <sub>1</sub> <strong>else</strong> <em>P</em> <sub>2</sub> twice: once with the ”higher view” than <em>l</em>, i.e., with <em>pc</em> <sub>1</sub> = {<em>l</em>′ ∈ <em>pc</em> | <em>l</em>⊑<em>l</em>′} and <em>y</em> set to a private facet <em>V</em> <sub>1</sub>, and another time with ”lower or incomparable view” than <em>l</em>, i.e. with <em>pc</em> <sub>2</sub> = <em>pc</em>∖<em>pc</em> <sub>1</sub> and <em>y</em> set to a public facet <em>V</em> <sub>2</sub>. We then combine the resulting memories using the ⊗ <sup><em>l</em></sup> operator. The combination of faceted memories is based on the fact that when <em>pc</em> is split into <em>pc</em> <sub>1</sub> and <em>pc</em> <sub>2</sub> in the GIf-S rule, all levels in <em>pc</em> <sub>1</sub> is larger than or equal to <em>l</em>, and all levels in <em>pc</em> <sub>2</sub> is smaller than or incomparable to <em>l</em>.</p>
        <p>Notice that the form of a faceted value constructed by combining values can be reduced. For example, a faceted value of the form ⟨<em>H</em> ? ⟨<em>M</em> <sub>1</sub> ? <em>V</em> <sub>11</sub> :  <em>V</em> <sub>12</sub>⟩ :  <em>V</em> <sub>2</sub>⟩ can be reduced to ⟨<em>H</em> ? <em>V</em> <sub>11</sub> :  <em>V</em> <sub>2</sub>⟩ because <em>M</em> <sub>1</sub>⊑<em>H</em> and the projection of the original value at any level is either <em>V</em> <sub>11</sub> or <em>V</em> <sub>2</sub>. We use the optimisation on the constructed faceted values from Fig.&nbsp;<a class="fig" href="#fig7">7</a>.</p>
        <figure id="fig7">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-fig7.svg" class="img-responsive" alt="Figure 7" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 7:</span> <span class="figure-title">Optimisation of a faceted value.</span>
          </div>
        </figure>
        <p></p>
        <p>Therefore, in the GIf-S rule after the evaluation of <em>P</em>′ in two contexts, we combine the resulting faceted memories <span class="inline-equation"><span class="tex">$\hat{\mu }_1^{\prime }\setminus \!\!\!\setminus y$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }_2^{\prime } \setminus \!\!\!\setminus y$</span></span> and apply an optimisation operator [[]] for each newly constructed faceted value. The correctness of [[]] used to optimize faceted values is proven in Lemma&nbsp;<a class="enc" href="#enc4">3.3</a>.</p>
        <div class="lemma" id="enc4">
          <label>Lemma 3.3.</label>
          <p>For all <em>l</em>, all <em>V</em>, it follows that <em>l</em>(<em>V</em>) = <em>l</em>([[<em>V</em>]]).</p>
        </div>
        <div class="example" id="enc5">
          <label>Example 3.4 (Evaluation of if instruction).</label>
          <p>Consider the security lattice <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}_{\diamond }}, \sqsubseteq \rangle$</span></span> from Fig.&nbsp;<a class="fig" href="#fig3">3</a> and the evaluation of the following program <em>P</em> with <span class="inline-equation"><span class="tex">$pc = {\mathcal {L}_{\diamond }}$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\mu }(x) = \langle M_1 \,{?}\, \langle H \,{?}\, {\textsf {tt} } \,{:}\, {\textsf {ff}} \rangle \,{:}\, {\textsf {tt} } \rangle$</span></span> .</p>
          <p><img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-img4.svg" class="img-responsive" alt="" longdesc="" /></p>
          <p>The evaluation follows the GIf-S rule since <span class="inline-equation"><span class="tex">$M_1 |||{\mathcal {L}_{\diamond }}$</span></span> . We construct <em>P</em>′ = <strong>if</strong> <em>y</em> <sub>1</sub> <strong>then</strong> <em>P</em> <sub>1</sub> <strong>else</strong> <em>P</em> <sub>2</sub> and first evaluate <em>P</em>′ with <em>pc</em> <sub>1</sub> = {<em>l</em>′ ∈ <em>pc</em> | <em>M</em> <sub>1</sub>⊑<em>l</em>′} = {<em>M</em> <sub>1</sub>, <em>H</em>} and <span class="inline-equation"><span class="tex">$\hat{\mu }_1= \hat{\mu }\uplus (y \mapsto \langle H \,{?}\, {\textsf {tt} } \,{:}\, {\textsf {ff}} \rangle)$</span></span> , and then evaluate <em>P</em>′ with <em>pc</em> <sub>2</sub> = <em>pc</em>∖<em>pc</em> <sub>1</sub> = {<em>M</em> <sub>2</sub>, <em>L</em>}, <span class="inline-equation"><span class="tex">$\hat{\mu }_2= \hat{\mu }\uplus (y \mapsto {\textsf {tt} })$</span></span> .</p>
          <p>Since <em>pc</em> <sub>1</sub> = {<em>H</em>, <em>M</em> <sub>1</sub>} and <span class="inline-equation"><span class="tex">$\hat{\mu }^{pc}(y) = \langle H \,{?}\, {\textsf {tt} } \,{:}\, {\textsf {ff}} \rangle$</span></span> , the evaluation of <em>P</em>′ with <em>pc</em> <sub>1</sub> and <span class="inline-equation"><span class="tex">$\hat{\mu }_1$</span></span> is split again to two evaluations: one with <em>P</em>′′ = <strong>if</strong> <em>t</em> <strong>then</strong> <em>P</em> <sub>1</sub> <strong>else</strong> <em>P</em> <sub>2</sub>, <em>pc</em> <sub>11</sub> = {<em>H</em>}, and <span class="inline-equation"><span class="tex">$\hat{\mu }_{11}= \hat{\mu }_1\uplus (t \mapsto {\textsf {tt} })$</span></span> ; and the other one with <em>P</em>′′, <em>pc</em> <sub>12</sub> = {<em>M</em> <sub>1</sub>}, and <span class="inline-equation"><span class="tex">$\hat{\mu }_{12}= \hat{\mu }_1\uplus (t \mapsto {\textsf {ff}})$</span></span> .</p>
          <p>The evaluation of <em>P</em>′′ with <em>pc</em> <sub>11</sub> and with <em>pc</em> <sub>12</sub> follow the GIf-C rule and we get two faceted memories <span class="inline-equation"><span class="tex">$\hat{\mu }_{11}^{\prime }$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }_{12}^{\prime }$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\mu }_{11}^{\prime }(z) = 10$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }_{12}^{\prime }(z) = 5$</span></span> . Then, <span class="inline-equation"><span class="tex">$\hat{\mu }_{11}^{\prime } \setminus \!\!\!\setminus t$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }_{12}^{\prime } \setminus \!\!\!\setminus t$</span></span> are combined and we get <span class="inline-equation"><span class="tex">$\hat{\mu }_1^{\prime }$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\mu }_1^{\prime }(z) = \langle H \,{?}\, 10 \,{:}\, 5 \rangle$</span></span> .</p>
          <p>The evaluation of <em>P</em> <sub>2</sub> with <em>pc</em> <sub>2</sub> follows the GIf-C rule and the result is <span class="inline-equation"><span class="tex">$\hat{\mu }_2^{\prime }$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\mu }_2^{\prime }(z) = 10$</span></span> . At this point, <span class="inline-equation"><span class="tex">$\hat{\mu }_1^{\prime } \setminus \!\!\!\setminus y_1$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }_2^{\prime } \setminus \!\!\!\setminus y_1$</span></span> are combined and the result is <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime }$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime }(z) = \langle M_1 \,{?}\, \langle H \,{?}\, 10 \,{:}\, 5 \rangle \,{:}\, 10 \rangle$</span></span> .</p>
        </div>
        <div class="example" id="enc6">
          <label>Example 3.5 (Evaluation with the GMF rule).</label>
          <p>Consider the lattice <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}_{\diamond }}, \sqsubseteq \rangle$</span></span> from Fig.&nbsp;<a class="fig" href="#fig3">3</a> and program <em>P</em> from Example&nbsp;<a class="enc" href="#enc5">3.4</a> with one more instruction <em>x</em> ≔ <em>x</em> <sub>1</sub> &gt; <em>x</em> <sub>2</sub>. Suppose that <em>Γ</em>(<em>x</em> <sub>1</sub>) = <em>M</em> <sub>1</sub>, <em>Γ</em>(<em>x</em> <sub>2</sub>) = <em>H</em>, <em>Γ</em>(<em>z</em>) = <em>H</em>, <em>μ</em>(<em>x</em> <sub>1</sub>) = 10, <em>μ</em>(<em>x</em> <sub>2</sub>) = 5, the default values for <em>x</em> <sub>1</sub> and <em>x</em> <sub>2</sub> are respectively 100 and 20 <a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>. Let <span class="inline-equation"><span class="tex">$\hat{\mu } = \mu \uparrow ^{\mathit {def}}_{\Gamma }$</span></span> . It follows that <span class="inline-equation"><span class="tex">$\hat{\mu }(x_1) = \langle M_1 \,{?}\, 10 \,{:}\, 100 \rangle$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }(x_2) = \langle H \,{?}\, 5 \,{:}\, 20 \rangle$</span></span> .</p>
          <p><img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-img5.svg" class="img-responsive" alt="" longdesc="" /></p>
          <p>Following GMF rule, the program is evaluated with <span class="inline-equation"><span class="tex">$pc = {\mathcal {L}_{\diamond }}= \lbrace H,M_1,M_2,L\rbrace$</span></span> . For the assignment instruction, the value of <em>x</em> is updated to <span class="inline-equation"><span class="tex">$\hat{\mu }^{pc}(x_1 {\gt} x_2) = \langle M_1 \,{?}\, \langle H \,{?}\, {\textsf {tt} } \,{:}\, {\textsf {ff}} \rangle \,{:}\, {\textsf {tt} } \rangle$</span></span> . The rest of the evaluation is described in Example&nbsp;<a class="enc" href="#enc5">3.4</a>, and the resultant faceted memory is <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime }$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime }(z) = \langle M_1 \,{?}\, \langle H \,{?}\, 10 \,{:}\, 5 \rangle \,{:}\, 10 \rangle$</span></span> .</p>
          <p>The memory after the application of rule GMF is <span class="inline-equation"><span class="tex">$\mu ^{\prime } = \hat{\mu }^{\prime }|_{\Gamma }$</span></span> . Since <em>Γ</em>(<em>z</em>) = <em>H</em>, the value of <em>z</em> is <em>μ</em>′(<em>z</em>) = <em>H</em>(⟨<em>M</em> <sub>1</sub> ? ⟨<em>H</em> ? 10 :  5⟩ :  10⟩) = 10.</p>
        </div>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.3</span> Equivalence to SME-TINI and Security Guarantee</h3>
          </div>
        </header>
        <p><em>SME-TINI</em>. The semantics of SME-TINI, termination-insensitive version of SME, for an arbitrary security lattice is presented below, where <span class="inline-equation"><span class="tex">$\vec{\mu }$</span></span> is a vector that maps levels to normal memories; <em>μ</em>⊎ <sup><em>l</em></sup> <em>Γ</em> constructs a memory where values of variables at levels that are not visible to <em>l</em> are replaced by default values; <span class="inline-equation"><span class="tex">$\odot _{\Gamma }(\vec{\mu })(x) \triangleq \vec{\mu }[\Gamma (x)](x)$</span></span> constructs a memory by combining all memories in <span class="inline-equation"><span class="tex">$\vec{\mu }$</span></span> ; and <em><em>def</em></em> is a function mapping variables to default values.</p>
        <p></p>
        <div class="table-responsive"><img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-display4.jpg" class="img-responsive" alt="" longdesc="" /></div>
        <p>We now prove that SME-TINI enforces <em>termination-insensitive noninterference (TINI)</em>. Two memories <em>μ</em> and <em>μ</em>′ are <em>equivalent at <em>l</em> w.r.t. <em>Γ</em></em> (denoted by <span class="inline-equation"><span class="tex">$\mu =_l^{\Gamma } \mu ^{\prime }$</span></span> ) iff for all <em>x</em>, <em>Γ</em>(<em>x</em>)⊑<em>l</em>⇒<em>μ</em>(<em>x</em>) = <em>μ</em>′(<em>x</em>). When <em>Γ</em> is clear from the context, <span class="inline-equation"><span class="tex">$\mu =_l^{\Gamma } \mu ^{\prime }$</span></span> is written as <em>μ</em> = <sub><em>l</em></sub> <em>μ</em>′.</p>
        <div class="definition" id="enc7">
          <label>Definition 3.6 (TINI).</label>
          <p>An enforcement mechanism <em>A</em> is <em>termination insensitive non-interferent (TINI)</em> if for all security environments <em>Γ</em>, programs <em>P</em>, and memories <em>μ</em> <sub>1</sub>, and <em>μ</em> <sub>2</sub>, we have</p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\[ \mu _1 =_l \mu _2 \:\wedge \: \Gamma \vdash (P,\mu _1) \Downarrow _{A} \mu _1^{\prime } \:\wedge \Gamma \vdash (P,\mu _2) \Downarrow _{A} \mu _2^{\prime } \Rightarrow \mu _1^{\prime } =_l \mu _2^{\prime }. \]</span><br />
            </div>
          </div>
          <p></p>
        </div>
        <div class="theorem" id="enc8">
          <label>Theorem 3.7.</label>
          <p>SME-TINI is TINI.</p>
        </div>
        <p><em>Equivalence to SME-TINI</em>.</p>
        <p>To prove the equivalence between GMF and SME-TINI, we formally define the semantic equivalence of two mechanisms.</p>
        <div class="definition" id="enc9">
          <label>Definition 3.8.</label>
          <p>Two enforcement mechanisms <em>A</em> and <em>B</em> are equivalent if for any <em>Γ</em>, <em>P</em> and <em>μ</em>, we have that <em>Γ</em>⊢(<em>P</em>, <em>μ</em>)⇓ <sub><em>A</em></sub> <em>μ</em>′ iff <em>Γ</em>⊢(<em>P</em>, <em>μ</em>)⇓ <sub><em>B</em></sub> <em>μ</em>′.</p>
        </div>
        <p>We next establish the relation between the execution with GMF semantics and the execution with the standard semantics.</p>
        <div class="lemma" id="enc10">
          <label>Lemma 3.9.</label>
          <p><span class="inline-equation"><span class="tex">$(P,\hat{\mu })\downarrow _{G}^{pc} \hat{\mu }^{\prime }$</span></span> iff <span class="inline-equation"><span class="tex">$({P},l(\hat{\mu }))\Downarrow l(\hat{\mu }^{\prime })$</span></span> for all <em>l</em> ∈ <em>pc</em>.</p>
        </div>
        <p>Thanks to Lemma&nbsp;<a class="enc" href="#enc10">3.9</a>, we now prove the equivalence of GMF and SME-TINI.</p>
        <div class="theorem" id="enc11">
          <label>Theorem 3.10.</label>
          <p>GMF and SME-TINI are equivalent.</p>
        </div>
        <p>As a consequence, we have that GMF is TINI.</p>
        <div class="remark" id="enc12">
          <label>Remark 3.1.</label>
          <p>MF [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>] is constructed for a set of principals. When the set <strong>P</strong> of principals is fixed, we can use GMF to encode MF: we construct the lattice ⟨2 <sup><strong>P</strong></sup> , ⊆⟩, where each element is a set of principals; we prove that GMF for ⟨2 <sup><strong>P</strong></sup> , ⊆⟩ and MF for <strong>P</strong> are equivalent [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>].</p>
        </div>
      </section>
    </section>
    <section id="sec-13">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Optimizing GMF</h2>
        </div>
      </header>
      <p>In Section&nbsp;<a class="sec" href="#sec-9">3</a>, we presented the semantics of Generalised Multiple Facets (GMF) for arbitrary lattice and have proven it to be equivalent to SME-TINI. However, GMF from Fig.&nbsp;<a class="fig" href="#fig6">6</a> can be further optimised and avoid repeating evaluations of the same commands. The following example demonstrates the sub-optimality of GMF.</p>
      <p></p>
      <div class="example" id="enc13">
        <label>Example 4.1 (GMF is not optimal).</label>
        <p>We consider the below program from Example&nbsp;<a class="enc" href="#enc1">2.1</a>. The lattice is <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}_{\text{B}}}, \sqsubseteq \rangle$</span></span> from Fig.&nbsp;<a class="fig" href="#fig2">2</a>.</p>
        <p><img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-img6.svg" class="img-responsive" alt="" longdesc="" /></p>
        <p>Suppose that the bid offers of <em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>, and <em>B</em> <sub>3</sub> are respectively 10, 5, and 7, and the default values for <em>B<sub>i</sub></em> are 0. W.r.t. this setting, the initial faceted memory is <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\mu }(x_1) = \langle {B}_1 \,{?}\, 10 \,{:}\, 0 \rangle$</span></span> , <span class="inline-equation"><span class="tex">$\hat{\mu }(x_2) = \langle {B}_2 \,{?}\, 5 \,{:}\, 0 \rangle$</span></span> , and <span class="inline-equation"><span class="tex">$\hat{\mu }(x_3) = \langle {B}_3 \,{?}\, 7 \,{:}\, 0 \rangle$</span></span> . We consider the execution of the program with GMF.</p>
        <p>After line 2, <span class="inline-equation"><span class="tex">$\mathit {test}= \langle {B}_1 \,{?}\, \langle {B}_2 \,{?}\, {\textsf {ff}} \,{:}\, {\textsf {ff}} \rangle \,{:}\, \langle {B}_2 \,{?}\, {\textsf {ff}} \,{:}\, \langle {B}_3 \,{?}\, {\textsf {tt} } \,{:}\, {\textsf {tt} } \rangle \rangle \rangle$</span></span> . Following the semantics of GMF, the assignment instruction <em>winner</em> ≔ 2 is evaluated twice with <em>pc</em> <sub><em>B</em>3</sub> = {<em>B</em> <sub>3</sub>}, and <em>pc</em> <sub>⊥</sub> = {⊥}; the <strong> skip</strong> instruction is evaluated three times with <em>pc</em> <sub>⊤</sub> = {⊤}, <em>pc</em> <sub><em>B</em>1</sub> = {<em>B</em> <sub>1</sub>}, and <em>pc</em> <sub><em>B</em>2</sub> = {<em>B</em> <sub>2</sub>}.</p>
      </div>
      <p></p>
      <p>The main idea of our optimisation lays in reducing the number of sub-evaluations and hence the number of faceted memory combinations. For Example&nbsp;<a class="enc" href="#enc13">4.1</a>, we propose a mechanism that merges the evaluations corresponding to <em>pc</em> <sub><em>B</em>3</sub> and <em>pc</em> <sub>⊥</sub> into one evaluation with <em>pc</em> <sub>1</sub> = {<em>B</em> <sub>3</sub>, ⊥}. This simplification is possible since <em>test</em> denotes the same value (i.e., <span class="inline-equation"><span class="tex">${\textsf {tt} }$</span></span> ) under <em>pc</em> <sub><em>B</em>3</sub> and <em>pc</em> <sub>⊥</sub>. Similarly, our simplification merges the evaluations corresponding to <em>pc</em> <sub>⊤</sub>, <em>pc</em> <sub><em>B</em>1</sub>, and <em>pc</em> <sub><em>B</em>2</sub>, where <em>test</em> denotes <span class="inline-equation"><span class="tex">${\textsf {ff}}$</span></span> , into one evaluation with <em>pc</em> <sub>2</sub> = {⊤, <em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>}, and thus evaluates each branch of the if command only once.</p>
      <p>In this section, we propose semantics of <em>optimized GMF</em> (OGMF) that reduces the number of sub-evaluations, and hence is more resource-friendly than GMF.</p>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Semantics</h3>
          </div>
        </header>
        <p>The ideas behind the OGMF rule, and the rules for skip, assignment, sequence, and while instructions are similar to the corresponding ones of GMF. The functions <span class="inline-equation"><span class="tex">$\mu \uparrow ^{\mathit {def}}_{\Gamma }(x)$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }|_{\Gamma }(x)$</span></span> are defined in Fig.&nbsp;<a class="fig" href="#fig5">5</a>. We now explain the semantic rules for the conditional instruction.</p>
        <p>Consider evaluation of the program <strong>if</strong> <em>e</em> <strong>then</strong> <em>P</em> <sub>1</sub> <strong>else</strong> <em>P</em> <sub>2</sub> with <em>pc</em> and memory <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> , and <span class="inline-equation"><span class="tex">$\hat{\mu }^{pc}(e) = V$</span></span> . In order to evaluate each branch of the conditional only once, we split the <em>pc</em> in two subsets: in the first subset <em>pc</em> <sub>1</sub> the visible value of <em>V</em> is true, and in the remaining subset <em>pc</em> <sub>2</sub>, <em>V</em> is false. We now have three distinct cases.</p>
        <p>If <em>pc</em> <sub>1</sub> = <em>pc</em>, meaning that for all levels in <em>pc</em>, the visible value of <em>V</em> is true, then <em>P</em> <sub>1</sub> is evaluated (rule OIf-T). If <em>pc</em> <sub>2</sub> = <em>pc</em>, then for all levels in <em>pc</em>, the visible value of <em>V</em> is false, and only <em>P</em> <sub>2</sub> is evaluated (rule OIf-F). Finally, when <em>pc</em> is split in non-empty <em>pc</em> <sub>1</sub> and <em>pc</em> <sub>2</sub>, then both <em>P</em> <sub>1</sub> and <em>P</em> <sub>2</sub> are evaluated, and their results (<span class="inline-equation"><span class="tex">$\hat{\mu }_1^{\prime }$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }_2^{\prime }$</span></span> ) are combined by <span class="inline-equation"><span class="tex">$\hat{\mu }_1^{\prime } \oplus ^{pc_1, pc_2} \hat{\mu }_2^{\prime }$</span></span> (rule OIf-S) to a new faceted memory. The intuition behind this combination is that the projection of <span class="inline-equation"><span class="tex">$\hat{\mu }_1^{\prime } \oplus ^{pc_1, pc_2} \hat{\mu }_2^{\prime }$</span></span> at <em>l</em> ∈ <em>pc</em> <sub>1</sub> is taken from the evaluation of <em>P</em> <sub>1</sub> and its projection at <em>l</em> ∈ <em>pc</em> <sub>2</sub> is taken from the evaluation of <em>P</em> <sub>2</sub>.</p>
        <p>In the definition of combination of memories for OGMF (bottom of Fig.&nbsp;<a class="fig" href="#fig8">8</a>), we distinguish two cases. If for some variable <em>x</em>, its value in both faceted memories is the same, (<span class="inline-equation"><span class="tex">$\hat{\mu }_1^{\prime }(x) = \hat{\mu }_2^{\prime }(x)$</span></span> ), then we do not need to construct a new faceted value. Instead, we optimize the current value using the optimisation operator from Fig.&nbsp;<a class="fig" href="#fig7">7</a>.</p>
        <figure id="fig8">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-fig8.svg" class="img-responsive" alt="Figure 8" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 8:</span> <span class="figure-title">Optimized multiple facets for arbitrary lattice.</span>
          </div>
        </figure>
        <p></p>
        <p>If the values of <em>x</em> in <span class="inline-equation"><span class="tex">$\hat{\mu }_1^{\prime }(x)$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }_2^{\prime }(x)$</span></span> are different, then we construct a new faceted value <span class="inline-equation"><span class="tex">$V = \mathbb {F}(V_1,V_2,pc_1,pc_2)$</span></span> and apply further optimisation on the resulting value <em>V</em> using a new optimisation operator that takes into account a faceted value and the current <em>pc</em>: <span class="inline-equation"><span class="tex">$[[ V,pc]]$</span></span> optimizes the form of <em>V</em> and is described in Fig.&nbsp;<a class="fig" href="#fig9">9</a>. We show an example of such optimisation in Example&nbsp;<a class="enc" href="#enc16">4.4</a>.</p>
        <figure id="fig9">
          <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-fig9.svg" class="img-responsive" alt="Figure 9" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 9:</span> <span class="figure-title">Definition of <span class="inline-equation"><span class="tex">${[[ V,pc]] }$</span></span> , and optimisation of a faceted value <em>V</em> with respect to the set of security levels <em>pc</em>.</span>
          </div>
        </figure>
        <p></p>
        <p>To combine two faceted memories, we first construct a new faceted value by using <span class="inline-equation"><span class="tex">$\mathbb {F}(V_1,V_2,pc_1,pc_2)$</span></span> :</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\[ \mathbb {F}(V_1,V_2,pc_1,pc_2) = \langle \!\langle \mathit {List}(pc_1 \cup pc_2), V_1,V_2,pc_1,pc_2 \rangle \!\rangle \]</span><br />
          </div>
        </div>where <em>List</em>(<em>S</em>) is a list of security levels from a set <em>S</em>, such that if <em>l</em> appears before <em>l</em>′ in <em>List</em>(<em>S</em>) then <span class="inline-equation"><span class="tex">$l \not\sqsubseteq l^{\prime }$</span></span> . If the relation ⊑ in a given security lattice is not a total order, we can transform it into a total order ⊑ <sub><em>T</em></sub> provided that ⊑ is a finite partial order. We can then view <em>List</em>(<em>S</em>) as a list such that for any <em>l</em> and <em>l</em>′ in this list, if <em>l</em> appears before <em>l</em>′, then <em>l</em>′⊑ <sub><em>T</em></sub> <em>l</em>.
        <p></p>
        <p>The definition of <span class="inline-equation"><span class="tex">$\mathbb {F}(V_1,V_2,pc_1,pc_2)$</span></span> uses the following operator that creates a faceted value based on an ordered list of security levels <em>L</em>, two faceted values, <em>pc</em> <sub>1</sub> and <em>pc</em> <sub>2</sub>:</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\[ \langle \!\langle L, V_1, V_2, pc_1, pc_2 \rangle \!\rangle = {\left\lbrace \begin{array}{@{}l@{\quad }l@{}}l(V_1) \hspace{14.22636pt} \text{if $L = l$, $l \in pc_1$,}\\ l(V_2) \hspace{14.22636pt} \text{if $L = l$, $l \in pc_2$,}\\ \langle l \,{?}\, l(V_1) \,{:}\, \langle \!\langle T, V_1, V_2,pc_1,pc_2 \rangle \!\rangle \rangle \\ \hspace{34.14322pt} \text{if $L = l.T$, $T \ne []$, $l \in pc_1$,}\\ \langle l \,{?}\, l(V_2) \,{:}\, \langle \!\langle T, V_1, V_2,pc_1,pc_2 \rangle \!\rangle \rangle \\ \hspace{34.14322pt} \text{if $L = l.T$, $T \ne []$, $l \in pc_2$.}\\ \end{array}\right.} \]</span><br />
          </div>
        </div>
        <p></p>
        <p>Notice that the form of the faceted value created by <span class="inline-equation"><span class="tex">$\mathbb {F}(V_1,V_2,pc_1,pc_2)$</span></span> may be suboptimal.</p>
        <div class="example" id="enc14">
          <label>Example 4.2 (Faceted value construction).</label>
          <p>Suppose that <em>V</em> <sub>1</sub> = 2, <em>V</em> <sub>2</sub> = 0, <em>pc</em> <sub>1</sub> = {<em>B</em> <sub>3</sub>, ⊥}, <em>pc</em> <sub>2</sub> = {⊤, <em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>}, <em>List</em>(<em>pc</em> <sub>1</sub>∪<em>pc</em> <sub>2</sub>) is ⊤.<em>B</em> <sub>1</sub>.<em>B</em> <sub>2</sub>.<em>B</em> <sub>3</sub>.⊥, and the lattice <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}_{\text{B}}}, \sqsubseteq \rangle$</span></span> is from Fig.&nbsp;<a class="fig" href="#fig2">2</a>.</p>
          <p>Following the definition of combination of faceted memories, we have <span class="inline-equation"><span class="tex">$\mathbb {F}(2,0,pc_1,pc_2) = \langle \top \,{?}\, 0 \,{:}\, \langle B_1 \,{?}\, 0 \,{:}\, \langle B_2 \,{?}\, 0 \,{:}\, \langle B_3 \,{?}\, 2 \,{:}\, 2 \rangle \rangle \rangle \rangle$</span></span> . This value can be further reduced to ⟨<em>B</em> <sub>1</sub> ? 0 :  ⟨<em>B</em> <sub>2</sub> ? 0 :  2⟩⟩.</p>
        </div>
        <p>We therefore define an optimisation function <span class="inline-equation"><span class="tex">${[[ V,pc]] }$</span></span> that further optimises the result <em>V</em> of a <span class="inline-equation"><span class="tex">$\mathbb {F}()$</span></span> function. The optimisation uses the observation that faceted value returned by <span class="inline-equation"><span class="tex">$\mathbb {F}()$</span></span> has the form of ⟨<em>l</em> ? <em>v</em> :  <em>V</em>′⟩, where <em>V</em>′ is either a simple value or a faceted value <a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>.</p>
        <p>The function <span class="inline-equation"><span class="tex">${[[ V,pc]] }$</span></span> is defined in Fig.&nbsp;<a class="fig" href="#fig9">9</a>. If <em>V</em> is of the form ⟨<em>l</em> ? <em>v</em> :  <em>v</em>′⟩, then the optimisation is straightforward. We now consider the case when <em>V</em> is of the form ⟨<em>l</em> ? <em>v</em> :  ⟨<em>l</em>′ ? <em>v</em>′ :  <em>V</em>′⟩⟩. For demonstration, consider the lattice <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}_{\text{B}}}, \sqsubseteq \rangle$</span></span> from Fig.&nbsp;<a class="fig" href="#fig2">2</a>.</p>
        <p>If the faceted value <em>V</em> is of the form ⟨⊤ ? <em>v</em> :  ⟨<em>B</em> <sub>1</sub> ? <em>v</em> :  <em>V</em>′⟩⟩ (formally, <em>l</em>′⊑<em>l</em> and <em>v</em> = <em>v</em>′), then it can be reduced to <span class="inline-equation"><span class="tex">$[[ \langle B_1 \,{?}\, v \,{:}\, V^{\prime } \rangle ,pc^{\prime }]]$</span></span> (formally, <span class="inline-equation"><span class="tex">$[[ \langle l^{\prime } \,{?}\, v^{\prime } \,{:}\, V^{\prime } \rangle ,pc^{\prime }]]$</span></span> ), where <em>pc</em>′ = <em>pc</em>∖{⊤}.</p>
        <p>If the faceted value <em>V</em> is of the form ⟨<em>B</em> <sub>1</sub> ? <em>v</em> :  ⟨<em>B</em> <sub>2</sub> ? <em>v</em> :  <em>V</em>′⟩⟩, (<em>l</em> and <em>l</em>′ are incomparable and <em>v</em> = <em>v</em>′), and moreover for all the levels in the <em>pc</em>, for which either <em>B</em> <sub>1</sub> or <em>B</em> <sub>2</sub> is visible, it is guaranteed that they observe the same value <em>v</em> (see the definition of <em>cond</em>(<em>V</em>, <em>pc</em>) below), then we distinguish the following two cases.</p>
        <p></p>
        <div class="table-responsive"><img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3185979/images/www18companion-40-display5.jpg" class="img-responsive" alt="" /></div>
        <p></p>
        <ul class="list-no-style">
          <li id="list4" label="•">If all levels in <em>pc</em> are greater than or equal to glb(<em>l</em>, <em>l</em>′) (i.e. glb(<em>l</em>, <em>l</em>′)≼<em>pc</em>), then <em>V</em> is reduced to <em>v</em>. For example, if <em>pc</em> = {<em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>, <em>B</em> <sub>3</sub>}, glb(<em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>) = ⊥, then glb(<em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>)≼<em>pc</em>, and thanks to the <em>cond</em>(<em>V</em>, <em>pc</em>) we know that <em>B</em> <sub>1</sub>(<em>V</em>) = <em>B</em> <sub>2</sub>(<em>V</em>) = <em>B</em> <sub>3</sub>(<em>V</em>) = <em>v</em>, then we can reduce such faceted value to simply <em>v</em> because value <em>V</em>′ is not useful for such <em>pc</em>.<br /></li>
          <li id="list5" label="•">If only some levels in <em>pc</em> are greater than or equal to glb(<em>l</em>, <em>l</em>′) (i.e. <span class="inline-equation"><span class="tex">$\text{glb}(l, l^{\prime }) |||pc$</span></span> ), then <em>V</em> is reduced to ⟨glb(<em>l</em>, <em>l</em>′) ? <em>v</em> :  <em>V</em>′′⟩ and this value is reduced further recursively. Consider that we add one more security level <em>L</em> to the lattice <span class="inline-equation"><span class="tex">$\langle {\mathcal {L}_{\text{B}}}, \sqsubseteq \rangle$</span></span> such that <em>L</em>⊑⊥. If <em>pc</em> = {<em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>, <em>L</em>}, glb(<em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>) = ⊥, then <span class="inline-equation"><span class="tex">$\text{glb}(B_1, B_2) |||pc$</span></span> because <span class="inline-equation"><span class="tex">$\bot \not\sqsubseteq L$</span></span> . We then construct a set of security levels <em>S</em> from <em>pc</em>, which are higher or equal than glb(<em>l</em>, <em>l</em>′), and therefore the view on <em>V</em> from all these levels is <em>v</em> (because <em>cond</em>(<em>V</em>, <em>pc</em>) holds). In our example, <em>S</em> = {<em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>}, and we construct a new faceted value <em>V</em>′′ = ⟨⟨{<em>L</em>}, <em>V</em>′⟩⟩ = <em>L</em>(<em>V</em>′). We then define a new <em>pc</em>′ = (<em>pc</em>∖<em>S</em>) ∪{glb(<em>l</em>, <em>l</em>′)} = {<em>L</em>, ⊥}, and we need to keep glb(<em>l</em>, <em>l</em>′) in <em>pc</em>′ because we must ensure that all the levels present in the new faceted value are also present in <em>pc</em>. Therefore, the reduced faceted value for our example is <span class="inline-equation"><span class="tex">$[[ \langle \bot \,{?}\, v \,{:}\, L(V^{\prime }) \rangle ,\lbrace \bot , L\rbrace ]]$</span></span> .<br /></li>
        </ul>
        <p>Finally, if none of the above conditions hold then we recursively reduce the facet ⟨<em>l</em>′ ? <em>v</em>′ :  <em>V</em>′⟩.</p>
        <p>The correctness of <span class="inline-equation"><span class="tex">$\hat{\mu }_1 \oplus ^{pc_1, pc_2} \hat{\mu }_2$</span></span> in the OIf-S rule is proven in Lemma&nbsp;<a class="enc" href="#enc15">4.3</a>.</p>
        <div class="lemma" id="enc15">
          <label>Lemma 4.3.</label>
          <p>For all levels <em>l</em>, variables <em>x</em>, sets of security levels <em>pc</em> <sub>1</sub> and <em>pc</em> <sub>2</sub>, and memories <span class="inline-equation"><span class="tex">$\hat{\mu }_1$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }_2$</span></span> ,</p>
          <p></p>
          <ul class="list-no-style">
            <li id="list6" label="•">if <em>l</em> ∈ <em>pc</em> <sub>1</sub>, then <span class="inline-equation"><span class="tex">$l(\hat{\mu }_1 \oplus ^{pc_1, pc_2} \hat{\mu }_2)(x) = l(\hat{\mu }_1)(x)$</span></span> ,<br /></li>
            <li id="list7" label="•">if <em>l</em> ∈ <em>pc</em> <sub>2</sub>, then <span class="inline-equation"><span class="tex">$l(\hat{\mu }_1 \oplus ^{pc_1, pc_2} \hat{\mu }_2)(x) = l(\hat{\mu }_2)(x)$</span></span> .<br /></li>
          </ul>
          <p></p>
        </div>
        <div class="example" id="enc16">
          <label>Example 4.4 (Optimisation of faceted value).</label>
          <p>Consider a faceted value ⟨⊤ ? 0 :  ⟨<em>B</em> <sub>1</sub> ? 0 :  ⟨<em>B</em> <sub>2</sub> ? 0 :  ⟨<em>B</em> <sub>3</sub> ? 2 :  2⟩⟩⟩⟩ and <em>pc</em> = {⊤, <em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>, <em>B</em> <sub>3</sub>, ⊥} from Example&nbsp;<a class="enc" href="#enc14">4.2</a>. We show how this value is optimised with our optimisation function <span class="inline-equation"><span class="tex">${[[ ,]] }$</span></span> :</p>
          <p></p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex">$ \begin{array}{lcl}{[[ \langle \top \,{?}\, 0 \,{:}\, \langle B_1 \,{?}\, 0 \,{:}\, \langle B_2 \,{?}\, 0 \,{:}\, \langle B_3 \,{?}\, 2 \,{:}\, 2 \rangle \rangle \rangle \rangle ,\lbrace \top , B_1, B_2, B_3, \bot \rbrace ]] } = \\ = {[[ \langle B_1 \,{?}\, 0 \,{:}\, \langle B_2 \,{?}\, 0 \,{:}\, \langle B_3 \,{?}\, 2 \,{:}\, 2 \rangle \rangle \rangle , \lbrace B_1, B_2, B_3, \bot \rbrace ]] } = \\ = \langle B_1 \,{?}\, 0 \,{:}\, {[[ \langle B_2 \,{?}\, 0 \,{:}\, \langle B_3 \,{?}\, 2 \,{:}\, 2 \rangle \rangle , \lbrace B_2, B_3, \bot \rbrace ]] } \rangle = \\ = \langle B_1 \,{?}\, 0 \,{:}\, \langle B_2 \,{?}\, 0 \,{:}\, {[[ \langle B_3 \,{?}\, 2 \,{:}\, 2 \rangle , \lbrace B_3, \bot \rbrace ]] } \rangle \rangle = \langle B_1 \,{?}\, 0 \,{:}\, \langle B_2 \,{?}\, 0 \,{:}\, 2 \rangle \rangle \end{array}$</span><br />
            </div>
          </div>
          <div class="example" id="enc17">
            <label>Example 4.5 (OGMF is more resource-friendly than GMF).</label>
            <p>Consider the program from Example&nbsp;<a class="enc" href="#enc13">4.1</a>. To show optimisation of OGMF, we evaluate it with <em>pc</em> = {⊤, <em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>, <em>B</em> <sub>3</sub>, ⊥} and <span class="inline-equation"><span class="tex">$\hat{\mu }$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\mu }(x_1) = \langle {B}_1 \,{?}\, 10 \,{:}\, 0 \rangle$</span></span> , <span class="inline-equation"><span class="tex">$\hat{\mu }(x_2) = \langle {B}_2 \,{?}\, 5 \,{:}\, 0 \rangle$</span></span> , and <span class="inline-equation"><span class="tex">$\hat{\mu }(x_3) = \langle {B}_3 \,{?}\, 7 \,{:}\, 0 \rangle$</span></span> . After the execution of the instruction at line 2, the faceted memory is <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime } = \hat{\mu }[\mathit {winner}\mapsto 0,\mathit {test}\mapsto V]$</span></span> , where</p>
            <div class="table-responsive">
              <div class="display-equation">
                <span class="tex mytex">\[ V=\langle B_1 \,{?}\, \langle B_2 \,{?}\, {\textsf {ff}} \,{:}\, {\textsf {ff}} \rangle \,{:}\, \langle B2 \,{?}\, {\textsf {ff}} \,{:}\, \langle B_3 \,{?}\, {\textsf {tt} } \,{:}\, {\textsf {tt} } \rangle \rangle \rangle . \]</span><br />
              </div>
            </div>
            <p></p>
            <p>We consider the execution of the if instruction. For levels <em>pc</em> <sub>1</sub> = {<em>B</em> <sub>3</sub>, ⊥}, the evaluation of <em>test</em> is <span class="inline-equation"><span class="tex">${\textsf {tt} }$</span></span> : <span class="inline-equation"><span class="tex">$B_3(\hat{\mu }^{pc}(\mathit {test})) = \bot (\hat{\mu }^{pc}(\mathit {test})) = {\textsf {tt} }$</span></span> . Moreover, <em>pc</em> <sub>1</sub> ≠ <em>pc</em>, therefore, the rule OIf-S applies. The evaluation of the program is split to two: the first evaluation is with <em>P</em> <sub>1</sub> = <em>winner</em> ≔ 2 and <em>pc</em> <sub>1</sub> = {<em>B</em> <sub>3</sub>, ⊥}; and the second evaluation is with <em>P</em> <sub>2</sub> = <strong> skip</strong> and <em>pc</em> <sub>2</sub> = {⊤, <em>B</em> <sub>1</sub>, <em>B</em> <sub>2</sub>}. Each branch of the conditional will be evaluated only once. The evaluation of <em>P</em> <sub>1</sub> with <em>pc</em> <sub>1</sub> terminates with <span class="inline-equation"><span class="tex">$\hat{\mu }_1^{\prime \prime }(\mathit {winner}) ={{2}}$</span></span> . The evaluation of <em>P</em> <sub>2</sub> with <em>pc</em> <sub>2</sub> terminates with <span class="inline-equation"><span class="tex">$\hat{\mu }_2^{\prime \prime }(\mathit {winner}) = 0$</span></span> . These two faceted memories are combined to <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime \prime }$</span></span> , where <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime \prime }(\mathit {winner}) = \langle B_1 \,{?}\, 0 \,{:}\, \langle B_2 \,{?}\, 0 \,{:}\, 2 \rangle \rangle$</span></span> (as described in Examples&nbsp;<a class="enc" href="#enc14">4.2</a> and&nbsp;<a class="enc" href="#enc16">4.4</a>).</p>
          </div>
          <p>In the example above, OGMF has only two sub-evaluations, while GMF has five, moreover OGMF combines faceted memories once, while GMF combines them four times. Therefore, OGMF is more resource-friendly than GMF.</p>
        </div>
      </section>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Equivalence to SME-TINI and Security Guarantee</h3>
          </div>
        </header>
        <p>We first establish the relation between the standard semantics and the semantics of OGMF.</p>
        <div class="lemma" id="enc18">
          <label>Lemma 4.6.</label>
          <p><span class="inline-equation"><span class="tex">$(P,\hat{\mu })\downarrow _{O}^{pc} \hat{\mu }^{\prime }$</span></span> iff <span class="inline-equation"><span class="tex">$({P},l(\hat{\mu }))\Downarrow l(\hat{\mu }^{\prime })$</span></span> for all <em>l</em> ∈ <em>pc</em>.</p>
        </div>
        <p>We now can prove the semantic equivalence result for OGMF and SME-TINI.</p>
        <div class="theorem" id="enc19">
          <label>Theorem 4.7.</label>
          <p>OGMF and SME-TINI are equivalent.</p>
        </div>
        <p>As a consequence, OGMF and GMF are equivalent even though OGMF is optimized. In addition, OGMF is TINI.</p>
      </section>
    </section>
    <section id="sec-16">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> A termination sensitive version of Multiple Facets</h2>
        </div>
      </header>
      <p>A <em>termination sensitive</em> model assumes that an attacker can observe termination of evaluations. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>], the model is explained further: an attacker at level <em>l</em> can observe the termination of evaluations at level <em>l</em> and lower. In the case of GMF and OGMF, an evaluation marked with <em>pc</em> is <em>an evaluation at <em>l</em></em> if <em>l</em> ∈ <em>pc</em>. Notice that an evaluation is at more than one level whenever <em>pc</em> is not a singleton.</p>
      <p>As illustrated by Example&nbsp;<a class="enc" href="#enc20">5.1</a>, GMF and OGMF do not prevent the influence of private data at higher levels to the termination of the evaluations at lower levels. In other words, GMF and OGMF do not prevent leakage on termination channel [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>].</p>
      <p></p>
      <div class="example" id="enc20">
        <label>Example 5.1.</label>
        <p>Suppose that <span class="inline-equation"><span class="tex">${\mathcal {L}}= \lbrace L,H\rbrace$</span></span> , where <em>L</em>⊑<em>H</em>. We look at the evaluation of <span class="inline-equation"><span class="tex">${\bf if} x {\bf then} ({\bf while}\ {\textsf {tt} }\ {\bf do}\ {\bf skip}) {\bf else} {\bf skip}$</span></span> with <span class="inline-equation"><span class="tex">$pc = {\mathcal {L}}$</span></span> and <span class="inline-equation"><span class="tex">$\hat{\mu }(x) = \langle H \,{?}\, {\textsf {tt} } \,{:}\, {\textsf {ff}} \rangle$</span></span> . When GMF or OGMF is used, the evaluation is split into two: one is with <em>pc</em> <sub>1</sub> = {<em>H</em>}, the other one is with <em>pc</em> <sub>2</sub> = {<em>L</em>}. The evaluation with <em>pc</em> <sub>2</sub> converges, while the evaluation with <em>pc</em> <sub>1</sub> diverges since its executing program is <span class="inline-equation"><span class="tex">${\bf while}\ {\textsf {tt} }\ {\bf do}\ {\bf skip}$</span></span> . Therefore, the evaluation of the whole program with <em>pc</em> = {<em>L</em>, <em>H</em>} also diverges and hence, to an attacker at <em>L</em>, the evaluation at <em>L</em> diverges. However, if the program is evaluated with <span class="inline-equation"><span class="tex">$\hat{\mu }^{\prime }(x) = \langle H \,{?}\, {\textsf {ff}} \,{:}\, {\textsf {ff}} \rangle$</span></span> , to the attacker at <em>L</em>, the evaluation at <em>L</em> converges. Based on observations on those two evaluations, an attacker at <em>L</em> can gain insight about the high facet of <em>x</em>. In other words, GMF and OGMF do not prevent the influence of data at <em>H</em> to the termination of the evaluation at <em>L</em>.</p>
      </div>
      <p></p>
      <p>Therefore, we propose <em>Termination Sensitive Multiple Facets</em> (TSMF), a version of MF that takes into account the termination sensitive model. TSMF is a generalization of a version of MF presented in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0008">8</a>, Appendix A]. The basic idea of TSMF is that when an if instruction is evaluated, TSMF performs a bounded evaluation of the instruction by using OGMF. If the OGMF evaluation does not terminate within the given time bound, then the instruction is evaluated instead using SME semantics with a low-prio scheduler [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]. The security guarantees offered by TSMF are the same as SME with the same low-prio scheduler [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>]. The semantics of TSMF and the proofs about its security guarantees can be found in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0023">23</a>].</p>
    </section>
    <section id="sec-17">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Related Work</h2>
        </div>
      </header>
      <p><em>SME.</em> Devriese and Piessens introduce the idea of Secure Multi-Execution [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>]. Since then, many researchers have developed different aspects of this approach. Close to our work, Kashyap et&nbsp;al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0019">19</a>] discuss how schedulers might affect security guarantees (i.e., TSNI and TINI) based on the chosen scheduler and the lattice ordering. They show several schedulers and classify them according to the strength of security guarantees and according to fairness properties. This work complement theirs by providing a similar analysis but for an interplay of MF and SME semantics. SME [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0014">14</a>] has many implementations: as a library in Haskell [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0018">18</a>], as an experimental web browser based on Firefox [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0013">13</a>], as a static program transformation for both Python and JavaScript [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>], and as an adaptation to reactive systems [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>]. In the work above, SME preserves the semantics of secure programs up to interleaving of events. To remedy that, Zanarini et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0037">37</a>] carefully leverage SME to design a precise monitor which exactly preserves semantics of secure programs <em>up to termination</em>. Several other works [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0033">33</a>] expand SME and introduce declassification. In this work, we focus on semantics guarantees up to interleaving of events—as in the SME original formulation.</p>
      <p><em>MF.</em> Austin and Flanagan introduce MF semantics [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>]—a technique often referred as an optimization for SME. However, as shown by Bielova and Rezk [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0007">7</a>], they do not provide the same security guarantees (i.e., TINI vs. TSNI) and differ in their treatment of default values. This work provides yet another look into a comparison between both techniques to show their differences, while introducing novel value-based optimizations to MF. Another work by the same authors [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0009">9</a>] compare and contrast five dynamic techniques, including MF and SME, to mainly reason about the preservation of semantics of secure programs, a property known as <em>transparency</em>. In this work, we show that GMF and OGMF enjoy the same transparency guarantees as SME-TINI (Theorems <a class="enc" href="#enc11">3.10</a> and <a class="enc" href="#enc19">4.7</a>).</p>
      <p><em>Tools.</em> Most information flow control tools provide TINI, e.g., Jif [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0021">21</a>], FlowCaml [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0025">25</a>], Laminar [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0027">27</a>], Paragon [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0011">11</a>], and JSFlow [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0016">16</a>]. Similarly, termination leaks are often ignored in security tools coming from the operating system research community, e.g., Asbestos [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0015">15</a>], HiStar [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0038">38</a>], and Flume [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0020">20</a>]. A few exceptions to this trend are the security libraries LIO [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0031">31</a>] and MAC [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0028">28</a>], which provide TSNI for concurrent programs.</p>
      <p><em>Decentralized label models.</em> The decentralized label model (DLM), allows one to express the interests of mutually-distrusting principals without a central authority [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0022">22</a>]. The set of labels forms a pre-order where the order relationship does not require to know all the points in the relationship to determine the result of comparing two labels—bearing in mind that there might be an infinite number of labels due to the dynamic creation of principals at runtime. In a similar spirit, DC-labels [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0034">34</a>] provides a decentralized label format which allows one to express rich policies dictated by mutually-distrusting principals as propositional logic formulas (without negation). In this work, we require to know all the points in the chosen lattice in order to optimize MF as shown by OGMF. Extending our techniques to DLM or DC-labels is an interesting direction for future work.</p>
    </section>
    <section id="sec-18">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span> Conclusion and Perspectives</h2>
        </div>
      </header>
      <p>This work contributes to develop techniques to secure programs using dynamic information flow—a promising approach to secure existing JavaScript code. We specially focus on proposing a technique that achieves a smaller number of executions than MF (and hence smaller memory footprint) without diminishing security guarantees. We further extend our MF-based technique to work with arbitrary finite lattices (GMF) based on the observation that off-the-shelf lattices with principals are not always the most convenient ones to use. Knowing all the points in the lattice allows for further optimizations: spawning multi-executions could be done on a value-based basis (OGMF) rather than on security levels—as in original MF. Finally, we propose a hybrid approach which present an interesting balance between the number of executions and security guarantees: it behaves as OGMF as long as it can and switches to SME when termination leaks could occur (TSMF). In other words, TSMF prioritizes resource usage as long as there are no risks for termination leaks. We expect that these insights will help inform future development of multi-execution-based techniques. In fact, an intriguing question is what it would take for our optimizations (or future ones) to work on potentially infinite lattices like the DLM or DC-labels—an interesting direction for future work.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="sec-19">
      <header>
        <div class="title-info">
          <h2>ACKNOWLEDGMENTS</h2>
        </div>
      </header>
      <p>We would like to thank anonymous reviewers for feedback that helped to improve this paper. This research has been partially supported by the ANR projects AJACS ANR-14-CE28-0008, CISC ANR-17-CE25-0014-01, the National Science Foundation under grants CCF-1337278 and CCF-1421016, and Swedish research agencies Vetenskapsrådet and SSF Cyber Security projects WebSec: Securing Web-driven Systems and Octopi: Secure Programming for the Internet of Things.</p>
    </section>
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Thomas&nbsp;H. Austin and Cormac Flanagan. 2009. Efficient Purely-dynamic Information Flow Analysis. In <em><em>Proc. of PLAS 2009</em></em> (<em>PLAS ’09</em>). 113–124.</li>
        <li id="BibPLXBIB0002" label="[2]">Thomas&nbsp;H. Austin and Cormac Flanagan. 2010. Permissive Dynamic Information Flow Analysis. In <em><em>Proc. of PLAS 2010</em></em> (<em>PLAS ’10</em>). 1–12.</li>
        <li id="BibPLXBIB0003" label="[3]">Thomas&nbsp;H. Austin and Cormac Flanagan. 2012. Multiple Facets for Dynamic Information Flow. In <em><em>Proc. of POPL 2012</em></em> (<em>POPL ’12</em>). 165–178.</li>
        <li id="BibPLXBIB0004" label="[4]">Gilles Barthe, Juan&nbsp;Manuel Crespo, Dominique Devriese, Frank Piessens, and Exequiel Rivas. 2012. Secure multi-execution through static program transformation. In <em><em>Formal Techniques for Distributed Systems</em></em> . Springer, 186–202.</li>
        <li id="BibPLXBIB0005" label="[5]">Abhishek Bichhawat, Vineet Rajani, Deepak Garg, and Christian Hammer. 2014. Generalizing Permissive-Upgrade in Dynamic Information Flow Analysis. In <em><em>Proc. of PLAS 2014</em></em> (<em>PLAS’14</em>). 15–24.</li>
        <li id="BibPLXBIB0006" label="[6]">N. Bielova, D. Devriese, F. Massacci, and F. Piessens. 2011. Reactive non-interference for a Browser model. In <em><em>Proc. of NSS 2011</em></em> . 97–104.</li>
        <li id="BibPLXBIB0007" label="[7]">Nataliia Bielova and Tamara Rezk. 2016. Spot the Difference: Secure Multi-execution and Multiple Facets. In <em><em>Proc. of ESORICS 2016</em></em> . 501–519.</li>
        <li id="BibPLXBIB0008" label="[8]">Nataliia Bielova and Tamara Rezk. 2016. <em><em>Spot the Difference: Secure Multi-Execution and Multiple Facets</em></em> . Technical Report. https://goo.gl/b7yoQ9.</li>
        <li id="BibPLXBIB0009" label="[9]">Nataliia Bielova and Tamara Rezk. 2016. A Taxonomy of Information Flow Monitors. In <em><em>Proc. of POST 2016</em></em> . 46–67.</li>
        <li id="BibPLXBIB0010" label="[10]">Iulia Boloşteanu and Deepak Garg. 2016. Asymmetric Secure Multi-execution with Declassification. In <em><em>Proc. of POST 2016</em></em> . 24–45.</li>
        <li id="BibPLXBIB0011" label="[11]">Niklas Broberg, Bart van Delft, and David Sands. 2013. Paragon for Practical Programming with Information-Flow Control.. In <em><em>Proc. of APLAS 2013</em></em> (<em>LNCS</em>), Vol.&nbsp;8301. Springer, 217–232.</li>
        <li id="BibPLXBIB0012" label="[12]">Stefano Calzavara, Alvise Rabitti, and Michele Bugliesi. 2016. Content Security Problems?: Evaluating the Effectiveness of Content Security Policy in the Wild. In <em><em>Proc. of CCS 2016</em></em> (<em>CCS ’16</em>). 1365–1375.</li>
        <li id="BibPLXBIB0013" label="[13]">Willem De&nbsp;Groef, Dominique Devriese, Nick Nikiforakis, and Frank Piessens. 2012. FlowFox: a web browser with flexible and precise information flow control. In <em><em>Proc. of CCS 2012</em></em> . ACM, 748–759.</li>
        <li id="BibPLXBIB0014" label="[14]">Dominique Devriese and Frank Piessens. 2010. Noninterference Through Secure Multi-execution. In <em><em>Proc. of IEEE SP 2010</em></em> (<em>SP ’10</em>). 109–124.</li>
        <li id="BibPLXBIB0015" label="[15]">Petros Efstathopoulos, Maxwell Krohn, Steve VanDeBogart, Cliff Frey, David Ziegler, Eddie Kohler, David Mazières, Frans Kaashoek, and Robert Morris. 2005. Labels and event processes in the Asbestos operating system. In <em><em>Proc. of SOSP 2005</em></em> (<em>SOSP</em>). ACM.</li>
        <li id="BibPLXBIB0016" label="[16]">D. Hedin, A. Birgisson, L. Bello, and A. Sabelfeld. 2014. JSFlow: Tracking information flow in JavaScript and its APIs. In <em><em>Proc. of SAC 2014</em></em> . ACM.</li>
        <li id="BibPLXBIB0017" label="[17]">Collin Jackson and Adam Barth. 2008. Beware of Finer-Grained Origins. In <em><em>Web 2.0 Security and Privacy</em></em> (<em>W2SP’08</em>).</li>
        <li id="BibPLXBIB0018" label="[18]">Mauro Jaskelioff and Alejandro Russo. 2011. Secure multi-execution in haskell. In <em><em>International Andrei Ershov Memorial Conference on Perspectives of System Informatics</em></em> . Springer, 170–178.</li>
        <li id="BibPLXBIB0019" label="[19]">Vineeth Kashyap, Ben Wiedermann, and Ben Hardekopf. 2011. Timing- and Termination-Sensitive Secure Information Flow: Exploring a New Approach. In <em><em>Proc. of IEEE SP 2011</em></em> (<em>SP ’11</em>). 413–428.</li>
        <li id="BibPLXBIB0020" label="[20]">Maxwell Krohn, Alexander Yip, Micah Brodsky, Natan Cliffer, M.&nbsp;Frans Kaashoek, Eddie Kohler, and Robert Morris. 2007. Information Flow Control for Standard OS Abstractions. In <em><em>Proc. of SOSP 2007</em></em> (<em>SOSP</em>).</li>
        <li id="BibPLXBIB0021" label="[21]">Andrew&nbsp;C Myers. 1999. JFlow: Practical mostly-static information flow control. In <em><em>Proc. of POPL 1999</em></em> . ACM, 228–241.</li>
        <li id="BibPLXBIB0022" label="[22]">Andrew&nbsp;C Myers and Barbara Liskov. 2000. Protecting privacy using the decentralized label model. <em><em>ACM Transactions on Software Engineering and Methodology (TOSEM)</em></em> 9, 4(2000), 410–442.</li>
        <li id="BibPLXBIB0023" label="[23]">Minh Ngo, Nataliia Bielova, Cormac Flanagan, Tamara Rezk, Alejandro Russo, and Thomas Schmitz. 2017. A Better Facet of Dynamic Information Flow Control. (2017). <a class="link-inline force-break" href="https://goo.gl/Y2SEnw">https://goo.gl/Y2SEnw</a>.
        </li>
        <li id="BibPLXBIB0024" label="[24]">Minh Ngo, Fabio Massacci, Dimiter Milushev, and Frank Piessens. 2015. Runtime Enforcement of Security Policies on Black Box Reactive Programs. In <em><em>Proc. of POPL 2015</em></em> .</li>
        <li id="BibPLXBIB0025" label="[25]">F. Pottier and V. Simonet. 2002. Information Flow Inference for ML. In <em><em>ACM Symp. on Principles of Programming Languages</em></em> . 319–330.</li>
        <li id="BibPLXBIB0026" label="[26]">Willard Rafnsson and Andrei Sabelfeld. 2013. Secure Multi-execution: Fine-Grained, Declassification-Aware, and Transparent. In <em><em>Proc. of CSF 2013</em></em> . 33–48.</li>
        <li id="BibPLXBIB0027" label="[27]">Indrajit Roy, Donald&nbsp;E. Porter, Michael&nbsp;D. Bond, Kathryn&nbsp;S. McKinley, and Emmett Witchel. 2009. Laminar: Practical Fine-grained Decentralized Information Flow Control. In <em><em>Proc. of PLDI 2009</em></em> (<em>PLDI</em>). ACM.</li>
        <li id="BibPLXBIB0028" label="[28]">Alejandro Russo. 2015. Functional Pearl: Two Can Keep a Secret, if One of Them Uses Haskell. In <em><em>Proc. of ICFP 2015</em></em> (<em>ICFP</em>). ACM.</li>
        <li id="BibPLXBIB0029" label="[29]">José&nbsp;Fragoso Santos, Thomas Jensen, Tamara Rezk, and Alan Schmitt. 2015. Hybrid Typing of Secure Information Flow in a JavaScript-Like Language. In <em><em>Proc. of TGC 2015</em></em> . 63–78.</li>
        <li id="BibPLXBIB0030" label="[30]">Dolière&nbsp;Francis Some, Nataliia Bielova, and Tamara Rezk. 2017. On the Content Security Policy Violations Due to the Same-Origin Policy. In <em><em>Proc. of WWW 2017</em></em> (<em>WWW ’17</em>). 877–886.</li>
        <li id="BibPLXBIB0031" label="[31]">Deian Stefan, Alejandro Russo, Pablo Buiras, Amit Levy, John&nbsp;C Mitchell, and David Mazieres. 2012. Addressing covert termination and timing channels in concurrent information flow systems. In <em><em>Proc. of ICFP 2012</em></em> , Vol.&nbsp;47. ACM, 201–214.</li>
        <li id="BibPLXBIB0032" label="[32]">D. Stefan, A. Russo, D. Mazières, and J.&nbsp;C. Mitchell. 2011. Disjunction Category Labels. In <em><em>Proc. of NordSec 2011</em></em> . Springer-Verlag.</li>
        <li id="BibPLXBIB0033" label="[33]">Mathy Vanhoef, Willem De&nbsp;Groef, Dominique Devriese, Frank Piessens, and Tamara Rezk. 2014. Stateful Declassification Policies for Event-Driven Programs. In <em><em>Proc. of CSF 2014</em></em> (<em>CSF ’14</em>). 293–307.</li>
        <li id="BibPLXBIB0034" label="[34]">Lucas Waye, Pablo Buiras, Dan King, Stephen Chong, and Alejandro Russo. 2015. It's My Privilege: Controlling Downgrading in DC-Labels. In <em><em>International Workshop on Security and Trust Management</em></em> .</li>
        <li id="BibPLXBIB0035" label="[35]">Wikipedia. 2017. Ad exchange. (2017). <a class="link-inline force-break" href="https://en.wikipedia.org/wiki/Ad_exchange">https://en.wikipedia.org/wiki/Ad_exchange</a>. Checked on Nov 08, 2017.
        </li>
        <li id="BibPLXBIB0036" label="[36]">Wikipedia. 2017. Real-time bidding. (2017). <a class="link-inline force-break" href="https://en.wikipedia.org/wiki/Real-time_bidding">https://en.wikipedia.org/wiki/Real-time_bidding</a>. Checked on Nov 08, 2017.
        </li>
        <li id="BibPLXBIB0037" label="[37]">Dante Zanarini, Mauro Jaskelioff, and Alejandro Russo. 2013. Precise enforcement of confidentiality for reactive systems. In <em><em>Proc. of CSF 2013</em></em> . IEEE, 18–32.</li>
        <li id="BibPLXBIB0038" label="[38]">Nickolai Zeldovich, Silas Boyd-Wickizer, Eddie Kohler, and David Mazières. 2006. Making information flow explicit in HiStar. In <em><em>USENIX Symp. on Operating Systems Design and Implementation</em></em> . USENIX.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>We give here the termination insensitive version of SME.</p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>The values and default values for <em>x</em> <sub>1</sub> and <em>x</em> <sub>2</sub> are chosen so that the value of <em>x</em> after the evaluation of the assignment instruction is <span class="inline-equation"><span class="tex">$\langle M_1 \,{?}\, \langle H \,{?}\, {\textsf {tt} } \,{:}\, {\textsf {ff}} \rangle \,{:}\, {\textsf {tt} } \rangle$</span></span> .</p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>The function <span class="inline-equation"><span class="tex">$\mathbb {F}()$</span></span> cannot return a simple value since it is called on non-empty <em>pc</em> <sub>1</sub> and <em>pc</em> <sub>2</sub>.</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&nbsp;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>
      <p><em>WWW '18 Companion, April 23–27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&nbsp;4.0 License.<br />
      ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3184558.3185979">https://doi.org/10.1145/3184558.3185979</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
