<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Network Embedding Based Recommendation Method in Social Networks</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Network Embedding Based Recommendation Method in Social Networks</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Yufei</span>      <span class="surName">Wen</span>     Shandong Normal University, No.88 East Wenhua RoadJinan, China 250014, <a href="mailto:wenyufei92@sina.com">wenyufei92@sina.com</a>     </div>     <div class="author">     <span class="givenName">Lei</span>      <span class="surName">Guo</span>     Shandong Normal University, No.88 East Wenhua RoadJinan, China 250014<a class="fn" href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>, <a href="mailto:leiguo.cs@gmail.com">leiguo.cs@gmail.com</a>     </div>     <div class="author">     <span class="givenName">Zhumin</span>      <span class="surName">Chen</span>     Shandong University, No. 27 Shanda NanluJinan, China 250100, <a href="mailto:chenzhumin@sdu.edu.cn">chenzhumin@sdu.edu.cn</a>     </div>     <div class="author"><a href="../../../data/deliveryimages.acm.org/10.1145/3190000/3186904/" ref="author"><span class="givenName">Jun</span>      <span class="surName">Ma</span></a>     Shandong University, No. 27 Shanda NanluJinan, China 250100, <a href="mailto:majun@sdu.edu.cn">majun@sdu.edu.cn</a>     </div>            </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3186904" target="_blank">https://doi.org/10.1145/3184558.3186904</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>With the advent of online social networks, the use of information hidden in social networks for recommendation has been extensively studied. Unlike previous work regarded social influence as regularization terms, we take advantage of network embedding techniques and propose an embedding based recommendation method. Specifically, we first pre-train a network embedding model on the users&#x2019; social network to map each user into a low dimensional space, and then incorporate them into a matrix factorization model, which combines both latent and pre-learned features for recommendation. The experimental results on two real-world datasets indicate that our proposed model is more effective and can reach better performance than other related methods.</small>     </p>    </div>    <div class="CCSconcepts">     <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Data mining;</strong> <em>Collaborative filtering;</em></small> </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Social Recommendation</small>, </span>     <span class="keyword">      <small> Network Embedding</small>, </span>     <span class="keyword">      <small> Matrix Factorization</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Yufei Wen, Lei Guo, Zhumin Chen, and Jun Ma. 2018. Network Embedding Based Recommendation Method in Social Networks. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 2 Pages. <a href="https://doi.org/10.1145/3184558.3186904" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3186904</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-3">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>In social networks, users are more likely to seek suggestions from their friends. Social relationships provide an independent source of information about users beyond rating information. Therefore, how to utilize social information to assist recommendation has been widely studied in recent years [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>]. For example, Mohsen et al.[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>] incorporated the mechanism of trust propagation into Matrix Factorization (MF) to predict the behavior of users. However, most of these existing works mainly regard social influence as regularization terms, and the deeper structural information of social networks has not been fully explored.</p>    <p>Motivated by the success of network embedding techniques, we first pre-train the network embedding model node2vec[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>] to learn high-level network representations from social relations, and then incorporate them into the MF based model. By combining the latent and pre-learned network features together, our method not only can make use of the social network information deeply, but also can take advantage of the collaborative filtering model for recommendation. Experimental results on two real-world datasets demonstrate the effectiveness of our proposed approach.</p>   </section>   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Recommendation Method</h2>     </div>    </header>    <p>In this section, we first introduce the classic latent factor model, and then focus on how to combine the pre-trained network representations into MF to conduct social recommendation.</p>    <section id="sec-5">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Low-rank Matrix Factorization Model</h3>     </div>     </header>     <p>Let <span class="inline-equation"><span class="tex">$\mathcal {U}$</span>     </span>={<em>u</em>     <sub>1</sub>...<em>u<sub>M</sub>     </em>} denote the user set, <span class="inline-equation"><span class="tex">$\mathcal {I}$</span>     </span>={<em>i</em>     <sub>1</sub>...<em>i<sub>N</sub>     </em>} denote the item set, and <em>R</em> = [<em>R</em>     <sub>      <em>u</em>, <em>i</em>     </sub>]<sub>      <em>M</em> &#x00D7; <em>N</em>     </sub> denote the user-item rating matrix, where <em>R</em>     <sub>      <em>u</em>, <em>i</em>     </sub> represents the ratings of user <em>u</em> on item <em>i</em>. A low-rank matrix factorization approach seeks to approximate the rating matrix <em>R</em> by a multiplication of <em>k</em>-rank factors, and its objective function can be arrived as: <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \min _{U, I}\frac{1}{|D|}\sum _{(u,i)\in D}\mathcal {L}(R_{u,i},\widehat{R}_{u,i}(U, I))+\Omega (U, I) \end{equation} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div> Where <em>D</em> is the observed user-item rating pairs, <em>U</em> and <em>I</em> are the latent feature factors of users and items, with column vectors <span class="inline-equation"><span class="tex">$U_u \in \mathbb {R}^k$</span>     </span> and <span class="inline-equation"><span class="tex">$I_i\in \mathbb {R}^k$</span>     </span> representing user-specific and item-specific feature vectors, respectively. <span class="inline-equation"><span class="tex">$\widehat{R}_{u,i}(U, I) =U^T_ u I_i$</span>     </span> is the predicted score for the dyad (<em>u</em>, <em>i</em>), <span class="inline-equation"><span class="tex">$\mathcal {L}(\cdot ,\cdot)$</span>     </span> is the square loss function, and <span class="inline-equation"><span class="tex">$\Omega (U,I)=\frac{\lambda _U}{2}\Vert U\Vert ^2_F+\frac{\lambda _I}{2}\Vert I\Vert ^2_F$</span>     </span> is the corresponding regularization term.</p>    </section>    <section id="sec-6">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Combined with Pre-learned Features</h3>     </div>     </header>     <p>As users in social networks often express their social interest by making different friends, a better understanding of these social networks is potentially helpful for recommendation. Let <span class="inline-equation"><span class="tex">$\mathcal {G}$</span>     </span> present the social relationships among users, where an edge denotes there is a friend relationship between user <em>u</em> and <em>v</em>. To mine the deep social structure from <span class="inline-equation"><span class="tex">$\mathcal {G}$</span>     </span>, we introduce the network embedding model node2vec[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>] to learn the high-level user representations<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a>, and let <span class="inline-equation"><span class="tex">$X_u\in \mathbb {R}^d$</span>     </span> represent the learned feature vector of user <em>u</em>, which denotes how well a user is influenced by his friends in graph <span class="inline-equation"><span class="tex">$\mathcal {G}$</span>     </span>. By fusing these pre-trained features with the latent features from collaborative filtering model linearly, we can arrive at our embedding based recommendation method MFn2v: <div class="table-responsive" id="eq1">      <div class="display-equation">       <span class="tex mytex">\begin{eqnarray} \mathcal {L}(U,I,W)&#x0026;=&#x0026;\min _{U,I,W}\frac{1}{2}\sum _{u=1}^M\sum _{i=1}^N(R_{u,i}-U_u^TI_i-W_u^TX_u)^2\nonumber \\ &#x0026;&#x0026;+\frac{\lambda _U}{2}\Vert U\Vert ^2_F+\frac{\lambda _I}{2}\Vert I\Vert ^2_F+ \frac{\lambda _W}{2}\Vert W\Vert ^2_F \end{eqnarray} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$W_u\in \mathbb {R}^d$</span>     </span> is the weighted vector that indicates how much the pre-trained network features should contribute to user <em>u</em>.</p>     <p>We apply stochastic gradient descent method to find a local minimum of Eq. <a class="eqn" href="#eq1">2</a>, and update the latent factors <em>U</em>, <em>I</em> and <em>W</em> by the following gradients: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{align*} &#x0026;\frac{\partial \mathcal {L}(U,I,W)}{\partial U_u}=\sum _{i=1}^N(U_u^TI_i+W_u^TX_u-R_{u,i})I_i+\lambda _UU_u\\ &#x0026;\frac{\partial \mathcal {L}(U,I,W)}{\partial I_i}=\sum _{u=1}^M(U_u^TI_i+W_u^TX_u-R_{u,i})U_u+\lambda _II_i\\ &#x0026;\frac{\partial \mathcal {L}(U,I,W)}{\partial W_u}=\sum _{i=1}^N(U_u^TI_i+W_u^TX_u-R_{u,i})X_u+\lambda _WW_u\\\end{align*} </span>       <br/>      </div>     </div>     </p>    </section>   </section>   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Evaluation</h2>     </div>    </header>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Experimental Setup and Comparisons</h3>     </div>     </header>     <p>We utilize two real-world datasets (Ciao and Epinions) to evaluate our recommendation method, and for Ciao[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>] the latent factor dimension <em>k</em> is set as 15 and the regularization parameters are set as <em>&#x03BB;<sub>U</sub>     </em> = <em>&#x03BB;<sub>I</sub>     </em> = 0.6 and <em>&#x03BB;<sub>W</sub>     </em> = 0.001. For Epinions[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>], the parameters are set as: <em>k</em> =15, <em>&#x03BB;<sub>U</sub>     </em> = <em>&#x03BB;<sub>I</sub>     </em> = 0.6, <em>&#x03BB;<sub>W</sub>     </em> = 0.005.</p>     <p>For both of these two datasets, 80% of randomly selected ratings are used for training, and RMSE and MAE[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>] are utilized as the evaluation metrics. In this work, we compare our method with three related approaches: MF, LFL[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>] and SocialMF[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>].</p>     <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">The Performance Comparison on Ciao and Epinion</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">Dataset</td>        <td style="text-align:center;">Metrics</td>        <td style="text-align:center;">MF</td>        <td style="text-align:center;">LFL</td>        <td style="text-align:center;">SocialMF</td>        <td>MFn2v</td>       </tr>       <tr>        <td style="text-align:center;">Ciao</td>        <td style="text-align:center;">MAE</td>        <td style="text-align:center;">0.782</td>        <td style="text-align:center;">0.760</td>        <td style="text-align:center;">0.755</td>        <td>0.746</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">RMSE</td>        <td style="text-align:center;">1.006</td>        <td style="text-align:center;">1.002</td>        <td style="text-align:center;">0.990</td>        <td>0.974</td>       </tr>       <tr>        <td style="text-align:center;">Epinions</td>        <td style="text-align:center;">MAE</td>        <td style="text-align:center;">0.846</td>        <td style="text-align:center;">0.842</td>        <td style="text-align:center;">0.830</td>        <td>0.823</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">RMSE</td>        <td style="text-align:center;">1.086</td>        <td style="text-align:center;">1.070</td>        <td style="text-align:center;">1.062</td>        <td>1.058</td>       </tr>      </tbody>     </table>     </div>     <p>The experimental results are shown in Table <a class="tbl" href="#tab1">1</a>, from which we can find: As MF only uses the rating information for recommendation, it does worse than other methods. The state-of-the-art social recommendation method SocialMF achieves a better performance than both MF and LFL, which demonstrates the social relationship is helpful to model users&#x2019; preference. From this result, we can also find that our proposed method MFn2v can perform better than SocialMF, and reach the best performance in experiments, which indicates that fusing the pre-trained embedding with latent factors is helpful, and can effectively model both the users&#x2019; personal and social interests.</p>    </section>    <section id="sec-9">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Convergence Analysis</h3>     </div>     </header>     <p>To explore the efficiency of our model, we further conduct experiments to compare the convergence of our MFn2v method with MF method on Ciao. To make them comparable, same learning rates are adopted. Fig. <a class="fig" href="#fig1">1</a> shows the comparison results, from which we can observe both these two methods converge very fast (converge within 80 iterations). The convergence rate of MFn2v is not slowed down by incorporating the social network representations, on the contrary it can make a better performance than MF method (Similar results can also be reached on the Epinions data). <figure id="fig1">      <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186904/images/www18companion-144-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 1:</span>       <span class="figure-title">Convergence analysis on the Ciao data (a) RMSE (b) MAE.</span>      </div>     </figure>     </p>    </section>   </section>  </section>  <section class="back-matter">   <section id="sec-10">    <header>     <div class="title-info">     <h2>ACKNOWLEDGMENTS</h2>     </div>    </header>    <p>This work is supported by the Natural Science Foundation of China (Nos. 61602282, 61672324, 61672322), and the China Postdoctoral Science Foundation (No. 2016M602181).</p>   </section>   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">A Grover and J Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In <em>      <em>KDD</em>     </em>. ACM, 855&#x2013;864.</li>     <li id="BibPLXBIB0002" label="[2]">Mohsen Jamali and Martin Ester. 2010. A matrix factorization technique with trust propagation for recommendation in social networks. In <em>      <em>RecSys</em>     </em>. ACM, 135&#x2013;142.</li>     <li id="BibPLXBIB0003" label="[3]">Jarana Manotumruksa, Craig Macdonald, and Iadh Ounis. 2016. Regularising Factorised Models for Venue Recommendation using Friends and their Comments. In <em>      <em>CIKM</em>     </em>. ACM, 1981&#x2013;1984.</li>     <li id="BibPLXBIB0004" label="[4]">Aditya&#x00A0;Krishna Menon and Charles Elkan. 2011. A Log-Linear Model with Latent Features for Dyadic Prediction. In <em>      <em>ICDM</em>     </em>. IEEE, 364&#x2013;373.</li>     <li id="BibPLXBIB0005" label="[5]">Suhang Wang, Jiliang Tang, and Huan Liu. 2015. Toward dual roles of users in recommender systems. In <em>      <em>CIKM</em>     </em>. ACM, 1651&#x2013;1660.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>Corresponding author</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a>The parameter settings of our pre-trained node2vec model are: <em>d</em> = 10; <em>l</em> = 80; <em>r</em> = 10; <em>k</em> = 10; <em>p</em> = 1; <em>q</em> = 0.5.</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186904">https://doi.org/10.1145/3184558.3186904</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
