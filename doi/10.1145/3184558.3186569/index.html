<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>Compromised Account Detection Based on Clickstream Data</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main">  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">Compromised Account Detection Based on Clickstream Data</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author"><a href="https://orcid.org/1234-5678-9012" ref="author"><span class="givenName">Tobias</span>      <span class="surName">Weller</span></a><a class="fn" 		  href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>,     Institute AIFB (KIT), Karlsruhe, Germany, <a href="mailto:tobias.weller@kit.edu">tobias.weller@kit.edu</a>    </div>        </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3184558.3186569" target="_blank">https://doi.org/10.1145/3184558.3186569</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>The number of users of the world wide web is constantly increasing. However, this also increases the risks. There is the possibility that other users illegally gain access to a users&#x2019; account of social networks, web shops or other web services. Previous work use graph-based methods to identify hijacked or compromised accounts. Most often posts are used in social networks to detect fraudulences. However, not every compromised account is used to spread propaganda information or phishing attacks. Therefore, we restrict ourselves to the clickstreams from the accounts. In order to identify compromised accounts by means of clickstreams, we will also consider a temporal aspect, since the preferences of a user change over time. We choose a hybrid approach consisting of methods from subsymbolic and symbolic AI to detect fraudulences in clickstreams. We will also take into account the experience of domain experts. Our approach can also be used to identify not only compromised accounts but also shared accounts on instance streaming sites.</small>    </p>    </div>    <div class="CCSconcepts">    <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Web log analysis;</strong> &#x2022;<strong> Security and privacy </strong>&#x2192; <strong>Intrusion/anomaly detection and malware mitigation;</strong> &#x2022;<strong> Social and professional topics </strong>&#x2192; <em>Identity theft;</em> &#x2022;<strong> Mathematics of computing </strong>&#x2192; Probabilistic representations;</small> </p>    </div>    <div class="classifications">    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Tobias Weller. 2018. Compromised Account Detection Based on Clickstream Data. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 5 Pages. <a href="https://doi.org/10.1145/3184558.3186569" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3184558.3186569</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <p>Clickstream Analysis, Clickstream Fraud Detection, Anomaly Detection, Machine Learning</p>   <section id="sec-2">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Problem</h2>    </div>    </header>    <p>The Internet serves as a worldwide interconnection of individual networks. The number of users participating in this network increased since its beginning in 1994. Currently, 4,157 million users are estimated to use the world wide web<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a>. At the same time are the number of users in social networks<a class="fn" href="#fn3" id="foot-fn3"><sup>2</sup></a> such as Facebook and Twitter increasing, as is the number of digital buyers<a class="fn" href="#fn4" id="foot-fn4"><sup>3</sup></a> in web shops such as Amazon and Alibaba. All these networks have in common that users have to login to use the application in full. These accounts are in particular interested for hackers. Hackers try to gain unnoticed access to the users&#x2019; accounts in order to use them for their criminal activities. These hijacked accounts are among others used for phishing attacks, cyber crime-related scams, spam campaigns and spreading propaganda information.</p>    <p>However, there is also a preliminary stage, even before hijacked accounts, namely compromised accounts. Compromised accounts are those accounts whose passwords are unnoticedly available to others, so that these people can gain access to the account unnoticed. In this case, the hackers often just try to gather as much information as possible and log out, without posting or to inflict further harm. Often the affected users are not aware of the fact that their account has been compromised. Therefore are indicators and measures needed to identify compromised accounts or abnormally movements of users. Methods that evaluate the users&#x2019; postings to determine a compromise are unsuitable for this use case. Current approaches like sending emails when logging in from unknown clients, like Facebook or Google does, are only of limited use. Users are annoyed by those emails or remain unnoticed in the inbox.</p>    <p>A related use case, which is similar, is the detection of shared accounts. Often are users sharing their accounts so that two or more persons use the same account. On the one hand, provider of web solutions may not be interested in users sharing their accounts with others, but on the other hand, it might be interesting for those providers to identify the currently browsing person and make targeted advertising or recommendations. This way, you could advertise or recommend on the basis of the person who is currently using the account and not on the basis of the account itself. For example, when using a family Amazon account you could try to identify and address the person yourself. Figure&#x00A0;<a class="fig" href="#fig1">1</a> summarizes the two possible use cases. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186569/images/www18companion-123-fig1.jpg" class="img-responsive" alt="Figure 1"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Two use cases can be tackled with this work. Use Case A: Identification of a shared account person. Use Case B: Detection of a compromised account.</span>     </div>    </figure>    </p>   </section>   <section id="sec-3">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> State of the art</h2>    </div>    </header>    <p>Within this work, three topics are dealt with. These are fraud and anomaly detection, web log analysis and to a small extent data modeling and reasoning. In the following we will show how current research is dealing with these topics.</p>    <p>In the area of socially compromised accounts, the posts of the users are often analyzed to detect changes of content, as a compromise indication&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>]. Most work investigates behavioral changes. Thereby statistical methods are used to recognize these. Bayesian models are used to identify anomalies in graphs at discrete times&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>]. Hereby, the network structure of the social network is exploited. Similarity analysis is also used to detect compromises in individual accounts&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>]. In contrast to fraud detection in social networks, similar methods are used to detect anomalies in online advertising. Providers of an Internet platform receive a commission for each successful click on an advertisement. The providers try to increase their commission by fraudulent clicks in these so-called pay-per-click models. Subject of the research was to identify these fraudulent clicks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>]. Here, however, the focus is on identifying duplicates rather than a sequence of clicks. Association rules are also used for fraud detection in advertising networks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>]. Just as in social networks, graph-based methods are used to detect anomalies in graph-based data. A few works often use two techniques&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>]. On the one hand a technique to identify regularities in graphs to identify the normality. And secondly, techniques to identify anomalies, i. e. deviations from the standard.</p>    <p>Fraud detection is also subject in identifying anomalies in UNIX commands. Hereby, sequences of commands of users are compared by using similarity measures to the profile of an user&#x0027;s command sequence&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>]. Other techniques on the server side use text mining methods for intrusion detection&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>]. Another technique is the use of Neural Networks for intrusion detection. This is called NNID (Neural Network Intrusion Detector)&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>]. Here, the presumption is that each user leaves a fingerprint on the server, which is basically the same assumption as we do, but ours is based on clickstreams. A Neural Network is used to learn the print and identify users, based on these prints. If a user&#x0027;s behavior does not match to his print, then his account is classified as a possible security breech. Surveys provide a comprehensive overview of anomaly and intrusion detection systems. In addition, trends are discussed&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>].</p>    <p>Besides the identification of anomalies of a user in social networks or on servers, fraud detection was often used in the financial sector. Many works use neural networks for fraud detection. Some of them operate in online systems&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>]. Besides this, data mining techniques and neural network algorithms were combined successfully to obtain a high fraud coverage, combined with a low false alarm rate&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>]. Within these works, the time aspect in financial fraud detection is always considered&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>]. Surveys in the field of financial fraud detection summarizes applied methods from the past&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>]. The surveys shows that mining algorithms, statistical tests, regression analysis, neural networks, decision trees and Bayesian networks are used for fraud detection. Moreover, the surveys show that in general, the detecting effect and accuracy of neural networks are superior to regression model.</p>    <p>As seen, clickstreams to identify compromised accounts has not been subject matter of research. However, web logs have been analyzed for various reasons. AltaVista Search Engine query logs had been analyzed. Hereby, correlation analysis were used to analyze log entries and studying the interaction of terms within queries&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>]. A further analysis of transaction logs of a korean web search engine (NAVER) shows that user&#x0027;s behave in a simple way&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>]. Other work uses unsupervised algorithms to cluster users, based on online transaction data from an university. In addition, filters and combinations had been presented&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>]. Matrix clustering was successfully implemented for representing relationships between pages and users in a binary matrix from Web access logs. The page clusters extracted by matrix clustering can be applied to web access prediction&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>]. An overview of about 10 years of research on log analysis had been presented in surveys&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>].</p>    <p>To a small extent, we will use methods of logic and modeling. Organizations analyze such data to evaluate the effectiveness of their campaigns and applications&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>]. Further papers focuses to use the web data for fuzzy approximate reasoning for recommendation systems&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>]. Dynamic multinomial probit model of clickstreams are used as model for predicting and categorizing clickstream paths. It has been shown that this technique outperforms traditional first-order Markov models&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>]. Besides considering only clickstreams, further features are taken into account like e.g. recommendation lists, ratings, styles and tags. Considering additional features shows a significant impact, however both, positive and negative&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>]. Other work identified typical and atypical sessions in clickstreams. The outliers can be identified with different distance measures such as the Mahalanobis distance in the user session space. The results demonstrate that identifying typical and atypical user sessions is extremely valuable for cleaning &#x201D;noisy&#x201D; user session data for increased accuracy in evaluating user experience&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>]. Semantic user models are also the subject of research. Words can be extracted from the user&#x0027;s session and disambiguate with words from Wordnet or other lexicons. By means of similarity measurements, the semantic vector spaces can then be classified&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>].</p>   </section>   <section id="sec-4">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> Proposed approach</h2>    </div>    </header>    <p>The overall goal of this work is to detect compromised user accounts based on clickstream data. Currently, there is very few research made in the area of detecting compromised user accounts. Mostly, the work focuses on detecting hijacked social accounts or the intrusion on web servers. Moreover, the amount of work considering clickstream data to detect compromised accounts is even less. Existing approaches mostly uses graph-based methods to identify hijacked accounts. However, we assume that the clickstreams of a compromised account differ from the clickstreams made before the compromising of the account. The hacker, which has gained access to the account, traverses and behaves differently than the actual user. These produced clickstreams therefore differ from the ones before and can be considered as anomalies. Besides detecting compromised accounts, we will detect if the account is a shared account and if so, the current person using the account. Knowing the person, using the account, allows for personalized advertisements, even in a shared account manner. For this purpose we will also use clickstream data. However, we also have to consider the user&#x0027;s preferences over time, as they can change. Only in this way can we identify unforeseen things and determine whether the preferences are too different. Accounts whose preferences change abruptly or do not match are marked as conspicuous.</p>    <p>Throughout the entire work, we use an agile approach to obtain initial results as quickly as possible in order to gain initial insights and use this to adapt the methods and improve the models. We hope that this approach will produce good results as soon as possible and reject erroneous hypotheses as soon as possible. Figure&#x00A0;<a class="fig" href="#fig2">2</a> shows an high level overview of the agile process and the single steps. <figure id="fig2">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186569/images/www18companion-123-fig2.jpg" class="img-responsive" alt="Figure 2"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 2:</span>      <span class="figure-title">Agile approach for the underlying work.</span>     </div>    </figure>    </p>    <p>The first step in the approach is to raise research questions and provide appropriate contributions to each research question. Based on the motivation and problem statements we identified the following research Questions:</p>    <ul class="list-no-style">    <li id="uid7" label="RQ1">How can we identify compromised user accounts, based on a user&#x0027;s clickstreams and taking into account a temporal aspect?<br/></li>    <li id="uid8" label="RQ2">How many clicks and background knowledge about the user do we need in order to be able to give a sufficient confidence about the compromising.<br/></li>    <li id="uid9" label="RQ3">Does our approach work for every clickstream data or is it limited to a certain domain?<br/></li>    </ul>    <p>The first research questions tackles the aspect of identifying fraudulences in a user&#x0027;s account. The methods we can use for these and the following research questions will be explained in more detail in the next section. The second research questions is about providing a confidence for the predictions made by RQ1. More clicks and background knowledge about the user probably leads to an improved confidence of the prediction. The question is, however, how many clicks and background knowledge are needed to get a certain confidence. In addition, the question of which methods are suitable when this critical amount of information is not available to make a statement with a certain confidence is also of interest. The last research questions tackles the applicability of our approach regarding its suitability for certain domains. Here we will examine whether the clickstreams of the different scenarios differ and whether our approach is limited to a specific use case. For each research question will corresponding contributions be provided. After we have sharpened the research questions, we have to identify the relevant literature in the next step. We have already taken a first step here (see section <a class="sec" href="#sec-3">2</a> - stateOfTheArt). However, other research ideas and applications of methods can lead to further search for relevant literature. This step will therefore be carried out in parallel with the method selection.</p>    <p>In order to evaluate the methods and the approach, data sets are required. Preferably, the selected methods are not tested on a single data set, but on several. Existing datasets such as RecSys Challenge 2015<a class="fn" href="#fn5" id="foot-fn5"><sup>4</sup></a> and Yandex<a class="fn" href="#fn6" id="foot-fn6"><sup>5</sup></a> all have in common that although they contain clickstreams in different forms, it is unknown whether they contain fraud clicks or not. This means that it is not possible to quantify how good our methods actually are. However, as mentioned in section <a class="sec" href="#sec-3">2</a> - stateOfTheArt, the topic is related to fraud detection in the financial sector. Therefore, we could consider using financial data sets. There are synthetic data like banksim<a class="fn" href="#fn7" id="foot-fn7"><sup>6</sup></a> and paysim<a class="fn" href="#fn8" id="foot-fn8"><sup>7</sup></a> available. Therefore, we could take into account to adapt the synthetic financial data sets and considering each financial transaction as a click and subsequent transactions as a clickstream. The transferred amount of money could be considered as the duration on a webpage. The advantage here would be that labeled data would be available. This would facilitate the evaluation, because by comparing with the correct classification it can be determined exactly whether the chosen methods and approach are advantageous to recognize fraudulences in a data set. As a last option, we could create our own data set. Test persons could traverse on server-own systems and thus generate data sets including fraudulences.</p>    <p>Once we have selected one or more data sets, we can select appropriate methods and use them to identify compromised or shared accounts. We will distinguish ourselves from existing methods by using a semantic and structure-based analysis instead of a graph-based analysis. We will go into more detail on the selection of methods and evaluation criteria in section <a class="sec" href="#sec-5">4</a> - methodology.</p>    <p>We will continue to implement the agile approach until our chosen methods outperform existing approaches. In the end of the work we will draw conclusions based on the evaluations and experiences, gained during the research. The insights and selected, and possibly extended, methods are described and summarized. Research questions that have been asked at the beginning of the work are answered with the help of the insights. In addition, our work is embedded in the existing research environment to bring the work into a context. This ensures, on the one hand, that the work is again delimited from existing ones, synergies with other areas are identified and possible applications in other areas are presented.</p>   </section>   <section id="sec-5">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> Methodology</h2>    </div>    </header>    <p>For the present work we use methods from quantitative research. We use a hybrid approach to identify fraudulences. With the help of machine learning methods, we can quickly identify abnormalities and interrelationships. With this information we can build up a knowledge base to use this knowledge to identify compromised and shared accounts. In addition, we will enrich the knowledge base with practical knowledge. These two methods, build the base of our hybrid approach. We will explain in the following available methods of subsymbolic AI in more detail and then discuss the possible methods of symbolic AI.</p>    <p>As already mentioned, the identification of fraudulences is predominantly a binary classification problem. A variety of methods of subsymbolic AI are available to us for this purpose. First of all, we have to transform the clickstreams into a corresponding model. For this we can use methods from the field of Text Mining like e. g. a co-occurrence matrix, term-frequency matrix, calculate tfidf to identify the relevance of a click or use Doc2Vec. All of these methods have in common that they produce a numerical vector representation of the sessions or clicks. A numerical representation is recommended for further processing, as it allows us to use elementary algebra and geometry instruments for further processing. A further approach to determine a numerical representation is the use of Latent Semantic Analysis (LSA). We will consider including and identifying semantic information in clickstreams. LSA is used very successfully in the area of Natural Language Processing (NLP). We have already made first attempts to apply LSA to clickstreams.</p>    <p>Besides the appropriate representation of clickstreams, the selection of suitable methods is also crucial. Support Vector machines, Bayesian networks or artificial neural networks could be used. The methods have in common, however, that they consider the data statically and do not take any temporal aspect into account<a class="fn" href="#fn9" id="foot-fn9"><sup>8</sup></a>. This has to be taken into account, when representing clickstreams as well as when selecting models, since the preferences of a user can change over time and these clicks should not be considered as fraudulences. Therefore, both the model has to be adapted over time and the temporal component has to be taken into account. Methods may need to be adapted to take this into account. For RQ2, statistical methods are used to validate the prediction, on the one hand, to put the prediction in context with probabilities and thus to determine the quality of the prediction, and on the other hand to justify its applicability.</p>    <p>So far, we have only listed methods of supervised learning. However, unsupervised learning methods can also be used. This could be particularly advantageous if little is known about an user. By means of Nearest Neighbor or k-means clustering the user can be assigned to the most similar set. However, if the density of the cluster changes very much as a result of the assignment, it can be assumed that this user contains fraudulences, since the assignment is unfavorable.</p>    <p>The above methods highlight the application of subsymbolic AI. However, as already mentioned above, we choose a hybrid use of subsymbolic and symbolic AI. We would like to make the findings from the above methods available in a knowledge base. This knowledge base is enriched with methods from the field of symbolic AI. Here we want to make it possible to enrich the knowledge of machine learning with practical knowledge by domain experts. We hope that the hybrid approach will enable us to achieve a higher level of meaningfulness. One difficulty here is to find a suitable representation of both, the insights of machine learning and of practical knowledge and to model them accordingly. We also need to consider a temporal aspect when modeling knowledge. Similarly, the opinions and experience of different domain experts must also be taken into account in the modeling process. Different experts may have different experiences with compromised accounts and provide different experiences.</p>    <p>When selecting the evaluation criteria, it should be noted that in our case it is predominantly a binary classification problem. When identifying the person of a shared account, there could be several classes. In addition, it can be assumed that the considered data sets are very unbalanced. This means that there are a lot of sessions in the clickstream data sets in a certain class. In our case, the extent of sessions that are not compromised or shared will be greatly increased. For unbalanced data, <em>Area under the Curve (ROC AUC)</em> is recommended as evaluation criterion. ROC AUC is not reflected by data imbalance. ROC AUC computes the area under the receiver operating characteristic curve, which illustrates the true positive rate (TPR) against the false positive rate (FPR). The fact of ROC AUC being insensitive to class balance makes this evaluation criterion very suitable for our case. In order to compare our methodology and approach with existing methods, we will apply existing methods to the data sets in order to compare them with our methods. In the implementation of existing methods and the subsequent comparisons, the data set and the different methods must always be taken into account. Existing methods often use graph-based methods to identify compromised accounts. These graphs may not be available to us.</p>   </section>   <section id="sec-6">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Results</h2>    </div>    </header>    <p>Currently, the work is in an early stage. The approach of the work was clearly written down, the first related works were identified and possible methods of application were presented. However, during the work the overview of the related work will be enlarged.</p>    <p>Initial work was done to enable a semantic representation of clickstreams. The RecSys Challenge 2015<a class="fn" href="#fn10" id="foot-fn10"><sup>9</sup></a> dataset was used for this. The data was represented as a session item matrix. Thus we have created an embedding for each item and session respectively. LSA was then applied to it. LSA allows for representing a session-item matrix <em>A</em> as the product of three matrices: <em>A</em> = <em>U</em> &#x00B7; <em>&#x03A3;</em> &#x00B7; <em>V<sup>T</sup>    </em>. Here <em>U</em> represents the items and <em>V<sup>T</sup>    </em> the sessions. With this representation, the items could be assigned to the correct category with a high degree of accuracy. We used Support Vector Machines (SVM) to classify the items in their categories. The assignment to the category was used because this information was available. It was not possible to assign the sessions to users, since no information was known about them. A similarity analysis would have been possible, but could not have been compared with a gold standard. We showed in this work that LSA is applicable to assign items to their correct category, based on the clickstreams of users. With the help of LSA we exploited the semantics of the clickstreams. In addition we tried to rebuild the taxonomy of the product category by exploiting the semantics in the clickstreams. However, we did not have the taxonomy available. We build it based on the information of shared items for each category. This work helped as a first step for session modeling in clickstreams.</p>   </section>   <section id="sec-7">    <header>    <div class="title-info">     <h2>      <span class="section-number">6</span> Conclusions and future work</h2>    </div>    </header>    <p>The main goal of this work is to identify fraudulences and shared user accounts, based on clickstream data. One aspect, besides the identification of fraudulences, is the amount of information, needed to make meaningful predictions. Another aspect that is tackled during this work is the applicability of our approach to different domains. The approach should be abstract enough to be applicable to different clickstream data like e.g. social networks, web shops and web solutions. Most of the related work focus on graph-based solutions to identify hijacked accounts. We will focus on compromised accounts and use clickstream data with respect to a temporal aspect.</p>    <p>We use a hybrid approach, consisting of methods from subsymbolic and symbolic AI. Thus methods from data representation and machine learning are used, as well as logic-based methods. Insights gained from machine learning algorithms and practical knowledge from domain experts are considered in our approach. We hope that this will lead to improved results. Future work includes to identify one or more suitable data sets. The currently available data sets do not fulfill all specified requirements. We are currently considering using one of the synthetic financial data sets as a clickstream dataset, since it contains labeled data. This makes the evaluation credible, rather than data sets that are not known to contain fraudulences. It is important to note that the data set should have different sessions for one user in order to consider the change of preference for one user over time. Besides choosing appropriate data sets for the evaluation, a suitable model for the knowledge base has to be considered. Since we want to store the information in a knowledge base and enrich it with practical knowledge, we need to provide a data model that makes both possible. In addition, this data model must be able to deal with vague and contradictory practical knowledge and allow for a change over time. We can then convert the data into the appropriate data model and apply the selected methods to it. Due to the agile approach we will quickly adapt the results of the first experiments to reflect back the data model as well as the methods used. At the end of the work, we will collect the gained knowledge and thus answer the research questions.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">Palakorn Achananuparp, Hyoil Han, Olfa Nasraoui, and Roberta Johnson. 2007. Semantically Enhanced User Modeling. In <em>      <em>Proceedings of the 2007 ACM Symposium on Applied Computing</em>     </em>(<em>SAC &#x2019;07</em>). ACM, New York, NY, USA, 1335&#x2013;1339.</li>    <li id="BibPLXBIB0002" label="[2]">Juan Jos&#x00E9;&#x00A0;Garc&#x00ED;a Adeva and Juan Manuel&#x00A0;Pikatza Atxa. 2007. Intrusion detection in web applications using text mining. <em>      <em>Engineering Applications of Artificial Intelligence</em>     </em>20, 4(2007), 555 &#x2013; 566.</li>    <li id="BibPLXBIB0003" label="[3]">Maristella Agosti, Franco Crivellari, and Giorgio&#x00A0;Maria Di&#x00A0;Nunzio. 2012. Web log analysis: a review of a decade of studies about information acquisition, inspection and interpretation of user interaction. <em>      <em>Data Mining and Knowledge Discovery</em>     </em>24, 3 (01 May 2012), 663&#x2013;696.</li>    <li id="BibPLXBIB0004" label="[4]">R. Brause, T. Langsdorf, and M. Hepp. 1999. Neural data mining for credit card fraud detection. In <em>      <em>Proceedings 11th International Conference on Tools with Artificial Intelligence</em>     </em>. 103&#x2013;106.</li>    <li id="BibPLXBIB0005" label="[5]">Philip&#x00A0;K. Chan and Salvatore&#x00A0;J. Stolfo. 1998. Toward Scalable Learning with Non-uniform Class and Cost Distributions: A Case Study in Credit Card Fraud Detection. In <em>      <em>Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining</em>     </em>(<em>KDD&#x2019;98</em>). AAAI Press, 164&#x2013;168.</li>    <li id="BibPLXBIB0006" label="[6]">J.&#x00A0;R. Dorronsoro, F. Ginel, C. Sgnchez, and C.&#x00A0;S. Cruz. 1997. Neural fraud detection in credit card operations. <em>      <em>IEEE Transactions on Neural Networks</em>     </em>8, 4 (Jul 1997), 827&#x2013;834.</li>    <li id="BibPLXBIB0007" label="[7]">M. Egele, G. Stringhini, C. Kruegel, and G. Vigna. 2017. Towards Detecting Compromised Accounts on Social Networks. <em>      <em>IEEE Transactions on Dependable and Secure Computing</em>     </em>14, 4 (July 2017), 447&#x2013;460.</li>    <li id="BibPLXBIB0008" label="[8]">Manuel Egele, Gianluca Stringhini, Christopher Kr&#x00FC;gel, and Giovanni Vigna. 2013. COMPA: Detecting Compromised Accounts on Social Networks. In <em>      <em>NDSS</em>     </em>.</li>    <li id="BibPLXBIB0009" label="[9]">Andrew Foss, Weinan Wang, and Osmar&#x00A0;R. Za&#x00EF;ane. 2001. A Non-Parametric Approach to Web Log Analysis. (2001).</li>    <li id="BibPLXBIB0010" label="[10]">S. Ghosh and D.&#x00A0;L. Reilly. 1994. Credit card fraud detection with a neural-network. In <em>      <em>1994 Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences</em>     </em>, Vol.&#x00A0;3. 621&#x2013;630.</li>    <li id="BibPLXBIB0011" label="[11]">Nicholas&#x00A0;A. Heard, David&#x00A0;J. Weston, Kiriaki Platanioti, and David&#x00A0;J. Hand. 2010. Bayesian anomaly detection methods for social networks. <em>      <em>Ann. Appl. Stat.</em>     </em>4, 2 (06 2010), 645&#x2013;662.</li>    <li id="BibPLXBIB0012" label="[12]">Terran Lane and Carla&#x00A0;E. Brodley. 1997. An Application of Machine Learning to Anomaly Detection. In <em>      <em>In Proceedings of the 20th National Information Systems Security Conference</em>     </em>. 366&#x2013;380.</li>    <li id="BibPLXBIB0013" label="[13]">Ahmed Metwally, Divyakant Agrawal, and Amr&#x00A0;El Abbadi. 2005. Using Association Rules for Fraud Detection in Web Advertising Networks. In <em>      <em>Proceedings of the 31st International Conference on Very Large Data Bases</em>     </em>(<em>VLDB &#x2019;05</em>). VLDB Endowment, 169&#x2013;180.</li>    <li id="BibPLXBIB0014" label="[14]">Bamshad Mobasher. 2005. Web usage mining. In <em>      <em>Encyclopedia of data warehousing and mining</em>     </em>. IGI Global, 1216&#x2013;1220.</li>    <li id="BibPLXBIB0015" label="[15]">Alan&#x00A0;L. Montgomery, Shibo Li, Kannan Srinivasan, and John&#x00A0;C. Liechty. 2004. Modeling Online Browsing and Path Analysis Using Clickstream Data. <em>      <em>Marketing Science</em>     </em>23, 4 (2004), 579&#x2013;595.</li>    <li id="BibPLXBIB0016" label="[16]">O. Nasraoui and C. Petenes. 2003. An intelligent Web recommendation engine based on fuzzy approximate reasoning. In <em>      <em>Fuzzy Systems, 2003. FUZZ &#x2019;03. The 12th IEEE International Conference on</em>     </em>, Vol.&#x00A0;2. 1116&#x2013;1121 vol.2.</li>    <li id="BibPLXBIB0017" label="[17]">Caleb&#x00A0;C. Noble and Diane&#x00A0;J. Cook. 2003. Graph-based Anomaly Detection. In <em>      <em>Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>     </em>(<em>KDD &#x2019;03</em>). ACM, New York, NY, USA, 631&#x2013;636.</li>    <li id="BibPLXBIB0018" label="[18]">Rainer Olbrich and Christian Holsing. 2011. Modeling Consumer Purchasing Behavior in Social Shopping Communities with Clickstream Data. <em>      <em>International Journal of Electronic Commerce</em>     </em>16, 2(2011), 15&#x2013;40.</li>    <li id="BibPLXBIB0019" label="[19]">Shigeru Oyanagi, Kazuto Kubota, and Akihiko Nakase. 2001. Application of matrix clustering to web log analysis and access prediction. In <em>      <em>in: WEBKDD 2001&#x2014;Mining Web Log Data Across All Customers Touch Points, Third International Workshop</em>     </em>. 13&#x2013;21.</li>    <li id="BibPLXBIB0020" label="[20]">Soyeon Park, Joon&#x00A0;Ho Lee, and Hee&#x00A0;Jin Bae. 2005. End user searching: A Web log analysis of NAVER, a Korean Web search engine. <em>      <em>Library &#x0026; Information Science Research</em>     </em>27, 2 (2005), 203 &#x2013; 221.</li>    <li id="BibPLXBIB0021" label="[21]">Animesh Patcha and Jung-Min Park. 2007. An overview of anomaly detection techniques: Existing solutions and latest technological trends. <em>      <em>Computer Networks</em>     </em>51, 12 (2007), 3448 &#x2013; 3470.</li>    <li id="BibPLXBIB0022" label="[22]">Jake Ryan, Meng-Jang Lin, and Risto Miikkulainen. 1998. Intrusion Detection With Neural Networks. In <em>      <em>Advances in Neural Information Processing Systems 10</em>     </em>, Michael&#x00A0;I. Jordan, Michael&#x00A0;J. Kearns, and Sara&#x00A0;A. Solla (Eds.). Cambridge, MA: MIT Press, 943&#x2013;949.</li>    <li id="BibPLXBIB0023" label="[23]">Narayanan Sadagopan and Jie Li. 2008. Characterizing Typical and Atypical User Sessions in Clickstreams. In <em>      <em>Proceedings of the 17th International Conference on World Wide Web</em>     </em>(<em>WWW &#x2019;08</em>). ACM, New York, NY, USA, 885&#x2013;894.</li>    <li id="BibPLXBIB0024" label="[24]">David Savage, Xiuzhen Zhang, Xinghuo Yu, Pauline Chou, and Qingmai Wang. 2014. Anomaly detection in online social networks. <em>      <em>Social Networks</em>     </em>39, Supplement C (2014), 62 &#x2013; 70.</li>    <li id="BibPLXBIB0025" label="[25]">Craig Silverstein, Hannes Marais, Monika Henzinger, and Michael Moricz. 1999. Analysis of a Very Large Web Search Engine Query Log. <em>      <em>SIGIR Forum</em>     </em>33, 1 (Sept. 1999), 6&#x2013;12.</li>    <li id="BibPLXBIB0026" label="[26]">S. Wang. 2010. A Comprehensive Survey of Data Mining-Based Accounting-Fraud Detection Research. In <em>      <em>2010 International Conference on Intelligent Computation Technology and Automation</em>     </em>, Vol.&#x00A0;1. 50&#x2013;53.</li>    <li id="BibPLXBIB0027" label="[27]">L. Zhang and Y. Guan. 2008. Detecting Click Fraud in Pay-Per-Click Streams of Online Advertising Networks. In <em>      <em>2008 The 28th International Conference on Distributed Computing Systems</em>     </em>. 77&#x2013;84.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>Supervised by Dr. Maria Maleshkova</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a><a class="link-inline force-break"    href="http://www.internetworldstats.com/emarketing.htm">http://www.internetworldstats.com/emarketing.htm</a>, last access: 23rd February 2018</p>   <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a><a class="link-inline force-break"    href="https://www.statista.com/statistics/278414/number-of-worldwide-social-network-users/">https://www.statista.com/statistics/278414/number-of-worldwide-social-network-users/</a>, last access: 23rd February 2018</p>   <p id="fn4"><a href="#foot-fn4"><sup>3</sup></a><a class="link-inline force-break"    href="https://www.statista.com/statistics/251666/number-of-digital-buyers-worldwide/">https://www.statista.com/statistics/251666/number-of-digital-buyers-worldwide/</a>, last access: 23rd February 2018</p>   <p id="fn5"><a href="#foot-fn5"><sup>4</sup></a><a class="link-inline force-break"    href="http://recsys.yoochoose.net/challenge.html">http://recsys.yoochoose.net/challenge.html</a>, last access: 23rd February 2018</p>   <p id="fn6"><a href="#foot-fn6"><sup>5</sup></a><a class="link-inline force-break"    href="https://www.kaggle.com/c/yandex-personalized-web-search-challenge/data">https://www.kaggle.com/c/yandex-personalized-web-search-challenge/data</a>, last access: 23rd February 2018</p>   <p id="fn7"><a href="#foot-fn7"><sup>6</sup></a><a class="link-inline force-break"    href="https://www.kaggle.com/ntnu-testimon/banksim1/data">https://www.kaggle.com/ntnu-testimon/banksim1/data</a>, last access: 23rd February 2018</p>   <p id="fn8"><a href="#foot-fn8"><sup>7</sup></a><a class="link-inline force-break"    href="https://www.kaggle.com/ntnu-testimon/paysim1">https://www.kaggle.com/ntnu-testimon/paysim1</a>, last access: 23rd February 2018</p>   <p id="fn9"><a href="#foot-fn9"><sup>8</sup></a>Except for some NN like recurrent neural networks</p>   <p id="fn10"><a href="#foot-fn10"><sup>9</sup></a><a class="link-inline force-break"    href="http://recsys.yoochoose.net/challenge.html">http://recsys.yoochoose.net/challenge.html</a>, last access: 23rd February 2018</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186569">https://doi.org/10.1145/3184558.3186569</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
