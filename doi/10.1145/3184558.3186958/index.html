<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>A Story Coherence based Neural Network Model for
  Predicting Story Ending</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">A Story Coherence based Neural
          Network Model for Predicting Story Ending</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Qian</span> <span class=
          "surName">Li*</span> CCCE, Nankai University, China
        </div>
        <div class="author">
          <span class="givenName">Ziwei</span> <span class=
          "surName">Li</span> CCCE, Nankai University, China
        </div>
        <div class="author">
          <span class="givenName">Jin-Mao</span> <span class=
          "surName">Wei</span> CCCE, Nankai University, China
        </div>
        <div class="author">
          <span class="givenName">Zhenglu</span> <span class=
          "surName">Yang*</span> CCCE, Nankai University, China,
          <a href=
          "mailto:liqian515,lzw_nku@mail.nankai.edu.cn">liqian515,lzw_nku@mail.nankai.edu.cn</a>,
          <a href=
          "mailto:weijm,yangzl@nankai.edu.cn">weijm,yangzl@nankai.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Yanhui</span> <span class=
          "surName">Gu</span> School of CS and Technology,, Nanjing
          Normal University, China, <a href=
          "mailto:gu@njnu.edu.cn">gu@njnu.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">R. Uday</span> <span class=
          "surName">Kiran</span> Institute of Industrial Science,,
          The University of Tokyo, Japan, <a href=
          "mailto:uday_rage@tkl.iis.u-tokyo.ac.jp">uday_rage@tkl.iis.u-tokyo.ac.jp</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186958"
        target=
        "_blank">https://doi.org/10.1145/3184558.3186958</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Predicting the ending of a story is an
        interesting issue that has attracted considerable
        attention, as in case of the ROC Story Cloze Task (SCT).
        Although several studies have addressed this issue, the
        performance remains unsatisfactory due to ineffectiveness
        of story comprehension. In this paper, we propose to
        construct a story coherence based neural network model
        (SCNN) with well-designed optimizations. The preliminary
        evaluation demonstrates the effectiveness of our model
        which is superior to that of state-of-the-art
        approaches.</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>natural language
          processing</small>,</span> <span class=
          "keyword"><small>neural network</small>,</span>
          <span class="keyword"><small>story cloze</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Qian Li*, Ziwei Li, Jin-Mao Wei, Zhenglu Yang*, Yanhui
          Gu, and R. Uday Kiran. 2018. A Story Coherence based
          Neural Network Model for Predicting Story Ending. In
          <em>WWW '18 Companion: The 2018 Web Conference
          Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon,
          France. ACM, New York, NY, USA</em> 3 Pages. <a href=
          "https://doi.org/10.1145/3184558.3186958" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3186958</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Humans have the intrinsic inferential capabilities to
      predict the development of a story by using commonsense
      knowledge collected from real life. However, training
      machines to be able to extract underlying narrative
      structures to share experiences is an extremely challenging
      task. Most studies on this subject mainly focus on generating
      guesses for a missing event or paying attention to specific
      types of commonsense knowledge.</p>
      <p>Different from previous machine comprehension tasks, the
      Story Cloze Task (SCT) has been proposed as a new evaluation
      framework to predict what is expected to be the “right”
      ending to a story plot&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>]. The SCT has attracted significant
      attention. The state-of-the-art mechanical structure involves
      traditional feature engineering with external knowledge
      resources, e.g., New York Times data&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0002">2</a>], while others introduce
      neural network-based model to address this
      issue&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0001">1</a>].
      However, the performance of this task remains
      unsatisfactory.</p>
      <p>In this paper, we propose an effective story coherence
      neural network (SCNN) consisting of several optimal
      components, and we consider features of sentences by adding
      them as embedding representations. Without the help of
      external knowledge resources, we obtain the best result
      78.3%, which demonstrates that our approach performs better
      than the state-of-the-art methods.</p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> The SCNN
          Model</h2>
        </div>
      </header>
      <p>The purpose of this study is to deduce the right ending
      given its previous context in the story. Formally, given the
      story ⟨<em>P</em>, <em>E</em>⟩, where <em>P</em>=⟨<em>s</em>
      <sub>1</sub>, …, <em>s<sub>n</sub></em> ⟩ is a story plot,
      and the ending options <em>E</em>=⟨<em>e</em> <sub>1</sub>,
      …, <em>e<sub>k</sub></em> ⟩, the task is to select an
      appropriate ending <em>e<sub>i</sub></em> (1 ≤ <em>i</em> ≤
      <em>k</em>) from <em>E</em>. We address the task as a
      regression problem.</p>
      <p>The model consists of four layers, as illustrated in
      Fig.&nbsp;<a class="fig" href="#fig1">1</a>. The embedding
      layer maps each word to a high-dimension vector
      representation. Then the sentence encoding layer encodes the
      representation of context, and the feature extraction layer
      extracts feature from the interaction between plot and
      ending. Finally, the output layer provide the probability of
      the right ending.</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186958/images/www18companion-198-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">Architecture of SCNN<sup>1</sup></span>
        </div>
      </figure><strong>Embedding Layer:</strong> We concatenate
      five representations: (i) word embedding, (ii) character
      feature, (iii) part-of-speech (POS) tagging, (iv) sentiment
      polarity of a word, and (v) negation. Word embedding is
      conducted by converting token to high-dimensional vector
      space using 100-<em>d</em> GloVe. The character feature is
      obtained through a convolutional neural network that outputs
      a vector for each word by max pooling. By utilizing
      pre-processing tools, we tackle the last three aspects of a
      word as one-hot representations, while the POS tagging
      feature with natural language toolkit, sentiment polarity of
      a word with a look-up from pre-trained sentiment
      lexica&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0002">2</a>],
      and negation with a corpus of negation words (i.e., “not”,
      “neither”, “nor” and “n't”) are collected by ourselves. The
      concatenation of the five representations of a word is then
      passed through a two-layer Highway Network to fuse
      information of features.
      <p></p>
      <p><strong>Sentence Encoding Layer:</strong> We construct a
      Long Short-Term Memory Network (LSTM) in both directions and
      concatenate the outputs of forward and backward LSTMs, to
      learn high level abstractions from time-sequence features of
      context. We obtain <span class="inline-equation"><span class=
      "tex">$s_{lj, (j=1,\dots ,n)} \in \mathbb {R}^{2d\times
      {T}}$</span></span> for each sentence in plot and
      <span class="inline-equation"><span class="tex">$e_{li} \in
      \mathbb {R}^{2d\times {G}}$</span></span> for ending.</p>
      <p>The new representations are passed into self-weight
      operation to model the temporal interactions between words.
      Taking vector V as example, we define this operation
      <span class="inline-equation"><span class=
      "tex">$\widetilde{V}$</span></span> as follows:</p>
      <div class="table-responsive" id="eq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{eqnarray} M_{ij}=\alpha
          (V_i, V_j);\quad a_i=softmax(M_{i:});\quad
          \widetilde{V_{i}}=\sum _j a_{ij}V_j
          \end{eqnarray}</span><br />
          <span class="equation-number">(1)</span>
        </div>
      </div>where <em>α</em>(<em>V<sub>i</sub></em> ,
      <em>V<sub>j</sub></em> ) = <em>W<sup>T</sup></em>
      [<em>V<sub>i</sub></em> ; <em>V<sub>j</sub></em> ;
      <em>V<sub>i</sub></em> ○<em>V<sub>j</sub></em> ],
      <span class="inline-equation"><span class="tex">$W^T \in
      \mathbb {R}^{3d}$</span></span> is a weight matrix and ○ is
      element-wise multiplication. The higher-level semantics can
      directly tackled from encoding sequences through this
      mechanism. The encodings of story plot is concatenated as
      <span class="inline-equation"><span class="tex">$\hat{P}=
      [\widetilde{s_{l1}};\cdots
      ;\widetilde{s_{ln}}]$</span></span> , while the ending is
      simply represented as <span class=
      "inline-equation"><span class=
      "tex">$\hat{e}=\widetilde{e_{li}}$</span></span> .
      <p></p>
      <p><strong>Feature Extraction Layer:</strong> This layer is
      inspired by the IIN model [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>]. We combine the plot vectors and
      ending representations with element-wise multiplication to
      create a word-by-word interaction tensor, in which each
      channel represents the interaction of the word in one
      dimension. Then, we adapt DenseNet as a feature extractor
      that strengthens feature propagation and reduces information
      disappearance through time.</p>
      <p><strong>Output Layer:</strong> A linear layer is used to
      calculate a score to support the prediction.</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Experimental
          Evaluation</h2>
        </div>
      </header>
      <p>We evaluate our model by using the benchmark SCT
      Task&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0005">5</a>].
      Notably, the training set contains four-sentence articles
      with one correct ending, while the evaluation set consists of
      four-sentence stories with two ending options. The previous
      studies discarded the training stories and illustrated that
      learning on the training set was not as satisfactory as it
      was on the evaluation set&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0006">6</a>]. We follow the same strategy used by
      these state-of-the-art works.</p>
      <p>The parameters are optimized by conducting five-fold cross
      validation and choosing appropriate values based on average
      held-out accuracy. We use mean-square error (MSE) as the loss
      function.</p>
      <p>The experimental results obtained by comparing our model
      with state-of-the-art approaches are presented in
      Table&nbsp;<a class="tbl" href="#tab1">1</a>.
      Schwartz&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0006">6</a>] is the champion of the LSDSem 2017
      Shared Task, which achieves 75.2% by training a linear
      regression. HCM&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0002">2</a>] trains a joint model with feature
      engineering that employs external knowledge resources,
      thereby resulting in 77.6% precision. The previous NN-based
      models do not perform well, e.g., Cai&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0001">1</a>] obtains 74.7% accuracy
      with a hierarchical LSTM and ending2sentence attention. Under
      the condition in which external resources are not used and
      the fourth sentence of the plot with ending option are input,
      SCNN performs much better, i.e., up to 3% than the
      state-of-the-art ones. Even compared with the method using
      external resources, our model achieves better results. SCNN
      is superior because we deliberately introduce optimal
      strategies such as concatenated features with embedding
      representations, embedded into the hierarchical neural
      network.</p>
      <p>We also explore the ablation study&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0003">3</a>] on the proposed model to
      evaluate the effectiveness of each feature and component
      involved, as illustrated in Fig.&nbsp;<a class="fig" href=
      "#fig2">2</a>, showing that character of features and biLSTM
      of components contribute mainly to our model.</p>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">Performance comparison on precision</span>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <td colspan="3" style="text-align:center;">
                <strong>Machine Learning Algorithm</strong>
                <hr />
              </td>
              <td colspan="3" style="text-align:center;">
                <strong>Neural Network Algorithm</strong>
                <hr />
              </td>
            </tr>
            <tr>
              <td style="text-align:center;">
                DSSM[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0005">5</a>]
              </td>
              <td style="text-align:center;">
                Schwartz[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0006">6</a>]
              </td>
              <td style="text-align:center;">
                HCM[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0002">2</a>]
              </td>
              <td style="text-align:center;">
                LSTM[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0004">4</a>]
              </td>
              <td style="text-align:center;">
                Cai[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0001">1</a>]
              </td>
              <td style="text-align:center;">
              <strong>SCNN</strong></td>
            </tr>
            <tr>
              <td style="text-align:center;">58.5%</td>
              <td style="text-align:center;">75.2%</td>
              <td style="text-align:center;">77.6%</td>
              <td style="text-align:center;">72.8%</td>
              <td style="text-align:center;">74.7%</td>
              <td style="text-align:center;">
              <strong>78.3%</strong></td>
            </tr>
          </tbody>
        </table>
      </div>
      <figure id="fig2">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186958/images/www18companion-198-fig2.jpg"
        class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class=
          "figure-title">Ablation studies.</span>
        </div>
      </figure>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Conclusion</h2>
        </div>
      </header>
      <p>We have introduced an effective story coherence neural
      network for the Story Cloze Task, with several strategies
      proposed. The evaluation has demonstrated the effectiveness
      of our model.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2>ACKNOWLEDGMENTS</h2>
        </div>
      </header>
      <p>This work was supported in part by the National Natural
      Science Foundation of China under Grant No.U1636116,
      11431006, 61772288, 41571382, the Research Fund for
      International Young Scientists under Grant No. 61650110510
      and 61750110530, and Jiangsu Higher Education Institutions of
      China under Grant No. 15KJA420001.</p>
    </section>
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Zheng Cai, Lifu Tu, and
        Kevin Gimpel. 2017. Pay Attention to the Ending:Strong
        Neural Baselines for the ROC Story Cloze Task. In
        <em><em>ACL</em></em> .</li>
        <li id="BibPLXBIB0002" label="[2]">Snigdha Chaturvedi,
        Haoruo Peng, and Dan Roth. 2017. Story Comprehension for
        Predicting What Happens Next. In <em><em>EMNLP</em></em>
        .</li>
        <li id="BibPLXBIB0003" label="[3]">Yichen Gong, Heng Luo,
        and Jian Zhang. 2018. Natural language inference over
        interaction space. <em><em>In Proc. of ICLR</em></em>
        .</li>
        <li id="BibPLXBIB0004" label="[4]">Todor Mihaylov and
        Anette Frank. 2017. Story Cloze Ending Selection Baselines
        and Data Examination. In <em><em>LSDSem</em></em> .</li>
        <li id="BibPLXBIB0005" label="[5]">Nasrin Mostafazadeh,
        Nathanael Chambers, Xiaodong He, Devi Parikh, Dhruv Batra,
        Lucy Vanderwende, Pushmeet Kohli, and James Allen. 2016. A
        corpus and evaluation framework for deeper understanding of
        commonsense stories. In <em><em>NAACL</em></em> .</li>
        <li id="BibPLXBIB0006" label="[6]">Roy Schwartz, Maarten
        Sap, Ioannis Konstas, Leila Zilles, Yejin Choi, and
        Noah&nbsp;A Smith. 2017. The Effect of Different Writing
        Tasks on Linguistic Style: A Case Study of the ROC Story
        Cloze Task. In <em><em>CoNLL</em></em> .</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><label>1</label>w for word, c for character, p for
    POS, s for sentiment polarity, n for negation</p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3186958">https://doi.org/10.1145/3184558.3186958</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
