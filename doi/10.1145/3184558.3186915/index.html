<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head> <title>Handling Confounding for Realistic Off-Policy Evaluation</title> <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta> <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta> <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta> <link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet" href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script> <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script> <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script> <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script> <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script> <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main"> <section class="front-matter"> <section> <header class="title-info"> <div class="journal-title"> <h1> <span class="title">Handling Confounding for Realistic Off-Policy Evaluation</span> <br/> <span class="subTitle"/> </h1> </div> </header> <div class="authorGroup"> <div class="author"> <span class="givenName">Saurabh</span> <span class="surName">Sohoney</span> Amazon, <a href="mailto:sohoneys@amazon.com">sohoneys@amazon.com</a> </div> <div class="author"> <span class="givenName">Nikita</span> <span class="surName">Prabhu</span> Amazon, <a href="mailto:niprabhu@amazon.com">niprabhu@amazon.com</a> </div> <div class="author"> <span class="givenName">Vineet</span> <span class="surName">Chaoji</span> Amazon, <a href="mailto:vchaoji@amazon.com">vchaoji@amazon.com</a> </div> </div> <br/> <div class="pubInfo"> <p>DOI: <a href="https://doi.org/10.1145/3184558.3186915" target="_blank">https://doi.org/10.1145/3184558.3186915</a> <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p> </div> <div class="abstract"> <p> <small>Inverse Propensity Score estimator (IPS) is a basic, unbiased, off-policy evaluation technique to measure the impact of a userinteractive system without serving live traffic. We present our work on applying IPS to real-world settings by addressing some practical challenges, thereby enabling successful policy evaluation. In particular, we show that off-policy evaluation can be impossible in the absence of a complete context and we describe a systematic way of defining the context.</small> </p> </div> <div class="classifications"> <div class="AcmReferenceFormat"> <p> <small> <span style="font-weight:bold;">ACM Reference Format:</span> <br/> Saurabh Sohoney, Nikita Prabhu, and Vineet Chaoji. 2018. Handling Confounding for Realistic Off-Policy Evaluation. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em> <em>April 23&#x2013;27, 2018,</em> <em> Lyon, France. ACM, New York, NY, USA</em> 3 Pages. <a href="https://doi.org/10.1145/3184558.3186915" class="link-inline force-break" target="_blank">https://doi.org/10.1145/3184558.3186915</a></small> </p> </div> </div> </section> </section> <section class="body"> <section id="sec-4"> <header> <div class="title-info"> <h2> <span class="section-number">1</span> Introduction</h2> </div> </header> <p>A/B test is a standard technique to evaluate user-interactive systems on live traffic. However, an A/B test has a high turn-around time and is expensive to conduct. This becomes a bottle-neck for a fast-moving company like Amazon and necessitates off-policy evaluation.</p> <p>Off-policy evaluation seeks to exploit the logs generated from past user interactions to empirically estimate the value of a new policy. For example, the CTR of a new ad-ranker could be estimated using past clicks, without having the ranker actually serve ads to the users. A popular and fundamental technique for off-policy evaluation is Inverse Propensity Score (IPS) estimator [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>]. In a contextual bandit framework, where the domain of data is defined by distribution <span class="inline-equation"><span class="tex">$(x,\vec{r})\in D$</span> </span> (<em>x</em>: context, <span class="inline-equation"><span class="tex">$\vec{r}$</span> </span>: reward vector over actions), IPS defines the estimate of the value a policy, <em>&#x03C0;</em>: <em>x</em> &#x2192; <em>a</em>, as <div class="table-responsive" id="eq1"> <div class="display-equation"> <span class="tex mytex">\begin{equation} \hat{\mathbb {V}}_H(\pi) = \frac{1}{|H|}\sum _{(x_t,a_t,r_t,p_t)\in H} \frac{r_t*\mathbb {I}(a_t=\pi (x_t))}{p_t} \end{equation} </span> <br/> <span class="equation-number">(1)</span> </div> </div> </p> <p>Here, <em>H</em> represents historical logs of quadruples (context, action, reward, probability), indexed by <em>t</em>. Reward <em>r<sub>t</sub> </em> is a measure of user-satisfaction, e.g., click, like or purchase. Probability <em>p<sub>t</sub> </em> = <em>p</em>(<em>a<sub>t</sub> </em>|<em>x<sub>t</sub> </em>) represents the propensity with which the action <em>a<sub>t</sub> </em> is selected for the context <em>x<sub>t</sub> </em> in <em>H</em>. Division by action propensities neutralizes the sampling bias in <em>H</em> and makes IPS an unbiased estimator [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>]. Note that unbiasedness is crucial for simulating an A/B test. An important assumption for IPS to work is that all the actions should be explored sufficiently often&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>]. Next, we discuss three practical challenges faced while applying IPS to real-world datasets.</p> <ol class="list-no-style"> <li id="list1" label="(1)"><strong>High variance:</strong> IPS is sensitive to the probability values in the denominator of Eq.&#x00A0;<a class="eqn" href="#eq1">1</a> and often has large estimator variance. This problem has been addressed in literature and a standard solution is to trade some bias in order to limit the variance. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>] achieves this by bounding the denominator with a minimum value, while [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>] suggests forms of additive and multiplicative biases to accomplish the same.<br/></li> <li id="list2" label="(2)"><strong>Handling too many actions</strong>: When the pool of actions is large or dynamic, IPS performs poorly due to underexploration. This problem has been previously addressed by limiting the effective number of distinct actions. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>] &#x0026; [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>] recommend fuzzy matching of actions and [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>] also suggests partitioning of the action set through clustering.<br/></li> <li id="list3" label="(3)"><strong>Computing propensities</strong>: When action probabilities are not recorded in <em>H</em>, they need to be estimated. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>] &#x0026; [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>], authors suggest estimating them empirically as count ratios, <span class="inline-equation"><span class="tex">$p(a_t|x_t)=\#(a_t,x_t)/\#(x_t)$</span> </span> from <em>H</em>. Note that this is only possible when a clear definition of context (<em>x<sub>t</sub> </em>) is available.<br/></li> </ol> <p>Our contribution in this work is two-fold - 1) We present results for successful policy evaluation on real-world datasets, 2) We prove that IPS estimates can be invalid when the context is incomplete and we recommend a systematic way to define the context. As IPS forms the building block for many state-of-the-art off-policy evaluation techniques&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0005">5</a>], our solution automatically becomes relevant to all of them. To the best of our knowledge the problem of defining context, although crucial, has not been addressed previously for IPS, as authors have always assumed that either the propensities are recorded in <em>H</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0002">2</a>] or a clear definition of context is known [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0003">3</a>].</p> </section> <section id="sec-5"> <header> <div class="title-info"> <h2> <span class="section-number">2</span> The effect of confounding</h2> </div> </header> <p>As mentioned previously, count ratio estimates of propensities are dependent on the definition of the context. Propensity values can become incorrect when the context is incomplete. This lack of information is referred to as confounding in the data. Proposition 1 states the ill-effect of confounding on IPS estimates.</p> <p> <strong>Proposition 1:</strong> Policy evaluation using IPS can be impossible if the propensities are computed using incomplete context.</p> <p> <strong>Proof sketch:</strong> We prove this through a constructive example. Suppose, the exploration data <em>H</em>, consists of six tuples as shown in Table&#x00A0;<a class="tbl" href="#tab1">1</a>. <em>y</em>, <em>z</em> represent two context features and the action propensities are not recorded. We assume, without loss of generality, that these six tuples represent the entire domain. Let <em>P</em> be a policy, defined as {<em>y</em> <sub>1</sub> <em>z</em> <sub>1</sub> &#x2192; <em>a</em> <sub>1</sub>; <em>y</em> <sub>1</sub> <em>z</em> <sub>2</sub> &#x2192; <em>a</em> <sub>2</sub>}. The average reward, if P was run for generating <em>H</em> would be 6/6. Referring to the estimated action propensities (column 2 and 3, in Table <a class="tbl" href="#tab1">1</a>), the IPS estimates of the value of <em>P</em> as per Eq. <a class="eqn" href="#eq1">1</a>, becomes <span class="inline-equation"><span class="tex">$\frac{1}{6}*(\frac{1}{2/3}+0+0+\frac{1}{2/3}+\frac{1}{2/3}+\frac{1}{2/3})$</span> </span>=6/6, when <em>y</em> &#x0026; <em>z</em> together form the context and 8/6, when only y forms the context. Clearly, the estimate is incorrect when <em>z</em> is ignored.</p> <p>Note that, if the last two tuples in <em>H</em> are eliminated, the propensities become independent of <em>z</em> (all equal to 1/2). As a result, the estimate without <em>z</em> included in the context is also correct, i.e., 4/4.</p> <p>Having understood the importance of an accurate context, we now discuss a systematic way to achieve it.</p> <div class="table-responsive" id="tab1"> <div class="table-caption"> <span class="table-number">Table 1:</span> <span class="table-title">Constructive example to demonstrate confounding</span> </div> <table class="table"> <thead> <tr> <th style="text-align:left;">H: <<em>x<sub>t</sub> </em>, <em>a<sub>t</sub> </em>, <em>r<sub>t</sub> </em>></th> <th style="text-align:center;"> <span class="inline-equation"><span class="tex">$\hat{p}(a_t|x_t=(y,z))$</span> </span> </th> <th style="text-align:center;"> <span class="inline-equation"><span class="tex">$\hat{p}(a_t|x_t=y)$</span> </span> </th> </tr> </thead> <tbody> <tr> <td style="text-align:left;"><<em>y</em> <sub>1</sub> <em>z</em> <sub>1</sub>, <em>a</em> <sub>1</sub>, 1></td> <td style="text-align:center;">2/3</td> <td style="text-align:center;">1/2</td> </tr> <tr> <td style="text-align:left;"><<em>y</em> <sub>1</sub> <em>z</em> <sub>1</sub>, <em>a</em> <sub>2</sub>, 0></td> <td style="text-align:center;">1/3</td> <td style="text-align:center;">1/2</td> </tr> <tr> <td style="text-align:left;"><<em>y</em> <sub>1</sub> <em>z</em> <sub>2</sub>, <em>a</em> <sub>1</sub>, 0></td> <td style="text-align:center;">1/3</td> <td style="text-align:center;">1/2</td> </tr> <tr> <td style="text-align:left;"><<em>y</em> <sub>1</sub> <em>z</em> <sub>2</sub>, <em>a</em> <sub>2</sub>, 1></td> <td style="text-align:center;">2/3</td> <td style="text-align:center;">1/2</td> </tr> <tr> <td style="text-align:left;"><<em>y</em> <sub>1</sub> <em>z</em> <sub>1</sub>, <em>a</em> <sub>1</sub>, 1></td> <td style="text-align:center;">2/3</td> <td style="text-align:center;">1/2</td> </tr> <tr> <td style="text-align:left;"><<em>y</em> <sub>1</sub> <em>z</em> <sub>2</sub>, <em>a</em> <sub>2</sub>, 1></td> <td style="text-align:center;">2/3</td> <td style="text-align:center;">1/2</td> </tr> </tbody> </table> </div> </section> <section id="sec-6"> <header> <div class="title-info"> <h2> <span class="section-number">3</span> Handling confounding</h2> </div> </header> <p>In most real-world situations, the propensities are not recorded during logging and a valid context definition is needed to compute the propensities, i.e., to model <em>p</em>(<em>a</em>|<em>x</em>). Defining context can be challenging due to lack of visibility into the preceding systems or due to multiple systems simultaneously logging user interactions<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>. Moreover, choosing the full feature vector as context may not be feasible as it can result in underexploration. We recommend a systematic approach, similar to wrapper-based feature-selection techniques [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0006">6</a>], to choose the right context for IPS.</p> <ol class="list-no-style"> <li id="list4" label="(1)">Start with a maximal set of features that look relevant to the logic of action selection in exploration data.<br/></li> <li id="list5" label="(2)">Keep eliminating features until negative log-likelihood on a hold-out set starts increasing.<br/></li> </ol> <p>Increase in negative log-likelihood implies higher confounding. We suggest two guidelines in addition to the mentioned steps - 1) Numeric features should be binned in order to arrive at a discrete context, 2) For datasets with limited exploration logs, early stopping can be employed to trade confounding for better exploration. The described procedure is greedy and can also be followed in the reverse order by adding features. We note that more sophisticated alternatives can be employed for improving the performance further.</p> </section> <section id="sec-7"> <header> <div class="title-info"> <h2> <span class="section-number">4</span> Experimentation</h2> </div> </header> <p>Considering space limitations, we restrict ourselves to discussing experiments on only two datasets obtained from Amazon.</p> <section id="sec-8"> <header> <div class="title-info"> <h3> <span class="section-number">4.1</span> Dataset Description</h3> </div> </header> <section id="sec-9"> <p><em>4.1.1 Payments.</em> This dataset comes from Amazon&#x0027;s payment gateway page, where a user selects a payment method (action) to check-out the cart. A successful transaction results in a non-zero (=1) reward. Along with the action and reward, the system also logs customer, device, location and order related features. This data is collected when no recommendation policy is in place. Therefore, the logic for action selection is completely driven by users&#x2019; choice and we do not have sufficient information to model <em>p</em>(<em>a</em>|<em>x</em>).</p> </section> <section id="sec-10"> <p><em>4.1.2 Search.</em> This dataset comes from the Product Search page of Amazon where a search ranker maps a user query to a ranked list of products within a specified category. Unlike Payments, here the context is well-defined, i.e., a combination of query and category. Reward is 1 if the product is purchased within the session.</p> </section> </section> <section id="sec-11"> <header> <div class="title-info"> <h3> <span class="section-number">4.2</span> Results</h3> </div> </header> <p>We aim to highlight two aspects of our results - 1) Analysis of the ill-effects of confounding on off-policy evaluation (Payments) and off-policy comparison (Search), 2) Successful policy evaluation and A/B test simulation by minimizing the effect of confounding.</p> <section id="sec-12"> <p><em>4.2.1 Payments.</em> We define context by following the steps discussed in Section <a class="sec" href="#sec-6">3</a> and evaluate a payment recommender policy by estimating the success rate using IPS (Feats123 in Table&#x00A0;<a class="tbl" href="#tab2">2</a>). We further delete two sets of features, one at a time, from the defined context, to introduce confounding (Feats12 and Feats1). It is clear that the estimate is closest to the ground truth (measured using % deviation) when the confounding is minimum, i.e., with <em>Feats</em>123. On the other hand, estimates using incomplete contexts are sub-optimal. This proves the merit of the suggested approach.</p> </section> <section id="sec-13"> <p><em>4.2.2 Search.</em> We introduce confounding in Search data by eliminating Category field from the context. Table&#x00A0;<a class="tbl" href="#tab3">3</a> compares four competing policies based on the IPS estimates of the purchase rate (numbers are scaled to maintain confidentiality). The true pair-wise ordering as per three independent A/B tests is P1<P2, P2<P3 and P3>P4. IPS using the complete context is able to predict the outcome of all the three A/B tests correctly, while the order is reversed for the pair P1-P2, when context is incomplete. We also compare IPS estimate of one of the policies with the ground truth and observe that the estimate with the complete context is 20% closer to the target than that with the incomplete context.</p> <div class="table-responsive" id="tab2"> <div class="table-caption"> <span class="table-number">Table 2:</span> <span class="table-title">IPS based evaluation for Payments</span> </div> <table class="table"> <thead> <tr> <th style="text-align:left;">Context</th> <th style="text-align:center;">Neg LL</th> <th style="text-align:center;">% Deviation</th> </tr> </thead> <tbody> <tr> <td style="text-align:left;">Feats123</td> <td style="text-align:center;"> <strong>1.301</strong> </td> <td style="text-align:center;"> <strong>-0.77</strong> </td> </tr> <tr> <td style="text-align:left;">Feats12</td> <td style="text-align:center;">1.307</td> <td style="text-align:center;">+31.47</td> </tr> <tr> <td style="text-align:left;">Feats1</td> <td style="text-align:center;">1.312</td> <td style="text-align:center;">+104.94</td> </tr> </tbody> </table> </div> <div class="table-responsive" id="tab3"> <div class="table-caption"> <span class="table-number">Table 3:</span> <span class="table-title">IPS estimates for Search policies.</span> </div> <table class="table"> <thead> <tr> <th style="text-align:left;">Context</th> <th style="text-align:center;">P1</th> <th style="text-align:center;">P2</th> <th style="text-align:center;">P3</th> <th style="text-align:center;">P4</th> </tr> </thead> <tbody> <tr> <td style="text-align:left;">Query</td> <td style="text-align:center;">23.37</td> <td style="text-align:center;">23.27</td> <td style="text-align:center;">23.80</td> <td style="text-align:center;">23.65</td> </tr> <tr> <td style="text-align:left;">Query+Category</td> <td style="text-align:center;"> <strong>20.07</strong> </td> <td style="text-align:center;"> <strong>20.21</strong> </td> <td style="text-align:center;"> <strong>20.67</strong> </td> <td style="text-align:center;"> <strong>20.39</strong> </td> </tr> </tbody> </table> </div> </section> </section> </section> <section id="sec-14"> <header> <div class="title-info"> <h2> <span class="section-number">5</span> Conclusions</h2> </div> </header> <p>We demonstrated that defining context is a crucial step for applying IPS in a real-world setting. By providing a systematic way of choosing the context and by handling other practical challenges associated with IPS, we successfully evaluated one policy (in Payments) and simulated three A/B tests (in Search) offline.</p> </section> </section> <section class="back-matter"> <section id="ref-001"> <header> <div class="title-info"> <h2 class="page-brake-head">REFERENCES</h2> </div> </header> <ul class="bibUl"> <li id="BibPLXBIB0001" label="[1]">J. Langford, A. Strehl, and J. Wortman. 2008. Exploration Scavenging. In <em> <em>ICML</em> </em>.</li> <li id="BibPLXBIB0002" label="[2]">L. Li, S. Chen, J. Kleban, and A. Gupta. 2015. Counterfactual Estimation and Optimization of Click Metrics in Search Engines: A Case Study. In <em> <em>WWW &#x2019;15 Companion</em> </em>.</li> <li id="BibPLXBIB0003" label="[3]">L. Li, J.&#x00A0;Young Kim, and I. Zitouni. 2015. Toward Predicting the Outcome of an A/B Experiment for Search Relevance. In <em> <em>WSDM</em> </em>.</li> <li id="BibPLXBIB0004" label="[4]">A. Strehl, J. Langford, L. Li, and S. Kakade. 2010. Learning from Logged Implicit Exploration Data.. In <em> <em>NIPS</em> </em>.</li> <li id="BibPLXBIB0005" label="[5]">A. Swaminathan and T. Joachims. 2015. The self-normalized estimator for counterfactual learning. In <em> <em>NIPS</em> </em>.</li> <li id="BibPLXBIB0006" label="[6]">J. Tang, A. Salem, and L. Huan. 2014. Feature selection for classification: A review. In <em> <em>Data Classification: Algorithms and Applications</em> </em>.</li> </ul> </section> </section> <section id="foot-001" class="footnote"> <header> <div class="title-info"> <h2>FOOTNOTE</h2> </div> </header> <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>Collecting logs from multiple policies is desired for IPS as it results in better randomization [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top" href="#BibPLXBIB0004">4</a>]</p> <div class="bibStrip"> <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p> <p> <em>WWW '18, April 23-27, 2018, Lyon, France</em> </p> <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank" href="https://doi.org/10.1145/3184558.3186915">https://doi.org/10.1145/3184558.3186915</a> </p> </div> </section> <div class="pubHistory"> <p/> </div> </body> </html> 
