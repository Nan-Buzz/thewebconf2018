<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>An Improved Sampler for Bayesian Personalized Ranking by
  Leveraging View Data⁎⁎This work was supported in part by the
  National Nature Science Foundation of China under 61621091 and
  61673237, and research fund of Tsinghua University - Tencent
  Joint Laboratory for Internet Innovation Technology.</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3186905'>https://doi.org/10.1145/3184558.3186905</a> 
 Published in WWW2018 Proceedings © 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3186905'>https://w3id.org/oa/10.1145/3184558.3186905</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">An Improved Sampler for Bayesian
          Personalized Ranking by Leveraging View Data<a class="fn"
          href="#fn1" id="foot-fn1"><sup>⁎</sup></a></span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Jingtao</span> <span class=
          "surName">Ding</span> <sup>1</sup>Department of
          Electronic Engineering, Tsinghua University
        </div>
        <div class="author">
          <span class="givenName">Fuli</span> <span class=
          "surName">Feng</span> <sup>2</sup>School of Computing,
          National University of Singapore
        </div>
        <div class="author">
          <span class="givenName">Xiangnan</span> <span class=
          "surName">He</span> <sup>2</sup>School of Computing,
          National University of Singapore
        </div>
        <div class="author">
          <span class="givenName">Guanghui</span> <span class=
          "surName">Yu</span> <sup>1</sup>Department of Electronic
          Engineering, Tsinghua University
        </div>
        <div class="author">
          <span class="givenName">Yong</span> <span class=
          "surName">Li</span> <sup>1</sup>Department of Electronic
          Engineering, Tsinghua University
        </div>
        <div class="author">
          <span class="givenName">Depeng</span> <span class=
          "surName">Jin</span> <sup>1</sup>Department of Electronic
          Engineering, Tsinghua University, <a href=
          "mailto:liyong07@tsinghua.edu.cn;%20xiangnanhe@gmail.com">
          liyong07@tsinghua.edu.cn; xiangnanhe@gmail.com</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186905"
        target=
        "_blank">https://doi.org/10.1145/3184558.3186905</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>Bayesian Personalized Ranking (BPR) is a
        representative pairwise learning method for optimizing
        recommendation models. It is widely known that the
        performance of BPR depends largely on the quality of the
        negative sampler. In this short paper, we make two
        contributions with respect to BPR. First, we find that
        sampling negative items from the whole space is unnecessary
        and may even degrade the performance. Second, focusing on
        the purchase feedback of the E-commerce domain, we propose
        a simple yet effective sampler for BPR by leveraging the
        additional view data. Compared to the vanilla BPR that
        applies a uniform sampler on all candidates, our view-aware
        sampler enhances BPR with a relative improvement of 27.36%
        and 69.54% on two real-world datasets
        respectively.</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>BPR; recommendation;
          sampler; view data.</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Jingtao Ding, Fuli Feng, Xiangnan He, Guanghui Yu, Yong
          Li, and Depeng Jin. 2018. An Improved Sampler for
          Bayesian Personalized Ranking by Leveraging View Data. In
          <em>WWW '18 Companion: The 2018 Web Conference
          Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon,
          France. ACM, New York, NY, USA</em> 3 Pages. <a href=
          "https://doi.org/10.1145/3184558.3186905" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3186905</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Due to the prevalence of user implicit feedback in online
      information systems, recent research on recommendation has
      shifted from explicit ratings to implicit feedback, such as
      purchases, clicks, watches and so on&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0001">1</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0003">3</a>]. To learn recommender
      models from binary implicit feedback, Rendle et al.
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0005">5</a>] proposed
      the BPR method, which assumes that an observed interaction
      should be predicted with a higher score than its unobserved
      counterparts (i.e., the missing interactions).
      Mathematically, the objective function for BPR can be
      formulated as</p>
      <div class="table-responsive" id="eq1">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation}
          \mathop{arg\,min}_{\Theta } \sum _{(u,i,j)\in \mathcal
          {D}} -\ln \sigma (\hat{y}_{ui}(\Theta) -
          \hat{y}_{uj}(\Theta)), \end{equation}</span><br />
          <span class="equation-number">(1)</span>
        </div>
      </div>where <span class="inline-equation"><span class=
      "tex">$\hat{y}(\Theta)$</span></span> is the predictive
      model, <em>Θ</em> denotes the model parameters, <span class=
      "inline-equation"><span class="tex">$\sigma
      (x)=\frac{1}{1+\exp (-x)}$</span></span> is the sigmoid
      function to convert the margin to a probability, and
      <span class="inline-equation"><span class="tex">$\mathcal
      {D}$</span></span> denotes the set of pairwise training
      examples: <span class="inline-equation"><span class=
      "tex">$\lbrace (u,i,j)| i\in \mathcal {R}_u^+ \wedge j\notin
      \mathcal {R}_u^+ \rbrace$</span></span> , where <span class=
      "inline-equation"><span class="tex">$\mathcal
      {R}_u^+$</span></span> denotes the set of items that
      <em>u</em> has interacted with before. Note that we have
      omitted the <em>L</em> <sub>2</sub> regularization terms for
      clarity. The optimization of BPR is usually achieved by the
      stochastic gradient descent (SGD). In each step, it first
      randomly draws an observed interaction (<em>u</em>,
      <em>i</em>), and then selects an item <em>j</em> that
      <em>u</em> has not interacted with before to constitute
      (<em>u</em>, <em>i</em>, <em>j</em>). Such a process of
      selecting <em>j</em> is also known as <em>negative
      sampling</em>.
      <p></p>
      <p>In the original paper of BPR [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>], Rendle et al. applied a uniform
      negative sampler, i.e., sampling <em>j</em> from <strong>all
      items</strong> that <em>u</em> has not consumed before with
      an <strong>equal probability</strong>. Later on, it was
      reported that such a uniform negative sampler is highly
      ineffective and slows down the convergence of
      BPR&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0004">4</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0006">6</a>], especially
      for datasets that have a large number of items. To this end,
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0004">4</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0006">6</a>] proposed
      dynamic negative sampling (DNS) strategies, aiming to
      maximize the utility of a gradient step by choosing
      “difficult” negative examples — i.e., the negative examples
      that lead to a large prediction loss by the current model.
      Despite that significant improvements have been observed,
      existing DNS strategies sample negative items from the whole
      item space, which arguably may still suffer from low
      efficiency when the number of items is large.</p>
      <p>In this work, we aim to answer the following two research
      questions: 1) Is it necessary to sample negative items from
      the whole space? and 2) Can we design a better sampler for
      BPR?</p>
    </section>
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Experimental
          Settings</h2>
        </div>
      </header>
      <p><strong>Datasets</strong>. We perform experiments on two
      real-world datasets.</p>
      <p><strong>Beibei</strong><a class="fn" href="#fn3" id=
      "foot-fn3"><sup>1</sup></a>: Beibei is the largest E-commerce
      platform for maternal and infant products in China. We
      sampled a subset of user interactions that contain views and
      purchases from Beibei within the time period from 2017/05/25
      to 2017/06/28.</p>
      <p><strong>Tmall</strong><a class="fn" href="#fn4" id=
      "foot-fn4"><sup>2</sup></a>: Tmall is the largest
      business-to-consumer E-commerce platform in China. To allow
      our results to be reproducible, we used a public benchmark
      released by the ICJAI-2015<a class="fn" href="#fn5" id=
      "foot-fn5"><sup>3</sup></a>.</p>
      <p>We took three steps for data preprocessing. We first
      merged the repetitive purchases into one purchase with the
      earliest timestamp, as we aim to recommend novel items. Next
      we filtered out users’ views on their purchased items to
      avoid information leaking. Finally, we filtered out users and
      items with less than 12 and 16 purchases, respectively, to
      overcome the high sparsity of the raw datasets.
      Table&nbsp;<a class="tbl" href="#tab1">1</a> summarizes the
      statistics of our experiment datasets.</p>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">Statistics of the evaluation
          datasets.</span>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <td style="text-align:center;">
              <strong>Dataset</strong></td>
              <td style="text-align:center;">
              <strong>Purchase#</strong></td>
              <td style="text-align:center;">
              <strong>View#</strong></td>
              <td style="text-align:center;">
              <strong>User#</strong></td>
              <td style="text-align:center;">
              <strong>Item#</strong></td>
              <td style="text-align:center;">
              <strong>Sparsity</strong></td>
            </tr>
            <tr>
              <td style="text-align:center;">Beibei</td>
              <td style="text-align:center;">2,654,467</td>
              <td style="text-align:center;">46,912,880</td>
              <td style="text-align:center;">158,907</td>
              <td style="text-align:center;">119,012</td>
              <td style="text-align:center;">99.99%/99.75%</td>
            </tr>
            <tr>
              <td style="text-align:center;">Tmall</td>
              <td style="text-align:center;">464,426</td>
              <td style="text-align:center;">1,585,225</td>
              <td style="text-align:center;">28,059</td>
              <td style="text-align:center;">32,339</td>
              <td style="text-align:center;">99.95%/99.83%</td>
            </tr>
          </tbody>
        </table>
      </div>
      <p><strong>Evaluation Methodology</strong>. We adopted the
      <em>leave-one-out</em> protocol&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0003">3</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0005">5</a>], where the latest purchase
      interaction of each user is held out for testing. For
      hyperparameter tuning, we randomly sampled one purchase
      interaction for each user as the validation set. The training
      process was stopped once we observed increasing in the
      validation loss. We employed <em>Hit
      Ratio</em>&nbsp;(HR)&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>] for each user by truncating the
      ranked list of non-purchased items at the position of 100 and
      reported the average score of all users. We used the standard
      matrix factorization&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>] as the predictive model, where the
      number of latent factors equals to 32.</p>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Unnecessary to
          sample from all items</h2>
        </div>
      </header>
      <p>We controlled the sampling space of BPR on a user basis.
      For each user, the negative items are only sampled from a
      fraction of items, i.e., a randomly reduced item space. We
      varied the size and summarized the performance in Table
      <a class="tbl" href="#tab2">2</a>. For each setting, we
      repeated the experiment five times and reported the average
      score. The first row indicates the performance of the
      original BPR that samples negative items from the whole
      space.</p>
      <div class="table-responsive" id="tab2">
        <div class="table-caption">
          <span class="table-number">Table 2:</span> <span class=
          "table-title">Performance of BPR with different settings
          on the ratio of the reduced sampling space. “Size” means
          the number of items in sampling space for each
          user&nbsp;(Ratio × Item#).</span>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <td colspan="4" style="text-align:center;">
                <strong>Beibei</strong>
                <hr />
              </td>
              <td colspan="4" style="text-align:center;">
                <strong>Tmall</strong>
                <hr />
              </td>
            </tr>
            <tr>
              <td style="text-align:center;">
              <strong>Ratio</strong></td>
              <td style="text-align:center;">
              <strong>Size</strong></td>
              <td style="text-align:center;">
              <strong>HR</strong></td>
              <td style="text-align:center;">
              <strong><em>Δ</em>HR</strong></td>
              <td style="text-align:center;">
              <strong>Ratio</strong></td>
              <td style="text-align:center;">
              <strong>Size</strong></td>
              <td style="text-align:center;">
              <strong>HR</strong></td>
              <td style="text-align:center;">
              <strong><em>Δ</em>HR</strong></td>
            </tr>
            <tr>
              <td style="text-align:center;">2<sup>0</sup></td>
              <td style="text-align:center;">119,012</td>
              <td style="text-align:center;">0.1094</td>
              <td style="text-align:center;">0</td>
              <td style="text-align:center;">2<sup>0</sup></td>
              <td style="text-align:center;">32,339</td>
              <td style="text-align:center;">0.0301</td>
              <td style="text-align:center;">0</td>
            </tr>
            <tr>
              <td style="text-align:center;">2<sup>− 6</sup></td>
              <td style="text-align:center;">1,859</td>
              <td style="text-align:center;">0.1112</td>
              <td style="text-align:center;">+2.03%</td>
              <td style="text-align:center;">2<sup>− 3</sup></td>
              <td style="text-align:center;">4,042</td>
              <td style="text-align:center;">0.0300</td>
              <td style="text-align:center;">-0.27%</td>
            </tr>
            <tr>
              <td style="text-align:center;">2<sup>− 7</sup></td>
              <td style="text-align:center;">930</td>
              <td style="text-align:center;">0.1103</td>
              <td style="text-align:center;">+1.22%</td>
              <td style="text-align:center;">2<sup>− 4</sup></td>
              <td style="text-align:center;">2,021</td>
              <td style="text-align:center;">0.0300</td>
              <td style="text-align:center;">-0.33%</td>
            </tr>
            <tr>
              <td style="text-align:center;">2<sup>− 8</sup></td>
              <td style="text-align:center;">465</td>
              <td style="text-align:center;">0.1106</td>
              <td style="text-align:center;">+1.50%</td>
              <td style="text-align:center;">2<sup>− 5</sup></td>
              <td style="text-align:center;">1010</td>
              <td style="text-align:center;">0.0297</td>
              <td style="text-align:center;">-1.33%</td>
            </tr>
            <tr>
              <td style="text-align:center;">2<sup>− 9</sup></td>
              <td style="text-align:center;">232</td>
              <td style="text-align:center;">0.1104</td>
              <td style="text-align:center;">+1.26%</td>
              <td style="text-align:center;">2<sup>− 6</sup></td>
              <td style="text-align:center;">505</td>
              <td style="text-align:center;">0.0299</td>
              <td style="text-align:center;">-0.60%</td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>Surprisingly on the Beibei dataset, the performance is not
      decreased but increased after reducing the sampling space.
      For example, when the sampling space is 1/2<sup>9</sup>
      smaller, we obtained a relative improvement of 1.26% over the
      original BPR. This finding is novel and encouraging, meaning
      that sampling from the whole item space is not only
      unnecessary for BPR, but may even hurt the performance. On
      the Tmall dataset, as the original item space is not that
      large (which is one magnitude smaller), we did not observe
      improvements by reducing the sampling space. But still, we
      can see that with a much smaller sampling space, the
      performance remains the same level as the original BPR. This
      provides further evidence on the inefficiency of the uniform
      sampler for BPR.</p>
    </section>
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> A View-Enhanced
          Sampler</h2>
        </div>
      </header>
      <p>In E-commerce recommender systems, besides the purchase
      feedback that is directly related to optimizing the
      conversion rate, the view logs of users can be intuitively
      treated as an intermediate feedback between the purchased and
      missing interactions. Since a training example <span class=
      "inline-equation"><span class="tex">$(u,i,j)\in \mathcal
      {D}$</span></span> in BPR assumes that <em>u</em> prefers
      <em>i</em> over <em>j</em>, we can integrate the view signal
      by augmenting the training data. In our proposed
      view-enhanced sampler, we split the item space into three
      sets for each user <em>u</em>, namely <span class=
      "inline-equation"><span class="tex">$\mathcal
      {P}_u$</span></span> , <span class=
      "inline-equation"><span class="tex">$\mathcal
      {V}_u$</span></span> , and <span class=
      "inline-equation"><span class="tex">$\mathcal
      {R}_u$</span></span> , which indicate the purchased items,
      viewed (but not purchased) items, and remaining items,
      respectively. Then, we sample an item pair (<em>i</em>,
      <em>j</em>) from three candidate sets, <span class=
      "inline-equation"><span class="tex">$\lbrace (i,j)|i\in
      \mathcal {P}_u,j\in \mathcal {V}_u\rbrace$</span></span> ,
      <span class="inline-equation"><span class="tex">$\lbrace
      (i,j)|i\in \mathcal {P}_u,j\in \mathcal
      {R}_u\rbrace$</span></span> , and <span class=
      "inline-equation"><span class="tex">$\lbrace (i,j)|i\in
      \mathcal {V}_u,j\in \mathcal {R}_u\rbrace$</span></span> ,
      with predefined probabilities [<em>ω</em> <sub>1</sub>,
      <em>ω</em> <sub>2</sub>, <em>ω</em> <sub>3</sub>]
      respectively, where <em>ω</em> <sub>1</sub> + <em>ω</em>
      <sub>2</sub> + <em>ω</em> <sub>3</sub> = 1. The generated
      training example (<em>u</em>, <em>i</em>, <em>j</em>) is
      finally used to update the model parameters in
      Eq.&nbsp;(<a class="eqn" href="#eq1">1</a>). We term the BPR
      method with this view-enhanced sampler as
      <em>BPR+view</em>.</p>
      <p>Our proposed BPR+view achieved the best performance when
      [<em>ω</em> <sub>1</sub>, <em>ω</em> <sub>2</sub>, <em>ω</em>
      <sub>3</sub>] are set as [0.3, 0.3, 0.4] and [0.01, 0.09,
      0.9] on the Beibei and Tmall datasets, respectively. To
      demonstrate its effectiveness, we compare it with 1) the
      vanilla BPR [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0005">5</a>],
      and 2) BPR-DNS&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0006">6</a>], which selects the item with the
      highest prediction score among <em>X</em> randomly sampled
      negatives. For BPR-DNS, we tuned the <em>X</em> in the same
      way as the original paper. To our knowledge, DNS is the most
      effective sampler to date for BPR based on the interaction
      data only, and empirically outperforms [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0004">4</a>]. In addition, we evaluated
      a common baseline Popularity&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0003">3</a>], which simply recommends
      items based on their popularity evidenced by the number of
      purchases.</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186905/images/www18companion-145-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">Performance comparison in each
          iteration.</span>
        </div>
      </figure>
      <p></p>
      <p>Figure&nbsp;<a class="fig" href="#fig1">1</a> shows the
      testing HR of the compared methods in each training
      iteration. As can be seen, upon convergence, BPR+view
      significantly outperforms all other methods, and the
      improvements are more significant on the Tmall dataset (60%+
      relative improvements over BPR and BPR-DNS). This justifies
      the efficacy of accounting for the preference signal in the
      view data using our proposed sampler. Besides, we observed
      that Popularity performs as well as BPR on the Beibei
      dataset, which is unexpected since BPR is a personalized
      recommendation method. Our further investigation finds that
      the reason is because the Beibei dataset is highly
      popularity-skewed — the top-1% items contributed almost 50%
      of purchases.</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Future
          Work</h2>
        </div>
      </header>
      <p>We have demonstrated that sampling negative items from the
      whole space is unnecessary for BPR, and proposed an enhanced
      sampler based on the view data. In future, we will design an
      adaptive sampler to leverage view data and other implicit
      feedback more sufficiently. Furthermore, we plan to explore
      more generic feature-based recommender models, such as the
      state-of-the-art neural facterization machine&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0002">2</a>].</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Immanuel Bayer, Xiangnan
        He, Bhargav Kanagal, and Steffen Rendle. 2017. A Generic
        Coordinate Descent Framework for Learning from Implicit
        Feedback. In <em><em>WWW</em></em> . 1341–1350.</li>
        <li id="BibPLXBIB0002" label="[2]">Xiangnan He and Tat-Seng
        Chua. 2017. Neural factorization machines for sparse
        predictive analytics. In <em><em>SIGIR</em></em> .
        355–364.</li>
        <li id="BibPLXBIB0003" label="[3]">Xiangnan He, Lizi Liao,
        Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua.
        2017. Neural collaborative filtering. In
        <em><em>WWW</em></em> . 173–182.</li>
        <li id="BibPLXBIB0004" label="[4]">Steffen Rendle and
        Christoph Freudenthaler. 2014. Improving pairwise learning
        for item recommendation from implicit feedback. In
        <em><em>WSDM</em></em> . 273–282.</li>
        <li id="BibPLXBIB0005" label="[5]">Steffen Rendle,
        Christoph Freudenthaler, Zeno Gantner, and Lars
        Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking
        from Implicit Feedback. In <em><em>UAI</em></em> .
        452–461.</li>
        <li id="BibPLXBIB0006" label="[6]">Weinan Zhang, Tianqi
        Chen, Jun Wang, and Yong Yu. 2013. Optimizing top-n
        collaborative filtering via dynamic negative item sampling.
        In <em><em>SIGIR</em></em> . 785–788.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>⁎</sup></a>This work was
    supported in part by the National Nature Science Foundation of
    China under 61621091 and 61673237, and research fund of
    Tsinghua University - Tencent Joint Laboratory for Internet
    Innovation Technology.</p>
    <p id="fn3"><a href="#foot-fn3"><sup>1</sup></a><a class=
    "link-inline force-break" href=
    "http://www.beibei.com/">http://www.beibei.com/</a></p>
    <p id="fn4"><a href="#foot-fn4"><sup>2</sup></a><a class=
    "link-inline force-break" href=
    "https://www.tmall.com/">https://www.tmall.com/</a></p>
    <p id="fn5"><a href="#foot-fn5"><sup>3</sup></a>The dataset is
    downloaded from <a class="link-inline force-break" href=
    "https://tianchi.aliyun.com/datalab/dataSet.htm?id=5">https://tianchi.aliyun.com/datalab/dataSet.htm?id=5</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3186905">https://doi.org/10.1145/3184558.3186905</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
