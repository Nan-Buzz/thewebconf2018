<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>Real-time Detection of Content Polluters in Partially Observable Twitter Networks</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main">  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">Real-time Detection of Content Polluters in Partially Observable Twitter Networks</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author">     <span class="givenName">Mehwish</span>     <span class="surName">Nasim</span>     School of Mathematical Sciences University of Adelaide, Adelaide, Australia, <a href="mailto:mehwish.nasim@adelaide.edu.au">mehwish.nasim@adelaide.edu.au</a>    </div>    <div class="author">     <span class="givenName">Andrew</span>     <span class="surName">Nguyen</span>     School of Mathematical Sciences University of Adelaide, Adelaide, Australia, <a href="mailto:andrew.nguyen03@adelaide.edu.au">andrew.nguyen03@adelaide.edu.au</a>    </div>    <div class="author">     <span class="givenName">Nick</span>     <span class="surName">Lothian</span>     Tyto.ai, Adelaide, Australia<a class="fn" href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>, <a href="mailto:nick.lothian@gmail.com">nick.lothian@gmail.com</a>    </div>    <div class="author">     <span class="givenName">Robert</span>     <span class="surName">Cope</span>     School of Mathematical Sciences University of Adelaide, Adelaide, Australia, <a href="mailto:robert.cope@adelaide.edu.au">robert.cope@adelaide.edu.au</a>    </div>    <div class="author">     <span class="givenName">Lewis</span>     <span class="surName">Mitchell</span>     School of Mathematical Sciences University of Adelaide, Adelaide, Australia, <a href="mailto:lewis.mitchell@adelaide.edu.au">lewis.mitchell@adelaide.edu.au</a>    </div>                        </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3184558.3191574" target="_blank">https://doi.org/10.1145/3184558.3191574</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>Content polluters, or bots that hijack a conversation for political or advertising purposes are a known problem for event prediction, election forecasting and when distinguishing real news from fake news in social media data. Identifying this type of bot is particularly challenging, with state-of-the-art methods utilising large volumes of network data as features for machine learning models. Such datasets are generally not readily available in typical applications which stream social media data for real-time event prediction. In this work we develop a methodology to detect content polluters in social media datasets that are streamed in real-time. Applying our method to the problem of civil unrest event prediction in Australia, we identify content polluters from individual tweets, without collecting social network or historical data from individual accounts. We identify some peculiar characteristics of these bots in our dataset and propose metrics for identification of such accounts. We then pose some research questions around this type of bot detection, including: how good Twitter is at detecting content polluters and how well state-of-the-art methods perform in detecting bots in our dataset.</small>    </p>    </div>    <div class="CCSconcepts">    <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Social networking sites;</strong> &#x2022;<strong> Security and privacy </strong>&#x2192; <em>Social network security and privacy;</em></small> </p>    </div>    <div class="classifications">    <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Civil unrest</small>, </span>     <span class="keyword">      <small> Social bots</small>, </span>     <span class="keyword">      <small> Content polluters</small>, </span>     <span class="keyword">      <small> Missing links</small>, </span>     <span class="keyword">      <small> Twitter</small>     </span>    </div>    <br/>    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Mehwish Nasim, Andrew Nguyen, Nick Lothian, Robert Cope, and Lewis Mitchell. 2018. Real-time Detection of Content Polluters in Partially Observable Twitter Networks. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 9 Pages. <a href="https://doi.org/10.1145/3184558.3191574" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3184558.3191574</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-6">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>    </div>    </header>    <section id="sec-7">    <header>     <div class="title-info">      <h3>       <span class="section-number">1.1</span> Motivation</h3>     </div>    </header>    <p>Bots and content polluters in online social media affect the socio-political state of the world, from meddling in elections [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>] to influencing US veterans [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>]. In late September 2017, Twitter admitted to Congress that it had found 200 Russian accounts that overlapped with Facebook accounts which were used to sway Americans and create divisions during the elections held in 2016 [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>]. Of course, some bots are useful as well, for instance accounts that will tweet alerts to people about natural disasters. The problem arises when they try to influence people or spread misinformation. The importance of detecting bots in online social media has produced an active research area on this topic [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0021">21</a>].</p>    <p>State-of-the-art methods for bot detection use historical patterns of behaviour and a rich feature set including textual, temporal, and social network features, to distinguish automated bots from real human users [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0035">35</a>]. However, for real-time application using large streamed datasets, such methods can be prohibitive due to the sheer volume, velocity, and incompleteness of data samples. In this work we develop a new method to detect one particular type of social bot &#x2013; content polluters &#x2013; in streamed microblog datasets such as Twitter. Content polluters are bots that attempt to subvert a genuine discussion by hijacking it for political or advertising purposes. As we will show, these bots are a major concern for applications such as real-time event prediction, such as social unrest, from social media datasets.</p>    </section>    <section id="sec-8">    <header>     <div class="title-info">      <h3>       <span class="section-number">1.2</span> Problem context</h3>     </div>    </header>    <p>Social unrest prediction is a growing concern for governments worldwide. This is evidenced by DARPA&#x0027;s Open Source Intelligence program, which produced numerous methods to predict the occurrence of future population-level events such as civil unrest, political crises, election outcomes and disease outbreaks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>]. It has been observed that social events are either preceded or followed by changes in population-level communication behaviour, consumption and movement. A large fraction of population-level changes are implicitly reflected in online data such as blogs, online social networks, financial markets, or search queries. Some of these data sources have been shown to effectively detect population-level events in real time. Methods have been developed for predicting such events by fusing publicly available data from multiple sources. There exists a plethora of research focused on social media-based forecasting models, suggesting that features from micro-blogs such as Twitter can predict and detect population-level events [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0030">30</a>]. Once one develops a &#x201C;gold standard&#x201D; (ground truth) record of known events (e.g. election results, or protests occurring) models can be trained using open source data to make predictions. A significant challenge for such models is noise reduction through filtering &#x201C;fake news&#x201D;, removing misclassified or irrelevant tweets, or mitigating the effects of missing data. This is of particular concern, as the changing limits on accessing social media data remains a major challenge for researchers [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>]. Access to data through APIs and third parties can be inconsistent, incomplete, and corrupted by noise in the form of bots. Where bots are influencing people through fake social media accounts, they also act as <em>content polluters</em> on social media sites [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0033">33</a>]. According to the Digital Forensics Research Lab (DFRL), &#x201C;They can make a group of six people look like a group of 46,000 people.&#x201D;</p>    <p>The main goal of our work was finding out content polluters in a dataset comprising tweets related to Australian social unrest events in real time, without access to complete profile information of the users. Due to rate limits on the public API and the high cost of accessing data, we were restricted to using only streamed tweets satisfying certain criteria. While the actual event prediction algorithm is not the primary concern of this paper, further detail can be found in Osborne <em>et al.</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>].</p>    <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">Data statistics</span>     </div>     <table class="table">      <tbody>       <tr>       <td style="text-align:left;">Parameters</td>       <td style="text-align:left;">Adelaide</td>       <td style="text-align:left;">Brisbane</td>       <td style="text-align:left;">Melbourne</td>       <td style="text-align:left;">Perth</td>       <td>Sydney</td>       </tr>       <tr>       <td style="text-align:left;">Number of tweets</td>       <td style="text-align:left;">14087</td>       <td style="text-align:left;">5913</td>       <td style="text-align:left;">23720</td>       <td style="text-align:left;">8421</td>       <td>31568</td>       </tr>       <tr>       <td style="text-align:left;">Number of unique users</td>       <td style="text-align:left;">12039</td>       <td style="text-align:left;">3466</td>       <td style="text-align:left;">14611</td>       <td style="text-align:left;">6215</td>       <td>14515</td>       </tr>       <tr>       <td style="text-align:left;">Number of unique URLs</td>       <td style="text-align:left;">548</td>       <td style="text-align:left;">233</td>       <td style="text-align:left;">762</td>       <td style="text-align:left;">456</td>       <td>844</td>       </tr>       <tr>       <td style="text-align:left;">Average number of followers (in degree)</td>       <td style="text-align:left;">8812</td>       <td style="text-align:left;">9624</td>       <td style="text-align:left;">6733</td>       <td style="text-align:left;">5409</td>       <td>6052</td>       </tr>       <tr>       <td style="text-align:left;">Average number friends (out degree)</td>       <td style="text-align:left;">1223</td>       <td style="text-align:left;">1736</td>       <td style="text-align:left;">1517</td>       <td style="text-align:left;">1643</td>       <td>1860</td>       </tr>       <tr>       <td style="text-align:left;">Number of verified accounts</td>       <td style="text-align:left;">293</td>       <td style="text-align:left;">432</td>       <td style="text-align:left;">840</td>       <td style="text-align:left;">209</td>       <td>412</td>       </tr>      </tbody>     </table>    </div>    </section>    <section id="sec-9">    <header>     <div class="title-info">      <h3>       <span class="section-number">1.3</span> Related Work</h3>     </div>    </header>    <p>A social bot is a computer algorithm that automatically produces content and interacts with humans on social media, trying to emulate and possibly alter their behaviour [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>]. Social bots inhabit social media platforms, and online social networks are inundated by millions of bots exhibiting increasingly sophisticated, human-like behaviour. In the coming years a proliferation of social media bots is expected as advertisers, criminals, politicians, governments, terrorists, and other organizations attempt to influence populations [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0034">34</a>]. This introduces dimensions for social bots, including social network characteristics, temporal activity, diffusion patterns, and sentiment expression [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>].</p>    <p>Ghost <em>et al.</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0016">16</a>] conducted an analysis on the follower/followee links acquired by over 40,000 spammer accounts suspended by Twitter. They showed that penalizing users for connecting to spammers can be effective because it would de-incentivize users from linking with other users in order to gain influence. Yang <em>et al.</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0040">40</a>] found that bot accounts in online social networks connect to each other by chance and integrate into the social network just like normal users. Network information along with content has been shown to detect spam in online social networks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>]. While researchers were proposing various bot-detection models, Lee <em>et al.</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0024">24</a>] identified and engaged strangers on social media to effectively propagate information/misinformation. They proposed a model to leverage peoples&#x2019; social behaviour (online interactions) and users&#x2019; wait times for retweeting.</p>    <p>Social bots evolve over time, making them resilient against standard bot detection approaches [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>]. They are apt at changing discussion topics and posting activities [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0038">38</a>]. Researchers have proposed complex models, such as those based on interaction graphs of suspicious accounts [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0039">39</a>]. An adversary often controls multiple social bots known as a <em>sybil</em>. One strategy to detect such accounts relies on investigating social graph structure, on the assumption that sybil accounts link to a small number of legitimate users [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0007">7</a>]. Behavioural patterns and sentiments analysis have also been used for bot detection [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>]. Such patterns can easily be encoded in features, thus machine learning techniques can be used to distinguish bot-like from human-like behaviour. Previous work uses network-based features or content analysis for bot detection, along with indicators such as temporal activity, retweets, and crowd sourcing [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0036">36</a>]. Such efforts require substantial network knowledge or the ability to quickly query an API for a complete history of social media postings by suspected bots. However, real-time applications, such as streaming messages based on keywords or geographic locations, render this impractical. A major challenge therefore is developing methodologies to detect and remove bots based on partial information, message histories, and network knowledge, in real time.</p>    <p>In this work we detect bots from individual tweets downloaded for predicting social unrest in Australian cities. Given filters on keywords and geographic location of events (such as protests, rallies, civil disturbances) collected in real time, it leaves a small but informative dataset for prediction. Predictions are generated in real time by analysing data from online social media platforms such as Twitter and validated against hand-labeled &#x201C;Gold standard records&#x201D; (<em>GSR</em>) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>]. The GSR is created by the news analysts; after going through a validation and cleaning process this data is ready to be used as the ground truth. If Twitter data is contaminated with social bots, it can greatly degrade prediction models. It is therefore imperative to develop techniques for detecting and removing social bots for real-time data streams.</p>    <p>     <strong>Contributions:</strong> Our scientific contributions are as follows:</p>    <ol class="list-no-style">     <li id="list1" label="(1)">We develop a method to identify social bots in data using only partial information about the user and their tweet history, in real time.<br/></li>     <li id="list2" label="(2)">We present a new dataset of hand-labelled bots and legitimate records, and use it to validate our method<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a>.<br/></li>     <li id="list3" label="(3)">We pose a set of research questions for evaluating whether Twitter users, Twitter, or existing state-of-the-art bot detection methods could detect bots in our dataset or not.<br/></li>    </ol>    </section>    <section id="sec-10">    <header>     <div class="title-info">      <h3>       <span class="section-number">1.4</span> Dataset</h3>     </div>    </header>    <p>Our dataset consists of timestamped tweets from 1 January 2015 till 31 December 2016 from 5 major capital cities in Australia. Tweets identify one of the following locations: &#x2018;Australia&#x2019;, &#x2018;Adelaide&#x2019;, &#x2018;Brisbane&#x2019;, &#x2018;Melbourne&#x2019;, &#x2018;Perth&#x2019;, or &#x2018;Sydney&#x2019;. The data are targeted at studying civil unrest and intends to capture ways in which people express opinions and organize marches, rallies, peaceful/violent protests etc., within Australia. Such events aim to draw attention toward an issue e.g., infrastructure, taxes, immigration laws etc. Australia has a population of about 24.5 million people and, like in many developed countries, predicting civil unrest events is of interest to law enforcement agencies, government bodies, media and academia. Notwithstanding this fact, the literature is devoid of exploratory studies conducted on this population for real-time prediction of civil unrest events. The basic statistics about protest-related tweets in our dataset are reported in Table <a class="tbl" href="#tab1">1</a>.</p>    <p>Note that the dataset was devoid of information on the alters (followers/friends of egos), except for the total count of alters (numbers of followers and friends). <figure id="fig1">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191574/images/www18companion-313-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 1:</span>       <span class="figure-title">Graphs containing bots and legitimate users from the Melbourne events network.</span>      </div>     </figure>     <figure id="fig2">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191574/images/www18companion-313-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Graph containing bots and legitimate users from the Melbourne events network.</span>      </div>     </figure>    </p>    </section>   </section>   <section id="sec-11">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> Detecting content polluters</h2>    </div>    </header>    <p>We investigate two characteristics of tweets i.e., temporal information and message diversity in a tweet. <figure id="fig3">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191574/images/www18companion-313-fig3.jpg" class="img-responsive" alt="Figure 3"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 3:</span>      <span class="figure-title">Message diversity measured through 3 URLs for bots and genuine users.</span>     </div>    </figure>    </p>    <p>    <strong>Temporal Patterns:</strong> In the first step we were interested in 1). users who tweet frequently, 2). pairs of users who tweet on the same day using the desired keywords. Since no information about the network of individual users is available, we cannot construct a follower-friend network graph. Instead, we construct a two mode user-event network. For all the events in the data we connect two users if they have tweeted on the same event day. We represent this problem in graph theoretic terms as follows:</p>    <p>Let <em>G</em> be a bipartite graph of users and events. Let <em>U</em> be the set of users and let <em>V</em> be the set of events. Let <em>u</em>, <em>v</em> &#x2208; <em>U</em> and let <em>i</em>, <em>j</em> &#x2208; <em>V</em>. For any <em>i</em> &#x2208; <em>V</em> if <em>N</em>(<em>u</em>)&#x2229;<em>N</em>(<em>v</em>) &#x2260; {} then (<em>u</em>, <em>v</em>) &#x2208; <em>E</em> in the one-mode projection of the bipartite graph. The <em>neighbourhood N</em>(<em>v</em>) of a vertex <em>v</em> &#x2208; <em>U</em> is the set of vertices that are adjacent to <em>v</em>. The resulting projection is an undirected loopless multigraph. If the edge set <em>E</em> contains the same edge several times, then <em>E</em> is a multiset. If an edge occurs several times in <em>E</em>, the copies of that edge are called parallel edges. Graphs that have parallel edges are also called multigraphs. <figure id="fig4">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191574/images/www18companion-313-fig4.jpg" class="img-responsive" alt="Figure 4"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 4:</span>      <span class="figure-title">Gini score for ten URLs. High Gini coefficient indicates a legitimate URL. The three URLs with the lowest Gini coefficients were being tweeted by content-polluting bots.</span>     </div>    </figure>    </p>    <p>Similar to other social networks such as friendship networks, event networks are a result of complex sociological processes with a multitude of relations. When such relations are conflated into a dense network, the visualization often resembles a &#x201C;hairball&#x201D;. Various approaches to declutter drawings of such networks exist in the literature. We use the recent <em>backbone layout</em> approach for network visualization [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>], which accounts for strong ties (or multiplicity of edges) and uses the union of all maximum spanning trees as a sparsifier to ensure a connected subgraph. In Figure 1b, the thickness of edges represents how often a pair of nodes tweet on the same &#x2019;event day&#x2019;<a class="fn" href="#fn3" id="foot-fn3"><sup>2</sup></a> whereas, the size of the nodes indicates the individual frequency of tweets by a user<a class="fn" href="#fn4" id="foot-fn4"><sup>3</sup></a>. We noticed that bots tweeted together frequently. Their individual frequency to tweet is low as compared to other nodes in the graph, however the dyadic (pairwise) frequency is higher. For instance, the two purple nodes on the right have tweeted together frequently, in Figure 1a . Their individual frequency to tweet is low as compared to other nodes in the graph, however the dyadic (pairwise) frequency is higher. These two nodes are weakly connected to the core. Upon checking their complete profiles, the users were found to be political bots. This motivated us to further explore the tweets-graph.</p>    <p>The core of the network (green nodes) were found to be news channels and popular blogs in Australia, such as <em>MelbLiveNews</em>, <em>newsonaust</em>, <em>7NewsMelbourne</em> and <em>LoversMelbourne</em> to name a few. Media accounts are likely to report population-level events on the day of the events, thus they form a strongly-connected core of the events network graph.</p>    <p>We then clustered all tweets in a similar manner to construct a graph where two users have an edge between them if they have tweeted on the same day, irrespective of whether there was an event that day or not. We used the Louvain Method for clustering the network [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>], based on the concept of <em>modularity</em>. Optimizing the modularity results in the best possible grouping of nodes in a given network. We then found two strongly-connected components in the graph: 1. News channels, and 2. Bots. We analysed the strongly-connected vertex-induced subgraphs from the network. One such component for the city of <em>Melbourne</em> is shown in Figure <a class="fig" href="#fig2">2</a>, which is a strongly-connected component from Figure 1b . Bots are the purple nodes (validated by manual inspection of profiles). Green nodes represent false positives. Orange nodes are not bots but are also not relevant for predictions, since these users were not geographically located in Australia and were tweeting about Victoria in the UK.</p>    <p>    <strong>Message diversity:</strong> We computed the diversity in the tweets based upon mentions of URLs and hashtags. We selected the top most tweeted URLs, {<em>K</em>} (|<em>K</em>| = 20), and then filtered out the users (<span class="inline-equation"><span class="tex">$\bar{U} \subseteq U$</span>    </span>) who mentioned those URLs. The motivation for this approach is that an event prediction model should be resilient against bot-URLs that are infrequently mentioned in the tweets, so these will not greatly impact the prediction accuracy. We then computed the following three measures for each of the remaining users: i). total number of tweets containing any URL(s), <span class="inline-equation"><span class="tex">$u^{all}_i$</span>    </span>, ii). number of tweets mentioning URL <em>k</em> &#x2208; <em>K</em>, <span class="inline-equation"><span class="tex">$u^k_i$</span>    </span> and iii). diversity score i.e., the difference between the two measures, <span class="inline-equation"><span class="tex">$u^d_i = u^{all}_i - u^k_i$</span>    </span>.</p>    <p>We then plot the diversity score distribution for every <span class="inline-equation"><span class="tex">$u^k \in \bar{U}$</span>    </span>, for every URL <em>k</em> &#x2208; <em>K</em>. This immediately provides some relevant insights about the behaviour of content polluters: Figure 3a shows a legitimate URL (i.e., linked to by legitimate users), whereas, Figures 3b and 3c show bot-URLs (i.e., URLs linked to by bots). Users who tweet these URLs are classified as <em>potential bots</em>. The figures show that the diversity of users linking to legitimate URLs is generally far greater than those linking to bot-URLs. The temporal patterns of bot-URL mentions and those which are being tweeted at regular intervals indicated that these users were indeed bots.</p>    <p>We measure the extent of diversity in two ways:</p>    <ol class="list-no-style">    <li id="list4" label="(1)"><em>The Gini</em> coefficient (<span class="inline-equation"><span class="tex">$G \in \mathcal {R}$</span>     </span>, G=[0,1]): <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} G = \frac{\sum _{i=1}^{n} \sum _{j=1}^n | u^d_i - u^d_j|}{2n \sum _{i=1}^n u^d_i}, \end{equation} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div> where <em>n</em> is the number of users tweeting a particular URL.<br/>The Gini coefficient <em>G</em> describes the relative amount of inequality in the distribution of diversity: <em>G</em> = 0 indicates complete equality while <em>G</em> = 1 indicates complete inequality. A high <em>G</em> suggests coordination among the observations. The Gini coefficient does not measure absolute inequality and the interpretation can vary from situation to situation. Legitimate accounts such as news channels, newspapers, and famous activists are likely to tweet legitimate and diverse URLs, thus the Gini coefficient for legitimate URLs is high as compared to illegitimate URLs. The Gini coefficient for a sample of ten URLs is shown in Figure <a class="fig" href="#fig4">4</a>.<br/></li>    <li id="list5" label="(2)"><em>Rank-size Rule:</em> We observed that only a fraction of URLs are mentioned very frequently in the tweets and very large number of URLs barely find their way in more than a single tweet. It is interesting to note that cities and their rank also follow a similar distribution; this pattern is generally known as the <em>rank-size rule</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0031">31</a>]. This has also been observed in various studies on calling behaviour of users [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>][<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0027">27</a>].<br/></li>    </ol>    <p>We fit a curve on every user versus URL-diversity graph and measure the coefficient of determination <em>R</em>    <sup>2</sup>. Values close to zero indicate that the model explains little of the variability of the response data around its mean. For legitimate URLs, we obtained values close to 1 (Figure <a class="fig" href="#fig3">3</a>).</p>    <p>Recently, Gilani <em>et al.</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>] evaluated the characteristics of automated versus human accounts by looking at complete tweet histories. They initially hypothesized that bots tweet a number of different URLs, however in the actual data they found that humans may also post a number of URLs. Conversely, in this work we looked at most frequently posted URLs and then for each URL we analysed how diverse the users&#x2019; tweets are who are tweeting that URL.</p>    <p>We detected 849 bots in the data using message diversity on URLs, which we call <em>content polluters</em>. These content polluters contributed about 7% of tweets in the data. We computed some statistics on content polluters versus legitimate users, shown in Figure <a class="fig" href="#fig8">5</a>. In [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>], authors argued that social bots tend to have recent accounts with long names. However, we did not find a significant difference in our data between content polluters and regular users. The average account age of content polluters accounts was 2.9 years as compared to legitimate users which was 4.2 years. This difference was significant (<em>p</em> < 0.01).</p>    <p>This suggests that these particular type of bot accounts are relatively old and have remained (potentially) undetected by Twitter. The length of Twitter names for bots had on average 11 characters as compared to non-bots that had 12 characters. None of the bots had <em>verified</em> Twitter accounts. A total of 109 political bot accounts were created on 20 February 2014 with only 12 unique names, a strong indication of being a bot network. We also found several digital media bot accounts. Such accounts aim at becoming famous by attracting followers [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>]. A set of such accounts was created on 30 March 2016. This set consisted of 8 accounts with an average friend count of 4099 and follower count of 1112.</p>    <p>We also explored the dataset from [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>] using our algorithm. The dataset contains more than 600k tweets. The Gini coefficient for each dataset (bots and non-bots) was around 0.5, hence we remain inconclusive. The data set from Gilani <em>et al.</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>] only consisted of the number of URLs each user mentioned, therefore it was not possible to check the relative frequency of any particular URL. We argue that the nature of content polluting bots makes them difficult to distinguish in traditional bot-detection datasets. This motivates our research questions below and the creation of a new human-validated content-pollution dataset in the next section.</p>   </section>   <section id="sec-12">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> Creating a content-polluting bot dataset</h2>    </div>    </header>    <p>Given the peculiarities in the bot accounts that we found in our analysis, we move on to some pertinent research questions.</p>    <section id="sec-13">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Do humans succeed in detecting content polluters?</h3>     </div>    </header>    <p>We conducted a user study to hand-label a set of Twitter accounts that contained equal number of content polluters (from our list obtained in the previous section) and legitimate accounts. We asked three independent hand-labellers to create the dataset. Users were first shown several examples of content polluters as well as of legitimate accounts. All three participants were well versed with using Twitter. All participants found it very difficult to assess non-English accounts even with automatic translation.</p>    <p>The participants recorded the following comments: <figure id="fig5">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191574/images/www18companion-313-fig5.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>     <figure id="fig6">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191574/images/www18companion-313-fig6.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>     <figure id="fig7">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191574/images/www18companion-313-fig7.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>     <figure id="fig8">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191574/images/www18companion-313-fig8.jpg" class="img-responsive" alt="Figure 8"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 8:</span>       <span class="figure-title">Characteristics of users. Bots(red) versus Legitimate users(blue)</span>      </div>     </figure>     <figure id="fig9">      <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191574/images/www18companion-313-fig9.jpg" class="img-responsive" alt="Figure 9"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 9:</span>       <span class="figure-title">Results obtained from Truthy on the complete list of bots. Please note that the results were obtained after removing the 153 accounts that were suspended by Twitter.</span>      </div>     </figure>    </p>    <p>We constructed a labelled dataset from this collection by recording where 2 out of the 3 hand-labellers agreed on a classification. For our content polluter algorithm, we observed that the proportion of observed correct prediction (for both the classes) on this hand-labelled dataset was 0.57.</p>    <p>We test the following hypothesis: <strong>H1<sub>a</sub>     </strong>: Our method was able to find bot/non-bot accounts with greater than 50% accuracy. Hence, the null hypothesis is: <strong>H<sub>0</sub>     </strong>: Our method randomly labelled the bot/non-bot accounts.</p>    <p>After applying a <em>t</em> test we reject the null hypothesis at a significance level of <em>&#x03B1;</em> = 0.05 (<em>p</em> = 0.00029).</p>    </section>    <section id="sec-14">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> How efficient is Twitter in detecting social bots?</h3>     </div>    </header>    <p>Twitter continuously searches for suspicious accounts, and accounts that are found to be malicious may be deleted. In this experiment we studied how many bot accounts Twitter suspended from our detected bots list. The dataset that we analysed is from 2015/2016 but we conducted this experiment in April 2017, giving us a comprehensive set of accounts determined by Twitter to be bots. We used the Twitter API for this experiment. Given a query for a specific account, the Twitter API returns an error message if the account is suspended by Twitter or deleted by the user. It the error code&#x00A0;63 is returned then it means Twitter has suspended the account, whereas, error code&#x00A0;50 means the user deleted the account. For active accounts, metadata information about the account is returned. Upon querying the Twitter API, we found that Twitter had suspended 153 accounts out of the 849 content polluters that we have detected.</p>    <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Performance summary of our method versus Truthy. According to Truthy, 65% of the true positives in the user study were likely to be a bot, whereas, 21% of false positives also had a greater than 0.5 probability to be a bot.</span>     </div>     <table class="table">      <tbody>       <tr>       <td style="text-align:left;"/>       <td style="text-align:left;">Truthy (<em>pr</em> > = 0.5))</td>       <td style="text-align:left;">Truthy (<em>&#x03BC;</em>)</td>       <td>Truthy (<em>&#x03C3;</em>)</td>       </tr>       <tr>       <td style="text-align:left;">True Positives reported by user study</td>       <td style="text-align:left;">65%</td>       <td style="text-align:left;">0.556</td>       <td>0.159</td>       </tr>       <tr>       <td style="text-align:left;">False Positives reported by user study</td>       <td style="text-align:left;">21%</td>       <td style="text-align:left;">0.392</td>       <td>0.131</td>       </tr>      </tbody>     </table>    </div>    </section>    <section id="sec-15">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> How efficient other methods are for bot detection?</h3>     </div>    </header>    <p>We also tested the performance of state-of-the-art bot detection system called <em>Truthy</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0010">10</a>], also known as BotOrNot? [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0035">35</a>]. It is a publicly available API service developed by the Indiana University at Bloomington in May 2014 to evaluate the similarity of a Twitter account with the known characteristics of social bots. It uses the complete profile of a user to determine how likely the user account is to be a bot.</p>    <p>BotOrNot? employs a supervised machine-learning classifier that exploits more than 1000 features from the Twitter account under investigation. Features are derived based on network information and tweeting behaviour. The authors state that despite the fact that the service is specifically designed for detection of bots, the performance against evolved spambots might be worse than that was reported in the paper. We queried this service against our genuine set of bot accounts. Truthy displays scores against each account. Higher scores mean more bot-like accounts.</p>    <p>Figure <a class="fig" href="#fig9">6</a> shows the overall performance of Truthy against our list of bots. The mean score was 0.55 with a standard error of 0.14. Table <a class="tbl" href="#tab2">2</a> shows the performance summary. We remark that for the task of detecting content polluters our method performs comparably to Truthy, using only the information of URL diversity at the sampled-tweet level. We reiterate that we detected content polluter accounts using message diversity since we did not have access to complete account information, whereas Truthy exploited features obtained from the complete user profile and network. However, the aim of Truthy is much different from what we are trying to achieve. We utilize <strong>single tweets</strong> with users&#x2019; metadata to filter out bots in real-time for event prediction.</p>    </section>   </section>   <section id="sec-16">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> Discussion</h2>    </div>    </header>    <p>In this work we discovered social bots in protest-related tweets, using a stream of sampled Twitter data. Unlike previous bot-detection studies, our dataset was devoid of network information and detailed tweeting history. We showed the efficacy of a start-of-the-art Twitter-bot detection technique using complete profile and network information on our dataset. Further, we analysed the capabilities of Twitter and naive users in distinguishing bots from legitimate users. Twitter continuously looks for malicious accounts, which are deleted. However, this process may be very slow and a number of accounts remain undetected [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>]. It is difficult to track users who delete their tweets, since Twitter does not provide access to deleted tweets, or tweets older than 30 days. We show that even in the presence of complete network information, existing methods are not apt at detecting content-polluting bots. We argue that for real-time Twitter streams where it is difficult to obtain detailed profile information because of constraints on time and scalability, a cost-effective way is to compute the message diversity of tweets for each user. A low diversity might indicate suspicious accounts. The most challenging aspect of this work is to validate results since user perceptions are not always correct, and standard bot detection methods are very much prone to misclassification despite using complete twitter account information [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>]. Results from our user study indicate that our method agrees with the participants on most accounts that are legitimate. However, there is some difference in opinion for the bot accounts since it largely involves human perception of what a bot or a content polluter could be. For instance, participant-3 indicated that they did not consider an account to be a bot when this was associated with what appeared to be a carefully curated account for a business. However, when we looked into the original tweets, certain users used hashtags such as &#x2018;<span class="inline-equation"><span class="tex">$\#melbourne$</span>    </span>&#x2019;, while promoting their business that had nothing to do with the city Melbourne. Participants also indicated that some accounts seemed to be part automated and potentially part human. Even advanced Twitter users found distinguishing between bots and legitimate users a challenging task. Deletion of tweets is a major issue for traditional bot detection methods. In the case of US elections, a recent news article says, &#x201C;Twitter is either unable or unwilling to retrieve a substantial amount of tweets from bots and fake users spreading disinformation. Those users, which have been tied to Russia, have since deleted those tweets&#x201D; [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>]. In the absence of malicious tweets any validation method is prone to failure.</p>    <p>    <strong>Performance Improvement:</strong> In February 2017 we used our content-polluters detection methodology in order to improve the performance of a social media-based predictive model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>]. Users from a large Australian law enforcement agency provided positive feedback on improvements in the predictions. We noted that the model was no longer erroneously predicting events related to &#x2018;escorts&#x2019;, which improved model performance noticeably. Further, removal of bots also removed 18 non-interesting events in the month of February, related to lottery ticket sales.</p>   </section>   <section id="sec-17">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Conclusion and Future Work</h2>    </div>    </header>    <p>We found that content polluters in this dataset often timed their tweets together. By analysing the temporal patterns one could infer the presence of bot accounts. However, we also noticed that tweets from news channels were also temporally correlated. Using only temporal methods could lead to misclassification of legitimate accounts. We also found that bots used a small set of URLs in their tweets, therefore by finding out the most frequently-used URLs and computing their relative usage in tweets from the all the unique users in the dataset, one could successfully detect content polluters. Our analysis leads us to believe that conventional machine learning methods may require a number of features and may not be apt at correctly identifying bots. The bots that we detected in our dataset helped to remove noise in the data and significantly improved the performance of prediction models. In future we aim to:</p>    <ol class="list-no-style">    <li id="list6" label="(1)">Analyse non-protest related tweets for detecting bots, and utilise other available relations such as user-event relations, temporal relations, social interactions etc.<br/></li>    <li id="list7" label="(2)">Characterize bots into various categories and explore whether some bots could even be useful for civil unrest prediction.<br/></li>    <li id="list8" label="(3)">Conduct more user studies with a larger number of participants, in order to further understand the characteristics of content polluters.<br/></li>    </ol>   </section>   <section id="sec-18">    <header>    <div class="title-info">     <h2>      <span class="section-number">6</span> ACKNOWLEDGEMENTS</h2>    </div>    </header>    <p>The authors acknowledge financial support from Data to Decisions CRC. MN and LM also acknowledge support from the ARC Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS).</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">Marco&#x00A0;T Bastos and Dan Mercea. 2017. The Brexit Botnet and User-Generated Hyperpartisan News. <em>      <em>Social Science Computer Review</em>     </em>(2017), 0894439317734157.</li>    <li id="BibPLXBIB0002" label="[2]">Frank Bentley and Ying-Yu Chen. 2015. The Composition and Use of Modern Mobile Phonebooks. In <em>      <em>Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</em>     </em>. ACM, 2749&#x2013;2758.</li>    <li id="BibPLXBIB0003" label="[3]">Ofer Bergman, Andreas Komninos, Dimitrios Liarokapis, and James Clarke. 2012. You never call: Demoting unused contacts on mobile phones using DMTR. <em>      <em>Personal and Ubiquitous Computing</em>     </em>16, 6 (2012), 757&#x2013;766.</li>    <li id="BibPLXBIB0004" label="[4]">Alessandro Bessi and Emilio Ferrara. 2016. Social bots distort the 2016 US Presidential election online discussion. (2016).</li>    <li id="BibPLXBIB0005" label="[5]">Vincent&#x00A0;D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. 2008. Fast unfolding of communities in large networks. <em>      <em>Journal of statistical mechanics: theory and experiment</em>     </em>2008, 10(2008), P10008.</li>    <li id="BibPLXBIB0006" label="[6]">Yazan Boshmaf, Ildar Muslukhov, Konstantin Beznosov, and Matei Ripeanu. 2011. The socialbot network: when bots socialize for fame and money. In <em>      <em>Proceedings of the 27th annual computer security applications conference</em>     </em>. ACM, 93&#x2013;102.</li>    <li id="BibPLXBIB0007" label="[7]">Qiang Cao, Michael Sirivianos, Xiaowei Yang, and Tiago Pregueiro. 2012. Aiding the detection of fake accounts in large scale social online services. In <em>      <em>Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation</em>     </em>. USENIX Association, 15&#x2013;15.</li>    <li id="BibPLXBIB0008" label="[8]">Monica Chin. 2017. Report: Twitter deleted tweets related to the Russian investigation. (2017). <a class="link-inline force-break"      href="http://mashable.com/2017/10/13/twitter-deleted-russian-tweets/CIbGh7BglkqS"      target="_blank">http://mashable.com/2017/10/13/twitter-deleted-russian-tweets/CIbGh7BglkqS</a></li>    <li id="BibPLXBIB0009" label="[9]">Stefano Cresci, Roberto Di&#x00A0;Pietro, Marinella Petrocchi, Angelo Spognardi, and Maurizio Tesconi. 2017. The paradigm-shift of social spambots: Evidence, theories, and tools for the arms race. In <em>      <em>Proceedings of the 26th International Conference on World Wide Web Companion</em>     </em>. International World Wide Web Conferences Steering Committee, 963&#x2013;972.</li>    <li id="BibPLXBIB0010" label="[10]">Clayton&#x00A0;Allen Davis, Onur Varol, Emilio Ferrara, Alessandro Flammini, and Filippo Menczer. 2016. BotOrNot: A system to evaluate social bots. In <em>      <em>Proceedings of the 25th International Conference Companion on World Wide Web</em>     </em>. International World Wide Web Conferences Steering Committee, 273&#x2013;274.</li>    <li id="BibPLXBIB0011" label="[11]">John&#x00A0;P Dickerson, Vadim Kagan, and VS Subrahmanian. 2014. Using sentiment to detect bots on Twitter: Are humans more opinionated than bots?. In <em>      <em>Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on</em>     </em>. IEEE, 620&#x2013;627.</li>    <li id="BibPLXBIB0012" label="[12]">Andy Doyle, Graham Katz, Kristen Summers, Chris Ackermann, Ilya Zavorin, Zunsik Lim, Sathappan Muthiah, Patrick Butler, Nathan Self, Liang Zhao, <em>et al.</em> 2014. Forecasting significant societal events using the Embers streaming predictive analytics system. <em>      <em>Big data</em>     </em>2, 4 (2014), 185&#x2013;195.</li>    <li id="BibPLXBIB0013" label="[13]">Emilio Ferrara. 2017. Disinformation and social bot operations in the run up to the 2017 French presidential election. (2017).</li>    <li id="BibPLXBIB0014" label="[14]">Emilio Ferrara, Onur Varol, Clayton Davis, Filippo Menczer, and Alessandro Flammini. 2016. The rise of social bots. <em>      <em>Commun. ACM</em>     </em>59, 7 (2016), 96&#x2013;104.</li>    <li id="BibPLXBIB0015" label="[15]">John&#x00A0;D. Gallacher, Vlad Barash, Philip&#x00A0;N. Howard, and John Kelly. [n. d.]. Junk News on Military Affairs and National Security: Social Media Disinformation Campaigns Against US Military Personnel and Veterans. ([n. d.]). <a class="link-inline force-break"      href="http://comprop.oii.ox.ac.uk/publishing/working-papers/vetops/"      target="_blank">http://comprop.oii.ox.ac.uk/publishing/working-papers/vetops/</a></li>    <li id="BibPLXBIB0016" label="[16]">Saptarshi Ghosh, Bimal Viswanath, Farshad Kooti, Naveen&#x00A0;Kumar Sharma, Gautam Korlam, Fabricio Benevenuto, Niloy Ganguly, and Krishna&#x00A0;Phani Gummadi. 2012. Understanding and combating link farming in the twitter social network. In <em>      <em>Proceedings of the 21st international conference on World Wide Web</em>     </em>. ACM, 61&#x2013;70.</li>    <li id="BibPLXBIB0017" label="[17]">Zafar Gilani, Reza Farahbakhsh, Gareth Tyson, Liang Wang, and Jon Crowcroft. 2017. Of Bots and Humans (on Twitter). In <em>      <em>Proceedings of the 9th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM&#x2019;17). https://doi. org/10.1145/3110025.3110090</em>     </em>.</li>    <li id="BibPLXBIB0018" label="[18]">Zafar Gilani, Ekaterina Kochmar, and Jon Crowcroft. 2017. Classification of Twitter Accounts into Automated Agents and Human Users. In <em>      <em>Proceedings of the international conference on Advances in Social Network Analysis and Mining ASONAM</em>     </em>.</li>    <li id="BibPLXBIB0019" label="[19]">Jin&#x00A0;Seop Han and Byung&#x00A0;Joon Park. 2013. Efficient detection of content polluters in social networks. In <em>      <em>IT Convergence and Security 2012</em>     </em>. Springer, 991&#x2013;996.</li>    <li id="BibPLXBIB0020" label="[20]">Xia Hu, Jiliang Tang, and Huan Liu. 2014. Online Social Spammer Detection.. In <em>      <em>AAAI</em>     </em>. 59&#x2013;65.</li>    <li id="BibPLXBIB0021" label="[21]">Imrul Kayes and Adriana Iamnitchi. 2017. Privacy and security in online social networks: A survey. <em>      <em>Online Social Networks and Media</em>     </em>3 (2017), 1&#x2013;21.</li>    <li id="BibPLXBIB0022" label="[22]">Franziska&#x00A0;B Keller, David Schoch, Sebastian Stier, and JungHwan Yang. 2017. How to Manipulate Social Media: Analyzing Political Astroturfing Using Ground Truth Data from South Korea.. In <em>      <em>ICWSM</em>     </em>. 564&#x2013;567.</li>    <li id="BibPLXBIB0023" label="[23]">Kyumin Lee, Brian&#x00A0;David Eoff, and James Caverlee. 2011. Seven Months with the Devils: A Long-Term Study of Content Polluters on Twitter.. In <em>      <em>ICWSM</em>     </em>.</li>    <li id="BibPLXBIB0024" label="[24]">Kyumin Lee, Jalal Mahmud, Jilin Chen, Michelle Zhou, and Jeffrey Nichols. 2014. Who will retweet this?: Automatically identifying and engaging strangers on twitter to spread information. In <em>      <em>Proceedings of the 19th international conference on Intelligent User Interfaces</em>     </em>. ACM, 247&#x2013;256.</li>    <li id="BibPLXBIB0025" label="[25]">Sathappan Muthiah, Bert Huang, Jaime Arredondo, David Mares, Lise Getoor, Graham Katz, and Naren Ramakrishnan. 2015. Planned Protest Modeling in News and Social Media.. In <em>      <em>AAAI</em>     </em>. 3920&#x2013;3927.</li>    <li id="BibPLXBIB0026" label="[26]">Mehwish Nasim, Rapha&#x00EB;l Charbey, Christophe Prieur, and Ulrik Brandes. 2016. Investigating Link Inference in Partially Observable Networks: Friendship Ties and Interaction. <em>      <em>IEEE Transactions on Computational Social Systems</em>     </em>3, 3 (2016), 113&#x2013;119.</li>    <li id="BibPLXBIB0027" label="[27]">Mehwish Nasim, Aimal Rextin, Numair Khan, and Muhammad&#x00A0;Muddassir Malik. 2016. Understanding Call Logs of Smartphone Users for Making Future Calls. In <em>      <em>18th International Conference on Human-Computer Interaction with Mobile Devices and Services</em>     </em>. ACM.</li>    <li id="BibPLXBIB0028" label="[28]">Arlind Nocaj, Mark Ortmann, and Ulrik Brandes. 2014. Untangling hairballs: From 3 to 14 degrees of separation. In <em>      <em>22nd International Symposium, Graph Drawing 2014</em>     </em>. 101&#x2013;112.</li>    <li id="BibPLXBIB0029" label="[29]">Grant Osborne, Nick Lothian, Grant Neale, Terry Moscou, Andrew Nguyen, Jie Chen, Wei Kang, and Brenton Cooper. 2017. The beat the news system: Forecasting social disruption via modelling of online behaviours. <em>      <em>Journal of the Australian Institute of Professional Intelligence Officers</em>     </em> (2017).</li>    <li id="BibPLXBIB0030" label="[30]">Naren Ramakrishnan, Patrick Butler, Sathappan Muthiah, Nathan Self, Rupinder Khandpur, Parang Saraf, Wei Wang, Jose Cadena, Anil Vullikanti, Gizem Korkmaz, <em>et al.</em> 2014. &#x2019;Beating the news&#x2019; with EMBERS: forecasting civil unrest using open source indicators. In <em>      <em>Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</em>     </em>. ACM, 1799&#x2013;1808.</li>    <li id="BibPLXBIB0031" label="[31]">Kenneth&#x00A0;T Rosen and Mitchel Resnick. 1980. The size distribution of cities: an examination of the Pareto law and primacy. <em>      <em>Journal of Urban Economics</em>     </em>8, 2 (1980), 165&#x2013;186.</li>    <li id="BibPLXBIB0032" label="[32]">Parang Saraf and Naren Ramakrishnan. 2016. EMBERS autogsr: Automated coding of civil unrest events. In <em>      <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>     </em>. ACM, 599&#x2013;608.</li>    <li id="BibPLXBIB0033" label="[33]">Pablo Su&#x00E1;rez-Serrato, Margaret&#x00A0;E Roberts, Clayton Davis, and Filippo Menczer. 2016. On the influence of social bots in online protests. In <em>      <em>International Conference on Social Informatics</em>     </em>. Springer, 269&#x2013;278.</li>    <li id="BibPLXBIB0034" label="[34]">VS Subrahmanian, Amos Azaria, Skylar Durst, Vadim Kagan, Aram Galstyan, Kristina Lerman, Linhong Zhu, Emilio Ferrara, Alessandro Flammini, and Filippo Menczer. 2016. The DARPA Twitter bot challenge. <em>      <em>Computer</em>     </em>49, 6 (2016), 38&#x2013;46.</li>    <li id="BibPLXBIB0035" label="[35]">Onur Varol, Emilio Ferrara, Clayton&#x00A0;A Davis, Filippo Menczer, and Alessandro Flammini. 2017. Online Human-Bot Interactions : Detection , Estimation , and Characterization. In <em>      <em>Proceedings of the Eleventh International AAAI Conference on Web and Social Media (ICWSM 2017) Online</em>     </em>. 280&#x2013;289.</li>    <li id="BibPLXBIB0036" label="[36]">Bo Wang, Arkaitz Zubiaga, Maria Liakata, and Rob Procter. 2015. Making the most of tweet-inherent features for social spam detection on twitter. <em>      <em>arXiv preprint arXiv:1503.07405</em>     </em>(2015).</li>    <li id="BibPLXBIB0037" label="[37]">Charlie Warzel and Emma Loop. [n. d.]. Twitter Tells Congress It Found 200 Russian Accounts That Overlapped With Facebook. ([n. d.]). <a class="link-inline force-break"      href="https://www.buzzfeed.com/charliewarzel/twitter-russian-accounts?utm_term=.immV81Pgd#.siA4vLxop"      target="_blank">https://www.buzzfeed.com/charliewarzel/twitter-russian-accounts?utm_term=.immV81Pgd#.siA4vLxop</a></li>    <li id="BibPLXBIB0038" label="[38]">Liang Wu, Xia Hu, Fred Morstatter, and Huan Liu. 2017. Detecting Camouflaged Content Polluters.. In <em>      <em>ICWSM</em>     </em>. 696&#x2013;699.</li>    <li id="BibPLXBIB0039" label="[39]">Chao Yang, Robert Harkreader, and Guofei Gu. 2013. Empirical evaluation and new design for fighting evolving twitter spammers. <em>      <em>IEEE Transactions on Information Forensics and Security</em>     </em>8, 8(2013), 1280&#x2013;1293.</li>    <li id="BibPLXBIB0040" label="[40]">Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao, Ben&#x00A0;Y Zhao, and Yafei Dai. 2014. Uncovering social network sybils in the wild. <em>      <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em>     </em>8, 1(2014), 2.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>Work undertaken while at Data to Decisions CRC.</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a>Data can be accessed on <a class="link-inline force-break"    href="http://maths.adelaide.edu.au/mehwish.nasim/">http://maths.adelaide.edu.au/mehwish.nasim/</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a>Event day was confirmed from the <em>GSR</em>.</p>   <p id="fn4"><a href="#foot-fn4"><sup>3</sup></a>Networks visualizations are created in <em>visone</em> (<a class="link-inline force-break" href="http://www.visone.info/">http://www.visone.info/</a>).</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3191574">https://doi.org/10.1145/3184558.3191574</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
