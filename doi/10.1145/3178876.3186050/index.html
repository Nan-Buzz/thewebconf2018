<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>Multi-Task Learning Improves Disease Models from Web Search</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> <link rel="cite-as" href="https://doi.org/10.1145/3178876.3186050"/></head> <body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3178876.3186050'>https://doi.org/10.1145/3178876.3186050</a>.
 Published in WWW2018 Proceedings Â© 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3178876.3186050'>https://w3id.org/oa/10.1145/3178876.3186050</a>
</p></div>
<hr>

  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">Multi-Task Learning Improves Disease Models from Web Search</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author">     <span class="givenName">Bin</span>     <span class="surName">Zou</span>,     Department of Computer Science, University College London, United Kingdom, <a href="mailto:bin.zou.14@ucl.ac.uk">bin.zou.14@ucl.ac.uk</a>    </div>    <div class="author">     <span class="givenName">Vasileios</span>     <span class="surName">Lampos</span>,     Department of Computer Science, University College London, United Kingdom, <a href="mailto:v.lampos@ucl.ac.uk">v.lampos@ucl.ac.uk</a>    </div>    <div class="author">     <span class="givenName">Ingemar</span>     <span class="surName">Cox</span><a class="fn" href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>,     Department of Computer Science, University College London, United Kingdom, <a href="mailto:i.cox@ucl.ac.uk">i.cox@ucl.ac.uk</a>    </div>                </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3178876.3186050" target="_blank">https://doi.org/10.1145/3178876.3186050</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of the 2018 workshop on The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>We investigate the utility of multi-task learning to disease surveillance using Web search data. Our motivation is two-fold. Firstly, we assess whether concurrently training models for various geographies &#x2014; inside a country or across different countries &#x2014; can improve accuracy. We also test the ability of such models to assist health systems that are producing sporadic disease surveillance reports that reduce the quantity of available training data. We explore both linear and nonlinear models, specifically a multi-task expansion of elastic net and a multi-task Gaussian Process, and compare them to their respective single task formulations. We use influenza-like illness as a case study and conduct experiments on the United States (US) as well as England, where both health and Google search data were obtained. Our empirical results indicate that multi-task learning improves regional as well as national models for the US. The percentage of improvement on mean absolute error increases up to 14.8% as the historical training data is reduced from 5 to 1 year(s), illustrating that accurate models can be obtained, even by training on relatively short time intervals. Furthermore, in simulated scenarios, where only a few health reports (training data) are available, we show that multi-task learning helps to maintain a stable performance across all the affected locations. Finally, we present results from a cross-country experiment, where data from the US improves the estimates for England. As the historical training data for England is reduced, the benefits of multi-task learning increase, reducing mean absolute error by up to 40%.</small>    </p>    </div>    <div class="CCSconcepts">    <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Web mining;</strong> &#x2022;<strong> Applied computing </strong>&#x2192; <strong>Health informatics;</strong> &#x2022;<strong> Computing methodologies </strong>&#x2192; <strong>Supervised learning by regression;</strong> <strong>Multi-task learning;</strong> &#x2022;<strong> Theory of computation </strong>&#x2192; <strong>Gaussian processes;</strong></small> </p>    </div>    <div class="classifications">    <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Web Search; User-Generated Content; Disease Surveillance; Multi-Task Learning; Regularized Regression; Gaussian Processes</small>     </span>    </div>    <br/>    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Bin Zou<X>, </X>Vasileios Lampos<X>, and </X>Ingemar Cox<X>. </X>2018<X>. </X>Multi-Task Learning Improves Disease Models from Web Search<X>. </X>In <em>Proceedings of </em>       <em>The 2018 Web Conference,</em>       <em> Lyon, France, </em>       <em>April 23--27, 2018 (WWW 2018),</em> 10 Pages. DOI: <a href="https://doi.org/10.1145/3178876.3186050" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3178876.3186050</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-4">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>    </div>    </header>    <p>    <em>Online</em> user-generated content contains a significant amount of information about the <em>offline</em> behavior or state of users. For the past decade, user-generated content has been used in a variety of scientific areas, ranging from the social sciences&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>] to psychology&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0046">46</a>] and health&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>]. Focusing on the health aspect, user-generated content has the advantage of being a real-time and inexpensive resource, covering parts of the population that may not be accessible to established healthcare systems. Thus, it can facilitate novel approaches that may offer complementary insights to traditional disease surveillance schemes.</p>    <p>Existing algorithms for disease surveillance from user-generated content are predominantly based on supervised learning paradigms&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>]. These frameworks propose single task learning solutions that do not consider the correlations of data across different geographies. They are also not accounting for situations, where significantly fewer health reports are available for training a model. In this paper, we investigate the utility of multi-task learning to exploit these correlations to both improve overall performance and to compensate for a lack of training data in one or more geographic locations.</p>    <p>Multi-task learning can train a number of disease models jointly. Compared to single task learning, it has the potential to improve the generalization of a model by taking advantage of shared structures in the data. Previous work has shown that this may result in significant performance gains&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>]. In the context of disease modeling, we investigate whether it can provide an improved estimate of disease rates when (a) training data is available for multiple geographic locations, specifically geographic regions of the United States (US), and (b) when ground truth training data (health reports) is sporadic. In addition, we investigate its utility in estimating disease rates in a different country by exploiting a denser health reporting scheme of a reference country. We explore both linear and nonlinear regression models, namely multi-task elastic net&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>] and multi-task Gaussian Processes&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>], comparing them to their respective single task formulations.</p>    <p>We use influenza-like illness (ILI) as a case study and conduct experiments, where ILI rates are estimated, on the US (nationally and regionally) and England. Our experiments show that multi-task learning models improve regional as well as national ILI rate estimates from Google search data for the US. The percentage of improvement increases up to 14.8%, in terms of mean absolute error, as the historical training data is reduced, indicating that multi-task learning can facilitate the derivation of accurate models using significantly less training data. We also simulate situations, where partial ground truth data are available, perhaps due to unexpected reasons (natural disasters, a spreading epidemic, technical problems) or due to limitations of a public health system. Our experimental results indicate that multi-task learning models can mitigate such effects. Finally, we apply multi-task learning to a cross-country setting, where complete data for one country could improve the models of another country with insufficient health reports. In that case, it is shown to improve ILI rate estimates for England (up to 40% of mean absolute error decrease) under the assumption that increasingly limited historical data exist, when training models jointly with data from the US.</p>    <p>Here is a summary of the main contributions of the paper:</p>    <ol class="list-no-style">    <li id="list1" label="(1)">This is the first work to assess the utility of multi-task learning in infectious disease surveillance from Web search data.<br/></li>    <li id="list2" label="(2)">We use ILI as a case study and show that multi-task learning models improve:<br/>     <ol class="list-no-style">      <li id="list3" label="(a)">regional as well as national disease models for the US,<br/></li>      <li id="list4" label="(b)">regional US disease models, under the assumption of increasingly limited historical health reports (simulated by applying three different sampling methods), and<br/></li>      <li id="list5" label="(c)">country-level disease models for England, when training is performed jointly with data from a different, but culturally similar, country (the US).<br/></li>     </ol></li>    </ol>   </section>   <section id="sec-5">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> Methods</h2>    </div>    </header>    <p>We first provide a description for the disease modeling task, under both single and multi-task learning settings. Then, we present the linear and nonlinear techniques for performing single and multi-task regression used in our experiments.</p>    <section id="sec-6">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Task Description</h3>     </div>    </header>    <p>Our aim is to infer disease rates as reported by an established health surveillance system using the frequencies of Web search queries. We formulate this as a regression task, where we learn a function <em>f</em>:&#x00A0;<strong>X</strong> &#x2192; <strong>y</strong> that maps the input space <span class="inline-equation"><span class="tex">$\mathbf {X} \in \mathbb {R}^{n \times p}$</span>     </span> to the target variable <span class="inline-equation"><span class="tex">$\mathbf {y} \in \mathbb {R}^{n}$</span>     </span>; <em>n</em> denotes the number of samples and <em>p</em> is the size of our feature space, i.e. the number of unique search queries we consider. <strong>X</strong> contains time series of normalized frequencies of search queries and <strong>y</strong> represents the disease rates at the same time points as reported by the health agency. A normalized query frequency is defined as the count of a query divided by the total number of searches during a fixed time interval, e.g. one week.</p>    <p>In multi-task disease rate inference, we are modeling disease rates simultaneously for a number of different geographical locations (tasks). A tensor <span class="inline-equation"><span class="tex">$\mathbf {Q} \in \mathbb {R}^{n \times p \times m}$</span>     </span> is used to represent our input data for the <em>m</em> tasks.<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a>     <strong>Q</strong> can simply be interpreted as <em>m</em> versions of <strong>X</strong>; in the remainder of the script, we denote them using <strong>Q</strong>     <sub>      <em>j</em>     </sub>, where <em>j</em> refers to the <span class="inline-equation"><span class="tex">$j^{\textrm {th}}$</span>     </span> task or geographical location. An element of <strong>Q</strong>, <strong>Q</strong>     <sub>      <em>tij</em>     </sub>, represents the normalized frequency of a query <em>i</em> for the location <em>j</em> during the time interval <em>t</em>. The corresponding target variables, i.e. the disease rates for the <em>m</em> locations are denoted by <span class="inline-equation"><span class="tex">$\mathbf {Y} \in \mathbb {R}^{n \times m}$</span>     </span>. Similarly, we use <strong>Y</strong>     <sub>      <em>j</em>     </sub> to refer to the disease rates at the location <em>j</em>. Based on the aforementioned formulations, our task now becomes to learn a function <em>f</em>, such that <em>f</em>:&#x00A0;<strong>Q</strong> &#x2192; <strong>Y</strong>.</p>    </section>    <section id="sec-7">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Linear Regularized Regression</h3>     </div>    </header>    <p>Linear regressors have been successfully applied for conducting disease surveillance from web search and social media data&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0030">30</a>]. We use <em>elastic net</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0056">56</a>] to train a linear regression model. It can be seen as an extension of the &#x2113;<sub>1</sub>-norm regularization, known as <em>lasso</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0048">48</a>], that incorporates an &#x2113;<sub>2</sub>-norm, or <em>ridge</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0024">24</a>], regularizer on the inferred weight vector. Elastic net encourages sparse solutions, thereby performing feature selection. At the same time, it addresses model consistency problems that arise when collinear predictors exist in the input space&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>].</p>    <p>     <strong>Elastic Net (EN)</strong>.</p>    <p>Given the input matrix <strong>X</strong> and the observations <strong>y</strong>, linear regression has the form of <strong>y</strong> = <strong>X</strong>     <strong>w</strong> + <em>&#x03B2;</em>, where <em>&#x03B2;</em> is an intercept term and <span class="inline-equation"><span class="tex">$\mathbf {w} \in \mathbb {R}^{p}$</span>     </span> is a weight vector. Elastic net&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0056">56</a>] estimates <strong>w</strong> and <em>&#x03B2;</em> by minimizing <div class="table-responsive" id="eq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathop{\arg \!\min }\limits_{\mathbf {w}, \beta } \left(\left\Vert \mathbf {y} - \beta - \mathbf {X} \mathbf {w} \right\Vert _{2}^{2} + \lambda _1 \left\Vert \mathbf {w} \right\Vert _{2}^{2} + \lambda _2 \left\Vert \mathbf {w} \right\Vert _{1} \right) \, , \end{equation} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div> where <em>&#x03BB;</em>     <sub>1</sub> and <em>&#x03BB;</em>     <sub>2</sub> are the regularization parameters, and &#x2016; &#x00B7; &#x2016;<sub>1</sub>, &#x2016; &#x00B7; &#x2016;<sub>2</sub> denote the &#x2113;<sub>1</sub>-norm and &#x2113;<sub>2</sub>-norm, respectively.</p>    <p>     <strong>Multi-Task Elastic Net (MTEN)</strong>.</p>    <p>We extend the standard elastic net model to a multi-task version&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0053">53</a>]. It is specified by the following optimization task <div class="table-responsive" id="eq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathop{\arg \!\min }\limits_{\mathbf {W}, \beta } \left(\left\Vert \mathbf {Y} - \beta - \mathbf {Q} \mathbf {W} \right\Vert _{F}^{2} + \lambda _1 \left\Vert \mathbf {W} \right\Vert _{2{,}1} + \lambda _2 \left\Vert \mathbf {W} \right\Vert _{F}^{2} \right) \, , \end{equation} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$\mathbf {W} \in \mathbb {R}^{p \times m}$</span>     </span>, <span class="inline-equation"><span class="tex">$\beta \in \mathbb {R}^{m}$</span>     </span> are the weight matrix and intercept vector for all the <em>m</em> tasks, and the norms &#x2014; &#x2113;<sub>2, 1</sub> and Frobenius (<em>F</em>) &#x2014; are given by <div class="table-responsive" id="eq3">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \left\Vert \mathbf {W} \right\Vert _{2{,}1} = \sum _{i=1}^p \sqrt {\sum _{j=1}^m W_{ij}^2} \hspace{14.45377pt} \text{and} \end{equation} </span>       <br/>       <span class="equation-number">(3)</span>      </div>     </div>     <div class="table-responsive" id="eq4">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \left\Vert \mathbf {W} \right\Vert _{F} = \sqrt {\sum _{i=1}^{p} \sum _{j=1}^{m} W_{ij}^2 } \, . \end{equation} </span>       <br/>       <span class="equation-number">(4)</span>      </div>     </div>    </p>    </section>    <section id="sec-8">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.3</span> Nonlinear Regression</h3>     </div>    </header>    <p>We also deploy nonlinear regression models using Gaussian Processes as previous works have shown that the relationship between query frequencies and disease rates is significantly better captured by a nonlinear function&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0033">33</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0034">34</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0050">50</a>].</p>    <p>     <strong>Gaussian Process (GP)</strong>. GP models&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>] assume that the function <em>f</em>:&#x00A0;<strong>X</strong> &#x2192; <strong>y</strong> is a probability distribution over functions denoted as <div class="table-responsive" id="eq5">      <div class="display-equation">       <span class="tex mytex">\begin{equation} f(\mathbf {x}) \sim \mathcal {GP}(\mu (\mathbf {x}), k(\mathbf {x}, \mathbf {x}^{\prime })) \, , \end{equation} </span>       <br/>       <span class="equation-number">(5)</span>      </div>     </div> where <strong>x</strong>, <strong>x</strong>&#x2032; are rows of the input matrix <strong>X</strong>, <em>&#x03BC;</em>(<strong>x</strong>) is the mean function of the process, and <em>k</em>(<strong>x</strong>, <strong>x</strong>&#x2032;) is the covariance function (or kernel) that captures a relationship between input observations. We assume that <em>&#x03BC;</em>(<strong>x</strong>) = 0, and use the Squared Exponential kernel plus noise as our covariance function. It is defined by <div class="table-responsive" id="eq6">      <div class="display-equation">       <span class="tex mytex">\begin{equation} k(\mathbf {x}, \mathbf {x}^{\prime }) = \sigma ^2 \exp \left(- \frac{\Vert \mathbf {x} - \mathbf {x}^{\prime } \Vert _2^2}{2\ell ^2} \right) \, + \sigma _n^2 \cdot \delta (\mathbf {x}, \mathbf {x}^{\prime }) \, , \end{equation} </span>       <br/>       <span class="equation-number">(6)</span>      </div>     </div> where &#x2113; is the length-scale parameter, <em>&#x03B4;</em> is a Kronecker delta function, and <em>&#x03C3;</em>     <sup>2</sup>, <span class="inline-equation"><span class="tex">$\sigma _n^2$</span>     </span> are scaling constants that represent the overall variance. In GPs, predictions (<strong>y</strong>     <sub>*</sub>) can be made by using the conditional distribution <span class="inline-equation"><span class="tex">$p(\mathbf {y}_{*} | \mathbf {x}_{*}, \mathbf {X}, \mathbf {y}) \sim \mathcal {N} (\mu _{*}, \sigma _{*}^2)$</span>     </span>, where <strong>x</strong>     <sub>*</sub> denotes a new observation. Following the assumption that <em>&#x03BC;</em>(<strong>x</strong>) = 0, <em>&#x03BC;</em>     <sub>*</sub> and <span class="inline-equation"><span class="tex">$\sigma _{*}^2$</span>     </span> are given by <div class="table-responsive" id="eq7">      <div class="display-equation">       <span class="tex mytex">\begin{align} \mu _{*} &#x0026; = {\bf K}(\mathbf {x}_{*}, \mathbf {X})^{\top } {\bf K}(\mathbf {X}, \mathbf {X})^{-1}\mathbf {y} \, ,\text{ and}\end{align} </span>       <br/>       <span class="equation-number">(7)</span>      </div>     </div>     <div class="table-responsive" id="eq8">      <div class="display-equation">       <span class="tex mytex">\begin{align} \sigma _{*}^2 &#x0026; = {\bf K}(\mathbf {x}_{*}, \mathbf {x}_{*}) - {\bf K}(\mathbf {x}_{*}, \mathbf {X})^{\top } {\bf K}(\mathbf {X}, \mathbf {X})^{-1} {\bf K}(\mathbf {X}, \mathbf {x}_{*}) \, , \end{align} </span>       <br/>       <span class="equation-number">(8)</span>      </div>     </div> where <strong>K</strong> is a covariance matrix derived by applying Eq.&#x00A0;<a class="eqn" href="#eq6">6</a> element-wise. The hyperparameters of the GP model, <em>&#x03B8;</em> = {<em>&#x03C3;</em>, &#x2113;, <em>&#x03C3;<sub>n</sub>     </em>}, are learned by minimizing the negative log-marginal likelihood&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>], given by <div class="table-responsive" id="eq9">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathop{\arg \!\min }\limits_{\theta } \left(- \frac{1}{2} \mathbf {y}_j^{\top }({\bf K}(\mathbf {X}, \mathbf {X}))^{-1}\mathbf {y} - \frac{1}{2} \log | {\bf K}(\mathbf {X}, \mathbf {X}) | - \frac{n}{2} \log 2\pi \right). \end{equation} </span>       <br/>       <span class="equation-number">(9)</span>      </div>     </div>    </p>    <p>     <strong>Multi-Task Gaussian Process (MTGP)</strong>. GPs models were extended to a multi-task version (MTGP) by Bonilla et al.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>] and have been used in various tasks, including natural language processing applications&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>]. The MTGP model incorporates all <em>m</em> tasks into a single GP that is defined by <div class="table-responsive" id="eq10">      <div class="display-equation">       <span class="tex mytex">\begin{equation} f(\mathbf {Q}) \sim \mathcal {GP} (\mu _{\textrm {M}}(\mathbf {x}), k_{\textrm {M}}(\mathbf {x}, \mathbf {x}^{\prime }) \, , \end{equation} </span>       <br/>       <span class="equation-number">(10)</span>      </div>     </div> where <strong>x</strong> and <strong>x</strong>&#x2032; are inputs from tasks <em>j</em> and <em>j</em>&#x2032;, respectively. As with the single-task GP, we assume <span class="inline-equation"><span class="tex">$\mu _{\textrm {M}}(\mathbf {x}) = 0$</span>     </span>. MTGP&#x0027;s covariance function, <span class="inline-equation"><span class="tex">$k_{\textrm {M}}(\mathbf {x}, \mathbf {x}^{\prime })$</span>     </span>, is formed by placing a GP prior over the kernel function in Eq.&#x00A0;<a class="eqn" href="#eq6">6</a>, so that we directly induce correlations between the tasks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>]. It is given by <div class="table-responsive" id="eq11">      <div class="display-equation">       <span class="tex mytex">\begin{equation} k_{\textrm {M}}(\mathbf {x}, \mathbf {x}^{\prime }) = k^{\textrm {c}}(j, j^{\prime }) \times k^{\textrm {x}}(\mathbf {x}, \mathbf {x}^{\prime }) \, , \end{equation} </span>       <br/>       <span class="equation-number">(11)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$k^{\textrm {c}}$</span>     </span> is a correlation kernel that explains the relation between tasks <em>j</em> and <em>j</em>&#x2032;, and <span class="inline-equation"><span class="tex">$k^{\textrm {x}}$</span>     </span> is the covariance that explains the relation of inputs <strong>x</strong> and <strong>x</strong>&#x2032;. This approach is also known as the <em>intrinsic correlation model</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0049">49</a>].</p>    <p>Let <span class="inline-equation"><span class="tex">$\mathbf {K}_{\textrm {M}}$</span>     </span> be the covariance matrix of <strong>Q</strong>, <span class="inline-equation"><span class="tex">$\mathbf {K}^{\textrm {c}}$</span>     </span> the task correlation matrix, and <span class="inline-equation"><span class="tex">$\mathbf {K}^{\textrm {x}}$</span>     </span> the covariance matrix of inputs. We define <span class="inline-equation"><span class="tex">$\mathbf {K}_{\textrm {M}}$</span>     </span> as <div class="table-responsive" id="eq12">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathbf {K}_{\textrm {M}} = \mathbf {K}^{\textrm {c}} \otimes \mathbf {K}^{\textrm {x}} \, , \end{equation} </span>       <br/>       <span class="equation-number">(12)</span>      </div>     </div> where &#x2297; denotes a Kronecker product. <span class="inline-equation"><span class="tex">$\mathbf {K}^{\textrm {c}}$</span>     </span> is assumed to be a valid covariance matrix (satisfying Mercer&#x0027;s theorem). Its diagonal elements describe the correlation of the tasks with themselves and the non-diagonal elements correspond to the correlation between tasks. It can be constructed using the Cholesky decomposition and is parameterized by the elements of the lower triangular matrix of <div class="table-responsive" id="eq13">      <div class="display-equation">       <span class="tex mytex">\begin{equation} {\bf K}^\text{c}(j, j^{\prime }) = \mathbf {J} \mathbf {J}^{\top }, \ \mathbf {J} = {\left(\begin{array}{*10c}\theta _1^\text{c} &#x0026; 0 &#x0026; \ldots &#x0026; 0 \\ \theta _2^\text{c} &#x0026; \theta _3^\text{c} &#x0026; \ldots &#x0026; 0 \\ \vdots &#x0026; \vdots &#x0026; \ddots &#x0026; \vdots \\ \theta ^{\text{c}}_{\zeta -m+1}&#x0026; \theta ^{\text{c}}_{\zeta -m+2} &#x0026; \ldots &#x0026; \theta ^{\text{c}}_{\zeta } \\ \end{array}\right)} \, , \end{equation} </span>       <br/>       <span class="equation-number">(13)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$\mathbf {\theta }^\text{c} = \lbrace \theta ^{\text{c}}_u\rbrace$</span>     </span>, <em>u</em> &#x2208; {1, 2, &#x2026;, <em>&#x03B6;</em>} is the set of <strong>K</strong>     <sup>c</sup>&#x2019;s hyperparameters, with <em>&#x03B6;</em> = <em>m</em>(<em>m</em> + 1)/2.</p>    <p>Inference and hyperparameter learning in MTGPs is conducted similarly to the single task GPs&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0018">18</a>]. Given a new data point <strong>x</strong>     <sub>*</sub>, for task <em>j</em>, the predictions (<em>y</em>     <sub>*</sub>) can be made by using the conditional distribution <span class="inline-equation"><span class="tex">$p(\mathbf {y}_{*} | \mathbf {x}_{*}, \mathbf {Q}, \mathbf {Y}) \sim \mathcal {N} (\mu _{j*}, \sigma _{j*}^2)$</span>     </span>, where <div class="table-responsive" id="eq14">      <div class="display-equation">       <span class="tex mytex">\begin{align} \mu _{j*} &#x0026; = \left(\mathbf {k}_{j}^{\textrm {c}} \otimes \mathbf {k}_{*}^{\textrm {x}} \right)^{\top } \mathbf {K}_{\textrm {M}}^{-1} \mathbf {Y} \, ,\text{ and}\end{align} </span>       <br/>       <span class="equation-number">(14)</span>      </div>     </div>     <div class="table-responsive" id="eq15">      <div class="display-equation">       <span class="tex mytex">\begin{align} \sigma _{j*}^2 &#x0026; = \mathbf {K}_{\textrm {M}} + \mathbf {D} \otimes \mathbf {I} \, . \end{align} </span>       <br/>       <span class="equation-number">(15)</span>      </div>     </div> In the above equations, <span class="inline-equation"><span class="tex">$\mathbf {k}_{j}^{c}$</span>     </span> is the <span class="inline-equation"><span class="tex">$j^{\textrm {th}}$</span>     </span> column of <span class="inline-equation"><span class="tex">$\mathbf {K}^{\textrm {c}}$</span>     </span>, <span class="inline-equation"><span class="tex">$\mathbf {k}_{*}^{x}$</span>     </span> is the vector of covariances between <strong>x</strong>     <sub>*</sub> and the training points, and <strong>D</strong> is an <em>m</em> &#x00D7; <em>m</em> matrix in which the <span class="inline-equation"><span class="tex">$(j,j)^{\textrm {th}}$</span>     </span> element is the noise variance (<span class="inline-equation"><span class="tex">$\sigma _{j}^{2}$</span>     </span>) for the <span class="inline-equation"><span class="tex">$j^{\textrm {th}}$</span>     </span> task.</p>    </section>   </section>   <section id="sec-9">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> Experiments</h2>    </div>    </header>    <p>Our experiments assess a number of different disease modeling scenarios, where we expect that multi-task learning will have a positive impact. We focus on the estimation of ILI rates, which is a well-studied task&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>]. The locations of interest are the US at the national level, US regions as defined by the Department of Health and Human Services (HHS), and England.</p>    <section id="sec-10">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Data Sets and Experiment Settings</h3>     </div>    </header>    <p>     <strong>ILI rates from health agencies.</strong>. For the US, we use weekly ILI rates from the Centers for Disease Control and Prevention (CDC). These rates represent the average percentage of all outpatient visits to health care providers normalized by the respective regional population figures and are recorded by CDC&#x0027;s ILI surveillance network, ILINet.<a class="fn" href="#fn3" id="foot-fn3"><sup>2</sup></a> The 10 HHS US regions considered by the CDC are shown in Fig.&#x00A0;<a class="fig" href="#fig1">1</a>. Our data spans from September 1, 2007 to August 31, 2016 (both inclusive), which includes 9 consecutive influenza seasons as defined by the CDC. Each (expanded) flu season begins on September 1 and ends on August 31 of the next year. To provide further insight, we have plotted the ILI rates of US regions 1, 2, and the US as a whole in Fig.&#x00A0; <a class="fig" href="#fig2">2</a>. As expected, we see that the time series are strongly correlated, but each signal may be peaking at different moments throughout a flu season. For England, we obtain weekly ILI rates from Public Health England (PHE) through the syndromic surveillance network developed by the Royal College of General Practitioners. We focus on the same time period as for the US.</p>    <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186050/images/www2018-59-fig1.jpg" class="img-responsive" alt="Figure 1"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">The 10 US regions as specified by the Department of Health &#x0026; Human Services (HHS).</span>     </div>    </figure>     <figure id="fig2">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186050/images/www2018-59-fig2.jpg" class="img-responsive" alt="Figure 2"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 2:</span>      <span class="figure-title">Weekly ILI rates (from CDC) for the US (national level) as well as the US Regions 1 and 2.</span>     </div>    </figure>    <p>     <strong>Search query frequencies.</strong>.</p>    <p>We iteratively used Google Correlate<a class="fn" href="#fn4" id="foot-fn4"><sup>3</sup></a> starting with flu-related query seeds (such as the word &#x2018;flu&#x2019;) to obtain a set of 1, 641 candidate search queries. However, due to the existing seasonal confounders, many of the candidate queries we ended up with, such as &#x2018;college basketball&#x2019; or &#x2018;spring break&#x2019;, were not related to flu. To remove these unrelated queries in a principled fashion, we applied a topic filter specified using word embeddings. The filtering process was similar to the one we proposed in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0034">34</a>], but without the notion of a negative context. Embeddings were trained using <tt>word2vec</tt> on Google news&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0040">40</a>].<a class="fn" href="#fn5" id="foot-fn5"><sup>4</sup></a> We consider a query <em>q</em> as a set of <em>z</em> textual tokens, {&#x025B;<sub>1</sub>, &#x2026;, &#x025B;<sub>      <em>z</em>     </sub>}. The embedding of <em>q</em>, <strong>e</strong>     <sub>      <em>q</em>     </sub>, is computed by averaging across the embeddings of its tokens, <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathbf {e}_q = \frac{1}{z} \sum _{i = 1}^{z} \mathbf {e}_{\varepsilon _i} \, . \end{equation} </span>       <br/>       <span class="equation-number">(16)</span>      </div>     </div> We define a topic about flu, <span class="inline-equation"><span class="tex">$\mathcal {T}$</span>     </span>, as a set of two flu-related terms, specifically the name of the disease and one of its main symptoms, <span class="inline-equation"><span class="tex">$\mathcal {T} = \lbrace \text{`flu'}, \text{`fever'}\rbrace$</span>     </span>. For each of the queries, we calculate a similarity score defined as the product of the cosine similarities between the embeddings of the terms in <span class="inline-equation"><span class="tex">$\mathcal {T}$</span>     </span> and <strong>e</strong>     <sub>      <em>q</em>     </sub>, i.e. <div class="table-responsive" id="Xeq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} S(\mathbf {q}, \mathcal {T}) = \prod _{i=1}^{2} \cos (\mathbf {e}_\mathbf {q}, \mathbf {e}_{\mathbf {T}_{i}}) \, , \end{equation} </span>       <br/>       <span class="equation-number">(17)</span>      </div>     </div> where each cosine similarity component is mapped to [0, 1] via (cos&#x2009;(&#x00B7;, &#x00B7;) + 1)&#x00A0;/&#x00A0;2.<a class="fn" href="#fn6" id="foot-fn6"><sup>5</sup></a> Queries with <em>S</em> &#x2264; 0.5 are filtered out and are not considered in our experiments. The 0.5 threshold guarantees that even in the extreme case, where a candidate query has a perfect cosine similarity (equal to 1) with one of the two concept queries, it also needs to have a non-negative cosine similarity (prior to the [0, 1] mapping) with the other concept query. The semantic filter succeeds in eliminating some confounding features, i.e. queries that may be highly correlated with ILI rates, but are referring to different topics.<a class="fn" href="#fn7" id="foot-fn7"><sup>6</sup></a>    </p>    <p>We retain 128 search queries after applying the word embedding filter described above.<a class="fn" href="#fn8" id="foot-fn8"><sup>7</sup></a> The frequencies of these queries are retrieved through a private Google Health Trends API, provided for academic research with a health-oriented focus. The query frequency expresses the probability of a short search session<a class="fn" href="#fn9" id="foot-fn9"><sup>8</sup></a> conducted within a geographic region and during a specified time period. The probability is estimated based on a 10-15% sample of all Google searches. We obtained daily frequencies at the state-level (for the US) and the national-level (for the US and England) from September 1, 2007 to August 31, 2016 (both inclusive). Weekly frequencies were estimated by averaging the daily frequencies. Similarly, regional US frequencies were computed by averaging the state-level frequencies.</p>    <p>     <strong>Baselines, evaluation and parameter learning.</strong>. To demonstrate the effectiveness of multi-task learning models, we compare MTEN and MTGP with their single-task formulations, EN and GP, respectively. We use Pearson correlation (<em>r</em>) and the Mean Absolute Error (MAE) between inferred and target ILI rates as our evaluation metrics. For reporting the performance of multi-task learning models, we use the average MAE and correlation of the different test periods across all tasks (locations). The statistical significance of a performance improvement is tested via a paired-sample <em>t</em>-test by using the mean MAEs across all locations for the applied test periods (for the two methods under comparison). In our results, we use an asterisk (<sup>*</sup>) to indicate that a difference in performance is <strong>not</strong> statistically significant at the .05 level (<span class="inline-equation"><span class="tex">${\textit{p-value}} \ge .05$</span>     </span>). For learning the regularization parameters of the linear models, we perform grid search on 20% of the training data; all models are trained on the remaining 80% subset of the training data. We begin by training a model on data from the first <em>&#x03D5;</em> flu seasons, and test the model in the following season (<em>&#x03D5;</em> + 1). Then, we increase our training data by including one more flu season (<em>&#x03D5;</em> + 1) and test in the following season (<em>&#x03D5;</em> + 2); we repeat this process until we have tested on the last flu season in our data set. Before training a model, we only retain search queries that have a Pearson correlation higher than .3 with the respective disease rates (per location). This correlation threshold choice was motivated by the extensive experiments we conducted in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0034">34</a>] (see Table 3 in that paper). Note that the correlation filter is applied to each training data set separately and it may result in retaining different features for each task. Whenever this is the case, we maintain the intersection of features among the tasks. In addition, the GP and MTGP models are trained on the features that received a nonzero weight by the respective elastic net model, similarly to the methodology proposed in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0031">31</a>].</p>    </section>    <section id="sec-11">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Multi-Task Learning on US Regional and National ILI Surveillance Tasks</h3>     </div>    </header>    <p>First, we investigate whether multi-task learning can improve the accuracy of regional US models for the estimation of ILI rates. We test this hypothesis under a decreasing amount of training samples, where <em>L</em> varies from 5 to 1 year(s) of historical data. By doing this we can additionally assess whether multi-task learning models can have a positive impact when the historical training data are limited. The multi-task learning models are trained on data from the 10 US HSS regions jointly and their performance is compared to the performance obtained by learning these models separately.</p>    <p>Table&#x00A0;<a class="tbl" href="#tab1">1</a> enumerates the performance for the aforementioned comparison.<a class="fn" href="#fn10" id="foot-fn10"><sup>9</sup></a> We observe that in general multi-task learning models perform better than their single-task alternatives both in terms of MAE and correlation. In addition, the nonlinear models tend to outperform the linear ones. However, performance gains from multi-task learning (in MAE) only become statistically significant when <em>L</em> &#x2264; 2 years of historical training data are used. The greatest improvement occurs for <em>L</em> = 1; for this case MTEN reduces EN&#x0027;s MAE by 7.5%, whereas the MTGP reduces GP&#x0027;s MAE by 12.7%.</p>    <div class="table-responsive" id="tab1">    <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Performance of single and multi-task learning models for estimating ILI rates on US HHS regions. <em>L</em> denotes the length of the training period in years.</span>    </div>     <table class="table">      <thead>       <tr>       <th style="text-align:center;"/>       <th style="text-align:center;" colspan="2">        <strong>EN</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>MTEN</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>GP</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>MTGP</strong>        <hr/>       </th>       </tr>       <tr>       <th style="text-align:center;">        <em>L</em>       </th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       </tr>      </thead>      <tbody>       <tr>       <td style="text-align:center;">5</td>       <td style="text-align:center;">.928</td>       <td style="text-align:center;">.347</td>       <td style="text-align:center;">.935</td>       <td style="text-align:center;">.344<sup>*</sup>       </td>       <td style="text-align:center;">.936</td>       <td style="text-align:center;">.335</td>       <td style="text-align:center;">.944</td>       <td style="text-align:center;">.330<sup>*</sup>       </td>       </tr>       <tr>       <td style="text-align:center;">4</td>       <td style="text-align:center;">.919</td>       <td style="text-align:center;">.379</td>       <td style="text-align:center;">.927</td>       <td style="text-align:center;">.371<sup>*</sup>       </td>       <td style="text-align:center;">.926</td>       <td style="text-align:center;">.355</td>       <td style="text-align:center;">.938</td>       <td style="text-align:center;">.346<sup>*</sup>       </td>       </tr>       <tr>       <td style="text-align:center;">3</td>       <td style="text-align:center;">.912</td>       <td style="text-align:center;">.398</td>       <td style="text-align:center;">.921</td>       <td style="text-align:center;">.385<sup>*</sup>       </td>       <td style="text-align:center;">.916</td>       <td style="text-align:center;">.382</td>       <td style="text-align:center;">.929</td>       <td style="text-align:center;">.369<sup>*</sup>       </td>       </tr>       <tr>       <td style="text-align:center;">2</td>       <td style="text-align:center;">.901</td>       <td style="text-align:center;">.438</td>       <td style="text-align:center;">.913</td>       <td style="text-align:center;">.414</td>       <td style="text-align:center;">.906</td>       <td style="text-align:center;">.424</td>       <td style="text-align:center;">.924</td>       <td style="text-align:center;">.398</td>       </tr>       <tr>       <td style="text-align:center;">1</td>       <td style="text-align:center;">.845</td>       <td style="text-align:center;">.531</td>       <td style="text-align:center;">.858</td>       <td style="text-align:center;">.491</td>       <td style="text-align:center;">.844</td>       <td style="text-align:center;">.535</td>       <td style="text-align:center;">.867</td>       <td style="text-align:center;">.467</td>       </tr>       <tr>       <td colspan="9" style="text-align:left;">The asterisk (<sup>*</sup>) indicates that a multi-task learning model does <strong>not</strong> yield a statistically significant improvement over its single-task formulation.</td>       </tr>      </tbody>     </table>    </div>    <p>We next expand our observations by adding data for the US at a national level. Hence, we are now considering 11 tasks (US plus the 10 US regions). The aim is to test whether we can obtain a better model at the national level by training it together with regional data in a multi-task learning fashion. The results enumerated in Table&#x00A0;<a class="tbl" href="#tab2">2</a> confirm that this is the case. The impact of multi-task learning is greater and statistically significant (in terms of MAE), when <em>L</em> &#x2264; 3 years. The greatest improvement happens for <em>L</em> = 1; for this case MTEN reduces EN&#x0027;s MAE by 12.6%, whereas the MTGP reduces GP&#x0027;s MAE by 14.8%. In Fig.&#x00A0;<a class="fig" href="#fig3">3</a>, we compare the estimates from the GP and MTGP models for the ILI rates in the US during the test periods from 2012 to 2016 (4 flu seasons) under two different training data lengths (5 vs. 1 year of historical data) and against the rates reported by CDC. Even under the 5-year training period, where the difference in average performance between the models is small, we see that the GP makes a significant over-prediction of the peak during the 2012/13 flu season, something that the MTGP does not. The bottom sub-figure, where <em>L</em> = 1 year, showcases more clearly the level of improvement obtained by applying a multi-task learning scheme; MTGP delivers a quite accurate model despite being trained on a few samples. This is an important characteristic as it suggests that we can develop accurate disease prevalence models with much less historical data than previously considered&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0031">31</a>].</p>    <figure id="fig3">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186050/images/www2018-59-fig3.jpg" class="img-responsive" alt="Figure 3"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 3:</span>      <span class="figure-title">Comparing GP (red) and MTGP (blue) ILI estimates for the US using <em>L</em> = 5 years and <em>L</em> = 1 year of training data.</span>     </div>    </figure>     <div class="table-responsive" id="tab2">    <div class="table-caption">     <span class="table-number">Table 2:</span>     <span class="table-title">Performance of single and multi-task learning (including regional data) models for estimating US ILI rates; notational conventions as in Table&#x00A0;<a class="tbl" href="#tab1">1</a>.</span>    </div>     <table class="table">      <thead>       <tr>       <th style="text-align:center;"/>       <th style="text-align:center;" colspan="2">        <strong>EN</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>MTEN</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>GP</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>MTGP</strong>        <hr/>       </th>       </tr>       <tr>       <th style="text-align:center;">        <em>L</em>       </th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       </tr>      </thead>      <tbody>       <tr>       <td style="text-align:center;">5</td>       <td style="text-align:center;">.960</td>       <td style="text-align:center;">.353</td>       <td style="text-align:center;">.962<sup>*</sup>       </td>       <td style="text-align:center;">.351<sup>*</sup>       </td>       <td style="text-align:center;">.965</td>       <td style="text-align:center;">.253</td>       <td style="text-align:center;">.966<sup>*</sup>       </td>       <td style="text-align:center;">.245<sup>*</sup>       </td>       </tr>       <tr>       <td style="text-align:center;">4</td>       <td style="text-align:center;">.951</td>       <td style="text-align:center;">.356</td>       <td style="text-align:center;">.954<sup>*</sup>       </td>       <td style="text-align:center;">.353<sup>*</sup>       </td>       <td style="text-align:center;">.947</td>       <td style="text-align:center;">.265</td>       <td style="text-align:center;">.949<sup>*</sup>       </td>       <td style="text-align:center;">.251<sup>*</sup>       </td>       </tr>       <tr>       <td style="text-align:center;">3</td>       <td style="text-align:center;">.939</td>       <td style="text-align:center;">.398</td>       <td style="text-align:center;">.945</td>       <td style="text-align:center;">.374</td>       <td style="text-align:center;">.942</td>       <td style="text-align:center;">.286</td>       <td style="text-align:center;">.947<sup>*</sup>       </td>       <td style="text-align:center;">.268</td>       </tr>       <tr>       <td style="text-align:center;">2</td>       <td style="text-align:center;">.930</td>       <td style="text-align:center;">.408</td>       <td style="text-align:center;">.936</td>       <td style="text-align:center;">.362</td>       <td style="text-align:center;">.933</td>       <td style="text-align:center;">.351</td>       <td style="text-align:center;">.941</td>       <td style="text-align:center;">.323</td>       </tr>       <tr>       <td style="text-align:center;">1</td>       <td style="text-align:center;">.854</td>       <td style="text-align:center;">.531</td>       <td style="text-align:center;">.868</td>       <td style="text-align:center;">.464</td>       <td style="text-align:center;">.854</td>       <td style="text-align:center;">.513</td>       <td style="text-align:center;">.875</td>       <td style="text-align:center;">.437</td>       </tr>       <tr>       <td colspan="9" style="text-align:left;">The asterisk (<sup>*</sup>) indicates that a multi-task learning model does <strong>not</strong> yield a statistically significant improvement over its single-task formulation.</td>       </tr>      </tbody>     </table>    </div>    </section>    <section id="sec-12">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> Mitigating the Effect of Sporadic ILI Health Reports with Multi-Task Learning</h3>     </div>    </header>    <p>In many real-world scenarios, health surveillance reports are or can become temporally and/or geographically sporadic. For instance, syndromic surveillance networks, especially in developing countries, may focus on a few regions rather than an entire country due to infrastructure and economic constraints. Furthermore, established health surveillance schemes may be exposed to data loss due to unprecedented events, such as technical faults, natural disasters or a spreading epidemic during which doctor visits are discouraged. In the following experiments, we assess whether multi-task learning can help us establish more accurate disease models under various scenarios of sporadic health reporting. To assess this, we have performed several forms of down-sampling on the training data of several US HHS regions. All experiments were conducted by setting <em>L</em> = 1, i.e. based on 1-year long training periods, and results represent the average performance after 50 sampling trials.</p>    <p>We have applied the following sampling techniques: (<strong>A</strong>) <em>random weekly sampling</em>, (<strong>B</strong>) <em>random monthly sampling</em>, and (<strong>C</strong>) <em>random burst-error sampling</em>. In (A), we simply take random samples from our data, thereby simulating scenarios where reports for a specific week may be missing. In (B), we first partition our data into non-overlapping monthly periods and then randomly sample over these periods, thereby simulating situations where health systems may be affected for longer time periods. Finally, in (C) we randomly discard a block of temporally contiguous data points, and use the remaining points only. We apply a sampling rate <em>&#x03B3;</em> = {0.1, 0.2, &#x2026;, 1}, where <em>&#x03B3;</em> = 1 means that all data are used (no sampling), and <em>&#x03B3;</em> = 0.1 that 10% of the weekly data (for A) or monthly periods (for B) are maintained. In C, <em>&#x03B3;</em> determines the size of the error block <em>B</em>, <em>B</em> = (1 &#x2212; <em>&#x03B3;</em>)<em>&#x03C4;</em>, where <em>&#x03C4;</em> is equal to the size of the training data. In all experiments, we are sampling per location, meaning that the time points in the training data can vary across locations.<a class="fn" href="#fn11" id="foot-fn11"><sup>10</sup></a>    </p>    <p>We begin by assessing the added value of multi-task learning in situations, where progressively less health reports are obtained for half of the regions of a country. To simulate this, we partition the 10 US HSS regions into two sub-groups, <span class="inline-equation"><span class="tex">$\mathcal {R}$</span>     </span>-odd and <span class="inline-equation"><span class="tex">$\mathcal {R}$</span>     </span>-even consisting of the odd and even regions respectively (following the numbering of Fig.&#x00A0;<a class="fig" href="#fig1">1</a>). For the regions in <span class="inline-equation"><span class="tex">$\mathcal {R}$</span>     </span>-odd, we have increasingly down-sampled their training data; regions in <span class="inline-equation"><span class="tex">$\mathcal {R}$</span>     </span>-even were not subject to down-sampling.</p>    <p>Table&#x00A0;<a class="tbl" href="#tab3">3</a> enumerates the results of this experiment. The numbers in the table represent the average MAE of all test periods over the <span class="inline-equation"><span class="tex">$\mathcal {R}$</span>     </span>-odd regions. Generally, the performance of the multi-task learning models degrades less as down-sampling increases, i.e. there are less training data. MTGP always offers a statistically significant improvement over GP, whereas MTEN, in the worst case (for sampling type A), requires a <em>&#x03B3;</em> &#x2264; 0.4 to achieve this. Type A sampling, which can be seen as having missing weekly reports in various regions at random time points, affects single task learning models much more than multi-task learning models. For example, for the EN model, the MAE increased from .492 for <em>&#x03B3;</em> = 1 (no down-sampling), to .694 for <em>&#x03B3;</em> = 0.1, a degradation of 41.1%. In contrast, the MTEN model degrades by 13.5%. The effect is more pronounced for the nonlinear models, with GP degrading by 36.7% while MTGP degrades by only 4.8%. Note that MTGP&#x0027;s MAE is equal to .482 when the fewest data points are used (10% for <em>&#x03B3;</em> = 0.1), which is smaller than EN&#x0027;s or GP&#x0027;s MAEs, when no sampling is taking place (.492 and .502 respectively).</p>    <div class="table-responsive" id="tab3">    <div class="table-caption">     <span class="table-number">Table 3:</span>     <span class="table-title">Performance of single and multi-task learning models for estimating ILI rates on US HHS regions belonging to <span class="inline-equation"><span class="tex">$\mathcal {R}$</span>       </span>-odd under three sampling methods (A, B and C). Training data in <span class="inline-equation"><span class="tex">$\mathcal {R}$</span>       </span>-odd regions is down-sampled using a sampling rate (<em>&#x03B3;</em>).</span>    </div>     <table class="table">      <thead>       <tr>       <th style="text-align:center;"/>       <th style="text-align:center;"/>       <th style="text-align:center;" colspan="2">        <strong>EN</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>MTEN</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>GP</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>MTGP</strong>        <hr/>       </th>       </tr>       <tr>       <th style="text-align:center;"/>       <th style="text-align:center;">        <em>&#x03B3;</em>       </th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       </tr>      </thead>      <tbody>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">1.0</td>       <td style="text-align:center;">.825</td>       <td style="text-align:center;">.492</td>       <td style="text-align:center;">.843</td>       <td style="text-align:center;">.488<sup>*</sup>       </td>       <td style="text-align:center;">.828</td>       <td style="text-align:center;">.502</td>       <td style="text-align:center;">.856</td>       <td style="text-align:center;">.460</td>       </tr>       <tr>       <td style="text-align:center;">        <strong>A</strong>       </td>       <td style="text-align:center;">0.9</td>       <td style="text-align:center;">.823</td>       <td style="text-align:center;">.504</td>       <td style="text-align:center;">.840</td>       <td style="text-align:center;">.494<sup>*</sup>       </td>       <td style="text-align:center;">.825</td>       <td style="text-align:center;">.503</td>       <td style="text-align:center;">.852</td>       <td style="text-align:center;">.465</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.8</td>       <td style="text-align:center;">.806</td>       <td style="text-align:center;">.512</td>       <td style="text-align:center;">.839</td>       <td style="text-align:center;">.498<sup>*</sup>       </td>       <td style="text-align:center;">.817</td>       <td style="text-align:center;">.505</td>       <td style="text-align:center;">.850</td>       <td style="text-align:center;">.465</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.7</td>       <td style="text-align:center;">.805</td>       <td style="text-align:center;">.523</td>       <td style="text-align:center;">.834</td>       <td style="text-align:center;">.499<sup>*</sup>       </td>       <td style="text-align:center;">.811</td>       <td style="text-align:center;">.506</td>       <td style="text-align:center;">.849</td>       <td style="text-align:center;">.467</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.6</td>       <td style="text-align:center;">.800</td>       <td style="text-align:center;">.528</td>       <td style="text-align:center;">.824</td>       <td style="text-align:center;">.501<sup>*</sup>       </td>       <td style="text-align:center;">.804</td>       <td style="text-align:center;">.512</td>       <td style="text-align:center;">.835</td>       <td style="text-align:center;">.468</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.5</td>       <td style="text-align:center;">.798</td>       <td style="text-align:center;">.541</td>       <td style="text-align:center;">.823</td>       <td style="text-align:center;">.502<sup>*</sup>       </td>       <td style="text-align:center;">.804</td>       <td style="text-align:center;">.513</td>       <td style="text-align:center;">.835</td>       <td style="text-align:center;">.469</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.4</td>       <td style="text-align:center;">.789</td>       <td style="text-align:center;">.550</td>       <td style="text-align:center;">.822</td>       <td style="text-align:center;">.508</td>       <td style="text-align:center;">.801</td>       <td style="text-align:center;">.534</td>       <td style="text-align:center;">.829</td>       <td style="text-align:center;">.469</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.3</td>       <td style="text-align:center;">.768</td>       <td style="text-align:center;">.555</td>       <td style="text-align:center;">.817</td>       <td style="text-align:center;">.511</td>       <td style="text-align:center;">.801</td>       <td style="text-align:center;">.545</td>       <td style="text-align:center;">.825</td>       <td style="text-align:center;">.474</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.2</td>       <td style="text-align:center;">.758</td>       <td style="text-align:center;">.567</td>       <td style="text-align:center;">.803</td>       <td style="text-align:center;">.520</td>       <td style="text-align:center;">.789</td>       <td style="text-align:center;">.564</td>       <td style="text-align:center;">.824</td>       <td style="text-align:center;">.476</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.1</td>       <td style="text-align:center;">.698</td>       <td style="text-align:center;">.694</td>       <td style="text-align:center;">.793</td>       <td style="text-align:center;">.554</td>       <td style="text-align:center;">.700</td>       <td style="text-align:center;">.686</td>       <td style="text-align:center;">.824</td>       <td style="text-align:center;">.482</td>       </tr>       <tr>       <td style="text-align:center;">        <strong>B</strong>       </td>       <td style="text-align:center;">0.9</td>       <td style="text-align:center;">.813</td>       <td style="text-align:center;">.516</td>       <td style="text-align:center;">.835</td>       <td style="text-align:center;">.495<sup>*</sup>       </td>       <td style="text-align:center;">.814</td>       <td style="text-align:center;">.519</td>       <td style="text-align:center;">.851</td>       <td style="text-align:center;">.463</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.8</td>       <td style="text-align:center;">.806</td>       <td style="text-align:center;">.531</td>       <td style="text-align:center;">.827</td>       <td style="text-align:center;">.505<sup>*</sup>       </td>       <td style="text-align:center;">.805</td>       <td style="text-align:center;">.528</td>       <td style="text-align:center;">.843</td>       <td style="text-align:center;">.468</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.7</td>       <td style="text-align:center;">.793</td>       <td style="text-align:center;">.549</td>       <td style="text-align:center;">.823</td>       <td style="text-align:center;">.511<sup>*</sup>       </td>       <td style="text-align:center;">.792</td>       <td style="text-align:center;">.540</td>       <td style="text-align:center;">.834</td>       <td style="text-align:center;">.475</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.6</td>       <td style="text-align:center;">.775</td>       <td style="text-align:center;">.555</td>       <td style="text-align:center;">.821</td>       <td style="text-align:center;">.516</td>       <td style="text-align:center;">.776</td>       <td style="text-align:center;">.565</td>       <td style="text-align:center;">.825</td>       <td style="text-align:center;">.476</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.5</td>       <td style="text-align:center;">.752</td>       <td style="text-align:center;">.574</td>       <td style="text-align:center;">.820</td>       <td style="text-align:center;">.523</td>       <td style="text-align:center;">.756</td>       <td style="text-align:center;">.570</td>       <td style="text-align:center;">.823</td>       <td style="text-align:center;">.478</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.4</td>       <td style="text-align:center;">.702</td>       <td style="text-align:center;">.598</td>       <td style="text-align:center;">.818</td>       <td style="text-align:center;">.534</td>       <td style="text-align:center;">.751</td>       <td style="text-align:center;">.594</td>       <td style="text-align:center;">.819</td>       <td style="text-align:center;">.485</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.3</td>       <td style="text-align:center;">.621</td>       <td style="text-align:center;">.751</td>       <td style="text-align:center;">.815</td>       <td style="text-align:center;">.544</td>       <td style="text-align:center;">.650</td>       <td style="text-align:center;">.748</td>       <td style="text-align:center;">.817</td>       <td style="text-align:center;">.491</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.2</td>       <td style="text-align:center;">.510</td>       <td style="text-align:center;">.781</td>       <td style="text-align:center;">.814</td>       <td style="text-align:center;">.547</td>       <td style="text-align:center;">.516</td>       <td style="text-align:center;">.776</td>       <td style="text-align:center;">.814</td>       <td style="text-align:center;">.497</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.1</td>       <td style="text-align:center;">.425</td>       <td style="text-align:center;">.942</td>       <td style="text-align:center;">.806</td>       <td style="text-align:center;">.583</td>       <td style="text-align:center;">.433</td>       <td style="text-align:center;">.930</td>       <td style="text-align:center;">.809</td>       <td style="text-align:center;">.503</td>       </tr>       <tr>       <td style="text-align:center;">        <strong>C</strong>       </td>       <td style="text-align:center;">0.9</td>       <td style="text-align:center;">.817</td>       <td style="text-align:center;">.524</td>       <td style="text-align:center;">.836</td>       <td style="text-align:center;">.497<sup>*</sup>       </td>       <td style="text-align:center;">.818</td>       <td style="text-align:center;">.525</td>       <td style="text-align:center;">.848</td>       <td style="text-align:center;">.466</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.8</td>       <td style="text-align:center;">.805</td>       <td style="text-align:center;">.539</td>       <td style="text-align:center;">.829</td>       <td style="text-align:center;">.506<sup>*</sup>       </td>       <td style="text-align:center;">.810</td>       <td style="text-align:center;">.532</td>       <td style="text-align:center;">.839</td>       <td style="text-align:center;">.470</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.7</td>       <td style="text-align:center;">.796</td>       <td style="text-align:center;">.554</td>       <td style="text-align:center;">.817</td>       <td style="text-align:center;">.513</td>       <td style="text-align:center;">.801</td>       <td style="text-align:center;">.552</td>       <td style="text-align:center;">.832</td>       <td style="text-align:center;">.471</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.6</td>       <td style="text-align:center;">.784</td>       <td style="text-align:center;">.576</td>       <td style="text-align:center;">.814</td>       <td style="text-align:center;">.528</td>       <td style="text-align:center;">.788</td>       <td style="text-align:center;">.569</td>       <td style="text-align:center;">.825</td>       <td style="text-align:center;">.473</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.5</td>       <td style="text-align:center;">.756</td>       <td style="text-align:center;">.606</td>       <td style="text-align:center;">.807</td>       <td style="text-align:center;">.535</td>       <td style="text-align:center;">.766</td>       <td style="text-align:center;">.588</td>       <td style="text-align:center;">.819</td>       <td style="text-align:center;">.477</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.4</td>       <td style="text-align:center;">.689</td>       <td style="text-align:center;">.637</td>       <td style="text-align:center;">.799</td>       <td style="text-align:center;">.543</td>       <td style="text-align:center;">.713</td>       <td style="text-align:center;">.626</td>       <td style="text-align:center;">.818</td>       <td style="text-align:center;">.480</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.3</td>       <td style="text-align:center;">.621</td>       <td style="text-align:center;">.739</td>       <td style="text-align:center;">.794</td>       <td style="text-align:center;">.557</td>       <td style="text-align:center;">.632</td>       <td style="text-align:center;">.711</td>       <td style="text-align:center;">.804</td>       <td style="text-align:center;">.492</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.2</td>       <td style="text-align:center;">.483</td>       <td style="text-align:center;">.792</td>       <td style="text-align:center;">.781</td>       <td style="text-align:center;">.561</td>       <td style="text-align:center;">.506</td>       <td style="text-align:center;">.791</td>       <td style="text-align:center;">.800</td>       <td style="text-align:center;">.498</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">0.1</td>       <td style="text-align:center;">.414</td>       <td style="text-align:center;">.934</td>       <td style="text-align:center;">.780</td>       <td style="text-align:center;">.571</td>       <td style="text-align:center;">.424</td>       <td style="text-align:center;">.906</td>       <td style="text-align:center;">.796</td>       <td style="text-align:center;">.505</td>       </tr>       <tr>       <td colspan="10" style="text-align:left;">The asterisk (<sup>*</sup>) indicates that a multi-task learning model does <strong>not</strong> yield a statistically significant improvement over its single-task formulation.</td>       </tr>      </tbody>     </table>    </div>    <p>All models degrade worse for B and C sampling methods, which drop blocks of data points from the training set. However, the degradation in performance of the multi-task learning models is much less than for the comparative EN or GP models. For example, when <em>&#x03B3;</em> = 0.1, MTGP improves GP&#x0027;s MAE by 45.9% and 44.3% for B and C sampling types, respectively. Fig.&#x00A0;<a class="fig" href="#fig4">4</a> illustrates this performance difference by comparing the ILI estimates from the GP and MTGP models for US region 9 under burst error sampling, for <em>&#x03B3;</em> = 0.5 (top) and <em>&#x03B3;</em> = 0.1 (bottom).<a class="fn" href="#fn12" id="foot-fn12"><sup>11</sup></a> Clearly, for low sampling rates (<em>&#x03B3;</em> = 0.1) the MTGP model is still able to provide acceptable performance.</p>    <figure id="fig4">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186050/images/www2018-59-fig4.jpg" class="img-responsive" alt="Figure 4"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 4:</span>      <span class="figure-title">Comparing GP (red) and MTGP (blue) ILI estimates for US Region 9 for two burst error sampling (type C) rates (<em>&#x03B3;</em>).</span>     </div>    </figure>    <p>In a subsequent experiment, we performed burst-error sampling on all but two US regions with the highest population figures (Regions 4 and 9). The rational behind this setting is that in many occasions health reports are available for central locations in a country (i.e. two big cities), but are limited anywhere else. Fig.&#x00A0;<a class="fig" href="#fig5">5</a> compares the performance of all regression models under this scenario. It confirms that the pattern observed in the previous experiment still holds, i.e. that the multi-task models are much less affected by down-sampling. We can also see that MAE in single task learning models increases at an exponential rate as <em>&#x03B3;</em> decreases.</p>    <figure id="fig5">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186050/images/www2018-59-fig5.jpg" class="img-responsive" alt="Figure 5"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 5:</span>      <span class="figure-title">Comparing the performance of EN (dotted), GP (dashed), MTEN (dash dot) and MTGP (solid) on estimating the ILI rates for US HHS Regions (except Regions 4 and 9) for varying burst error sampling (type C) rates (<em>&#x03B3;</em>).</span>     </div>    </figure>    </section>    <section id="sec-13">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.4</span> Multi-Task Learning Across Countries</h3>     </div>    </header>    <p>We expand on the previous results to test whether a stable data stream for a country could be used to enhance a disease model for a different, but culturally similar, country. The underlying assumption here is that countries that share a common language and have cultural similarities may also share common patterns of user search behavior.</p>    <p>For this purpose, we use data from the US and England and assume that there are increasingly less historical health reports for England only, in a similar fashion as in the experiments described in Section&#x00A0;<a class="sec" href="#sec-11">3.2</a> (<em>L</em> from 5 to 1 year). For the US data, we always assume that the training window is based on the past <em>L</em> = 5 years. The search queries used in both countries are the same, with the following exception. Two of the US search queries about medication were changed to their British equivalent because their search frequencies in England are low; we changed &#x201C;tussin&#x201D; to &#x201C;robitussin&#x201D; and &#x201C;z pak&#x201D; to &#x201C;azithromycin&#x201D;.</p>    <p>Table&#x00A0;<a class="tbl" href="#tab4">4</a> shows a similar pattern of results as in the previous experiments. All multi-task learning models register statistically significant improvements compared to the single task learning ones. As the length of the training period is reduced, the improvements are greater; MTGP reduces MAE by 20.9% and 40.0% for <em>L</em> = 5 and <em>L</em> = 1 year, respectively. Fig.&#x00A0;<a class="fig" href="#fig6">6</a> presents the estimates for the GP and MTGP models for these extreme cases. Whereas both models seem to be inferring the trends of the time series correctly, the multi-task estimates are more close to the actual values of the signal&#x0027;s peaks.</p>    <figure id="fig6">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186050/images/www2018-59-fig6.jpg" class="img-responsive" alt="Figure 6"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 6:</span>      <span class="figure-title">Comparing GP (red) and MTGP (blue) ILI estimates for England under varying training data sizes.</span>     </div>    </figure>     <div class="table-responsive" id="tab4">    <div class="table-caption">     <span class="table-number">Table 4:</span>     <span class="table-title">Performance of single and multi-task learning models for estimating ILI rates in England; notational conventions as in Table&#x00A0;<a class="tbl" href="#tab1">1</a>.</span>    </div>     <table class="table">      <thead>       <tr>       <th style="text-align:center;"/>       <th style="text-align:center;" colspan="2">        <strong>EN</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>MTEN</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>GP</strong>        <hr/>       </th>       <th style="text-align:center;" colspan="2">        <strong>MTGP</strong>        <hr/>       </th>       </tr>       <tr>       <th style="text-align:center;">        <em>L</em>       </th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       <th style="text-align:center;">        <em>r</em>       </th>       <th style="text-align:center;">MAE</th>       </tr>      </thead>      <tbody>       <tr>       <td style="text-align:center;">5</td>       <td style="text-align:center;">.885</td>       <td style="text-align:center;">.696</td>       <td style="text-align:center;">.896</td>       <td style="text-align:center;">.491</td>       <td style="text-align:center;">.891</td>       <td style="text-align:center;">.599</td>       <td style="text-align:center;">.903</td>       <td style="text-align:center;">.474</td>       </tr>       <tr>       <td style="text-align:center;">4</td>       <td style="text-align:center;">.873</td>       <td style="text-align:center;">.734</td>       <td style="text-align:center;">.887</td>       <td style="text-align:center;">.504</td>       <td style="text-align:center;">.880</td>       <td style="text-align:center;">.664</td>       <td style="text-align:center;">.894</td>       <td style="text-align:center;">.491</td>       </tr>       <tr>       <td style="text-align:center;">3</td>       <td style="text-align:center;">.860</td>       <td style="text-align:center;">.788</td>       <td style="text-align:center;">.876</td>       <td style="text-align:center;">.530</td>       <td style="text-align:center;">.868</td>       <td style="text-align:center;">.742</td>       <td style="text-align:center;">.883</td>       <td style="text-align:center;">.517</td>       </tr>       <tr>       <td style="text-align:center;">2</td>       <td style="text-align:center;">.854</td>       <td style="text-align:center;">.842</td>       <td style="text-align:center;">.871</td>       <td style="text-align:center;">.554</td>       <td style="text-align:center;">.859</td>       <td style="text-align:center;">.815</td>       <td style="text-align:center;">.875</td>       <td style="text-align:center;">.528</td>       </tr>       <tr>       <td style="text-align:center;">1</td>       <td style="text-align:center;">.836</td>       <td style="text-align:center;">.999</td>       <td style="text-align:center;">.857</td>       <td style="text-align:center;">.603</td>       <td style="text-align:center;">.846</td>       <td style="text-align:center;">.977</td>       <td style="text-align:center;">.860</td>       <td style="text-align:center;">.586</td>       </tr>      </tbody>     </table>    </div>    <p>The results confirm our original hypothesis that data from one country could improve a disease model for another country with similar characteristics. This motivates the development of more advanced transfer learning schemes&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0041">41</a>], capable of operating between countries with different languages by overcoming language barrier problems, using variants of machine translation.</p>    </section>    <section id="sec-14">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.5</span> Qualitative Insights from the MTGP Model</h3>     </div>    </header>    <p>The main motivation for using multi-task learning models within the context of disease surveillance from Web search data was our assumption that relations between <em>correlated</em> locations will be identified and accounted for. According to our results, the best performing model under the vast majority of experimental settings was the MTGP model. Given this empirical result, we assume that the hyperparameters of the MTGP model could provide further insight about the inner-workings of the model. After training an MTGP model on all the US data available (10 HHS regions and US nationally), we examined the inferred correlation matrix (<span class="inline-equation"><span class="tex">$\mathbf {K}^{\textrm {c}}$</span>     </span> in Eq.&#x00A0;<a class="eqn" href="#eq13">13</a>), which we depict using a gray-scale heat map in Fig.&#x00A0;<a class="fig" href="#fig7">7</a>. We can identify two areas of the heat map that are characterized by increased correlation values, denoted as A1 and A2. A1 and A2 are &#x201C;clusters&#x201D;, representing groups of north-east and central states/regions of the US, respectively. Using the region numbering as a crude proxy for the distance between regions, we also observe that correlations are generally higher for neighboring areas. The same holds for smaller internal sub-clusters of the area A2 (e.g. regions R6-R8). Both observations provide further evidence that the MTGP model is probably capturing existing geographical relations.</p>    <figure id="fig7">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186050/images/www2018-59-fig7.jpg" class="img-responsive" alt="Figure 7"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 7:</span>      <span class="figure-title">A heat map depicting MTGP&#x0027;s correlation matrix (<span class="inline-equation"><span class="tex">$\mathbf {K}^{\textrm {c}}$</span>       </span>) for modeling ILI rates based on all US data (regional and national).</span>     </div>    </figure>    </section>   </section>   <section id="sec-15">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> Related Work</h2>    </div>    </header>    <p>The fundamentals of multi-task learning have been thoroughly presented in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>]. Compared to single task learning that attempts training on isolated tasks, multi-task learning performs this jointly using a shared representation. The tasks can be used as valuable sources of inductive bias for each other, leading to a more accurate model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>]. This may also allow more difficult problems, such as target variables with partial observations, to be modeled successfully&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>]. The majority of multi-task regression models were developed by extending their single-task formulations. Some examples for linear regression are the multi-task &#x2113;<sub>1</sub>-norm regularization&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] and the &#x2113;<sub>2, 1</sub>-norm regularization&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>]. Nonlinear multi-task regression models have also been explored, extending Support Vector Machines&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>], Gaussian Processes&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>], Convolutional or Recurrent Neural Networks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>].</p>    <p>In this work, we study the utility of multi-task learning in disease surveillance from Web search data. Existing approaches have routinely used single task models such as regularized regression&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>], Gaussian Processes&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>], and autoregressive frameworks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0047">47</a>]. Here, we have chosen to apply MTEN&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>] and MTGP [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>] for the following reasons: (a) EN and GPs have been applied in many text regression&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0044">44</a>] and disease modeling approaches [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0055">55</a>], and (b) the sample sizes we are operating on are limited and no performance gain would have been achieved by deploying neural network structures (such as &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0051">51</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0052">52</a>]).</p>    <p>Multi-task learning has been applied in the context of user-generated data modeling&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>] and computational health&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0053">53</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0054">54</a>]. Given various tasks and objectives, multi-task learning frameworks can be different. Zhou <em>et al.</em> and Emrani <em>et al.</em> formulated a fused sparse group lasso&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0054">54</a>] and a graph regularization approach&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>], respectively, aiming to model disease progression. Both models focused on the temporal relation between the various tasks and utilized image data from patients. However, our work focuses on textual user-generated content and the spatial relation among tasks. In&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>], Benton <em>et al.</em> used online multimodal user-generated content to train a multi-task feedforward neural network for classifying the mental health condition of online users. This model tries to capture shared structures of user attributes in relation to mental conditions. Our work, however, focuses on a collective regression task, aiming to exploit relationships at a higher level, determined by geography, rather than specific user characteristics. Finally, Zhao <em>et al.</em> proposed a linear regularized multi-task regression model to detect civil unrest events in various locations using Twitter data&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0053">53</a>]. In our work, apart from a different thematic focus, we also deploy nonlinear multi-task learning frameworks.</p>   </section>   <section id="sec-16">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Conclusions</h2>    </div>    </header>    <p>We have investigated the utility of multi-task learning to disease surveillance from Web search data. Disease surveillance models for various geographies &#x2014; inside a country and across different countries &#x2014; were trained jointly such that knowledge between different tasks could be shared. We explored both linear and nonlinear models (MTEN and MTGP) and used ILI surveillance as a case study. Experiments were conducted on the US and England. Our empirical results indicate that multi-task learning improves regional as well as national models for the US. The percentage of improvement increases as we reduce the historical training data. For a 1-year training period, the MTGP model improved MAE by 14.8% at the regional level. Furthermore, in simulated scenarios, where health reports (training data) are limited, we showed that multi-task learning helps to maintain a stable inference performance across all the affected locations. Experiments, where data for England were modeled in conjunction with US data, indicated that more accurate estimates were obtained for England, maxed at a 40% of MAE reduction when using 1-year long training periods. This suggests that multi-task learning can benefit models across different countries as well. Finally, our assumption that correlations in the search behavior of users across similar geographies and cultures will significantly assist this type of disease modeling is also supported by empirical evidence.</p>    <p>Future work will aim to extend this type of modeling by developing appropriate frameworks for transfer learning, e.g. between countries with different languages, and apply it in real-world situations. These should include locations (regions or countries) with underdeveloped disease surveillance schemes as well as different disease types for which fewer historical health reports are available.</p>   </section>   <section id="sec-17">    <header>    <div class="title-info">     <h2>Acknowledgments</h2>    </div>    </header>    <p>This work has been supported by the grant EP/K031953/1 (EPSRC). The authors would like to acknowledge PHE and RCGP for providing syndromic surveillance data, and Google for providing access to the Google Health Trends API. We also thank the anonymous reviewers for their constructive feedback.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">A.&#x00A0;H. Abdulnabi, G. Wang, J. Lu, and K. Jia. 2015. Multi-Task CNN Model for Attribute Prediction. <em>      <em>IEEE Transactions on Multimedia</em>     </em>17, 11 (2015), 1949&#x2013;1959.</li>    <li id="BibPLXBIB0002" label="[2]">A. Argyriou, T. Evgeniou, and M. Pontil. 2006. Multi-Task Feature Learning. In <em>      <em>Proceedings of Advances in Neural Information Processing Systems 19</em>     </em>.</li>    <li id="BibPLXBIB0003" label="[3]">A. Argyriou, T. Evgeniou, and M. Pontil. 2008. Convex Multi-Task Feature Learning. <em>      <em>Machine Learning</em>     </em>73, 3 (2008), 243&#x2013;272.</li>    <li id="BibPLXBIB0004" label="[4]">B. Bakker and T. Heskes. 2003. Task Clustering and Gating for Bayesian Multitask Learning. <em>      <em>Journal of Machine Learning Research</em>     </em>4 (2003), 83&#x2013;99.</li>    <li id="BibPLXBIB0005" label="[5]">E. Bakshy, S. Messing, and L.&#x00A0;A. Adamic. 2015. Exposure to ideologically diverse news and opinion on Facebook. <em>      <em>Science</em>     </em>348, 6239 (2015), 1130&#x2013;1132.</li>    <li id="BibPLXBIB0006" label="[6]">J. Baxter. 2000. A Model of Inductive Bias Learning. <em>      <em>Journal of Artificial Intelligence Research</em>     </em>12, 1 (2000), 149&#x2013;198.</li>    <li id="BibPLXBIB0007" label="[7]">D. Beck, T. Cohn, and L. Specia. 2014. Joint Emotion Analysis via Multi-task Gaussian Processes. In <em>      <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</em>     </em>. 1798&#x2013;1803.</li>    <li id="BibPLXBIB0008" label="[8]">S. Ben-David and R. Schuller. 2003. Exploiting Task Relatedness for Multiple Task Learning. In <em>      <em>Proceedings of the 16th Annual Conference on Learning Theory and 7th Kernel Workshop</em>     </em>. 567&#x2013;580.</li>    <li id="BibPLXBIB0009" label="[9]">A. Benton, M. Mitchell, and D. Hovy. 2017. Multitask Learning for Mental Health Conditions with Limited Social Media Data. In <em>      <em>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</em>     </em>. 152&#x2013;162.</li>    <li id="BibPLXBIB0010" label="[10]">S. Bickel, J. Bogojeska, T. Lengauer, and T. Scheffer. 2008. Multi-Task Learning for HIV Therapy Screening. In <em>      <em>Proceedings of the 25th International Conference on Machine Learning</em>     </em>. 56&#x2013;63.</li>    <li id="BibPLXBIB0011" label="[11]">E.&#x00A0;V. Bonilla, K.&#x00A0;M.&#x00A0;A. Chai, and C.&#x00A0;K.&#x00A0;I. Williams. 2007. Multi-task Gaussian Process Prediction. In <em>      <em>Proceedings of Advances in Neural Information Processing Systems 20</em>     </em>. 153&#x2013;160.</li>    <li id="BibPLXBIB0012" label="[12]">R. Caruana. 1993. Multitask Learning: A Knowledge-based Source of Inductive Bias. In <em>      <em>Proceedings of the 10th International Conference on Machine learning</em>     </em>. 41&#x2013;48.</li>    <li id="BibPLXBIB0013" label="[13]">R. Caruana. 1998. Multitask Learning. In <em>      <em>Learning to Learn</em>     </em>. Springer, 95&#x2013;133.</li>    <li id="BibPLXBIB0014" label="[14]">M.&#x00A0;De Choudhury, M. Gamon, S. Counts, and E. Horvitz. 2013. Predicting Depression via Social Media. In <em>      <em>Proceedings of the 7th International AAAI Conference on Weblogs and Social Media</em>     </em>. 128&#x2013;137.</li>    <li id="BibPLXBIB0015" label="[15]">T. Cohn and L. Specia. 2013. Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation. In <em>      <em>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</em>     </em>. 32&#x2013;42.</li>    <li id="BibPLXBIB0016" label="[16]">R. Collobert and J. Weston. 2008. A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning. In <em>      <em>Proceedings of the 25th International Conference on Machine Learning</em>     </em>. 160&#x2013;167.</li>    <li id="BibPLXBIB0017" label="[17]">A. Culotta. 2010. Towards Detecting Influenza Epidemics by Analyzing Twitter Messages. In <em>      <em>Proceedings of the 1st Workshop on Social Media Analytics</em>     </em>. 115&#x2013;122.</li>    <li id="BibPLXBIB0018" label="[18]">R. Durichen, M.&#x00A0;A.&#x00A0;F. Pimentel, L. Clifton, A. Schweikard, and D.&#x00A0;A. Clifton. 2014. Multi-task Gaussian process Models for Biomedical Applications. In <em>      <em>Proceedings of the 2014 IEEE-EMBS International Conference on Biomedical and Health Informatics</em>     </em>. 492&#x2013;495.</li>    <li id="BibPLXBIB0019" label="[19]">S. Emrani, A. McGuirk, and W. Xiao. 2017. Prognosis and Diagnosis of Parkinson&#x0027;s Disease Using Multi-Task Learning. In <em>      <em>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>     </em>. 1457&#x2013;1466.</li>    <li id="BibPLXBIB0020" label="[20]">T. Evgeniou and M. Pontil. 2004. Regularized Multi-Task Learning. In <em>      <em>Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>     </em>. 109&#x2013;117.</li>    <li id="BibPLXBIB0021" label="[21]">H. Gil&#x00A0;de Z&#x00FA;&#x00F1;iga, N. Jung, and S. Valenzuela. 2012. Social Media Use for News and Individuals&#x2019; Social Capital, Civic Engagement and Political Participation. <em>      <em>Journal of Computer-Mediated Communication</em>     </em>17, 3 (2012), 319&#x2013;336.</li>    <li id="BibPLXBIB0022" label="[22]">J. Ginsberg, M.&#x00A0;H. Mohebbi, R.&#x00A0;S. Patel, L. Brammer, M.&#x00A0;S. Smolinski, and L. Brilliant. 2009. Detecting Influenza Epidemics using Search Engine Query Data. <em>      <em>Nature</em>     </em>457, 7232 (2009), 1012&#x2013;1014.</li>    <li id="BibPLXBIB0023" label="[23]">T. Hastie, R. Tibshirani, and J. Friedman. 2009. <em>      <em>The Elements of Statistical Learning Data Mining, Inference, and Prediction, Second Edition</em>     </em>. Springer.</li>    <li id="BibPLXBIB0024" label="[24]">A.&#x00A0;E. Hoerl and R.&#x00A0;W. Kennard. 1970. Ridge Regression: Biased Estimation for Nonorthogonal Problems. <em>      <em>Technometrics</em>     </em>12, 1 (1970), 55&#x2013;67.</li>    <li id="BibPLXBIB0025" label="[25]">M. Kosinski, D. Stillwell, and T. Graepel. 2013. Private Traits and Attributes are Predictable from Digital Records of Human Behavior. <em>      <em>Proceedings of the National Academy of Sciences</em>     </em>110, 15(2013), 5802&#x2013;5805.</li>    <li id="BibPLXBIB0026" label="[26]">A.&#x00A0;D.&#x00A0;I. Kramer, J.&#x00A0;E. Guillory, and J.&#x00A0;T. Hancock. 2014. Experimental evidence of massive-scale emotional contagion through social networks. <em>      <em>Proceedings of the National Academy of Sciences</em>     </em>111, 24(2014), 8788&#x2013;8790.</li>    <li id="BibPLXBIB0027" label="[27]">V. Lampos, N. Aletras, D. Preo&#x0163;iuc-Pietro, and T. Cohn. 2014. Predicting and Characterising User Impact on Twitter. In <em>      <em>Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</em>     </em>. 405&#x2013;413.</li>    <li id="BibPLXBIB0028" label="[28]">V. Lampos and N. Cristianini. 2010. Tracking the flu pandemic by monitoring the Social Web. In <em>      <em>Proceedings of the 2nd International Workshop on Cognitive Information Processing</em>     </em>. 411&#x2013;416.</li>    <li id="BibPLXBIB0029" label="[29]">V. Lampos and N. Cristianini. 2012. Nowcasting Events from the Social Web with Statistical Learning. <em>      <em>ACM Transactions on Intelligent Systems and Technology</em>     </em>3, 4 (2012), 1&#x2013;22.</li>    <li id="BibPLXBIB0030" label="[30]">V. Lampos, T. De&#x00A0;Bie, and N. Cristianini. 2010. Flu Detector - Tracking Epidemics on Twitter. In <em>      <em>Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases</em>     </em>. 599&#x2013;602.</li>    <li id="BibPLXBIB0031" label="[31]">V. Lampos, A.&#x00A0;C. Miller, S. Crossan, and C. Stefansen. 2015. Advances in nowcasting influenza-like illness rates using search query logs. <em>      <em>Scientific Reports</em>     </em>5, 12760 (2015).</li>    <li id="BibPLXBIB0032" label="[32]">V. Lampos, D. Preo&#x0163;iuc-Pietro, and T. Cohn. 2013. A user-centric model of voting intention from social media. In <em>      <em>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</em>     </em>. 993&#x2013;1003.</li>    <li id="BibPLXBIB0033" label="[33]">V. Lampos, E. Yom-Tov, R. Pebody, and I.&#x00A0;J. Cox. 2015. Assessing the Impact of a Health Intervention via User-generated Internet Content. <em>      <em>Data Mining and Knowledge Discovery</em>     </em>29, 5 (2015), 1434&#x2013;1457.</li>    <li id="BibPLXBIB0034" label="[34]">V. Lampos, B. Zou, and I.&#x00A0;J. Cox. 2017. Enhancing Feature Selection Using Word Embeddings: The Case of Flu Surveillance. In <em>      <em>Proceedings of the 26th International Conference on World Wide Web</em>     </em>. 695&#x2013;704.</li>    <li id="BibPLXBIB0035" label="[35]">S. Lee, J. Zhu, and E.&#x00A0;P. Xing. 2010. Adaptive Multi-task Lasso: With Application to eQTL Detection. In <em>      <em>Proceedings of the 23rd International Conference on Neural Information Processing Systems</em>     </em>. 1306&#x2013;1314.</li>    <li id="BibPLXBIB0036" label="[36]">J. Liu, S. Ji, and J. Ye. 2009. Multi-task Feature Learning via Efficient &#x2113;<sub>2, 1</sub>-Norm Minimization. In <em>      <em>Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence</em>     </em>. 339&#x2013;348.</li>    <li id="BibPLXBIB0037" label="[37]">P. Liu, X. Qiu, and X. Huang. 2016. Recurrent Neural Network for Text Classification with Multi-task Learning. In <em>      <em>Proceedings of the 25th International Joint Conference on Artificial Intelligence</em>     </em>. 2873&#x2013;2879.</li>    <li id="BibPLXBIB0038" label="[38]">M. Lukasik, T. Cohn, and K. Bontcheva. 2015. Classifying Tweet Level Judgements of Rumours in Social Media. In <em>      <em>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</em>     </em>. 2590&#x2013;2595.</li>    <li id="BibPLXBIB0039" label="[39]">A.&#x00A0;M. Manago, T. Taylor, and P.&#x00A0;M. Greenfield. 2012. Me and my 400 friends: The anatomy of college students&#x2019; Facebook networks, their communication patterns, and well-being. <em>      <em>Developmental Psychology</em>     </em>48, 2 (2012), 369&#x2013;380.</li>    <li id="BibPLXBIB0040" label="[40]">T. Mikolov, I. Sutskever, K. Chen, G.&#x00A0;S. Corrado, and J. Dean. 2013. Distributed Representations of Words and Phrases and Their Compositionality. In <em>      <em>Proceedings of Advances in Neural Information Processing Systems 26</em>     </em>. 3111&#x2013;3119.</li>    <li id="BibPLXBIB0041" label="[41]">S.&#x00A0;J. Pan and Q. Yang. 2010. A Survey on Transfer Learning. <em>      <em>IEEE Transactions on Knowledge and Data Engineering</em>     </em>22, 10(2010), 1345&#x2013;1359.</li>    <li id="BibPLXBIB0042" label="[42]">M.&#x00A0;J. Paul, M. Dredze, and D. Broniatowski. 2014. Twitter Improves Influenza Forecasting. <em>      <em>PLOS Currents Outbreaks</em>     </em>(2014).</li>    <li id="BibPLXBIB0043" label="[43]">P.&#x00A0;M. Polgreen, Y. Chen, D.&#x00A0;M. Pennock, F.&#x00A0;D. Nelson, and R.&#x00A0;A. Weinstein. 2008. Using Internet Searches for Influenza Surveillance. <em>      <em>Clinical Infectious Diseases</em>     </em>47, 11 (2008), 1443&#x2013;1448.</li>    <li id="BibPLXBIB0044" label="[44]">D. Preo&#x0163;iuc-Pietro, V. Lampos, and N. Aletras. 2015. An analysis of the user occupational class through Twitter content. In <em>      <em>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</em>     </em>. 1754&#x2013;1764.</li>    <li id="BibPLXBIB0045" label="[45]">C.&#x00A0;E. Rasmussen and C.&#x00A0;K.&#x00A0;I. Williams. 2006. <em>      <em>Gaussian Processes for Machine Learning</em>     </em>. MIT Press.</li>    <li id="BibPLXBIB0046" label="[46]">H.&#x00A0;A. Schwartz <em>et al.</em> 2013. Personality, Gender, and Age in the Language of Social Media: The Open-Vocabulary Approach. <em>      <em>PLoS ONE</em>     </em>8, 9 (2013), e73791.</li>    <li id="BibPLXBIB0047" label="[47]">J. Shaman and A. Karspeck. 2012. Forecasting Seasonal Outbreaks of Influenza. <em>      <em>Proceedings of the National Academy of Sciences</em>     </em>109, 50(2012), 20425&#x2013;20430.</li>    <li id="BibPLXBIB0048" label="[48]">R. Tibshirani. 1996. Regression Shrinkage and Selection via the Lasso. <em>      <em>Journal of the Royal Statistical Society</em>     </em>58, 1 (1996), 267&#x2013;288.</li>    <li id="BibPLXBIB0049" label="[49]">H. Wackernagel. 2013. <em>      <em>Multivariate Geostatistics: An Introduction with Applications</em>     </em>. Springer.</li>    <li id="BibPLXBIB0050" label="[50]">M. Wagner, V. Lampos, E. Yom-Tov, R. Pebody, and I.&#x00A0;J. Cox. 2017. Estimating the Population Impact of a New Pediatric Influenza Vaccination Program in England Using Social Media Content. <em>      <em>Journal of Medical Internet Research</em>     </em>19, 12 (2017), e416.</li>    <li id="BibPLXBIB0051" label="[51]">W. Zhang, R. Li, T. Zeng, Q. Sun, S. Kumar, J. Ye, and S. Ji. 2015. Deep Model Based Transfer and Multi-Task Learning for Biological Image Analysis. In <em>      <em>Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>     </em>. 1475&#x2013;1484.</li>    <li id="BibPLXBIB0052" label="[52]">Z. Zhang, P. Luo, C.&#x00A0;C. Loy, and X. Tang. 2014. <em>      <em>Facial Landmark Detection by Deep Multi-task Learning</em>     </em>. 94&#x2013;108.</li>    <li id="BibPLXBIB0053" label="[53]">L. Zhao, Q. Sun, J. Ye, F. Chen, C.-T. Lu, and N. Ramakrishnan. 2015. Multi-Task Learning for Spatio-Temporal Event Forecasting. In <em>      <em>Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>     </em>. 1503&#x2013;1512.</li>    <li id="BibPLXBIB0054" label="[54]">J. Zhou, J. Liu, V.&#x00A0;A. Narayan, and J. Ye. 2012. Modeling Disease Progression via Fused Sparse Group Lasso. In <em>      <em>Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>     </em>. 1095&#x2013;1103.</li>    <li id="BibPLXBIB0055" label="[55]">B. Zou, V. Lampos, R. Gorton, and I.&#x00A0;J. Cox. 2016. On Infectious Intestinal Disease Surveillance using Social Media Content. In <em>      <em>Proceedings of the 6th International Conference on Digital Health</em>     </em>. 157&#x2013;161.</li>    <li id="BibPLXBIB0056" label="[56]">H. Zou and T. Hastie. 2005. Regularization and Variable Selection via the Elastic Net. <em>      <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>     </em>67, 2 (2005), 301&#x2013;320.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>Also with Department of Computer Science, University of Copenhagen, Denmark.</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a>Note that the number of samples <em>n</em> may be different for different locations (tasks).</p>   <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a>See <a class="link-inline force-break"    href="http://gis.cdc.gov/grasp/fluview/fluportaldashboard.html">gis.cdc.gov/grasp/fluview/fluportaldashboard.html</a>   </p>   <p id="fn4"><a href="#foot-fn4"><sup>3</sup></a><a class="link-inline force-break"    href="http://Google Correlate, google.com/trends/correlate">Google Correlate, google.com/trends/correlate</a>   </p>   <p id="fn5"><a href="#foot-fn5"><sup>4</sup></a>The embeddings were downloaded from <a class="link-inline force-break"    href="http://code.google.com/archive/p/word2vec">code.google.com/archive/p/word2vec</a>    <X>. </X>The specific training settings are detailed in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"    href="#BibPLXBIB0040">40</a>].</p>   <p id="fn6"><a href="#foot-fn6"><sup>5</sup></a>This resolves misleading similarity scores based on different sign combinations.</p>   <p id="fn7"><a href="#foot-fn7"><sup>6</sup></a>All candidate queries together with their similarity scores are listed at <a class="link-inline force-break"    href="http://github.com/binzou-ucl/google-flu-mtl">github.com/binzou-ucl/google-flu-mtl</a>    <X>. </X>   </p>   <p id="fn8"><a href="#foot-fn8"><sup>7</sup></a>For the experiments on England, two queries referring to medication available in the US are replaced by England-based equivalent medication (see Section&#x00A0;<a class="sec" href="#sec-13">3.4</a>).</p>   <p id="fn9"><a href="#foot-fn9"><sup>8</sup></a>A search session can be seen as a time window that may include more than one consecutive search queries from a user account. Therefore, a target search query is identified as a part of a potentially larger query set within a search session.</p>   <p id="fn10"><a href="#foot-fn10"><sup>9</sup></a>Numbers in the table represent the average performance across the 10 US regions and the 4 test periods. For additional clarity, all individual performance estimates (for <em>L</em> = 1) are enumerated at <a class="link-inline force-break"    href="http://github.com/binzou-ucl/google-flu-mtl">github.com/binzou-ucl/google-flu-mtl</a>    <X>. </X>   </p>   <p id="fn11"><a href="#foot-fn11"><sup>10</sup></a>We have also conducted experiments where sampling is temporally synchronized across regions, but we did not observe a significant difference in the performance outcomes. Due to space constraints, we only report the non-synchronized results.</p>   <p id="fn12"><a href="#foot-fn12"><sup>11</sup></a>Region 9 includes the states of California, Nevada and Arizona and one of the largest in terms of population (&#x2248; 49.1 million).</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 27 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186050">https://doi.org/10.1145/3178876.3186050</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
