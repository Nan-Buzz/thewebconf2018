<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>A Framework for Human-in-the-loop Monitoring of
  Concept-drift Detection in Event Log Stream</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">A Framework for Human-in-the-loop
          Monitoring of Concept-drift Detection in Event Log
          Stream</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Sylvio Barbon</span> <span class=
          "surName">Junior</span>, Londrina State University (UEL),
          Londrina, Brazil, <a href=
          "mailto:barbon@uel.br">barbon@uel.br</a>
        </div>
        <div class="author">
          <span class="givenName">Gabriel Marques</span>
          <span class="surName">Tavares</span>, Londrina State
          University (UEL), Londrina, Brazil, <a href=
          "mailto:gtavares@uel.br">gtavares@uel.br</a>
        </div>
        <div class="author">
          <span class="givenName">Victor G. Turrisi</span>
          <span class="surName">da Costa</span>, Londrina State
          University (UEL), Londrina, Brazil, <a href=
          "mailto:victorturrisi@uel.br">victorturrisi@uel.br</a>
        </div>
        <div class="author">
          <span class="givenName">Paolo</span> <span class=
          "surName">Ceravolo</span>, Università degli Studi di
          Milano (UNIMI), Crema, Italy, <a href=
          "mailto:paolo.ceravolo@unimi.it">paolo.ceravolo@unimi.it</a>
        </div>
        <div class="author">
          <span class="givenName">Ernesto</span> <span class=
          "surName">Damiani</span>, Khalifa University (KUST), Abu
          Dhabi, UAE, <a href=
          "mailto:ernesto.damiani@kustar.ac.ae">ernesto.damiani@kustar.ac.ae</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186343"
        target=
        "_blank">https://doi.org/10.1145/3184558.3186343</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>One of the main challenges of Cognitive Computing
        (CC) is reacting to evolving environments in near-real
        time. Therefore, it is expected that CC models provide
        solutions by examining a summary of past history, rather
        than using full historical data. This strategy has
        significant benefits in terms of response time and space
        complexity but poses new challenges in term of
        concept-drift detection, where both long term and short
        terms dynamics should be taken into account. In this paper,
        we introduce the Concept-Drift in Event Stream Framework
        (CDESF) that addresses some of these challenges for data
        streams recording the execution of a Web-based business
        process. Thanks to CDESF support for feature
        transformation, we perform density clustering in the
        transformed feature space of the process event stream,
        observe track concept-drift over time and identify
        anomalous cases in the form of outliers. We validate our
        approach using logs of an e-healthcare process.</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Process
          Mining</small>,</span> <span class=
          "keyword"><small>DBScan</small>,</span> <span class=
          "keyword"><small>Concept-drift</small>,</span>
          <span class="keyword"><small>Clustering</small>,</span>
          <span class="keyword"><small>Stream Mining</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Sylvio Barbon Junior, Gabriel Marques Tavares, Victor G.
          Turrisi da Costa, Paolo Ceravolo, and Ernesto Damiani.
          2018. A Framework for Human-in-the-loop Monitoring of
          Concept-drift Detection in Event Log Stream. In <em>WWW
          '18 Companion: The 2018 Web Conference Companion,</em>
          <em>April 23–27, 2018,</em> <em>Lyon, France. ACM, New
          York, NY, USA</em> 8 Pages. <a href=
          "https://doi.org/10.1145/3184558.3186343" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3186343</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-6">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Recent advances in Cognitive Computing (CC) envision
      systems that can reason with purpose and interact with the
      environment, going a step forward the quantitative and
      deterministic approach of traditional Machine Learning
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0016">16</a>]. A major
      challenge of CC is delivering autonomous reasoning and
      continuous learning toward rational comprehension and the
      natural interaction between humans and machines [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0024">24</a>]. Tackling
      this challenge requires handling uncertain knowledge and
      approximate solutions [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0030">30</a>], as well as being able to react to
      novel stimuli, avoiding abrupt degradation of performance
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0017">17</a>]. If this
      reaction has to be organized in real time, or near-real time,
      we enter in the domain of data stream processing, where
      results have to be continuously updated using incoming
      updates.</p>
      <p>A well-known problem affecting data streams is
      <em>concept-drift</em> where the underlying relations between
      a recorded tuple <span class="inline-equation"><span class=
      "tex">$\vec{x}$</span></span> and a system response
      <em>y</em> change over time [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0018">18</a>]. Ignoring concept-drift can lead to
      a deterioration in the quality of the algorithm and its
      capacity to represent the most recent concepts in data.
      Moreover, concept-drift is relevant to the validation process
      of any learning task because it recasts the ratio between
      observed data and response. Implementing a concept-drift
      adaptation strategy is not a trivial task as different types
      of concept-drift are possible and different adaptations can
      be operated in response to them [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0015">15</a>].</p>
      <p>In this paper, we argue that concept-drift may represent a
      key aspect to reinforce the cooperation between human and
      machines. Instead of creating an additional level of
      complexity that isolates the final user from the deep
      behavior of the system, concept-drift may offer a valid
      instrument to supervise its evolution and guide its
      validation via a human-in-the-loop process where the human
      observes the emergence of concept-drift over time and can
      address the system behavior by adjusting hyperparameters.</p>
      <p>In order to achieve this goal, a concept-drift detection
      procedure has to implement the following properties: (a) be
      generically applicable, i.e. taking as input the results of
      any algorithm that process data streams; (b) be monitorable,
      i.e. a human can monitor it using a synthetic human-readable
      representation and navigate through the evolution of the
      system over time.</p>
      <p>Along these lines, we introduce the Concept-Drift in Event
      Stream Framework (CDESF) to address concept-drift monitoring
      for a generic data stream processing algorithm. To make the
      system evolution understandable to the human user, CDESF
      encodes it using a three dimensional space whose axes are
      time and two metrics summarising the results of the analytics
      applied to incoming data. When orthogonal aspects are
      captured by the two selected metrics, the user obtains a wide
      coverage of the response offered by the algorithm. At the
      same time, when the probability distribution of responses
      changes, the user observes an evolution in the CDESF
      representation. Besides displaying the evolution, our CDESF
      acts as a controller on hyperparameters handling
      concept-drift detection; in particular, it can modify the
      probability distribution adopted to identify a
      concept-drift.</p>
      <p>To evaluate CDESF, we identified a concrete learning task
      and a reference literature to compare our results. We chose
      to address Process Mining (PM) [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0026">26</a>] because it imposes challenging
      constrain to event stream processing [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0006">6</a>] and because change
      detection is a widely addressed topic [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0002">2</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0008">8</a>].</p>
      <p>The remainder of the paper is organised as follows.
      Section <a class="sec" href="#sec-7">2</a> presents the
      overall framework proposed in this paper. This section also
      discusses some formal concepts of process mining, stream
      analysis, anomaly detection and trace clustering. In this
      section, stream clustering challenges are presented and
      together with some human-friendly insights obtained from the
      proposed framework. After that, Section <a class="sec" href=
      "#sec-15">3</a> describes the clustering algorithms used in
      the experiments. Section <a class="sec" href="#sec-16">4</a>
      presents the technologies involved in the implementation and
      evaluation of the framework. Finally, Section <a class="sec"
      href="#sec-19">5</a> concludes the paper and outlines our
      future work.</p>
    </section>
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Event Stream
          Framework</h2>
        </div>
      </header>
      <p>This section describes the workflow of the proposed
      framework, as well as, the technologies and techniques
      applied. In Figure&nbsp;<a class="fig" href="#fig1">1</a> it
      is possible to see an overview of CDESF.</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">Overview of Stream Process Mining
          Framework.</span>
        </div>
      </figure>
      <p></p>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span>
            Formalization</h3>
          </div>
        </header>
        <section id="sec-9">
          <p><em>2.1.1 Process Mining Essentials.</em> The learning
          task addressed in this work is PM. PM exploits event
          streams to run analytics on business processes. Unlike
          other stream-related problems, PM analysis cannot be
          approached with traditional stream mining techniques,
          since the single tuple imputing the learning procedure is
          obtained by grouping multiple events through time, with
          past events affecting future ones [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0005">5</a>]. In PM
          each event records the execution of some activity, which
          is a task or an action carried out by the user. Each
          event is also related to a single instance or execution,
          often called <em>case</em> [<a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0027">27</a>], which gathers the sequence of
          activities executed to achieve a specific result. A
          unique sequence of activities is called a <em>trace</em>;
          thus multiple cases can exhibit the same trace.</p>
          <p>Events can then be ordered based on their time of
          execution or grouped based on their activity type, or
          other attributes, such as the cost of execution of an
          activity, the originator (who started or supervised an
          execution), or the resources exploited during
          execution.</p>
        </section>
        <section id="sec-10">
          <p><em>2.1.2 Core Data Stream concepts.</em> In
          traditional machine learning, one has access to all
          available data, however, when dealing with data streams,
          this assumption cannot be made. In this scenario, data is
          usually made available through infinite streams in which
          underlying regularities of data may evolve during time
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0014">14</a>, <a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0018">18</a>]. A stream <em>S</em> is defined
          in the format <span class="inline-equation"><span class=
          "tex">$S = \lbrace i_1, i_2, i_3, ...,
          i_n\rbrace$</span></span> , where <em>i</em> corresponds
          to a pair <span class="inline-equation"><span class=
          "tex">$(\vec{x}, y)$</span></span> when the ground truth
          for that instance is known or simply <span class=
          "inline-equation"><span class=
          "tex">$\vec{x}$</span></span> when it is not, with
          <span class="inline-equation"><span class=
          "tex">$\vec{x}$</span></span> being the feature vector of
          that instance and <em>y</em> being its label, and
          <em>n</em> is possibly infinite.</p>
          <p>Since data processing is continuous and potentially
          infinite, it is not feasible to store all observed
          instances for future computations. Metrics and statistics
          have then been used to cope with single-time processing
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0011">11</a>, <a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0014">14</a>, <a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0019">19</a>]. Histograms, for example, can be
          computed in an online fashion, but the information they
          provide is no more than a summary of what the system
          observed.</p>
          <p>CDESF addresses data stream processing using an
          informed forgetting mechanism. Older cases are deleted at
          time horizons adjusted by a Nyquist rate [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0010">10</a>] that
          define the minimum number of instances required to
          properly update the system mode. The following subsection
          gives more details about our forgetting mechanism as a
          whole.</p>
        </section>
        <section id="sec-11">
          <p><em>2.1.3 Hyperparameters.</em> Since ingestion of
          event data is asynchronous, we cannot rely on our
          framework to start with an event data set. For this
          reason, inspired by the concept of Grace Period (GP)
          presented in [<a class="bib" data-trigger="hover"
          data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0011">11</a>], we introduced the idea of a
          period where data is collected to bootstrap it. It means
          that during the GP, there is no reference model and new
          events are used to feed the model construction. GP is a
          hyperparameter for our framework and different GP values
          impact in different modelling and following analysis. For
          example, if the GP is ten, the framework will render the
          stream until ten distinct cases are available. Then the
          GP is declared over, and the model creation is triggered.
          From this point on, each new event is processed, compared
          to the model and evaluated.</p>
          <p>Time horizon (TH) is a hyperparameter that specifies a
          time interval in seconds. We refer to the end of a TH as
          a checkpoint (CP). Thus, at CP the framework will
          reevaluate its number of cases used to update the
          histograms. The exact number of cases is calculated by
          the Nyquist sampling theorem, where the sampling
          frequency during data acquisition should be at least
          twice the highest frequency contained in the signal
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0020">20</a>]. Figure&nbsp;<a class="fig"
          href="#fig2">2</a> shows an example of histogram updating
          using a time horizon of 60 seconds.</p>
          <figure id="fig2">
            <img src=
            "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig2.jpg"
            class="img-responsive" alt="Figure 2" longdesc="" />
            <div class="figure-caption">
              <span class="figure-number">Figure 2:</span>
              <span class="figure-title">Histogram computation.
              After 11 events the histogram was updated, the memory
              adjusted to keep the last 10 cases and a checkpoint
              (CP).</span>
            </div>
          </figure>
          <p></p>
          <p>At each CP, the number of total cases is verified to
          check if there are no more cases than the maximum
          delimited by the Nyquist parameter. If there are more
          cases than Nyquist requires, the older cases are released
          from memory and a new Nyquist value is generated. The
          highest frequency in our method is the number of new
          cases that occurred during the last TH. If the new
          Nyquist is smaller than the initial GP number, then it is
          set to its initial value (which is the GP). A flag is
          raised because it would not be cohesive to create metrics
          with a lower number of cases than the GP. Thus, with a
          new set of cases, determined by the Nyquist theorem,
          metrics are updated. Equation <a class="eqn" href=
          "#eq1">1</a> shows our adaptation of the Nyquist
          frequency.</p>
          <div class="table-responsive" id="eq1">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} Nyquist\
              Frequency = number\_of\_new\_cases * 2
              \end{equation}</span><br />
              <span class="equation-number">(1)</span>
            </div>
          </div>
          <p></p>
        </section>
        <section id="sec-12">
          <p><em>2.1.4 Case analysis.</em> After the end of GP, a
          model is constructed with the goal of evaluating traces
          and pointing out the irregular and common ones. The
          metrics we adopted to control the system behavior are
          based on a histogram of traces and a histogram of
          timestamps. The histogram of traces counts the number of
          occurrences of each event throughout all cases of a
          specific process, giving us information about the
          recurrence of activities.</p>
          <p>When new events arrive, the corresponding case is
          retrieved, and its activity is added to the trace. The
          updated trace string is then compared to the histogram
          string. Since this is a string-to-string matching
          problem, we used the well-known Edit Distance algorithm
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0028">28</a>], which aims to compare two
          strings and quantify their dissimilarity. The standard
          edit distance algorithm allows three edit computations:
          changing one symbol of a string into another single one;
          deleting one symbol from a string; or inserting a single
          symbol into a string. Our string comparison does not
          depend on the order of the characters, so only two of the
          three edit operations (deletion and insertion) are
          relevant.</p>
          <p>After identifying events that are different in both
          strings (histogram and trace), a weighted value based on
          their histogram occurrence is calculated. The sum of the
          weighted distances is the final value of the trace
          comparison with the histogram.</p>
          <p>We named this new distance calculation as Edit
          Weighted Distance (EWD). EWD is a key notion in our
          approach and is considered (along with time analysis) a
          decisive descriptor of a case's behavior. An example
          follows to make this idea clearer.</p>
          <p>Given a set of traces <span class=
          "inline-equation"><span class="tex">$ L = \lbrace \langle
          a,b,c,d,e \rangle , \langle a,b,c\rangle , \langle
          a,d,c\rangle , \langle a,b\rangle \rbrace$</span></span>
          , a histogram <span class="inline-equation"><span class=
          "tex">$H$</span></span> is built from the events’
          frequencies in <span class="inline-equation"><span class=
          "tex">$L$</span></span> . Thus, <span class=
          "inline-equation"><span class="tex">$ H = \lbrace
          4,3,3,2,1\rbrace$</span></span> . The order of the
          histogram values follows the alphabetical order of the
          letters. Given a new trace <span class=
          "inline-equation"><span class="tex">$ T = \langle
          a,b,c\rangle$</span></span> , the EWD value is given by
          the weighted distance between the two strings. The
          different symbols between <span class=
          "inline-equation"><span class="tex">$H$</span></span> and
          <span class="inline-equation"><span class=
          "tex">$T$</span></span> are <span class=
          "inline-equation"><span class="tex">$\langle d,e
          \rangle$</span></span> . The weighted distance comes from
          the normalization (Equation <a class="eqn" href=
          "#eq2">2</a>) of <span class=
          "inline-equation"><span class="tex">$H$</span></span> ,
          which rescales the values into a range of <span class=
          "inline-equation"><span class="tex">$[0,1]$</span></span>
          ; so, in this case, <span class=
          "inline-equation"><span class="tex">$Hnorm = \lbrace
          1,0.75,0.75,0.5,0\rbrace$</span></span> . The EWD value
          is the sum of the correspondent <span class=
          "inline-equation"><span class="tex">$d$</span></span> and
          <span class="inline-equation"><span class=
          "tex">$e$</span></span> events, thus, EWD = 0.5.</p>
          <div class="table-responsive" id="eq2">
            <div class="display-equation">
              <span class="tex mytex">\begin{equation} Xnorm =
              \frac{X - Xmin}{Xmax - Xmin}
              \end{equation}</span><br />
              <span class="equation-number">(2)</span>
            </div>
          </div>
          <p></p>
          <p>In the case of an activity that is present in
          <span class="inline-equation"><span class=
          "tex">$T$</span></span> and not in <span class=
          "inline-equation"><span class="tex">$H$</span></span> ,
          its weighted value is determined as 0.5.</p>
          <p>The histogram of timestamps is built from the same
          group of cases used for the histogram of traces but with
          some additional steps. First, for each case, a list of
          the differences between the events timestamps is created.
          Then, the list serves as input for quartiles calculation.
          Quartiles are cutpoints dividing the range of a
          probability distribution with equal probabilities
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0013">13</a>]. Lastly, the list values are
          placed into the quartile bins. We explain our binning
          techniques with reference to Table <a class="tbl" href=
          "#tab1">1</a>, which represents several events from the
          same case.</p>
          <ul class="list-no-style">
            <li id="list1" label="•">The events timestamps are
            arranged in a list, i.e. [2012/12/14 19:52:39,
            2012/12/14 20:34:00, 2012/12/14 23:23:20, 2012/12/15
            01:42:51, 2012/12/15 07:28:00, 2012/12/15
            11:55:05];<br /></li>
            <li id="list2" label="•">The time difference between
            activities is calculated in seconds, resulting in [0,
            2481, 12641, 21012, 41721, 57746];<br /></li>
            <li id="list3" label="•">The quartiles are computed
            based on the time distance: [0, 5021, 16826.5,
            36543.75, 57746];<br /></li>
            <li id="list4" label="•">The time differences are
            binned, i.e. put into the quartiles bins by range.
            Example: 0 falls between [0, 5021], so it is placed in
            the first quartile. The same applies to 2481. Then,
            12641 is between [5021, 16826.5], so it belongs to the
            second quartile. This is done until the last value of
            the time differences;<br /></li>
            <li id="list5" label="•">The resulting bin is [2, 1, 1,
            2]. This means that the first quartile has two
            elements, the second has one and so on.<br /></li>
          </ul>
          <div class="table-responsive" id="tab1">
            <div class="table-caption">
              <span class="table-number">Table 1:</span>
              <span class="table-title">Log of events from the same
              case.</span>
            </div>
            <table class="table">
              <thead>
                <tr>
                  <th style="text-align:center;">Case ID</th>
                  <th style="text-align:center;">Activity</th>
                  <th style="text-align:center;">Complete
                  Timestamp</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="text-align:center;">Case 55</td>
                  <td style="text-align:center;">A</td>
                  <td style="text-align:center;">2012/12/14
                  19:52:39</td>
                </tr>
                <tr>
                  <td style="text-align:center;">Case 55</td>
                  <td style="text-align:center;">B</td>
                  <td style="text-align:center;">2012/12/14
                  20:34:00</td>
                </tr>
                <tr>
                  <td style="text-align:center;">Case 55</td>
                  <td style="text-align:center;">C</td>
                  <td style="text-align:center;">2012/12/14
                  23:23:20</td>
                </tr>
                <tr>
                  <td style="text-align:center;">Case 55</td>
                  <td style="text-align:center;">D</td>
                  <td style="text-align:center;">2012/12/15
                  01:42:51</td>
                </tr>
                <tr>
                  <td style="text-align:center;">Case 55</td>
                  <td style="text-align:center;">E</td>
                  <td style="text-align:center;">2012/12/15
                  07:28:00</td>
                </tr>
                <tr>
                  <td style="text-align:center;">Case 55</td>
                  <td style="text-align:center;">F</td>
                  <td style="text-align:center;">2012/12/15
                  11:55:05</td>
                </tr>
              </tbody>
            </table>
          </div>
          <p>The same steps described above are repeated for all
          cases. Finally, the histogram is created from the sum of
          the bins.</p>
          <p>Given a new event, its case timestamps are retrieved
          and binned. The bin is normalised and subtracted from the
          (also normalised) histogram of timestamps (both
          normalisations follow Equation <a class="eqn" href=
          "#eq2">2</a>). The result is the time-weighted distance
          (TWD) related to local time representation, which
          considers the interval between the activities of a case.
          On the other hand, the global time concerns to the last
          event of a given case. Thus, the local time is
          represented by a normalised distance from the histogram
          and the global time obey the real-event timestamp.</p>
          <p>In general terms, the weighted distances - EWD (trace)
          and TWD (local time) - and global time are parameters
          that describe the behavior of a given case projected in
          the feature space. These three features compose a
          triple:</p>
          <div class="table-responsive">
            <div class="display-equation">
              <span class="tex mytex">\[ \langle EWD, TWD, Time
              \rangle \]</span><br />
            </div>
          </div>summarising a given case.
          <p></p>
        </section>
        <section id="sec-13">
          <p><em>2.1.5 Concept-Drift and Anomaly Detection.</em>
          Concept-Drift and Anomaly detection are two connected
          tasks. An anomalous phenomenon is related to the absence
          or presence of patterns in the event log which may
          indicate fraudulent actions, security violation or a
          malfunction in the system [<a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0002">2</a>]. Frequently, a process anomaly
          related to a probing or attack, when detected early
          enough, can be halted or migrated to a honeypot
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0001">1</a>]. Available techniques for anomaly
          detection include techniques related to density-based
          [<a class="bib" data-trigger="hover" data-toggle=
          "popover" data-placement="top" href=
          "#BibPLXBIB0004">4</a>], nearest neighbours [<a class=
          "bib" data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0029">29</a>], and
          partition-based [<a class="bib" data-trigger="hover"
          data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0023">23</a>]. Outliers are detected in the
          case's feature space (EWD, TWD and time) by looking at
          distribution sparsity.</p>
          <p>Clustering is a popular technique for detecting
          anomalies [<a class="bib" data-trigger="hover"
          data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0025">25</a>]. When a new sample falls outside
          the boundary of any existing cluster, it is marked as an
          anomaly and its density is monitored. We remark that an
          increase in the number of samples within the radius of an
          anomalous one indicates a concept-drift. Our technique
          can be considered an implicit drift detector since it
          relies on the unlabelled cases’ feature values. Not
          needing labeled examples makes our technique useful in
          applications where labelling is expensive, time-consuming
          or not possible at all [<a class="bib" data-trigger=
          "hover" data-toggle="popover" data-placement="top" href=
          "#BibPLXBIB0025">25</a>].</p>
          <p>In Figure&nbsp;<a class="fig" href="#fig3">3</a>, five
          anomalous micro-clusters are highlighted in feature space
          based on trace distance, local time distance and global
          time. This snapshot was obtained after 3700 events and
          each point represents a case. The current event (the
          orange point) is <tt>CHANGE DIAGN</tt> from the web-based
          process <span class="inline-equation"><span class=
          "tex">$Hospital\_Billing$</span></span> which corresponds
          to someone using the application for modifying a
          patient's diagnosis. The micro-clusters correspond to
          unusual event sequences within the application log. In
          the next Section, we will discuss how to facilitate
          micro-cluster interpretation on the part of humans.</p>
          <figure id="fig3">
            <img src=
            "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig3.jpg"
            class="img-responsive" alt="Figure 3" longdesc="" />
            <div class="figure-caption">
              <span class="figure-number">Figure 3:</span>
              <span class="figure-title">Five anomalous
              micro-clusters highlighted from feature space based
              on trace distance (EWD), local time distance (TWD)
              and global time after 3700 events.</span>
            </div>
          </figure>
          <p></p>
        </section>
      </section>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span>
            Human-in-the-loop monitoring</h3>
          </div>
        </header>
        <p>Analysing logs at the granularity of an individual event
        might not always allow the perceptions of phenomena like
        anomalies [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0002">2</a>]. Moreover, the lack of
        interoperability related to context information certainly
        occurs from a direct event log stream analysis. We face the
        event granularity drawback aggregating the events as a
        trace and extracting from it only three features (EWD, TWD
        and time). EWD is computed directly from the trace, as wide
        explored in PM solutions [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0026">26</a>]. In [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0003">3</a>] the use of local (TWD) and global
        (time) features based on time were used in statistical
        hypothesis to discover concept-drifts and enrich the trace
        analysis. By these features, the CDESF can improve
        understanding and promote fact-based insights from the
        processes.</p>
        <p>A human analyst is interested in knowing whether there
        are any unusual patterns in the log [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0002">2</a>]. Specifically,
        clustering data relies on humans to become aware of a
        chance and explain its significance referring to
        topological structured groups of data. Even more, this
        would help when dealing with a massive amount of data where
        change is not easily noticeable due to the infrequent
        occurrence of anomalous events.</p>
        <p>Our technique transforms events stream into cases and
        reducing their information to three features, providing a
        clustering strategy of anomaly detection. Furthermore, the
        clustering stream provides continuous interactions between
        human and computer during the data processing. As we shall
        see, when dealing with three dimensions alone, it is
        possible to construct a human-friendly inference
        system.</p>
      </section>
    </section>
    <section id="sec-15">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Clustering
          Algorithms</h2>
        </div>
      </header>
      <p>There are two main types of clustering algorithms:
      partitioning and hierarchical. In the first one, the
      algorithm tries to group instances while trying to minimise a
      goal function, for example, to create the most homogeneous
      <em>k</em> clusters, with <em>k</em> being a hyperparameter.
      On the other hand, hierarchical algorithms build a top-down,
      or bottom-up, approach by starting with a single cluster with
      all instances and performing splits until each instance has
      its own cluster. Or the other way around, merging clusters
      until a single cluster exists. The choice of when to stop
      splitting is also a hyperparameter very difficult to
      determine [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href=
      "#BibPLXBIB0012">12</a>].</p>
      <p>Partitioning algorithms, for example K-means, are
      generally incapable of dealing with clusters with arbitrary
      shapes [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0009">9</a>].
      To deal with this, and to remove the need to choose a good
      <em>k</em> value according to domain knowledge, and outliers,
      we used the DBSCAN algorithm [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0012">12</a>].</p>
      <p>This algorithm works by starting with an arbitrary
      instance and expanding its cluster according to density-based
      metrics. Given two hyperparameters, <span class=
      "inline-equation"><span class="tex">$n\_min$</span></span>
      and ϵ, which corresponds to the minimum number of instances
      to build a cluster and the maximum density difference between
      two clusters when merging them, the algorithm expands regions
      until all instances are contained in a cluster or they are
      considered outliers and cannot be part of any group. Lastly,
      the average complexity of DBSCAN is <em>O</em>(<em>n</em> 
      <em>log</em>(<em>n</em>)), which fits with stream processing
      requirements. When using DBSCAN, one needs to optimise the ϵ
      value, since it is the most sensitive hyperparameter of the
      two. Let the distance between two sets of points S1 and S2 be
      equal to <em>min</em>{<em>dist</em>(<em>p</em>,
      <em>q</em>)∣<em>p</em> ∈ <em>S</em>1, <em>q</em> ∈
      <em>S</em>2}. Then, the two sets having at least the density
      of the least dense cluster in the database will be separated
      from each other only if the distance between the two sets is
      larger than ϵ [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0012">12</a>]. Since the density can be computed
      from unlabeled data only, it could be used as a substitute to
      explicitly labeled drift detection techniques, for monitoring
      changes [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href=
      "#BibPLXBIB0025">25</a>].</p>
    </section>
    <section id="sec-16">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Implementation
          and Evaluation</h2>
        </div>
      </header>
      <p>Our framework was implemented in Python (version 3). The
      source code and some demo event log are publicly available
      <a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>. For
      the DBSCAN algorithm, we used the Scikit Learn library
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0022">22</a>].</p>
      <p>The choice of data set was guided by a real-life
      healthcare scenario with a massive stream <a class="fn" href=
      "#fn2" id="foot-fn2"><sup>2</sup></a>. The event log is
      formed by events (<tt>NEW</tt>, <tt>CHANGE DIAGN</tt>,
      <tt>FIN</tt>, <tt>RELEASE</tt>, <tt>CODE OK</tt>, <tt>CODE
      NOK</tt>, <tt>STORNO</tt>, <tt>REJECT</tt>, <tt>REOPEN</tt>,
      <tt>DELETE</tt>, and <tt>BILLED</tt>) that are related to the
      billing of medical services. Each trace of the event log
      records the activities executed to bill a package of medical
      services that were bundled together [<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0021">21</a>]. The event log is
      composed of 451.359 anonymised events (activities) which
      comprehend more than 100,000 traces random sampled of process
      instances that were recorded throughout three years. The time
      between events within a trace has not been altered.</p>
      <p>We reported the results in the first month of hospital
      event log to make a concise exploration through comparing
      with [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0021">21</a>]
      results. There is a large number of events and cases per day
      to support TH hyperparameter exploration. TH variation
      translates into a more or less recurrent CPs, which
      influences the histogram update. There are few days with less
      than 10 cases, with the minimum of cases per day being 5.
      This particular day had seven events, which poses as the
      minimum of events per day. The most active day in terms of
      events had 139; the mean stands at 72 with a standard
      variation of 33. The trace length is also important. Even
      though the most extended trace is about nine events, most of
      the traces are way smaller, with a mean of 1.6 and a standard
      deviation of almost 0.8. Time lengths, on the other hand, are
      usually considerable. The longest case goes on for almost 26
      days, which is understandable when considering a hospital
      treatment. However, the mean time length is around 0.76 days
      with a standard variation of 3.12. There are several cases
      with only one event, so there is no time difference between
      the beginning and the end of the case.</p>
      <p>In Manhard et al. [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0021">21</a>] the same healthcare data set was
      explored using the Data-aware Heuristic Miner (DHM). DHM
      discovered a model (Figure <a class="fig" href="#fig4">4</a>)
      which fits 97% of the observed behavior in the the beginning
      of event log. This result emphasises two interesting aspects:
      the presence of anomalous processes and the challenging task
      to deal with the data set by a static approach. The authors
      made some assumptions about the behavior of specific
      activities supported by interviews with the hospital
      domain.</p>
      <figure id="fig4">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig4.jpg"
        class="img-responsive" alt="Figure 4" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 4:</span> <span class=
          "figure-title">Process model of DHM [<a class="bib"
          data-trigger="hover" data-toggle="popover"
          data-placement="top" href="#BibPLXBIB0021">21</a>] with
          97% of fitting.</span>
        </div>
      </figure>
      <p></p>
      <p>In order to evaluate our framework's performance,
      different time horizons (6 h, 12 h, 24 h, 48 h, and 96 h)
      were explored with <span class="inline-equation"><span class=
      "tex">$n\_min = 1$</span></span> and ϵ = 0.1 as
      hyperparameters of DBSCAN. It was possible to detect
      anomalies and concept-drifts in the first part of the stream
      as described in [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0021">21</a>]. The great part of anomalies was
      detected from 114 h to 240 h of processing stream, as Figure
      <a class="fig" href="#fig5">5</a> shows. The red line exposes
      a peak of anomalous cases in some TH values (12 h, 24 h, 48
      h, 96 h). TH value of 6 h differs from the other TH values in
      detecting anomalous cases since the two greatest amount of
      outliers were detected before 110 h and after 618 h. This
      occurs due to a horizon that undersampled the events
      necessary to support assumptions about this stream scenario.
      In other words, for this scenario, a time horizon superior to
      24 h fits well to anomaly detection. More about anomalous
      cases are explored in the Section&nbsp;<a class="sec" href=
      "#sec-17">4.1</a>.</p>
      <figure id="fig5">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig5.jpg"
        class="img-responsive" alt="Figure 5" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 5:</span> <span class=
          "figure-title">Flow analysis of thirty days of event log
          stream. Time Horizon (TH) of 24 h, 48 h and 96 h were
          capable to detect a concept-drift (highlighted by a black
          vertical line).</span>
        </div>
      </figure>
      <p></p>
      <p>In Figure <a class="fig" href="#fig5">5</a> it is also
      possible to observe the concept-drift phenomenon. The black
      vertical line in the figure points the identification of a
      drift, which could be automatically discovered by observing
      the time the number of outliers detected is below the number
      of clusters generated. This occurs once the cluster is
      updated from the recomputed histogram, and an outlier case
      converges to a common cluster. This convergence concerns a
      change in the global density of feature space with a cluster
      region expansion towards grouping an outlier case.
      Concept-drift, as anomalies, were better detected with higher
      time horizons. This concept changing is exposed with more
      details in Section&nbsp;<a class="sec" href=
      "#sec-18">4.2</a></p>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Anomaly
            detection results</h3>
          </div>
        </header>
        <p>A close look at the first two outliers detected
        exemplifies the CDESF anomalous cases detection over the
        stream. In the figures <a class="fig" href="#fig6">6</a>,
        <a class="fig" href="#fig7">7</a>, <a class="fig" href=
        "#fig8">8</a>, <a class="fig" href="#fig9">9</a>, <a class=
        "fig" href="#fig10">10</a> it is possible to see the
        different time horizons and the same anomalous cases: Case
        29 and 291 (<span class="inline-equation"><span class=
        "tex">$Hospital\_Billing$</span></span> ). In other words,
        the anomalies were recognised by ranging the TH
        hyperparameter from 6 h to 96 h and a suspicious behavior
        was discovered. In Table <a class="tbl" href="#tab2">2</a>
        it is possible to observe the details of trace and time
        histograms of CPs including the distances (EWD and TWD)
        from these anomalous cases. The cluster of common cases
        presented an average EWD and TWD of 0.39 and 0.55,
        respectively. As shown in Table <a class="tbl" href=
        "#tab2">2</a>, anomalous cases presented significantly
        superior values.</p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Case 29 and 291 identified as anomalous
            based on several time horizons.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">TH</th>
                <th style="text-align:center;">CP</th>
                <th style="text-align:center;">Trace
                Hist<sup>1</sup></th>
                <th colspan="2" style="text-align:center;">
                  Case 29
                  <hr />
                </th>
                <th colspan="2" style="text-align:center;">
                  Case 291
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;"></th>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">Trace</th>
                <th style="text-align:center;">EWD</th>
                <th style="text-align:center;">
                Trace<sup>2</sup></th>
                <th style="text-align:center;">EWD</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">6</td>
                <td style="text-align:center;">13</td>
                <td style="text-align:center;">
                [a:19,c:10,d:1,e:1]</td>
                <td style="text-align:center;">[a, d, e]</td>
                <td style="text-align:center;">2</td>
                <td style="text-align:center;">[a, b, d, e]</td>
                <td style="text-align:center;">1.5</td>
              </tr>
              <tr>
                <td style="text-align:center;">12</td>
                <td style="text-align:center;">7</td>
                <td style="text-align:center;">[a:20,c:5]</td>
                <td style="text-align:center;">[a, d, e]</td>
                <td style="text-align:center;">2</td>
                <td style="text-align:center;">[a, b, d, e]</td>
                <td style="text-align:center;">1</td>
              </tr>
              <tr>
                <td style="text-align:center;">24</td>
                <td style="text-align:center;">4</td>
                <td style="text-align:center;">
                [a:36,c:8,d:1,e:1]</td>
                <td style="text-align:center;">[a, d, e]</td>
                <td style="text-align:center;">1.2</td>
                <td style="text-align:center;">[a, b, d, e]</td>
                <td style="text-align:center;">1</td>
              </tr>
              <tr>
                <td style="text-align:center;">48</td>
                <td style="text-align:center;">2</td>
                <td style="text-align:center;">[a:10,c:2]</td>
                <td style="text-align:center;">[a, d, e]</td>
                <td style="text-align:center;">2</td>
                <td style="text-align:center;">[a, b, d, e]</td>
                <td style="text-align:center;">1.3</td>
              </tr>
              <tr>
                <td style="text-align:center;">96</td>
                <td style="text-align:center;">1</td>
                <td style="text-align:center;">[a:10,b:1,c:4]</td>
                <td style="text-align:center;">[a, d, e]</td>
                <td style="text-align:center;">1.3</td>
                <td style="text-align:center;">[a, b, d, e]</td>
                <td style="text-align:center;">1.4</td>
              </tr>
            </tbody>
            <thead>
              <tr>
                <th colspan="2" style="text-align:left;"></th>
                <th style="text-align:center;">Time Hist</th>
                <th style="text-align:center;">Time</th>
                <th style="text-align:center;">TWD</th>
                <th style="text-align:center;">Time</th>
                <th style="text-align:center;">TWD</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">6</td>
                <td style="text-align:center;">13</td>
                <td style="text-align:center;">[20, 0, 0, 11]</td>
                <td style="text-align:center;">[1, 0, 0, 1]</td>
                <td style="text-align:center;">0.61</td>
                <td style="text-align:center;">[1, 1, 0, 1]</td>
                <td style="text-align:center;">1.4</td>
              </tr>
              <tr>
                <td style="text-align:center;">12</td>
                <td style="text-align:center;">7</td>
                <td style="text-align:center;">[20, 0, 0, 5]</td>
                <td style="text-align:center;">[1, 0, 0, 1]</td>
                <td style="text-align:center;">0.8</td>
                <td style="text-align:center;">[1, 1, 0, 1]</td>
                <td style="text-align:center;">1.56</td>
              </tr>
              <tr>
                <td style="text-align:center;">24</td>
                <td style="text-align:center;">4</td>
                <td style="text-align:center;">[36, 1, 0, 9]</td>
                <td style="text-align:center;">[1, 0, 0, 1]</td>
                <td style="text-align:center;">0.8</td>
                <td style="text-align:center;">[1, 1, 0, 1]</td>
                <td style="text-align:center;">1.56</td>
              </tr>
              <tr>
                <td style="text-align:center;">48</td>
                <td style="text-align:center;">2</td>
                <td style="text-align:center;">[10, 0, 0, 2]</td>
                <td style="text-align:center;">[1, 0, 0, 1]</td>
                <td style="text-align:center;">0.8</td>
                <td style="text-align:center;">[1, 1, 0, 1]</td>
                <td style="text-align:center;">1.5</td>
              </tr>
              <tr>
                <td style="text-align:center;">96</td>
                <td style="text-align:center;">1</td>
                <td style="text-align:center;">[10, 0, 0, 5]</td>
                <td style="text-align:center;">[1, 1, 0, 1]</td>
                <td style="text-align:center;">1.5</td>
                <td style="text-align:center;">[1, 1, 0, 1]</td>
                <td style="text-align:center;">1.5</td>
              </tr>
              <tr>
                <td colspan="7" style="text-align:center;">
                  <sup>1</sup>Conversion of activity names and
                  letters: ’NEW’: ’a’, ’DELETE’: ’b’, ’CHANGE
                  DIAGN’: ’c’, ’FIN’: ’d’, ’RELEASE’: ’e’, ’CODE
                  OK’: ’f’
                  <hr />
                </td>
              </tr>
              <tr>
                <td colspan="7" style="text-align:center;">
                  <sup>2</sup>The trace sequence acquired was a, d,
                  e, and b
                  <hr />
                </td>
              </tr>
            </tbody>
          </table>
        </div>
        <figure id="fig6">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig6.jpg"
          class="img-responsive" alt="Figure 6" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 6:</span>
            <span class="figure-title">Snapshot obtained using 6
            hours as TH, cases 29 and 291 detected as
            anomalies.</span>
          </div>
        </figure>
        <figure id="fig7">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig7.jpg"
          class="img-responsive" alt="Figure 7" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 7:</span>
            <span class="figure-title">Snapshot obtained using 12
            hours as TH, cases 29 and 291 detected as
            anomalies.</span>
          </div>
        </figure>
        <figure id="fig8">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig8.jpg"
          class="img-responsive" alt="Figure 8" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 8:</span>
            <span class="figure-title">Snapshot obtained using 24
            hours as TH, cases 29 and 291 detected as
            anomalies.</span>
          </div>
        </figure>
        <p>An important consideration about Case 29 is related to
        its recent activity when compared to Case 291. Case 29 is
        positioned in the top of the snapshots, independent of TH,
        due to its last related event being more recent to the Case
        291. This can support the indication of suspicious time
        spent in Case 29. However, Case 291 presented a higher TWD
        than other detected anomalies, emphasising a more uncommon
        behavior. It is worth noting that Case 291 trace sequence
        was a, d, e and b. However, our approach does not rely on
        the sequence, and the histogram would have been the same
        with other permutations of the same group of activities.
        Also, old cases are released from memory between CPs using
        the Nyquist rate.</p>
        <figure id="fig9">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig9.jpg"
          class="img-responsive" alt="Figure 9" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 9:</span>
            <span class="figure-title">Snapshot obtained using 48
            hours as TH, cases 29 and 291 detected as
            anomalies.</span>
          </div>
        </figure>
        <figure id="fig10">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig10.jpg"
          class="img-responsive" alt="Figure 10" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 10:</span>
            <span class="figure-title">Snapshot obtained using 96
            hours as TH, cases 29 and 291 detected as
            anomalies.</span>
          </div>
        </figure>
        <p></p>
        <p>The authors in [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0021">21</a>] presented some important diagnosis
        about the cases. Deleted cases should not be in the closed
        status, whereas reopened cases with a change in diagnosis
        can be eventually closed in the future. Case 29 runs all
        activities (<tt>NEW</tt>, <tt>FIN</tt>, <tt>RELEASE</tt>,
        <tt>CODE OK</tt> and <tt>BILLED</tt>), but spends a long
        time to reach the last activity. Case 291 clearly
        represents an anomaly, since it did not follow the common
        <span class="inline-equation"><span class=
        "tex">$Hospital\_Billing$</span></span> process, running
        <tt>NEW</tt>, <tt>FIN</tt>, <tt>RELEASE</tt> and
        <tt>DELETE</tt>.</p>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span>
            Concept-drift issues</h3>
          </div>
        </header>
        <p>It was possible to detect the same concept-drift by
        three different time horizons. As possible to observe in
        Figure&nbsp;<a class="fig" href="#fig5">5</a>, the
        checkpoints 3 (96 h), 6 (48 h) and 13 (24 h) exposed a CD
        phenomenon in the stream. This CD was capable of changing
        several outliers with TH = 24 h (cases 71, 294 and 308) and
        with TH = 48 h (cases 29, 71, 101, 155 and 525) to be faced
        as common cases. The Case 71 is an example, it was
        identified as an outlier until histogram updating (CP=12
        for TH=24 and CP=5 for TH=48) and after clusterized as a
        common case, as Figures <a class="fig" href="#fig11">11</a>
        and <a class="fig" href="#fig12">12</a> show.</p>
        <figure id="fig11">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig11.jpg"
          class="img-responsive" alt="Figure 11" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 11:</span>
            <span class="figure-title">Concept-drift with time
            horizon of 24 hours.</span>
          </div>
        </figure>
        <p></p>
        <p>This fact occurs due to the adaption of the histogram by
        new cases similar to the former outlier towards discovering
        its pattern as a common one. The time horizon influences
        directly the anomaly detection since a rather wide horizon
        carries on several anomalous cases ending with aggregating
        them as a common cluster. On the other hand, a narrow limit
        increases the number of false positive cases.</p>
        <p>As Figure <a class="fig" href="#fig11">11</a> shows,
        Case 71 changed from an anomalous to common behavior
        between CP 12 and 13 with a TH = 24 h. Table <a class="tbl"
        href="#tab3">3</a> exposes this change. The EWD value went
        from 1.04 to 0.04. This is a clear picture of a
        concept-drift. That is, the case's behavior was far from
        the other cases, however more cases that mimic Case 71
        nature appeared between those CPs, and that influenced the
        histogram update, which made Case 71 come to the common
        group. The same phenomenon happened with a TH of 48 hours
        (Figure <a class="fig" href="#fig12">12</a>), but both EWD
        and TWD values were maintained. This is explained by the
        fact that a group of cases with similar nature appeared
        between the CPs, but they were not significant enough to
        change the histogram density completely. However, the group
        as a whole characterizes new behavior in the stream, which
        put them as common cases. The contrasting example is Case
        291, which presented as an anomaly that kept is pattern
        after a concept-drift in several experimented time
        horizons.</p>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class=
            "table-title">Concept-drift and cases 71 and
            291.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">TH</th>
                <th style="text-align:center;">CP</th>
                <th style="text-align:center;">Trace
                Hist<sup>1</sup></th>
                <th colspan="2" style="text-align:center;">
                  Case 71
                  <hr />
                </th>
                <th colspan="2" style="text-align:center;">
                  Case 291
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;"></th>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">Trace</th>
                <th style="text-align:center;">EWD</th>
                <th style="text-align:center;">
                Trace<sup>2</sup></th>
                <th style="text-align:center;">EWD</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">24</td>
                <td style="text-align:center;">12</td>
                <td style="text-align:center;">
                [a:81,b:3,c:39,d:5,e:4,f:1]</td>
                <td style="text-align:center;">[a, c]</td>
                <td style="text-align:center;">1.04</td>
                <td style="text-align:center;">[a, b, d, e]</td>
                <td style="text-align:center;">1.9</td>
              </tr>
              <tr>
                <td style="text-align:center;">24</td>
                <td style="text-align:center;">13</td>
                <td style="text-align:center;">
                [a:94,b:3,c:53,d:1,e:1,f:2]</td>
                <td style="text-align:center;">[a, c]</td>
                <td style="text-align:center;">0.04</td>
                <td style="text-align:center;">[a, b, d, e]</td>
                <td style="text-align:center;">0.8</td>
              </tr>
              <tr>
                <td style="text-align:center;">48</td>
                <td style="text-align:center;">5</td>
                <td style="text-align:center;">
                [a:106,b:1,c:48,d:5,e:3]</td>
                <td style="text-align:center;">[a, c]</td>
                <td style="text-align:center;">1.05</td>
                <td style="text-align:center;">[a, b, d, e]</td>
                <td style="text-align:center;">1.5</td>
              </tr>
              <tr>
                <td style="text-align:center;">48</td>
                <td style="text-align:center;">6</td>
                <td style="text-align:center;">
                [a:133,b:4,c:63,d:7,e:5,f:1]</td>
                <td style="text-align:center;">[a, c]</td>
                <td style="text-align:center;">1.05</td>
                <td style="text-align:center;">[a, b, d, e]</td>
                <td style="text-align:center;">0.6</td>
              </tr>
            </tbody>
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">Time Hist</th>
                <th style="text-align:center;">Time</th>
                <th style="text-align:center;">TWD</th>
                <th style="text-align:center;">Time</th>
                <th style="text-align:center;">TWD</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">24</td>
                <td style="text-align:center;">12</td>
                <td style="text-align:center;">[85, 6, 1, 41]</td>
                <td style="text-align:center;">[1, 0, 0, 0]</td>
                <td style="text-align:center;">0.5</td>
                <td style="text-align:center;">[1, 0, 0, 0]</td>
                <td style="text-align:center;">0.4</td>
              </tr>
              <tr>
                <td style="text-align:center;">24</td>
                <td style="text-align:center;">13</td>
                <td style="text-align:center;">[99, 4, 0, 51]</td>
                <td style="text-align:center;">[1, 0, 0, 0]</td>
                <td style="text-align:center;">0.5</td>
                <td style="text-align:center;">[1, 0, 0, 0]</td>
                <td style="text-align:center;">1.4</td>
              </tr>
              <tr>
                <td style="text-align:center;">48</td>
                <td style="text-align:center;">5</td>
                <td style="text-align:center;">[108, 4, 0, 51]</td>
                <td style="text-align:center;">[1, 0, 0, 0]</td>
                <td style="text-align:center;">0.5</td>
                <td style="text-align:center;">[1, 0, 0, 0]</td>
                <td style="text-align:center;">0.2</td>
              </tr>
              <tr>
                <td style="text-align:center;">48</td>
                <td style="text-align:center;">6</td>
                <td style="text-align:center;">[137, 7, 1, 68]</td>
                <td style="text-align:center;">[1, 0, 0, 0]</td>
                <td style="text-align:center;">0.5</td>
                <td style="text-align:center;">[1, 0, 0, 0]</td>
                <td style="text-align:center;">1.4</td>
              </tr>
              <tr>
                <td colspan="7" style="text-align:center;">
                  <sup>1</sup>Conversion of activity names and
                  letters: ’NEW’: ’a’, ’DELETE’: ’b’, ’CHANGE
                  DIAGN’: ’c’, ’FIN’: ’d’, ’RELEASE’: ’e’, ’CODE
                  OK’: ’f’
                  <hr />
                </td>
              </tr>
              <tr>
                <td colspan="7" style="text-align:center;">
                  <sup>2</sup>The trace sequence acquired was a, d,
                  e and b
                  <hr />
                </td>
              </tr>
            </tbody>
          </table>
        </div>
        <figure id="fig12">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186343/images/www18companion-105-fig12.jpg"
          class="img-responsive" alt="Figure 12" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 12:</span>
            <span class="figure-title">Concept-drift with time
            horizon of 48 hours.</span>
          </div>
        </figure>
        <p>TH selection is dependent on the problem and stream
        evaluated. In the case of the hospital stream, best results
        were obtained by a TH with at least 24 hours. As Figure
        <a class="fig" href="#fig5">5</a> shows, time horizon of 6
        and 12 hours are not able to detect concept-drifts, this is
        due to the lower CP time, and the consequence is a biased
        adaptation. Most business processes require a quite large
        time of observation. Thus, with a larger window (horizon),
        CDDSF can better understand the standard behavior, detect
        anomalies and fit itself over time.</p>
        <p>It is important to highlight that CDDSF could deal with
        incomplete traces through the proposed feature space, where
        the traces that did not reach the final common activity are
        grouped in the same cluster. These aspects support our
        purpose of a reacting system, where a case on the fly (even
        incomplete) could be distinguished. Furthermore, a running
        process case could be followed closely when presenting an
        anomalous pattern since the first activities.</p>
      </section>
    </section>
    <section id="sec-19">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Conclusion</h2>
        </div>
      </header>
      <p>In this paper, we have addressed the problem of reacting
      to evolving environments in near-real time. For this purpose,
      we have developed a new framework to identify anomalies and
      concept-drift through a given time horizon desired by the
      specialist. In order to validate our approach, we have
      carried out various experiments using a real-life healthcare
      stream data set.</p>
      <p>We have noticed the ability of our framework to
      effectively detect the anomalies and drift detection over the
      stream with different user time horizons. Even more, an
      unfinished process case could be observed closely from the
      beginning leading to early identification of anomalous
      patterns. This way, it is possible to mitigate a costly
      error, resist an attack before it reaches its goal, halt or
      migrate the fraudulent execution to a honeypot.</p>
      <p>For future work, we aim at developing our framework toward
      handling complex concept-drift by monitoring unsupervised
      indicators, in order to detect change earlier. This can be of
      interest for many real-world applications where some drift
      phenomena need to be prematurely identified.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="sec-20">
      <header>
        <div class="title-info">
          <h2>ACKNOWLEDGMENTS</h2>
        </div>
      </header>
      <p>The authors would like to thank the Information and
      Communication Technology (ICT) Fund. ABU DHABI for the
      financial support for this research.</p>
    </section>
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Kristof Böhmer and
        Stefanie Rinderle-Ma. 2016. Automatic signature generation
        for anomaly detection in business process instance data. In
        <em><em>International Workshop on Business Process
        Modeling, Development and Support</em></em> . Springer,
        196–211.</li>
        <li id="BibPLXBIB0002" label="[2]">
        RP&nbsp;Jagadeesh&nbsp;Chandra Bose and Wil&nbsp;MP
        van&nbsp;der Aalst. 2010. Trace Alignment in Process
        Mining: Opportunities for Process Diagnostics.. In
        <em><em>BPM</em></em> , Vol.&nbsp;6336. Springer,
        227–242.</li>
        <li id="BibPLXBIB0003" label="[3]">
        RP&nbsp;Jagadeesh&nbsp;Chandra Bose, Wil&nbsp;MP
        van&nbsp;der Aalst, Indrė Žliobaitė, and Mykola
        Pechenizkiy. 2011. Handling concept drift in process
        mining. In <em><em>International Conference on Advanced
        Information Systems Engineering</em></em> . Springer,
        391–405.</li>
        <li id="BibPLXBIB0004" label="[4]">Markus Breunig,
        Hans-Peter Kriegel, Raymond Ng, and Jörg Sander. 1999.
        Optics-of: Identifying local outliers. <em><em>Principles
        of data mining and knowledge discovery</em></em> (1999),
        262–270.</li>
        <li id="BibPLXBIB0005" label="[5]">Andrea Burattin, Marta
        Cimitile, Fabrizio&nbsp;M Maggi, and Alessandro Sperduti.
        2015. Online discovery of declarative process models from
        event streams. <em><em>IEEE Transactions on Services
        Computing</em></em> 8, 6 (2015), 833–846.</li>
        <li id="BibPLXBIB0006" label="[6]">Andrea Burattin,
        Alessandro Sperduti, and Wil&nbsp;MP van&nbsp;der Aalst.
        2014. Control-flow discovery from event streams. In
        <em><em>Evolutionary Computation (CEC), 2014 IEEE Congress
        on</em></em> . IEEE, 2420–2427.</li>
        <li id="BibPLXBIB0007" label="[7]">Paolo Ceravolo, Ernesto
        Damiani, Mohammadsadegh Torabi, and Sylvio Barbon. 2017.
        Toward a New Generation of Log Pre-processing Methods for
        Process Mining. In <em><em>International Conference on
        Business Process Management</em></em> . Springer,
        55–70.</li>
        <li id="BibPLXBIB0008" label="[8]">Paolo Ceravolo, Ernesto
        Damiani, and Marco Viviani. 2005. Adding a peer-to-peer
        trust layer to metadata generators. In <em><em>OTM
        Confederated International Conferences” On the Move to
        Meaningful Internet Systems”</em></em> . Springer,
        809–815.</li>
        <li id="BibPLXBIB0009" label="[9]">Yixin Chen and Li Tu.
        2007. Density-based clustering for real-time stream data.
        <em><em>Proceedings of the 13th ACM SIGKDD international
        conference on Knowledge discovery and data mining KDD
        07</em></em> d (2007), 133. <a class=
        "link-inline force-break" href=
        "https://doi.org/10.1145/1281192.1281210" target="_blank">
          https://doi.org/10.1145/1281192.1281210</a>
        </li>
        <li id="BibPLXBIB0010" label="[10]">RA DeCarlo, J Murray,
        and R Saeks. 1977. Multivariable nyquist theory.
        <em><em>Internat. J. Control</em></em> 25, 5 (1977),
        657–675.</li>
        <li id="BibPLXBIB0011" label="[11]">Pedro Domingos and
        Geoff Hulten. 2000. Mining high-speed data streams.
        <em><em>Proceedings of the sixth ACM SIGKDD international
        conference on Knowledge discovery and data mining</em></em>
        (2000), 71–80. <a class="link-inline force-break" href=
        "https://doi.org/10.1145/347090.347107" target=
        "_blank">https://doi.org/10.1145/347090.347107</a>
        </li>
        <li id="BibPLXBIB0012" label="[12]">Martin Ester,
        Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. A
        Density-based Algorithm for Discovering Clusters a
        Density-based Algorithm for Discovering Clusters in Large
        Spatial Databases with Noise. In <em><em>Proceedings of the
        Second International Conference on Knowledge Discovery and
        Data Mining</em></em> (<em>KDD’96</em>). AAAI Press,
        226–231.</li>
        <li id="BibPLXBIB0013" label="[13]">Michael Frigge,
        David&nbsp;C Hoaglin, and Boris Iglewicz. 1989. Some
        implementations of the boxplot. <em><em>The American
        Statistician</em></em> 43, 1 (1989), 50–54.</li>
        <li id="BibPLXBIB0014" label="[14]">João Gama,
        Pedro&nbsp;Pereira Rodrigues, Eduardo Spinosa, and Andre
        Carvalho. 2010. Knowledge Discovery from Data Streams. <em>
          <em>Web Intelligence and Security - Advances in Data and
          Text Mining Techniques for Detecting and Preventing
          Terrorist Activities on the Web</em></em> (2010),
          125–138. <a class="link-inline force-break" href=
          "https://doi.org/10.3233/978-1-60750-611-9-125" target=
          "_blank">https://doi.org/10.3233/978-1-60750-611-9-125</a>
        </li>
        <li id="BibPLXBIB0015" label="[15]">João Gama, Indrė
        Žliobaitė, Albert Bifet, Mykola Pechenizkiy, and Abdelhamid
        Bouchachia. 2014. A survey on concept drift adaptation.
        <em><em>ACM Computing Surveys (CSUR)</em></em> 46, 4
        (2014), 44.</li>
        <li id="BibPLXBIB0016" label="[16]">Xiaoxi Huang, Huaxin
        Huang, Beishui Liao, and Cihua Xu. 2013. An ontology-based
        approach to metaphor cognitive computation. <em><em>Minds
        and Machines</em></em> 23, 1 (2013), 105–121.</li>
        <li id="BibPLXBIB0017" label="[17]">Imen Khamassi, Moamar
        Sayed-Mouchaweh, Moez Hammami, and Khaled Ghédira. 2015.
        Self-adaptive windowing approach for handling complex
        concept drift. <em><em>Cognitive Computation</em></em> 7, 6
        (2015), 772–790.</li>
        <li id="BibPLXBIB0018" label="[18]">B Krawczyk, LL Minku, J
        Gama, and J Stefanowski. 2017. Ensemble learning for data
        stream analysis: A survey. <em><em>Information</em></em>
        (2017), 1–86.</li>
        <li id="BibPLXBIB0019" label="[19]">Bartosz Krawczyk,
        Leandro&nbsp;L Minku, João Gama, Jerzy Stefanowski, and
        Michał Woźniak. 2017. Ensemble learning for data stream
        analysis: a survey. <em><em>Information Fusion</em></em>
        37(2017), 132–156.</li>
        <li id="BibPLXBIB0020" label="[20]">Luc Lévesque. 2014.
        Nyquist sampling theorem: understanding the illusion of a
        spinning wheel captured with a video camera.
        <em><em>Physics Education</em></em> 49, 6 (2014), 697–705.
        <a class="link-inline force-break" href=
        "https://doi.org/10.1088/0031-9120/49/6/697" target=
        "_blank">https://doi.org/10.1088/0031-9120/49/6/697</a>
        </li>
        <li id="BibPLXBIB0021" label="[21]">Felix Mannhardt,
        Massimiliano de Leoni, Hajo&nbsp;A Reijers, and Wil&nbsp;MP
        van&nbsp;der Aalst. 2017. Data-Driven Process
        Discovery-Revealing Conditional Infrequent Behavior from
        Event Logs. In <em><em>International Conference on Advanced
        Information Systems Engineering</em></em> . Springer,
        545–560.</li>
        <li id="BibPLXBIB0022" label="[22]">F. Pedregosa, G.
        Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,
        M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J.
        Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M.
        Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine
        Learning in Python. <em><em>Journal of Machine Learning
        Research</em></em> 12 (2011), 2825–2830.</li>
        <li id="BibPLXBIB0023" label="[23]">Sridhar Ramaswamy,
        Rajeev Rastogi, and Kyuseok Shim. 2000. Efficient
        algorithms for mining outliers from large data sets. In
        <em><em>ACM Sigmod Record</em></em> , Vol.&nbsp;29. ACM,
        427–438.</li>
        <li id="BibPLXBIB0024" label="[24]">Maximilian Röglinger,
        Johannes Seyfried, Simon Stelzl, and Michael zur Muehlen.
        2017. Cognitive Computing: What's in for Business Process
        Management? An Exploration of Use Case Ideas. (2017).</li>
        <li id="BibPLXBIB0025" label="[25]">Tegjyot&nbsp;Singh
        Sethi and Mehmed Kantardzic. 2017. On the reliable
        detection of concept drift from streaming unlabeled data.
        <em><em>Expert Systems with Applications</em></em> 82
        (2017), 77–99.</li>
        <li id="BibPLXBIB0026" label="[26]">Wil&nbsp;MP
        van&nbsp;der Aalst. 2016. <em><em>Process mining: data
        science in action</em></em> . Springer.</li>
        <li id="BibPLXBIB0027" label="[27]">Wil M.&nbsp;P.
        van&nbsp;der Aalst. 2011. <em><em>Process Mining:
        Discovery, Conformance and Enhancement of Business
        Processes</em> (1st ed.)</em>. Springer Publishing Company,
        Incorporated.</li>
        <li id="BibPLXBIB0028" label="[28]">Robert&nbsp;A. Wagner
        and Michael&nbsp;J. Fischer. 1974. The String-to-String
        Correction Problem. <em><em>J. ACM</em></em> 21, 1 (Jan.
        1974), 168–173. <a class="link-inline force-break" href=
        "https://doi.org/10.1145/321796.321811" target=
        "_blank">https://doi.org/10.1145/321796.321811</a>
        </li>
        <li id="BibPLXBIB0029" label="[29]">Mingxi Wu and
        Christopher Jermaine. 2006. Outlier detection by sampling
        with accuracy guarantees. In <em><em>Proceedings of the
        12th ACM SIGKDD international conference on Knowledge
        discovery and data mining</em></em> . ACM, 767–772.</li>
        <li id="BibPLXBIB0030" label="[30]">Yingxiu Zhao, Jinhai
        Li, Wenqi Liu, and Weihua Xu. 2017. Cognitive concept
        learning from incomplete information. <em><em>International
        Journal of Machine Learning and Cybernetics</em></em> 8,
        1(2017), 159–170.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a href=
    "https://github.com/gbrltv/CDESF" target=
    "_blank">https://github.com/gbrltv/CDESF</a></p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a href=
    "https://data.4tu.nl/repository/uuid:76c46b83-c930-4798-a1c9-4be94dfeb741"
    target=
    "_blank">https://data.4tu.nl/repository/uuid:76c46b83-c930-4798-a1c9-4be94dfeb741</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3186343">https://doi.org/10.1145/3184558.3186343</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
