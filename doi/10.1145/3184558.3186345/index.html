<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>PersuAIDE ! An Adaptive Persuasive Text Generation System for Fashion Domain</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3186345'>https://doi.org/10.1145/3184558.3186345</a> 
 Published in WWW2018 Proceedings Â© 2018 International World Wide Web Conference Committee, published under 
 <a rel='license' property='license' href='https://creativecommons.org/licenses/by/4.0/'>
 Creative Commons CC By 4.0 License</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3186345'>https://w3id.org/oa/10.1145/3184558.3186345</a>
</p></div>
<hr>

  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">PersuAIDE ! An Adaptive Persuasive Text Generation System for Fashion Domain</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Vitobha</span>      <span class="surName">Munigala</span>     IBM Research, <a href="mailto:vmunigal@in.ibm.com">vmunigal@in.ibm.com</a>     </div>     <div class="author">     <span class="givenName">Abhijit</span>      <span class="surName">Mishra</span>     IBM Research, <a href="mailto:abhijimi@in.ibm.com">abhijimi@in.ibm.com</a>     </div>     <div class="author">     <span class="givenName">Srikanth G</span>      <span class="surName">Tamilselvam</span>     IBM Research, <a href="mailto:srikanth.tamilselvam@in.ibm.com">srikanth.tamilselvam@in.ibm.com</a>     </div>     <div class="author">     <span class="givenName">Shreya</span>      <span class="surName">Khare</span>     IBM Research, <a href="mailto:skhare34@in.ibm.com">skhare34@in.ibm.com</a>     </div>     <div class="author">     <span class="givenName">Riddhiman</span>      <span class="surName">Dasgupta</span>     IBM Research, <a href="mailto:riddasgu@in.ibm.com">riddasgu@in.ibm.com</a>     </div>     <div class="author">     <span class="givenName">Anush</span>      <span class="surName">Sankaran</span>     IBM Research, <a href="mailto:anussank@in.ibm.com">anussank@in.ibm.com</a>     </div>                             </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3186345" target="_blank">https://doi.org/10.1145/3184558.3186345</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Persuasiveness is a creative art which aims at inducing certain set of beliefs in the target audience. In an e-commerce setting, for a newly launched product, persuasive descriptions are often composed to motivate an online buyer towards a successful purchase. Such descriptions can be catchy taglines, product-summaries, style-tips <em>etc.</em>. In this paper, we present <em>PersuAIDE!</em> - a persuasive system based on linguistic creativity to generate various forms of persuasive sentences from the input product specification. To demonstrate the effectiveness of the proposed system, we have applied the technology to fashion domain, where, for a given fashion product like <em>&#x201D;red collar shirt&#x201D;</em> we were able to generate descriptive sentences that not only explain the item but also garner positive attention, making it persuasive.</small>     </p>     <p>     <small>      <em>PersuAIDE!</em> identifies fashion related keywords from input specifications and intelligently expands the keywords to creative phrases. Once such compatible phrases are obtained, persuasive descriptions are synthesized from the set of phrases and input keywords with the help of a neural language model trained on a large domain-specific fashion corpus. We evaluate the system on a large fashion corpus collected from different sources using (a) automatic text generation metrics used for Machine Translation and Automatic Summarization evaluation and Readability measurement, and (b) human judgment scores evaluating the persuasiveness and fluency of the generated text. Experimental results and qualitative analysis show that an unsupervised system like ours can produce more creative and better constructed persuasive output than supervised generative counterparts based on neural sequence-to-sequence models and statistical machine translation.</small>     </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Persuasiveness</small>, </span>     <span class="keyword">      <small> Persuasive Systems</small>, </span>     <span class="keyword">      <small> Persuasion in Fashion</small>, </span>     <span class="keyword">      <small> Style-tip Generation</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Vitobha Munigala, Abhijit Mishra, Srikanth G Tamilselvam, Shreya Khare, Riddhiman Dasgupta, and Anush Sankaran. 2018. PersuAIDE ! An Adaptive Persuasive Text Generation System for Fashion Domain. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 8 Pages. <a href="https://doi.org/10.1145/3184558.3186345" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3186345</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>One of the major drawbacks of the current <em>Weak AI</em> based language generation systems is the inability to generate language in the same manner, expressing similar levels of creativity, originality and brevity as humans. To produce language generators that are more humanly (otherwise known as Strong AI systems [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>]), one has to demonstrate the capabilities of such systems towards performing generation tasks that demand extreme cognitive capabilities. In this paper, we proceed in such a direction, with the aim of empowering natural language generation systems with the ability to be <em>persuasive</em>. Persuasiveness, which is an extremely creative and cogitative art, often intends to infuse cognitive change in the mental state of target audience. Persuasive systems have utilities in multitude of scenarios - dynamic advertisement, preventive medicine, social action, and edutainment to name a few, as mentioned in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>].</p>    <p>We present <em>PersuAIDE!</em> - a persuasive system that brings in linguistic creativity to transform given specification (a list of key-words) to various forms of persuasive descriptions; the descriptions are typically one sentence long. To demonstrate the effectiveness, we apply the technology to fashion domain, where, for given keywords of a fashion item like <em>Levis white round neck t-shirt</em>, the system generates descriptive sentences that not only explains the item but also garners positive attention, making it persuasive (e.g.,&#x201C;<em>Accentuate an easy-going summer look with white round neck t-shirt</em><a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>&#x201D;). Our system can be quite useful especially in an fashion e-commerce setup, as illustrated in Figure <a class="fig" href="#fig1">1</a>, which is from a popular fashion e-commerce website of <SmallCap>TataCliq</SmallCap><a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186345/images/www18companion-107-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Illustrative example from TataCliq</span>     </div>     </figure>    </p>    <p>Persuasive systems are nuanced by two key challenges as mentioned below.</p>    <ol class="list-no-style">     <li id="list1" label="(1)"><strong>Data scarcity:</strong> It is almost impossible to generate domain specific labeled corpus (parallel corpus) containing general descriptions and the corresponding persuasive descriptions. This is due to the fact that there can be a considerably large number of possible persuasive variations of the given input descriptions. For the input of &#x201C;Levis white turtle neck t-shirt&#x201D;, several persuasive descriptions can be generated, emphasizing on each individual aspect such as &#x201C;Levis&#x201D;, &#x201C;White&#x201D;, &#x201C;Turtle neck&#x201D; and &#x201C;T-shirt&#x201D;. Hence, it is hard to run popular supervised machine learning / deep learning based transformation techniques such as Statistical Machine Translation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>] or Neural Sequence-to-sequence Transformation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>] or their variants.<br/></li>     <li id="list2" label="(2)"><strong>Lack of good evaluation measures:</strong> Evaluating the persuasiveness of a given text can be highly challenging as it requires jointly evaluating the <em>psychological and cognitive</em> aspects of persuasiveness (such as creativity, originality) as well as the linguistic aspects (such as fluency and adequacy) of the text generated.<br/></li>    </ol>    <p>     <em>PersuAIDE!</em> intends to tackle the first challenge by following a modular architecture, in which the modules, at most, rely on a large amount of monolingual, in-domain English corpora and word list that are easily accessible. The job of transforming an input specification into a persuasive description is carried out by (a) parsing the input specification to obtain a list of entities, (b) deciding key-entities on which the text has to be persuasive, (c) mining a list of relevant persuasive key-phrases which could be suitable to describe the key-entities, and (d) stitching the persuasive key-phrases and entities in the input specification together to generate the persuasive description. The systems performance is evaluated using various manual and automatic evaluation measures which test the system from psychological, cognitive and linguistic perspectives. Experiments indicate that our system, which does not require any labeled data for persuasive text generation, performs competitive to supervised machine learning based alternatives in the lines of persuasiveness and fluency.</p>    <p>The rest of the paper is organized as follows. Section <a class="sec" href="#sec-8">2</a> presents a summary of works that are relevant to ours. Section <a class="sec" href="#sec-9">3</a> introduces the overall system architecture and the components. The experiment setup is discussed in Section <a class="sec" href="#sec-19">4</a>. Evaluation results and error-analysis are presented in Section <a class="sec" href="#sec-24">5</a>. Section <a class="sec" href="#sec-25">6</a> concludes the paper and points to future possibilities.</p>   </section>   <section id="sec-8">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>     </div>    </header>    <p>Research in creative natural language text generation has seen a spurt in recent years which is evident from the classes of works on poetry generation[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>][<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>][<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>][<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>][<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>], story generation[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>][<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>], slogan generation[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>], humor generation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>]. Similarly, there has been a good amount of active study on persuasion system and its various aspects[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>][<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>][<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>]. In this section, we provide an overview of two work that are most relevant and heavily inspired the development of <em>PersuAIDE!</em>.</p>    <p>Ozbal et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>] proposed an extensible framework <tt>BRAINSUP</tt> that allows retaining of input key-words in the final expression, inducing user-desired emotion, generating domain specific expressions <em>etc</em>. But it makes heavy use of syntactic information (in other words, templates) to generate well-formed sentences and generation happens by selecting an appropriate template and then filling the empty slots in the template with appropriate words from the input.</p>    <p>Lexical substitution based methods have been used for generating persuasive sentences. Tomasic et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>] follow the same approach as <tt>BRAINSUP</tt> to transform slogan to target specification. Gatti et al. substitute popular concept from trending news in template expressions [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>]. But these works consume fairly expressive text like headline, slogan as inputs and apply simple substitution for domain adaptation where as <em>PersuAIDE!</em> generates complete sentences from roughly 3 to 4 keywords.</p>    <p>A notable study focusing on negotiation, a close form to persuasion, Facebook Artificial Intelligence Research (FAIR) team&#x0027;s work on <em>Deal or no deal?</em>: Training AI bots to negotiate [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>] demonstrate linguistic and reasoning capabilities of the AI bots to negotiate. While their work is a pioneering work in negotiations, their utterances are limited and are focused towards reaching consensus rather than persuading the other agent based on catchy expressions. Moreover, since it is fundamentally a dialog system, it gets several chances during a conversation to understand the opponent agent and act accordingly. A system like <em>PersuAIDE!</em> gets only one chance to appeal to the global consumers with no prior knowledge regarding possible reactions from users. <figure id="fig2">     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186345/images/www18companion-107-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 2:</span>      <span class="figure-title">Architecture for persuasive text generation</span>     </div>     </figure>    </p>   </section>   <section id="sec-9">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> System Architecture</h2>     </div>    </header>    <p>Our system takes a short product specification text as input (henceforth referred to as <em>&#x201C;title text&#x201D;</em>) and produces a persuasive description as the output (henceforth referred to as <em>&#x201C;style tip&#x201D;</em>). Figure <a class="fig" href="#fig2">2</a> shows an overview of the proposed system architecture with a suitable end-to-end example. The proposed system has five major steps: (i) Given the title text of a product, the first step is identify the entities and tag them as generic keywords or named entities (such as brand names), (ii) a keyword expansion is then performed to enhance the generic keywords that encompass more qualitative information about the product, (iii) a set of relevant catchy noun phrases are selected based on the enhanced keywords; these phrases are supposed to best explain the given title text, (iv) using a neural language model, the selected noun phrases are combined with the extracted entities and a prior list of function words to yield candidate persuasive sentences, (v) ranking is performed on the candidate sentences generated in the previous step to choose the most persuasive and fluent style tip for the given title text.</p>    <p>In further sections, we provide a detailed explanation of each module in our system.</p>    <section id="sec-10">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Resources Used</h3>     </div>     </header>     <p>Prior to explaining the system components, we describe the data resources used to implement the different modules of our system. We would like to remind the reader that our system takes no labeled data as input, <em>i.e.,</em> it does not require any parallel corpora containing &#x201C;title-text&#x201D; at one side and &#x201C;style-tip&#x201D; at the other side. This helps us overcome the first challenge of persuasive text generation <em>i.e.,</em> data-scarcity, as mentioned in the introductory section. The resources we intend to use in our system are either in the form of lexicons (a list of domain specific relevant words) or a large amount of unlabeled domain specific texts.</p>     <p>Table&#x00A0;<a class="tbl" href="#tab1">1</a> captures notations used in our work. We now list the resources used below.</p>     <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">List of abbreviations and descriptions</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">        <strong>Abbrevation</strong>        </td>        <td style="text-align:center;">        <strong>Description</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">DC</td>        <td style="text-align:center;">Domain corpus</td>       </tr>       <tr>        <td style="text-align:center;">D</td>        <td style="text-align:center;">Product Descriptions</td>       </tr>       <tr>        <td style="text-align:center;">DNP</td>        <td style="text-align:center;">Domain Noun Phrase</td>       </tr>       <tr>        <td style="text-align:center;">B</td>        <td style="text-align:center;">List of brands</td>       </tr>       <tr>        <td style="text-align:center;">P</td>        <td style="text-align:center;">List of product categories</td>       </tr>       <tr>        <td style="text-align:center;">C</td>        <td style="text-align:center;">List of colors</td>       </tr>       <tr>        <td style="text-align:center;">DA</td>        <td style="text-align:center;">List of domain adjectives</td>       </tr>       <tr>        <td style="text-align:center;">DV</td>        <td style="text-align:center;">List of domain verbs</td>       </tr>      </tbody>     </table>     </div>     <section id="sec-11">     <p><em>3.1.1 Domain Corpus.</em> We extract an unlabeled corpus related to fashion domain (referred to as <em>DC</em>) from various retail sites and magazines. The texts present fashion products from various categories. For each product, we extract the product title, product description or the style-tip, product brand, fabric, suitable gender, etc. Overall, we collected around 149<em>k</em> sentences related to product descriptions. From some websites, we could extract both &#x201C;title-text&#x201D; and &#x201C;style-tip&#x201D; for the same product, which resulted in a small scale parallel-corpus. We do not use the &#x201C;title-text&#x201D; and &#x201C;style-tip&#x201D; alignment anywhere in our pipeline and whatever parallel corpus is extracted is used to train and test out supervised baselines such as sequence-to-sequence model and statistical machine translation.</p>     </section>     <section id="sec-12">     <p><em>3.1.2 Domain constructs.</em> We populate useful fashion constructs namely adjectives (<em>DA</em>), verbs (<em>DV</em>) from <em>words-to-use</em> website<a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>. Additionally, a list of brand names (B), product types (P), and colors (C) are extracted from the e-commerce website data discussed above using simple heuristics.</p>     </section>     <section id="sec-13">     <p><em>3.1.3 Domain Noun phrases (DNP).</em> From the crawled unlabeled fashion corpus <em>DC</em>, product descriptions <em>D</em> are extracted, we bootstrap useful descriptive noun phrases <em>DNP</em> like <em>easy-going summer look</em>, <em>real heart stealer</em>, <em>a tassel-tipped tie-up</em>. These noun phrases are extracted using the following steps:</p>     <ul class="list-no-style">      <li id="list3" label="&#x2022;"><strong>Step 1:</strong> Initialize <em>DNP</em> list with NULL.<br/></li>      <li id="list4" label="&#x2022;"><strong>Step 2:</strong> Sentence-tokenize <em>D</em>.<br/></li>      <li id="list5" label="&#x2022;"><strong>Step 3:</strong> Perform noun chunking of each sentence <em>S</em> in <em>D</em>. This will extract a list of noun phrases (NP) from S.<br/></li>      <li id="list6" label="&#x2022;"><strong>Step 4:</strong> If NP satisfies constraints 1 and 2 (mentioned below), add it to <em>DNP</em> list.<br/></li>     </ul>     <p>For tokenizing and noun-chunking we used the <em>Spacy</em> parser. The noun-phrases in <em>DNP</em> are expected to be generic descriptors and should not represent a specific brand, color, or product. To ensure this, two constraints are imposed: (1) the noun phrase should be between 3-5 words and (2) the noun phrase should not contain words from <em>B</em>, <em>P</em> and <em>C</em>, which are highly product/brand/item/color specific.</p>     </section>     <section id="sec-14">     <p><em>3.1.4 Domain Word Representations.</em> In order to build a meaningful context-aware representation for each word in the fashion domain corpus, we trained word2vec[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0023">23</a>] model using the title text and product description sentences in <em>DC</em>. This word2vec model has been exclusively trained on a fashion corpus to capture the semantic relationship between the words in the fashion domain.</p>     </section>    </section>    <section id="sec-15">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Input Preprocessing and Entity Separation</h3>     </div>     </header>     <p>The input title text is parsed to identify the keywords. This lists all the words in the input title text; an example is shown in Figure <a class="fig" href="#fig2">2</a>. The keywords are then categorized into two classes: (1) <strong>Generic Keywords</strong>: words that carry information about color, gender, and product type and (2) <strong>Named Entities:</strong> words containing brand names, named products, for example, &#x201C;Nehru&#x201D; in &#x201C;Nehru Jacket&#x201D;. Generic keywords are then sent to the keyword expansion module whereas the named entities are retained to be used in the sentence generation module.</p>    </section>    <section id="sec-16">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> Keywords Extraction and Expansion</h3>     </div>     </header>     <p>This module expands the generic keyword list by adding more nouns, adjectives, and adverbs to it. The idea here is to get more informative and creative words which, in some sense, are closely associated with the generic keywords. For our purpose, a word-based similarity measure is implemented using a similarity measure between two word-embedding-vectors (like cosine similarity) is thus used to measure the semantic relatedness among the words. For the input keyword <em>i</em>, the semantic relatedness score is used to pick top <em>K</em> similar words from the fashion vocabulary. To eliminate possibilities of adding noisy/irrelevant words (<em>e.g.,</em> &#x201C;brown&#x201D; could turn out to be highly similar to &#x201C;white&#x201D; in the embedding space but it is not a good candidate in our case), we impose additional constraints such as the part-of-speech of the related keywords should be either &#x201C;common noun&#x201D; or &#x201C;adjective&#x201D; and and should not match with words from <em>B</em>, <em>P</em> and <em>C</em>, which are highly product/brand/item/color specific.</p>     <p>To give an example, for the input title text <em>levis white neck t-shirt</em>, the term &#x2019;levis&#x2019; is identified as a brand and is therefore ignored. The rest of the terms are expanded to obtain words like &#x2019;luminous&#x2019;, &#x2019;royal&#x2019;, &#x2019;retro&#x2019;, &#x2019;funky&#x2019; <em>etc</em> based on <em>word2vec</em> similarity and constraint satisfaction. At this point we have <em>K</em> descriptors for each generic keyword entity.</p>    </section>    <section id="sec-17">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.4</span> Noun phrase selection</h3>     </div>     </header>     <p>The <em>K</em> expanded keywords are then compared with the domain noun phrase list <em>DNP</em> and the top <em>L</em> phrases are identified, again based on the maximum similarity score. At this point, we are aware of the best noun phrases that goes well with expanded keywords. Example &#x2019;easy-going summer look&#x2019; might be the best noun phrase for &#x2019;retro t-shirt&#x2019;. All the unique <em>DNP</em> are selected for sentence generation task.</p>     <p>Since the comparison of the expanded keywords and the noun phrases happen in the word2vec space, it is important for us to get a common representation for both the keywords as well as the phrases. For keyword representation, we take the average between the word embedding for generic keyword <em>k</em> and the word embedding of the expanded keywords. For <em>DNP</em> representation, the embeddings of the constituent words are averaged. Once the representations for both the entities are obtained, a semantic relatedness score based on <em>Earth Mover&#x0027;s distance (EMD)</em> is established between all the possible pairs of feature modifiers, <em>DNP</em>. Based on the matrix of semantic relation scores; the best score for each <em>DNP</em> is obtained and finally, the top <em>L</em> from <em>DNP</em> list are chosen to be part of the sentence composition.</p>    </section>    <section id="sec-18">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.5</span> Sentence Generation</h3>     </div>     </header>     <p>The keywords extracted from the input title text, top <em>L</em> domain noun phrase from <em>DNP</em> list, common function/stop words <em>S</em>, domain verb list <em>DV</em>, and a stop word list are used to prepare the final sentence. We leverage domain adjectives <em>DA</em>, only to identify the compatible noun phrases for the input keywords and they are not used in generation task. By this step, relevant persuasiveness is induced in the form of expanded keywords and domain noun phrases. Further, persuasiveness is induced with the introduction of verbs that determines how the candidates could be used to form a fluent (and hopefully, catchy) sentence. We leverage neural language model [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>] for this final task of sentence generation. During generation, <em>beam search</em> is applied to prevent the explosion of possible hypotheses (pertaining to all possible choices from candidates words and phrases) at a given time step in the generation. Our generation ensures that selection of next words/phrases in each time step minimizes the overall perplexity of the description generated so far with respect to the language model.</p>     <p>We initiate the generation process with the selection of a seed word (which is always a verb in our case as we aim to generated imperative persuasive texts). The seed word is randomly sampled from the <em>DA</em>. At each time step a word/phrase is chosen in a way such that the overall perplexity score is minimized. The generation aims to consume all the keywords extracted from the title text, <em>L DNP</em> with an appropriate usage of the function words to coherently stitch the essential components of the sentence.</p>     <p>A concise representation of the entire system is provided in Algorithm&#x00A0;1 .</p>     <p>     <img src="../../../data/deliveryimages.acm.org/10.1145/3190000/3186345/images/www18companion-107-img1.svg" class="img-responsive" alt=""       longdesc=""/>     </p>    </section>   </section>   <section id="sec-19">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Experimental Setup</h2>     </div>    </header>    <p>The dataset and the setup used in this research to experimentally validate the proposed persuaive system is described in this section. Further, the evaluation metrics are defined and some existing systems are explained that are used for comparison purposes.</p>    <section id="sec-20">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Dataset</h3>     </div>     </header>     <p>As discussed earlier, we design the system to work on fashion domain data crawled from various websites. Some statistics about the dataset are mentioned in the Table&#x00A0;<a class="tbl" href="#tab2">2</a>. Cumulatively, our dataset consists information about 149<em>K</em> products spanning different categories like men&#x0027;s wear, women&#x0027;s wear, footwear, etc. For each product, we extract multiple parameters like title, description, color, gender, age group, taxonomy, brand name, etc. However, for the current task, we mainly rely on the product title and its description.</p>     <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Dataset Statistics</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:center;"/>        <th style="text-align:center;">value</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">Number of samples</td>        <td style="text-align:center;">149320</td>       </tr>       <tr>        <td style="text-align:center;">Avg. words in title</td>        <td style="text-align:center;">6</td>       </tr>       <tr>        <td style="text-align:center;">Max. words in title</td>        <td style="text-align:center;">15</td>       </tr>       <tr>        <td style="text-align:center;">Avg. words in style-tip</td>        <td style="text-align:center;">18</td>       </tr>       <tr>        <td style="text-align:center;">Max. words in style-tip</td>        <td style="text-align:center;">74</td>       </tr>       <tr>        <td style="text-align:center;">Number of colors</td>        <td style="text-align:center;">696</td>       </tr>       <tr>        <td style="text-align:center;">Number of brands</td>        <td style="text-align:center;">591</td>       </tr>       <tr>        <td style="text-align:center;">Total samples related to men</td>        <td style="text-align:center;">95677</td>       </tr>       <tr>        <td style="text-align:center;">Total samples related to women</td>        <td style="text-align:center;">53559</td>       </tr>       <tr>        <td style="text-align:center;">Number of fashion categories</td>        <td style="text-align:center;">234</td>       </tr>      </tbody>     </table>     </div>     <section id="sec-21">     <p><em>4.1.1 Dataset Split for Evaluation and Comparison.</em> As we have pointed in the introductory section, it is difficult to apply popular supervised generation techniques for persuasive text generation (such as Sequence to Sequence neural models, Statistical Machine Translation <em>etc.</em>) as getting parallel labeled text would be extremely difficult. We still managed to create a small parallel corpus from a retail website. The title text is considered as the source side text and the style tip is considered as the target text. This way we could gather a parallel corpus which is split to a train-test set of in the ratio of <strong>93:7</strong>.</p>     <p>The performance of our system is compared with some existing systems using (discussed in <a class="sec" href="#sec-22">4.2</a>) using known evaluation metrics (discussed in <a class="sec" href="#sec-23">4.3</a>), using the test data of 2736 instances. Additionally, we perform manual evaluation by randomly forming a held-out set of 30 test-instances.</p>     </section>    </section>    <section id="sec-22">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Comparison with Existing Systems</h3>     </div>     </header>     <p>Since there is no other existing system at this moment that works with a similar goal like ours, we decide to compare our system&#x0027;s performance with three relatively close systems. The systems are mentioned below.</p>     <ol class="list-no-style">     <li id="list7" label="(1)"><strong>Slogan4U</strong>: <tt>slogan4u.com</tt> is a free slogan generator that takes a phrase as input and produce slogan variations as output. The reason we chose this as a viable system for comparison is that the slogan generated by the website (a) retain the input phrase in them, thereby offering a loss-less transformation of the input phrase (b) the slogans appear to be creative and, to some extent, persuasive.<br/></li>     <li id="list8" label="(2)"><strong>Seq2Seq</strong>: We train a neural sequence-to-sequence system [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0020">20</a>] built with Long-Short-Term-Memory (LSTMs) units over input word embeddings. The framework is based on encoder-decoder architecture and is empowered with attention mechanism. We use default parameters and training configuration as reported by the authors of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0020">20</a>]. The validation set is used to tune other hyperparameters.<br/></li>     <li id="list9" label="(3)"><strong>SMT</strong>: We train a <em>phrase-based statistical machine translation (SMT)</em> system using the Moses framework [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0016">16</a>]. For phrase based translation model learning, <em>grow-diag-final-and</em> heuristic is opted, and to tackle lexicalized reordering, we use the <em>msd-bidirectional-fe</em> model. GIZA++ is configured to apply the principles of IBM model 4 and 5 for alignment learning [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0003">3</a>]. We tuned the trained SMT models with the validation set using Minimum Error Rate Training (MERT) with default parameters (100 best list, max 25 iterations). We trained a 5-gram language model using the target side (descriptions) of the training data. For this, we use use Kneser-Ney smoothing algorithm implemented in KenLM toolkit [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0012">12</a>], bundled with Moses.<br/></li>     </ol>    </section>    <section id="sec-23">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Evaluation</h3>     </div>     </header>     <p>Evaluating a creative task like persuasive text generation is challenging as it requires evaluating the system from both psychological and linguistic perspectives. In the absence of direct evaluation metrics, we choose the following automatic evaluation metrics that are popularly used for generation tasks (especially Machine Translation and Summarization). Additionally, we use popular readability metrics to check the quality of the generated descriptions form the perspective of readability.</p>     <div class="table-responsive" id="tab3">     <div class="table-caption">      <span class="table-number">Table 3:</span>      <span class="table-title">Evaluation of systems using metrics used for Machine Translation and Summarization.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:center;">        <strong>System</strong>        </th>        <th style="text-align:center;">        <strong>BLEU-4</strong>        </th>        <th style="text-align:center;">        <strong>METEOR</strong>        </th>        <th style="text-align:center;">        <strong>ROUGE</strong>        </th>        <th style="text-align:center;">        <strong>ROUGE</strong>        </th>        <th style="text-align:center;">        <strong>Sim</strong>        </th>       </tr>       <tr>        <th style="text-align:center;"/>        <th style="text-align:center;">         <strong>(%)</strong>        </th>        <th style="text-align:center;"/>        <th style="text-align:center;">        <strong>1</strong>        </th>        <th style="text-align:center;">        <strong>L</strong>        </th>        <th style="text-align:center;">        <strong>-ilarity</strong>        </th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">Solgan4U</td>        <td style="text-align:center;">19.6</td>        <td style="text-align:center;">0.16</td>        <td style="text-align:center;">0.14</td>        <td style="text-align:center;">0.11</td>        <td style="text-align:center;">0.76</td>       </tr>       <tr>        <td style="text-align:center;">Seq2Seq</td>        <td style="text-align:center;">25.91</td>        <td style="text-align:center;">0.21</td>        <td style="text-align:center;">0.26</td>        <td style="text-align:center;">0.20</td>        <td style="text-align:center;">0.64</td>       </tr>       <tr>        <td style="text-align:center;">SMT</td>        <td style="text-align:center;">56.91</td>        <td style="text-align:center;">0.24</td>        <td style="text-align:center;">0.22</td>        <td style="text-align:center;">0.2</td>        <td style="text-align:center;">0.7</td>       </tr>       <tr>        <td style="text-align:center;">Our Approach @1</td>        <td style="text-align:center;">22.0</td>        <td style="text-align:center;">0.23</td>        <td style="text-align:center;">0.17</td>        <td style="text-align:center;">0.21</td>        <td style="text-align:center;">0.75</td>       </tr>       <tr>        <td style="text-align:center;">Our Approach @2</td>        <td style="text-align:center;">22.4</td>        <td style="text-align:center;">0.24</td>        <td style="text-align:center;">0.18</td>        <td style="text-align:center;">0.22</td>        <td style="text-align:center;">0.74</td>       </tr>      </tbody>     </table>     </div>     <div class="table-responsive" id="tab4">     <div class="table-caption">      <span class="table-number">Table 4:</span>      <span class="table-title">Evaluation of systems using different readability measures (averaged across test data)</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:center;">        <strong>System</strong>        </th>        <th style="text-align:center;">        <strong>Flesch-Kincaid</strong>        </th>        <th style="text-align:center;">        <strong>SMOG-Index</strong>        </th>        <th style="text-align:center;">        <strong>DaleChal-Index</strong>        </th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">        <strong>Reference</strong>        </td>        <td style="text-align:center;">7.38</td>        <td style="text-align:center;">8.81</td>        <td style="text-align:center;">9.85</td>       </tr>       <tr>        <td style="text-align:center;">Solgan4U</td>        <td style="text-align:center;">4.4</td>        <td style="text-align:center;">6.3</td>        <td style="text-align:center;">10.7</td>       </tr>       <tr>        <td style="text-align:center;">Seq2Seq</td>        <td style="text-align:center;">5.68</td>        <td style="text-align:center;">5.9</td>        <td style="text-align:center;">10.6</td>       </tr>       <tr>        <td style="text-align:center;">SMT</td>        <td style="text-align:center;">4.05</td>        <td style="text-align:center;">6.06</td>        <td style="text-align:center;">9.38</td>       </tr>       <tr>        <td style="text-align:center;">Our Approach @1</td>        <td style="text-align:center;">9.02</td>        <td style="text-align:center;">9.76</td>        <td style="text-align:center;">12.18</td>       </tr>       <tr>        <td style="text-align:center;">Our Approach @2</td>        <td style="text-align:center;">8.61</td>        <td style="text-align:center;">9.31</td>        <td style="text-align:center;">11.61</td>       </tr>      </tbody>     </table>     </div>     <div class="table-responsive" id="tab5">     <div class="table-caption">      <span class="table-number">Table 5:</span>      <span class="table-title">Manual evaluation of systems using different metrics for persuasiveness</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:center;">        <strong>System</strong>        </th>        <th style="text-align:center;">        <strong>Catchyness</strong>        </th>        <th style="text-align:center;">        <strong>Relatedness</strong>        </th>        <th style="text-align:center;">        <strong>Fluency</strong>        </th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">slogan4u</td>        <td style="text-align:center;">0.4977</td>        <td style="text-align:center;">0.6244</td>        <td style="text-align:center;">0.68</td>       </tr>       <tr>        <td style="text-align:center;">slogan4u</td>        <td style="text-align:center;">0.4911</td>        <td style="text-align:center;">0.6755</td>        <td style="text-align:center;">0.7533</td>       </tr>       <tr>        <td style="text-align:center;">Our Approach @1</td>        <td style="text-align:center;">0.7688</td>        <td style="text-align:center;">0.9</td>        <td style="text-align:center;">0.7688</td>       </tr>       <tr>        <td style="text-align:center;">Our Approach @2</td>        <td style="text-align:center;">0.7</td>        <td style="text-align:center;">0.9022</td>        <td style="text-align:center;">0.7</td>       </tr>      </tbody>     </table>     </div>     <p>The evaluation metrics are listed below:</p>     <ol class="list-no-style">     <li id="list10" label="(1)"><strong>Generation:</strong>      <br/>      <ul class="list-no-style">       <li id="list11" label="&#x2022;"><strong>BLEU:</strong> A popular n-gram match based evaluation metrics [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0026">26</a>].<br/></li>       <li id="list12" label="&#x2022;"><strong>METEOR:</strong> Based on n-gram match but also considers synonyms and paraphrase based replacements [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0001">1</a>].<br/></li>       <li id="list13" label="&#x2022;"><strong>ROUGE:</strong> A popular <em>recall-based</em> metric used for summarization evaluation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"        href="#BibPLXBIB0019">19</a>].<br/></li>       <li id="list14" label="&#x2022;"><strong>Similarity:</strong> Document similarity method using <em>Spacy</em> tool indicating to what extent the generated text is similar to the input title text.<br/></li>      </ul></li>     <li id="list15" label="(2)"><strong>Readability:</strong> <a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a>      <br/>      <ul class="list-no-style">       <li id="list16" label="&#x2022;"><strong>Flesch-Kincaid Index [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0014">14</a>]</strong>        <br/></li>       <li id="list17" label="&#x2022;"><strong>SMOG Index [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0021">21</a>]</strong>        <br/></li>       <li id="list18" label="&#x2022;"><strong>Dale-Chal Index [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"         href="#BibPLXBIB0004">4</a>]</strong>        <br/></li>      </ul></li>     </ol>     <p>Since, the above metrics are still not enough to capture the creative aspects of persuasive text generation, we carry out manual evaluation on a small test dataset of 30 instances. The metrics that we use for manual evaluation following the work of [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0025">25</a>], are as follows:</p>     <ol class="list-no-style">     <li id="list19" label="(1)"><strong>Catchyness:</strong> Is the description attractive, catchy [Yes/No]?<br/></li>     <li id="list20" label="(2)"><strong>Relatedness:</strong> Is the description semantically related to the target domain? [Yes/No]?<br/></li>     <li id="list21" label="(3)"><strong>Fluency:</strong> Is the sentence grammatically correct? [Yes/No]?<br/></li>     </ol>     <p>We now proceed to the result section.</p>     <div class="table-responsive" id="tab6">     <div class="table-caption">      <span class="table-number">Table 6:</span>      <span class="table-title">Sample generations from different systems along with inputs and reference descriptions</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">        <strong>Input</strong>        </th>        <th style="text-align:left;">oxolloxo orange checks shirt</th>       </tr>       <tr>        <th style="text-align:left;">        <strong>Reference</strong>        </th>        <th style="text-align:left;">Opt for casual comfort with this orange shirt from oxolloxo</th>       </tr>       <tr>        <th style="text-align:left;">        <strong>slogan4u</strong>        </th>        <th style="text-align:left;">oxolloxo orange checks shirt the cream of the crop.</th>       </tr>       <tr>        <th style="text-align:left;">        <strong>seq2seq</strong>        </th>        <th style="text-align:left;">Look stylish by sporting this pair of oxolloxo casual shoes.</th>       </tr>       <tr>        <th style="text-align:left;">        <strong>SMT</strong>        </th>        <th style="text-align:left;">This orange color shirt from oxolloxo</th>       </tr>       <tr>        <th style="text-align:left;">        <strong>PersuAIDE!</strong>        </th>        <th style="text-align:left;">Go well with your off-duty styles on a stylised fit using orange checks shirt</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:left;">        <strong>Input</strong>        </td>        <td style="text-align:left;">cobblerz black derby formal shoes</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Reference</strong>        </td>        <td style="text-align:left;">Embrace the age old charm of derby shoes with the black derby shoes by cobblerz.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>slogan4u</strong>        </td>        <td style="text-align:left;">Got cobblerz black derby formal shoes?</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>seq2seq</strong>        </td>        <td style="text-align:left;">Flaunt your casual collection with this black top from cobblerz. Made from polyester fabric, this regular fit top will keep you sweat free all day long.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>SMT</strong>        </td>        <td style="text-align:left;">Flaunt your chic look with black shoes</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>PersuAIDE!</strong>        </td>        <td style="text-align:left;">Embellish at a chic finishing touch with the new season&#x0027;s trends using black derby formal shoes</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Input</strong>        </td>        <td style="text-align:left;">zudio dark beige back strap sandals</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Reference</strong>        </td>        <td style="text-align:left;">Update your footwear collection with &#x2019;s dark beige sandals.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>slogan4u</strong>        </td>        <td style="text-align:left;">zudio dark beige back strap sandals is crazy good.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>seq2seq</strong>        </td>        <td style="text-align:left;">Team this shirt with a pair of denims and casual shoes.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>SMT</strong>        </td>        <td style="text-align:left;">fetherlite this pair of dark brown casual</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>PersuAIDE!</strong>        </td>        <td style="text-align:left;">Flaunt on your amazing fashion sense in a swanky ensemble using dark beige back strap sandals.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Input</strong>        </td>        <td style="text-align:left;">109 f black printed cavi top</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Reference</strong>        </td>        <td style="text-align:left;">Incorporate unique prints in your wardrobe with this black Cavi top from 109f.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>slogan4u</strong>        </td>        <td style="text-align:left;">109 f black printed cavi top quality you can see.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>seq2seq</strong>        </td>        <td style="text-align:left;">Look stylish by wearing this pair of 109f casual shoes.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>SMT</strong>        </td>        <td style="text-align:left;">Steal the limelight wearing this pair of casual shoes from</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>PersuAIDE!</strong>        </td>        <td style="text-align:left;">Flatter the figure this black printed cavi top with a marvelously versatile pick using flavoursome fusion fashion</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Input</strong>        </td>        <td style="text-align:left;">dc council mid lx navy sneakers</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>Reference</strong>        </td>        <td style="text-align:left;">Hit the road in style by wearing this pair of navy casual sneakers from the house of dc council</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>slogan4u</strong>        </td>        <td style="text-align:left;">Me and my dc council mid lx navy sneakers.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>seq2seq</strong>        </td>        <td style="text-align:left;">Look stylish by sporting this pair of dc council casual shoes.</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>SMT</strong>        </td>        <td style="text-align:left;">sultan in style by wearing this pair of navy casual sneakers from</td>       </tr>       <tr>        <td style="text-align:left;">        <strong>PersuAIDE!</strong>        </td>        <td style="text-align:left;">Look sexy in your beachside look with mid lx navy sneakers using a cool hip-hop look</td>       </tr>      </tbody>     </table>     </div>    </section>   </section>   <section id="sec-24">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Results</h2>     </div>    </header>    <p>For our system, we take two different output candidate descriptions obtained with respect to two different sets of expanded keywords from the input title-text. The two output descriptions are denoted as @1, @2 approach in result tables. Results are reported on the test data of 2736 instances, used for automatic evaluation and a held-out set of 30 instances, used for manual evaluation.</p>    <p>From the perspective of considering our persuasive system as yet another machine translation system that converts a non-persuasive product title into a persuasive product description, we have results shown in Table&#x00A0;<a class="tbl" href="#tab3">3</a>. Popular machine translation and summarization metrics such as BLEU, METEOR, ROUGE-1 and ROUGE-L, and similarity measures are used. The proposed algorithm is compared against three existing systems. Since most of these metrics work purely based on the keyword matching, most of the creative systems tend to preform low because of the artistic freedom to choose varied and unusual words. Additionally, methods like sequence-to-sequence and SMT learn to produce results closer to the reference text, indirectly optimizing the evaluation metrics we have considered here, hence the results are better for these techniques. But, given the fact that it is extremely difficult to get access to parallel data in real world scenarios, our system, producing results competitive to these supervised systems is definitely a positive indication going forward.</p>    <p>From the perspective of generative systems, we use several readability measures to evaluate if the persuasive generated descriptions are readable (in terms of English language structure). The results are shown in Table&#x00A0;<a class="tbl" href="#tab4">4</a>. Across all the three measures: Flesch-Kincaid, SMOG-Index, and DaleChal-Index, we observe that our proposed system generates quite readable sentences (with scores ranging from [9-12]). However, the scores being higher for our systems than the baselines indicated that descriptions generated by our systems contain more nuances (from the perspective of reading) than the simpler descriptions generated by the baselines.</p>    <p>From the perspective of human psychology of persuasive product descriptions, we manually evaluated the generated descriptions using human interviews. Three different measures were used to evaluate the human subjectiveness: Catchyness, Relatedness, and Fluency. It can be evidently observed that the proposed system generated more catchy, better related, and grammatically correct sentences compared to the creative slogan generation systems.</p>    <p>It can be clearly observed from Table&#x00A0;<a class="tbl" href="#tab3">3</a> and Table&#x00A0;<a class="tbl" href="#tab5">5</a> that, though our system out performs the existing system based on human evaluation, it performs low on the standard text generation metrics. This can be attributed to the constraint of matching the exact words or synonyms and not considering the creative liberty to choose words/phrases that are unusual.</p>    <p>For qualitative analysis, we also provide the sentences generated from our system as well as other systems in the Table&#x00A0;<a class="tbl" href="#tab6">6</a>. As we can see, the descriptions generated by our systems are competitive or better in terms of creativity, persuasiveness and fluency than the supervised baselines but have less overlap with the reference descriptions. This explains why our system is deemed to have underperformed than the baselines, as per the automatic evaluation scores. In general, the field of creative text generation demands looking beyond simplistic evaluation measures and it is about time that trainable metrics for evaluating persuasive text holistically, including aspects on creativity, coherency, novelty are proposed.</p>   </section>   <section id="sec-25">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Conclusion and Future Work</h2>     </div>    </header>    <p>In this paper, we presented a system called PersuAIDE! which aims to generate persuasive text for input product description. We demonstrated the work in fashion domain where for a given fashion product title such as <em>&#x2019;Levis white round neck t-shirt&#x2019;</em>, we were able to first expand features and keywords of the provided entity words in the title. Further, we generate descriptive sentences with random seed verbs using a neural network based language model and other NLP techniques to generate a persuasive sentence - <em>shape your evening outfit with this white neck t-shirt</em>. We evaluate our work against a popular slogan generation system using manual analysis and compare our work with popular supervised generative models. We also find that our work consistently performs as good as supervised machine learning based alternatives in the lines of persuasion and correctness, as established through various metrics. Our study could be considered as a novel attempt to generate persuasive product description in a linguistically motivated framework that accounts for syntagmatic and paradigmatic aspects of language. Applying our technique to different other domains (such as news, tourism <em>etc.</em>) is definitely a future possibility.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In <em>      <em>Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization</em>     </em>, Vol.&#x00A0;29. 65&#x2013;72.</li>     <li id="BibPLXBIB0002" label="[2]">Yoshua Bengio, R&#x00E9;jean Ducharme, Pascal Vincent, and Christian Jauvin. 2003. A neural probabilistic language model. <em>      <em>Journal of machine learning research</em>     </em>3, Feb (2003), 1137&#x2013;1155.</li>     <li id="BibPLXBIB0003" label="[3]">Peter&#x00A0;F Brown, Vincent J&#x00A0;Della Pietra, Stephen A&#x00A0;Della Pietra, and Robert&#x00A0;L Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. <em>      <em>Computational linguistics</em>     </em>(1993).</li>     <li id="BibPLXBIB0004" label="[4]">Jeanne&#x00A0;Sternlicht Chall and Edgar Dale. 1995. <em>      <em>Readability revisited: The new Dale-Chall readability formula</em>     </em>. Brookline Books.</li>     <li id="BibPLXBIB0005" label="[5]">Simon Colton, Jacob Goodwin, and Tony Veale. 2012. Full-FACE Poetry Generation.. In <em>      <em>ICCC</em>     </em>. 95&#x2013;102.</li>     <li id="BibPLXBIB0006" label="[6]">Lorenzo Gatti, Marco Guerini, Oliviero Stock, and Carlo Strapparava. 2014. Sentiment variations in text for persuasion technology. In <em>      <em>International Conference on Persuasive Technology</em>     </em>. Springer, 106&#x2013;117.</li>     <li id="BibPLXBIB0007" label="[7]">Lorenzo Gatti, Gozde Ozbal, Marco Guerini, Oliviero Stock, and Carlo Strapparava. 2016. Heady-Lines: A Creative Generator Of Newspaper Headlines. In <em>      <em>Companion Publication of the 21st International Conference on Intelligent User Interfaces</em>     </em>. ACM, 79&#x2013;83.</li>     <li id="BibPLXBIB0008" label="[8]">Hugo Gon&#x00E7;alo&#x00A0;Oliveira. 2015. Tra-la-lyrics 2.0: Automatic generation of song lyrics on a semantic domain. <em>      <em>Journal of Artificial General Intelligence</em>     </em>6, 1 (2015), 87&#x2013;110.</li>     <li id="BibPLXBIB0009" label="[9]">Erica Greene, Tugba Bodrumlu, and Kevin Knight. 2010. Automatic analysis of rhythmic poetry with applications to generation and translation. In <em>      <em>Proceedings of the 2010 conference on empirical methods in natural language processing</em>     </em>. Association for Computational Linguistics, 524&#x2013;533.</li>     <li id="BibPLXBIB0010" label="[10]">Marco Guerini, Fabio Pianesi, and Oliviero Stock. 2014. Is it morally acceptable for a system to lie to persuade me?<em>      <em>arXiv preprint arXiv:1404.3959</em>     </em>(2014).</li>     <li id="BibPLXBIB0011" label="[11]">Marco Guerini, Oliviero Stock, and Massimo Zancanaro. 2007. A taxonomy of strategies for multimodal persuasive message generation. <em>      <em>Applied Artificial Intelligence</em>     </em>21, 2 (2007), 99&#x2013;136.</li>     <li id="BibPLXBIB0012" label="[12]">Kenneth Heafield. 2011. KenLM: Faster and smaller language model queries. In <em>      <em>Proceedings of the Sixth Workshop on Statistical Machine Translation</em>     </em>.</li>     <li id="BibPLXBIB0013" label="[13]">Parag Jain, Priyanka Agrawal, Abhijit Mishra, Mohak Sukhwani, Anirban Laha, and Karthik Sankaranarayanan. 2017. Story Generation from Sequence of Independent Short Descriptions. <em>      <em>arXiv preprint arXiv:1707.05501</em>     </em>(2017).</li>     <li id="BibPLXBIB0014" label="[14]">J&#x00A0;Peter Kincaid, Robert&#x00A0;P Fishburne&#x00A0;Jr, Richard&#x00A0;L Rogers, and Brad&#x00A0;S Chissom. 1975. <em>      <em>Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel</em>     </em>. Technical Report. DTIC Document.</li>     <li id="BibPLXBIB0015" label="[15]">Philipp Koehn. 2009. <em>      <em>Statistical machine translation</em>     </em>. Cambridge University Press.</li>     <li id="BibPLXBIB0016" label="[16]">Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, <em>et al.</em> 2007. Moses: Open source toolkit for statistical machine translation. In <em>      <em>Proceedings of the 45th annual meeting of the ACL on interactive poster and demonstration sessions</em>     </em>. Association for Computational Linguistics, 177&#x2013;180.</li>     <li id="BibPLXBIB0017" label="[17]">Ray Kurzweil. 2005. <em>      <em>The singularity is near: When humans transcend biology</em>     </em>. Penguin.</li>     <li id="BibPLXBIB0018" label="[18]">Mike Lewis, Denis Yarats, Yann&#x00A0;N. Dauphin, Devi Parikh, and Dhruv Batra. 2017. Deal or No Deal? End-to-End Learning for Negotiation Dialogues. <em>      <em>CoRR</em>     </em>abs/1706.05125(2017). arxiv:1706.05125<a class="link-inline force-break" href="http://arxiv.org/abs/1706.05125"      target="_blank">http://arxiv.org/abs/1706.05125</a></li>     <li id="BibPLXBIB0019" label="[19]">Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In <em>      <em>Text summarization branches out: Proceedings of the ACL-04 workshop</em>     </em>, Vol.&#x00A0;8. Barcelona, Spain.</li>     <li id="BibPLXBIB0020" label="[20]">Minh-Thang Luong, Hieu Pham, and Christopher&#x00A0;D Manning. 2015. Effective approaches to attention-based neural machine translation. <em>      <em>arXiv preprint arXiv:1508.04025</em>     </em>(2015).</li>     <li id="BibPLXBIB0021" label="[21]">G&#x00A0;Harry Mc&#x00A0;Laughlin. 1969. SMOG grading-a new readability formula. <em>      <em>Journal of reading</em>     </em>12, 8 (1969), 639&#x2013;646.</li>     <li id="BibPLXBIB0022" label="[22]">Neil McIntyre and Mirella Lapata. 2009. Learning to tell tales: A data-driven approach to story generation. In <em>      <em>Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1</em>     </em>. Association for Computational Linguistics, 217&#x2013;225.</li>     <li id="BibPLXBIB0023" label="[23]">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. <em>      <em>arXiv preprint arXiv:1301.3781</em>     </em>(2013).</li>     <li id="BibPLXBIB0024" label="[24]">Hugo&#x00A0;Gon&#x00E7;alo Oliveira. 2012. PoeTryMe: a versatile platform for poetry generation. <em>      <em>Computational Creativity, Concept Invention, and General Intelligence</em>     </em>1 (2012), 21.</li>     <li id="BibPLXBIB0025" label="[25]">G&#x00F6;zde &#x00D6;zbal, Daniele Pighin, and Carlo Strapparava. 2013. BRAINSUP: Brainstorming Support for Creative Sentence Generation.. In <em>      <em>ACL (1)</em>     </em>. 1446&#x2013;1455.</li>     <li id="BibPLXBIB0026" label="[26]">Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In <em>      <em>Proceedings of the 40th annual meeting on association for computational linguistics</em>     </em>. Association for Computational Linguistics, 311&#x2013;318.</li>     <li id="BibPLXBIB0027" label="[27]">Oliviero Stock, Marco Guerini, and Fabio Pianesi. 2016. Ethical Dilemmas for Adaptive Persuasion Systems.. In <em>      <em>AAAI</em>     </em>. 4157&#x2013;4162.</li>     <li id="BibPLXBIB0028" label="[28]">Ilya Sutskever, Oriol Vinyals, and Quoc&#x00A0;V Le. 2014. Sequence to sequence learning with neural networks. In <em>      <em>Advances in neural information processing systems</em>     </em>. 3104&#x2013;3112.</li>     <li id="BibPLXBIB0029" label="[29]">Jukka Toivanen, Hannu Toivonen, Alessandro Valitutti, Oskar Gross, <em>et al.</em> 2012. Corpus-based generation of content and form in poetry. In <em>      <em>Proceedings of the Third International Conference on Computational Creativity</em>     </em>.</li>     <li id="BibPLXBIB0030" label="[30]">Polona Toma&#x0161;ic, M Znidar&#x0161;ic, and Gregor Papa. 2014. Implementation of a slogan generator. In <em>      <em>Proceedings of 5th International Conference on Computational Creativity, Ljubljana, Slovenia</em>     </em>, Vol.&#x00A0;301. 340&#x2013;343.</li>     <li id="BibPLXBIB0031" label="[31]">Alessandro Valitutti, Oliviero Stock, and Carlo Strapparava. 2009. Graphlaugh: a tool for the interactive generation of humorous puns. In <em>      <em>Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009. 3rd International Conference on</em>     </em>. IEEE, 1&#x2013;2.</li>     <li id="BibPLXBIB0032" label="[32]">Alessandro Valitutti, Hannu Toivonen, Antoine Doucet, and Jukka&#x00A0;M Toivanen. 2013. &#x201D; Let Everything Turn Well in Your Wife&#x201D;: Generation of Adult Humor Using Lexical Constraints.. In <em>      <em>ACL (2)</em>     </em>. 243&#x2013;248.</li>     <li id="BibPLXBIB0033" label="[33]">Martin Znidar&#x0161;ic, Polona Toma&#x0161;ic, and Gregor Papa. 2015. Case-Based Slogan Production. (2015).</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>This description has been generated by our system</p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break" href="https://www.tatacliq.com/">https://www.tatacliq.com/</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a><a class="link-inline force-break"     href="http://www.words-to-use.com/words/clothing/">http://www.words-to-use.com/words/clothing/</a>   </p>   <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>Higher readability scores indicate more reading complexity</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186345">https://doi.org/10.1145/3184558.3186345</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
