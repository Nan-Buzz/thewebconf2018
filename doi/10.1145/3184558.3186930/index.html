<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Spam2Vec: Learning Biased Embeddings for Spam Detection in
  Twitter</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Spam2Vec: Learning Biased
          Embeddings for Spam Detection in Twitter</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Suman Kalyan</span> <span class=
          "surName">Maity</span>, Dept. of CSE, IIT Kharagpur,
          India, <a href=
          "mailto:sumankalyan.maity@cse.iitkgp.ernet.in">sumankalyan.maity@cse.iitkgp.ernet.in</a>
        </div>
        <div class="author">
          <span class="givenName">Santosh K</span> <span class=
          "surName">C</span>, Dept. of CS, University of Houston,
          TX, USA, <a href=
          "mailto:syantokc@gmail.com">syantokc@gmail.com</a>
        </div>
        <div class="author">
          <span class="givenName">Arjun</span> <span class=
          "surName">Mukherjee</span>, Dept. of CS, University of
          Houston, TX, USA, <a href=
          "mailto:arjun@cs.uh.edu">arjun@cs.uh.edu</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3186930"
        target=
        "_blank">https://doi.org/10.1145/3184558.3186930</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>In this paper, we propose a semi-supervised
        framework <em>Spam</em>2<em>Vec</em> to identify spammers
        in Twitter. This algorithmic framework learns the spam
        representations of the node in the network by leveraging
        biased random walks. Our spammer detection method yields an
        AUC of 0.54 with precision@100 as 0.12 and performs
        significantly better with 7.77% increase in AUC and a 2.4
        times improvement on precision over the best performing
        baseline.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS
        Concepts:</span> • <strong>Information systems</strong> →
        <strong>Data mining;</strong> <strong>Social
        networks;</strong></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Spam
          detection</small>,</span> <span class=
          "keyword"><small>Biased embedding</small>,</span>
          <span class="keyword"><small>Biased Random
          walks</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Suman Kalyan Maity, Santosh K C, and Arjun Mukherjee.
          2018. Spam2Vec: Learning Biased Embeddings for Spam
          Detection in Twitter. In <em>WWW '18 Companion: The 2018
          Web Conference Companion,</em> <em>April 23–27, 2018 (WWW
          ’18 Companion),</em> <em>Lyon, France. ACM, New York, NY,
          USA</em> 3 Pages. <a href=
          "https://doi.org/10.1145/3184558.3186930" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3186930</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-3">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>Social spammers are sophisticated and adaptable. Reflexive
      reciprocity makes it easier for social spammers to establish
      social influence and pretend to be normal users by
      accumulating a large number of friends and thereby easily
      bypass the spam detection systems. In this paper, we present
      <em>Spam</em>2<em>Vec</em>, a framework to collectively use
      both content and network information for social spammer
      detection. <em>Spam</em>2<em>Vec</em> learns a biased spam
      embeddings in the network by leveraging biased random walks.
      We first calculate follow-spam scores of the nodes in the
      network and try to bias the random walks with follow-spam
      scores of the nodes together with spam related features of
      the nodes. The biasing methodology maximizes the likelihood
      of obtaining spammer nodes in local few hop neighborhood
      instead of just concentrating on the immediate neighbor.</p>
      <p>In Twitter, there are limited attempts been made to tackle
      the spam detection problem&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0012">12</a>]. Lee et al.&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0006">6</a>] leveraged profile-based
      features and deployed social honeypots to detect new social
      spammers. Ghosh et al.&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0003">3</a>] studied link farming in Twitter. Zhu
      et al.&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0012">12</a>]
      propose a Supervised Matrix Factorization method with Social
      Regularization for spammer detection.</p>
    </section>
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Model
          Description</h2>
        </div>
      </header>
      <p>We use the Twitter dataset collected by Yang et
      al.&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0011">11</a>]
      consisting of posts from 17 million users from June 2009 to
      December 2009. We extracted the follower-following topology
      of Twitter from &nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>]. We further prune the network and we
      are left with 4,405,698 users and separately crawled the
      status of users to identify if they were suspended or not. In
      total, we have 100,758 spammer accounts.</p>
      <p>Our entire framework is composed of 3 components: a)
      Follow-spam, b) Biasing in the network, c) Learning Spam
      Representation in the network.</p>
      <section id="sec-5">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span>
            Follow-spam</h3>
          </div>
        </header>
        <p>One of the prominent ways of spamming in Twitter is
        follow-spam where a Twitter user follows large number of
        unknown other users hoping that these pretend-friends will
        follow him back in exchange. In this module, we design a
        pagerank-like model inspired by&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0003">3</a>] to rank the nodes in the
        who-follows-whom network based on their spamicity (see
        Algorithm 1).</p>
        <p><img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186930/images/www18companion-170-img1.svg"
        class="img-responsive" alt="" longdesc="" /></p>
      </section>
      <section id="sec-6">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Biasing in
            the network</h3>
          </div>
        </header>
        <p>We want to combine the follow-spam scores and also
        consider the spammer's properties into a single framework
        that will at the same time consider rich node and edge
        features as well as the structure of the network. From a
        given source node <em>s</em> and set of spammer nodes
        (<em>S</em>) in the network, we aim to bias the random walk
        originating from <em>s</em> (irrespective of whether it is
        a spammer node or not) so that it visits other spammer
        nodes more often than the non-spammer nodes (<em>H</em>) in
        the network. For edge (<em>u</em>, <em>v</em>) in the
        network, we compute the edge strength
        <em>a<sub>uv</sub></em> = <em>ψ<sub>w</sub></em>
        (<em>ϕ<sub>uv</sub></em> ) where <em>ϕ<sub>uv</sub></em>
        denotes the corresponding feature vector that describes the
        nodes <em>u</em>, <em>v</em> and their interaction.
        Function <em>ψ<sub>w</sub></em> parameterized by <em>w</em>
        takes the edge feature vector <em>ϕ<sub>uv</sub></em> as
        input and computes the corresponding edge strength
        <em>a<sub>uv</sub></em> which models the biased random walk
        transition probability. Therefore, we need to set the
        parameters <em>w</em> of function <em>ψ<sub>w</sub></em>
        (<em>ϕ<sub>uv</sub></em> ) so that it will assign edge
        weights <em>a<sub>uv</sub></em> in such a way that a random
        walker will more likely visit spammer nodes <em>S</em> than
        non-spammer nodes <em>H</em>. Towards this objective, we
        formulate the optimization problem to find the optimal set
        of parameters <em>w</em> of edge-weight objective function
        <em>ψ<sub>w</sub></em> (<em>ϕ<sub>uv</sub></em> ) as
        follows:</p>
        <div class="table-responsive">
          <div class="display-equation">
            <span class="tex mytex">\begin{align*} &amp;\min _{{w}}
            \Omega (w) = ||w||^2 \hspace{5.69054pt} \text{such
            that} \\ &amp;\forall s \in S \&amp; t \in \Gamma (s),
            \hspace{2.84526pt} \psi _{s,t \in H} {\lt} \beta _1
            \psi _{s,t \in S} \\ &amp; \text{and}
            \hspace{5.69054pt} \forall h \in H \&amp; t \in \Gamma
            (h), \hspace{2.84526pt} \psi _{h,t \in H} {\lt} \beta
            _2 \psi _{h,t \in S}\end{align*}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>
        <p>Note that <span class="inline-equation"><span class=
        "tex">$\psi _{u,v}^{OPT}$</span></span> =
        <em>ϕ<sub>uv</sub></em> .<em>w<sup>OPT</sup></em>
        .(<em>f<sub>u</sub></em> + <em>f<sub>v</sub></em> )
        <sup><em>γ</em></sup> where <em>f<sub>u</sub></em> and
        <em>f<sub>v</sub></em> are the follow-spam scores of node
        <em>u</em> and <em>v</em> respectively and
        <em>w<sup>OPT</sup></em> is the optimal <em>w</em> vector.
        We further bias the random walk with neighborhood spam. The
        idea behind this is that when a walker lands up on a node,
        he will choose a node that increases the likelihood of
        finding a spammer in his local neighborhood.</p>
      </section>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.3</span> Learning
            Spam Representation</h3>
          </div>
        </header>
        <p>We now want to learn the spam representations (network
        embeddings) of the nodes in the network. For each node
        <em>u</em> in the network <em>G</em> = (<em>V</em>,
        <em>E</em>), we define a proximity or neighborhood
        <em>N</em>(<em>u</em>) which can be obtained by simulating
        a biased random walk (defined above) on the network
        starting at node <em>u</em>. We optimize the following
        objective function that predicts which nodes belong to the
        neighborhood <em>N</em>(<em>u</em>) based on the learned
        node attributes <em>y</em>, by adopting the Skip-gram
        architecture&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0009">9</a>].</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \max _{{y}}
            \sum _{{u \in V}}log(\prod _{{n \in N(u)}}P(n|y(u)))
            \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>
        <p>We also make the assumption that a source node and
        neighborhood node have a symmetric effect over each other
        in representation space. So, we have</p>
        <div class="table-responsive" id="Xeq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} P(n|y(u)) =
            \exp (y(n).y(u))/\sum _{v \in V}\exp (y(v).y(u))
            \end{equation}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>
        <p></p>
        <p>Since the per-node function ∑ <sub><em>v</em> ∈
        <em>V</em></sub>
        exp (<em>y</em>(<em>v</em>).<em>y</em>(<em>u</em>)) is
        computationally expensive, we approximate it using negative
        sampling&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0008">8</a>]. We then optimize the objective
        function mentioned in Eq.<a class="eqn" href="#eq1">2</a>
        using stochastic gradient descent over the model
        parameters. The detailed methodology is presented as
        Algorithm 2.</p>
        <p><img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186930/images/www18companion-170-img2.svg"
        class="img-responsive" alt="" longdesc="" /></p>
      </section>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span>
          Experiments</h2>
        </div>
      </header>
      <p>We use the node representations learnt earlier as features
      for spammer detection task. We learn a SGD regressor giving
      spammer nodes and non-spammer nodes two distinct values and
      then rank the nodes in test set according to the regression
      values. We evaluate our model with several baseline models to
      see how they are performing against various evaluation
      metrics.</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186930/images/www18companion-170-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">Cumulative Distribution Function of spam
          nodes.</span>
        </div>
      </figure>
      <p></p>
      <p>In fig&nbsp;<a class="fig" href="#fig1">1</a>, we present
      the cumulative distribution function for presence of spam
      nodes in the rank percentile of nodes. We can observe that
      <em>Spam</em>2<em>Vec</em> performs best followed by
      node2vec. We also calculated area under the above curve (see
      table&nbsp;<a class="tbl" href="#tab1">1</a>). Our model
      performs significantly better both in terms of Area under the
      CDF curve as well as precision@n (<em>n</em>=100).
      <em>Spam</em>2<em>Vec</em> yields an AUC of 0.541 with
      precision@100 as 0.12 which outperforms the best performing
      baseline model (<em>node</em>2<em>vec</em>) by 7.77% and 2.4
      times increase in AUC and precision respectively. For other
      values of <em>n</em> also, <em>Spam</em>2<em>Vec</em>
      performs consistently and better than the other baseline
      models.</p>
      <div class="table-responsive" id="tab1">
        <div class="table-caption">
          <span class="table-number">Table 1:</span> <span class=
          "table-title">Evaluation Results: AUC and Precision
          @100.</span>
        </div>
        <table class="table">
          <thead>
            <tr>
              <th style="text-align:left;">Models</th>
              <th style="text-align:left;">AUC</th>
              <th style="text-align:left;">P @100</th>
              <th style="text-align:left;">Models</th>
              <th style="text-align:left;">AUC</th>
              <th style="text-align:left;">P @100</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="text-align:left;">
                Markov Random Field[<a class="bib" data-trigger=
                "hover" data-toggle="popover" data-placement="top"
                href="#BibPLXBIB0002">2</a>]
              </td>
              <td style="text-align:left;">0.38</td>
              <td style="text-align:left;">0.02</td>
              <td style="text-align:left;">
                DeepWalk[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0009">9</a>]
              </td>
              <td style="text-align:left;">0.488</td>
              <td style="text-align:left;">0.05</td>
            </tr>
            <tr>
              <td style="text-align:left;">
                Benevenuto et al.&nbsp;[<a class="bib"
                data-trigger="hover" data-toggle="popover"
                data-placement="top" href="#BibPLXBIB0001">1</a>]
              </td>
              <td style="text-align:left;">0.42</td>
              <td style="text-align:left;">0.06</td>
              <td style="text-align:left;">
                node2vec[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0004">4</a>]
              </td>
              <td style="text-align:left;">0.502</td>
              <td style="text-align:left;">0.05</td>
            </tr>
            <tr>
              <td style="text-align:left;">
                Lee et al.&nbsp;[<a class="bib" data-trigger=
                "hover" data-toggle="popover" data-placement="top"
                href="#BibPLXBIB0006">6</a>]
              </td>
              <td style="text-align:left;">0.452</td>
              <td style="text-align:left;">0.07</td>
              <td style="text-align:left;"><strong>Our Model
              <em>Spam</em>2<em>Vec</em></strong></td>
              <td style="text-align:left;">
              <strong>0.541</strong></td>
              <td style="text-align:left;">
              <strong>0.12</strong></td>
            </tr>
            <tr>
              <td style="text-align:left;">
                Zhu et al.&nbsp;[<a class="bib" data-trigger=
                "hover" data-toggle="popover" data-placement="top"
                href="#BibPLXBIB0012">12</a>]
              </td>
              <td style="text-align:left;">0.454</td>
              <td style="text-align:left;">0.03</td>
              <td style="text-align:left;"></td>
              <td style="text-align:left;"></td>
              <td style="text-align:left;"></td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span>
          Conclusions</h2>
        </div>
      </header>
      <p>We propose a network-cum-content based spam-represented
      embedding learning framework <em>Spam</em>2<em>Vec</em>. We
      boost our spam representation learning of the node in the
      network by leveraging biased random walks. We compare our
      method <em>Spam</em>2<em>Vec</em> with already existing
      baselines. <em>Spam</em>2<em>Vec</em> yields an AUC of 0.54
      with precision@100 as 0.12 and performs significantly better
      with 7.77% increase in AUC and a 2.4 times improvement on
      precision over the best performing baseline.</p>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span>
          Acknowledgments</h2>
        </div>
      </header>
      <p>This research work is supported in part by the National
      Science Foundation under grant no. 1527364.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Fabricio Benevenuto,
        Gabriel Magno, Tiago Rodrigues, and Virgilio Almeida. 2010.
        Detecting spammers on twitter. In <em><em>CEAS</em></em> ,
        Vol.&nbsp;6. 12.</li>
        <li id="BibPLXBIB0002" label="[2]">Geli Fei, Arjun
        Mukherjee, Bing Liu, Meichun Hsu, Malu Castellanos, and
        Riddhiman Ghosh. 2013. Exploiting Burstiness in Reviews for
        Review Spammer Detection. <em><em>ICWSM</em></em> 13(2013),
        175–184.</li>
        <li id="BibPLXBIB0003" label="[3]">Saptarshi Ghosh, Bimal
        Viswanath, Farshad Kooti, Naveen&nbsp;Kumar Sharma, Gautam
        Korlam, Fabricio Benevenuto, Niloy Ganguly, and
        Krishna&nbsp;Phani Gummadi. 2012. Understanding and
        combating link farming in the twitter social network. In
        <em><em>WWW</em></em> . 61–70.</li>
        <li id="BibPLXBIB0004" label="[4]">Aditya Grover and Jure
        Leskovec. 2016. node2vec: Scalable feature learning for
        networks. In <em><em>ACM SIGKDD</em></em> . ACM,
        855–864.</li>
        <li id="BibPLXBIB0005" label="[5]">Haewoon Kwak, Changhyun
        Lee, Hosung Park, and Sue Moon. 2010. What is Twitter, a
        social network or a news media?. In <em><em>WWW</em></em> .
        591–600.</li>
        <li id="BibPLXBIB0006" label="[6]">Kyumin Lee, James
        Caverlee, and Steve Webb. 2010. Uncovering social spammers:
        social honeypots+ machine learning. In
        <em><em>SIGIR</em></em> . 435–442.</li>
        <li id="BibPLXBIB0007" label="[7]">Tomas Mikolov, Kai Chen,
        Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation
        of word representations in vector space.
        <em><em>ICLR</em></em> (2013).</li>
        <li id="BibPLXBIB0008" label="[8]">Tomas Mikolov, Ilya
        Sutskever, Kai Chen, Greg&nbsp;S Corrado, and Jeff Dean.
        2013. Distributed representations of words and phrases and
        their compositionality. In <em><em>NIPS</em></em> .
        3111–3119.</li>
        <li id="BibPLXBIB0009" label="[9]">Bryan Perozzi, Rami
        Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning
        of social representations. In <em><em>ACM SIGKDD</em></em>
        . ACM, 701–710.</li>
        <li id="BibPLXBIB0010" label="[10]">KC Santosh,
        Suman&nbsp;Kalyan Maity, and Arjun Mukherjee. 2017. ENWalk:
        Learning Network Features for Spam Detection in Twitter. In
        <em><em>SBP-BRiMS</em></em> . 90–101.</li>
        <li id="BibPLXBIB0011" label="[11]">Jaewon Yang and Jure
        Leskovec. 2011. Patterns of temporal variation in online
        media. In <em><em>WSDM</em></em> . ACM, 177–186.</li>
        <li id="BibPLXBIB0012" label="[12]">Yin Zhu, Xiao Wang,
        Erheng Zhong, Nanthan&nbsp;N. Liu, He Li, and Qiang Yang.
        2012. Discovering Spammers in Social Networks. In
        <em><em>AAAI</em></em> . 171–177.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3186930">https://doi.org/10.1145/3184558.3186930</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
