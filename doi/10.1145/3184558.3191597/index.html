<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Characterising Dataset Search Queries</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Characterising Dataset Search Queries</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Emilia</span>      <span class="surName">Kacprzak</span>     University of Southampton, The Open Data Institute, London, UK, <a href="mailto:emilia.kacprzak@theodi.org">emilia.kacprzak@theodi.org</a>     </div>     <div class="author">     <span class="givenName">Laura</span>      <span class="surName">Koesten</span>     University of Southampton, The Open Data Institute, London, UK, <a href="mailto:laura.koesten@theodi.org">laura.koesten@theodi.org</a>     </div>     <div class="author">     <span class="givenName">Jeni</span>      <span class="surName">Tennison</span>     The Open Data Institute, London, UK, <a href="mailto:jeni@theodi.org">jeni@theodi.org</a>     </div>     <div class="author">     <span class="givenName">Elena</span>      <span class="surName">Simperl</span>     University of Southampton, Southampton, UK, <a href="mailto:e.simperl@soton.ac.uk">e.simperl@soton.ac.uk</a>     </div>                     </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3191597" target="_blank">https://doi.org/10.1145/3184558.3191597</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April </p>    </div>    <div class="abstract">     <p>     <small>The amount of data generated and published on the web is increasing rapidly, but search for structured data on the web still presents challenges. In this paper we explore dataset search by analysing queries specifically generated for this work through a crowdsourcing experiment and comparing them to a search log analysis of queries on data portals. The change in search environment together with the task we gave people altered the generated queries. We found that queries issued in our experiment were much longer than search queries for datasets on data portals. They further contained seven times more mentions of geospatial and of temporal information and are more likely to be structured as questions. These insights can be used to tailor search functionalities to the particular information needs and characteristics of dataset search.</small>     </p>    </div>    <div class="CCSconcepts">     <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Query log analysis;</strong></small> </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>dataset search</small>, </span>     <span class="keyword">      <small> search log analysis</small>, </span>     <span class="keyword">      <small> query generation</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Emilia Kacprzak, Laura Koesten, Jeni Tennison, and Elena Simperl. . Characterising Dataset Search Queries. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 5 Pages. <a href="https://doi.org/10.1145/3184558.3191597" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3191597</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>More and more data generated by individuals, industry and governments can be accessed online. Searching for structured data on the web is becoming part of people&#x0027;s work activities. However, data search still presents challenges to many people using data for their work tasks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>]. By data we mean sets of facts or figures that are presented in a structured form. These are typically grouped into datasets, many of which are published on the web, for instance in data catalogues available on the web. This work is concerned with how people search for datasets online. This is typically done through data portals or via conventional web search engines. The latter are not ideal for data search, as they have been designed primarily for documents, not data [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>]. While we know a lot about general web search from literature we still know relatively little about how people search for datasets online. In a prior search log analysis of open data portals we identified differences in search queries for documents as opposed to search queries for datasets [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>]. However, we assume that the analysed queries do not necessarily reflect how people would search for data in an ideal search system. People often do not expect their search activity for data to be successful, as they are aware of the limited performance of search functionalities for data [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>]. We further believe the user experience of searching for documents on the web, as well as the interface (e.g. sizing and design of the search box) influence how people search for data. This work aims to better understand the specific characteristics of dataset search scenarios to inform the design of future search functionalities tailored to structured data. We analysed a set of queries for data (<em>crowd queries</em>) which were generated using human computation. We asked crowd workers to generate queries based on a sample of free form text requests for data. We compare these queries to those used to search data portals [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>] to understand whether the change of search environment results in different characteristics of queries.</p>    <p>We looked at the following research questions: (1) How do search queries for data within a data portal differ from those in a less constrained environment? (2) How are search queries for data that have been issued in a less constrained environment structured?</p>    <p>We found that queries generated in a less constrained environment are much longer and contain seven times more temporal and geospatial information than queries issued to data portals [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>]. This indicates these information types as important and distinct factors that are of particular interest in dataset search. We further found a larger prevalence of file types, dataset types and numbers represented in the queries. We believe a better understanding of what dataset search queries look like is needed to inform interfaces and search functionalities for the unique characteristics of dataset search. This includes the importance of indexing temporal or geospatial information or specific presentation modes for search results that are tailored to dataset search.</p>   </section>   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>     </div>    </header>    <p>     <strong>Data search</strong>Searching for data still presents challenges, even for data professionals, and is far from providing the same user experience we are used to in web search [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>]. Existing techniques used in general web search cannot be directly applied to searching for data [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>]. In a prior study analysing the search logs of four governmental open data portals [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>] we discussed the specific characteristics of queries for datasets and compared to general web search queries. General web search queries have evolved over time in parallel with advances in search functionalities. Data search is similar in its characteristics to web search around 15 years ago [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>] (e.g. queries have been steadily growing in length over time [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>]). We assume different information types constitute for different search contexts and influence the way people query. Dataset retrieval on the web is still a relatively immature research area. This study focuses on the characteristics of query formulation for structured&#x00A0;datasets. Structured data, means data that is organised explicitly - such as in spreadsheets, web tables, databases or&#x00A0;maps.</p>    <p>     <strong>Search in different environments</strong>Vertical search is search that targets a specific subset of online content (which could be distinct based on its topic, data type or its context). The limited scope of relevant resources allows for greater precision, more complex schemas or ontologies to match specific search scenarios; and so tends to support more complex user tasks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>]. Verticals include for instance people search&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>], email search [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>], research publication search [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>] or digital libraries &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>]. Each vertical has a clear distinction from other verticals and from general web search. For instance, email search is an example in which [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>] noticed that when searching, users know the precise attributes of a resource they are looking for. The key differences to general web search are that the set of emails is a personal set unique for each user and there is additional metadata (e.g. sender address, subject or time stamp) which can help both organising and searching through the results. In search for research publications [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>] argue that web search could be improved for this vertical by using temporal information attached to each publication. For instance, algorithms like PageRank and HITS calculate the relevance of each resource and favour older resources over newer ones in their ranking. In publication search, the reputation of the resource, in addition to its content relevance, citation count and reputation of its authors and journals are more influential. Dataset search can be seen as a separate vertical due to the specific characteristics of the information source. Kunze et al. have recently introduced the concept of <em>dataset retrieval</em>, as a branch of information retrieval applied to data instead of documents focused on determining the most relevant datasets according to a user query [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>]. Their focus was on a specific data type - RDF datasets - however, we believe that this applies to structured data independent of its format.</p>    <p>     <strong>Query analysis</strong>The first query log analysis on the web was made for the Altavista search engine&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>], and the technique has been used since to study several aspects of web search (see&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>] for a survey). Broder et al. report a <em>classification of query types</em> in their taxonomy of web search queries which is based on user needs [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>]. This includes informational, navigational and transactional queries. In dataset search the information need is &#x2018;finding data&#x2019; and can therefore be seen as predominantly informational. Various metrics for analysing queries were developed in the area of general web search several of which can apply to data&#x00A0;search.</p>    <p>     <em>Query Length &#x0026; Distribution</em> are the most commonly presented statistics and are part of the analysis in our study.</p>    <p>     <em>Query Structure</em> describes the prevalence of e.g. questions, operators, and whether the query is composite or non-composite [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>], which is mostly relevant for long queries. Question queries are identified by starting words that indicate questions. Operators are boolean operators: AND, OR and NOT or special web search operators eg. url, site or filetype. As shown in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>], who report a transaction log analysis of nine search engines, results of different search log analyses are not directly comparable. This means that even within web search it is problematic to compare metrics of different search log analyses, we assume that between different information sources (e.g. textual documents versus structured datasets) it might be even more&#x00A0;so.</p>   </section>   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Experiment</h2>     </div>    </header>    <p>     <strong>Data</strong>We analysed a set of search queries generated in this work (<em>crowd queries</em>) and compared them with queries from a dataset search log analysis [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>] which analysed queries from four open data portals referred to as <em>portal queries</em>. <em>Crowd queries</em> were generated in a crowdsourcing experiment based on data requests to the UK Government Open Data portal<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> and are available in a Github repository<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>. These are formal natural language requests for data that users could not find on the platform, submitted via a semi-structured contact form and available as open data<a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>. An example of an excerpt of a data request is <em>&#x201D;Request annual return data on total numbers of Sheep &#x0026; Lambs and Cattle &#x0026; Calves in the following two North Yorkshire parishes from 1986 to the latest available date: for Malham Moor Parish and for Buckden Parish&#x201D;</em>. We randomly selected 10% (50 requests) of all the openly published data requests, and manually checked for their understandability concerning language and domain specific terminology - we then excluded requests which were potentially difficult to understand and replaced them with other randomly selected requests.</p>    <p>In our experiments we used the title and the description of the request. For each data request we generated 10 queries through human computation. After excluding spam answers (51 of all queries, which were manually detected) the set contained 449 queries in total. An example of a resulting query is <em>&#x201D;Businesses in Yorkshire that employ over 1000 workers&#x201D;</em>.</p>    <p>     <strong>Design</strong>We conducted a crowdsourcing experiment to generate <em>crowd queries</em>. Participants were users of the crowdsourcing platform CrowdFlower. As the data requests are unstructured English text that could potentially be difficult to understand for people with low English language skills, we limited the experiment to workers in native-English speaking countries; and we restricted the worker pool to a smaller group of more experienced, higher accuracy contributors on the platform. We included 5 short qualification questions, assessing basic reading, reasoning and data literacy skills. Workers were paid <font style="normal">&#x0024;</font>0.15 to generate each search query that they considered suitable for a single data request.</p>    <p>Our open-ended text creation task was formulated as: <em>We ask you to write a search query which you think would return the requested dataset from a data search engine</em>. The workers were shown an overview of the task, step-by-step instructions, and a sample data request with examples of corresponding queries. The output was a search query constrained to be between one and twenty words in length. To minimise &#x201D;spam&#x201D; answers we prevented pasting of content and validated each word from the query against an English language dictionary, requiring an 80% matching threshold for a query to be accepted. We also rejected answers containing the same word three or more times. Participants were not instructed to generate their queries in a particular structure; however, they were shown five examples, with various compositions of keywords, and a question. The minimum time permitted to generate a single query was 1 minute to allow time for detailed reading of the data requests. No personal data was collected. Despite the workers&#x2019; lack of in-depth understanding of the information need that is represented in the data request we believe that the resulting queries give us valuable insights into the necessary complexity and characteristics of queries for data.</p>   </section>   <section id="sec-8">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Results</h2>     </div>    </header>    <p>     <strong>Analysis</strong>Statistics of the queries analysed include: <em>Query length</em> including average query length and distribution for both sets of queries; <em>Query characteristics</em>: queries containing keywords describing: location; time frame; file and dataset type; numbers; abbreviations (described in detail in Table <a class="tbl" href="#tab1">1</a>); and <em>Question queries</em>: to recognise question queries we counted queries containing the words: <em>what</em>, <em>who</em>, <em>where</em>, <em>when</em>, <em>why</em>, <em>how</em>, <em>which</em>, <em>whom</em>, <em>whose</em>, <em>whether</em>, <em>did</em>, <em>do</em>, <em>does</em>, <em>am</em>, <em>are</em>, <em>is</em>, <em>will</em>, <em>have</em>, <em>has</em>, as in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>]. In this section we present the results of our analysis of the <em>crowd queries</em> created in this study and compare these to the portal queries presented in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>].</p>    <p>     <strong>Query Length</strong>The majority of portal queries have been reported to be between one and three words, with an average of 2.03 words per query. We found <em>crowd queries</em> to be significantly longer than portal queries with an average of 9.16 words per query. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191597/images/www18companion-336-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Percentage of queries according to number of words in them</span>     </div>     </figure> Figure <a class="fig" href="#fig1">1</a> shows an overview of the percentage of queries by number of words per query, for both the crowd and the portal queries reported in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>]. We can see single word queries represent almost half of the entire corpus of the portal queries whereas the <em>crowd queries</em> had a minimum of 2 words, with the most queries between 7 to 11 words. We believe this difference in query length indicates that the portal queries might not represent realistic search strategies, but rather expose limitations of current dataset search. Users do not expect search functionalities to fulfil their information need when searching for data, which can lead to underspecified queries&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>].</p>    <p>     <strong>Query Types -</strong> In this work we analysed the same metrics as in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>], which include geospatial, temporal, numerical information or appearances of file type and acronyms in the query. Table <a class="tbl" href="#tab1">1</a> summarises the percentage of queries for each of the metrics. Geospatial information was much more prevalent in the <em>crowd queries</em>: 36.1% of those contained a location in comparison to only 5.4% of portal queries and 12.01% in general web search [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>]. In contrast to searching on a data portal, which is often tied to a specfific location or can have national boundaries attached to it, our experiment did not specify a particular location and was so less constrained from a geospatial point of view. Participants may have compensated for this by specifying location keywords. However, the high number of location bound keywords (36.1%) may simply emphasise the high importance of location in data search. Temporal information was seven times more popular in the <em>crowd queries</em> 49.2% in contrast to the results reported for portal queries (7.29%) and 32 times more prevalent than for general web search (1.5% [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>]). Users indicate interest in different aspects of temporal information: date of data creation, the frequency of data releases, updates and time frames described in the data. File and dataset types (such as queries containing <em>csv</em> or <em>json</em>, etc as can be seen in Table <a class="tbl" href="#tab1">1</a> were much more popular within <em>crowd queries</em> (49%) in comparison to the portal queries for which file types were reported for 6.25% of the queries. This could be due to filtering options over file types on the data portals in which the portal queries were recorded. Crowd workers could further be biased in their creation of queries in thinking they need to add the word <em>data</em> to a query for data (as would be the case on general web search). Excluding the word data from this analysis we found 26.95% queries including common file types, as can be seen in Table&#x00A0;<a class="tbl" href="#tab1">1</a>. The percentage of queries containing numbers, that were not temporal information, were 5.57% and there were no queries containing only numbers. These results are similar to those reported for portal queries (5.23%) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>]. Numbers in queries represent mainly sample sizes or desired constraints to the data, such as: <em>Police spending over &#x00A3;500 local data</em>. We further report the percentage of queries including abbreviations. We found 2.23% in the <em>crowd queries</em> included abbreviations; in comparison to 5.11% reported for the portal queries. Abbreviations were mostly used when they appeared in the data request that the query was based&#x00A0;on.</p>    <div class="table-responsive" id="tab1">     <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Definition of query characterisation metrics. Percentage of queries for both, portal queries as reported in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0009">9</a>] and crowd queries of this study</span>     </div>     <table class="table">     <tbody>      <tr>       <td style="text-align:left;">Metric - Definition</td>       <td style="text-align:left;">% portal</td>       <td style="text-align:left;">% crowd</td>      </tr>      <tr>       <td style="text-align:left;">        <strong>Geospatial</strong> - the name of a city or geographical area (either town, city, county, region or countries)</td>       <td style="text-align:left;">5.4%</td>       <td style="text-align:left;">36.1%</td>      </tr>      <tr>       <td style="text-align:left;">        <strong>Temporal</strong> - years (1000 to 2017), names of months, days of a week and the words <em>week(ly)</em>, <em>year(ly)</em>, <em>month(ly)</em>, <em>day(ly)</em>, <em>date</em>, <em>time</em> and <em>decade</em>       </td>       <td style="text-align:left;">7.3%</td>       <td style="text-align:left;">49.2%</td>      </tr>      <tr>       <td style="text-align:left;">        <strong>File and dataset type</strong> - file types: <em>csv, pdf, xls, json, wfs, zip, html, api</em> and keywords denoting a type of dataset: <em>data, dataset, average, index, graph, table, database, indice, rate, stat</em>       </td>       <td style="text-align:left;">6.3%</td>       <td style="text-align:left;">49%</td>      </tr>      <tr>       <td style="text-align:left;">        <strong>Numbers</strong> - the number of queries including numbers excluding those indicating time frames</td>       <td style="text-align:left;">5.2%</td>       <td style="text-align:left;">5.6%</td>      </tr>      <tr>       <td style="text-align:left;">        <strong>Only numbers</strong> - queries that contain only numbers</td>       <td style="text-align:left;">0.4%</td>       <td style="text-align:left;">0%</td>      </tr>     </tbody>     </table>    </div>    <p>     <strong>Question queries</strong>Formulating queries as questions is increasingly common in web search, thanks to advances in speech recognition and conversational search interfaces [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>]. In 2009, 7.49% queries were questions in a study on general web search [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>]. Less than 1% of the portal queries are structured as questions [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>]. The low number of question queries in dataset search might be due to the lack of question-answering capabilities of the dataset search functionalities. We found 9.35% of <em>crowd queries</em> were questions. This may be due to the larger search box used in our experiment; or due to a different conceptualisation of data opposed to documents.</p>   </section>   <section id="sec-9">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Discussion and limitations</h2>     </div>    </header>    <p>We found that queries for data differ between those issued on a data portal and those created in an environment with fewer constraints. The queries generated in this study were longer and included approximately seven times more temporal and geospatial information. The higher importance of these information types has been recognised in literature[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>]. Structurally we found the <em>crowd queries</em> to include a higher percentage of questions and 4 times as many queries included a specific file type or format. The length of these queries suggest that the information need expressed in the data requests are complex; based on literature we believe this is typical for data centric information needs [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>]. In comparison, the portal queries were short and underspecified. Although in both of the query sets people were looking for data, we believe that neither set necessarily represents how people would like to search for data. These findings emphasise a large design space for data search environments; one possible direction being encouraging users to issue longer queries, for instance by providing larger search boxes or suggesting additional keywords. Search log analyses can illustrate the specific characteristics of a given search vertical. We know that queries on portals are underspecified, but this work shows that when asked to search outside of a search environment people issue much longer queries which correspond to complex information needs for data. The high prevalence of geospatial or temporal information in the <em>crowd queries</em> should inform the design of dataset search systems, for instance by allowing users to search by specific locations or time frames. It could further indicate a need to extend existing metadata standards to include these two types of information, which could then be exploited by search functionalities. We believe new retrieval models for dataset search, that take the unique characteristics of this information source into account, are needed to make data on the web more discoverable.</p>    <p>     <strong>Limitations</strong> As with any experiment using human computation, instructions and the experiment design influence the outcome. We tried to take into account that workers might not know what <em>data</em> is and used a spreadsheet as well as a product search analogy in the instructions. We had no control of the workers prior experience and their conceptual models of data. However, this is a natural limitation of such experiments. While we acknowledge that the <em>crowd queries</em> are created in an artificial setting, without the workers own naturalistic information need, we believe that they give us relevant insights into how queries for data could potentially look in the future. We acknowledge that neither query set can be a representative reflection of how people would search for data in an &#x201D;ideal&#x201D; system. However the results of this work can be seen as an approximation that can inform further&#x00A0;research.</p>   </section>   <section id="sec-10">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Conclusion &#x0026; Future Work</h2>     </div>    </header>    <p>In this work we present a search log analysis of queries generated through crowdsourcing using requests for data from an open data portal to describe an information need. We compare our results to [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>], in which we analysed queries explicitly issued to find data. Our findings indicate that dataset search logs do not fully represent the behaviour of users searching for data, but rather uncover the limitations of current search functionalities. The differences of the two sets of queries indicate the need for further research to deepen our understanding of how people search for data. This could include an additional analysis of queries generated by data professionals to understand the differences and commonalities of queries issued by people with different prior knowledge about data. Future studies could include a more in-depth analysis of user behaviour in dataset search, taking into account search sessions and query refinements together with a qualitative component to better understand user needs. This can enable us to develop search functionalities for data that are tailored to user needs as well as to the particular characteristics of dataset search.</p>    <p>     <strong>Acknowledgements</strong>This project is supported by the EU H2020 program: Marie Sk&#x0142;odowska-Curie grant agreement No. 642795</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Qingyao Ai, Susan&#x00A0;T. Dumais, Nick Craswell, and Daniel&#x00A0;J. Liebling. 2017. Characterizing Email Search using Large-scale Behavioral Logs and Surveys. In <em>      <em>Proceedings of the 26th International Conference on World Wide Web, WWW</em>     </em>. 1511&#x2013;1520. <a class="link-inline force-break" href="https://doi.org/10.1145/3038912.3052615"      target="_blank">https://doi.org/10.1145/3038912.3052615</a></li>     <li id="BibPLXBIB0002" label="[2]">Michael Bendersky and W.&#x00A0;Bruce Croft. 2009. Analysis of Long Queries in a Large Scale Search Log. In <em>      <em>Proceedings of the 2009 Workshop on Web Search Click Data</em>     </em>. ACM, 8&#x2013;14. <a class="link-inline force-break" href="https://doi.org/10.1145/1507509.1507511"      target="_blank">https://doi.org/10.1145/1507509.1507511</a></li>     <li id="BibPLXBIB0003" label="[3]">Andrei Broder. 2002. A Taxonomy of Web Search. <em>      <em>SIGIR Forum</em>     </em>36, 2 (2002), 3&#x2013;10. <a class="link-inline force-break" href="https://doi.org/10.1145/792550.792552"      target="_blank">https://doi.org/10.1145/792550.792552</a></li>     <li id="BibPLXBIB0004" label="[4]">Michael&#x00A0;J. Cafarella, Alon Halevy, and Jayant Madhavan. 2011. Structured Data on the Web. <em>      <em>Commun. ACM</em>     </em>54, 2 (2011), 72&#x2013;79. <a class="link-inline force-break" href="https://doi.org/10.1145/1897816.1897839"      target="_blank">https://doi.org/10.1145/1897816.1897839</a></li>     <li id="BibPLXBIB0005" label="[5]">Qingqing Gan, Josh Attenberg, Alexander Markowetz, and Torsten Suel. 2008. Analysis of Geographic Queries in a Search Engine Log. In <em>      <em>Proceedings of the First International Workshop on Location and the Web</em>     </em>. ACM, 49&#x2013;56. <a class="link-inline force-break" href="https://doi.org/10.1145/1367798.1367806"      target="_blank">https://doi.org/10.1145/1367798.1367806</a></li>     <li id="BibPLXBIB0006" label="[6]">Bernard&#x00A0;J. Jansen and Amanda Spink. 2006. How Are We Searching the World Wide Web?: A Comparison of Nine Search Engine Transaction Logs. <em>      <em>Information Processing and Management</em>     </em>42, 1 (2006), 248&#x2013;263. <a class="link-inline force-break"      href="https://doi.org/10.1016/j.ipm.2004.10.007"      target="_blank">https://doi.org/10.1016/j.ipm.2004.10.007</a></li>     <li id="BibPLXBIB0007" label="[7]">Daxin Jiang, Jian Pei, and Hang Li. 2013. Mining Search and Browse Logs for Web Search: A Survey. <em>      <em>ACM Transactions on Intelligent Systems and Technology</em>     </em>4, 4, Article 57 (2013), 37&#x00A0;pages. <a class="link-inline force-break" href="https://doi.org/10.1145/2508037.2508038"      target="_blank">https://doi.org/10.1145/2508037.2508038</a></li>     <li id="BibPLXBIB0008" label="[8]">Steve Jones, Sally&#x00A0;Jo Cunningham, Rodger McNab, and Stefan Boddie. 2000. A transaction log analysis of a digital library. <em>      <em>International Journal on Digital Libraries</em>     </em>3, 2 (2000), 152&#x2013;169. <a class="link-inline force-break" href="https://doi.org/10.1007/s007999900022"      target="_blank">https://doi.org/10.1007/s007999900022</a></li>     <li id="BibPLXBIB0009" label="[9]">Emilia Kacprzak, Laura&#x00A0;M. Koesten, Luis-Daniel Ib&#x00E1;&#x00F1;ez, Elena Simperl, and Jeni Tennison. 2017. <em>      <em>A Query Log Analysis of Dataset Search</em>     </em>. Springer International Publishing, Cham, 429&#x2013;436. <a class="link-inline force-break"      href="https://doi.org/10.1007/978-3-319-60131-1_29"      target="_blank">https://doi.org/10.1007/978-3-319-60131-1_29</a></li>     <li id="BibPLXBIB0010" label="[10]">Dagmar Kern and Brigitte Mathiak. 2015. Are There Any Differences in Data Set Retrieval Compared to Well-Known Literature Retrieval?. In <em>      <em>19th International Conference on Theory and Practice of Digital Libraries, TPDL</em>     </em>. 197&#x2013;208. <a class="link-inline force-break"      href="https://doi.org/10.1007/978-3-319-24592-8_15"      target="_blank">https://doi.org/10.1007/978-3-319-24592-8_15</a></li>     <li id="BibPLXBIB0011" label="[11]">Laura&#x00A0;M. Koesten, Emilia Kacprzak, Jenifer F.&#x00A0;A. Tennison, and Elena Simperl. 2017. The Trials and Tribulations of Working with Structured Data - a Study on Information Seeking Behaviour. In <em>      <em>Proceedings of Conference on Human Factors in Computing Systems</em>     </em>(<em>CHI &#x2019;17</em>). ACM, New York, NY, USA, 1277&#x2013;1289. <a class="link-inline force-break" href="https://doi.org/10.1145/3025453.3025838"      target="_blank">https://doi.org/10.1145/3025453.3025838</a></li>     <li id="BibPLXBIB0012" label="[12]">Sven&#x00A0;R. Kunze and Soren Auer. 2013. Dataset Retrieval. In <em>      <em>2013 IEEE Seventh International Conference on Semantic Computing</em>     </em>. <a class="link-inline force-break" href="https://doi.org/10.1109/ICSC.2013.12"      target="_blank">https://doi.org/10.1109/ICSC.2013.12</a></li>     <li id="BibPLXBIB0013" label="[13]">Xin Li, Bing Liu, and Philip&#x00A0;S. Yu. 2010. <em>      <em>Time Sensitive Ranking with Application to Publication Search</em>     </em>. Springer, New York, 187&#x2013;209. <a class="link-inline force-break"      href="https://doi.org/10.1007/978-1-4419-6515-8_7"      target="_blank">https://doi.org/10.1007/978-1-4419-6515-8_7</a></li>     <li id="BibPLXBIB0014" label="[14]">S&#x00E9;rgio Nunes, Cristina Ribeiro, and Gabriel David. 2008. Use of temporal expressions in web search. In <em>      <em>European Conference on Information Retrieval</em>     </em>. Springer, 580&#x2013;584.</li>     <li id="BibPLXBIB0015" label="[15]">Craig Silverstein, Hannes Marais, Monika Henzinger, and Michael Moricz. 1999. Analysis of a very large web search engine query log. <em>      <em>ACM SIGIR Forum</em>     </em>33, 1 (1999), 6&#x2013;12.</li>     <li id="BibPLXBIB0016" label="[16]">Amanda Spink, Dietmar Wolfram, Major&#x00A0;BJ Jansen, and Tefko Saracevic. 2001. Searching the web: The public and their queries. <em>      <em>Journal of the American society for information science and technology</em>     </em>52, 3 (2001), 226&#x2013;234.</li>     <li id="BibPLXBIB0017" label="[17]">Mona Taghavi, Ahmed Patel, Nikita Schmidt, Christopher Wills, and Yiqi Tew. 2012. An analysis of web proxy logs with query distribution pattern approach for search engines. <em>      <em>Computer Standards &#x0026; Interfaces</em>     </em>34, 1 (2012), 162&#x2013;170.</li>     <li id="BibPLXBIB0018" label="[18]">Wouter Weerkamp, Richard Berendsen, Bogomil Kovachev, Edgar Meij, Krisztian Balog, and Maarten de Rijke. 2011. People Searching for People: Analysis of a People Search Engine Log. In <em>      <em>Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval</em>     </em>.</li>     <li id="BibPLXBIB0019" label="[19]">Ryen&#x00A0;W. White, Matthew Richardson, and Wen-tau Yih. 2015. Questions vs. Queries in Informational Search Tasks. In <em>      <em>Proceedings of the 24th International Conference on World Wide Web</em>     </em>(<em>WWW &#x2019;15 Companion</em>). ACM, New York, NY, USA, 135&#x2013;136. <a class="link-inline force-break" href="https://doi.org/10.1145/2740908.2742769"      target="_blank">https://doi.org/10.1145/2740908.2742769</a></li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class="link-inline force-break" href="http://data.gov.uk">data.gov.uk</a>   </p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break"     href="https://github.com/chabrowa/data-requests-query-dataset">https://github.com/chabrowa/data-requests-query-dataset</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a><a class="link-inline force-break"     href="https://data.gov.uk/dataset/data-requests-at-data-gov-uk">https://data.gov.uk/dataset/data-requests-at-data-gov-uk</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; ; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3191597">https://doi.org/10.1145/3184558.3191597</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
