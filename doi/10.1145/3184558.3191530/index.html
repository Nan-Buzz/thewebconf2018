<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Understanding Types of Cyberbullying in an Anonymous Messaging Application</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../data/dl.acm.org/pubs/lib/css/main.css"/><script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../data/dl.acm.org/pubs/lib/js/MathJax.TeX-AMS_CHTML.js"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Understanding Types of Cyberbullying in an Anonymous Messaging Application</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Arpita</span>      <span class="surName">Chakraborty</span>,     SUNY Binghamton, <a href="mailto:achakra4@binghamton.edu">achakra4@binghamton.edu</a>     </div>     <div class="author">     <span class="givenName">Yue</span>      <span class="surName">Zhang</span>,     SUNY Binghamton, <a href="mailto:yzhan202@binghamton.edu">yzhan202@binghamton.edu</a>     </div>     <div class="author">     <span class="givenName">Arti</span>      <span class="surName">Ramesh</span>,     SUNY Binghamton, <a href="mailto:artir@binghamton.edu">artir@binghamton.edu</a>     </div>                 </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3191530" target="_blank">https://doi.org/10.1145/3184558.3191530</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>The possibility of anonymity and lack of effective ways to identify inappropriate messages have resulted in a significant amount of online interaction data that attempt to harass, bully, or offend the recipient. In this work, we perform a preliminary linguistic study on messages exchanged using one such popular web/smartphone application&#x2014;<em>Sarahah</em>, that allows friends to exchange messages anonymously. Since messages exchanged via Sarahah are private, we collect them when the recipient shares it on Twitter. We then perform an analysis of the different kinds of messages exchanged through this application. Our linguistic analysis reveals that a significant number of these messages (<span class="inline-equation"><span class="tex">$\sim 20\%$</span>      </span>) include inappropriate, hurtful, or profane language intended to embarrass, offend, or bully the recipient. Our analysis helps in understanding the different ways in which anonymous message exchange platforms are used and the different types of bullying present in such exchanges.</small>     </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>cyberbullying types</small>, </span>     <span class="keyword">      <small> topic models</small>, </span>     <span class="keyword">      <small> social media analysis</small>, </span>     <span class="keyword">      <small> anonymous message exchanges</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Arpita Chakraborty, Yue Zhang, and Arti Ramesh. 2018. Understanding Types of Cyberbullying in an Anonymous Messaging Application. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France.</em> ACM, New York, NY, USA, 5 Pages. <a href="https://doi.org/10.1145/3184558.3191530" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3191530</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>Recent times have witnessed a stupendous growth in online interactions. A significant portion of online interaction data is in the form of text such as posts on social networks, messages, and comments. With the proliferation of online interactions, there is also a corresponding increase in concern surrounding the nature of this content. Textual interactions that signify disturbing and negative phenomena such as online harassment, cyberbullying, cyber threats, stalking, and hatred are on the rise [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>]. This detrimental online behavior can have significant traumatic effects on the individual experiencing this and can lead to severe psychological problems [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>]. Furthermore, online data tends to be digitally preserved for a considerable length of time, aggravating the effect.</p>    <p>Anonymity has been shown to be a contributing factor in cyber harassment and bullying. Previous work on <em>Ask.fm</em> and <em>Yik-Yak</em> have shown that the possibility of anonymity significantly propels the number of cyberbullying messages [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>]. In this work, we focus on one such anonymous message exchange application that topped the download charts in the period between July&#x2014;September, 2017 on App Store: <em>Sarahah</em>. The Sarahah mobile/web application can be added to other social networks such as Twitter and Facebook, hence allowing users to send anonymous messages to their friends in the network. Though the app was originally designed as a platform for exchanging anonymous messages, it soon transformed into a breeding ground for hate [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>]. Most previous work on cyber bullying has been in settings such as Ask.fm and Youtube, where the people exchanging bullying or hateful comments need not necessarily know each other at a personal level. Our analysis especially brings forth the amount of negative content in messages exchanged between &#x201C;friends&#x201D;, making it more personal than other instances of bullying.</p>    <p>In this work, we perform an initial study on the types of messages exchanged through the <em>Sarahah</em> application on the Twitter social network. Since we don&#x0027;t have direct access to this data through Sarahah, we collect it via Twitter, when the recipient shares the Sarahah message on their Twitter feed, sometimes along with a brief response to the message. Our dataset contains messages exchanged between August&#x2014;October, 2017, which is when the application&#x0027;s popularity peaked. While the sender remains unknown in this setting, the recipient is known, as he/she shares this message on Twitter. As only a portion of messages exchanged via the Sarahah platform are potentially shared by the recipients on Twitter, this data may not represent all the messages exchanged through Sarahah and can potentially be biased because of its collection using the Twitter search API [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>]. Despite these possible biases, the unique characteristics of this data (anonymous sender, exchanged between friends on a social network, and presence of recipients&#x2019; responses) make this an important source of information to understand the different kinds of bullying present in online interactions.</p>    <p>We leverage topic modeling (also known as Latent Dirichlet Allocation (LDA)) to perform a linguistic analysis on the different types of conversations and bullying categories present in this data. We first identify the LDA topics that are related to bullying using the top words in each of these topics. By filtering the Sarahah messages in the LDA topics that are related to bullying, we observe that 20% of these messages fall in the bullying topic categories. We also observe that most bullying events happen when an anonymous sender shares specific opinions/confesses about their true feelings toward the recipient or asks embarrassing personal questions. Our analysis paves way for understanding the different types of conversations and bullying topic categories in anonymous message exchanges.</p>   </section>   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>     </div>    </header>    <p>Detecting and understanding bullying on social media has received considerable interest in the recent years. Corcoran et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>] and Hosseinmardi et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>] draw attention to the broader issue of cyber aggression rather than cyberbullying. Hosseinmardi et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>] identify media sessions on Instagram that have at least one profane word in their comments by users other than the profile owner.</p>    <p>Raisi et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>] propose a participant-vocabulary consistency model for identifying the instigators and victims of bullying in a social network and simultaneously building a bullying vocabulary by starting with a corpus of social interactions and a seed dictionary of bullying indicators. They evaluate the model on data from Twitter and Ask.fm and show that the proposed method can detect new bullying vocabulary as well as victims and bullies. Several work consider social interaction features along with textual features to detect cyberbullying [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>]. Bigelow et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>] use latent semantic indexing to detect cyberbullying. There is also previous work on detecting abusive and hateful speech targeting specific groups including ethnicity, origin, religion, gender, sexual orientation and physical appearance [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>]. Dinakar et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>] show that individual classifiers perform better than multi-class classifiers for this problem on a Youtube comments dataset. Li et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>] analyze the negative and positive sense of the words on Instagram and Ask.fm networks. Margono et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>] analyze bullying patterns in Indonesia on Twitter. Whittaker et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>] examine the prevalence of cyberbullying in college students. Bellmore et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>] and Tokunaga et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>] study the socio-psychological issues of bullying in social media data.</p>    <p>There is also previous work that do not especially focus on cyberbullying or abusive language, but on similar problems. Nguyen et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>] study the <em>k</em>-suspector problem aiming to identify the <em>k</em> most suspected users in online social network from the set of victims who are already influenced by the misinformation. Mahendiran et al. propose a novel unsupervised learning algorithm which builds dynamic vocabularies using probabilistic soft logic in order to understand the true membership within the social group and capturing the dynamic trends and forecasting specific to election campaigns from eight different countries [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>]. Bifet et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>] propose a sliding window Kappa statistic for mining opinions and analyzing sentiment in evolving Twitter data streams.</p>   </section>   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Data</h2>     </div>    </header>    <p>In this work, we focus on data from a recent anonymous mobile application, <em>Sarahah</em>. It entered the US Apple Store in June 13, 2017 and gradually spread out to Canada, India, and a few other countries. The popularity of the application spiked after an update that allowed people to share Sarahah messages was launched by Snapchat on July 5, 2017. Gradually, it became the top rated application in App Store leaving behind all popular social media applications such as Twitter, Facebook, and Snapchat. While this application was originally created to exchange anonymous messages, it soon became a breeding ground for hate and a platform for cyberbullying as users started posting threatening, hurtful, profane, and pornographic messages [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>].</p>    <p>In this paper, we present analysis on data collected from 30<sup>     <em>th</em>     </sup> August, 2017 to 15<sup>     <em>th</em>     </sup> October, 2017, which coincides with the peak popularity period of Sarahah. We collect messages exchanged using Sarahah on Twitter by searching for images with the hashtag <em>#Sarahah</em> using the Twitter search API [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>]. Since Twitter allows you to only extract tweets posted in the last week, we collect at one-week intervals during the specified period. We also extract Sarahah messages by crawling specific users&#x2019; Twitter accounts. Figure <a class="fig" href="#fig1">1</a>(a) shows an example of a message exchanged through <em>Sarahah</em>. Since the messages exchanged using Sarahah are in the form of images, we use Google&#x0027;s optical character recognition software to extract text from the images [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>]. The extracted data has three components: i) the textual message exchanged using Sarahah, ii) user&#x0027;s reaction to the message when the user shares this message on Twitter, and iii) other user-related information extracted from user&#x0027;s profile. <figure id="fig1">     <img src="../../../data/deliveryimages.acm.org/10.1145/3200000/3191530/images/www18companion-269-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Figures showing an example message from Sarahah (left) and statistics of different languages in our data (right).</span>     </div>     </figure>    </p>    <p>Since Sarahah messages are generally from friends, they tend to be also in languages other than English. In our extracted dataset, we found the presence of several languages including German, French, Afrikaans, Swahili, Interlingua, Finnish, Somali, Czech, Tagalog, English, Romanian, Moldavian, Moldovan, Croatian, Panish, Norwegian, Latvian, Welsh, Portuguese, Catalan, Danish, Swedish, Estonian, Dutch, Slovenian, Italian, Albanian, Hungarian, Polish, Slovak, Turkish, Lithuanian, Vietnamese, Hindi, and Tamil. English remains the most popular language in our dataset. We report the distribution of messages across the top <span class="inline-equation"><span class="tex">$50 \%$</span>     </span> languages other than English in Figure <a class="fig" href="#fig1">1</a>(b). We use Google&#x0027;s language detection library <em>langdetect</em> to detect the language and convert the message and users&#x2019; response to English for our analysis [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>]. Since we follow a bag-of-words approach, translation errors have little effect on our analysis as they tend to occur mostly in the sentence construction.</p>    <p>In all, we collect 82,193 Sarahah messages and corresponding user reactions. Removing duplicates and empty messages, we have 76,278 messages and corresponding user responses in our dataset. We perform standard NLP preprocessing techniques of stop-word removal, tokenization and stemming using porter stemmer on the messages and responses.</p>    <p>Table <a class="tbl" href="#tab1">1</a> and Figure <a class="fig" href="#fig1">1</a>(a) give some examples of messages exchanged using <em>Sarahah</em> and corresponding user reactions. The first message is a sexually abusive message, the second is a casual message containing some sexually offensive words, and the third message expresses hate towards the recipient. The user reactions corresponding to these messages give some of the different ways in which people respond to offensive messages. From the first and second responses, it is unclear how much the message affected the recipient. While the user receiving the third bullying message responds to it by using offensive words, such as <em>b*tch</em>, in an attempt to hurt the sender. We observe a similar behavior in Figure <a class="fig" href="#fig1">1</a>(a), where the response contains words such as <em>hurt</em> and <em>rude</em> indicating that the user is affected by this message. The recipient also uses words such as <em>ugly</em> in the response in an attempt to hurt the sender. These user responses to Sarahah messages are a very unique aspect of our dataset.</p>    <div class="table-responsive" id="tab1">     <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Example messages exchanged via Sarahah and corresponding user reactions.</span>     </div>     <table class="table">     <thead>      <tr>       <th style="text-align:left;">Message</th>       <th style="text-align:left;">Reaction</th>      </tr> 					 </thead> 					 <tbody>      <tr>       <td style="text-align:left;">How can we s*xchat - can&#x0027;t wait to make love to you.</td>       <td style="text-align:left;">It&#x0027;s not free dear.</td>      </tr>      <tr>       <td style="text-align:left;">Can we meet and have random s*x?</td>       <td style="text-align:left;">Yes, only if you are the last man on earth.</td>      </tr>      <tr>       <td style="text-align:left;">Why you so ugly?</td>       <td style="text-align:left;">Cause b*tch your momma had me.</td>      </tr>     </tbody>     </table>    </div>    </section>   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Linguistic Analysis of Sarahah Messages</h2>     </div>    </header>    <p>We first perform linguistic analysis of the messages exchanged using Sarahah. Our analysis paves way for understanding the nature of these messages and identifying the different bullying categories.</p>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Topic Analysis using Latent Dirichlet Allocation (LDA)</h3>     </div>     </header>     <p>Topic modeling, also known as latent Dirichlet allocation (LDA) is a popular means to analyze document corpora [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>]. We first start by using LDA to understand the presence of different bullying related words in our data. We consider each message as a document and run LDA for 10,000 iterations. We use standard values of <em>&#x03B1;</em> = 0.01 and <em>&#x03B2;</em> = 0.01 for the hyperparameters and 30 topics. Using the LDA topics, we identify the different types of conversations present in our data and the types that are more likely to contain bullying messages. We then consider the top 50 words from topic-word distributions of these 30 topics. We identify the <em>bullying</em> words from this set of words and group them into different categories based on the type of bullying.</p>    </section>    <section id="sec-9">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Types of Conversation using Sarahah</h3>     </div>     </header>     <p>Analyzing the LDA topics, we identify the different ways in which users use Sarahah. We map the different types of messages to standard conversation types [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>]. Table <a class="tbl" href="#tab2">2</a> gives us the different types of conversation and sub-categories in them, and some example messages in each category. We identify <em>four</em> types of conversations on Sarahah; we describe them briefly below:</p>    <div class="table-responsive" id="tab2">     <div class="table-caption">     <span class="table-number">Table 2:</span>     <span class="table-title">Different conversation types found in Sarahah messages and example messages in each conversation type.</span>     </div>     <table class="table">     <thead>      <tr>       <th style="text-align:left;">Conversation Types</th>       <th style="text-align:left;">Sub-categories</th>       <th style="text-align:left;">Example Messages</th>      </tr> 					 </thead> 					 <tbody>      <tr>       <td style="text-align:left;">Confession</td>       <td style="text-align:left;">Positive</td>       <td style="text-align:left;">I always had a crush on you, the way you smile the way how your beautiful eyes are.</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;"/>       <td style="text-align:left;"> You&#x0027;re actually so pretty, people will always hate no matter what only listen to the opinions from people who matter most in your life.</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;">Romantic</td>       <td style="text-align:left;">Hi crush. I love you.</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;"/>       <td style="text-align:left;">And I love u even more when you tweet my messages.</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;"/>       <td style="text-align:left;">Love you more than anything</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;">Negative</td>       <td style="text-align:left;">I want to punch you. In your face.</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;"/>       <td style="text-align:left;">You are such a waste of oxygen.</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;"/>       <td style="text-align:left;">I think you&#x0027;re vile, disgusting, and deserve nothing but grief in your life. Pathetic waste.</td>      </tr>      <tr>       <td style="text-align:left;">Questions</td>       <td style="text-align:left;">General</td>       <td style="text-align:left;">What inspired you to photography?</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;"/>       <td style="text-align:left;"> Food or volleyball?</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;">Personal</td>       <td style="text-align:left;">Do you have a girlfriend?</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;"/>       <td style="text-align:left;">Can I have Your Number?</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;"/>       <td style="text-align:left;">How many times you literally got *ss f*cked?</td>      </tr>      <tr>       <td style="text-align:left;">Opinions on World Issues</td>       <td style="text-align:left;"/>       <td style="text-align:left;">North Koreas trade China so Trump can threaten China</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;"/>       <td style="text-align:left;">Pakistani think Partition bad idea Jinnah Nehru didn&#x0027;t lose anything and in fact became legends in respective countries. We are the victims. The decision was made without our consent.</td>      </tr>      <tr>       <td style="text-align:left;"/>       <td style="text-align:left;"/>       <td style="text-align:left;">Pakistan has started to fence its Afghan border and there is a deep profound message in it for Trump</td>      </tr>      <tr>       <td style="text-align:left;">Inspirational</td>       <td style="text-align:left;"/>       <td style="text-align:left;">Life is one big road with lots of signs. So when you ricling through the ruts, don&#x0027;t complicate your mind. Flee from hate, mischief and jealousy. Don&#x0027;t bury your thoughts, put your vision to reality. Wake Up and Live!</td>      </tr>     </tbody>     </table>    </div>     <p>     <em>Confession</em>. Messages that are meant to convey feelings anonymously that the sender does not wish to disclose under non-anonymous circumstances. The messages in this category range from secret admiration, flirting, and love proposals to bullying messages such as hatred/sexually offensive messages. We break down messages in this category into three sub-categories: i) <em>positive</em>, ii) <em>romantic</em>, and iii) <em>negative</em> messages. Positive confessions mention positive feelings about a person without the explicit mention of romantic feelings. The second sub-category captures confessions that convey romantic interests as noted by the presence of words such as <em>crush</em> and <em>love</em>. The third sub-category captures confessions that convey feelings of malice or hatred towards the recipient, indicated by words such as <em>punch, vile, disgusting</em>, and <em>waste</em>. We identify that the <em>negative</em> and the <em>romantic</em> messages can potentially cause discomfort to the recipient.</p>     <p>     <em>Questions</em>. In this conversation category, we find questions directed to the recipient. This category contains both general (i.e., non-intrusive) questions as well as intrusive and offensive personal questions. Note that in the examples under personal questions in Table <a class="tbl" href="#tab2">2</a>, we find both intrusive personal questions such as <em>What is your phone number?</em> to offensive ones such as <em>Do you like an*l s*x?</em>.</p>     <p>     <em>Opinions on world issues</em>. There are also opinions on world issues, especially sensitive ones, which users may not be comfortable sharing in a non-anonymous setting. Some examples of world issues we see in our data are related to: i) President Trump, ii) India-Pakistan partition, and iii) North Korean politics.</p>     <p>     <em>Inspirational</em>. We also find some inspirational messages which may/may not be targeted towards the recipient.</p>     <p>We identify that bullying messages primarily occur in the <em>confession</em> and <em>questions</em> messages.</p>    </section>    <section id="sec-10">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Bullying Categories</h3>     </div>     </header>     <p>Using our LDA topics, we identify the different prominent bullying categories present in this data. The sensitive nature of this data restricts creating and sharing labeled data, making unsupervised methods lucrative for this problem. In order to overcome the need for message-level labels, we label the LDA topics based on the presence of bullying words in them. We find words related to the following bullying categories in the LDA topics.</p>     <p>     <em>Sexual</em>. Messages in this category contain explicit sexually offensive words that are intended to harass, intimidate, or make the recipient uncomfortable. There are both confessions, which convey the sender&#x0027;s feeling towards the recipient and personal questions that are intended to make the recipient uncomfortable.</p>     <p>     <em>Hate</em>. Messages in this category are intended to convey hatred and emotionally unsettle the recipient. Messages that convey hatred, death threats, and emotional/physical abuse belong in this bullying category.</p>     <p>     <em>Inappropriate flirting</em>. The messages in this category are intended to convey a romantic interest toward the recipient. While this may not be considered bullying under normal circumstances, since the sender is anonymous, this can potentially cause significant distress to the recipient. We see messages that imply stalking, divulging/asking for personal secrets, and usage of words implying romantic interests, which especially under circumstances when the sender is anonymous can unsettle the recipient. This makes it an important bullying category to study.</p>     <p>We present the different bullying categories and top words in each category in Table <a class="tbl" href="#tab3">3</a>. If we filter the messages using the top words in the bullying categories 1 &#x2212; 3 in Table <a class="tbl" href="#tab3">3</a>, we find that around 20% of the messages contain one or more of these words, which is considerably high given that the messages are exchanged between users who are friends on the social network. In addition to the three bullying categories, we also find messages that convey admiration (category 4 in Table <a class="tbl" href="#tab3">3</a>). While the messages in this category are mostly positive ones, some messages do have a touch of flirting in them. The subtle bullying words that could possibly be present in messages in this category make it an important category to study.</p>    <div class="table-responsive" id="tab3">     <div class="table-caption">     <span class="table-number">Table 3:</span>     <span class="table-title">Coarse-grained topic categories in Sarahah and representative words in each category.</span>     </div>     <table class="table">     <thead>      <tr>       <th style="text-align:left;">Coarse-grained Bullying Categories</th>       <th style="text-align:left;">Words</th>      </tr> 					 </thead> 					 <tbody>      <tr>       <td style="text-align:left;">Sexual</td>       <td style="text-align:left;">s*xy, *ss, b*tch, gay, hot, f*ck, b**bs, d*ck, s*ck, seductive, b**ty, virgin, lesbian, bl*wj*b, straight, homosexual, b*tt, h*rny, h*es, trans, lick, bite, bed, naked, wh*re</td>      </tr>      <tr>       <td style="text-align:left;">Hate</td>       <td style="text-align:left;">punch, shoot, kick, fat, bullsh*t, beast, threat, fight, death, rude, ruin, sh*t, slap, ugly, abuse, betray, harm, size, ego, loathe, sad, cheat, trash, pain, tear, cry, emotion, breakup, trap, annoy, heartless, loser</td>      </tr>      <tr>       <td style="text-align:left;">Inappropriate Flirting</td>       <td style="text-align:left;">crush, dreams, appeal, stalk, babe, crave, love, proposal, hit, cheek, sweetie, baby, candy, babe, look, pie, cutie, hug, chick, romance, desires, pleasure, bomb</td>      </tr>      <tr>       <td style="text-align:left;">Admiration</td>       <td style="text-align:left;">beautiful, amazing, smile, awesome, kind, pretty, heart, great, gorgeous, nice, handsome, sweet, funny, hilarious, smart, strong, laugh, adorable, appreciate, proud, laugh, good, like, decent, positive, inspiration, perfect, blessings, genuine, courageous, brighten, honest, respect</td>      </tr>     </tbody>     </table>    </div>     <p>Table <a class="tbl" href="#tab4">4</a> gives some example messages in each bullying category. Bullying words are highlighted in italics. Notice that the first two categories have profane/offensive/hurtful words making it easier to automatically flag them. However, messages in the flirting category have words such as <em>kiss</em>, <em>hug</em>, which in an anonymous setting could potentially cause discomfort to the recipient but is harder to detect automatically using vocabulary-based approaches. Also, these messages combine positive words such as <em>love</em>, with possibly concerning words such as <em>kiss</em>, <em>hug</em>, and <em>shape</em>, making it necessary to understand the semantics of these messages and their corresponding user responses to accurately determine whether they could potentially unsettle the recipient.</p>     <div class="table-responsive" id="tab4">     <div class="table-caption">      <span class="table-number">Table 4:</span>      <span class="table-title">Bullying topic categories and some example messages in each category.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">Bullying Category</th>        <th style="text-align:left;">Example post</th>       </tr> 						</thead> 						<tbody>       <tr>        <td style="text-align:left;">Sexual</td>        <td style="text-align:left;">Do you wanna <em>s*x</em> with me?</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">Is small <em>d*ck</em> a turn off?</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">Leak your <em>d*ck</em> pics?</td>       </tr>       <tr>        <td style="text-align:left;">Hate</td>        <td style="text-align:left;">I <em>hate</em> you please leave the twitter.</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">Go cut yourself Iol. Why you an <em>ugly dumb sl*t</em>?</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">Why are you so pretty <em>b*tch</em>? It just makes me hate my genes.</td>       </tr>       <tr>        <td style="text-align:left;">Flirting</td>        <td style="text-align:left;">I&#x0027;d love to steal a kiss from you one day.</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">I wish I could hug and kiss you all day long.</td>       </tr>       <tr>        <td style="text-align:left;"/>        <td style="text-align:left;">In love with the shape of you.</td>       </tr>      </tbody>     </table>     </div>    </section>   </section>   <section id="sec-11">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Discussion and Future Work</h2>     </div>    </header>    <p>In this work, we introduced data collected from a recently released anonymous web/mobile messenger application, <em>Sarahah</em>. We performed a preliminary linguistic analysis of messages and found that cyberbullying can occur in different forms, with or without the presence of profane words, calling for a fine-grained analysis. Our analysis is helpful in identifying the different ways in which anonymous applications are used and understanding the different types of bullying present in anonymous exchanges between people who already know each other. There are several exciting directions to go from here. The unique aspect of the user responses when recipients share these messages opens up possibilities for studying the varying levels of discomfort caused by bullying messages. Our data and subsequent analysis could potentially help in answering many important questions related to cyberbullying. The first and foremost question is what kinds of messages cause the most distress to recipients. Understanding the effect that bullying messages has on the recipient can be useful in identifying the severity of bullying. We observe that not all recipients react the same way to messages in the same bullying category. So, a related question is, can we take the recipients&#x2019; characteristics and background to predict what kind of messages could possibly be hurtful to the recipient? Understanding some important characteristics of people who get bullied the most can be helpful in taking preventative action towards bullying. Lastly, can we design models that possess a superior semantic understanding of cyberbullying and can identify different types of bullying that can occur with/without the presence of profane/offensive words. Developing models that can detect the different subtle signals present in bullying messages and responses (i.e., sarcasm, emotional, and psycholinguistic signals) will help in accurately identifying different forms of bullying and foster a deeper understanding of their impact on recipients.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">[n. d.]. pypi.python.org Twitter API python library. ([n. d.]). <a class="link-inline force-break" href="https://pypi.python.org/pypi/twitter" target="_blank">https://pypi.python.org/pypi/twitter</a></li>     <li id="BibPLXBIB0002" label="[2]">[n. d.]. StopBullying.gov Webiste, Federal Govt.<a class="link-inline force-break" href="https://www.stopbullying.gov/" target="_blank">https://www.stopbullying.gov/</a>. ([n. d.]). Accessed: 2017-09-12.</li>     <li id="BibPLXBIB0003" label="[3]">[n. d.]. StopBullying.gov Webiste, Federal Govt.<a class="link-inline force-break" href="https://cyberbullying.org/sarahah" target="_blank">https://cyberbullying.org/sarahah</a> ([n. d.]).. Accessed: 2017-09-12.</li>     <li id="BibPLXBIB0004" label="[4]">[n. d.]. trends.google.com Sarahah trends by Google Trends. <a class="link-inline force-break" href="https://trends.google.com/trends/explore?q=sarahah" target="_blank">https://trends.google.com/trends/explore?q=sarahah</a>. ([n. d.]). Accessed: 2017-10-30.</li>     <li id="BibPLXBIB0005" label="[5]">Elias Aboujaoude, Matthew&#x00A0;W Savage, Vladan Starcevic, and Wael&#x00A0;O Salame. 2015. Cyberbullying: Review of an old problem gone viral. <em>      <em>Journal of Adolescent Health</em>     </em>57, 1 (2015), 10&#x2013;18.</li>     <li id="BibPLXBIB0006" label="[6]">Amy Bellmore, Angela&#x00A0;J Calvin, Jun-Ming Xu, and Xiaojin Zhu. 2015. The five ways of bullying on twitter: who, what, why, where, and when. <em>      <em>Computers in Human Behavior</em>     </em>44 (2015), 305&#x2013;314.</li>     <li id="BibPLXBIB0007" label="[7]">Albert Bifet and Eibe Frank. 2010. Sentiment knowledge discovery in twitter streaming data. In <em>      <em>Proceedings of the International conference on Discovery Science</em>     </em>.</li>     <li id="BibPLXBIB0008" label="[8]">Jacob&#x00A0;L. Bigelow, April Edwards&#x00A0;(Kontostathis), and Lynne Edwards. 2016. Detecting Cyberbullying Using Latent Semantic Indexing. In <em>      <em>Proceedings of the Workshop on Computational Methods for CyberSafety</em>     </em>.</li>     <li id="BibPLXBIB0009" label="[9]">David&#x00A0;M. Blei, Andrew&#x00A0;Y. Ng, and Michael&#x00A0;I. Jordan. 2003. Latent Dirichlet Allocation. <em>      <em>Journal of Machine Learning Research</em>     </em>3 (March 2003), 993&#x2013;1022.</li>     <li id="BibPLXBIB0010" label="[10]">Lucie Corcoran, Conor&#x00A0;Mc Guckin, and Garry Prentice. 2015. Cyberbullying or cyber aggression?: A review of existing definitions of cyber-based peer-to-peer aggression. <em>      <em>Societies</em>     </em>5, 2 (2015), 245&#x2013;255.</li>     <li id="BibPLXBIB0011" label="[11]">Karthik Dinakar, Roi Reichart, and Henry Lieberman. 2011. Modeling the detection of Textual Cyberbullying.<em>      <em>The Social Mobile Web</em>     </em>11, 02 (2011).</li>     <li id="BibPLXBIB0012" label="[12]">Homa Hosseinmardi, Amir Ghasemianlangroodi, Richard Han, Qin Lv, and Shivakant Mishra. 2014. Towards understanding cyberbullying behavior in a semi-anonymous social network. In <em>      <em>Proceedings of the Conference on Advances in Social Networks Analysis and Mining (ASONAM)</em>     </em>.</li>     <li id="BibPLXBIB0013" label="[13]">H. Hosseinmardi, R.&#x00A0;I. Rafiq, R. Han, Q. Lv, and S. Mishra. 2016. Prediction of cyberbullying incidents in a media-based social network. In <em>      <em>Proceedings of the Conference on Advances in Social Networks Analysis and Mining (ASONAM)</em>     </em>.</li>     <li id="BibPLXBIB0014" label="[14]">Qianjia Huang, Vivek&#x00A0;Kumar Singh, and Pradeep&#x00A0;Kumar Atrey. 2014. Cyber bullying detection using social and textual analysis. In <em>      <em>Proceedings of the Workshop on Socially-Aware Multimedia</em>     </em>.</li>     <li id="BibPLXBIB0015" label="[15]">Homa Hosseinmardi&#x00A0;Shaosong Li, Zhili Yang, Qin Lv, Rahat Ibn Rafiq&#x00A0;Richard Han, and Shivakant Mishra. 2014. A comparison of common users across Instagram and ask.fm to better understand cyberbullying. In <em>      <em>Proceedings of the Conference on Big Data and Cloud Computing (BdCloud)</em>     </em>.</li>     <li id="BibPLXBIB0016" label="[16]">Aravindan Mahendiran, Wei Wang, Jaime Arredondo&#x00A0;Sanchez Lira, Bert Huang, Lise Getoor, David Mares, and Naren Ramakrishnan. 2014. Discovering evolving political vocabulary in social media. In <em>      <em>Proceedings of the Conference on Behavior, Economic and Social Computing (BESC)</em>     </em>.</li>     <li id="BibPLXBIB0017" label="[17]">Hendro Margono, Xun Yi, and Gitesh&#x00A0;K Raikundalia. 2014. Mining Indonesian cyber bullying patterns in social networks. In <em>      <em>Proceedings of the Australasian Computer Science Conference</em>     </em>.</li>     <li id="BibPLXBIB0018" label="[18]">Fred Morstatter, J&#x00FC;rgen Pfeffer, Huan Liu, and Kathleen&#x00A0;M Carley. 2013. Is the Sample Good Enough? Comparing Data from Twitter&#x0027;s Streaming API with Twitter&#x0027;s Firehose.. In <em>      <em>Proceedings of the Conference on Social and Information Networks</em>     </em>.</li>     <li id="BibPLXBIB0019" label="[19]">Vinita Nahar, Xue Li, and Chaoyi Pang. 2013. An effective approach for cyberbullying detection. <em>      <em>Communications in Information Science and Management Engineering</em>     </em>3, 5(2013), 238.</li>     <li id="BibPLXBIB0020" label="[20]">Dung&#x00A0;T Nguyen, Nam&#x00A0;P Nguyen, and My&#x00A0;T Thai. 2012. Sources of misinformation in online social networks: Who to suspect?. In <em>      <em>Proceedings of the Conference on Military Communications Conference (MILCOM)</em>     </em>.</li>     <li id="BibPLXBIB0021" label="[21]">Thomas Piehn and Allison Piehn. 2001. Voice enabled digital camera and language translator. (Feb.&#x00A0;20 2001). US Patent App. 09/789,220.</li>     <li id="BibPLXBIB0022" label="[22]">Charis Psaltis and Gerard Duveen. 2007. Conservation and conversation types: Forms of recognition and cognitive development. <em>      <em>British Journal of Developmental Psychology</em>     </em>25, 1(2007), 79&#x2013;102.</li>     <li id="BibPLXBIB0023" label="[23]">Elaheh Raisi and Bert Huang. 2017. Cyberbullying Detection with Weakly Supervised Machine Learning. In <em>      <em>Proceedings of the Conference on Advances in Social Networks Analysis and Mining (ASONAM)</em>     </em>.</li>     <li id="BibPLXBIB0024" label="[24]">Elaheh Raisi and Bert Huang. 2017. Cyberbullying Detection with Weakly Supervised Machine Learning. In <em>      <em>Proceedings of the International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</em>     </em>.</li>     <li id="BibPLXBIB0025" label="[25]">Shari&#x00A0;Kessel Schneider, Lydia O&#x0027;donnell, Ann Stueve, and Robert&#x00A0;WS Coulter. 2012. Cyberbullying, school bullying, and psychological distress: A regional census of high school students. <em>      <em>American Journal of Public Health</em>     </em>102, 1 (2012), 171&#x2013;177.</li>     <li id="BibPLXBIB0026" label="[26]">Ray Smith. 2007. An overview of the Tesseract OCR engine. In <em>      <em>Proceedings of the Conference on Document Analysis and Recognition (ICDAR)</em>     </em>.</li>     <li id="BibPLXBIB0027" label="[27]">Robert&#x00A0;S Tokunaga. 2010. Following you home from school: A critical review and synthesis of research on cyberbullying victimization. <em>      <em>Computers in Human Behavior</em>     </em>26, 3 (2010), 277&#x2013;287.</li>     <li id="BibPLXBIB0028" label="[28]">William Warner and Julia Hirschberg. 2012. Detecting hate speech on the world wide web. In <em>      <em>Proceedings of the Workshop on Language in Social Media</em>     </em>.</li>     <li id="BibPLXBIB0029" label="[29]">Elizabeth Whittaker and Robin&#x00A0;M Kowalski. 2015. Cyberbullying via social media. <em>      <em>Journal of School Violence</em>     </em>14, 1 (2015), 11&#x2013;29.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18 Companion, April 23&#x2013;27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. <br/>ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3191530">https://doi.org/10.1145/3184558.3191530</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
