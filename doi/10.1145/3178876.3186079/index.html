<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Detecting Crowdturfing “Add to Favorites” Activities in
  Online Shopping</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "../../../data/dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Detecting Crowdturfing “Add to
          Favorites” Activities in Online Shopping</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Ning</span> <span class=
          "surName">Su</span>, DCST, Tsinghua University, Beijing,
          China, <a href="mailto:sn-40@163.com">sn-40@163.com</a>
        </div>
        <div class="author">
          <span class="givenName">Yiqun</span> <span class=
          "surName">Liu</span>, DCST, Tsinghua University, Beijing,
          China, <a href=
          "mailto:yiqunliu@tsinghua.edu.cn">yiqunliu@tsinghua.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Zhao</span> <span class=
          "surName">Li</span>, Alibaba Group, Hangzhou, China,
          <a href=
          "mailto:lizhao.lz@alibaba-inc.com">lizhao.lz@alibaba-inc.com</a>
        </div>
        <div class="author">
          <span class="givenName">Yuli</span> <span class=
          "surName">Liu</span>, Qinghai University, Qinghai, China,
          <a href=
          "mailto:liu-yuli@foxmail.com">liu-yuli@foxmail.com</a>
        </div>
        <div class="author">
          <span class="givenName">Min</span> <span class=
          "surName">Zhang</span>, DCST, Tsinghua University,
          Beijing, China, <a href=
          "mailto:z-m@tsinghua.edu.cn">z-m@tsinghua.edu.cn</a>
        </div>
        <div class="author">
          <span class="givenName">Shaoping</span> <span class=
          "surName">Ma</span>, DCST, Tsinghua University, Beijing,
          China, <a href=
          "mailto:msp@tsinghua.edu.cn">msp@tsinghua.edu.cn</a>
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3178876.3186079"
        target=
        "_blank">https://doi.org/10.1145/3178876.3186079</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3178876" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>‘‘Add to Favorites” is a popular function in
        online shopping sites which helps users to make a record of
        potentially interesting items for future purchases. It is
        usually regarded as a type of explicit feedback signal for
        item popularity and therefore also adopted as a ranking
        signal by many shopping search engines. With the increasing
        usage of crowdsourcing platforms, some malicious online
        sellers also organize crowdturfing activities to increase
        the numbers of “Add to Favorites” for their items. By this
        means, they expect the items to gain higher positions in
        search ranking lists and therefore boost sales. This kind
        of newly-appeared malicious activity proposes challenges to
        traditional search spam detection efforts because it
        involves the participation of many crowd workers who are
        normal online shopping users in most of the times, and
        these activities are composed of a series of behaviors
        including search, browse, click and add to
        favorites.</small></p>
        <p><small>To shed light on this research question, we are
        among the first to investigate this particular spamming
        activity by looking into both the task organization
        information in crowdsourcing platforms and the user
        behavior information from online shopping sites. With a
        comprehensive analysis of some ground truth spamming
        activities from the perspective of behavior, user and item,
        we propose a factor graph based model to identify this kind
        of spamming activity. Experimental results based on data
        collected in practical shopping search environment show
        that our model helps detect malicious “Add to Favorites”
        activities effectively.</small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Online Shopping;
          Crowdsourcing Manipulation; Spam Detection</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Ning Su, Yiqun Liu, Zhao Li, Yuli Liu, Min Zhang, and
          Shaoping Ma. 2018. Detecting Crowdturfing “Add to
          Favorites” Activities in Online Shopping. In <em>WWW
          2018: The 2018 Web Conference,</em> <em>April 23–27,
          2018,</em> <em>Lyon, France. ACM, New York, NY, USA</em>
          10 Pages. <a href=
          "https://doi.org/10.1145/3178876.3186079" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3178876.3186079</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-7">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3186079/images/www2018-88-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">An example of crowdturfing Add to
          Favorites Task.</span>
        </div>
      </figure>
      <p>Online shopping sites, such as Amazon and Taobao, have
      become popular platforms for people to find and buy items.
      For these sites, user behavior data plays an important role
      in the optimization of their personalized recommendation and
      shopping search results [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0018">18</a>]. When shopping online, users
      sometimes want to save some potentially interesting items for
      future purchase activities. For this situation, most online
      shopping sites provide an “Add to List” (in Amazon) or “Add
      to Favorites” (in Taobao, hereafter referred to as “A2F”)
      function for users. While bringing convenience to users,
      online shopping sites can also benefit from this kind of
      behavior data. For example, sometimes the amount of A2F, also
      called popularity, is regarded as a facet of item ranking in
      shopping search result pages. This information can also be
      used in the default ranking process of shopping search
      engines [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href=
      "#BibPLXBIB0013">13</a>].</p>
      <p>Nowadays, with the wide usage of crowdsourcing systems,
      some online sellers try to manipulate the ranking of shopping
      search results by increasing their items’ popularity with the
      help of crowd workers and to boost sales. As shown in
      Figure&nbsp;<a class="fig" href="#fig1">1</a>, a malicious
      online seller posts a task on a crowdsourcing platform to
      increase his/her item's A2F amount (popularity). In this
      task, crowd workers need to follow some particularly designed
      guidelines to disguise themselves as normal users. First,
      crowd workers need to submit a specific query to the target
      shopping search engine and click on the item which the
      malicious seller wants to prompt. Then, crowd workers need to
      stay in the item details page for a while, usually 2 minutes
      at least, and then click the “Add to Favorites” button. To
      simulate a more realistic online shopping scenario, some
      tasks may even require crowd workers to browse the results
      list for a while and click on a random number of non-target
      items.</p>
      <p>After accepting these crowdturfing tasks, crowd workers
      should first take a screenshot of their account ID in online
      shopping site, and then follow the guidelines to perform the
      tasks, with a screenshot at each step. The task requesters
      only approve those submissions that meet their requirements
      according to the screenshots, and pay the remuneration. These
      spamming activities affect the ranking strategy and
      recommendation mechanism of online shopping sites. Meanwhile,
      they will mislead normal users, because occasionally
      malicious sellers are trying to prompt low-quality or even
      fake items with these crowdturfing efforts.</p>
      <p>In this paper, we aim to detect the above-described
      newly-appeared spamming activities in online shopping.
      Compared to prior works, many challenges arise regarding this
      detection task: (1) These spamming activities are composed of
      a series of user behaviors, including search, browse, click
      and add to favorites, which are more complex and more
      challenging to be detected. So we need to track and analyze
      users’ whole behavior sequences. This is quite different from
      content-based spamming activities, such as deceptive product
      reviews [<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0009">9</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0023">23</a>], promotion
      campaigns in Community Question Answering (CQA) [<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0014">14</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0026">26</a>] and
      promotional microblog posts [<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0004">4</a>]. And this is also different from fake
      likes in OSNs [<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0008">8</a>], which only need a simple user
      action. (2) Since these spamming activities are performed by
      crowd workers, they are very similar to normal ones and
      difficult to be detected even with manual efforts. (3)
      Compared to posting spam product reviews and organizing CQA
      campaigns, these activities are private and hardly noticed by
      the public. So there is a lack of effective indicators such
      as “review helpfulness” or “selected as best answer”
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0017">17</a>]. (4) Some
      tasks set requirements of crowd workers’ account in online
      shopping site (e.g. the accounts should be registered at
      least 2 years ago). Therefore, these crowd workers in
      spamming activities are normal users for most of time. They
      will also carry out some normal A2F activities by themselves
      (see Section&nbsp;<a class="sec" href="#sec-18">4.3</a>).
      Meanwhile, with the increasing popularity of deceptive items,
      a number of normal users may also be attracted by them and
      contribute normal A2F activities. In other words, both spam
      users and items have a part of normal records. This also
      brings more challenges to the detection process.</p>
      <p>To tackle these challenges, we first exploit a number of
      crowdturfing tasks to form the dataset, and look into the
      corresponding user behavior log records that are highly
      likely to be spamming activities. Then we analyze the
      attributes of these crowdturfing A2F activities from the
      perspective of behavior, user and item. By integrating
      attributes and correlations (user-based and item-based) with
      a factor graph model, we conduct a discriminative model to
      detect spamming A2F activities. Through experimental
      comparisons with competitive baselines, we empirically show
      that our framework is robust and effective.</p>
      <p>Our study has the following contributions:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">We specify the problem of
        crowdturfing A2F activities in online shopping. To our best
        knowledge, we are among the first to investigate this type
        of deceptive activities.<br /></li>
        <li id="list2" label="•">Through simultaneously locating
        crowdturfing A2F tasks and collecting user behavior log
        from online shopping sites, we create a dataset which
        contains both normal user behavior data and a number of
        ground truth spamming activities.<br /></li>
        <li id="list3" label="•">We provide a comprehensive
        analysis of these spamming activities from the perspective
        of behavior, user and item.<br /></li>
        <li id="list4" label="•">We propose a novel detection
        framework that can effectively detect spamming
        activities.<br /></li>
      </ul>
    </section>
    <section id="sec-8">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related
          work</h2>
        </div>
      </header>
      <p>Three lines of research works are highly related with the
      detection of crowdturfing A2F activities: individual spam
      detection, collusive spam detection and crowdsourced
      manipulation.</p>
      <section id="sec-9">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Individual
            Spam Detection</h3>
          </div>
        </header>
        <p>With the development of E-Commerce, opinion spam (i.e.,
        deceptive reviews) has attracted much attention. It is
        firstly presented by Jindal and Liu in [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0009">9</a>], in which they analyze
        Amazon data and identify three types of spam. With manually
        labeled training examples, they further train a supervised
        learning model to detect fake reviews, which is called
        opinion spam. Ott et&nbsp;al. [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0023">23</a>] reports that the number of
        deceptive reviews grown across multiple consumer-oriented
        review sites. They find that deceptive opinion spam is
        growing in general, but with different growth rates across
        communities. Yoo and Gretzel [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0036">36</a>] manually compared the
        psychologically relevant linguistic differences between
        collected truthful and deceptive hotel reviews. However,
        the results suggest that it might be difficult to
        distinguish between deceptive and truthful reviews based on
        syntactic features. Feng et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0007">7</a>] regard the opinion spam
        as a distributional anomaly. They find distinguishing
        patterns between ordinary and fake reviews from product
        review ratings and the time windows when reviews are
        posted. In [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0024">24</a>], Ott et&nbsp;al. use n-gram and
        part-of-speech(POS) tag features for supervised learning on
        a gold-standard fake review dataset through Amazon
        Mechanical Turk. The problem of review spammer detection
        has also been widely studied in [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0016">16</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0020">20</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0025">25</a>]. These research studies
        identify several features related to rating behaviors and
        model these features to detect spam reviewers. Lu
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0020">20</a>] use a probability graph model to
        detect fake reviews and review spammers simultaneously on a
        large labeled dataset.</p>
        <p>Besides fake review and review spammer detection in the
        review systems, spam detection has also been studied in
        other platforms, such as Community Question Answering (CQA)
        portals [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href="#BibPLXBIB0001">1</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0002">2</a>, <a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0005">5</a>, <a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0008">8</a>, <a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0014">14</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0026">26</a>] and
        online social networks (OSNs) [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0010">10</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0011">11</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0028">28</a>]</p>
        <p>Compared with this line of research, our work aims to
        deal with a newly-appeared collusive spamming activity
        which involves crowdturfing activities. However, some of
        the features adopted in existing individual spam detection
        may also be inspiring our researches.</p>
      </section>
      <section id="sec-10">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Collusive
            Spam Detection</h3>
          </div>
        </header>
        <p>A related line of research focuses on collusive spam
        detection [<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href="#BibPLXBIB0003">3</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0021">21</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0033">33</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0034">34</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0035">35</a>]. Lu
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0019">19</a>] exploit contextual information
        about reviewers’ identities and social networks for
        improving review quality prediction. They find that social
        context is useful to find groups of review spammers.
        Mukherjee et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0021">21</a>] are among the first to study
        spammer groups in review communities. They find that
        labeling fake reviewer groups is much easier than labeling
        individual fake reviews or reviewers, and propose a novel
        relation-based methods to detect spammer groups on the
        labeled dataset. In [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0034">34</a>], Xu et&nbsp;al. propose two novel
        methods to cluster reviewers and detect collusive spammers,
        using both individual and collusive indicators. Besides,
        collusive spam detection is also studied in online social
        networks. For example, Cao et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0004">4</a>] investigate the
        individual-based and group-based user behavior of URL
        sharing in social media toward uncovering these organic
        versus organized user groups.</p>
        <p>We can see that most of these collusive spam detection
        efforts focus on the opinion spam. These deceptive reviews
        will affect users’ judgment about items or services
        directly. Our research is the first work to specify the
        problem of crowdturfing A2F activities. Different from
        previous work, these spamming activities will first affect
        the ranking strategy and recommendation mechanism of online
        shopping sites, and then affect users through them.</p>
      </section>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.3</span>
            Crowdsourced Manipulation</h3>
          </div>
        </header>
        <p>Recently, with the wide usage of crowdsourcing systems,
        many researchers begin to study the crowdsourced
        manipulation problem which aims to spread manipulated
        contents to target sites. Wang et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0031">31</a>] find that not only do
        malicious crowdsourcing systems exist, but they are rapidly
        growing in both user base and total revenue. They estimate
        that about 90% of all tasks on two Chinese crowdsourcing
        platforms are malicious tasks. Lee et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0012">12</a>] analyze
        the types of malicious tasks and the properties of
        requesters and workers on Western crowdsourcing sites. They
        further propose and develop statistical user models to
        automatically differentiate among regular social media
        users and workers. In [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0006">6</a>], the authors link crowdsourced
        deceptive review tasks to target products. They use a
        Conditional Random Field model to cluster reviewers and
        embed the results of this probabilistic model into a
        classification framework for detecting crowd manipulated
        reviews. Liu et&nbsp;al. [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0017">17</a>] study collusive spamming
        activities on CQA platforms. They propose a combined factor
        graph model, using various extracted attributes and
        correlations to learn to infer whether a question or an
        answer is deceptive. In [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0030">30</a>], the authors formalize the crowd
        fraud detection problem in Internet advertising, and
        carefully analyze the behaviors of crowd fraud.</p>
        <p>We can see that this line of research provide valuable
        insights in how crowd workers are organized to finish
        complex spamming tasks. However, none of them aim to solve
        the crowdturfing A2F threats exposed to online shopping
        sites. Compared with previous spamming activities,
        crowdturfing A2F activities are more subtle and more
        difficult to be perceived by users. In addition, these
        spamming activities are composed of a series of user
        behaviors, which are much more complex and more difficult
        to be detected than opinion spam.</p>
      </section>
    </section>
    <section id="sec-12">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Data collection
          and annotation</h2>
        </div>
      </header>
      <p>Since there is no public available dataset for the problem
      of spamming A2F activities in online shopping, we aim to
      collect data first to construct a dataset that can enable us
      to provide insights and evaluate our algorithms.</p>
      <section id="sec-13">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.1</span> Data
            Collection</h3>
          </div>
        </header>
        <p>To collect data, we first locate a number of
        crowdturfing A2F tasks in a crowdsourcing platform as the
        seed set. Then we collect the related user behavior log
        based on the seed user set.</p>
        <p>As mentioned before, in some popular crowdsourcing
        platforms, such as Zhubajie.com and RapidWorkers.com, the
        crowd worker who participates in a crowdturfing A2F task is
        required to submit a specific query to the shopping search
        engine and take a screenshot of his/her account ID. This
        provides a chance to acquire ground truth spamming
        activities for us. We first locate the crowdturfing A2F
        tasks in a crowdsourcing platform using manual searching
        and filtering of the search results. All the queries and
        crowd workers’ account IDs are manually extracted according
        to the submitted screenshots. Through this way, we obtain
        60 tasks during 10 days that contain 113 spam users and 296
        unique spam queries (each task may provide more than one
        query). Meanwhile, we also extract the spam shops manually
        for later use. We do not extract the spam items because the
        required items are presented in the form of pictures in the
        tasks (see Figure&nbsp;<a class="fig" href="#fig1">1</a>),
        and the item descriptions may change frequently.</p>
        <p>Based on the common assumption that “spam users tend to
        post spam contents” in the content-based spamming
        activities [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0020">20</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0032">32</a>], we make two similar assumptions
        in this problem before the collection process: (1) spam
        users tend to add spam items to their favorites, and (2)
        spam items tend to be added to favorites by spam users. We
        will briefly verify these two assumptions through some
        examples in Section&nbsp;<a class="sec" href=
        "#sec-15">4</a>. With the collected account IDs and these
        two assumptions, we begin to collect the corresponding user
        behavior log from the target online shopping site, which is
        considered as one of the most popular e-commerce websites
        and has a large number of A2F activities each day. The
        collection process consists of three steps.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">User behavior log record.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;">
                <strong>Field</strong></th>
                <th style="text-align:center;">
                <strong>Description</strong></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">User id</td>
                <td style="text-align:center;">User's digital
                id</td>
              </tr>
              <tr>
                <td style="text-align:left;">Search timestamp</td>
                <td style="text-align:center;">The timestamp of
                query submitting</td>
              </tr>
              <tr>
                <td style="text-align:left;">Query</td>
                <td style="text-align:center;">Submitted query</td>
              </tr>
              <tr>
                <td style="text-align:left;">Ranking type</td>
                <td style="text-align:center;">The selected result
                ranking type (0 for default)</td>
              </tr>
              <tr>
                <td style="text-align:left;">Item id</td>
                <td style="text-align:center;">Item's digital
                id</td>
              </tr>
              <tr>
                <td style="text-align:left;">Page number</td>
                <td style="text-align:center;">The page where the
                item is located</td>
              </tr>
              <tr>
                <td style="text-align:left;">Click timestamp</td>
                <td style="text-align:center;">The timestamp of the
                click</td>
              </tr>
              <tr>
                <td style="text-align:left;">Dwell time</td>
                <td style="text-align:center;">The time of the user
                staying in the details page</td>
              </tr>
              <tr>
                <td style="text-align:left;">Shop id</td>
                <td style="text-align:center;">Shop's digital
                id</td>
              </tr>
              <tr>
                <td style="text-align:left;">Seller id</td>
                <td style="text-align:center;">Seller's digital
                id</td>
              </tr>
              <tr>
                <td style="text-align:left;">Add to Cart</td>
                <td style="text-align:center;">Whether the user add
                the item to the cart</td>
              </tr>
              <tr>
                <td style="text-align:left;">Previous clicks</td>
                <td style="text-align:center;">Other clicks before
                this one (including item id and click
                timestamp)</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p><strong>Step one:</strong> We extract these spam users’
        behavior log during the period from March 8 to April 13,
        2017 (covering the active time for all 60 tasks). Each
        behavior log record represents an interaction session
        triggered by shopping search and aimed to finish a A2F
        activity. Table&nbsp;<a class="tbl" href="#tab1">1</a>
        lists all the fields we extract from the online shopping
        site.</p>
        <p><strong>Step two:</strong> Based on the first assumption
        that spam users tend to add spam items to their favorites,
        we collect all the items in step one, and then expand the
        dataset by extracting the user behavior log related to
        these items during the period.</p>
        <p><strong>Step three:</strong> Based on the second
        assumption that spam items tend to be added to favorites by
        spam users, we identify all the users in step two, and then
        expand the dataset again by extracting the behavior log of
        these users during the period.</p>
        <p>After these three steps, we constructed a dataset which
        covers 81,778 users, 1,544,996 items and 4,272,221 user
        behavior log records. We believe that a large number of
        users in this dataset may be involved in the crowdturfing
        A2F activities. However, not all the items in this data set
        are spam targets because even spam users also perform
        normal A2F activities.</p>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Dataset Statistics.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Spam (+)</th>
                <th style="text-align:center;">Normal (-)</th>
                <th style="text-align:center;">Suspicious (?)</th>
                <th style="text-align:center;">All</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">5,333</td>
                <td style="text-align:center;">156,192</td>
                <td style="text-align:center;">4,110,696</td>
                <td style="text-align:center;">4,272,221</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-14">
        <header>
          <div class="title-info">
            <h3><span class="section-number">3.2</span> Data
            Annotation</h3>
          </div>
        </header>
        <p>According to our assumption, each user behavior log
        record in this dataset has a certain probability of spam.
        However, as mentioned before, both spam users and spam
        items have a number of normal records. For both algorithm
        designing and evaluation purposes, we need to annotate the
        data, spot spam behavior log records, as well as normal
        ones. Due to the huge size of behavior log and the
        similarity between spamming activities and normal ones, it
        is sometimes difficult to ascertain which records are spam
        and which are normal with manual effort. However, we
        believe that it is still possible to identify a number of
        ground truth spamming activities and normal activities
        based on the crowdturfing task designs. Following are our
        annotation method:</p>
        <p><strong>Spam(+):</strong>We first identify a number of
        ground truth spam behavior log records. Considering the
        fact that the queries provided by the crowdturfing tasks
        are usually quite specific and similar to the name of the
        target items so that crowd workers can find these
        low-popularity items quickly in the results list, we regard
        interaction sessions initialized with a spam query as the
        ground truth spam log records (i.e., spamming activities).
        With 296 unique spam queries (see Section&nbsp;<a class=
        "sec" href="#sec-13">3.1</a>), we spot 5,333 spam behavior
        log records.</p>
        <p><strong>Normal(-):</strong>Considering the fact that
        high-quality items will naturally attract a large number of
        A2F activities, there is no need for their sellers to
        prompt them with crowdturfing tasks. Therefore, to spot
        normal behavior log records, we first count the amount of
        A2F activities for each item in the dataset, and then
        extract popular items with more than 500 A2F activities.
        Since the number is much larger than the maximum trading
        volume (about 100-150) of all crowdturfing tasks during
        this period, we regard their log records as normal ones. In
        total, we extract 179 items and 156,192 normal log records.
        Meanwhile, we count the shops appeared in these log
        records, and find none of them is spam shop extracted in
        Section&nbsp;<a class="sec" href="#sec-13">3.1</a>. This
        also verifies the rationality of our method.</p>
        <p><strong>Suspicious(?):</strong>We consider the rest
        4,110,696 unlabeled log records are suspicious records. Our
        goal is to detect spamming A2F activities in these log
        records.</p>
        <p>The statistics of the automatically annotated dataset as
        described above are shown in Table&nbsp;<a class="tbl"
        href="#tab2">2</a>.</p>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class=
            "table-title">Comparisons of behavior attributes
            between spamming and normal A2F activities.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">Spam</th>
                <th style="text-align:center;">Normal</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Add to Cart</td>
                <td style="text-align:center;">0.06</td>
                <td style="text-align:center;">0.08</td>
              </tr>
              <tr>
                <td style="text-align:left;">Rank the results</td>
                <td style="text-align:center;">0.24</td>
                <td style="text-align:center;">0.29</td>
              </tr>
              <tr>
                <td style="text-align:left;">With previous
                clicks</td>
                <td style="text-align:center;">0.20</td>
                <td style="text-align:center;">0.02</td>
              </tr>
              <tr>
                <td style="text-align:left;">On weekends</td>
                <td style="text-align:center;">0.32</td>
                <td style="text-align:center;">0.26</td>
              </tr>
            </tbody>
          </table>
        </div>
        <figure id="fig2">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186079/images/www2018-88-fig2.jpg"
          class="img-responsive" alt="Figure 2" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 2:</span>
            <span class="figure-title">Comparisons of behavior
            attribute distributions between spamming and normal A2F
            activities.</span>
          </div>
        </figure>
      </section>
    </section>
    <section id="sec-15">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Spamming A2F
          activities analysis</h2>
        </div>
      </header>
      <p>Based on the annotated dataset, we make a comparative
      analysis of the crowdturfing A2F activities. Our analysis
      will be in three aspects: behavior, user and item.</p>
      <section id="sec-16">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Behavior
            Analysis</h3>
          </div>
        </header>
        <p>We first make a comparative analysis on behavior
        attributes between spamming and normal A2F activities
        according to the annotated log records.
        Table&nbsp;<a class="tbl" href="#tab3">3</a> depicts the
        comparisons between the proportions of spam and normal log
        records containing the corresponding attributes. As we can
        observe, only 6% spamming activities (i.e., spam log
        records) and 8% normal activities contain add to cart
        operation. It is predictable because the items that users
        add to their favorites are not what they want to buy
        immediately, and few tasks require this operation. When
        searching for items, users will use different ranking
        strategies provided by shopping search engine to find
        better items efficiently. Compared to the normal
        activities, fewer spamming activities contain this
        operation. As for “<em>with previous clicks</em>”, we find
        that in about 20% spamming activities, users have clicked
        on other items before clicking the target item, while only
        2% normal activities have previous clicks on other items.
        This is because crowdturfing tasks usually require workers
        to click on a random number of non-target items, as
        mentioned before. Besides, we also look into when these
        activities happen. From the table, we can see more spamming
        activities happen on weekends compared to normal ones.
        However, except the attribute of “<em>with previous
        clicks</em>”, the difference between spamming and normal
        activities is very small. This further indicates that
        spamming activities are very similar to normal ones and
        difficult to be detected.</p>
        <p>Figure&nbsp;<a class="fig" href="#fig2">2</a> further
        shows the comparisons of behavior attributes between
        spamming activities and normal ones, in terms of query
        length, page number, browse time (time interval between
        search and click) and dwell time (in details page). As
        Figure&nbsp;<a class="fig" href="#fig2">2</a>(a) indicates,
        the query length of spamming activities is concentrated at
        4-6 (about 75%), while for normal activities, the
        distribution of query length is more uniform. This is
        because the queries provided by the crowdturfing tasks need
        to contain a certain number of keywords to match their
        items, while too many words may lead to unnecessary typing
        errors. But for normal activities, the length of the query
        varies with user intent. From Figure&nbsp;<a class="fig"
        href="#fig2">2</a>(b), we observe that users view more
        pages to find the required item in spamming activities,
        which indicates that the spam items in these tasks are not
        so popular and ranked at a low position. Despite the use of
        the specific queries, crowd workers still can not find
        these items in the first few pages. As for time-related
        attributes, spamming activities’ browse time and dwell time
        are usually longer than those of normal ones (shown in
        Figure&nbsp;<a class="fig" href="#fig2">2</a>(c) and 2(d)),
        due to the corresponding requests in the crowdturfing
        tasks.</p>
        <div class="table-responsive" id="tab4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class=
            "table-title">Comparisons of user attributes between
            spam and other users.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th colspan="2" style="text-align:center;">
                  Spam
                  <hr />
                </th>
                <th colspan="2" style="text-align:center;">
                  Other
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">Mean</th>
                <th style="text-align:center;">Median</th>
                <th style="text-align:center;">Mean</th>
                <th style="text-align:center;">Median</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Number of A2F</td>
                <td style="text-align:center;">70.3</td>
                <td style="text-align:center;">42</td>
                <td style="text-align:center;">122.7</td>
                <td style="text-align:center;">65</td>
              </tr>
              <tr>
                <td style="text-align:left;">Number of Add to
                Cart</td>
                <td style="text-align:center;">42.2</td>
                <td style="text-align:center;">18</td>
                <td style="text-align:center;">62.8</td>
                <td style="text-align:center;">25</td>
              </tr>
              <tr>
                <td style="text-align:left;">Number of
                purchase</td>
                <td style="text-align:center;">7.0</td>
                <td style="text-align:center;">3</td>
                <td style="text-align:center;">16.6</td>
                <td style="text-align:center;">10</td>
              </tr>
              <tr>
                <td style="text-align:left;">Number of item
                reviews</td>
                <td style="text-align:center;">4.6</td>
                <td style="text-align:center;">1</td>
                <td style="text-align:center;">9.9</td>
                <td style="text-align:center;">4</td>
              </tr>
              <tr>
                <td style="text-align:left;">Add to Cart / A2F</td>
                <td style="text-align:center;">0.70</td>
                <td style="text-align:center;">0.63</td>
                <td style="text-align:center;">1.35</td>
                <td style="text-align:center;">0.47</td>
              </tr>
              <tr>
                <td style="text-align:left;">Purchase / A2F</td>
                <td style="text-align:center;">0.17</td>
                <td style="text-align:center;">0.04</td>
                <td style="text-align:center;">0.51</td>
                <td style="text-align:center;">0.15</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="table-responsive" id="tab5">
          <div class="table-caption">
            <span class="table-number">Table 5:</span> <span class=
            "table-title">Comparisons of item attributes between
            spam and other items.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;"></th>
                <th colspan="2" style="text-align:center;">
                  Spam
                  <hr />
                </th>
                <th colspan="2" style="text-align:center;">
                  Other
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:center;">Mean</th>
                <th style="text-align:center;">Median</th>
                <th style="text-align:center;">Mean</th>
                <th style="text-align:center;">Median</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Number of A2F</td>
                <td style="text-align:center;">288.7</td>
                <td style="text-align:center;">145</td>
                <td style="text-align:center;">1763.7</td>
                <td style="text-align:center;">288</td>
              </tr>
              <tr>
                <td style="text-align:left;">Number of Add to
                Cart</td>
                <td style="text-align:center;">300.9</td>
                <td style="text-align:center;">102</td>
                <td style="text-align:center;">964.1</td>
                <td style="text-align:center;">143</td>
              </tr>
              <tr>
                <td style="text-align:left;">Number of
                purchase</td>
                <td style="text-align:center;">71.3</td>
                <td style="text-align:center;">30</td>
                <td style="text-align:center;">633.5</td>
                <td style="text-align:center;">49</td>
              </tr>
              <tr>
                <td style="text-align:left;">Number of item
                reviews</td>
                <td style="text-align:center;">44.7</td>
                <td style="text-align:center;">23</td>
                <td style="text-align:center;">253.4</td>
                <td style="text-align:center;">25</td>
              </tr>
              <tr>
                <td style="text-align:left;">Add to Cart / A2F</td>
                <td style="text-align:center;">1.13</td>
                <td style="text-align:center;">0.98</td>
                <td style="text-align:center;">1.85</td>
                <td style="text-align:center;">1.51</td>
              </tr>
              <tr>
                <td style="text-align:left;">Purchase / A2F</td>
                <td style="text-align:center;">0.32</td>
                <td style="text-align:center;">0.20</td>
                <td style="text-align:center;">0.97</td>
                <td style="text-align:center;">0.35</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> User
            Analysis</h3>
          </div>
        </header>
        <p>We now look into the user attributes. Since we only spot
        normal activities in Section&nbsp;<a class="sec" href=
        "#sec-14">3.2</a> and there is no effective method to spot
        normal users or normal items, we compare user attributes
        between spam users extracted in the crowdsourcing platform
        and other users in our dataset, and so does for item
        attributes. According to the user id, we collect users’
        information from the online shopping site during the period
        from March 8 to April 13, 2017.</p>
        <p>As shown in Table&nbsp;<a class="tbl" href=
        "#tab4">4</a>, spam users have relatively fewer A2F, Add to
        Cart, purchase and item reviews. It indicates that spam
        users spend less time on normal online shopping activities.
        Since these attributes are related to users’ active time on
        the shopping site, which varies from user to user, we
        calculate the ratio of Add to Cart and purchase to A2F. We
        can see that spam users showing a smaller consumer demand
        compared to other users, which indicates that these users
        have less purchasing power.</p>
        <p>We also look into the continuity of spam users’ A2F
        activities in our dataset from a case study. As we can see
        in Figure&nbsp;<a class="fig" href="#fig3">3</a>, this spam
        user adds a number of spam items to his/her favorites in a
        continuous period of time (the first half month). It
        indicates that spam users tend to add spam items to their
        favorites (Assumption 1), and these spamming activities are
        continuous.</p>
        <figure id="fig3">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186079/images/www2018-88-fig3.jpg"
          class="img-responsive" alt="Figure 3" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 3:</span>
            <span class="figure-title">A2F activities of a spam
            user.</span>
          </div>
        </figure>
        <figure id="fig4">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186079/images/www2018-88-fig4.jpg"
          class="img-responsive" alt="Figure 4" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 4:</span>
            <span class="figure-title">A2F activities of a spam
            item and a popular item.</span>
          </div>
        </figure>
        <p></p>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.3</span> Item
            Analysis</h3>
          </div>
        </header>
        <p>As mentioned in Section&nbsp;<a class="sec" href=
        "#sec-13">3.1</a>, we don't extract the spam items in the
        tasks. Therefore, to get spam items, we extract activities
        performed by spam users with a spam query in the dataset,
        and spot the corresponding items as spam items. With 296
        spam queries and 113 spam users, we spot 58 spam items in
        total. We compare item attributes between spam items and
        other items in our dataset.</p>
        <p>As shown in Table&nbsp;<a class="tbl" href=
        "#tab5">5</a>, spam items have fewer A2F, add to cart,
        purchase and item reviews. It indicates that spam items are
        usually low-quality items that cannot attract normal users.
        Since these attributes are related to the exposure of the
        items, we also calculate the ratio of Add to Cart and
        purchase to A2F. We can see that these two attributes of
        spam items are much lower than those of others, indicating
        the lower demand for these items. In other words, users are
        less likely to buy these spam items, which validates the
        necessary of identifying these items and avoid them being
        ranked at high positions in the results list.</p>
        <p>Similarly, we look into the continuity of items’ A2F
        activities in our dataset. Figure&nbsp;<a class="fig" href=
        "#fig4">4</a>(a) shows a spam item's A2F activities. We can
        see that all the spam users’ A2F activities are
        concentrated within a short period of time, which is
        probably the active time of the crowdturfing task. It
        indicates that spam items tend to be added to the favorites
        by spam users (Assumption 2), and these spamming activities
        are continuous and concentrated. Meanwhile, there are also
        concentrated A2F activities happen in the first 9 days.
        Therefore, we have reason to doubt that these activities in
        the first 9 days may be performed by another group of crowd
        workers in another crowdsourcing platform.
        Figure&nbsp;<a class="fig" href="#fig4">4</a>(b) shows A2F
        activities of a popular item (as mentioned in
        Section&nbsp;<a class="sec" href="#sec-14">3.2</a>). The
        number of A2F activities is stable over time. Besides,
        there are some activities performed by spam users,
        indicating that spam users will also carry out normal A2F
        activities.</p>
      </section>
      <section id="sec-19">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.4</span>
            Summary</h3>
          </div>
        </header>
        <p>From the above analysis, it is clear that some behavior
        attributes between crowdturfing A2F activities and normal
        activities are asymmetric. Besides, we can find that there
        are certain differences between spam users/items and normal
        ones. We also observe that the spamming activities of spam
        users/items are continuous and concentrated. Based on these
        findings, we construct a factor graph model to detect
        spamming A2F activities in next Section.</p>
        <figure id="fig5">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186079/images/www2018-88-fig5.jpg"
          class="img-responsive" alt="Figure 5" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 5:</span>
            <span class="figure-title">Graphical representation of
            the AFGM.</span>
          </div>
        </figure>
        <p></p>
      </section>
    </section>
    <section id="sec-20">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> Spamming A2F
          Activities Detection</h2>
        </div>
      </header>
      <p>In this section, we propose a novel Activity Factor Graph
      Model (AFGM) to incorporate all the information about
      behaviors, users and items for better predicting spamming A2F
      activities. We first sample a part of nodes as the training
      set and the remaining as the test set, then our model infers
      each of the remaining node's probability of spam. Our goal is
      to train a partially labeled factor graph model.</p>
      <section id="sec-21">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.1</span> Model
            Framework</h3>
          </div>
        </header>
        <p>Factor graph assumes that observation are cohesive with
        attributes and correlations. It has been successfully
        applied in a number of spam detection works [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0017">17</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0020">20</a>].</p>
        <p>In this work, we formalized our problem into an Activity
        Factor Graph Model(AFGM). Figure&nbsp;<a class="fig" href=
        "#fig5">5</a> shows the graphical representation. The set
        of activity nodes <em>V</em> = {<em>A</em> <sub>1</sub>,
        <em>A</em> <sub>2</sub>, ..., <em>A<sub>N</sub></em> } in
        network G is mapped to a factor node set <em>Y</em> =
        {<em>y</em> <sub>1</sub>, <em>y</em> <sub>2</sub>, ...,
        <em>y<sub>N</sub></em> } in activity factor graph. The
        activities in G are partially labeled, thus <em>Y</em> can
        be divided into two subsets <em>Y<sub>L</sub></em> and
        <em>Y<sub>U</sub>,</em> corresponding to the labeled(the
        training set) and unlabeled(the test set) activities
        respectively. Using the known factor node set in the
        training set, AFGM infers how likely an unknown node is to
        be spam. Based on the findings in Section&nbsp;<a class=
        "sec" href="#sec-15">4</a>, we define the following four
        types of factors:</p>
        <ul class="list-no-style">
          <li id="list5" label="•"><strong>Behavior attribute
          factor:</strong> <em>f<sub>b</sub></em>
          (<em>y<sub>i</sub></em> |<em>b<sub>i</sub></em> )
          represents the posterior probability of
          <em>y<sub>i</sub>,</em> given the behavior attribute
          vector <em>b<sub>i</sub></em> .<br /></li>
          <li id="list6" label="•"><strong>User attribute
          factor:</strong> <em>f<sub>u</sub></em>
          (<em>y<sub>i</sub></em> |<em>u<sub>i</sub></em> )
          represents the posterior probability of
          <em>y<sub>i</sub>,</em> given the user attribute vector
          <em>u<sub>i</sub></em> that are extracted from user
          <em>U<sub>i</sub></em> .<br /></li>
          <li id="list7" label="•"><strong>Item attribute
          factor:</strong> <em>f<sub>p</sub></em>
          (<em>y<sub>i</sub></em> |<em>p<sub>i</sub></em> )
          represents the posterior probability of
          <em>y<sub>i</sub>,</em> given the item attribute vector
          <em>p<sub>i</sub></em> that are extracted from
          item(product) <em>P<sub>i</sub></em> .<br /></li>
          <li id="list8" label="•">
            <strong>Correlation factor:</strong> Based on the
            finding that spam users/items’ spamming activities are
            continuous and concentrated, we have two intuitions
            that (1) A2F activities performed by the same user in a
            small period of time may have a correlation, and (2)
            activities on the same item in a small period of time
            may have a correlation. Therefore, we have two
            correlation factors:<br />
            <ul class="list-no-style">
              <li id="list9" label="•"><em>g<sub>u</sub></em>
              (<em>y<sub>i</sub>,</em> <em>C<sub>u</sub></em>
              (<em>y<sub>i</sub></em> )) denotes the user-based
              correlations between the activities, where
              <em>C<sub>u</sub></em> (<em>y<sub>i</sub></em> ) is
              the set of user correlated factor nodes to
              <em>y<sub>i</sub></em> in the graph.<br /></li>
              <li id="list10" label="•"><em>g<sub>p</sub></em>
              (<em>y<sub>i</sub>,</em> <em>C<sub>p</sub></em>
              (<em>y<sub>i</sub></em> )) denotes the item-based
              correlations between the activities, where
              <em>C<sub>p</sub></em> (<em>y<sub>i</sub></em> ) is
              the set of item correlated factor nodes to
              <em>y<sub>i</sub></em> in the graph.<br /></li>
            </ul>
          </li>
        </ul>
        <p>Given the activity network <em>G</em>, the formation
        probability of the activities in the AFGM defines as
        follow:</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            P(Y|G)=\frac{1}{Z}\prod _{i} f_b&amp;(y_i|b_i)\cdot
            f_u(y_i|u_i)\cdot f_p(y_i|p_i)\\ &amp;\cdot
            g_u(y_i,C_u(y_i))\cdot g_p(y_i,C_p(y_i)) \end{split}
            \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>where <em>Z</em> is the normalized factor, which sums
        up the formation probability
        <em>P</em>(<em>Y</em>|<em>G</em>) over all the possible
        labels of all the activities. The objective of our model is
        to maximize this formation probability.
        <p></p>
      </section>
      <section id="sec-22">
        <header>
          <div class="title-info">
            <h3><span class="section-number">5.2</span> Model
            Inference</h3>
          </div>
        </header>
        <p>The factors in our model can be instantiated in
        different ways. Following previous work [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0029">29</a>], we use
        exponential-linear functions and define the three attribute
        factors as</p>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            f_b(y_i|b_i)=exp\left\lbrace \lambda ^{T}_{b}\Phi
            _{b}(y_i,b_i)\right\rbrace \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            f_u(y_i|u_i)=exp\left\lbrace \lambda ^{T}_{u}\Phi
            _{u}(y_i,u_i)\right\rbrace \end{equation}</span><br />
            <span class="equation-number">(3)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq4">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            f_p(y_i|p_i)=exp\left\lbrace \lambda ^{T}_{p}\Phi
            _{p}(y_i,p_i)\right\rbrace \end{equation}</span><br />
            <span class="equation-number">(4)</span>
          </div>
        </div>where <em>λ<sub>b</sub>,</em> <em>λ<sub>u</sub>,</em>
        <em>λ<sub>p</sub></em> are weighting vectors, and
        <em>Φ<sub>b</sub>,</em> <em>Φ<sub>u</sub>,</em>
        <em>Φ<sub>p</sub></em> are vectors of feature functions.
        Similarly, the correlation factors can be defined as
        <div class="table-responsive" id="eq5">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            g_u(y_i,C_u(y_i))=exp\left\lbrace \sum _{y_j\in
            C_u(y_i)}\varphi ^{T}_{u} \Theta _{u}(y_i,y_j)
            \right\rbrace \end{equation}</span><br />
            <span class="equation-number">(5)</span>
          </div>
        </div>
        <div class="table-responsive" id="eq6">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation}
            g_p(y_i,C_p(y_i))=exp\left\lbrace \sum _{y_j\in
            C_p(y_i)}\varphi ^{T}_{p} \Theta _{p}(y_i,y_j)
            \right\rbrace \end{equation}</span><br />
            <span class="equation-number">(6)</span>
          </div>
        </div>where ϕ <sub><em>u</em></sub> , ϕ
        <sub><em>p</em></sub> are weighting vectors, and
        <em>Θ<sub>u</sub>,</em> <em>Θ<sub>p</sub></em> can be
        defined as vectors of indicator functions. Learning AFGM is
        to estimate a parameter configuration <em>θ</em> =
        (<em>λ<sub>b</sub>,</em> <em>λ<sub>u</sub>,</em>
        <em>λ<sub>p</sub>,</em> ϕ <sub><em>u</em></sub> , ϕ
        <sub><em>p</em></sub> ), by maximizing the formation
        probability <em>P</em>(<em>Y</em>|<em>G</em>).
        <p></p>
        <p>For presentation simplicity, we concatenate all factor
        functions in Eq&nbsp;<a class="eqn" href=
        "#eq2">2</a>-<a class="eqn" href="#eq6">6</a> for a factor
        node <em>y<sub>i</sub></em> as</p>
        <div class="table-responsive" id="Xeq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            {\bf s}(y_i)=(\Phi _{b}(y_i,&amp;b_i)^T,\Phi
            _{b}(y_i,u_i)^T,\Phi _{b}(y_i,p_i)^T,\\ &amp;\sum
            _{y_j\in C_u(y_i)}\Theta _{u}(y_i,y_j)^T,\sum _{y_j\in
            C_p(y_i)}\Theta _{p}(y_i,y_j)^T)^T \end{split}
            \end{equation}</span><br />
            <span class="equation-number">(7)</span>
          </div>
        </div>
        <p></p>
        <p>Then, the formation probability in Eq&nbsp;<a class=
        "eqn" href="#eq1">1</a> can be written as</p>
        <div class="table-responsive" id="Xeq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            P(Y|G) &amp;=\frac{1}{Z}\prod _{i} exp\left\lbrace
            \theta ^{T} {\bf s}(y_i)\right\rbrace \\
            &amp;=\frac{1}{Z} exp\left\lbrace \theta ^{T} \sum
            _{i}{\bf s}(y_i)\right\rbrace \\ &amp;=\frac{1}{Z}
            exp\left\lbrace \theta ^{T} {\bf S}\right\rbrace
            \end{split} \end{equation}</span><br />
            <span class="equation-number">(8)</span>
          </div>
        </div>where <strong>s</strong> is the aggregation of factor
        functions over all factor nodes, i.e. <strong>S</strong> =
        ∑ <sub><em>i</em></sub>
        <strong>s</strong>(<em>y<sub>i</sub></em> ).
        <p></p>
        <p>Since the factor node set <em>Y</em> is partially
        labeled, to calculate the formation probability, we define
        <em>Y</em>|<em>Y<sub>L</sub></em> as a labeling
        configuration given the known labels <em>Y<sub>L</sub></em>
        . Further, we can define the log-likelihood objective
        function as</p>
        <div class="table-responsive" id="Xeq3">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            O(\theta) &amp;=log(\sum _{Y|Y_L} P(Y|G))\\
            &amp;=log(\sum _{Y|Y_L} \frac{1}{Z} exp\left\lbrace
            \theta ^{T} {\bf S}\right\rbrace)\\ &amp;=log(\sum
            _{Y|Y_L} exp\left\lbrace \theta ^{T} {\bf
            S}\right\rbrace)-log(Z)\\ &amp;=log(\sum _{Y|Y_L}
            exp\left\lbrace \theta ^{T} {\bf
            S}\right\rbrace)-log(\sum _{Y} exp\left\lbrace \theta
            ^{T} {\bf S}\right\rbrace) \end{split}
            \end{equation}</span><br />
            <span class="equation-number">(9)</span>
          </div>
        </div>
        <p></p>
        <p>We adopt a gradient descent algorithm [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0029">29</a>] to solve the
        log-likelihood objective function. The gradient for each
        parameter <em>θ</em> is</p>
        <div class="table-responsive" id="Xeq4">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            \frac{\partial O(\theta)}{\partial \theta }
            &amp;=\frac{\partial (log(\sum _{Y|Y_L} exp\left\lbrace
            \theta ^{T} {\bf S}\right\rbrace)-log(\sum _{Y}
            exp\left\lbrace \theta ^{T} {\bf
            S}\right\rbrace))}{\partial \theta }\\ &amp;=\frac{\sum
            _{Y|Y_L} exp\left\lbrace \theta ^{T} {\bf
            S}\right\rbrace \cdot {\bf S}}{\sum _{Y|Y_L}
            exp\left\lbrace \theta ^{T} {\bf S}\right\rbrace } -
            \frac{\sum _{Y} exp\left\lbrace \theta ^{T} {\bf
            S}\right\rbrace \cdot {\bf S}}{\sum _{Y}
            exp\left\lbrace \theta ^{T} {\bf S}\right\rbrace }\\
            &amp;=E_{Y|Y_L,G}({\bf S})-E_{Y|G}({\bf S}) \end{split}
            \end{equation}</span><br />
            <span class="equation-number">(10)</span>
          </div>
        </div>where <span class="inline-equation"><span class=
        "tex">$E_{Y|Y_L,G}({\bf S})$</span></span> represents the
        expectation of <strong>S</strong> given the known label
        <em>Y<sub>L</sub>,</em> and <em>E</em>
        <sub><em>Y</em>|<em>G</em></sub> (<strong>S</strong>)
        represents the expectation of <strong>S</strong> over all
        the possible labels.
        <p></p>
        <p>Since it is intractable to calculate <span class=
        "inline-equation"><span class="tex">$E_{Y|Y_L,G}({\bf
        S})$</span></span> and <em>E</em>
        <sub><em>Y</em>|<em>G</em></sub> (<strong>S</strong>), we
        use loopy belief propagation (LBP) algorithm [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0022">22</a>] to
        achieve an near-optimal solution. Specifically, we perform
        LBP process twice in each iteration, one time for
        estimating the marginal probability of unknown nodes (i.e.
        <em>p</em>(<em>y</em>|<em>Y<sub>L</sub>,</em> <em>G</em>),
        <em>y</em> ∈ <em>Y<sub>U</sub></em> ) and the other for the
        marginal probability of all nodes (i.e.
        <em>p</em>(<em>y</em>|<em>G</em>)). With the marginal
        probabilities, <span class="inline-equation"><span class=
        "tex">$E_{Y|Y_L,G}({\bf S})$</span></span> and <em>E</em>
        <sub><em>Y</em>|<em>G</em></sub> (<strong>S</strong>) can
        be obtained by summing over all corresponding nodes.
        Finally with the gradient, we update each parameter with a
        learning rate <em>α</em>:</p>
        <div class="table-responsive" id="Xeq5">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \theta
            _{t+1}=\theta _{t}+\alpha \cdot \nabla _{\theta }
            \end{equation}</span><br />
            <span class="equation-number">(11)</span>
          </div>
        </div>
        <p></p>
        <p>Based on learned parameters <em>θ</em>, we again use LBP
        algorithm to calculate the marginal probability of each
        factor node in the test set <em>Y<sub>U</sub></em> . Then,
        the marginal probability is taken as the prediction
        confidence, i.e., the activity node's probability of spam
        or normal.</p>
      </section>
    </section>
    <section id="sec-23">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span>
          Experiments</h2>
        </div>
      </header>
      <section id="sec-24">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.1</span>
            Experimental Setup</h3>
          </div>
        </header>
        <p><strong>Feature.</strong>According to
        Section&nbsp;<a class="sec" href="#sec-15">4</a> and
        Section&nbsp;<a class="sec" href="#sec-20">5</a>, we give
        our features used in factor construction. All the attribute
        features involved are listed in Table&nbsp;<a class="tbl"
        href="#tab6">6</a>. For both user and item attribute
        features, we only use two ratio attributes because we think
        quantitative attributes are biased for different users or
        items as mentioned before, and these two ratios can better
        reflect the quality of users and items. It is worth noting
        that the first four are binary attributes and the rest are
        continuous-valued attributes. To simplify representation
        for continuous-valued attributes, we discretize these
        continuous attribute space over some number of <em>H</em>
        intervals, each <em>H</em> is tuned according to the
        corresponding attribute distribution [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0027">27</a>]. Thus, each
        continuous-valued attribute can take on values from
        {1...<em>H</em>}, i.e. convert to one of <em>H</em>
        attributes.</p>
        <p>As for correlation factors, since spam users/items’
        spamming activities are continuous and concentrated, we
        consider that continuous <em>N<sub>u</sub></em>
        /<em>N<sub>p</sub></em> activities of same user/item have a
        strong relationship. Therefore, for the activity node
        <em>A<sub>i</sub>,</em> we add factor nodes of previous
        <em>N<sub>u</sub></em> − 1 activities performed by the same
        user into <em>C<sub>u</sub></em> (<em>y<sub>i</sub></em> ).
        Similarly, for item-based correlation, we add factor nodes
        of previous <em>N<sub>p</sub></em> − 1 activities on the
        same item into <em>C<sub>p</sub></em>
        (<em>y<sub>i</sub></em> ). In our work, we set both
        <em>N<sub>u</sub></em> and <em>N<sub>p</sub></em> to 3.</p>
        <p><strong>Dataset.</strong> As mentioned in
        Section&nbsp;<a class="sec" href="#sec-12">3</a>, our goal
        is to detect spamming A2F activities in suspicious log
        records. Due to the fact that spamming activities are very
        similar to normal ones, we can not label these log records
        as “Spam” or “Normal” manually. Therefore, it is difficult
        to evaluate the performance of our algorithm. To solve this
        problem, we randomly select 80% of the spam log records
        (about 4K records), together with all the normal log
        records as the training set (<em>Y<sub>L</sub></em> ), and
        leave the rest 20% of the spam log records for the
        evaluation. We use the five-fold cross validation to split
        spam records and examine the performance of detection
        model.</p>
        <p>For the suspicious log records, we extract the items
        with no more than 10 records and remove their records,
        because we consider that the low number of related log
        records in the dataset indicates that these items are
        unlikely to be spam items. Even if they are spam items,
        their harm to the online shopping site is negligible due to
        the low number of the spamming activities. In this way, we
        removed 2,495,066 log records. Therefore, our test set
        (<em>Y<sub>U</sub></em> ) consists of the remaining
        1,615,630 suspicious records and 20% of the spam
        records.</p>
        <div class="table-responsive" id="tab6">
          <div class="table-caption">
            <span class="table-number">Table 6:</span> <span class=
            "table-title">Attribute Features List.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;">Cat.</th>
                <th style="text-align:center;">No</th>
                <th style="text-align:center;">Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">Behavior
                attribute</td>
                <td style="text-align:center;">1</td>
                <td style="text-align:center;">Add to Cart</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">2</td>
                <td style="text-align:center;">Rank the
                results</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">3</td>
                <td style="text-align:center;">With previous
                clicks</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">4</td>
                <td style="text-align:center;">On weekends</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">5</td>
                <td style="text-align:center;">Query length</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">6</td>
                <td style="text-align:center;">Page number</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">7</td>
                <td style="text-align:center;">Browse time</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">8</td>
                <td style="text-align:center;">Dwell time</td>
              </tr>
              <tr>
                <td style="text-align:center;">User attribute</td>
                <td style="text-align:center;">9</td>
                <td style="text-align:center;">Add to Cart /
                A2F</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">10</td>
                <td style="text-align:center;">Purchase / A2F</td>
              </tr>
              <tr>
                <td style="text-align:center;">Item attribute</td>
                <td style="text-align:center;">11</td>
                <td style="text-align:center;">Add to Cart /
                A2F</td>
              </tr>
              <tr>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">12</td>
                <td style="text-align:center;">Purchase / A2F</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-25">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.2</span> Baseline
            Methods</h3>
          </div>
        </header>
        <p>Since we are among the first to investigate the spamming
        A2F activities in online shopping, there is a lack of
        effective detection models for this problem. Therefore, we
        compare our proposed model (AFGM) with three widely-used
        methods for classification in many fields. Meanwhile, to
        investigate our proposed features, we also add some
        simplified models as our baseline methods. Details are
        given below:</p>
        <ul class="list-no-style">
          <li id="list11" label="•"><strong>Support Vector
          Machine:</strong>Given all behavior attribute features,
          user attribute features and item attribute features, we
          can represent each log record with an attribute vector
          and train a Support Vector Machine (SVM) classification
          model, based on the training set. With the learned model,
          we can get the spam probability of each log record in our
          test set.<br /></li>
          <li id="list12" label="•"><strong>Logistic Regression
          Classifiers:</strong>Similarly, we train a Logistic
          Regression (LR) models with all the attribute features.
          Then we use our trained LR classifier to infer the spam
          probability of each log record in the test
          set.<br /></li>
          <li id="list13" label="•"><strong>Random Forest
          Classifiers:</strong>We also train a Random Forest
          Classifiers (RF) with all the attribute features. We use
          our learned RF model to infer unlabeled records and
          compare performance with our approach.<br /></li>
          <li id="list14" label="•">
            <strong>Bipartite Graph</strong>We take the idea of
            label propagation algorithm [<a class="bib"
            data-trigger="hover" data-toggle="popover"
            data-placement="top" href="#BibPLXBIB0015">15</a>] to
            build a “user-item” bipartite graph based on the two
            assumptions mentioned before. In the bipartite graph,
            there is an unweighted edge between a user and its
            collected item, i.e. each edge means a A2F activity.
            The spam items mentioned in Section&nbsp;<a class="sec"
            href="#sec-18">4.3</a> are used as the labeled seed to
            drive the algorithm. The spam probability of each log
            record is calculated by the spam probability of the
            user and the item in the graph.<br />
          </li>
          <li id="list15" label="•"><strong>AFGM − UP</strong>
          <strong>:</strong>Comparing to AFGM, it removes user
          attribute factors and item attribute factors, which only
          use features extracted from individual log records and
          their correlations. We construct this model to illustrate
          the necessity of user and item attributes.<br /></li>
          <li id="list16" label="•"><strong>AFGM −
          C<sub>u</sub></strong> <strong>:</strong>It uses the
          proposed activity factor graph model, but the user-based
          correlations between activities are not integrated in it.
          Through this method, we want to analyze whether
          user-based correlations are useful for our
          model.<br /></li>
          <li id="list17" label="•"><strong>AFGM −
          C<sub>p</sub></strong> <strong>:</strong>Similarly, to
          show whether item-based correlations is useful for our
          model, the item-based correlations are not used in this
          approach compared to AFGM.<br /></li>
        </ul>
      </section>
      <section id="sec-26">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.3</span> Evaluation
            Metrics</h3>
          </div>
        </header>
        <p>Due to the difficulty of manual annotation for the test
        set, we use two metrics to evaluate our detection model
        AFGM and compare AFGM with baseline methods.</p>
        <p>As mentioned in Section&nbsp;<a class="sec" href=
        "#sec-24">6.1</a>, the test set (<em>Y<sub>U</sub></em> )
        contains 20% of ground truth data. Considering the fact
        that a discriminative detection model should identify spam
        records, we focus on the spam probabilities of these ground
        truth data. We first sort all the activity log records in
        the test set by their spam probabilities given by the
        detection model. Then, we calculate the recall rate at top
        1%, i.e.</p>
        <div class="table-responsive" id="Xeq6">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} Recall@Top\
            1\% = \frac{Number\ of\ spam\ records\ in\ the\ top\
            1\%\ records}{Number\ of\ spam\ records}
            \end{equation}</span><br />
            <span class="equation-number">(12)</span>
          </div>
        </div>We do not use precision rate because suspicious log
        records in the test set have high probabilities of spam.
        Our goal is to detect spamming A2F activities in these
        records. Thus, it is unreasonable to regard these records
        as non-spam records when calculating precision rate.
        Meanwhile, we also use AUC metric to see whether the
        detection model can give these spam log records higher spam
        probabilities.
        <p></p>
        <div class="table-responsive" id="tab7">
          <div class="table-caption">
            <span class="table-number">Table 7:</span> <span class=
            "table-title">Comparisons between our methods and
            baselines.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:center;"></th>
                <th style="text-align:center;">Recall@Top 1%</th>
                <th style="text-align:center;">AUC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:center;">LR</td>
                <td style="text-align:center;">0.078</td>
                <td style="text-align:center;">0.689</td>
              </tr>
              <tr>
                <td style="text-align:center;">SVM</td>
                <td style="text-align:center;">0.121</td>
                <td style="text-align:center;">0.682</td>
              </tr>
              <tr>
                <td style="text-align:center;">RF</td>
                <td style="text-align:center;">0.166</td>
                <td style="text-align:center;">0.706</td>
              </tr>
              <tr>
                <td style="text-align:center;">BG</td>
                <td style="text-align:center;">0.247</td>
                <td style="text-align:center;">0.699</td>
              </tr>
              <tr>
                <td style="text-align:center;">AFGM-UP</td>
                <td style="text-align:center;">0.580</td>
                <td style="text-align:center;">0.899</td>
              </tr>
              <tr>
                <td style="text-align:center;">AFGM −
                C<sub>u</sub></td>
                <td style="text-align:center;">0.448</td>
                <td style="text-align:center;">0.877</td>
              </tr>
              <tr>
                <td style="text-align:center;">AFGM −
                C<sub>p</sub></td>
                <td style="text-align:center;">0.334</td>
                <td style="text-align:center;">0.757</td>
              </tr>
              <tr>
                <td style="text-align:center;">AFGM</td>
                <td style="text-align:center;">
                <strong>0.617</strong></td>
                <td style="text-align:center;">
                <strong>0.903</strong></td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>
      <section id="sec-27">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.4</span>
            Experimental Results</h3>
          </div>
        </header>
        <p>Table&nbsp;<a class="tbl" href="#tab7">7</a> shows the
        performance of spam detection with different methods on our
        evaluation metrics. The best performance has been
        highlighted in bold.</p>
        <p>As we can see, LR model achieves the worst performance
        on Recall@Top 1% (0.078), followed by SVM (0.121) and RF
        (0.166). The AUCs of these three baseline methods are
        around 0.7, which means these widely-used methods are not
        appropriate for this problem. BG model achieves a better
        performance on Recall@Top 1% (0.247), which indicates
        correlations are more important than attributes in this
        detection task.</p>
        <p>It can be easily found that all our models perform
        better than 4 baselines, and AFGM achieves the best
        performance on both Recall@Top 1% (0.617) and AUC (0.903).
        By comparing AFGM − C<sub>u</sub> and AFGM − C<sub>p</sub>
        with AFGM, we find that removing user-based or item-based
        correlations will decrease the performance to some extent.
        And it can explain why LR, SVM and RF models achieve bad
        performance because they do not use these correlations.
        Besides, AFGM − C<sub>u</sub> performs better than AFGM −
        C<sub>p</sub>, which indicates that item-based correlations
        are important than user-based correlations. It is
        reasonable because crowd workers are normal users for most
        time and will also carry out some normal A2F activities by
        themselves, while most activities for spam items are
        spamming. By comparing AFGM-UP and AFGM, we can find that
        individual log record contains enough information
        (including behavior attributes and their correlation) to
        detect spamming activities, while user and item attributes
        can further enhance performance.</p>
        <p>Figure&nbsp;<a class="fig" href="#fig6">6</a> shows the
        detection performance of different proposed models measured
        by recall rate at top k%. We can observe that nearly 80% of
        spamming activities can be acquired in the top 10% log
        records of the test set with AFGM and AFGM-UP. AFGM-UP
        achieves a very close performance with AFGM. This could be
        because the correlation factors contain enough information
        to cover the user and item attribute factors. Therefore,
        more effective user and item attributes may be needed to
        improve AFGM. The gap between AFGM − C<sub>p</sub> and
        other models are large, which indicates that item-based
        correlations are relatively more important to detect
        spamming activities.</p>
        <figure id="fig6">
          <img src=
          "../../../data/deliveryimages.acm.org/10.1145/3190000/3186079/images/www2018-88-fig6.jpg"
          class="img-responsive" alt="Figure 6" longdesc="" />
          <div class="figure-caption">
            <span class="figure-number">Figure 6:</span>
            <span class="figure-title">Comparisons of different
            proposed models measured by Recall@Top k%.</span>
          </div>
        </figure>
        <p></p>
      </section>
    </section>
    <section id="sec-28">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span> Discussion</h2>
        </div>
      </header>
      <p>According to Table&nbsp;<a class="tbl" href="#tab7">7</a>
      and Figure&nbsp;<a class="fig" href="#fig6">6</a>, more than
      60% of the ground truth spam records can be found in the top
      1% test records. As mentioned in Section&nbsp;<a class="sec"
      href="#sec-12">3</a>, each behavior log record has a certain
      probability of spam. Therefore, besides spam log records,
      online shopping site should pay attention to the records with
      high spam probability calculated by AFGM. For example, we can
      warn or punish the users and items, which appear in the top
      1% test records twice or more. Or we can calculate a discount
      weight for spam items’ popularities or remove spam records
      directly. However, it will have a worse effect if we regard a
      normal user/item as spam one and carry out the punishment.
      Therefore, more effort is needed to determine whether a
      user/item is really spam.</p>
      <p>One limitation of our work is that we regard interaction
      sessions on items with more than 500 records in the dataset
      as normal log records. This may ignore some niche items that
      also contain a number of normal A2F activities. Therefore, we
      need to further improve our annotation method to acquire a
      more complete labeled dataset.</p>
    </section>
    <section id="sec-29">
      <header>
        <div class="title-info">
          <h2><span class="section-number">8</span>
          Conclusions</h2>
        </div>
      </header>
      <p>In this paper, we investigate the crowdturfing “Add to
      Favorites” activities in online shopping. To look into this
      kind of newly-appeared malicious activities and make the
      detection, we create a dataset through simultaneously
      locating a number of crowdturfing tasks and collecting user
      behavior log from online shopping activities. With a
      comprehensive analysis of some ground truth spamming
      activities, we find some differences between spamming
      activities and normal ones in terms of behavior, user and
      item.</p>
      <p>Given various extracted attributes (behavior-level,
      user-level and item-level) and correlations (user-based and
      item-based), we propose an activity factor graph model (AFGM)
      to infer whether a A2F activity is spamming. Experimental
      results on our dataset validate the effectiveness of the
      proposed model. More than 60% of the spam records can be
      found in the top 1% records of the test set. By comparing
      with some simplified models, we show that the features we use
      are helpful to the detection, while item-based correlations
      are most important except behavior attributes.</p>
      <p>As future work, it is important to study how to detect
      spam users and spam items based on our result. Since the user
      and item attributes have limited contributions to our model,
      we need to find more effective indicators, which may also
      help us to evaluate different detection methods. Besides, the
      current model is built for detection spamming activities in a
      period of time. A timely detection model is also an
      interesting future research direction.</p>
    </section>
    <section id="sec-30">
      <header>
        <div class="title-info">
          <h2><span class="section-number">9</span>
          Acknowledgements</h2>
        </div>
      </header>
      <p>We thank Mr. Haifeng Lu for providing very useful
      suggestions for this paper. This work is supported by Natural
      Science Foundation of China (Grant No. 61622208, 61732008,
      61532011), National Key Basic Research Program (2015CB358700)
      and Alibaba Group through Alibaba Innovative Research (AIR)
      Program.</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Prudhvi&nbsp;Ratna
        Badri&nbsp;Satya, Kyumin Lee, Dongwon Lee, Thanh Tran, and
        Jason&nbsp;Jiasheng Zhang. 2016. Uncovering fake likers in
        online social networks. In <em><em>Proceedings of the 25th
        ACM International on Conference on Information and
        Knowledge Management</em>.</em> ACM, 2365–2370.</li>
        <li id="BibPLXBIB0002" label="[2]">Antoaneta Baltadzhieva.
        2015. Question Quality in Community Question Answering
        Forums:a survey. <em><em>Acm Sigkdd Explorations
        Newsletter</em></em> 17, 1 (2015), 8–13.</li>
        <li id="BibPLXBIB0003" label="[3]">Alex Beutel, Wanhong Xu,
        Venkatesan Guruswami, Christopher Palow, and Christos
        Faloutsos. 2013. CopyCatch: stopping group attacks by
        spotting lockstep behavior in social networks. 33, 9
        (2013), 119–130.</li>
        <li id="BibPLXBIB0004" label="[4]">Cheng Cao, James
        Caverlee, Kyumin Lee, Hancheng Ge, and Jinwook Chung. 2015.
        Organic or Organized?: Exploring URL Sharing Behavior. In
        <em><em>ACM International on Conference on Information and
        Knowledge Management</em>.</em> 513–522.</li>
        <li id="BibPLXBIB0005" label="[5]">Cheng Chen, Kui Wu, V
        Srinivasan, and K Bharadwaj, R. 2012. The best answers?
        Think twice: Online detection of commercial campaigns in
        the CQA forums. (2012), 458–465.</li>
        <li id="BibPLXBIB0006" label="[6]">Amir Fayazi, Kyumin Lee,
        James Caverlee, and Anna Squicciarini. 2015. Uncovering
        Crowdsourced Manipulation of Online Reviews. In
        <em><em>International ACM SIGIR Conference on Research and
        Development in Information Retrieval</em>.</em>
        233–242.</li>
        <li id="BibPLXBIB0007" label="[7]">Song Feng, Longfei Xing,
        Anupam Gogar, and Yejin Choi. 2012. Distributional
        Footprints of Deceptive Product Reviews.</li>
        <li id="BibPLXBIB0008" label="[8]">David&nbsp;Mandell
        Freeman. 2017. Can You Spot the Fakes?: On the Limitations
        of User Feedback in Online Social Networks. In
        <em><em>International Conference on World Wide
        Web</em>.</em> 1093–1102.</li>
        <li id="BibPLXBIB0009" label="[9]">Nitin Jindal and Bing
        Liu. 2008. Opinion spam and analysis. In
        <em><em>Proceedings of the 2008 International Conference on
        Web Search and Data Mining</em>.</em> ACM, 219–230.</li>
        <li id="BibPLXBIB0010" label="[10]">Kyumin Lee, James
        Caverlee, Zhiyuan Cheng, and Daniel&nbsp;Z. Sui. 2014.
        Campaign extraction from social media. <em><em>Acm
        Transactions on Intelligent Systems &amp;
        Technology</em></em> 5, 1 (2014), 1–28.</li>
        <li id="BibPLXBIB0011" label="[11]">Kyumin Lee,
        Brian&nbsp;David Eoff, and James Caverlee. 2006. Seven
        Months with the Devils: A Long-Term Study of Content
        Polluters on Twitter. (2006).</li>
        <li id="BibPLXBIB0012" label="[12]">Kyumin Lee, Prithivi
        Tamilarasan, and James Caverlee. 2013. Crowdturfers,
        Campaigns, and Social Media: Tracking and Revealing
        Crowdsourced Manipulation of Social Media.</li>
        <li id="BibPLXBIB0013" label="[13]">Beibei Li, Anindya
        Ghose, and Panagiotis&nbsp;G Ipeirotis. 2011. Towards a
        theory model for product search. In <em><em>Proceedings of
        the 20th international conference on World wide
        web</em>.</em> ACM, 327–336.</li>
        <li id="BibPLXBIB0014" label="[14]">Baichuan Li, Tan Jin,
        Michael&nbsp;R. Lyu, Irwin King, and Barley Mak. 2012.
        Analyzing and predicting question quality in community
        question answering services. In <em><em>International
        Conference on World Wide Web</em>.</em> 775–782.</li>
        <li id="BibPLXBIB0015" label="[15]">Xin Li, Yiqun Liu, Min
        Zhang, Shaoping Ma, Xuan Zhu, and Jiashen Sun. 2015.
        Detecting Promotion Campaigns in Community Question
        Answering.. In <em><em>IJCAI</em>.</em> 2348–2354.</li>
        <li id="BibPLXBIB0016" label="[16]">Ee&nbsp;Peng Lim,
        Viet&nbsp;An Nguyen, Nitin Jindal, Bing Liu, and
        Hady&nbsp;Wirawan Lauw. 2010. Detecting product review
        spammers using rating behaviors. In <em><em>ACM
        International Conference on Information and Knowledge
        Management</em>.</em> 939–948.</li>
        <li id="BibPLXBIB0017" label="[17]">Yuli Liu, Yiqun Liu, Ke
        Zhou, Min Zhang, and Shaoping Ma. 2017. Detecting Collusive
        Spamming Activities in Community Question Answering. In
        <em><em>The International Conference</em>.</em>
        1073–1082.</li>
        <li id="BibPLXBIB0018" label="[18]">Bo Long, Jiang Bian,
        Anlei Dong, and Yi Chang. 2012. Enhancing product search by
        best-selling prediction in e-commerce. In
        <em><em>Proceedings of the 21st ACM international
        conference on Information and knowledge
        management</em>.</em> ACM, 2479–2482.</li>
        <li id="BibPLXBIB0019" label="[19]">Yue Lu, Panayiotis
        Tsaparas, Alexandros Ntoulas, and Livia Polanyi. 2010.
        Exploiting social context for review quality prediction.
        (2010), 691–700.</li>
        <li id="BibPLXBIB0020" label="[20]">Yuqing Lu, Lei Zhang,
        Yudong Xiao, and Yangguang Li. 2013. Simultaneously
        detecting fake reviews and review spammers using factor
        graph model. In <em><em>ACM Web Science
        Conference</em>.</em> 225–233.</li>
        <li id="BibPLXBIB0021" label="[21]">Arjun Mukherjee, Bing
        Liu, and Natalie Glance. 2012. Spotting fake reviewer
        groups in consumer reviews. In <em><em>International
        Conference on World Wide Web</em>.</em> 191–200.</li>
        <li id="BibPLXBIB0022" label="[22]">Kevin Murphy, Yair
        Weiss, and Michael&nbsp;I. Jordan. 2013. Loopy Belief
        Propagation for Approximate Inference: An Empirical Study.
        (2013), 467–475.</li>
        <li id="BibPLXBIB0023" label="[23]">Myle Ott, Claire
        Cardie, and Jeff Hancock. 2012. Estimating the prevalence
        of deception in online review communities. (2012),
        201–210.</li>
        <li id="BibPLXBIB0024" label="[24]">Myle Ott, Yejin Choi,
        Claire Cardie, and Jeffrey&nbsp;T. Hancock. 2011. Finding
        deceptive opinion spam by any stretch of the imagination. 1
        (2011), 309–319.</li>
        <li id="BibPLXBIB0025" label="[25]">Vlad Sandulescu and
        Martin Ester. 2015. Detecting Singleton Review Spammers
        Using Semantic Similarity. (2015).</li>
        <li id="BibPLXBIB0026" label="[26]">Chirag Shah and
        Jefferey Pomerantz. 2010. Evaluating and predicting answer
        quality in community QA. In <em><em>International ACM SIGIR
        Conference on Research and Development in Information
        Retrieval</em>.</em> 411–418.</li>
        <li id="BibPLXBIB0027" label="[27]">Neil Shah. 2017. FLOCK:
        Combating Astroturfing on Livestreaming Platforms. In
        <em><em>The International Conference</em>.</em>
        1083–1091.</li>
        <li id="BibPLXBIB0028" label="[28]">Shankar&nbsp;S Siva.
        2014. Survey Paper for WARNINGBIRD: Detecting Suspicious
        URLs in Twitter Stream. <em><em>International Journal of
        Advanced Trends in Computer Science &amp;
        Engineering</em></em> 3, 5(2014), 2319–7242.</li>
        <li id="BibPLXBIB0029" label="[29]">Wenbin Tang, Honglei
        Zhuang, and Jie Tang. 2011. Learning to Infer Social Ties
        in Large Networks. In <em><em>Joint European Conference on
        Machine Learning and Knowledge Discovery in
        Databases</em>.</em> 381–397.</li>
        <li id="BibPLXBIB0030" label="[30]">Tian Tian, Jun Zhu, Fen
        Xia, Xin Zhuang, and Tong Zhang. 2015. Crowd fraud
        detection in internet advertising. In <em><em>Proceedings
        of the 24th International Conference on World Wide
        Web</em>.</em> International World Wide Web Conferences
        Steering Committee, 1100–1110.</li>
        <li id="BibPLXBIB0031" label="[31]">Gang Wang, Christo
        Wilson, Xiaohan Zhao, Yibo Zhu, Manish Mohanlal, Haitao
        Zheng, and Ben&nbsp;Y. Zhao. 2012. Serf and turf:
        crowdturfing for fun and profit. In <em><em>International
        Conference on World Wide Web</em>.</em> 679–688.</li>
        <li id="BibPLXBIB0032" label="[32]">Fangzhao Wu, Jinyun
        Shu, Yongfeng Huang, and Zhigang Yuan. 2015. Social spammer
        and spam message co-detection in microblogging with social
        context regularization. In <em><em>Proceedings of the 24th
        ACM International on Conference on Information and
        Knowledge Management</em>.</em> ACM, 1601–1610.</li>
        <li id="BibPLXBIB0033" label="[33]">Chang Xu and Jie Zhang.
        2016. Towards Collusive Fraud Detection in Online Reviews.
        In <em><em>IEEE International Conference on Data
        Mining</em>.</em> 1051–1056.</li>
        <li id="BibPLXBIB0034" label="[34]">Chang Xu, Jie Zhang,
        Kuiyu Chang, and Chong Long. 2013. Uncovering collusive
        spammers in chinese review websites. In <em><em>Proceedings
        of the 22nd ACM international conference on Conference on
        information &amp; knowledge management</em>.</em> ACM,
        979–988.</li>
        <li id="BibPLXBIB0035" label="[35]">Junting Ye and Leman
        Akoglu. 2015. Discovering Opinion Spammer Groups by Network
        Footprints. In <em><em>Joint European Conference on Machine
        Learning and Knowledge Discovery in Databases</em>.</em>
        267–282.</li>
        <li id="BibPLXBIB0036" label="[36]">Kyung&nbsp;Hyan Yoo and
        Ulrike Gretzel. 2009. Comparison of Deceptive and Truthful
        Travel Reviews. In <em><em>Information and Communication
        Technologies in Tourism, Enter 2009, Proceedings of the
        International Conference in Amsterdam, the
        Netherlands</em>.</em> 37–47.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5639-8/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3178876.3186079">https://doi.org/10.1145/3178876.3186079</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
