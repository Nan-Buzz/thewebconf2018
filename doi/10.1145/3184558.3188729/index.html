<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta name="generator" content=
  "HTML Tidy for HTML5 for Linux version 5.7.16" />
  <title>Detect Rumor and Stance Jointly by Neural Multi-task
  Learning</title>
  <!-- Copyright (c) 2010-2015 The MathJax Consortium -->
  <meta http-equiv="Content-Type" content=
  "text/html; charset=utf-8" />
  <meta name="viewport" content=
  "width=device-width; initial-scale=1.0;" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/bootstrap-theme.min.css" />
  <link media="screen, print" rel="stylesheet" href=
  "../../../data/dl.acm.org/pubs/lib/css/main.css" />
  <script src="../../../data/dl.acm.org/pubs/lib/js/jquery.min.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bootstrap.min.js"
  type="text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/bibCit.js" type=
  "text/javascript"></script>
  <script src="../../../data/dl.acm.org/pubs/lib/js/divTab.js" type=
  "text/javascript"></script>
  <script type="text/javascript" src=
  "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>
  <script type="text/x-mathjax-config">
  <![CDATA[
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  ]]>
  </script>
</head>
<body id="main">
<div>
<p style='font-size: 75%; color #444'>
This is a web copy of <a href='https://doi.org/10.1145/3184558.3188729'>https://doi.org/10.1145/3184558.3188729</a> 
originally published by ACM Press, 
redistributed under the terms of 
<a href='https://creativecommons.org/licenses/by/4.0/'>Creative Commons Attribution 4.0 (CC BY 4.0)</a>.
The <a href='https://github.com/usable-oa/thewebconf2018/tree/master/scripts'>modifications</a> 
from the original are solely to improve HTML aiming to make it Findable, Accessible, Interoperable and Reusable. 
augmenting HTML metadata and avoiding ACM trademark.
To reference this HTML version, use:
</p><p>
<strong>Permalink:</strong>
<a href='https://w3id.org/oa/10.1145/3184558.3188729'>https://w3id.org/oa/10.1145/3184558.3188729</a>
</p></div>
<hr>


  <section class="front-matter">
    <section>
      <header class="title-info">
        <div class="journal-title">
          <h1><span class="title">Detect Rumor and Stance Jointly
          by Neural Multi-task Learning</span><br />
          <span class="subTitle"></span></h1>
        </div>
      </header>
      <div class="authorGroup">
        <div class="author">
          <span class="givenName">Jing</span> <span class=
          "surName">Ma</span>, The Chinese University of Hong Kong,
          Hong Kong SAR, <a href=
          "mailto:majing@se.cuhk.edu.hk">majing@se.cuhk.edu.hk</a>
        </div>
        <div class="author">
          <span class="givenName">Wei</span> <span class=
          "surName">Gao</span>, Victoria University of Wellington,
          New Zealand, <a href=
          "mailto:wei.gao@vuw.ac.nz">wei.gao@vuw.ac.nz</a>
        </div>
        <div class="author">
          <span class="givenName">Kam-Fai</span> <span class=
          "surName">Wong</span>, The Chinese University of Hong
          Kong MoE Key Lab of High Confidence Software
          Technologies, China
        </div>
      </div><br />
      <div class="pubInfo">
        <p>DOI: <a href="https://doi.org/10.1145/3184558.3188729"
        target=
        "_blank">https://doi.org/10.1145/3184558.3188729</a><br />
        WWW '18: <a href="https://doi.org/10.1145/3184558" target=
        "_blank">Proceedings of The Web Conference 2018</a>, Lyon,
        France, April 2018</p>
      </div>
      <div class="abstract">
        <p><small>In recent years, an unhealthy phenomenon
        characterized as the massive spread of fake news or
        unverified information (i.e., rumors) has become
        increasingly a daunting issue in human society. The rumors
        commonly originate from social media outlets, primarily
        microblogging platforms, being viral afterwards by the
        wild, willful propagation via a large number of
        participants. It is observed that rumorous posts often
        trigger versatile, mostly controversial stances among
        participating users. Thus, determining the stances on the
        posts in question can be pertinent to the successful
        detection of rumors, and vice versa. Existing studies,
        however, mainly regard rumor detection and stance
        classification as separate tasks. In this paper, we argue
        that they should be treated as a joint, collaborative
        effort, considering the strong connections between the
        veracity of claim and the stances expressed in responsive
        posts.</small></p>
        <p><small>Enlightened by the multi-task learning scheme, we
        propose a joint framework that unifies the two highly
        pertinent tasks, i.e., rumor detection and stance
        classification. Based on deep neural networks, we train
        both tasks jointly using weight sharing to extract the
        common and task-invariant features while each task can
        still learn its task-specific features. Extensive
        experiments on real-world datasets gathered from Twitter
        and news portals demonstrate that our proposed framework
        improves both rumor detection and stance classification
        tasks consistently with the help of the strong inter-task
        connections, achieving much better performance than
        state-of-the-art methods.</small></p>
      </div>
      <div class="CCSconcepts">
        <p><small><span style="font-weight:bold;">CCS
        Concepts:</span> • <strong>Computing methodologies</strong>
        → <strong>Artificial intelligence;</strong> <strong>Natural
        language processing;</strong> <strong>Multi-task
        learning;</strong> • <strong>Applied computing</strong> →
        <em>Document analysis;</em></small></p>
      </div>
      <div class="classifications">
        <div class="author">
          <span style=
          "font-weight:bold;"><small>Keywords:</small></span>
          <span class="keyword"><small>Rumor detection; Stance
          classification; Multi-task learning; Weight sharing;
          Social media; Microblog</small></span>
        </div><br />
        <div class="AcmReferenceFormat">
          <p><small><span style="font-weight:bold;">ACM Reference
          Format:</span><br />
          Jing Ma, Wei Gao, and Kam-Fai Wong. 2018. Detect Rumor
          and Stance Jointly by Neural Multi-task Learning. In
          <em>WWW '18 Companion: The 2018 Web Conference
          Companion,</em> <em>April 23–27, 2018,</em> <em>Lyon,
          France. ACM, New York, NY, USA</em> 9 Pages. <a href=
          "https://doi.org/10.1145/3184558.3188729" class=
          "link-inline force-break" target=
          "_blank">https://doi.org/10.1145/3184558.3188729</a></small></p>
        </div>
      </div>
    </section>
  </section>
  <section class="body">
    <section id="sec-4">
      <header>
        <div class="title-info">
          <h2><span class="section-number">1</span>
          Introduction</h2>
        </div>
      </header>
      <p>The popularity of microblogging websites makes them
      important for information dissemination and sharing. Hundreds
      of millions of users could spontaneously post messages on
      microblogs to release latest news or share their opinions
      about various information everyday. Without accurate
      systematic effort to moderate the posts, large volumes of
      fake or unverified information can emerge and spread for
      various motivations, like conducting social advertising,
      political astroturfing, etc. For instance, during the 2016 US
      election, massive fake news spread on social media such as
      Facebook and Twitter, which has led to real-world political
      repercussions<a class="fn" href="#fn1" id=
      "foot-fn1"><sup>1</sup></a>.</p>
      <p>The massive spread of rumors could seriously hurt the user
      experience and hinder the healthy development of
      microblogging systems. It is observed however that skeptical
      and opposing voices against rumors always arise along with
      their propagation, serving as helpful indicators that signal
      the truthfulness of information. Thus, identifying rumors as
      well as analyzing various stances on the concerned
      information are meaningful and beneficial for giving early
      precautions on rumor's diffusion in order to minimize its
      negative influence. Nevertheless, both rumor detection and
      stance classification are challenging tasks due to the
      ever-increasing volumes of microblog data and the complex
      nature of controversies.</p>
      <p>Rumor detection aims to determine the veracity of a given
      claim about some subject matter. Traditional approaches
      either used supervised machine learning algorithms that
      incorporate a wide variety of features manually crafted from
      post content, user profiles, and diffusion patterns of the
      posts&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0006">6</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0024">24</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0028">28</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0033">33</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0045">45</a>], or
      exploited rules or regular expressions to discover unusual
      patterns from tweets&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0047">47</a>]. To alleviate the heavy manual
      effort in these methods, models without feature engineering
      were proposed more recently and had achieved promising
      results for the task, e.g., purely data-driven models using
      recurrent neural networks&nbsp;[<a class="bib" data-trigger=
      "hover" data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0040">40</a>] and a tree-kernel-based model
      capturing high-order propagation structures&nbsp;[<a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0034">34</a>].</p>
      <p>Stance detection aims to determine the different attitudes
      expressed in a text towards a specific target. Several
      supervised models were developed for the task based on
      feature engineering approach&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0001">1</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0038">38</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0041">41</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0046">46</a>]. Lukasik et&nbsp;al.
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0029">29</a>],
      ,<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0030">30</a>] dealt with
      rumor stance classification by considering both temporal and
      textual signals via continuous time sequence classification
      using Hawkes processes. More recently, Zubiaga et&nbsp;al.
      [<a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0048">48</a>] exploited
      the conversational structure among microblog texts for
      classifying tweet stance. Another line of work mainly focus
      on using deep learning models, such as recurrent or
      convolutional neural networks&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0003">3</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0043">43</a>] for stance feature
      learning and classification.</p>
      <p>Previous analyses also indicate that false rumors tend to
      provoke tremendous controversies than normal news
      report&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0035">35</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0049">49</a>], in which
      denying and questioning stances were found playing crucial
      role in signaling claims as being rumors. It is noticed that
      several studies on rumor detection have taken into account
      such kind of stance-bearing signals in their
      models&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0028">28</a>,
      <a class="bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0038">38</a>, <a class=
      "bib" data-trigger="hover" data-toggle="popover"
      data-placement="top" href="#BibPLXBIB0047">47</a>]. In this
      paper, we argue that such approach exploiting stance
      information for aiding rumor detection is narrow and
      suboptimal, which can be radically revolutionized into a
      joint reinforcement approach for boosting the performance of
      both rumor detection and stance classification tasks in one
      shot. Our idea is motivated by the observation that people's
      stances are closely correlated with the veracity of concerned
      information. We assume that there can be some positive mutual
      feedback established between the two tasks: the indicative
      stances towards a claim can be helpful for debunking the
      rumor while validating the veracity of the claim is in turn
      conducive to infer the stances of involved posts.
      Figure&nbsp;<a class="fig" href="#fig1">1</a> illustrates the
      intuition using statistics based on a set of 100 real-world
      rumorous events randomly sampled from our datasets (see
      Section&nbsp;<a class="sec" href="#sec-15">6.1</a>). It can
      be seen that users tend to express denying stance more often
      than supporting stance in false rumors than in true rumors,
      which can be used to indicate rumor types for rumor
      detection; on the other hand, given the type of rumor, the
      tweets about false rumors are more likely to hold denying
      than supporting stance, and conversely in the tweets about
      true rumors, suggesting that the stances in relevant tweets
      may be inferred based on rumor types.</p>
      <figure id="fig1">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3188729/images/www18companion-237-fig1.jpg"
        class="img-responsive" alt="Figure 1" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 1:</span> <span class=
          "figure-title">The proportions of different stances
          regarding rumorous claims change over time (in # of hours
          since initial tweets), which demonstrates the variation
          of stance distributions in rumors that are later proven
          to be false or true.</span>
        </div>
      </figure>
      <p></p>
      <p>Inspired by the success of multi-task
      learning&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0026">26</a>], we attempt to reinforce rumor
      detection and stance classification together via mutual
      feedback in a unified architecture. Different from existing
      models that regard the two tasks independent, in this paper
      we propose unified multi-task models that learn a set of
      common, bilaterally friendly features relevant to both of the
      tasks to facilitate their interaction while each task can
      also learn to strengthen their task-specific features via a
      mutual learning process. This is achieved by using
      multi-layer recurrent neural networks (RNN), where we employ
      a shared layer and a task-specific layer to accommodate
      different types of representations of the tasks and their
      corresponding parameters. Benefited from not only having more
      data (i.e., additionally from a relevant task) for training,
      the use of multi-task learning also reduces overfitting to
      each individual task. Thus, the learned representation can
      result in more compact models than those built from
      surface-form features on a single task. Experimental results
      show that the joint learning on the two rumor-related tasks
      together can improve the performance of each task
      significantly relative to learning them in separate.</p>
      <p>Our contributions are of three folds:</p>
      <ul class="list-no-style">
        <li id="list1" label="•">To the best of our knowledge, this
        is the first work that aims to tackle rumor detection and
        stance classification together in a unified approach based
        on multi-task learning, which successfully learns to
        represent and classify data for two core tasks
        jointly.<br /></li>
        <li id="list2" label="•">We propose two multi-task
        architectures based on RNNs for capturing shared common
        features from the two tasks, and also show that our model
        is not only compact but also enables agile development to
        new information source platform such as news reports apart
        from microblogs.<br /></li>
        <li id="list3" label="•">We empirically evaluate our
        proposed method via extensive experiments on real-world
        datasets from Twitter and news reports, demonstrating that
        our multi-task approach significantly improve the
        performances on both tasks simultaneously.<br /></li>
      </ul>
    </section>
    <section id="sec-5">
      <header>
        <div class="title-info">
          <h2><span class="section-number">2</span> Related
          Work</h2>
        </div>
      </header>
      <p>In this section, we provide a brief review of the research
      related to ours in three main areas: rumor detection, stance
      classification, and multi-task learning.</p>
      <section id="sec-6">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.1</span> Rumor
            Detection</h3>
          </div>
        </header>
        <p>Detecting rumors is an important research topic and has
        been studied in various disciplines&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0012">12</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0037">37</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0042">42</a>]. Social psychology
        literature generally defined a rumor as “unverified and
        instrumentally relevant information statements in
        circulation”&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0014">14</a>]. This unverified information may
        eventually turn out to be true, partly or entirely false,
        or remain unresolved&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0049">49</a>]. Supervised classification was
        widely used to identify rumors in social media posts. The
        main concern of this approach is to define effective
        features for training rumor classifiers. Castillo
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0006">6</a>] provided a wide range of features
        crafted from the post contents, user profiles and
        propagation patterns. Subsequently, further
        studies&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0017">17</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0019">19</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0024">24</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0033">33</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0044">44</a>] were conducted to detect rumors
        with several new temporal features for representing rumor
        diffusion.</p>
        <p>Instead of defining complex feature sets, Zhao
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0047">47</a>] focused on early rumor detection
        by using regular expressions (such as “not true”,
        “unconfirmed” or “really?”, etc.) for finding questioning
        and denying tweets as the key for debunking rumors. More
        recently, Ma et&nbsp;al. [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0032">32</a>] and Rath et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0040">40</a>] used RNN
        to learn automatically the representations of rumors and
        rumor spreaders from post content and user interactions at
        different times, respectively. Ma et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0034">34</a>] also
        proposed a tree-kernel-based method which captures
        high-order propagation patterns for differentiating various
        types of rumors on Twitter. In this work, we will learn
        better representations of rumors by leveraging feature
        learning capacity from two related tasks, which can be
        considered a two-task extension of the prior RNN-based
        rumor detection method&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0032">32</a>].</p>
      </section>
      <section id="sec-7">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.2</span> Stance
            Detection</h3>
          </div>
        </header>
        <p>Stance detection has gained increasing popularity in
        different research areas&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0039">39</a>]. One of the pioneering studies was
        reported by Mendoza et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0035">35</a>], which aims to
        understand the stances with respect to different type of
        rumors via non-automated manual analysis. They found that
        the vast majority of tweets related to true rumors hold
        supporting stance, whereas half of the tweets on false
        rumors are denied or questioned.</p>
        <p>In automated methods, existing studies can be divided
        into two categories: The first category is to extract
        indicative features and then apply supervised learning
        techniques to classify the stances. Following Qazvinian
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0038">38</a>] who aimed to classify
        rumor-related tweets into supportive or not, a wide range
        of features were proposed in follow-up studies to improve
        the performance of stance classification&nbsp;[<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0028">28</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0046">46</a>]. But
        these stance classifiers ignored the rumor identities and
        temporal dependencies. More recently, Lukasik et&nbsp;al.
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0029">29</a>],
        ,<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0030">30</a>]
        exploited the temporal sequence to classify tweet stances
        in a sequence regarding a rumor using Gaussian Process and
        Hawkes Process. Zubiaga et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0048">48</a>] built a tree-CRF
        classifier that learns the dynamics of stance in
        tree-structured conversations such as Twitter replies,
        instead of classifying tweets in isolation. Unlike the
        traditional binary classification (i.e., support or
        denial), these recent research performed a finer-grained
        classification to encompass all different kinds of
        reactions to rumors which include supporting, denying,
        questioning and commenting (SDQC).</p>
        <p>The second category is the models based on deep neural
        networks. Kochkina et&nbsp;al. [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0022">22</a>] employed LSTM for
        sequential classification of tweet stances, where a
        bidirectional LSTM encoding approach was used to represent
        tweets relevant to the target&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0003">3</a>]. Chen et&nbsp;al.
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0007">7</a>] used
        convolutional neural networks (CNN) for obtaining the
        representation of each tweet, then assigned probabilities
        to different classes that the tweet may belong to by a
        softmax classifier. One drawback of the existing methods is
        that they only considered that a tweet is conditioned on
        the target, but ignored that the stances are also
        conditioned on the truthfulness of the target. This
        observation, as mentioned in&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0047">47</a>], could potentially be
        leveraged to improve the model for stance
        classification.</p>
      </section>
      <section id="sec-8">
        <header>
          <div class="title-info">
            <h3><span class="section-number">2.3</span> Multi-task
            Learning</h3>
          </div>
        </header>
        <p>The general idea of multi-task learning dates back
        to&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href=
        "#BibPLXBIB0005">5</a>], which aims to improve the
        performance of a task using other related tasks. Most of
        multi-task learning or joint learning models can be
        regarded as parameter sharing approaches, where models are
        trained jointly and parameters or features are shared
        across multiple tasks&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0002">2</a>]. There has been amount of research
        on multi-task learning in pipelined Natural Language
        Processing (NLP) tasks, such as word segmentation, POS
        tagging and dependency parsing [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0004">4</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0020">20</a>, <a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0025">25</a>], and more recently on
        text classification&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0026">26</a>].</p>
        <p>In the context of neural models for NLP, multi-task
        learning has been proven effective in many related
        problems. For example, Collobert and Weston [<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0010">10</a>] proposed an unified
        framework which uses a shared lookup table for input words,
        and then jointly trained several NLP tasks using
        convolutional neural networks such as part-of-speech
        tagging, semantic role labeling and named-entity
        recognition. Liu et&nbsp;al. [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0027">27</a>] developed a multi-task deep neural
        network for learning shared representations for arbitrary
        text across multiple tasks, which combines query
        classification and ranking for web search. More recently,
        neural multi-task learning was applied to
        sequence-to-sequence problems with recurrent neural
        networks. Several multi-task encoder-decoder networks were
        proposed for neural machine translation&nbsp;[<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0013">13</a>,
        <a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0016">16</a>], which
        allows translating one source language to many target
        languages by making use of cross-lingual information. Luong
        et&nbsp;al. [<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0031">31</a>] utilized multi-task
        sequence-to-sequence models to study the ensemble of a wide
        range of tasks, e.g., syntactic parsing, machine
        translation, image caption, etc. Liu et&nbsp;al. [<a class=
        "bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0026">26</a>]
        introduced three RNN-based architectures to model text
        sequence which provided different information sharing
        mechanisms for multiple text classification tasks. In most
        of these models, multi-task architectures basically share
        some lower layers across all tasks to determine common
        features, while the remaining layers are task specific. Our
        model is inspired from the general sharing structure for
        RNN-based multi-task learning&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0026">26</a>]. Our main challenge
        lies in designing an effective shared weighting method to
        obtain better task-specific representations by enhancing
        the interaction between the rumor pertinent tasks.</p>
      </section>
    </section>
    <section id="sec-9">
      <header>
        <div class="title-info">
          <h2><span class="section-number">3</span> Problem
          Formulation</h2>
        </div>
      </header>
      <p>Our goal is to formulate a multi-task model that jointly
      learns the rumor detection and stance classification models,
      where one task may or may not use data from the same source
      as the other. For instance, we can typically use tweets in
      rumor detection but use news reports in stance
      classification, considering the availability of training data
      and specific setting.</p>
      <p>Since tweets are short in nature, containing very limited
      context, a claim is generally associated with a collection of
      posts that are relevant to it. Therefore, we model the
      Twitter data as a set of claims <span class=
      "inline-equation"><span class="tex">$\lbrace C_1,C_2,\cdots
      ,C_{|\mathcal {C}|}\rbrace$</span></span> , where each claim
      <em>C<sub>i</sub></em> = {(<em>x<sub>ij</sub></em> ,
      <em>t<sub>ij</sub></em> )} is composed of a set of relevant
      tweets, and <em>x<sub>ij</sub></em> is a post posted at time
      <em>t<sub>ij</sub></em> .</p>
      <p><strong>Rumor detection:</strong> We formulate this task
      as a supervised <em>sequence classification</em> problem,
      which learns a classifier <em>f</em> from labeled claims
      where each claim <em>C<sub>i</sub></em> corresponds to an
      input sequence of its relevant posts <span class=
      "inline-equation"><span class="tex">$x_{i1}x_{i2}\ldots
      x_{iT_i}$</span></span> , that is, <span class=
      "inline-equation"><span class="tex">$f:x_{i1}x_{i2}\ldots
      x_{iT_i} \rightarrow Y_i$</span></span> , where
      <em>Y<sub>i</sub></em> takes one of four possible class
      labels: Non-rumor, True rumor, False rumor and Unverified
      rumor (NTFU). If one is concerned about the truthfulness of
      individual post, the task can be turned into
      sequence-to-sequence problem. But since such setting is
      uncommon in rumor detection, we do not consider it here.</p>
      <p><strong>Stance Classification:</strong> This task refers
      to determine the type of orientation that <em>each individual
      post or a document</em> expresses towards the veracity of a
      claim. We formulate it as a sequence labeling or sequence
      classification problem depending on the specific type of
      input:</p>
      <ul class="list-no-style">
        <li id="list4" label="•">When the input claim
        <em>C<sub>i</sub></em> is composed of a sequence of posts
        <span class="inline-equation"><span class=
        "tex">$x_{i1}x_{i2}\ldots x_{iT_i}$</span></span> , it
        modeled as sequence labeling, that is, <span class=
        "inline-equation"><span class="tex">$g: x_{i1}x_{i2}\ldots
        x_{iT_i} \rightarrow y_{i1}y_{i2}\ldots
        y_{iT_i}$</span></span> , where each
        <em>y<sub>ij</sub></em> is the label that takes one of
        supporting, denying, questioning or commenting (SDQC). In
        particular, commenting is assigned to tweets that do not
        add anything to the veracity of a claim.<br /></li>
        <li id="list5" label="•">When stance detection is applied
        to applications such as fake news detection<a class="fn"
        href="#fn2" id="foot-fn2"><sup>2</sup></a>, an input claim
        (or headline) can be associated with a single news article.
        Therefore, it is considered as classifying the news article
        body into one of the four categories above. Let
          <span class="inline-equation"><span class=
          "tex">$x_{i1}x_{i2}\ldots x_{iT_i}$</span></span> be the
          sequence of sentences of the article corresponding to a
          claim or headline <em>C<sub>i</sub></em> , the problem
          becomes sequence classification, i.e., <span class=
          "inline-equation"><span class="tex">$g^{\prime }:
          x_{i1}x_{i2}\ldots x_{iT_i} \rightarrow
          y_i$</span></span> , where <em>y<sub>i</sub></em> takes
          one of SDQC.<br />
        </li>
      </ul>
    </section>
    <section id="sec-10">
      <header>
        <div class="title-info">
          <h2><span class="section-number">4</span> Joint Rumor and
          Stance Detection</h2>
        </div>
      </header>
      <figure id="fig2">
        <img src=
        "../../../data/deliveryimages.acm.org/10.1145/3190000/3188729/images/www18companion-237-fig2.jpg"
        class="img-responsive" alt="Figure 2" longdesc="" />
        <div class="figure-caption">
          <span class="figure-number">Figure 2:</span> <span class=
          "figure-title">The two multi-task architectures. The
          embedding vector <span class=
          "inline-equation"><span class=
          "tex">$\tilde{x}^m_t$</span></span> is computed from the
          original input <span class="inline-equation"><span class=
          "tex">$x^m_t$</span></span> at the <em>t</em>-th step
          that is represented as a vector of <em>tf*idf</em> values
          of vocabulary words (we hide the original input for
          simplicity, and select <em>tf*idf</em> based on Occam's
          Razor principle), and then mapped into a low dimensional
          vector using the shared or task-specific parameters,
          followed by operations for sequence labeling or sequence
          classification depending on the specific tasks.</span>
        </div>
      </figure>
      <p>Compared to standalone learning models, multi-task
      learning approach can take advantage of the related tasks to
      learn complex signals indicative of fake information. By
      considering the inter-task correlations, the representations
      learned in one task can be shared and used to reinforce the
      feature learning of the other task, thus boosting the overall
      performance of both tasks via mutual feedback within a
      unified framework. For instance, a strong false rumor feature
      is most likely to be projected to the vicinity of a feature
      indicating denial or question in the shared representation
      space, whereas a feature indicating comment or time would be
      largely projected into the specific feature space of their
      own task.</p>
      <p>Inspired by the RNN-based neural multi-task
      model&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0026">26</a>],
      we present two deep architectures based on RNN with a shared
      layer. The first model contains only a single shared hidden
      layer and the second model is enhanced by considering
      additional task-specific hidden layers apart from the shared
      layer. Our model is different from &nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0026">26</a>] in that 1) we aim to deal
      with heterogeneous rumor-related tasks where input and output
      structures vary widely among the tasks while their model is
      focused on homogeneous, traditional text classification
      tasks; 2) our method learns to optimize separate objectives
      of different tasks instead of only a same objective; 3) we
      use Gated Recurrent Unit (GRU)&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0008">8</a>] for representing hidden
      units rather than Long-Short Term Memory
      (LSTM)&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
      "popover" data-placement="top" href="#BibPLXBIB0021">21</a>]
      for efficiency. The architectures of our models are shown in
      Figure&nbsp;<a class="fig" href="#fig2">2</a>.</p>
      <section id="sec-11">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.1</span> Uniform
            Shared-Layer Architecture</h3>
          </div>
        </header>
        <p>In this model, the different tasks share a same hidden
        layer and each task has its own task-specific input and
        embeddings, which is shown as the Uniform Shared-Layer
        Architecture in Figure&nbsp;2(a) .</p>
        <p>For a task <em>m</em>, given a sequence of posts or
        sentences <span class="inline-equation"><span class=
        "tex">$\lbrace x^m_t\rbrace$</span></span> for an input
        claim, a straightforward strategy is to map each input unit
        <span class="inline-equation"><span class=
        "tex">$x^m_t$</span></span> at time step <em>t</em> to a
        fixed-sized vector using one RNN, for which we adopt
        GRU&nbsp;[<a class="bib" data-trigger="hover" data-toggle=
        "popover" data-placement="top" href="#BibPLXBIB0008">8</a>]
        as hidden representation. For each <em>t</em>, the GRU
        transition equations are the following:</p>
        <div class="table-responsive" id="eq1">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            &amp;\tilde{x}^m_t=E^m x^m_t\\ &amp;r^m_t=\sigma \left(
            {W}^s_r \tilde{x}^m_t+ {U}^s_r h^m_{t-1}\right) \\
            &amp;z^m_t=\sigma \left( {W}^s_z \tilde{x}^m_t+ {U}^s_z
            h^m_{t-1}\right) \\ &amp;\tilde{h}^m_t=tanh\left(
            {W}^s_{h} \tilde{x}^m_t+ {U}^s_{h} (h^m_{t-1} \odot
            r_t)\right)\\ &amp;h^m_t=(1-z^m_t) \odot h^m_{t-1}
            +z^m_t \odot \tilde{h}^m_t \end{split}
            \end{equation}</span><br />
            <span class="equation-number">(1)</span>
          </div>
        </div>where <span class="inline-equation"><span class=
        "tex">$x^m_t$</span></span> is the <em>t</em>-th post and
        <em>E<sup>m</sup></em> denotes the task-specific embedding
        matrix, <span class="inline-equation"><span class=
        "tex">$[W^s_*, U^s_*]$</span></span> are the weight
        connections inside GRU which are <em>shared</em> across
        different tasks. As defined in standard GRU, <span class=
        "inline-equation"><span class="tex">$h^m_t$</span></span>
        and <span class="inline-equation"><span class=
        "tex">$h^m_{t-1}$</span></span> refer to the current and
        previous state, respectively; ⊙ denotes element-wise
        multiplication; a reset gate <span class=
        "inline-equation"><span class="tex">$r^m_t$</span></span>
        determines how to combine the current input <span class=
        "inline-equation"><span class="tex">$x^m_t$</span></span>
        with the previous memory, and an update gate <span class=
        "inline-equation"><span class="tex">$z^m_t$</span></span>
        defines how much previous memory from the previous posts is
        cascaded into the current time step; and <span class=
        "inline-equation"><span class=
        "tex">$\tilde{h}^m_t$</span></span> denotes the candidate
        activation of the hidden state <span class=
        "inline-equation"><span class="tex">$h^m_t$</span></span> .
        <p></p>
        <p>For the sequence classification in rumor detection task,
        the output of the last time step <em>h<sub>T</sub></em> can
        be straightforwardly associated with the representation of
        the entire post sequence. For stance classification task in
        particular, however, most previous research did not treat
        it as a sequence problem, especially for news data.
        Instead, it was typically modeled to classify a given
        headline-article (or claim-post) pair, which thus ignored
        the valuable contextual information among sentences (or
        posts)&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0038">38</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0046">46</a>]. Here we aim to solve a sequence
        problem (i.e., either being sequence labeling or sequence
        classification depending on the form of input data (see
        Section&nbsp;<a class="sec" href="#sec-9">3</a>)), and
        input a headline (or claim) at the first time step plus its
        corresponding sentences (or posts) sequence for the rest of
        the time steps in an RNN, provided that the pairwise
        similarities among the neighboring units can be leveraged
        to improve sequence labeling or classification performance
        (see Section&nbsp;<a class="sec" href="#sec-13">5</a> for
        detail).</p>
      </section>
      <section id="sec-12">
        <header>
          <div class="title-info">
            <h3><span class="section-number">4.2</span> Enhanced
            Shared-Layer Architecture</h3>
          </div>
        </header>
        <p>The Uniform Shared-Layer Architecture fully shares all
        the GRU parameters of the hidden features extracted from
        the two tasks. So, the two tasks can capture and share the
        common patterns that are highly weighted. However, there is
        a shortcoming as it ignores the fact that some patterns
        should be more important in one task than in the other. For
        example, since rumor detection task needs to pay more
        attention on veracity-related information, patterns
        conveying semantics like “true” and “false” would be more
        important than patterns representing “believe” and “don't
        think” which are supposed more useful for stance
        classification task. In order to address the problem, we
        extend the model by adding an extra task-specific layer
        into the architecture for each task.</p>
        <p>As shown in Figure&nbsp;2(b), the Enhanced Shared-Layer
        Architecture adopts two hidden layers for each task: one is
        used to extract the common pattens via the shared
        parameters, and the other is used to capture task-specific
        features via the separate parameter sets. Accordingly, each
        task is assigned a shared GRU layer and a task-specific GRU
        layer, which hopefully can be used to capture the shared
        and local representations for different tasks.</p>
        <p>Specifically, for a task <em>m</em>, the output of the
        shared layer at time step <em>t</em> is computed as
        <span class="inline-equation"><span class=
        "tex">$h_t^s=GRU(h^s_{t-1}, x^m_t)$</span></span> , where
        the function <em>GRU</em>(·) is a shorthand of
        Eq.&nbsp;<a class="eqn" href="#eq1">1</a>. To enhance the
        interaction between the task-specific layers and the shared
        layer, we redefine Eq.&nbsp;<a class="eqn" href=
        "#eq1">1</a> and let the hidden output at <em>t</em> be
        dependent on the hidden state from the shared layer
        <span class="inline-equation"><span class=
        "tex">$h^s_t$</span></span> , the previous hidden state
        from the task specific layer <span class=
        "inline-equation"><span class=
        "tex">$h^m_{t-1}$</span></span> , and the current input
        <span class="inline-equation"><span class=
        "tex">$x^m_t$</span></span> . Therefore, the hidden state
        of the task-specific layer for task <em>m</em> can be
        computed as:</p>
        <div class="table-responsive" id="eq2">
          <div class="display-equation">
            <span class="tex mytex">\begin{equation} \begin{split}
            &amp;\tilde{x}^m_t=E^m x^m_t\\ &amp;r^m_t=\sigma \left(
            {W}^m_r \tilde{x}^m_t+ {U}^m_r h^m_{t-1}+ {U}^{s
            \rightarrow m}_r h^s_t \right) \\ &amp;z^m_t=\sigma
            \left( {W}^m_z \tilde{x}^m_t+ {U}^m_z h^m_{t-1}+ {U}^{s
            \rightarrow m}_z h^s_t\right) \\
            &amp;\tilde{h}^m_t=tanh\left( {W}^m_{h} \tilde{x}^m_t+
            {U}^m_{h} (h^m_{t-1} \odot r^m_t)+ {U}^{s \rightarrow
            m}_h h^s_t\right)\\ &amp;h^m_t=(1-z^m_t) \odot
            h^m_{t-1} +z^m_t \odot \tilde{h}^m_t \end{split}
            \end{equation}</span><br />
            <span class="equation-number">(2)</span>
          </div>
        </div>where <span class="inline-equation"><span class=
        "tex">$x^m_t$</span></span> is the <em>t</em>-th input of
        task <em>m</em>, and <span class=
        "inline-equation"><span class="tex">$U^{s \rightarrow
        m}_*$</span></span> denotes the weight matrix which
        connects the shared layer and the task-specific layer. The
        other settings are same as standard GRU. We also tried
        using a gate to decide how much information from the shared
        layer <span class="inline-equation"><span class=
        "tex">$h^s_t$</span></span> should accept, just as the
        gating mechanism for <span class=
        "inline-equation"><span class=
        "tex">$h^m_{t-1}$</span></span> , but empirically
        Eq.&nbsp;<a class="eqn" href="#eq2">2</a> gave much better
        results. The reason might be that gating mechanism may not
        be able to well control signals flowing between different
        layers.
        <p></p>
      </section>
    </section>
    <section id="sec-13">
      <header>
        <div class="title-info">
          <h2><span class="section-number">5</span> The Training
          Procedure</h2>
        </div>
      </header>
      <p>For an input sequence of a task, its task-specific
      representation, emitted by the enhanced architecture, can be
      ultimately fed into different output layers for prediction.
      For the uniform architecture, in contrast, the hidden state
      from the shared layer can be directly fed into the output
      layers due to the lack of task-specific layer.</p>
      <p>In the rumor detection task, we mark its task index
      <em>m</em> = 1 and represent the whole post sequence of a
      claim using the hidden vector at the last time step
      <span class="inline-equation"><span class=
      "tex">$h^{m=1}_T$</span></span> . Accordingly, the final
      classification decision for the claim is formulated
      probabilistically as <em>softmax</em>:</p>
      <div class="table-responsive" id="eq3">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation}
          y=Softmax(V^{m=1} h^{m=1}_T +b^{m=1})
          \end{equation}</span><br />
          <span class="equation-number">(3)</span>
        </div>
      </div>where <em>y</em> is the vector of predicted
      probabilities over different rumor classes, <em>V</em>
      <sup><em>m</em> = 1</sup> is the weights of the output layer,
      and <em>b</em> <sup><em>m</em> = 1</sup> is the trainable
      bias, both of which are task-specific parameters for the
      rumor detection task.
      <p></p>
      <p>In the stance classification task, we mark the index
      <em>m</em> = 2 and let <span class=
      "inline-equation"><span class="tex">$h^{m=2}_1$</span></span>
      and <span class="inline-equation"><span class="tex">$\lbrace
      h^{m=2}_t\rbrace _{t=2}^T$</span></span> be the
      low-dimensional task-specific representations of the claim
      (or headline) which are placed at the first time step and the
      sequence of posts (or sentences) at the rest of time steps to
      be classified<a class="fn" href="#fn3" id=
      "foot-fn3"><sup>3</sup></a>, respectively. We then feed them
      into a fully connected layer with <em>softmax</em> activation
      functions to generate the prediction for each post (or an
      article<a class="fn" href="#fn4" id=
      "foot-fn4"><sup>4</sup></a>):</p>
      <div class="table-responsive" id="eq4">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation}
          y_t=Softmax(V_1^{m=2} h^{m=2}_1 +V^{m=2}
          h^{m=2}_t+b^{m=2}), \textrm { ~~for~} t\ge 2
          \end{equation}</span><br />
          <span class="equation-number">(4)</span>
        </div>
      </div>where <em>y<sub>t</sub></em> is the predicted
      probabilities over different stance classes at time
      <em>t</em> ≥ 2, <span class="inline-equation"><span class=
      "tex">$V_1^{m=1}$</span></span> and <em>V</em>
      <sup><em>m</em> = 1</sup> respectively denote the weights of
      the output layer for the claim (or headline) and the tweets
      (or sentences), and <em>b</em> <sup><em>m</em> = 2</sup> is a
      bias term. All of them are task-specific parameters for
      stance detection.
      <p></p>
      <p><img src=
      "../../../data/deliveryimages.acm.org/10.1145/3190000/3188729/images/www18companion-237-img1.svg"
      class="img-responsive" alt="" longdesc="" /></p>
      <p>The parameters of the proposed multi-task model for each
      task are trained to minimize the cross-entropy of the
      predicted and ground truth distributions:</p>
      <div class="table-responsive" id="eq5">
        <div class="display-equation">
          <span class="tex mytex">\begin{equation} L=-\sum _t \sum
          _c g^c_t \log {y^c_t} + \lambda ||\Theta ||^2_2\
          \end{equation}</span><br />
          <span class="equation-number">(5)</span>
        </div>
      </div>where <span class="inline-equation"><span class=
      "tex">$g^c_t$</span></span> and <span class=
      "inline-equation"><span class="tex">$y^c_t$</span></span> are
      respectively the ground truth and the predicted probability
      corresponding to the <em>c</em>-th class at time step
      <em>t</em>. Here the <em>L</em> <sub>2</sub> regularizer
      trades off the error and the scale of the model, <em>Θ</em>
      is all the model parameters, and <em>λ</em> is the trade-off
      coefficient. Note that the summation over <em>t</em> has
      different forms in different cases: For sequence
      classification (i.e., rumor detection or article-based stance
      classification), <em>t</em> takes the last time step
      <em>T</em> because there is output only at <em>T</em>; For
      sequence labeling (i.e., tweets stance detection), 2 ≤
      <em>t</em> ≤ <em>T</em> as there is an outputs at each step
      from step 2 up to <em>T</em>.
      <p></p>
      <p>We train our model using stochastic gradient decent by
      looping over the tasks similarly as&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0010">10</a>, <a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0027">27</a>]. The training procedure
      is shown in Algorithm&nbsp;1, where in each iteration, a task
      is selected randomly, and the model is updated according to
      the task-specific objective. More specifically, 1) model
      parameters are empirically initialized with uniform
      distribution, and updated by employing the derivative of the
      loss through back-propagation&nbsp;[<a class="bib"
      data-trigger="hover" data-toggle="popover" data-placement=
      "top" href="#BibPLXBIB0011">11</a>]; 2) we use AdaGrad
      algorithm&nbsp;[<a class="bib" data-trigger="hover"
      data-toggle="popover" data-placement="top" href=
      "#BibPLXBIB0015">15</a>] to speed up the convergence. 3) we
      fix the vocabulary size as 5,000, the size of embedding and
      hidden units as 100. 4) we run Algorithm&nbsp;1 until the
      loss value of each task converges or the maximum epoch number
      is met.</p>
    </section>
    <section id="sec-14">
      <header>
        <div class="title-info">
          <h2><span class="section-number">6</span> Experiments and
          Results</h2>
        </div>
      </header>
      <section id="sec-15">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.1</span> Datasets
            and Evaluation Metrics</h3>
          </div>
        </header>
        <p>For rumor detection task, we made expansion based on a
        public Twitter dataset described in &nbsp;Liu et&nbsp;al.
        [<a class="bib" data-trigger="hover" data-toggle="popover"
        data-placement="top" href="#BibPLXBIB0028">28</a>]. The
        original dataset were used for binary classification of
        claims into rumor and non-rumor given the relevant tweets
        of each claim. We finer granularized the ground-truth label
        set by using the four NTFU tags according to the veracity
        tagging adopted by the popular rumor debunking websites
        (e.g., <a class="link-inline force-break" href=
        "http://Snopes.com">Snopes.com</a>, <a class=
        "link-inline force-break" href=
        "http://Emergent.info">Emergent.info</a>, etc)<a class="fn"
        href="#fn5" id="foot-fn5"><sup>5</sup></a>. In addition,
        the fraction of different types of rumors are imbalanced in
        real world. As per our statistics based on <a class=
        "link-inline force-break" href=
        "http://Snopes.com">Snopes.com</a> since January 2015, the
        proportions of articles under the NTFU categories are as
        the following: 76.0% non-rumors, 16.5% false rumors, 3.4%
        true rumors and 4.1% unverified rumors. Accordingly, we
        enriched the dataset to conform to such class distribution
        by implementing the tweets gathering method described
        by&nbsp;Liu et&nbsp;al. [<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0028">28</a>]. Table&nbsp;<a class="tbl" href=
        "#tab1">1</a>(a) gives the statistics of this expanded
        dataset which is named as LIU+.</p>
        <p>For stance classification task, we used the PHEME
        dataset&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0049">49</a>] which contains 297 claims
        corresponding to eight breaking events, which provide
        tweet-level stance annotations. We followed the common
        practice of prior works&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0030">30</a>, <a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0048">48</a>] that employed this dataset to
        convert the original labels into SDQC set based on a set of
        rules proposed in&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0030">30</a>]. In this task, we also examined an
        additional dataset based on news articles released by the
        2017 Fake News Challenge (FNC, <a class=
        "link-inline force-break" href=
        "http://www.fakenewschallenge.org">www.fakenewschallenge.org</a>),
        which aimed to classify the text in a news article body
        with respect to the content in its headline. There are four
        categories, into which the stance must be classified:
        <em>agrees, disagrees, discusses and unrelated</em>. We
        summarize the statistics of the two stance datasets in
        Table&nbsp;<a class="tbl" href="#tab1">1</a>(b).</p>
        <p>Owing to the imbalanced class prevalence, evaluation
        solely based on accuracy cannot arguably suffice to capture
        competitive performance beyond the majority
        class&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0048">48</a>]. Therefore, we used both
        micro-averaged and macro-averaged F1 scores as evaluation
        metrics for both tasks. We hold out 10% of the instances in
        each dataset for model tuning, and for the rest of the
        instances, we perform 5-fold cross-validation throughout
        all experiments.</p>
        <div class="table-responsive" id="tab1">
          <div class="table-caption">
            <span class="table-number">Table 1:</span> <span class=
            "table-title">Statistics of the datasets.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th colspan="5" style="text-align:center;">(a)
                Rumor detection dataset</th>
              </tr>
              <tr>
                <th style="text-align:left;">LIU+</th>
                <th style="text-align:left;">N</th>
                <th style="text-align:left;">T</th>
                <th style="text-align:left;">F</th>
                <th>U</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Claim #</td>
                <td style="text-align:left;">2,280</td>
                <td style="text-align:left;">99</td>
                <td style="text-align:left;">498</td>
                <td>123</td>
              </tr>
              <tr>
                <td style="text-align:left;">Proportion</td>
                <td style="text-align:left;">76.0%</td>
                <td style="text-align:left;">3.3%</td>
                <td style="text-align:left;">16.6%</td>
                <td>4.1%</td>
              </tr>
              <tr>
                <td style="text-align:left;">posts # / Claim</td>
                <td style="text-align:left;">757</td>
                <td style="text-align:left;">1,029</td>
                <td style="text-align:left;">587</td>
                <td>686</td>
              </tr>
              <tr>
                <td style="text-align:left;">Users #</td>
                <td style="text-align:left;">61,7374</td>
                <td style="text-align:left;">6,5475</td>
                <td style="text-align:left;">18,2459</td>
                <td>5,5298</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
              </tr>
            </tbody>
            <thead>
              <tr>
                <th colspan="5" style="text-align:center;">(b)
                Stance classification dataset</th>
              </tr>
              <tr>
                <th style="text-align:left;">PHEME</th>
                <th style="text-align:left;">Support</th>
                <th style="text-align:left;">Deny</th>
                <th style="text-align:left;">Question</th>
                <th>Comment</th>
              </tr>
            </thead>
            <tr>
              <td style="text-align:left;">Tweets #</td>
              <td style="text-align:left;">891</td>
              <td style="text-align:left;">335</td>
              <td style="text-align:left;">353</td>
              <td>2,855</td>
            </tr>
            <tr>
              <td style="text-align:left;">Proportion</td>
              <td style="text-align:left;">20.09%</td>
              <td style="text-align:left;">7.56%</td>
              <td style="text-align:left;">7.96%</td>
              <td>64.39%</td>
            </tr>
            <tr>
              <td style="text-align:left;">Users #</td>
              <td style="text-align:left;">732</td>
              <td style="text-align:left;">295</td>
              <td style="text-align:left;">318</td>
              <td>2,036</td>
            </tr>
            <thead>
              <tr>
                <th style="text-align:left;">FNC</th>
                <th style="text-align:left;">Agree</th>
                <th style="text-align:left;">Disagree</th>
                <th style="text-align:left;">Discuss</th>
                <th>Unrelated</th>
              </tr>
            </thead>
            <tr>
              <td style="text-align:left;">articles #</td>
              <td style="text-align:left;">5,581</td>
              <td style="text-align:left;">1,537</td>
              <td style="text-align:left;">13,373</td>
              <td>54,894</td>
            </tr>
            <tr>
              <td style="text-align:left;">Proportion</td>
              <td style="text-align:left;">7.40%</td>
              <td style="text-align:left;">2.03%</td>
              <td style="text-align:left;">17.74%</td>
              <td>72.81%</td>
            </tr>
            <tr>
              <td style="text-align:left;">Sentence #</td>
              <td style="text-align:left;">62,593</td>
              <td style="text-align:left;">18,090</td>
              <td style="text-align:left;">146,872</td>
              <td>582,206</td>
            </tr>
          </table>
        </div>
      </section>
      <section id="sec-16">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.2</span> Rumor
            Detection</h3>
          </div>
        </header>
        <div class="table-responsive" id="tab2">
          <div class="table-caption">
            <span class="table-number">Table 2:</span> <span class=
            "table-title">Results on rumor detection.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;">Method</th>
                <th style="text-align:left;"></th>
                <th style="text-align:left;"></th>
                <th style="text-align:left;">N</th>
                <th style="text-align:left;">F</th>
                <th style="text-align:left;">T</th>
                <th>U</th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:left;">MicF1</th>
                <th style="text-align:left;">MacF1</th>
                <th style="text-align:left;"><em>F</em>
                <sub>1</sub></th>
                <th style="text-align:left;"><em>F</em>
                <sub>1</sub></th>
                <th style="text-align:left;"><em>F</em>
                <sub>1</sub></th>
                <th><em>F</em> <sub>1</sub></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">
                  DTR&nbsp;[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0047">47</a>]
                </td>
                <td style="text-align:left;">0.734</td>
                <td style="text-align:left;">0.338</td>
                <td style="text-align:left;">0.856</td>
                <td style="text-align:left;">0.349</td>
                <td style="text-align:left;">0.071</td>
                <td>0.076</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  SVM-RBF&nbsp;[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0045">45</a>]
                </td>
                <td style="text-align:left;">0.760</td>
                <td style="text-align:left;">0.216</td>
                <td style="text-align:left;">0.864</td>
                <td style="text-align:left;">0.000</td>
                <td style="text-align:left;">0.000</td>
                <td>0.000</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  DTC&nbsp;[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0006">6</a>]
                </td>
                <td style="text-align:left;">0.793</td>
                <td style="text-align:left;">0.357</td>
                <td style="text-align:left;">0.883</td>
                <td style="text-align:left;">0.528</td>
                <td style="text-align:left;">0.018</td>
                <td>0.000</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  SVM-TS&nbsp;[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0033">33</a>]
                </td>
                <td style="text-align:left;">0.786</td>
                <td style="text-align:left;">0.361</td>
                <td style="text-align:left;">0.879</td>
                <td style="text-align:left;">0.506</td>
                <td style="text-align:left;">0.037</td>
                <td>0.014</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  RFC&nbsp;[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0023">23</a>]
                </td>
                <td style="text-align:left;">
                <strong>0.799</strong></td>
                <td style="text-align:left;">0.389</td>
                <td style="text-align:left;">
                <strong>0.889</strong></td>
                <td style="text-align:left;">0.541</td>
                <td style="text-align:left;">0.031</td>
                <td>0.091</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  MT-single&nbsp;[<a class="bib" data-trigger=
                  "hover" data-toggle="popover" data-placement=
                  "top" href="#BibPLXBIB0032">32</a>]
                </td>
                <td style="text-align:left;">0.762</td>
                <td style="text-align:left;">0.426</td>
                <td style="text-align:left;">0.875</td>
                <td style="text-align:left;">0.487</td>
                <td style="text-align:left;">0.05</td>
                <td>0.292</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td colspan="6" style="text-align:center;">
                  LIU+ &amp; PHEME datasets
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:left;">MT-US</td>
                <td style="text-align:left;">0.761</td>
                <td style="text-align:left;">0.431</td>
                <td style="text-align:left;">0.872</td>
                <td style="text-align:left;">0.513</td>
                <td style="text-align:left;">0.089</td>
                <td>0.292</td>
              </tr>
              <tr>
                <td style="text-align:left;">MT-ES</td>
                <td style="text-align:left;">0.783</td>
                <td style="text-align:left;">
                <strong>0.464</strong></td>
                <td style="text-align:left;">0.876</td>
                <td style="text-align:left;">
                <strong>0.534</strong></td>
                <td style="text-align:left;">
                <strong>0.114</strong></td>
                <td><strong>0.333</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td colspan="6" style="text-align:center;">
                  LIU+ &amp; FNC dataset
                  <hr />
                </td>
              </tr>
              <tr>
                <td style="text-align:left;">MT-US</td>
                <td style="text-align:left;">0.752</td>
                <td style="text-align:left;">0.439</td>
                <td style="text-align:left;">0.858</td>
                <td style="text-align:left;">
                <strong>0.545</strong></td>
                <td style="text-align:left;">0.105</td>
                <td>0.323</td>
              </tr>
              <tr>
                <td style="text-align:left;">MT-ES</td>
                <td style="text-align:left;">0.778</td>
                <td style="text-align:left;">
                <strong>0.443</strong></td>
                <td style="text-align:left;">0.872</td>
                <td style="text-align:left;">0.503</td>
                <td style="text-align:left;">
                <strong>0.074</strong></td>
                <td><strong>0.324</strong></td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>Table&nbsp;<a class="tbl" href="#tab2">2</a> compares
        rumor detection results of the following systems:</p>
        <p><strong>DTR</strong>: A Decision-Tree-based Ranking
        method to identify trending rumors&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0047">47</a>] by searching for
        enquiry phrases.</p>
        <p><strong>DTC</strong> and <strong>SVM-RBF</strong>: The
        Twitter information credibility model using Decision Tree
        Classifier&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0006">6</a>] and the SVM-based model with RBF
        kernel&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0045">45</a>], respectively, both using various
        handcrafted features based on the overall statistics of the
        posts.</p>
        <p><strong>RFC</strong>: The Random Forest Classifier using
        three parameters to fit the temporal properties and a set
        of handcrafted features on user, linguistic and structure
        characteristics&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0023">23</a>].</p>
        <p><strong>SVM-TS</strong>: A linear SVM classification
        model that uses time-series to model the variation of a set
        of handcrafted features&nbsp;[<a class="bib" data-trigger=
        "hover" data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0033">33</a>].</p>
        <p><strong>MT-US</strong>: Our multi-task model with the
        Uniform Shared-Layer Architecture.</p>
        <p><strong>MT-ES</strong>: Our multi-task model with the
        Enhanced Shared-Layer Architecture.</p>
        <p><strong>MT-single</strong>: Our MT-US model that removes
        the stance classification component. This reduces to an
        existing single-task rumor detection model based on RNN
        proposed in&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0032">32</a>].</p>
        <p>We implement <strong>DTC</strong> and
        <strong>RFC</strong> using Weka<a class="fn" href="#fn6"
        id="foot-fn6"><sup>6</sup></a>, SVM-based models using
        LibSVM<a class="fn" href="#fn7" id=
        "foot-fn7"><sup>7</sup></a> and neural-network-based models
        with Theano<a class="fn" href="#fn8" id=
        "foot-fn8"><sup>8</sup></a>.</p>
        <p>We highlight that some baseline models above have
        exploited <em>stance as features</em> for rumor detection:
        DTR relies on the questioning or denying stances to debunk
        rumors; others like RFC and SVM-TS craft some features
        relative to individual opinions. So, they are reasonably
        compared with our proposed method here.</p>
        <p>The benefit of using multi-task learning is obvious
        among all the baselines due to the improvement of Macro-F1
        and F1 scores over most classes. Further, we have the
        following observations:</p>
        <p>In the first glance, it appears that our method does not
        have advantage due to the lower Micro-F1 scores than many
        baselines. But when we look at specific classes, it is
        found that the baselines performing better in Micro-F1
        (e.g., DTC, SVM-TS, RFC) are only better off on the
        majority class (i.e., non-rumors), but much worse off on
        all minority classes. This is also why our method achieves
        clearly higher Macro-F1 performance than all the baselines.
        This verifies that the proposed method is overall
        advantageous, especially on the three minority rumor types
        which are more difficult to classify, and can better deal
        with the imbalanced class prevalence in rumor
        detection.</p>
        <p>SVM-TS and RFC appear to be better than other
        feature-based baselines because both of them utilize an
        extensive set of features especially focusing on temporal
        traits. But they are much worse than all the RNN-based
        models, which can learn advanced representations of
        responsive tweets by capturing the hidden non-linear
        correlations. This indicates the effectiveness of complex
        signals indicative of rumors beyond surface signals or
        shallow patterns typically exploited in the baseline
        models.</p>
        <p>MT-US outperforms all the baselines including the models
        that have incorporated stance information as features. This
        is because the proposed multi-task framework cannot only
        learn the representation of rumor detection task itself
        effectively via a neural model, but also can strengthen the
        learned features by transferring some helpful
        representation from the task of stance detection. We can
        also see that MT-ES, as an extension of MT-US, yields the
        highest Macro-F1 score on both datasets, suggesting that
        the learned representation is more effective due to the
        introduction of task-specific representation layers in
        addition to the shared layer. Furthermore, the performance
        of our models on LIU+ &amp; PHEME data is generally better
        than that on LIU+ &amp; FNC. This is because PHEME data are
        also based on tweets and may share more common features
        with LIU+ dataset, such as specific symbols or writing
        styles.</p>
      </section>
      <section id="sec-17">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.3</span> Stance
            Classification</h3>
          </div>
        </header>
        <div class="table-responsive" id="tab3">
          <div class="table-caption">
            <span class="table-number">Table 3:</span> <span class=
            "table-title">Comparison with baselines for stance
            detection.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th colspan="7" style="text-align:center;">
                  (a) PHEME dataset (S: Support; D: Deny; Q:
                  Question; C: Comment)
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:left;"></th>
                <th style="text-align:left;"></th>
                <th style="text-align:left;">S</th>
                <th style="text-align:left;">D</th>
                <th style="text-align:left;">Q</th>
                <th>C</th>
              </tr>
              <tr>
                <th style="text-align:left;">Method</th>
                <th style="text-align:left;">MicF1</th>
                <th style="text-align:left;">MacF1</th>
                <th style="text-align:left;"><em>F</em>
                <sub>1</sub></th>
                <th style="text-align:left;"><em>F</em>
                <sub>1</sub></th>
                <th style="text-align:left;"><em>F</em>
                <sub>1</sub></th>
                <th><em>F</em> <sub>1</sub></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">Majority Vote</td>
                <td style="text-align:left;">0.641</td>
                <td style="text-align:left;">0.195</td>
                <td style="text-align:left;">0.000</td>
                <td style="text-align:left;">0.000</td>
                <td style="text-align:left;">0.000</td>
                <td>0.781</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  NB&nbsp;[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0038">38</a>]
                </td>
                <td style="text-align:left;">0.277</td>
                <td style="text-align:left;">0.244</td>
                <td style="text-align:left;">0.395</td>
                <td style="text-align:left;">0.038</td>
                <td style="text-align:left;">0.182</td>
                <td>0.362</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  DT&nbsp;[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0018">18</a>]
                </td>
                <td style="text-align:left;">0.552</td>
                <td style="text-align:left;">0.374</td>
                <td style="text-align:left;">0.421</td>
                <td style="text-align:left;">0.112</td>
                <td style="text-align:left;">0.278</td>
                <td>0.688</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  BOW&nbsp;[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0036">36</a>]
                </td>
                <td style="text-align:left;">
                <strong>0.652</strong></td>
                <td style="text-align:left;">0.344</td>
                <td style="text-align:left;">0.273</td>
                <td style="text-align:left;">0.108</td>
                <td style="text-align:left;">0.206</td>
                <td><strong>0.790</strong></td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  HP[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0030">30</a>]
                </td>
                <td style="text-align:left;">0.650</td>
                <td style="text-align:left;">0.390</td>
                <td style="text-align:left;">0.519</td>
                <td style="text-align:left;">0.079</td>
                <td style="text-align:left;">0.394</td>
                <td>0.771</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  CNN&nbsp;[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0007">7</a>]
                </td>
                <td style="text-align:left;">0.642</td>
                <td style="text-align:left;">0.324</td>
                <td style="text-align:left;">0.301</td>
                <td style="text-align:left;">0.08</td>
                <td style="text-align:left;">0.178</td>
                <td>0.739</td>
              </tr>
              <tr>
                <td style="text-align:left;">
                  BiGRU&nbsp;[<a class="bib" data-trigger="hover"
                  data-toggle="popover" data-placement="top" href=
                  "#BibPLXBIB0003">3</a>]
                </td>
                <td style="text-align:left;">0.605</td>
                <td style="text-align:left;">0.373</td>
                <td style="text-align:left;">0.299</td>
                <td style="text-align:left;">0.158</td>
                <td style="text-align:left;">0.286</td>
                <td>0.751</td>
              </tr>
              <tr>
                <td style="text-align:left;">MT-single</td>
                <td style="text-align:left;">0.583</td>
                <td style="text-align:left;">0.344</td>
                <td style="text-align:left;">0.212</td>
                <td style="text-align:left;">0.154</td>
                <td style="text-align:left;">0.272</td>
                <td>0.737</td>
              </tr>
              <tr>
                <td style="text-align:left;">MT-US</td>
                <td style="text-align:left;">0.635</td>
                <td style="text-align:left;">0.400</td>
                <td style="text-align:left;">
                <strong>0.355</strong></td>
                <td style="text-align:left;">0.116</td>
                <td style="text-align:left;">0.337</td>
                <td>0.776</td>
              </tr>
              <tr>
                <td style="text-align:left;">MT-ES</td>
                <td style="text-align:left;">0.622</td>
                <td style="text-align:left;">
                <strong>0.430</strong></td>
                <td style="text-align:left;">0.314</td>
                <td style="text-align:left;">
                <strong>0.158</strong></td>
                <td style="text-align:left;">
                <strong>0.531</strong></td>
                <td>0.739</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
                <td></td>
              </tr>
            </tbody>
            <thead>
              <tr>
                <th colspan="7" style="text-align:center;">
                  (b) FNC dataset (A: Agree; N: Disagree; D:
                  Discuss; U: Unrelated)
                  <hr />
                </th>
              </tr>
              <tr>
                <th style="text-align:left;">Method</th>
                <th style="text-align:left;"></th>
                <th style="text-align:left;"></th>
                <th style="text-align:left;">A</th>
                <th style="text-align:left;">N</th>
                <th style="text-align:left;">D</th>
                <th>U</th>
              </tr>
              <tr>
                <th style="text-align:left;"></th>
                <th style="text-align:left;">MicF1</th>
                <th style="text-align:left;">MacF1</th>
                <th style="text-align:left;"><em>F</em>
                <sub>1</sub></th>
                <th style="text-align:left;"><em>F</em>
                <sub>1</sub></th>
                <th style="text-align:left;"><em>F</em>
                <sub>1</sub></th>
                <th><em>F</em> <sub>1</sub></th>
              </tr>
            </thead>
            <tr>
              <td style="text-align:left;">Majority Vote</td>
              <td style="text-align:left;">0.722</td>
              <td style="text-align:left;">0.209</td>
              <td style="text-align:left;">0.000</td>
              <td style="text-align:left;">0.000</td>
              <td style="text-align:left;">0.000</td>
              <td>0.839</td>
            </tr>
            <tr>
              <td style="text-align:left;">
                NB&nbsp;[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0038">38</a>]
              </td>
              <td style="text-align:left;">0.676</td>
              <td style="text-align:left;">0.214</td>
              <td style="text-align:left;">0.000</td>
              <td style="text-align:left;">0.003</td>
              <td style="text-align:left;">0.043</td>
              <td>0.810</td>
            </tr>
            <tr>
              <td style="text-align:left;">
                DT&nbsp;[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0018">18</a>]
              </td>
              <td style="text-align:left;">0.615</td>
              <td style="text-align:left;">0.240</td>
              <td style="text-align:left;">0.054</td>
              <td style="text-align:left;">0.013</td>
              <td style="text-align:left;">0.127</td>
              <td>0.767</td>
            </tr>
            <tr>
              <td style="text-align:left;">
                BOW&nbsp;[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0036">36</a>]
              </td>
              <td style="text-align:left;">
              <strong>0.724</strong></td>
              <td style="text-align:left;">0.214</td>
              <td style="text-align:left;">0.010</td>
              <td style="text-align:left;">0.000</td>
              <td style="text-align:left;">0.000</td>
              <td><strong>0.847</strong></td>
            </tr>
            <tr>
              <td style="text-align:left;">
                HP[<a class="bib" data-trigger="hover" data-toggle=
                "popover" data-placement="top" href=
                "#BibPLXBIB0030">30</a>]
              </td>
              <td style="text-align:left;">−</td>
              <td style="text-align:left;">−</td>
              <td style="text-align:left;">−</td>
              <td style="text-align:left;">−</td>
              <td style="text-align:left;">−</td>
              <td>−</td>
            </tr>
            <tr>
              <td style="text-align:left;">
                CNN&nbsp;[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0007">7</a>]
              </td>
              <td style="text-align:left;">0.691</td>
              <td style="text-align:left;">0.277</td>
              <td style="text-align:left;">0.054</td>
              <td style="text-align:left;">0.000</td>
              <td style="text-align:left;">0.242</td>
              <td>0.817</td>
            </tr>
            <tr>
              <td style="text-align:left;">
                BiGRU&nbsp;[<a class="bib" data-trigger="hover"
                data-toggle="popover" data-placement="top" href=
                "#BibPLXBIB0003">3</a>]
              </td>
              <td style="text-align:left;">0.571</td>
              <td style="text-align:left;">0.305</td>
              <td style="text-align:left;">0.178</td>
              <td style="text-align:left;">0.025</td>
              <td style="text-align:left;">0.297</td>
              <td>0.718</td>
            </tr>
            <tr>
              <td style="text-align:left;">MT-single</td>
              <td style="text-align:left;">0.584</td>
              <td style="text-align:left;">0.291</td>
              <td style="text-align:left;">0.163</td>
              <td style="text-align:left;">0.026</td>
              <td style="text-align:left;">0.243</td>
              <td>0.731</td>
            </tr>
            <tr>
              <td style="text-align:left;">MT-US</td>
              <td style="text-align:left;">0.604</td>
              <td style="text-align:left;">0.310</td>
              <td style="text-align:left;">0.094</td>
              <td style="text-align:left;">
              <strong>0.103</strong></td>
              <td style="text-align:left;">
              <strong>0.298</strong></td>
              <td>0.741</td>
            </tr>
            <tr>
              <td style="text-align:left;">MT-ES</td>
              <td style="text-align:left;">0.609</td>
              <td style="text-align:left;">
              <strong>0.328</strong></td>
              <td style="text-align:left;">
              <strong>0.219</strong></td>
              <td style="text-align:left;">0.096</td>
              <td style="text-align:left;">0.251</td>
              <td>0.744</td>
            </tr>
          </table>
        </div>
        <p>Table&nbsp;<a class="tbl" href="#tab3">3</a> shows the
        results on stance classification by comparing the following
        systems:</p>
        <p><strong>Majority Vote</strong>: This method simply takes
        the class of majority in the training data to predict the
        stance in test data.</p>
        <p><strong>NB</strong>: A Naive Bayes
        classifier&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0038">38</a>] that utilizes a set of
        hand-crafted features.</p>
        <p><strong>DT</strong>: A J48 decision tree
        classifier&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0018">18</a>], which adopts an enriched set of
        features such as temporal information.</p>
        <p><strong>BOW</strong>: A SVM classifier using
        bag-of-words and N-grams (e.g., 1-gram, bi-gram and
        tri-gram) features as reported in&nbsp;[<a class="bib"
        data-trigger="hover" data-toggle="popover" data-placement=
        "top" href="#BibPLXBIB0036">36</a>].</p>
        <p><strong>HP</strong>: The state-of-the-art approach
        proposed by&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0030">30</a>] that classifies stance by using
        Hawkes process and exploits both temporal and textual
        information.</p>
        <p><strong>CNN</strong>: A convolutional neural model
        proposed in&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0007">7</a>] for obtaining the representation of
        each tweet and classifying tweet stances with a softmax
        layer.</p>
        <p><strong>BiGRU</strong>: A bidirectional RNN-based tweet
        stance model&nbsp;[<a class="bib" data-trigger="hover"
        data-toggle="popover" data-placement="top" href=
        "#BibPLXBIB0003">3</a>] which considered the bidirectional
        contexts between target and tweet. We replaced the original
        LSTM units with GRU for fair comparison.</p>
        <p><strong>MT-single</strong>: Our MT-US model that removes
        the rumor detection component, as a strong baseline for
        comparison between single-task model and multi-task
        model.</p>
        <p><strong>MT-US</strong> and <strong>MT-ES</strong>: Our
        multi-task models with the Uniform Shared-Layer and
        Enhanced Shared-Layer Architecture.</p>
        <p>The superiority of the multi-task proposals is clear as
        MT-US and MT-ES yield much better results than all
        baselines in terms of Macro-F1 scores and F1 scores of most
        classes.</p>
        <p>It is observed that the Micro-F1 for Majority Vote is
        very high. This is unsurprising due to the very imbalanced
        class prevalences: the majority of the instances fall into
        “comment” (or “unrelated”) class. It has been similarly
        demonstrated by the lower Micro-F1 score of our models on
        rumor detection task (see Section&nbsp;<a class="sec" href=
        "#sec-16">6.2</a>).</p>
        <p>For Macro-F1 scores, those feature-based methods like
        NB, DT and BOW perform obviously poorly because the feature
        engineering is generally biased and less effective, which
        is hard to generalize. HP outperforms other baselines
        because of its wider spectrum of information incorporated
        including post contents and temporal properties. But it is
        still clearly worse than our proposed method since similar
        as other baselines HP just utilized surface-form features
        like N-grams to represent content while our method can
        learn the hidden pattens for better representation. Note
        that HP is specifically designed for dealing with
        tweet-like dataset in time sequence labeling task that is
        dependent on the detailed post time, and therefore, it is
        not applicable on the FNC dataset.</p>
        <p>All the neural-network-based baselines (i.e., MT-single,
        BiGRU, CNN) perform worse than our two multi-task models
        because they are all single-task models regardless of their
        strong feature capturing power. In our multi-task models,
        MT-ES performs better than MT-US, suggesting the improved
        effectiveness by adding the task-specific layers to each
        task upon the shared layer.</p>
        <p>Interestingly, all the models perform worse on FNC than
        PHEME dataset. This is because most of existing stance
        classification methods are designed for dealing with social
        media data. However, the large improvements made by our
        multi-task models, especially on FNC dataset, indicate that
        the pattens learned from different data platforms can be
        complementary to each other. This suggests that our
        proposed method can be more effectively deployed to news
        domain other than social media platform.</p>
        <p>Furthermore, when drilling down to the performance of
        MT-US and MT-ES on specific classes, we find that there are
        distinct observations of model performance between the
        PHEME and FNC datasets. For example, on PHEME, MT-ES
        performs better for the “Deny” class than MT-US does, but
        on FNC, the trend is reversed for the “Disagree” class.
        This can be explained by the influence resulting from the
        class prevalence that varies across different datasets and
        may sometimes affect the model's performance (e.g., the
        prevalence of “Deny” is much lower than “Disagree”).</p>
        <p>With these comprehensive experiments on both tasks, we
        confirm the advantages of our multi-task approach over a
        few strong state-of-the-art baselines.</p>
      </section>
      <section id="sec-18">
        <header>
          <div class="title-info">
            <h3><span class="section-number">6.4</span> Case
            Study</h3>
          </div>
        </header>
        <div class="table-responsive" id="tab4">
          <div class="table-caption">
            <span class="table-number">Table 4:</span> <span class=
            "table-title">Typical patterns captured by shared layer
            and task-specific layer of MT-ES compared with the
            single task model MT-single on the two tasks.</span>
          </div>
          <table class="table">
            <thead>
              <tr>
                <th style="text-align:left;">Model</th>
                <th style="text-align:center;">Shared Layer</th>
                <th style="text-align:center;">Rumor-specific</th>
                <th>Stance-specific</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="text-align:left;">MT-ES</td>
                <td style="text-align:center;">really?, what?</td>
                <td style="text-align:center;">what?, really?</td>
                <td>why?, what is</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:center;">not like, great,
                omg</td>
                <td style="text-align:center;">is real/fact</td>
                <td>what happened</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:center;">disgusting,
                scary</td>
                <td style="text-align:center;">totally false</td>
                <td>no doubt, may</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:center;">I guess,
                probably</td>
                <td style="text-align:center;">seriously wrong</td>
                <td>not sure, really?</td>
              </tr>
              <tr>
                <td style="text-align:left;">MT-single</td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">what is, what?</td>
                <td>no doubt</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">seriously wrong</td>
                <td>may be, not</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:center;">
                <strong>−</strong></td>
                <td style="text-align:center;">totally false</td>
                <td>what happened</td>
              </tr>
              <tr>
                <td style="text-align:left;"></td>
                <td style="text-align:center;"></td>
                <td style="text-align:center;">is real, wtf?</td>
                <td>what is, why</td>
              </tr>
            </tbody>
          </table>
        </div>
        <p>To get an intuitive understanding of what is happening
        when we use the multi-task model, we design an experiment
        to try to disclose the behaviors of neurons in
        task-specific and shared layer. Specifically, from the
        hidden vector of each post at the shared and task-specific
        layer, we look for those elements with the largest feature
        values, and map them into the corresponding elements in the
        input layer so that we can find out those important
        patterns.</p>
        <p>We sample a detected (true) rumor claim about “Saudi
        Arabia confers citizenship on a robot named Sophia” from
        several recent news and list some typical patterns captured
        by MT-single and our Enhanced Shared-Layer Architecture on
        LIU+ and PHEME datasets. In Table&nbsp;<a class="tbl" href=
        "#tab4">4</a>, we can see that: 1) Some patterns captured
        by MT-single can be also captured by the task-specific
        layer of MT-ES, which indicates that the task-specific
        layer captures as much information as MT-single does. 2)
        The shared layer of MT-ES captures some inclusive patterns
        such as “not like”, “I guess”, “great”, etc., which may
        appear not as frequent as task-specific patterns, but they
        can work together with the task-specific ones to boost the
        performance. 3) We also find the pattens captured by the
        shared layer and the task-specific layer of MT-ES have a
        small amount of overlap, which again implies that the two
        kinds of layers can work complementarily.</p>
      </section>
    </section>
    <section id="sec-19">
      <header>
        <div class="title-info">
          <h2><span class="section-number">7</span> Conclusions and
          Future Work</h2>
        </div>
      </header>
      <p>Existing research works tackle rumor detection and stance
      classification separately. In this paper, we attempt to
      jointly optimize the two tasks based on a unified neural
      multi-task learning framework. Specifically, we adopt two
      multi-task architectures based on RNNs to model information
      sharing and representation reinforcement between the tasks
      that use different datasets. The experimental results based
      on real-world tweets and news reports demonstrate that the
      multi-task approach consistently outperforms many strong
      baselines for both tasks, indicating that training these
      rumor-related tasks jointly with multi-task architecture
      seems a better strategy.</p>
      <p>Beyond rumor detection and stance classification tasks, we
      believe that there are other related tasks that can be
      incorporated into such unified framework, such as evaluating
      users trustworthiness together with existing tasks.</p>
    </section>
    <section id="sec-20">
      <header>
        <div class="title-info">
          <h2>Acknowledgment</h2>
        </div>
      </header>
      <p>This work is partly supported by Innovation and Technology
      Fund (6904333), and General Research Fund of Hong Kong
      (12183516).</p>
    </section>
  </section>
  <section class="back-matter">
    <section id="ref-001">
      <header>
        <div class="title-info">
          <h2 class="page-brake-head">REFERENCES</h2>
        </div>
      </header>
      <ul class="bibUl">
        <li id="BibPLXBIB0001" label="[1]">Rob Abbott, Marilyn
        Walker, Pranav Anand, Jean&nbsp;E Fox&nbsp;Tree, Robeson
        Bowmani, and Joseph King. 2011. How can you say such
        things?!?: Recognizing disagreement in informal political
        argument. In <em><em>Proceedings of the Workshop on
        Languages in Social Media</em></em> . Association for
        Computational Linguistics, 2–11.</li>
        <li id="BibPLXBIB0002" label="[2]">Rie&nbsp;Kubota Ando and
        Tong Zhang. 2005. A framework for learning predictive
        structures from multiple tasks and unlabeled data.
        <em><em>Journal of Machine Learning Research</em></em> 6,
        Nov (2005), 1817–1853.</li>
        <li id="BibPLXBIB0003" label="[3]">Isabelle Augenstein, Tim
        Rocktäschel, Andreas Vlachos, and Kalina Bontcheva. 2016.
        Stance detection with bidirectional conditional encoding.
        <em><em>arXiv preprint arXiv:1606.05464</em></em>
        (2016).</li>
        <li id="BibPLXBIB0004" label="[4]">Bernd Bohnet and Joakim
        Nivre. 2012. A transition-based system for joint
        part-of-speech tagging and labeled non-projective
        dependency parsing. In <em><em>Proceedings of the 2012
        Joint Conference on Empirical Methods in Natural Language
        Processing and Computational Natural Language
        Learning</em></em> . Association for Computational
        Linguistics, 1455–1465.</li>
        <li id="BibPLXBIB0005" label="[5]">Rich Caruana. 1998.
        Multitask learning. In <em><em>Learning to learn</em></em>
        . Springer, 95–133.</li>
        <li id="BibPLXBIB0006" label="[6]">Carlos Castillo, Marcelo
        Mendoza, and Barbara Poblete. 2011. Information credibility
        on twitter. In <em><em>Proceedings of WWW</em></em> .</li>
        <li id="BibPLXBIB0007" label="[7]">Yi-Chin Chen, Zhao-Yang
        Liu, and Hung-Yu Kao. 2017. IKM at SemEval-2017 Task 8:
        Convolutional Neural Networks for stance detection and
        rumor verification. In <em><em>Proceedings of the 11th
        International Workshop on Semantic Evaluation
        (SemEval-2017)</em></em> . 465–469.</li>
        <li id="BibPLXBIB0008" label="[8]">Kyunghyun Cho, Bart van
        Merriënboer, Dzmitry Bahdanau, and Yoshua Bengio. 2014. On
        the properties of neural machine translation:
        Encoder-decoder approaches. <em><em>arXiv preprint
        arXiv:1409.1259</em></em> (2014).</li>
        <li id="BibPLXBIB0009" label="[9]">Ju-han Chuang and Shukai
        Hsieh. 2015. Stance classification on ptt comments. In
        <em><em>Proceedings of the 29th Pacific Asia Conference on
        Language, Information and Computation</em></em> .</li>
        <li id="BibPLXBIB0010" label="[10]">Ronan Collobert and
        Jason Weston. 2008. A unified architecture for natural
        language processing: Deep neural networks with multitask
        learning. In <em><em>Proceedings of the 25th international
        conference on Machine learning</em></em> . ACM,
        160–167.</li>
        <li id="BibPLXBIB0011" label="[11]">Ronan Collobert, Jason
        Weston, Léon Bottou, Michael Karlen, Koray Kavukcuoglu, and
        Pavel Kuksa. 2011. Natural language processing (almost)
        from scratch. <em><em>Journal of Machine Learning
        Research</em></em> 12, Aug (2011), 2493–2537.</li>
        <li id="BibPLXBIB0012" label="[12]">Nicholas DiFonzo and
        Prashant Bordia. 2007. Rumor, gossip and urban legends.
        <em><em>Diogenes</em></em> 54, 1 (2007), 19–35.</li>
        <li id="BibPLXBIB0013" label="[13]">Daxiang Dong, Hua Wu,
        Wei He, Dianhai Yu, and Haifeng Wang. 2015. Multi-Task
        Learning for Multiple Language Translation.. In <em><em>ACL
        (1)</em></em> . 1723–1732.</li>
        <li id="BibPLXBIB0014" label="[14]">Pamela Donovan. 2007.
        How idle is idle talk? One hundred years of rumor research.
        <em><em>Diogenes</em></em> 54, 1 (2007), 59–82.</li>
        <li id="BibPLXBIB0015" label="[15]">John Duchi, Elad Hazan,
        and Yoram Singer. 2011. Adaptive subgradient methods for
        online learning and stochastic optimization.
        <em><em>Journal of Machine Learning Research</em></em> 12,
        Jul (2011), 2121–2159.</li>
        <li id="BibPLXBIB0016" label="[16]">Orhan Firat, Kyunghyun
        Cho, and Yoshua Bengio. 2016. Multi-Way, Multilingual
        Neural Machine Translation with a Shared Attention
        Mechanism. In <em><em>Proceedings of NAACL-HLT</em></em> .
        866–875.</li>
        <li id="BibPLXBIB0017" label="[17]">Adrien Friggeri,
        Lada&nbsp;A Adamic, Dean Eckles, and Justin Cheng. 2014.
        Rumor cascades. In <em><em>Proceedings of ICWSM</em></em>
        .</li>
        <li id="BibPLXBIB0018" label="[18]">Sardar Hamidian and
        Mona Diab. 2015. Rumor detection and classification for
        twitter data. In <em><em>The Fifth International Conference
        on Social Media Technologies, Communication, and
        Informatics, SOTICS, IARIA</em></em> . 71–77.</li>
        <li id="BibPLXBIB0019" label="[19]">Aniko Hannak, Drew
        Margolin, Brian Keegan, and Ingmar Weber. 2014. Get Back!
        You Don't Know Me Like That: The Social Mediation of Fact
        Checking Interventions in Twitter Conversations.. In
        <em><em>ICWSM</em></em> .</li>
        <li id="BibPLXBIB0020" label="[20]">Jun Hatori, Takuya
        Matsuzaki, Yusuke Miyao, and Jun'ichi Tsujii. 2012.
        Incremental joint approach to word segmentation, POS
        tagging, and dependency parsing in Chinese. In
        <em><em>Proceedings of the 50th Annual Meeting of the
        Association for Computational Linguistics: Long
        Papers-Volume 1</em></em> . Association for Computational
        Linguistics, 1045–1053.</li>
        <li id="BibPLXBIB0021" label="[21]">Sepp Hochreiter and
        Jürgen Schmidhuber. 1997. Long short-term memory.
        <em><em>Neural computation</em></em> 9, 8 (1997),
        1735–1780.</li>
        <li id="BibPLXBIB0022" label="[22]">Elena Kochkina, Maria
        Liakata, and Isabelle Augenstein. 2017. Turing at
        SemEval-2017 Task 8: Sequential Approach to Rumour Stance
        Classification with Branch-LSTM. <em><em>arXiv preprint
        arXiv:1704.07221</em></em> (2017).</li>
        <li id="BibPLXBIB0023" label="[23]">Sejeong Kwon, Meeyoung
        Cha, and Kyomin Jung. 2017. Rumor Detection over Varying
        Time Windows. <em><em>PLOS ONE</em></em> 12, 1 (2017),
        e0168344.</li>
        <li id="BibPLXBIB0024" label="[24]">Sejeong Kwon, Meeyoung
        Cha, Kyomin Jung, Wei Chen, and Yajun Wang. 2013. Prominent
        features of rumor propagation in online social media. In
        <em><em>Proceedings of ICDM</em></em> .</li>
        <li id="BibPLXBIB0025" label="[25]">Zhenghua Li, Min Zhang,
        Wanxiang Che, Ting Liu, and Wenliang Chen. 2014. Joint
        optimization for Chinese pos tagging and dependency
        parsing. <em><em>IEEE/ACM Transactions on Audio, Speech,
        and Language Processing</em></em> 22, 1(2014),
        274–286.</li>
        <li id="BibPLXBIB0026" label="[26]">Pengfei Liu, Xipeng
        Qiu, and Xuanjing Huang. 2016. Recurrent neural network for
        text classification with multi-task learning. In
        <em><em>Proceedings of the Twenty-Fifth International Joint
        Conference on Artificial Intelligence</em></em> . AAAI
        Press, 2873–2879.</li>
        <li id="BibPLXBIB0027" label="[27]">Xiaodong Liu, Jianfeng
        Gao, Xiaodong He, Li Deng, Kevin Duh, and Ye-Yi Wang. 2015.
        Representation Learning Using Multi-Task Deep Neural
        Networks for Semantic Classification and Information
        Retrieval.. In <em><em>HLT-NAACL</em></em> . 912–921.</li>
        <li id="BibPLXBIB0028" label="[28]">Xiaomo Liu, Armineh
        Nourbakhsh, Quanzhi Li, Rui Fang, and Sameena Shah. 2015.
        Real-time Rumor Debunking on Twitter. In
        <em><em>Proceedings of CIKM</em></em> .</li>
        <li id="BibPLXBIB0029" label="[29]">Michal Lukasik, Trevor
        Cohn, and Kalina Bontcheva. 2015. Classifying tweet level
        judgements of rumours in social media. <em><em>arXiv
        preprint arXiv:1506.00468</em></em> (2015).</li>
        <li id="BibPLXBIB0030" label="[30]">Michal Lukasik, PK
        Srijith, Duy Vu, Kalina Bontcheva, Arkaitz Zubiaga, and
        Trevor Cohn. 2016. Hawkes processes for continuous time
        sequence classification: an application to rumour stance
        classification in twitter. In <em><em>Proceedings of 54th
        Annual Meeting of the Association for Computational
        Linguistics</em></em> . Association for Computational
        Linguistics, 393–398.</li>
        <li id="BibPLXBIB0031" label="[31]">Minh-Thang Luong,
        Quoc&nbsp;V Le, Ilya Sutskever, Oriol Vinyals, and Lukasz
        Kaiser. 2015. Multi-task sequence to sequence learning.
        <em><em>arXiv preprint arXiv:1511.06114</em></em>
        (2015).</li>
        <li id="BibPLXBIB0032" label="[32]">Jing Ma, Wei Gao,
        Prasenjit Mitra, Sejeong Kwon, Bernard&nbsp;J Jansen,
        Kam-Fai Wong, and Meeyoung Cha. 2016. Detecting rumors from
        microblogs with recurrent neural networks. In
        <em><em>Proceedings of IJCAI</em></em> .</li>
        <li id="BibPLXBIB0033" label="[33]">Jing Ma, Wei Gao,
        Zhongyu Wei, Yueming Lu, and Kam-Fai Wong. 2015. Detect
        Rumors Using Time Series of Social Context Information on
        Microblogging Websites. In <em><em>Proceedings of
        CIKM</em></em> .</li>
        <li id="BibPLXBIB0034" label="[34]">Jing Ma, Wei Gao, and
        Kam-Fai Wong. 2017. Detect Rumors in Microblog Posts Using
        Propagation Structure via Kernel Learning. In
        <em><em>Proceedings of the 55th Annual Meeting of the
        Association for Computational Linguistics (Volume 1: Long
        Papers)</em></em> , Vol.&nbsp;1. 708–717.</li>
        <li id="BibPLXBIB0035" label="[35]">Marcelo Mendoza,
        Barbara Poblete, and Carlos Castillo. 2010. Twitter Under
        Crisis: Can we trust what we RT?. In <em><em>Proceedings of
        the first workshop on social media analytics</em></em> .
        ACM, 71–79.</li>
        <li id="BibPLXBIB0036" label="[36]">Saif Mohammad, Svetlana
        Kiritchenko, Parinaz Sobhani, Xiao-Dan Zhu, and Colin
        Cherry. 2016. SemEval-2016 Task 6: Detecting Stance in
        Tweets.. In <em><em>SemEval@ NAACL-HLT</em></em> .
        31–41.</li>
        <li id="BibPLXBIB0037" label="[37]">Meredith&nbsp;Ringel
        Morris, Scott Counts, Asta Roseway, Aaron Hoff, and Julia
        Schwarz. 2012. Tweeting is believing?: understanding
        microblog credibility perceptions. In <em><em>Proceedings
        of the ACM 2012 conference on Computer Supported
        Cooperative Work</em></em> . ACM, 441–450.</li>
        <li id="BibPLXBIB0038" label="[38]">Vahed Qazvinian, Emily
        Rosengren, Dragomir&nbsp;R Radev, and Qiaozhu Mei. 2011.
        Rumor has it: Identifying misinformation in microblogs. In
        <em><em>Proceedings of EMNLP</em></em> .</li>
        <li id="BibPLXBIB0039" label="[39]">Sarvesh Ranade, Rajeev
        Sangal, and Radhika Mamidi. 2013. Stance Classification in
        Online Debates by Recognizing Users’ Intentions.. In
        <em><em>SIGDIAL Conference</em></em> . 61–69.</li>
        <li id="BibPLXBIB0040" label="[40]">Bhavtosh Rath, Wei Gao,
        Jing Ma, and Jaideep Srivastava. 2015. From Retweet to
        Believability: Utilizing Trust to Identify Rumor Spreaders
        on Twitter. In <em><em>Advances in Social Networks Analysis
        and Mining (ASONAM), 2017 IEEE/ACM International Conference
        on</em></em> . IEEE, 179–186.</li>
        <li id="BibPLXBIB0041" label="[41]">Sara Rosenthal and
        Kathy McKeown. 2015. I Couldn't Agree More: The Role of
        Conversational Structure in Agreement and Disagreement
        Detection in Online Discussions.. In <em><em>SIGDIAL
        Conference</em></em> . 168–177.</li>
        <li id="BibPLXBIB0042" label="[42]">Ralph&nbsp;L Rosnow.
        1991. Inside rumor: A personal journey. <em><em>American
        Psychologist</em></em> 46, 5 (1991), 484.</li>
        <li id="BibPLXBIB0043" label="[43]">Prashanth
        Vijayaraghavan, Ivan Sysoev, Soroush Vosoughi, and Deb Roy.
        2016. Deepstance at semeval-2016 task 6: Detecting stance
        in tweets using character and word-level cnns.
        <em><em>arXiv preprint arXiv:1606.05694</em></em>
        (2016).</li>
        <li id="BibPLXBIB0044" label="[44]">Ke Wu, Song Yang, and
        Kenny&nbsp;Q Zhu. 2015. False rumors detection on sina
        weibo by propagation structures. In <em><em>Proceedings of
        ICDE</em></em> .</li>
        <li id="BibPLXBIB0045" label="[45]">Fan Yang, Yang Liu,
        Xiaohui Yu, and Min Yang. 2012. Automatic detection of
        rumor on sina weibo. In <em><em>Proceedings of the ACM
        SIGKDD Workshop on Mining Data Semantics</em></em> .</li>
        <li id="BibPLXBIB0046" label="[46]">Li Zeng, Kate Starbird,
        and Emma&nbsp;S Spiro. 2016. # Unconfirmed: Classifying
        Rumor Stance in Crisis-Related Social Media Messages. In
        <em><em>Tenth International AAAI Conference on Web and
        Social Media</em></em> .</li>
        <li id="BibPLXBIB0047" label="[47]">Zhe Zhao, Paul Resnick,
        and Qiaozhu Mei. 2015. Enquiring Minds: Early Detection of
        Rumors in Social Media from Enquiry Posts. In
        <em><em>Proceedings of WWW</em></em> .</li>
        <li id="BibPLXBIB0048" label="[48]">Arkaitz Zubiaga, Elena
        Kochkina, Maria Liakata, Rob Procter, and Michal Lukasik.
        2016. Stance classification in rumours as a sequential task
        exploiting the tree structure of social media
        conversations. <em><em>arXiv preprint
        arXiv:1609.09028</em></em> (2016).</li>
        <li id="BibPLXBIB0049" label="[49]">Arkaitz Zubiaga, Maria
        Liakata, Rob Procter, Geraldine Wong&nbsp;Sak Hoi, and
        Peter Tolmie. 2016. Analysing how people orient to and
        spread rumours in social media by looking at conversational
        threads. <em><em>PloS one</em></em> 11, 3 (2016),
        e0150989.</li>
      </ul>
    </section>
  </section>
  <section id="foot-001" class="footnote">
    <header>
      <div class="title-info">
        <h2>FOOTNOTE</h2>
      </div>
    </header>
    <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class=
    "link-inline force-break" href=
    "http://money.cnn.com/2016/11/17/technology/facebook-election-influence/">http://money.cnn.com/2016/11/17/technology/facebook-election-influence/</a></p>
    <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class=
    "link-inline force-break" href=
    "http://www.fakenewschallenge.org">www.fakenewschallenge.org</a></p>
    <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>For the case
    that the input is a news article, the output corresponding to
    the last sentence is used as the dense vector representation of
    the article.</p>
    <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a>For an article,
    only the activation function of the last time step is used for
    prediction.</p>
    <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>The original
    tweets were gathered following threads in the articles on these
    websites. Therefore, the NTFU tags are easily restored.</p>
    <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a><a class=
    "link-inline force-break" href=
    "http://www.cs.waikato.ac.nz/ml/weka/">http://www.cs.waikato.ac.nz/ml/weka/</a></p>
    <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a><a class=
    "link-inline force-break" href=
    "https://www.csie.ntu.edu.tw/~cjlin/libsvm/">https://www.csie.ntu.edu.tw/~cjlin/libsvm/</a></p>
    <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a><a class=
    "link-inline force-break" href=
    "http://deeplearning.net/software/theano/">http://deeplearning.net/software/theano/</a></p>
    <div class="bibStrip">
      <p>This paper is published under the Creative Commons
      Attribution 4.0 International (CC-BY&nbsp;4.0) license.
      Authors reserve their rights to disseminate the work on their
      personal and corporate Web sites with the appropriate
      attribution.</p>
      <p><em>WWW '18, April 23-27, 2018, Lyon, France</em></p>
      <p>© 2018; IW3C2 (International World Wide Web Conference
      Committee), published under Creative Commons CC-BY&nbsp;4.0
      License. ACM ISBN 978-1-4503-5640-4/18/04.<br />
      DOI: <a class="link-inline force-break" target="_blank" href=
      "https://doi.org/10.1145/3184558.3188729">https://doi.org/10.1145/3184558.3188729</a></p>
    </div>
  </section>
  <div class="pubHistory">
    <p></p>
  </div>
</body>
</html>
