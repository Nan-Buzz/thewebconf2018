<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Semantics-aware Recommender Systems Exploiting Linked Open Data and Graph-based Features</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/main.css"/><script src="../../../../dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../../dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Semantics-aware Recommender Systems Exploiting Linked Open Data and Graph-based Features</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Cataldo</span>      <span class="surName">Musto</span>     Dept. of Computer Science - University of Bari Aldo Moro, <a href="mailto:cataldo.musto@uniba.it">cataldo.musto@uniba.it</a>     </div>     <div class="author">     <span class="givenName">Pasquale</span>      <span class="surName">Lops</span>     Dept. of Computer Science - University of Bari Aldo Moro, <a href="mailto:pasquale.lops@uniba.it">pasquale.lops@uniba.it</a>     </div>     <div class="author">     <span class="givenName">Marco</span>      <span class="surName">de Gemmis</span>     Dept. of Computer Science - University of Bari Aldo Moro, <a href="mailto:marco.degemmis@uniba.it">marco.degemmis@uniba.it</a>     </div>     <div class="author">     <span class="givenName">Giovanni</span>      <span class="surName">Semeraro</span>     Dept. of Computer Science - University of Bari Aldo Moro, <a href="mailto:giovanni.semeraro@uniba.it">giovanni.semeraro@uniba.it</a>     </div>                     </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3186233" target="_blank">https://doi.org/10.1145/3184558.3186233</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>In this contribution we propose a <em>hybrid recommendation framework</em> based on classification algorithms such as Random Forests and Naive Bayes, which are fed with several heterogeneous groups of features. We split our features into two classes: <em>classic features</em>, as popularity-based, collaborative and content-based ones, and <em>extended features</em> gathered from the Linked Open Data (LOD) cloud, as basic ones (i.e. <em>genre</em> of a movie or the <em>writer</em> of a book) and graph-based features calculated on the ground of the different topological characteristics of the <em>tripartite</em> representation connecting users, items and properties in the LOD cloud. In the experimental session we evaluate the effectiveness of our framework on varying of different groups of features, and results show that both LOD-based and graph-based features positively affect the overall performance of the algorithm, especially in <em>highly sparse</em> recommendation scenarios. Our approach also outperforms several state-of-the-art recommendation techniques, thus confirming the insights behind this research.</small>     </p>     <p>     <small>This extended abstract summarizes the content of the journal paper [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0007">7</a>] published on <em>Knowledge-based Systems</em>.</small>     </p>    </div>    <div class="CCSconcepts">     <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Recommender systems;</strong> <em>Web data description languages;</em> &#x2022;<strong> Computing methodologies </strong>&#x2192; <em>Supervised learning by classification;</em></small> </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Recommender Systems</small>, </span>     <span class="keyword">      <small> Machine Learning</small>, </span>     <span class="keyword">      <small> Linked Open Data</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Cataldo Musto, Pasquale Lops, Marco de Gemmis, and Giovanni Semeraro. 2018. Semantics-aware Recommender Systems Exploiting Linked Open Data and Graph-based Features. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 4 Pages. <a href="https://doi.org/10.1145/3184558.3186233" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3186233</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>According to recent statistics<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>, 150 billions of <tt>RDF</tt> triples and almost 10,000 linked datasets are now available in the so-called LOD cloud: such <tt>RDF</tt> triples interconnect in a semantics-aware fashion the information covering many topical domains, such as geographical locations, people, books, films, music, and so on. The <em>nucleus</em> of such data is commonly represented by <tt>DBpedia</tt> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>], the <tt>RDF</tt> mapping of Wikipedia. This huge availability of semantics-aware machine-readable data attracted researchers and practitioners in the area of Content-based Recommender Systems (RS) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>], willing to investigate how such information can be exploited to improve the effectiveness of existing algorithms or to tackle several problems RSs typically suffer from.</p>    <p>In this article we investigate the impact of such <em>exogenous knowledge</em> on the performance of a <em>hybrid</em> recommendation framework based on classification techniques as Random Forests and Naive Bayes. In this work we followed the hybridization strategy which is typically referred to as <em>feature combination</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>], that is to say, we represented the items by means of different heterogeneous groups of features and we used this unique representation to feed the classifiers with training examples. Such a model is then exploited to classify new and unseen items as <em>relevant</em> or not relevant for the <em>target user</em>.</p>    <p>The features we used are roughly classified in two groups: <em>classic features</em> and <em>extended</em> ones. The features that are typically used in hybrid item representations, as unstructured <em>content-based</em> features, <em>collaborative</em> features and simple <em>popularity-based</em> ones, fall in the first group. Next, we extended the representation by introducing data points gathered from the LOD cloud, as <em>basic</em> structured features (as the <em>genre</em> of a movie or the <em>writer</em> of a book) and <em>graph-based features</em>, calculated by mining the different topological characteristics of the <em>tripartite</em> graph-based representation that connects users, items and properties in the LOD cloud.</p>    <p>In the experimental session we evaluated the effectiveness of our framework on varying of these sets of features, and results provided several interesting insights, since it emerged that the overall accuracy significantly benefits from the introduction of LOD-based and graph-based features. Moreover, the results we obtained also overcame several state-of-the-art recommendation techniques.</p>   </section>   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Methodology</h2>     </div>    </header>    <p>In this section we provide the details of our methodology, by introducing the groups of features we used to feed the classification algorithms and by describing our recommendation framework.</p>    <section id="sec-7">     <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Description of the Features and Recommendation Framework</h3>     </div>     </header>     <p>     <strong>Popularity features.</strong> This set of features includes basic popularity-based information about the items, such as the <em>number of ratings</em> received by the item, the number of <em>positive</em> ratings received by the item and the <em>ratio</em> between positive ratings and the overall number of ratings.</p>     <p>This (tiny) group of features may seem trivial and not useful, but this kind of data is typically very informative for a recommendation task, since it gives information about how popular is a certain item among the users and how positive is their general opinion about it. As Cremonesi et al. already shown [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>], non-personalized algorithms based on simple popularity measures can obtain performance comparable to that of more sophisticated techniques.</p>     <p>     <strong>Collaborative features.</strong> This class of features models the information encoded in the <em>user-item matrix</em> which is typically exploited in collaborative filtering (CF) algorithms. Differently from classical CF algorithms, that use the <em>whole</em> matrix to calculate the <em>neighbors</em> of the target user and to predict the items the user may be interested in, in our approach we are only interested in extracting the <em>column vector</em> modeling the ratings received by an item in order to include them in our <em>hybrid</em> item representation. Accordingly, the number of <em>collaborative features</em> we encoded for each item corresponds to the number of the <em>rows</em> of the matrix, that is to say, to the number of the <em>users</em> in the dataset.</p>     <p>The choice of including this set of features in our hybrid representation is quite straightforward, since CF algorithms and matrix factorization techniques tend to obtain very good performance especially when the <em>sparsity</em> of the original matrix is not high.</p>     <p>     <strong>Content-based features.</strong> Textual content is another interesting source that can be exploited to provide items with useful and descriptive features. As an example, the <em>plot</em> of a movie contains several distinctive characteristics of the item, which can be extracted from such data.</p>     <p>However, <em>textual descriptions</em> are typically <em>noisy</em>, thus it is necessary to properly process such data by adopting Natural Language Processing (NLP) techniques before including them in our items representation. In our pipeline the content was first tokenized, then stop-words were removed and the entities occurring in the text were identified. Next, the remaining tokens were stemmed. In this case, the amount of features added to the model corresponds to the size of the <em>vocabulary</em>, that is to say, to the number of different tokens occurring in the description of <em>all the items</em> in the dataset.</p>     <p>     <strong>LOD-based features.</strong> The first group of <em>extended features</em> includes structured basic properties gathered from the LOD cloud, as the <em>genre</em> of a <em>movie</em> or the author of a book. To gather LOD-based features we preliminarily carried out a mapping procedure to obtain the corresponding <tt>URI</tt> for each item in the dataset. The goal of the mapping procedure is to identify, for each available item, the corresponding element in the LOD cloud the item refers to. As an example, we associate the movie <em>The Matrix</em> with its corresponding <tt>URI</tt> in the LOD cloud<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>. It is worth to emphasize that the mapping is a necessary and mandatory step to get an <em>entry point</em> to the LOD cloud.</p>     <p>Next, for each domain, we defined a subset of relevant properties by exploiting the outcomes of our previous research [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0006">6</a>] and finally we used <tt>SPARQL</tt> to extract such data.</p>     <p>As we did for content-based features, we built a <em>vocabulary</em> of LOD-based properties and we provided each item with these new features. The score of each feature was set to 1 if the item is described through that <tt>RDF</tt> property, 0 otherwise. Table <a class="tbl" href="#tab1">1</a> reports some of the properties describing <em>The Matrix</em> gathered from the LOD cloud. In this case, each feature is represented through the couple <em><property,value></em>, since each entity can have different roles in the same movie (and in different ones, as well).</p>     <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">Partial representation of the vector modeling the LOD-based features extracted from <tt>DBpedia</tt> for the movie <em>The Matrix</em>      </span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">        <strong>property - value</strong>        </td>        <td style="text-align:center;">        <strong>The Matrix</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">        <tt>dbo:director - dbr:The_Wachowski</tt>        </td>        <td style="text-align:center;">1</td>       </tr>       <tr>        <td style="text-align:center;">        <tt>dbo:director - dbr:Mel_Gibson</tt>        </td>        <td style="text-align:center;">0</td>       </tr>       <tr>        <td style="text-align:center;">        <tt>dbo:composer - dbr:Ennio_Morricone</tt>        </td>        <td style="text-align:center;">0</td>       </tr>       <tr>        <td style="text-align:center;">        <tt>dct:subject - dbc:Dystopian_films</tt>        </td>        <td style="text-align:center;">1</td>       </tr>       <tr>        <td style="text-align:center;">        <tt>dct:subject - dbc:American_Horror_movies</tt>        </td>        <td style="text-align:center;">0</td>       </tr>       <tr>        <td style="text-align:center;">        <strong>...</strong>        </td>        <td style="text-align:center;">...</td>       </tr>       <tr>        <td style="text-align:center;">        <tt>dbo:producer - dbr:Joel_Silver</tt>        </td>        <td style="text-align:center;">1</td>       </tr>      </tbody>     </table>     </div>     <p>     <strong>Graph-based Features.</strong> The second group of extended features is built on the ground of the graph-based representation obtained by connecting the users to the items they liked and, in turn, the items to the properties gathered from <SmallCap>DBpedia</SmallCap> (see Figure <a class="fig" href="#fig1">1</a>). We refer to these features as <em>tripartite</em> ones. <figure id="fig1">      <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186233/images/www18companion-86-fig1.jpg" class="img-responsive" alt=""       longdesc=""/>     </figure>     </p>     <p>Given such representations, we decided to mine this graph and to calculate some measures describing its <em>topological characteristics</em>. Specifically, in our item representation we encoded five graph-based features calculated on the tripartite user-item graph, that is to say: <em>Degree Centrality</em>, <em>Average Neighbor Degree</em>, <em>PageRank</em> score, <em>Node Redundancy</em> and <em>Cluster Coefficient</em>.</p>     <p>     <strong>Recommendation Framework.</strong> In this work we <em>cast</em> the recommendation task to a classification one, that is to say, we used the vectors representing the items the user liked as <em>positive examples</em> and those he did not like as <em>negative examples</em>. Next, we trained the classifiers and we exploited them to classify all the items the user did not consumed yet as <em>interesting</em> or not <em>interesting</em> for her.</p>     <p>To sum up, given a target user <em>u</em>, a training set <em>TR</em>(<em>u</em>) (the items the user previously rated), and a group of features <em>F</em>, our classifier is fed with the examples <em>i<sub>F</sub>     </em> &#x2208; <em>TR</em>(<em>u</em>) and we use the classification model to predict the most interesting items for the target user. Specifically, items in the test set are ranked according to the <em>confidence</em> of the prediction returned by the classification algorithm and the <em>top-K</em> items are returned to the target user. In the experimental session the overall effectiveness of our recommendation framework has been evaluated by varying different sets of features and by using two different classification algorithms, namely <em>Random Forests</em> and <em>Na&#x00EF;ve Bayes</em>.</p>    </section>   </section>   <section id="sec-8">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Experimental Evaluation</h2>     </div>    </header>    <p>Our experiments were designed on the ground of three different research questions: How do <em>LOD-based features</em> impact on the overall performance of the recommendations? (<em>Experiment 1</em>). How do <em>graph-based features</em> impact on the overall performance of the recommendations? (<em>Experiment 2</em>). How does our best-performing configuration perform with respect to <em>state-of-the-art techniques</em>? (<em>Experiment 3</em>).</p>    <p>     <strong>Experimental protocol.</strong> Experiments were carried out on two state-of-the-art datasets, i.e. <tt>MovieLens-1M</tt><a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a>, and <SmallCap>DBbook</SmallCap>. The first one is a widespread dataset for movie recommendation, the second was used in the ESWC 2014 Recommender Systems challenge<a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a> and focuses on book recommendation.</p>    <p>Experiments were performed by adopting different protocols. We used a 80%-20% training-test split for <tt>MovieLens-1M</tt>. For <tt>DBbook</tt> we used the training-test split that provided with the data. Different protocols were also adopted to build user profiles. In <tt>MovieLens-1M</tt>, user preferences are expressed on a 5-point discrete scale, thus we decided to consider as <em>positive</em> only those ratings equal to 4 and 5. On the other side, the <tt>DBbook</tt> dataset is already available as <em>binarized</em>, thus no further processing was needed. As classification algorithms we used the implementations of <em>Random Forest</em> and <em>Naive Bayes</em> made available in the Weka Toolkit<a class="fn" href="#fn5" id="foot-fn5"><sup>5</sup></a>.</p>    <p>     <em>Popularity features</em> were extracted by simply processing the original data and by counting the ratings received by each item. As regards <em>collaborative features</em>, we replaced missing values with a special character and we used a binary representation to encode positive and negative ratings. Next, to generate <em>content-based features</em> we used the methods implemented in the Apache Lucene<a class="fn" href="#fn6" id="foot-fn6"><sup>6</sup></a> library for tokenization, language detection and stop-words removal. Textual descriptions were all gathered from the Wikipedia pages of the items. Finally, tokens were stemmed by exploiting the Snowball library <a class="fn" href="#fn7" id="foot-fn7"><sup>7</sup></a>.</p>    <p>As previously explained, each item was mapped to a <tt>DBpedia</tt> entry in order to gather the features from the LOD cloud. To this end, we exploited some mappings already available in literature. In our setting, 3,300 <tt>MovieLens-1M</tt> entries and 6,600 items (98.02%) from <tt>DBbook</tt> (85% of the items) were successfully mapped. The items for which a <tt>DBpedia</tt> entry was not found were represented by using the basic groups of features alone. Finally, <em>graph-based features</em> were calculated by exploiting the Jung framework<a class="fn" href="#fn8" id="foot-fn8"><sup>8</sup></a>, a Java library to manage graph-based data. As previously explained, for each item node we calculated <em>Degree Centrality</em>, <em>Average Neighbor Degree</em>, <em>PageRank</em> score, <em>Node Redundancy</em> and <em>Cluster Coefficient</em> for tripartite graph.</p>    <p>The performance of each configuration of our recommendation framework was evaluated in terms of <em>F1@5</em>, calculated through the Rival toolkit<a class="fn" href="#fn9" id="foot-fn9"><sup>9</sup></a>.</p>    <p>     <strong>Discussion of the Results.</strong> By analyzing the behavior of LOD features on <tt>MovieLens</tt> data (Table <a class="tbl" href="#tab2">2</a>), it emerges that the only configuration that benefits of such injection is the one exploiting <em>content-based features</em>. This can be probably due to the low sparsity of the dataset, which makes superfluous most of the features except <em>collaborative</em> ones. However, even if these experimental settings showed that the adoption of LOD features has to be carefully evaluated, the overall best configuration (highlighted with (*)) actually <em>includes LOD features</em>, since the configuration merging popular, collaborative and LOD features obtained the higher F1@5. A similar pattern was noted on <tt>DBbook</tt>, since RF is the algorithm which takes the best from the LOD-based features. An interesting outcome emerging from this experiment is that when data are sparse, as for <tt>DBbook</tt>, <em>LOD-based</em> data points represent a good alternative also to <em>collaborative</em> features. Indeed, in this experiment <em>Popular+LOD</em> obtained the best overall F1@5. This means that, when the rating patterns are noisy, LOD features can be used to enrich the representation with new and relevant information.</p>    <div class="table-responsive" id="tab2">     <div class="table-caption">     <span class="table-number">Table 2:</span>     <span class="table-title">Impact of LOD-based Features on <tt>MovieLens</tt> data.</span>     </div>     <table class="table">     <tbody>      <tr>       <td/>       <td/>       <td/>       <td/>       <td/>      </tr>      <tr>       <td style="text-align:center;"/>       <td colspan="2" style="text-align:center;">        <strong>RF</strong>        <hr/>       </td>       <td colspan="2" style="text-align:center;">        <strong>NB</strong>        <hr/>       </td>      </tr>      <tr>       <td style="text-align:center;">        <em>F1@5</em>       </td>       <td style="text-align:center;">        <em>No-LOD</em>       </td>       <td style="text-align:center;">LOD</td>       <td style="text-align:center;">        <em>No-LOD</em>       </td>       <td style="text-align:left;">LOD</td>      </tr>      <tr>       <td style="text-align:center;">Popular (P)</td>       <td style="text-align:center;">        <em>0.5338</em>       </td>       <td style="text-align:center;">0.5312</td>       <td style="text-align:center;">        <em>0.5458</em>       </td>       <td style="text-align:left;">0.5320</td>      </tr>      <tr>       <td style="text-align:center;">Collaborative (C)</td>       <td style="text-align:center;">        <em>0.5618</em>       </td>       <td style="text-align:center;">0.5609</td>       <td style="text-align:center;">        <em>0.5486</em>       </td>       <td style="text-align:left;">0.5450</td>      </tr>      <tr>       <td style="text-align:center;">Content-based (T)</td>       <td style="text-align:center;">        <em>0.4913</em>       </td>       <td style="text-align:center;">        <strong>0.4943</strong>       </td>       <td style="text-align:center;">        <em>0.4913</em>       </td>       <td style="text-align:left;">        <strong>0.4932</strong>       </td>      </tr>      <tr>       <td style="text-align:center;">        <strong>P+C</strong>       </td>       <td style="text-align:center;">        <em>0.5635</em>       </td>       <td style="text-align:center;">        <strong>0.5642 (*)</strong>       </td>       <td style="text-align:center;">        <em>0.5483</em>       </td>       <td style="text-align:left;">0.5451</td>      </tr>      <tr>       <td style="text-align:center;">P+T</td>       <td style="text-align:center;">        <em>0.5051</em>       </td>       <td style="text-align:center;">        <strong>0.5079</strong>       </td>       <td style="text-align:center;">        <em>0.4965</em>       </td>       <td style="text-align:left;">        <strong>0.4974</strong>       </td>      </tr>      <tr>       <td style="text-align:center;">C+T</td>       <td style="text-align:center;">        <em>0.5187</em>       </td>       <td style="text-align:center;">        <strong>0.5188</strong>       </td>       <td style="text-align:center;">        <em>0.5180</em>       </td>       <td style="text-align:center;">0.5169</td>      </tr>      <tr>       <td style="text-align:center;">P+C+T</td>       <td style="text-align:center;">        <em>0.5246</em>       </td>       <td style="text-align:center;">0.5246</td>       <td style="text-align:center;">        <em>0.5189</em>       </td>       <td style="text-align:center;">0.5174</td>      </tr>     </tbody>     </table>    </div>    <div class="table-responsive" id="tab3">     <div class="table-caption">     <span class="table-number">Table 3:</span>     <span class="table-title">Impact of LOD-based Features on <tt>DBbook</tt> data.</span>     </div>     <table class="table">     <tbody>      <tr>       <td/>       <td/>       <td/>       <td/>       <td/>      </tr>      <tr>       <td style="text-align:center;"/>       <td colspan="2" style="text-align:center;">        <strong>RF</strong>        <hr/>       </td>       <td colspan="2" style="text-align:center;">        <strong>NB</strong>        <hr/>       </td>      </tr>      <tr>       <td style="text-align:center;">        <em>F1@5</em>       </td>       <td style="text-align:center;">        <em>No-LOD</em>       </td>       <td style="text-align:center;">LOD</td>       <td style="text-align:center;">        <em>No-LOD</em>       </td>       <td style="text-align:left;">LOD</td>      </tr>      <tr>       <td style="text-align:center;">        <strong>Popular (P)</strong>       </td>       <td style="text-align:center;">        <em>0.5610</em>       </td>       <td style="text-align:center;">        <strong>0.5659 (*)</strong>       </td>       <td style="text-align:center;">        <em>0.5576</em>       </td>       <td style="text-align:left;">        <strong>0.5577</strong>       </td>      </tr>      <tr>       <td style="text-align:center;">Collaborative (C)</td>       <td style="text-align:center;">        <em>0.5421</em>       </td>       <td style="text-align:center;">        <strong>0.5560</strong>       </td>       <td style="text-align:center;">        <em>0.5610</em>       </td>       <td style="text-align:left;">0.5564</td>      </tr>      <tr>       <td style="text-align:center;">Content-based (T)</td>       <td style="text-align:center;">        <em>0.5532</em>       </td>       <td style="text-align:center;">        <strong>0.5551</strong>       </td>       <td style="text-align:center;">        <em>0.5465</em>       </td>       <td style="text-align:left;">        <strong>0.5494</strong>       </td>      </tr>      <tr>       <td style="text-align:center;">P+C</td>       <td style="text-align:center;">        <em>0.5627</em>       </td>       <td style="text-align:center;">        <strong>0.5630</strong>       </td>       <td style="text-align:center;">        <em>0.5615</em>       </td>       <td style="text-align:left;">0.5580</td>      </tr>      <tr>       <td style="text-align:center;">P+T</td>       <td style="text-align:center;">        <em>0.5567</em>       </td>       <td style="text-align:center;">        <strong>0.5569</strong>       </td>       <td style="text-align:center;">        <em>0.5467</em>       </td>       <td style="text-align:left;">        <strong>0.5497</strong>       </td>      </tr>      <tr>       <td style="text-align:center;">C+T</td>       <td style="text-align:center;">        <em>0.5549</em>       </td>       <td style="text-align:center;">        <strong>0.5553</strong>       </td>       <td style="text-align:center;">        <em>0.5464</em>       </td>       <td style="text-align:center;">        <strong>0.5491</strong>       </td>      </tr>      <tr>       <td style="text-align:center;">P+C+T</td>       <td style="text-align:center;">        <em>0.5583</em>       </td>       <td style="text-align:center;">0.5560</td>       <td style="text-align:center;">        <em>0.5468</em>       </td>       <td style="text-align:center;">        <strong>0.5497</strong>       </td>      </tr>     </tbody>     </table>    </div>    <div class="table-responsive" id="tab4">     <div class="table-caption">     <span class="table-number">Table 4:</span>     <span class="table-title">Impact of Graph-based Features.</span>     </div>     <table class="table">     <tbody>      <tr>       <td style="text-align:center;"/>       <td colspan="2" style="text-align:center;">        <tt>MovieLens</tt>        <hr/>       </td>       <td colspan="2" style="text-align:center;">        <tt>DBbook</tt>        <hr/>       </td>      </tr>      <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">RF</td>       <td style="text-align:center;">NB</td>       <td style="text-align:center;">RF</td>       <td style="text-align:center;">NB</td>      </tr>      <tr>       <td style="text-align:center;">        <em>Baseline</em>       </td>       <td style="text-align:center;">        <em>0.5635</em>       </td>       <td style="text-align:center;">        <em>0.5486</em>       </td>       <td style="text-align:center;">        <em>0.5627</em>       </td>       <td style="text-align:center;">        <em>0.5615</em>       </td>      </tr>      <tr>       <td style="text-align:center;">Baseline+Trip.</td>       <td style="text-align:center;">0.5621</td>       <td style="text-align:center;">0.5483</td>       <td style="text-align:center;">0.5607</td>       <td style="text-align:center;">0.5542</td>      </tr>      <tr>       <td style="text-align:center;">        <em>Baseline+LOD</em>       </td>       <td style="text-align:center;">        <em>0.5642</em>       </td>       <td style="text-align:center;">        <em>0.5451</em>       </td>       <td style="text-align:center;">        <em>0.5659</em>       </td>       <td style="text-align:center;">        <em>0.5580</em>       </td>      </tr>      <tr>       <td style="text-align:center;">        <strong>Baseline+LOD+Trip.</strong>       </td>       <td style="text-align:center;">        <strong>0.5678(*)</strong>       </td>       <td style="text-align:center;">        <strong>0.5481</strong>       </td>       <td style="text-align:center;">        <strong>0.5667(*)</strong>       </td>       <td style="text-align:center;">        <strong>0.5589</strong>       </td>      </tr>     </tbody>     </table>    </div>    <p>Next, we evaluated the impact of graph-based features on our recommendation framework. For each dataset we considered as <em>baseline</em> the best-performing configuration emerged from the previous tables and we extended the representation by introducing <em>tripartite</em> features. By considering <tt>MovieLens</tt> dataset, a positive impact only emerged when <em>graph-based</em> features are merged with <em>LOD-based</em> ones. Indeed, both RF and NB are able to improve F1@5 with a statistically significant improvement when <em>tripartite graph-based features</em> are exploited. This means that the topological information coming from the injection of the features gathered from the LOD cloud can improve the performance of our framework. Overall, the best configuration for ML data is that based on both <em>LOD-based</em> and <em>tripartite graph-based</em> features which uses RF. Similar outcomes emerge if we take into account the results on <tt>DBbook</tt> data. Also in this case, when <em>LOD-based</em> features are included in the representation, graph-based features produce a significant increase of F1@5.</p>    <p>In the last experiment we compared the effectiveness of our hybrid recommendation methodology with several state of the art recommendation algorithms, as User-to-User (U2U-KNN), Item-to-Item Collaborative Filtering (I2I-KNN), the Bayesian Personalized Ranking (BPRMF) and an implementation of PageRank with Priors. Moreover, we also compared our methodology to other <em>LOD-aware recommendation techniques</em>. As future work, we plan to compare our approach also to other semantics-aware RS [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>]. Specifically, we used the features gathered from the LOD as side information for BPRMF and we also extended PageRank with Priors (PPR) with LOD-based features as we investigated in our previous research [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>]. PPR was run by using default settings (80% of the weight distributed to the items the user liked). For brevity, we only report the results obtained by the best-performing configurations (80 neighbors for U2U-KNN and I2I-KNN, 100 factors for BPRMF, 50 factors for BPRMF with side information). For U2U-KNN, I2I-KNN and BPRMF we exploited the implementations already available in MyMediaLite<a class="fn" href="#fn10" id="foot-fn10"><sup>10</sup></a>, while the methods implemented in the Jung framework<a class="fn" href="#fn11" id="foot-fn11"><sup>11</sup></a> were used to run PPR.</p>    <div class="table-responsive" id="tab5">     <div class="table-caption">     <span class="table-number">Table 5:</span>     <span class="table-title">Comparison to state of the art algorithms</span>     </div>     <table class="table">     <tbody>      <tr>       <td style="text-align:center;"/>       <td colspan="2" style="text-align:center;">        <em>F1@5</em>        <hr/>       </td>      </tr>      <tr>       <td style="text-align:center;">Algorithm</td>       <td style="text-align:center;">        <tt>MovieLens-1M</tt>       </td>       <td style="text-align:center;">        <tt>DBbook</tt>       </td>      </tr>      <tr>       <td style="text-align:center;">        <tt>LOD-RecSys</tt>       </td>       <td style="text-align:center;">        <strong>0.5678</strong>       </td>       <td style="text-align:center;">        <strong>0.5667</strong>       </td>      </tr>      <tr>       <td style="text-align:center;">        <tt>U2U-KNN</tt>       </td>       <td style="text-align:center;">0.4270</td>       <td style="text-align:center;">0.5193</td>      </tr>      <tr>       <td style="text-align:center;">        <tt>I2I-KNN</tt>       </td>       <td style="text-align:center;">0.4320</td>       <td style="text-align:center;">0.5111</td>      </tr>      <tr>       <td style="text-align:center;">        <tt>BPRMF</tt>       </td>       <td style="text-align:center;">0.5218</td>       <td style="text-align:center;">0.5290</td>      </tr>      <tr>       <td style="text-align:center;">        <tt>BPRMF+LOD</tt>       </td>       <td style="text-align:center;">0.5215</td>       <td style="text-align:center;">0.5304</td>      </tr>      <tr>       <td style="text-align:center;">        <tt>PPR</tt>       </td>       <td style="text-align:center;">0.5397</td>       <td style="text-align:center;">0.5502</td>      </tr>      <tr>       <td style="text-align:center;">        <tt>PPR+LOD</tt>       </td>       <td style="text-align:center;">0.5400</td>       <td style="text-align:center;">0.5540</td>      </tr>     </tbody>     </table>    </div>    <p>As shown in Table <a class="tbl" href="#tab5">5</a>, our hybrid recommendation framework always overcomes all the baselines on <tt>MovieLens-1M</tt> and <tt>DBbook</tt> data. All the increases are statistically significant. It is worth to note that our approach obtains better results when compared to both classic baselines as well as to other LOD-aware techniques as <tt>BPRMF+LOD</tt> and <tt>PPR+LOD</tt>.</p>    <p>To sum up, several interesting outcomes emerge from these experiments: first, RF was the classification algorithm able to take the best out of our hybrid data representation. Another interesting outcome is the connection between the <em>sparsity</em> of the dataset and the choice of the features to be included in the model. When the dataset is not sparse, <em>collaborative</em> features along with non-personalized <em>popularity-based</em> emerge as the most informative ones. On the other side, when data are sparse, collaborative features need to be replaced or coupled with different information sources. These results further confirmed the outcomes behind this research, since they clearly showed that the injection of exogenous data points gathered from the LOD cloud (in the form of both <em>semantics-aware content-based features</em> and <em>topological tripartite</em> ones) can significantly improve the predictive accuracy of our recommendation framework, leading to an interesting improvement over all the state-of-the-art baselines.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R.Cyganiak, and Z.&#x00A0;G. Ives. 2007. DBpedia: A Nucleus for a Web of Open Data. In <em>      <em>ISWC 2007</em>     </em>(<em>Lecture Notes in Computer Science</em>), Vol.&#x00A0;4825. Springer, 722&#x2013;735. <a class="link-inline force-break"      href="http://dx.doi.org/10.1007/978-3-540-76298-0_52"      target="_blank">http://dx.doi.org/10.1007/978-3-540-76298-0_52</a></li>     <li id="BibPLXBIB0002" label="[2]">R. Burke. 2002. Hybrid recommender systems: Survey and experiments. <em>      <em>UMUAI</em>     </em>12, 4 (2002), 331&#x2013;370.</li>     <li id="BibPLXBIB0003" label="[3]">P. Cremonesi, Y. Koren, and R. Turrin. 2010. Performance of recommender algorithms on top-n recommendation tasks. In <em>      <em>ACM RECSYS</em>     </em>. ACM, 39&#x2013;46.</li>     <li id="BibPLXBIB0004" label="[4]">M. de Gemmis, P. Lops, C. Musto, F. Narducci, and G. Semeraro. 2015. Semantics-Aware Content-Based Recommender Systems. In <em>      <em>Recommender Systems Handbook</em>     </em>. Springer, 119&#x2013;159.</li>     <li id="BibPLXBIB0005" label="[5]">C. Musto, P. Basile, P. Lops, M. de Gemmis, and G. Semeraro. 2017. Introducing linked open data in graph-based recommender systems. <em>      <em>Information Processing &#x0026; Management</em>     </em>53, 2 (2017), 405&#x2013;435.</li>     <li id="BibPLXBIB0006" label="[6]">C. Musto, P. Lops, P. Basile, M. de Gemmis, and G. Semeraro. Semantics-aware Graph-based Recommender Systems Exploiting Linked Open Data. In <em>      <em>Proceedings of the 2016 Conference on User Modeling Adaptation and Personalization</em>     </em>(<em>UMAP 2016</em>). ACM, 229&#x2013;237.</li>     <li id="BibPLXBIB0007" label="[7]">C. Musto, P. Lops, M. de Gemmis, and G. Semeraro. 2017. Semantics-aware Recommender Systems exploiting Linked Open Data and graph-based features. <em>      <em>Knowledge-Based Systems</em>     </em>136, Supplement C (2017), 1 &#x2013; 14.</li>     <li id="BibPLXBIB0008" label="[8]">C. Musto, G. Semeraro, P. Lops, and M. de Gemmis. 2011. Random Indexing and Negative User Preferences for Enhancing Content-Based Recommender Systems. In <em>      <em>EC-Web 2011</em>     </em>(<em>Lecture Notes in Business Inf. Processing</em>), Vol.&#x00A0;85. Springer, 270&#x2013;281.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>http://stats.lod2.eu/</p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>    <tt>http://dbpedia.org/resource/The_Matrix</tt>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a>http://grouplens.org/datasets/movielens/1m/</p>   <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a><a class="link-inline force-break"     href="http://challenges.2014.eswc-conferences.org/index.php/RecSys">http://challenges.2014.eswc-conferences.org/index.php/RecSys</a>   </p>   <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>http://www.cs.waikato.ac.nz/ml/weka/</p>   <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a><a class="link-inline force-break" href="https://lucene.apache.org/">https://lucene.apache.org/</a>   </p>   <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a><a class="link-inline force-break" href="http://snowball.tartarus.org/">http://snowball.tartarus.org/</a>   </p>   <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a><a class="link-inline force-break" href="http://jung.sourceforge.net/">http://jung.sourceforge.net/</a>   </p>   <p id="fn9"><a href="#foot-fn9"><sup>9</sup></a><a class="link-inline force-break" href="http://rival.recommenders.net/">http://rival.recommenders.net/</a>   </p>   <p id="fn10"><a href="#foot-fn10"><sup>10</sup></a><a class="link-inline force-break" href="http://www.mymedialite.net/">http://www.mymedialite.net/</a>   </p>   <p id="fn11"><a href="#foot-fn11"><sup>11</sup></a><a class="link-inline force-break" href="http://jung.sourceforge.net/">http://jung.sourceforge.net/</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186233">https://doi.org/10.1145/3184558.3186233</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
