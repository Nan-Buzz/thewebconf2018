<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Assessing the News Landscape: A Multi-Module Toolkit for Evaluating the Credibility of News</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/main.css"/><script src="../../../../dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../../dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Assessing the News Landscape: A Multi-Module Toolkit for Evaluating the Credibility of News</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Benjamin D.</span>      <span class="surName">Horne</span>     Rensselaer Polytechnic InstituteTroy, New YorkUSA, <a href="mailto:horneb@rpi.edu">horneb@rpi.edu</a>     </div>     <div class="author">     <span class="givenName">William</span>      <span class="surName">Dron</span>     Raytheon BBN TechnologiesCambridge, Massachusetts, USA, <a href="mailto:will.dron@raytheon.com">will.dron@raytheon.com</a>     </div>     <div class="author">     <span class="givenName">Sara</span>      <span class="surName">Khedr</span>     Rensselaer Polytechnic InstituteTroy, New YorkUSA, <a href="mailto:khedrs@rpi.edu">khedrs@rpi.edu</a>     </div>     <div class="author">     <span class="givenName">Sibel</span>      <span class="surName">Adal&#x0131;</span>     Rensselaer Polytechnic InstituteTroy, New YorkUSA, <a href="mailto:adalis@rpi.edu">adalis@rpi.edu</a>     </div>                     </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3186987" target="_blank">https://doi.org/10.1145/3184558.3186987</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Today, journalist, information analyst, and everyday news consumers are tasked with discerning and fact-checking the news. This task has became complex due to the ever-growing number of news sources and the mixed tactics of maliciously false sources. To mitigate these problems, we introduce the The News Landscape (NELA) Toolkit: an open source toolkit for the systematic exploration of the news landscape. NELA allows users to explore the credibility of news articles using well-studied content-based markers of reliability and bias, as well as, filter and sort through article predictions based on the user&#x0027;s own needs. In addition, NELA allows users to visualize the media landscape at different time slices using a variety of features computed at the source level. NELA is built with a modular, pipeline design, to allow researchers to add new tools to the toolkit with ease. Our demo is an early transition of automated news credibility research to assist human fact-checking efforts and increase the understanding of the news ecosystem as a whole.</small>     </p>    </div>    <div class="CCSconcepts">     <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Data analytics;</strong> <strong>Clustering and classification;</strong> &#x2022;<strong> Human-centered computing </strong>&#x2192; Visualization toolkits; Content ranking;</small> </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>content analysis</small>, </span>     <span class="keyword">      <small> news credibility</small>, </span>     <span class="keyword">      <small> fact-checking assistance</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Benjamin D. Horne, William Dron, Sara Khedr, and Sibel Adal&#x0131;. 2018. Assessing the News Landscape: A Multi-Module Toolkit for Evaluating the Credibility of News. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 5 Pages. <a href="https://doi.org/10.1145/3184558.3186987" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3186987</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>Understanding and analyzing the news landscape has became a priority for researchers across many disciplines. The production and consumption of news in today&#x0027;s media landscape favors clicks and attention, as opposed to in-depth analysis. This drive for attention has lead to the emergence of a large number of media sources with ever increasing visibility. These sources operate under different incentives: from benign to opportunistic and malicious. Those sources which are partisan or malicious in intent employ a wide-range of tactics to make their message heard. They employ tactics such as reporting incorrect information, using emotionally charged language, manipulative titles, and mixing true news with fake news. Fake news stories and hyper-partisan news coverage are thought to have influenced various key elections worldwide. This, coupled with the well-known susceptibility of individuals to false and misleading information&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>], has lead to the increasing need for tools that assist researchers, journalists, and every day individuals in the analysis of news. Supporting this notion, in a 2017 agenda for fake news research, Lazer et al. argue that we &#x201D;need to translate existing research into a form that is digestible by journalist and public-facing organizations&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>].&#x201D; However, given the complexity, the problem requires multi-faceted solutions and a better understanding of the wide-range of news sources. In addition, tools should be able to quickly evaluate sources to decide where to dedicate fact-checking efforts (before an article&#x0027;s spread).</p>    <p>To address these problems, we introduce the The News Landscape (NELA) Toolkit: an open source toolkit for the systematic exploration of the news landscape, through a unique combination of (a) real data from news sources and social media, (b) state-of-the-art tools that predict different factors of credibility, and (c) visualization tools to compare a large number of media sources across different axes. Specifically, NELA is made up of multiple independent modules, in which users can scrape news articles for article-level predictions or explore source-level characteristics using the built-in NELA data set. In this demonstration, we discuss the first release of the toolkit, and briefly discuss its utility using an initial 7 months of news data from 92 sources across the reliability and bias spectrum. <figure id="fig1">     <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186987/images/www18companion-227-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">NELA Toolkit architecture</span>     </div>     </figure>    </p>   </section>   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Description of The Demo</h2>     </div>    </header>    <p>To use the NELA Toolkit, visit the NELA Toolkit website (<a class="link-inline force-break" href="http://nelatoolkit.science">nelatoolkit.science</a>). The homepage provides two choices &#x201C;Check a News Article&#x201D; or &#x201C;Compare News Sources.&#x201D;</p>    <p>Under &#x201C;Check a News Article&#x201D; users can provide a url to a news article or manually enter news article text. The tool then performs several predictions on the article: reliability, political impartiality, title objectivity, text objectivity, and several online community interest predictions. Each of these predictions is displayed as a probability and each article with associated predictions are entered into a table. As more article entries are provided, this table can be sorted and filtered by different predictions using the table filters menu at the top of the page. Further, more details about the article and analysis of the article can be found by clicking on the entry in the table. The ultimate goal of this page is to allow journalist and information analyst to quickly filter articles down to ones that need to be fact-checked or are of interest.</p>    <p>Under &#x201C;Compare News Sources&#x201D; users can explore and compare a variety of news sources using content-based features. Specifically, users can select multiple features, sources, and a time range to visualize on a 2-dimensional scatter plot. For example, a user can select &#x201C;reading complexity&#x201D; for the x-axis and &#x201C;negative sentiment&#x201D; for the y-axis using the chart setting menu on the left side of the page. They can then select any number of sources from our data set and a data range over which to explore. The tool will then generate a scatter plot of the selected sources for comparison. If a user wants more details about a source, they can double-click the source bubble in the scatter plot. This detailed page will show source metadata, credibility predictions, and Facebook engagement over time. These details can also be found on the &#x201C;View All Sources&#x201D; page.</p>    <p>The overall architecture of the toolkit can be found in Figure&#x00A0;<a class="fig" href="#fig1">1</a>. Due to lack of space and the many parts of the toolkit, we do not provide screenshots. We encourage readers to visit the NELA Toolkit website (<a class="link-inline force-break" href="http://nelatoolkit.science">nelatoolkit.science</a>), watch our demo walk-through (<a class="link-inline force-break" href="http://nelatoolkit.science/help">nelatoolkit.science/help</a>), or check out our code-base (<a class="link-inline force-break" href="http://goo.gl/cSpWmp">goo.gl/cSpWmp</a>).</p>   </section>   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Data</h2>     </div>    </header>    <p>&#x00A0; Every module in the NELA toolkit is based on real news data. To create a general news data set, we first gather a wide variety of sources using multiple lexicons (opensources.co, Wikipedia) and studies&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>]. These news sources include: mainstream sources, satire sources, maliciously false sources, political blogs, and some relatively unknown sources. Each news source&#x0027;s website or RSS feed is scraped twice a day, everyday, between April 2017 and October 2017, totalling in 92 sources and 136K articles. To control for topic, we only collect news from politics pages and feeds. The complete list of sources currently in the data set can be found on the NELA toolkit website.</p>    <p>From this general news data set, two subsets are created to build a reliability labeled news data set and a bias labeled news data set. Specifically, we use OpenSources (<a class="link-inline force-break" href="http://www.opensources.co/">www.opensources.co/</a>), an expert-curated news source lexicon, to create 4 groups of sources: reliable news, unreliable news, biased news, and unbiased news (Table&#x00A0;<a class="tbl" href="#tab2">2</a>). Opensources has 12 different tags: fake, satire, extreme bias, conspiracy, rumor, state, junk science, hate speech, clickbait, unreliable, political, and reliable. We use the fake and conspiracy tags to create our unreliable group and the bias and political tags to create our biased group. The articles from each labeled source are used in training and testing the two machine learning models, discussed in Sections&#x00A0;<a class="sec" href="#sec-9">4.1</a> and&#x00A0;<a class="sec" href="#sec-10">4.2</a>.</p>    <p>It is important to note this ground truth is a <em>previous behavior</em>-based ground truth rather than a <em>correctness</em>-based ground truth. In other words, if a news source has been found to publish many fake articles in the past, they are an unreliable source, or if a news source has been found to be hyper-partisan many times in the past, they are a biased source. We choose this method for two primary reasons:&#x00A0;(1) reliability and bias can be labeled quickly over time, allowing for our tool to be retrained as the news changes. Currently, fact-checking (or biased-checking) articles is a very slow and selective process. Hence, fact-checked data for algorithm training can be very small and time specific, making trained classifiers difficult to maintain over time. (2) We can reasonably classify fake articles using this method. Explicitly, on a small fact-checked, correctness labeled test set (of 100 articles), the reliability labeled classifier performs well in detecting fake news as unreliable and real news as reliable (with 90% accuracy). However, our predictions are built to predict the &#x201C;type of source&#x201D; a news article is coming from, not the specific nature of the claims in an article. This notion is further discussed in Section&#x00A0;<a class="sec" href="#sec-8">4</a>.</p>    <p>This data will continue to be collected for use in the toolkit and its later release.</p>    <div class="table-responsive" id="tab1">     <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">ROC curves for each feature set using a Random Forest machine learning model, where NECO17 is from &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0002">2</a>], CIKM16 is from &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0008">8</a>], and POS is a standard Part-Of-Speech feature set.</span>     </div>     <table class="table">     <tbody>      <tr>       <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186987/images/www18companion-227-graphic2.jpg" class="img-responsive" alt=""         longdesc=""/>       </td>       <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186987/images/www18companion-227-graphic3.jpg" class="img-responsive" alt=""         longdesc=""/>       </td>      </tr>      <tr>       <td style="text-align:center;">Reliable vs. Unreliable</td>       <td style="text-align:center;">Unbiased vs. Hyper-partisan</td>      </tr>     </tbody>     </table>    </div>   </section>   <section id="sec-8">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Modules in the NELA Toolkit</h2>     </div>    </header>    <p>&#x00A0; In this section, we will briefly discuss the basic research behind each module in the NELA Toolkit.</p>    <section id="sec-9">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Reliability prediction</h3>     </div>     </header>     <p>&#x00A0; The first module predicts the reliability of a user-selected news article. Given a url, the tool scrapes the title and body content from the web page. After the news article is scraped, it is passed through a feature computation pipeline, which computes a large set of content-based features. These features primarily come from&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>], but are also influence by other studies on persuasion&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0007">7</a>]. Due to space restrictions, descriptions of these features can be found on the NELA Toolkit website. After features are computed, they are passed through a feature selection module, which selects the best features for the reliability prediction based on a previously computed variance analysis. Once feature selection is done, the single feature vector, representing the user-selected article, is passed to our machine learning model. The reliability model is a Random Forest classifier trained on news sources labeled by previous behavior, discussed in section&#x00A0;<a class="sec" href="#sec-7">3</a>. To make the ground truth stronger, we also require news sources in the unreliable category to have published more than 1 completely false article according to online fact checkers (eg. <a class="link-inline force-break" href="http://snopes.com">snopes.com</a>, <a class="link-inline force-break" href="http://politifact.com">politifact.com</a>, etc.). In the current implementation, we trained the classifier on 4504 articles and tested it on 1130 articles, achieving 0.89 ROC AUC (refer to Table&#x00A0;<a class="tbl" href="#tab1">1</a>).</p>     <p>The final output of the classifier is a probability of being reliable rather than a strict binary classification. To do this, we use the mean predicted class probabilities from the trees in the forest. This probability is then colored based on the strength of the prediction (where green is strongly reliable, red is strongly not reliable, and yellow is an edge case). This design choice allows for some notion of certainty or uncertainty in the algorithms predictions. News is inherently not a two-class problem, rather a spectrum between the two-classes; hence, it is important to show the user when a data point is near the edge of the decision boundary. Each result is entered into a sort-able and filterable table to allow for batch article analysis. For example, if an analyst is given a large number of news articles to assess, they can use the NELA Toolkit to quickly filter down to the most interesting articles.</p>    </section>    <section id="sec-10">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Bias and subjectivity prediction</h3>     </div>     </header>     <p>&#x00A0; The next module is made up of two independent classifiers: (1) a Random Forest classifier trained on content-based features to predict hyper-partisan articles, (2) a Naive Bayes classifier trained on objective and subjective labeled sentences. Just as in the reliability module (Section&#x00A0;<a class="sec" href="#sec-9">4.1</a>), a user provides a url, and the title and body content is scraped from the web page. The content is then passed through both feature computation and model-specific feature selection pipelines.</p>     <p>The first classifier in this module is very similar to our reliability module, only differing in the data and features selected. The features are based on several studies on news and political bias in text&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>] and the labeled data is discussed in Section&#x00A0;<a class="sec" href="#sec-7">3</a>. The sources are balanced between politically right and politically left hyper-partisan sources. In the current implementation, we trained the classifier on 6158 articles and tested it on 1539 articles, achieving 0.92 ROC AUC (refer to Table&#x00A0;<a class="tbl" href="#tab1">1</a>). The final output from this classifier is a probability of an article being classified as impartial.</p>     <p>The second classifier in this module is more generic than the previous, focusing on sentence level objectivity. Specifically, the classifier will provide a probability of being objective for both the title and body of the news article independently. The separation of title and body allows for a finer-grain analysis of title dynamics. This classifier is built using a Naive Bayes model that is trained on 10K sentences from Pang and Lee 2004&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0006">6</a>], and it achieves a 92% 5-fold cross-validation accuracy. The final outputs of this classifier are the probability of being objective for both the title and body text.</p>     <p>The results from both classifiers are also added to the sort-able and filterable table for quick batch analysis.</p>     <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Sources used in each category</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">        <strong>Reliable/Unbiased sources</strong>        </td>        <td style="text-align:center;">        <strong>Unreliable sources</strong>        </td>        <td style="text-align:center;">        <strong>Hyper-partisan sources</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Associated Press</td>        <td style="text-align:center;">Infowars</td>        <td style="text-align:center;">Brietbart</td>       </tr>       <tr>        <td style="text-align:center;">PBS</td>        <td style="text-align:center;">Liberty News</td>        <td style="text-align:center;">Young Cons</td>       </tr>       <tr>        <td style="text-align:center;">NPR</td>        <td style="text-align:center;">Natural News</td>        <td style="text-align:center;">RedState</td>       </tr>       <tr>        <td style="text-align:center;">CBS</td>        <td style="text-align:center;">Alt Media Syndicate</td>        <td style="text-align:center;">The Blaze</td>       </tr>       <tr>        <td style="text-align:center;">USA Today</td>        <td style="text-align:center;">DC Clothesline</td>        <td style="text-align:center;">CNS</td>       </tr>       <tr>        <td style="text-align:center;">BBC</td>        <td style="text-align:center;">Newslo</td>        <td style="text-align:center;">Bipartisan Report</td>       </tr>       <tr>        <td style="text-align:center;">New York Times</td>        <td style="text-align:center;">Ending the Fed</td>        <td style="text-align:center;">Occupy Democrats</td>       </tr>       <tr>        <td style="text-align:center;">The Guardian</td>        <td style="text-align:center;">Daily Buzz Live</td>        <td style="text-align:center;">Daily Kos</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Intellihub</td>        <td style="text-align:center;">Shareblue</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">Freedom Daily</td>        <td style="text-align:center;">Politicus USA</td>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec-11">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Community interest prediction</h3>     </div>     </header>     <p>Our next module is built to predict which online groups are interested in an article using news communities on <tt>reddit.com</tt>. To build this module, we first collect recent posts from 4 news communities (<tt>r/new_right</tt>, <tt>r/esist</tt>, and <tt>r/conspiracy</tt>). Once these posts are collected, we extract the top 25% of posts by their ranking score (roughly upvotes minus downvotes). These posts can be considered the most popular or most widely accepted by the community during the time slice collected. The news article in each post is scraped and content-based features are computed&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>]. We compare <tt>r/news</tt> (a general interest community) to the other three subreddits (specific interest communities). Specifically, using these features, we train 3 binary classifiers to predict articles as &#x201C;<tt>r/news</tt> interest&#x201D; or &#x201C;(<tt>r/new_right</tt>, <tt>r/esist</tt>, <tt>r/conspiracy</tt>) interest.&#x201D; Each classification is shown as a probability, similar to the other modules in the toolkit. In the current implementation, we trained each classifier on 2000 articles and tested each on 500 articles, achieving 0.77 ROC AUC on average.</p>     <p>These community interest models are in a very early stage of development. Currently these models are based solely on news content features, but could be significantly improved with topic, source, or community-specific features. In addition, more in-depth feature analysis can provide insights into community differences and similarities. For example, it may be that highly emotional or subjective articles are popular in both <tt>r/new_right</tt> and <tt>r/esist</tt>, but the articles differ in slant (due to selection bias, framing bias, etc.). Automatic methods to capture these various types of bias in a general news setting could significantly improve our accuracy. We leave these improvements to future work.</p>    </section>    <section id="sec-12">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.4</span> Feature-based source visualizations</h3>     </div>     </header>     <p>Our last module analyzes the news at a source-level granularity, rather than an article-level granularity. Using our data set (refer to Section&#x00A0;<a class="sec" href="#sec-7">3</a>), we computed 260 content-based features&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>] on each article. Users can pick a set of news sources, a time frame, and 2 to 4 features to visualize on a 2-dimensional plane. This visualization provides a quick and easy comparison of individual sources or clusters of sources.</p>     <p>Further, we provide meta data for each source, which can be accessed by clicking on a source bubble in the visualization. The meta data includes:</p>     <ol class="list-no-style">     <li id="list1" label="(1)">Percentage of articles that were predicted as reliable using our reliability model<br/></li>     <li id="list2" label="(2)">Percentage of articles that were predicted as impartial using our bias model<br/></li>     <li id="list3" label="(3)">Top phrases for each month using Autophrase&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0010">10</a>]<br/></li>     <li id="list4" label="(4)">The year the source was founded and the country of origin, if known<br/></li>     <li id="list5" label="(5)">Facebook shares, reactions, and comments over time<br/></li>     </ol>     <p>As data is collected, this module will be updated to reflect the current predictions and articles from each source, allowing for users to explore changes in sources over time.</p>    </section>   </section>   <section id="sec-13">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Acknowledgments</h2>     </div>    </header>    <p>Research was sponsored by the Army Research Laboratory and was accomplished under Cooperative Agreement Number W911NF-09-2-0053 (the ARL Network Science CTA). The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.</p>   </section>   <section id="sec-14">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Authors</h2>     </div>    </header>    <p>     <strong>Benjamin Horne</strong> is a PhD student in Computer Science at Rensselaer Polytechnic Institute. His research focuses on online information quality and credibility, along with the human decisions in assessing online information. This work utilizes techniques in machine learning, natural language processing, and social network analysis to both characterize and detect the veracity information.</p>    <p>     <strong>William Dron</strong> is a Senior Scientist at Raytheon BBN Technologies, where he has worked since 2004. William has a background in communications networks and computer science, particularly for military use. Over the past 8 years, he has focused on cross network genre experimentation and has incorporated social and information sciences in his work. He is particularly interested in utilizing software engineering principles and visualizations to create cohesive and scalable software solutions.</p>    <p>     <strong>Sara Khedr</strong> is a Master&#x0027;s student in the Computer Science department at Rensselaer Polytechnic Institute (RPI). She received her Bachelor&#x0027;s degree in Computer and System Engineering from RPI. During her education, Sara has focused on attaining general software development experience and has previously interned for Workday and Salesforce, two SaaS companies.</p>    <p>     <strong>Dr. Sibel Adal&#x0131;</strong> is a Professor and Associate Head of Computer Science at Renssealer Polytechnic Institute. Her research concentrates on cross-cutting problems related to trust, information processing, and social networks. As part of her work, she has worked as the ARL-lead Network Science Collaborative Technology Alliance (NS-CTA) wide Trust Coordinator, Social and Cognitive Networks Academic Research Center (SCNARC) Associate Director.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Abhijnan Chakraborty, Bhargavi Paranjape, Sourya Kakarla, and Niloy Ganguly. 2016. Stop clickbait: Detecting and preventing clickbaits in online news media. In <em>      <em>ASONAM 2016</em>     </em>. IEEE, 9&#x2013;16.</li>     <li id="BibPLXBIB0002" label="[2]">Benjamin&#x00A0;D Horne and Sibel Adali. 2017. This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire than Real News. (2017).</li>     <li id="BibPLXBIB0003" label="[3]">Benjamin&#x00A0;D Horne, Sibel Adali, and Sujoy Sikdar. 2017. Identifying the social signals that drive online discussions: A case study of Reddit communities. (2017).</li>     <li id="BibPLXBIB0004" label="[4]">David Lazer, Matthew Baum, Nir Grinberg, Lisa Friedland, Kenneth Joseph, Will Hobbs, and Carolina Mattsson. 2017. Combating fake news: An agenda for research and action. <em>      <em>Harvard Kennedy School, Shorenstein Center on Media, Politics and Public Policy</em>     </em>2(2017).</li>     <li id="BibPLXBIB0005" label="[5]">Stephan Lewandowsky, Ullrich&#x00A0;KH Ecker, Colleen&#x00A0;M Seifert, Norbert Schwarz, and John Cook. 2012. Misinformation and its correction: Continued influence and successful debiasing. <em>      <em>Psychological Science in the Public Interest</em>     </em>13, 3(2012), 106&#x2013;131.</li>     <li id="BibPLXBIB0006" label="[6]">Bo Pang and Lillian Lee. [n. d.]. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In <em>      <em>ACL 2004</em>     </em>.</li>     <li id="BibPLXBIB0007" label="[7]">R.&#x00A0;E. Petty and J.&#x00A0;T Cacioppo. 1986. The elaboration likelihood model of persuasion. In <em>      <em>In Communication and Persuasion</em>     </em>. New York: Springer, 1&#x2013;24.</li>     <li id="BibPLXBIB0008" label="[8]">Kashyap Popat, Subhabrata Mukherjee, Jannik Str&#x00F6;tgen, and Gerhard Weikum. [n. d.]. Credibility assessment of textual claims on the web. In <em>      <em>CIKM 2016</em>     </em>. ACM.</li>     <li id="BibPLXBIB0009" label="[9]">Marta Recasens, Cristian Danescu-Niculescu-Mizil, and Dan Jurafsky. 2013. Linguistic Models for Analyzing and Detecting Biased Language.. In <em>      <em>ACL (1)</em>     </em>. 1650&#x2013;1659.</li>     <li id="BibPLXBIB0010" label="[10]">Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare&#x00A0;R Voss, and Jiawei Han. 2017. Automated Phrase Mining from Massive Text Corpora. <em>      <em>arXiv preprint arXiv:1702.04457</em>     </em>(2017).</li>     <li id="BibPLXBIB0011" label="[11]">Yla&#x00A0;R Tausczik and James&#x00A0;W Pennebaker. 2010. The psychological meaning of words: LIWC and computerized text analysis methods. <em>      <em>Journal of language and social psychology</em>     </em>29, 1 (2010), 24&#x2013;54.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186987">https://doi.org/10.1145/3184558.3186987</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
