<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>Leveraging Social Media Signals for Record Linkage</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/main.css"/><script src="../../../../dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../../dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main">  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">Leveraging Social Media Signals for Record Linkage</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author">     <span class="givenName">Andrew T.</span>     <span class="surName">Schneider</span>,     Temple University, <a href="mailto:atschneider@temple.edu">atschneider@temple.edu</a>    </div>    <div class="author">     <span class="givenName">Arjun</span>     <span class="surName">Mukherjee</span>,     University of Houston, <a href="mailto:arjun@cs.uh.edu">arjun@cs.uh.edu</a>    </div>    <div class="author">     <span class="givenName">Eduard C.</span>     <span class="surName">Dragut</span>,     Temple University, <a href="mailto:edragut@temple.edu">edragut@temple.edu</a>    </div>                </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3178876.3186018" target="_blank">https://doi.org/10.1145/3178876.3186018</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>Many data-intensive applications collect (structured) data from a variety of sources. A key task in this process is record linkage, which is the problem of determining the records from these sources that refer to the same real-world entities. Traditional approaches use the record representation of entities to accomplish this task. With the nascence of social media, entities on the Web are now accompanied by user generated content. We present a method for record linkage that uses this hitherto untapped source of entity information. We use document-based distances, with an emphasis on word embedding document distances, to determine if two entities match. Our rationale is that user evaluations of entities converge in semantic content, and hence in the word embedded space, as the number of user evaluations grows. We analyze the effectiveness of the proposed method both as a stand-alone method and in combination with record-based record linkage methods. Experimental results using real-world reviews demonstrate the high effectiveness of our approach. To our knowledge, this is the first work exploring the use of user generated content accompanying entities in the record linkage task.</small>    </p>    </div>    <div class="CCSconcepts">    <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Deduplication;</strong> <strong>Data cleaning;</strong></small> </p>    </div>    <div class="classifications">    <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Record Linkage; Word Embeddings; Word Mover&#x0027;s Distance</small>     </span>    </div>    <br/>    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Andrew T. Schneider, Arjun Mukherjee, and Eduard C. Dragut. 2018. Leveraging Social Media Signals for Record Linkage. In <em>WWW 2018: The 2018 Web Conference,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 10 pages. <a href="https://doi.org/10.1145/3178876.3186018" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3178876.3186018</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-4">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>    </div>    </header>    <p>    <em>Record Linkage</em> (RL) is the task of identifying record entries from different (Web) sources that refer to the same real-world entity. RL is an important component of processes that collect and aggregate data from multiple sources, such as Web data warehousing (e.g., Google and Bing Shopping), data aggregation (e.g., product and service reviews) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>], and security data mining for tracking criminal activities&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>]. Records to be resolved reside in independent and uncooperative data sources. For example, Yelp.com (Yelp), TripAdvisor.com (TA), and OpenTable.com (OT) have business listings (e.g., restaurants) and there is substantial overlap in the entities to which the entries in these listings refer. Each entry takes the form of a record with multiple attributes: e.g., Yelp has the entry <em>r</em>    <sub>1</sub> (Table <a class="tbl" href="#tab1">1</a>) which refers to the entity <em>Parc Restaurant</em>, containing attributes such as name, address, and phone.</p>    <p>Traditional RL techniques [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>] focus on attribute similarities to determine if the same real-world entity appears in multiple sources. The problem is notoriously hard if one resorts to attribute-to-attribute similarity since there can be multiple correct values for the same attribute and incomplete, out-of-date, and erroneous data. For example, the entity <em>Parc Restaurant</em> in Table <a class="tbl" href="#tab1">1</a>, has the names &#x201C;Parc Restaurant, Bistro &#x0026; Cafe&#x201D; in Yelp, &#x201C;Parc Brasserie&#x201D; in TA, and &#x201C;Parc&#x201D; in OT and its address varies between &#x201C;227 South 18th Street&#x201D; and &#x201C;227 S 18th St.&#x201D; <em>Tru Restaurant</em> has different phone numbers in the OT and TA records, <em>r</em>    <sub>4</sub> and <em>r</em>    <sub>5</sub>, in Table <a class="tbl" href="#tab1">1</a>. As an example of erroneous data, <em>r</em>    <sub>6</sub> and <em>r</em>    <sub>7</sub> in Table <a class="tbl" href="#tab1">1</a> have the same address and phone, but different names. <em>r</em>    <sub>7</sub> is an incorrect piece of data. Record-oriented matching of entities develops similarity functions and thresholds per attribute [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>]. Oftentimes these functions necessitate domain knowledge and manually created rules [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>], e.g., &#x201C;St.&#x201D; expands to &#x201C;Street&#x201D; helps to match the addresses of <em>r</em>    <sub>1</sub> and <em>r</em>    <sub>2</sub>.</p>    <div class="table-responsive" id="tab1">    <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Example of real-world business listings.</span>    </div>    <table class="table">     <thead>      <tr>       <td style="text-align:center;">RID</td>       <td style="text-align:center;">Name</td>       <td style="text-align:center;">Phone</td>       <td style="text-align:center;">Address</td>       <td style="text-align:center;">Reviews</td>       <td>Source</td>      </tr>     </thead>     <tbody>      <tr>       <td style="text-align:center;">       <em>r</em>       <sub>1</sub>       </td>       <td style="text-align:center;">Parc Rest., Bistro &#x0026; Cafe</td>       <td style="text-align:center;">215-545-2262</td>       <td style="text-align:center;">227 S. 18th St.</td>       <td style="text-align:center;">1,360</td>       <td>Yelp</td>      </tr>      <tr>       <td style="text-align:center;">       <em>r</em>       <sub>2</sub>       </td>       <td style="text-align:center;">Parc Brasserie</td>       <td style="text-align:center;">215-545-2262</td>       <td style="text-align:center;">277 S 18th Street</td>       <td style="text-align:center;">1,294</td>       <td>TripAdvisor</td>      </tr>      <tr>       <td style="text-align:center;">       <em>r</em>       <sub>3</sub>       </td>       <td style="text-align:center;">Parc</td>       <td style="text-align:center;">215-545-2262</td>       <td style="text-align:center;">227 South 18th Street</td>       <td style="text-align:center;">5,479</td>       <td>OpenTable</td>      </tr>      <tr>       <td style="text-align:center;">       <em>r</em>       <sub>4</sub>       </td>       <td style="text-align:center;">Tru Restaurant</td>       <td style="text-align:center;">312-202-0001</td>       <td style="text-align:center;">676 N Saint Clair St</td>       <td style="text-align:center;">1,796</td>       <td>OpenTable</td>      </tr>      <tr>       <td style="text-align:center;">       <em>r</em>       <sub>5</sub>       </td>       <td style="text-align:center;">Tru Restaurant</td>       <td style="text-align:center;">312-488-2488</td>       <td style="text-align:center;">676 North St. Clair Street</td>       <td style="text-align:center;">329</td>       <td>TripAdvisor</td>      </tr>      <tr>       <td style="text-align:center;">       <em>r</em>       <sub>6</sub>       </td>       <td style="text-align:center;">Zahav</td>       <td style="text-align:center;">215-625-8800</td>       <td style="text-align:center;">237 St James Pl</td>       <td style="text-align:center;">1,434</td>       <td>Yelp</td>      </tr>      <tr>       <td style="text-align:center;">       <em>r</em>       <sub>7</sub>       </td>       <td style="text-align:center;">Zahav&#x0027;s Down the Shore Party</td>       <td style="text-align:center;">237 St James Pl</td>       <td style="text-align:center;">215-625-8800</td>       <td style="text-align:center;">3</td>       <td>Yelp</td>      </tr>     </tbody>    </table>    </div>    <p>As a consequence, techniques using auxiliary information have been proposed for the task of RL, for example, mining entity relations [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>] and query logs [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0047">47</a>]. We propose an RL technique of this class in this paper. We consider the <em>user generated content</em> (UGC) accompanying entities on the Web as a new source of information to enhance the quality of RL. Virtually all entities on the Web are now accompanied by UGC in the form of <em>user reviews</em>, which are freely accessible. We propose an NLP-driven solution to RL, which has customarily been solved with record-centric techniques.</p>    <p>    <strong>Brief Approach Overview.</strong> Figure <a class="fig" href="#fig1">1</a> gives a graphic depiction of the basic steps of our algorithm. Our solution infers if two entities match based on their UGC. For each <em>entry</em> (Fig. <a class="fig" href="#fig1">1</a>.a) in a Web source, we collect its <em>user reviews</em> (Fig. <a class="fig" href="#fig1">1</a>.b) and organize them in a document, called a <em>user review document</em> (URD) (Fig. <a class="fig" href="#fig1">1</a>.c). Steps <em>b</em> and <em>c</em> are opaque to the user. All that we consider in assessing similarity are the resultant <em>vectors</em> (Fig. <a class="fig" href="#fig1">1</a>.d) that are the output of these processes. We determine whether two entities match by computing the similarity or <em>distance</em> between their associated vectors (Fig. <a class="fig" href="#fig1">1</a>.e); a key feature of these vector representations is that they are conducive to pairwise distance measures. For example, we collect and organize the reviews of <em>r</em>    <sub>1</sub> in Yelp into URD <em>d</em>    <sub>1</sub> and those of <em>r</em>    <sub>2</sub> in TA into URD <em>d</em>    <sub>2</sub>. We decide whether <em>r</em>    <sub>1</sub> and <em>r</em>    <sub>2</sub> refer to the same real-world entity based on the similarity between <em>d</em>    <sub>1</sub> and <em>d</em>    <sub>2</sub>. To our knowledge, this is the first work exploring the use of such content in the task of RL.</p>    <p>Numerous algorithms have been proposed to compute the distance between documents represented as vectors, or collections of vectors [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>]. Our work is largely focused on a recently proposed algorithm, <em>Word Mover&#x0027;s Distance</em> (WMD) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>]. WMD employs word embeddings, where semantically meaningful representations of words are learned from their local occurrences within sentences. The appeal of word embeddings in our setting is that, in the embedded space, semantically related words, such as &#x201C;Japanese&#x201D; and &#x201C;sushi&#x201D; or &#x201C;table&#x201D; and &#x201C;seating&#x201D; from the restaurant domain, become very close, allowing entities to be matched with high accuracy. WMD has been shown to give unprecedented low <em>k</em>-nearest neighbor document classification error rates compared to the state-of-the-art document distances [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>]. The problem of entity matching can be considered an instance of <em>k</em>-nearest neighbors clustering. Once the distance measure has been calculated, a <em>decision</em> is made (Fig. <a class="fig" href="#fig1">1</a>.f) as to whether this pair of entities constitutes a matching pair. We explore the decision process in multiple contexts. In one paradigm, we assume that there exists at most one correct match for each entity. The decision process here is based on determining the best possible assignment of pairings, in which we use an approach derived from the <em>stable marriage problem</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>]. In the more general setting, we make no such assumptions and use a general document clustering algorithm, specifically Ricochet [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>]. In both cases we show that the URD distance is a highly accurate measure for distinguishing entity matches.</p>    <p>The key principle of our approach is that a sufficient level of similarity between two URDs suggests that their respective entries refer to the same entity. This idea is based on the empirical observation that <em>in the limit</em> people tend to say the same things about the same entities. In other words, two individuals may focus on different aspects of a given entity in each of their respective reviews, but when considered as a group, the set of all reviews will exhibit a substantial internal similarity in content. This is similar to the motivation behind an aggregation of reviews (say 1 &#x2013; 5 star reviews), where a product is tagged with the average over all the reviews, and it is assumed that as the number of reviews grows, this average converges to a stable limit. Intuitively, our approach mirrors those instances when a person draws a blank when trying to recall the name of an entity in a conversation (say an actor or a scientist), and then starts providing details (e.g., movies or papers, co-stars or co-authors, types of roles or areas of expertise) until the other person is able to correctly identify the entity in question.</p>    <p>It is intuitive that entities within a certain subdomain will cluster together. For instance, in the restaurant domain, two entities with the same <em>cuisine type</em> (e.g., Japanese) would be expected to contain much similar language and therefore have a small document distance. The empirical results of our experiments, however, show that this similarity extends beyond the subdomain to such a degree that pairs of records referring to the same entities consistently occur as the best match despite the existence of multiple subdomains across our datasets. Empirically, our results show that the semantics of the UGC do converge and that our proposed technique is effective. <figure id="fig1">     <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186018/images/www2018-27-fig1.jpg" class="img-responsive" alt="Figure 1"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Process flow of our matching algorithm.</span>     </div>    </figure>    </p>    <p>    <strong>Main Goal.</strong> We study the value of UGC in the task of RL both as a stand-alone method and in conjunction with a record-based RL method. Since our approach and the record-based approaches utilize complementary input: unstructured (user reviews) vs. structured (records), the use of one approach does not exclude the other. We first describe and analyze our UGC-based method in isolation. Then we discuss its added benefit when used together with a record-based RL method. We use FEBRL [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>] for the latter. FEBRL includes features that are useful in our study: a tool for the generation of records with random typo noise and a clustering-based RL algorithm. We show that the joint application of our approach with a record-based approach can improve upon the latter by up to 11%.</p>    <p>Our experimental study with a large volume of reviews from the Restaurant and Hotel domains (about 1.7GB of total data) shows the promise of the approach. Our lead method obtains an average f1-score accuracy of .92, which matches or exceeds that of record-based approaches reported in the literature. We empirically show that the proposed WMD-based approach is robust to review sizes and results in graceful degradation in performance as the number of reviews is reduced.</p>    <p>    <strong>The contributions</strong> of this paper are:</p>    <ul class="list-no-style">    <li id="list1" label="&#x2022;">Give the first RL solution using user generated content, to our knowledge.<br/></li>    <li id="list2" label="&#x2022;">Showcase an emerging application of word embeddings.<br/></li>    <li id="list3" label="&#x2022;">Show that social media signals improve record-based methods from 3%, in the presence of modest UGC (20 reviews per entity), to 12%, when UGC abounds (at least 100 per entity).<br/></li>    <li id="list4" label="&#x2022;">Show the high effectiveness of our approach with experiments on real-world data sets from varied domains, electronics, commodity goods, and business listings.<br/></li>    </ul>   </section>   <section id="sec-5">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>    </div>    </header>    <p>The work on RL can be broadly classified into three categories: (i) effective RL, (ii) optimal selection of similarity measures, and (iii) efficient RL. The works in (i) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>] employ a broad range of machine learning techniques such as decision trees, SVM, logistic regression, correlation mining, and clustering. In (ii), the goal is to automatically select optimal similarity functions [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>] for each attribute of an entity (e.g., using edit distance for the attribute <em>phone</em> and Jaccard distance for <em>name</em>) and determine similarity thresholds [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>]. Scaling to large datasets increases the challenge of RL and the works in (iii) aim to develop parallel and efficient techniques to speed up the process [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0044">44</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0046">46</a>]. There are two broad approaches: distributed RL using MapReduce-like frameworks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>] and blocking [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0040">40</a>]. <em>Blocking</em> uses a subset of the attributes to partition a set of entity records into <em>blocks</em> of records and treats records in different blocks as non-matching a priori. Many approaches are built around locality-sensitive hashing. RL is only applied within blocks to ameliorate its <em>O</em>(<em>n</em>    <sup>2</sup>) complexity. All works in (i) assume that data is partitioned a priori. We make the same assumption, except in Section <a class="sec" href="#sec-25">6.4</a>.</p>    <p>Our work falls into (i) but distinguishes itself from the above approaches in that it is a record oblivious technique. It completely disregards the record attribute values of the records and relies entirely on the entities&#x2019; UGC.</p>   </section>   <section id="sec-6">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> Problem Formulation</h2>    </div>    </header>    <p>Let <em>E</em> be a set of real-world entities within the same application domain (e.g., restaurant, hotel, book). Each entity has a set of attributes (e.g., a business entity has the attributes name, address, and telephone). Let <em>S</em>    <sub>1</sub> and <em>S</em>    <sub>2</sub> be two independent and uncooperative Web sources, each of which has records about the entities in <em>E</em> and each record is accompanied by a set of user reviews. We call these records <em>entity records</em>. The RL problem is to determine all entity records in <em>S</em>    <sub>1</sub> &#x00D7; <em>S</em>    <sub>2</sub> that represent the same real-world entity.</p>    <p>Denote by <span class="inline-equation"><span class="tex">$R_i^{re},$</span>    </span> for <em>i</em> &#x2208; {1, 2}, the set of user reviews attached to the entity record <em>re</em> in Web source <em>S<sub>i</sub>    </em>. The problem to be solved is: given two review sets <span class="inline-equation"><span class="tex">$R^{re}_1$</span>    </span> and <span class="inline-equation"><span class="tex">$R^{rf}_2$</span>    </span> determine whether <em>re</em> &#x2243; <em>rf</em>, i.e., whether <em>re</em> and <em>rf</em> refer to the same real-world entity <em>e</em> &#x2208; <em>E</em>.</p>   </section>   <section id="sec-7">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> Technical Ingredients</h2>    </div>    </header>    <p>In this section, we introduce the main technical tools utilized in our proposed technique: word embeddings, document representations for URD, and the <em>Word Mover&#x0027;s Distance</em> (WMD), which gives a measure of the dissimilarity between two text documents.</p>    <section id="sec-8">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Word2Vec Embedding</h3>     </div>    </header>    <p>A word embedding is a mapping of a vocabulary <em>L</em> to a real number vector space <span class="inline-equation"><span class="tex">$\mathbb {R}^d$</span>     </span>. <em>d</em> is typically in the range 50 to 1000. The key idea to embedding is that semantically similar words become &#x201C;close&#x201D; in the embedded vector space. Several (deep) learning methods have been proposed to generate this mapping [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0039">39</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0041">41</a>]. We use the <em>word2vec</em> embedding method [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>]. <em>word2vec</em> learns a vector representation for each word using a shallow neural network language model, using the <em>skip-gram</em> method. For a sequence of training words <em>w</em>     <sub>1</sub>, ..., <em>w<sub>T</sub>     </em>, the objective of <em>word2vec</em> is to maximize the average log probability <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\[ \frac{1}{T}\sum _{i \in [1..T]}\sum _{j \in nb(i)} log\, p(w_{i+j}|w_i) \] </span>       <br/>      </div>     </div> where <em>nb</em>(<em>i</em>) is the set of neighboring words of the word <em>i</em> and <em>p</em>(<em>w</em>     <sub>      <em>i</em> + <em>j</em>     </sub>|<em>w<sub>i</sub>     </em>) is defined using the softmax function of the associated word vectors <span class="inline-equation"><span class="tex">$v_{w_i}$</span>     </span> and <span class="inline-equation"><span class="tex">$v_{w_j}$</span>     </span>. One reason for choosing this model is its &#x201C;light&#x201D; computation requirements: we conduct all the experiments on a conventional desktop computer. The outcome is a lookup table (or matrix) with a column for each word.</p>    </section>    <section id="sec-9">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Document Representations</h3>     </div>    </header>    <p>We represent documents as real number vectors <strong>d</strong> over the vocabulary <em>L</em>, |<em>L</em>| = <em>n</em>. We consider three different document representation models: Binary, TF-IDF, and Normalized. The latter two are instances of normalized bag-of-words (nBOW) models. The motivation for exploring multiple models is to try to determine which one gives the highest accuracy and <em>consistency</em>. We elaborate on this notion in the discussion in Section <a class="sec" href="#sec-24">6.3</a>. We define the word weighting of these models here. In the following <em>c<sub>i</sub>     </em> denotes number of occurrences of the word <em>i</em> from <em>L</em> in the document at hand. We discard the stop words in all cases.</p>    <p>     <strong>Binary:</strong>     <em>d<sub>i</sub>     </em> = 1 if word <em>i</em> is present in the document and <em>d<sub>i</sub>     </em> = 0 if it is not.</p>    <p>     <strong>TF-IDF:</strong>     <em>d<sub>i</sub>     </em> = <em>tf<sub>i</sub>     </em> &#x00D7; <em>idf<sub>i</sub>     </em>. We consider two weighting schemes [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0025">25</a>], referred to as NT and LT. In both cases, <span class="inline-equation"><span class="tex">$idf_i = log \frac{N}{df_i}$</span>     </span>, where <em>N</em> is the number of documents, and <em>df<sub>i</sub>     </em> is the number of documents that have word <em>i</em>. <em>tf<sub>i</sub>     </em> = <em>c<sub>i</sub>     </em> in NT and <em>tf<sub>i</sub>     </em> = 1 + <em>log</em>(<em>c<sub>i</sub>     </em>) in LT.</p>    <p>     <strong>Normalized:</strong> (ND) <span class="inline-equation"><span class="tex">$d_i = \frac{c_i}{\sum _{i = 1}^{n} c_i}$</span>     </span>.</p>    <p>We implemented a fifth model, Okapi BM25, but due to its consistently poor performance, we omit it from the results.</p>    </section>    <section id="sec-10">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Word Mover&#x0027;s Distance</h3>     </div>    </header>    <p>WMD [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>] is inspired from the Earth Mover&#x0027;s Distance metric [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0035">35</a>]. It interprets the distance between two documents, <em>D</em> and <em>D</em>&#x2032;, as a transportation problem: the distance is the minimum amount that the embedded words of <em>D</em> need to travel to become the embedded words of <em>D</em>&#x2032;.</p>    <p>Let <strong>d</strong> and <strong>d&#x2032;</strong> be the document representation vectors of <em>D</em> and <em>D</em>&#x2032;, respectively. Let <span class="inline-equation"><span class="tex">$\mathbf {X} \in \mathbb {R}^{d \times n}$</span>     </span> be the matrix embedding produced by <em>word2vec</em> for the vocabulary <em>L</em>. The <em>i<sup>th</sup>     </em> column of <strong>X</strong>, denoted <strong>x</strong>     <sub>      <em>i</em>     </sub>, represents the embedding of word <em>i</em> in <span class="inline-equation"><span class="tex">$\mathbb {R}^{d}$</span>     </span>. WMD allows each word <em>i</em> in <strong>d</strong> to be transformed into any word <em>j</em> in <strong>d</strong>&#x2032;, subject to the constraints that the amount leaving word <em>i</em> in <strong>d</strong> equals <em>d<sub>i</sub>     </em> and the amount received by word <em>j</em> in <strong>d&#x2032;</strong> is <em>d<sub>j</sub>     </em>. These constraints can be expressed using a matrix flow <strong>T</strong>, where <strong>T</strong>     <sub>      <em>ij</em>     </sub> denotes the &#x201C;amount&#x201D; of word <em>i</em> in <strong>d</strong> that travels to word <em>j</em> in <strong>d</strong>&#x2032;. The WMD between two documents is defined as the minimum weighted cumulative cost required to move all words from <strong>d</strong> to <strong>d</strong>&#x2032; and is given by the solution to the following linear program: <div class="table-responsive" id="eq1">      <div class="display-equation">       <span class="tex mytex">\begin{align} \text{min}_{\mathbf {T} \ge 0} &#x0026; \sum _{i,j \in [1..n]} \mathbf {T}_{ij} \, c(i, j) &#x0026; \nonumber \\\text{subject to } &#x0026; \sum _{j \in [1..n]} \mathbf {T}_{ij} = d_i &#x0026; \forall i \in [1..n] \\\text{and } &#x0026; \sum _{i \in [1..n]} \mathbf {T}_{ij} = d_j &#x0026; \forall j \in [1..n] \nonumber\end{align} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div>    </p>    <p>where <em>c</em>(<em>i</em>, <em>j</em>) = ||<strong>x</strong>     <sub>      <em>i</em>     </sub> &#x2212; <strong>x</strong>     <sub>      <em>j</em>     </sub>||<sub>2</sub> is the <em>Euclidean</em> distance computed in the <em>word2vec</em> embedding space and represents the distance between words <em>i</em> and <em>j</em>.</p>    </section>   </section>   <section id="sec-11">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Record Linkage with Social Media</h2>    </div>    </header>    <p>We present our RL algorithm in this section, whose main ingredient is the social media content accompanying the records. Our solution is built upon the following hypothesis: A single user review may not give enough details to unambiguously infer the entity to which it refers, but collectively (hundreds of them) they converge to a &#x201C;signature&#x201D; that uniquely identifies the entity. The set of users from a Web source (e.g., Yelp) and the set of users from another Web source (e.g., TripAdvisor) give, independently of each other, very similar aggregated depictions of a given entity. As long as the physical entity is fixed, user evaluations will converge in the review semantics of the word embedded space.</p>    <p>Out algorithm has the following steps:</p>    <ol class="list-no-style">    <li id="list5" label="(1)">Create the URD for each entity record.<br/></li>    <li id="list6" label="(2)">Create the domain vocabulary and compute the vectors <strong>d</strong> for the URDs.<br/></li>    <li id="list7" label="(3)">Compute the document distance <em>&#x03C3;</em>(<strong>d</strong>, <strong>d&#x2032;</strong>) for every pair of URDs.<br/></li>    <li id="list8" label="(4)">Identify matching entity records. (Section <a class="sec" href="#sec-15">5.4</a>)<br/></li>    </ol>    <p>We describe the steps of the algorithm in the following sections.</p>    <section id="sec-12">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.1</span> User Review Document</h3>     </div>    </header>    <p>For each entity record <em>re</em> in the source <em>S<sub>i</sub>     </em>, <em>i</em> = 1, 2, we collect the set of all its reviews <span class="inline-equation"><span class="tex">$R_i^{re}$</span>     </span>. We create a URD <em>D<sub>re</sub>     </em> from <span class="inline-equation"><span class="tex">$R_i^{re}$</span>     </span> as follows. We discard the metadata (e.g., user name, time and date) from each review <span class="inline-equation"><span class="tex">$u \in R_i^{re}$</span>     </span> and perform basic text normalization steps to the content of <em>u</em>, yielding <em>u</em>&#x2032;. This <em>u</em>&#x2032; is appended to <em>D<sub>re</sub>     </em>.</p>    </section>    <section id="sec-13">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.2</span> Domain Vocabulary</h3>     </div>    </header>    <p>The domain vocabulary <em>L</em> is the set of all unique words found among all URDs <em>D<sub>re</sub>     </em> in all <em>S<sub>i</sub>     </em>&#x2019;s. We perform basic word normalization steps to reduce the size of <em>L</em>. We remove all words that appear less than a specified threshold <em>&#x03B6;</em> across all <em>D<sub>re</sub>     </em>&#x2019;s in each source. <em>&#x03B6;</em> = 5 in this work. Table <a class="tbl" href="#tab3">3</a> gives the sizes of <em>L</em> for the various datasets we utilized. We then compute the vector <strong>d</strong>     <sub>      <em>re</em>     </sub> of each URD <em>D<sub>re</sub>     </em> over <em>L</em> as described in Section <a class="sec" href="#sec-9">4.2</a>.</p>    </section>    <section id="sec-14">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.3</span> Document Distances</h3>     </div>    </header>    <p>After finding the URDs of all entities from sources <em>S</em>     <sub>1</sub> and <em>S</em>     <sub>2</sub>, respectively, we compute the distances between every pair of entity records in <em>S</em>     <sub>1</sub> &#x00D7; <em>S</em>     <sub>2</sub>. Let <em>re</em>     <sub>1</sub> &#x2208; <em>S</em>     <sub>1</sub> and <em>re</em>     <sub>2</sub> &#x2208; <em>S</em>     <sub>2</sub> be two entity records and <span class="inline-equation"><span class="tex">$\mathbf {d}_{re_1}$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathbf {d}_{re_2}$</span>     </span> their vectors, respectively. Let <span class="inline-equation"><span class="tex">$\sigma (\mathbf {d}_{re_1}, \mathbf {d}_{re_2})$</span>     </span> be the distance between <span class="inline-equation"><span class="tex">$\mathbf {d}_{re_1}$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathbf {d}_{re_2}$</span>     </span>. We use two standard distances, Euclidean and Jaccard [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0016">16</a>], for <em>&#x03C3;</em> in <span class="inline-equation"><span class="tex">$\mathbb {R}^n$</span>     </span>. These constitute our baseline distances. For WMD, we use each of the document representations as the word weights, which determine the amount required to move between two document representations in the WMD space <span class="inline-equation"><span class="tex">$\mathbb {R}^d$</span>     </span>. The location of each weighted point in this space is determined by the word&#x0027;s <em>word2vec</em> embedding.</p>    </section>    <section id="sec-15">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.4</span> Identify Matching Entity Records</h3>     </div>    </header>    <p>We now discuss how to produce the <em>final</em> set of matching entity records from the <em>&#x03C3;</em>&#x2019;s computed in the previous step. We call a <em>match</em> a subset <em>M</em>&#x2286;<em>S</em>     <sub>1</sub> &#x00D7; <em>S</em>     <sub>2</sub>. Among all possible matches <em>M</em> we seek the match <span class="inline-equation"><span class="tex">$\widehat{M}$</span>     </span> with the property that for every pair <span class="inline-equation"><span class="tex">$(re, rf) \in \widehat{M}$</span>     </span>, <em>re</em> and <em>rf</em> refer to the same real-world entity. In general, <span class="inline-equation"><span class="tex">$\widehat{M}$</span>     </span> may contain pairs of the form (<em>re</em>, <em>rf</em>) and (<em>re</em>, <em>rf</em>&#x2032;), <em>rf</em> &#x2260; <em>rf</em>&#x2032;, i.e, an entity record in <em>S</em>     <sub>1</sub> is mapped to multiple entity records in <em>S</em>     <sub>2</sub>, which can happen when <em>S</em>     <sub>2</sub> contains duplicates. For example, the entity records <em>r</em>     <sub>6</sub> and <em>r</em>     <sub>7</sub> (Table <a class="tbl" href="#tab1">1</a>) are duplicates. We distinguish two cases: (1) <em>S</em>     <sub>1</sub> and <em>S</em>     <sub>2</sub> are duplicate free and (2) <em>S</em>     <sub>1</sub> and <em>S</em>     <sub>2</sub> may each contain duplicates. We study both in this work and show that our approach to RL leads to substantial improvements in both cases.</p>    <section id="sec-16">     <p><em>5.4.1 Duplicate Free Sources.</em> In practice, one may assume that <em>S</em>      <sub>1</sub> and <em>S</em>      <sub>2</sub> are duplicate free on the following empirical observation:</p>     <div class="observation" id="enc1">      <Label>Observation 1.</Label>      <p> Let <em>A<sub>m</sub>       </em> be the set of entity records in a Web source such that each record has at least <em>m</em> user reviews. We empirically observed that for a moderately large <em>m</em> (e.g., <em>m</em> = 20), <em>A<sub>m</sub>       </em> is <em>duplicate free</em>, i.e., &#x2204;<em>re</em>       <sub>1</sub>, <em>re</em>       <sub>2</sub> &#x2208; <em>A<sub>m</sub>       </em> such that <em>re</em>       <sub>1</sub> and <em>re</em>       <sub>2</sub> refer to the same real-world entity.</p>     </div>     <p>This observation has the following intuitive basis. If a source has two (or more) entity records about a real-world entity <em>e</em>, then users converge in large numbers toward the entity record that is the correct representation of <em>e</em> and avoid the incorrect one. Some users may still add their reviews to the wrong entity record, but their number is very small. For example, <em>r</em>      <sub>6</sub>, which is correct, amassed 1,434 reviews, whereas <em>r</em>      <sub>7</sub>, which is incorrect, amassed only 3 reviews. We implicitly meet this constraint on <em>m</em>, because we require each entity record to have sufficient reviews to allow accurate document to document comparison. We present a study about the sensitivity of our RL approach to the number of reviews in Section <a class="sec" href="#sec-26">6.5</a>.</p>     <p>With the assumption that <em>S</em>      <sub>1</sub> and <em>S</em>      <sub>2</sub> are duplicate free, the problem of finding <span class="inline-equation"><span class="tex">$\widehat{M}$</span>      </span> is closely related to well-known matching problems in bipartite graphs [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0024">24</a>]. In particular, it becomes an instance of the <em>stable marriage problem</em> (SMP). The basic formulation of the SMP is as follows. We are given two disjoint sets of size <em>n</em>, the men and the women. Each person has a list of strictly ordered preferences that contains <em>all</em> the members of the other sex. Person <em>x</em> prefers <em>y</em> to <em>z</em>, where <em>y</em> and <em>z</em> are not in the same set with <em>x</em>, iff <em>y</em> precedes <em>z</em> on <em>x</em>&#x2019;s preference list. A matching &#x03A5; is a one-to-one correspondence between men and women. &#x03A5; is <em>stable</em> if there are no two pairs (<em>x</em>, <em>y</em>) and (<em>x</em>&#x2032;, <em>y</em>&#x2032;) in &#x03A5; such that <em>x</em> prefers <em>x</em>&#x2032; to <em>y</em> and <em>y</em>&#x2032; prefers <em>x</em> to <em>x</em>&#x2032;. The SMP is to find a <em>stable matching</em>. The SMP can be extended to the cases where (i) the sets of men and women are of unequal sizes and (ii) each person&#x0027;s preference list is a subset of the members of the opposite sex in strict order. This is called the SMP with<em>incomplete lists</em> (SMI). A stable matching always exists for an instance of SMI and can be found in <em>O</em>(<em>n</em>      <sup>2</sup>) time complexity [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0013">13</a>]. The matching may be <em>partial</em>: there may be men or women who do not have a partner in &#x03A5;.</p>     <p>Our RL problem is an instance of SMI because, in general, <em>S</em>      <sub>1</sub> and <em>S</em>      <sub>2</sub> are of unequal sizes. We utilize a learned distance threshold <em>&#x03C4;</em> with which we eliminate possible pairings. If <em>&#x03C3;</em>(<strong>d</strong>      <sub>       <em>re</em>      </sub>, <strong>d</strong>      <sub>       <em>rf</em>      </sub>) > <em>&#x03C4;</em> our method determines that <span class="inline-equation"><span class="tex">$re \not\simeq rf$</span>      </span>, even if <em>rf</em> is the best match for <em>re</em>. The list of preferences of an entity record <em>re</em> &#x2208; <em>S</em>      <sub>1</sub> is the list of entity records [<em>rf</em>      <sub>1</sub>, ..., <em>rf<sub>s</sub>      </em>] in <em>S</em>      <sub>2</sub> with the property that <span class="inline-equation"><span class="tex">$\tau {\gt} \sigma (\mathbf {d}_{re}, \mathbf {d}_{rf_j}), \forall j \in [1, s]$</span>      </span> and <span class="inline-equation"><span class="tex">$\sigma (\mathbf {d}_{re}, \mathbf {d}_{rf_j}) {\gt} \sigma (\mathbf {d}_{re}, \mathbf {d}_{rf_t})$</span>      </span>, 1 &#x2264; <em>t</em> < <em>j</em> &#x2264; <em>s</em>. We similarly obtain the list of preferences of an entity record <em>rf</em> &#x2208; <em>S</em>      <sub>2</sub> in <em>S</em>      <sub>1</sub>. <span class="inline-equation"><span class="tex">$\widehat{M}$</span>      </span> corresponds to &#x03A5;.</p>    </section>    <section id="sec-17">     <p><em>5.4.2 Non Duplicate Free Sources.</em> There may be instances when either <em>S</em>      <sub>1</sub> or <em>S</em>      <sub>2</sub>, or both, contain duplicates. In that case, the previous approach will not work. We need a grouping or clustering approach. A cluster is a set of duplicate entity records from both <em>S</em>      <sub>1</sub> and <em>S</em>      <sub>2</sub>. We follow the Stringer duplication detection framework [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0015">15</a>] for this setting. Stringer examines a broad spectrum of algorithms for documents clustering as pertains to the RL problem. We considered all the algorithms presented in Stringer together with our proposed WMD measures. For many of them the performance was poor. The Ricochet family of algorithms [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0045">45</a>], particularly the Sequential Rippling (SR) algorithm, performed well for our task. We present the empirical results in Section <a class="sec" href="#sec-25">6.4</a>. The SR algorithm takes as input the similarity between pairs. We convert the WMD distance into a similarity <em>s</em> as: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\[ s(\mathbf {d}_{re}, \mathbf {d}_{rf}) = \frac{1}{1 + \sigma (\mathbf {d}_{re}, \mathbf {d}_{rf})} \] </span>       <br/>       </div>      </div>     </p>     <p>In the SR algorithm, vertices (representing entities) are sorted in descending order of the average weight of their adjacent edges (pairwise similarity scores). The vertex with the highest weight is chosen as the seed of the first cluster, and all other vertices are assigned to this cluster. Subsequently, each following vertex is selected as a seed of a new cluster in order. For each new seed, vertices are reassigned to the new cluster if their similarity to the current seed is greater than to its previous cluster seed [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0045">45</a>].</p>    </section>    </section>    <section id="sec-18">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.5</span> Matching Entity Records with Structured and Unstructured Data</h3>     </div>    </header>    <p>In a real world setting, entity records may be accompanied by varying amounts of UGC or none at all. In Section <a class="sec" href="#sec-27">6.6</a> we show that our UGC based technique can be effective in conjunction with traditional record based methods, even when the amount of available UGC is small (e.g., 20 user reviews). For a data source <em>S<sub>i</sub>     </em>, let <em>US<sub>i</sub>     </em> be the subset of entity records accompanied by UGC and <em>SS<sub>i</sub>     </em> be the subset of entity records without UGC.</p>    <p>For datasources <em>S</em>     <sub>1</sub> and <em>S</em>     <sub>2</sub>, we apply a purely record-based approach to the pairs in the sets: <em>SS</em>     <sub>1</sub> &#x00D7; <em>SS</em>     <sub>2</sub>, <em>SS</em>     <sub>1</sub> &#x00D7; <em>US</em>     <sub>2</sub>, and <em>US</em>     <sub>1</sub> &#x00D7; <em>SS</em>     <sub>2</sub>. We are able to make use of the available UGC and apply a combination of the structured and unstructured approaches to the pairs in the sets <em>UG</em>     <sub>1</sub> &#x00D7; <em>UG</em>     <sub>2</sub>. In a basic record based RL setting, we first find the pairwise distance for all equivalent fields between two sets of records. This distance <em>&#x03C1;</em> is some type of string edit distance.</p>    <p>For example, for records <em>R</em>     <sub>1</sub> and <em>R</em>     <sub>2</sub>, with fields <em>name<sub>i</sub>     </em>, <em>phone<sub>i</sub>     </em>, and <em>address<sub>i</sub>     </em> for <em>i</em> = 1, 2, we first find the vector of distances <em>&#x03C1;</em> = [<em>&#x03C1;<sup>name</sup>     </em>, <em>&#x03C1;<sup>phone</sup>     </em>, <em>&#x03C1;<sup>address</sup>     </em>] where <em>&#x03C1;<sup>name</sup>     </em> = <em>&#x03C1;</em>(<em>name</em>     <sub>1</sub>, <em>name</em>     <sub>2</sub>), <em>&#x03C1;<sup>phone</sup>     </em> = <em>&#x03C1;</em>(<em>phone</em>     <sub>1</sub>, <em>phone</em>     <sub>2</sub>), and <em>&#x03C1;<sup>address</sup>     </em> = <em>&#x03C1;</em>(<em>address</em>     <sub>1</sub>, <em>address</em>     <sub>2</sub>). These distances serve as the input to a decision function <em>f</em>(<strong>d</strong>), typically a linear function: <em>f</em>(<em>&#x03C1;</em>) = &#x2211;<sub>      <em>k</em>     </sub>     <em>&#x03B1;<sub>k</sub>     </em> &#x00B7; <em>&#x03C1;<sup>k</sup>     </em>. The weights <em>&#x03B1;<sub>i</sub>     </em> can be learned using a training set of pairs of records whose match/nonmatch status are known. If the value <em>f</em>(<em>&#x03C1;</em>) > <em>&#x03B8;</em> for some threshold <em>&#x03B8;</em>, then the pair is predicted to be a match. A straightforward way to combine our UGC distance, <em>&#x03C3;<sup>UGC</sup>     </em>, with this system is to append it to the vector <em>&#x03C1;</em>. The system then learns the optimal weight <em>&#x03B1;<sub>UGC</sub>     </em> for combining <em>&#x03C3;<sup>UGC</sup>     </em> with the record field values. This is the method we consider in this work. The exploration of alternative formulations for this combination is left as future work.</p>    <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Dataset characteristics. Total and average # reviews per entity, average # words per review. # entity matches between sources, # entities per source in magenta.</span>     </div>     <table class="table">      <tbody>       <tr>       <td style="text-align:left;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186018/images/www2018-27-graphic2.jpg" class="img-responsive" alt="" longdesc=""/>       </td>       </tr>      </tbody>     </table>    </div>    </section>   </section>   <section id="sec-19">    <header>    <div class="title-info">     <h2>      <span class="section-number">6</span> Experimental Study</h2>    </div>    </header>    <p>This section describes experimental results on real-world Web sources from a diverse spectrum of application domains, business listings, electronics, and consumer goods. We first analyze the proposed approach in isolation and then in connection with a record-based approach. The main takeaway is (1) in the presence of UGC our method is at least as effective as a record-based approach, but it requires each entity record to have at least 100 user reviews, and (2) when combined with a record-based approach the overall RL effectiveness improves by 7% on average, in some domains by up to 12%. Improvements in accuracy can begin at only 20 reviews per entity record.</p>    <section id="sec-20">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.1</span> Experiment Setting</h3>     </div>    </header>    <p>We describe the datasets and experiment settings in this section. We report accuracy with f1-scores.</p>    <section id="sec-21">     <p><em>6.1.1 Datasets.</em> We evaluate our approach on four real-world datasets: <strong>TOY</strong>, <strong>HOTEL</strong>, and <strong>Amazon</strong> compiled by ourselves<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>, and <strong>Restaurant</strong> based on the dataset from the RIDDLE repository<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>. Table <a class="tbl" href="#tab2">2</a> gives the statistics of the datasets. We report our empirical findings using the traditional f1-score measure. The results are reported in Table <a class="tbl" href="#tab4">4</a>.</p>     <p>      <strong>TOY</strong> contains three lists of restaurant records from TA, OT and Yelp. They have 741, 487, and 250 entity records, respectively. We pair them giving us 3 sets: Yelp-TA, Yelp-OT, and OT-TA. We manually identified 131, 187, and 147 matched entity record pairs, respectively (Table <a class="tbl" href="#tab2">2</a>).</p>     <p>      <strong>Hotel</strong> contains lists of hotel records from TA (HT) and Hotels.com (HC). There are 169 entities in HT and 375 in HC. We identified 152 matched pairs between the 2 sources (Table <a class="tbl" href="#tab2">2</a>).</p>     <p>      <strong>Riddle</strong> has lists of restaurants from Zagat.com and Fodors.com, of sizes 331 and 533, respectively. It has 112 matched pairs. It does not have user reviews. We searched for the Fodors restaurants in TA and the Zagat restaurants in Yelp to find their respective UGC.</p>     <p>      <strong>Amazon</strong> has lists of products from the categories Bikes, Mattresses, TVs, and Laptops with 157, 72, 124, and 78 entities, respectively. We use this dataset to show the percentage improvement to the task of RL when we combine our proposed method with a record-base matcher and to demonstrate the applicability of our technique across domains.</p>     <div class="table-responsive" id="tab3">      <div class="table-caption">       <span class="table-number">Table 3:</span>       <span class="table-title">Entity matching framework instantiation.</span>      </div>      <table class="table">       <tbody>       <tr>        <td style="text-align:center;">         <strong>Document Models</strong>        </td>       </tr>       <tr>        <td style="text-align:left;">NT, LT, Binary, ND</td>       </tr>       <tr>        <td style="text-align:center;">         <strong>Document Similarity Measures : <em>&#x03C3;</em>         </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">Jaccard, Euclidean, WMD-G, WMD-D</td>       </tr>       <tr>        <td style="text-align:center;">         <strong>Lexicon Sizes |<em>L</em>| = <em>n</em>         </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">TA-OT : 36,293, TA-Y : 48,329, Y-OT : 55,194,</td>       </tr>       <tr>        <td style="text-align:left;">RIDDLE : 26,668, HOTEL : 35,031, Bike : 20,347,</td>       </tr>       <tr>        <td style="text-align:left;">TV : 16,944, Laptop : 28,288, Mattress : 15,417</td>       </tr>       <tr>        <td style="text-align:center;">         <strong>Word Embeddings Dimensions : <em>d</em>         </strong>        </td>       </tr>       <tr>        <td style="text-align:left;">WMD-G : 300, WMD-D : 50</td>       </tr>       </tbody>      </table>     </div>    </section>    <section id="sec-22">     <p><em>6.1.2 Document models.</em> For comparison, we implement 4 document models, Binary, LT, NT, and ND (Section <a class="sec" href="#sec-9">4.2</a>); and four document distances, Jaccard, Euclidean, WMD-G, and WMD-D. WMD-G is backed by the Google News <em>word2vec</em> model, which has an embedding for 3M words/phrases; WMD-D is backed by a domain <em>word2vec</em> model trained on all the URDs from Yelp, TA, and OT, in the Restaurant domain, and on all the URDs from HT and HC in the Hotel domain. WMD-G and WMD-D operate on the embedded space <span class="inline-equation"><span class="tex">$\mathbb {R}^d$</span>      </span>, <em>d</em> = 300 and <em>d</em> = 50, respectively. In total, we implement 10 RL algorithms: the Jaccard distance and binary document model are paired together; each of Euclidean, WMD-G and WMD-D is paired with each of the document models LT, NT, and ND. The Jaccard and all Euclidean instantiations of the RL algorithm are the baselines against which we compare the WMD-G and WMD-D instantiations, our contribution. The baselines operate in <span class="inline-equation"><span class="tex">$\mathbb {R}^n$</span>      </span>, where <em>n</em> is the size of vocabulary <em>L</em>. <em>n</em> varies between 26,668 (in <strong>Riddle</strong>) and 55,195 (in Yelp&#x2013;OT) (Table <a class="tbl" href="#tab3">3</a>, third item). We remove all words that appear fewer than <em>&#x03B6;</em> = 5 times across all URDs. Table <a class="tbl" href="#tab3">3</a> summarizes the instantiations of the proposed RL framework.</p>     <div class="table-responsive" id="tab4">      <div class="table-caption">       <span class="table-number">Table 4:</span>       <span class="table-title">Overall effectiveness results on TOY, Riddle, and HOTEL datasets. The shaded columns highlight the best performing document model for each distance type. In particular, <span style="text-decoration: underline;">WMD-G-NT</span>, the darker shaded column, shows the highest average performance (.92) with the lowest fluctuation (standard deviation = 0.3).</span>      </div>      <table class="table">       <tbody>       <tr>        <td style="text-align:left;">         <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186018/images/www2018-27-graphic3.jpg" class="img-responsive" alt="" longdesc=""/>        </td>       </tr>       </tbody>      </table>     </div>     <figure id="fig2">      <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186018/images/www2018-27-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Accuracy variation across top-n words.</span>      </div>     </figure>    </section>    </section>    <section id="sec-23">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.2</span> Top-n Words</h3>     </div>    </header>    <p>As mentioned in Section <a class="sec" href="#sec-14">5.3</a>, the computation of WMD can be costly. In this trial, we study the number of words <em>n</em> over which we need to compute WMD (Eq. <a class="eqn" href="#eq1">1</a>) to achieve high accuracy. We use WMD-D-NT and WMD-G-NT, the best two performing instantiations of our algorithm. We randomly select a set <em>V</em> of 100 matched entity record pairs from <strong>TOY</strong>. The words are ranked by their <em>d<sub>i</sub>     </em> weights (Section <a class="sec" href="#sec-9">4.2</a>). We range <em>n</em> from 10 to 100 in increments of 10 and run both WMD-D-NT and WMD-G-NT on <em>V</em>, every time recording the f1-scores. Figure <a class="fig" href="#fig2">2</a> shows the outcome of this study. We observe that both WMD-D-NT and WMD-G-NT converge very quickly to high f1-scores. This allows us to select low <em>n</em>&#x2019;s, thus ameliorating the computational demands of our algorithm. In all subsequent experiments, we set <em>n</em> = 40 for WMD-G and <em>n</em> = 50 for WMD-D.</p>    </section>    <section id="sec-24">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.3</span> Evaluating Effectiveness</h3>     </div>    </header>    <p>Table <a class="tbl" href="#tab4">4</a> compares the accuracy of all 10 instantiations of the proposed RL algorithm across the 3 datasets. The table shows for each method the highest f1-score and the overall accuracy in the domain. We give the threshold <em>&#x03C4;</em> of the latter in the header of each column. The shaded columns in the table correspond to the best performing document model for particular a document distance. We draw a number of interesting observations from this set of experiments.</p>    <p>(i) WMD-G-NT obtains the highest f1-score in most cases (the right most gray shaded column in the Table <a class="tbl" href="#tab4">4</a>). The 3M word Google News model performs superior to the smaller domain model. This supports the finding that more data creates better embeddings than less, but domain relevant data [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0027">27</a>].</p>    <p>(ii) The NT document model gives the best performance for both WMD-D and WMD-G, and also performs consistently well with the lowest standard deviation of all methods (the middle and right most right gray shaded columns in the Table <a class="tbl" href="#tab4">4</a>). Euclidean performs unexpectedly poorly with either of the TF-IDF weighting schemes. The least sophisticated of the considered document models, binary, outperforms it by a significant margin, over 130%.</p>    <p>(iii) Euclidean distance under the ND model looks to perform comparably to both WMD-G-NT and WMD-D-NT on several pairings of the entity record lists (the left most column in the Table <a class="tbl" href="#tab4">4</a>). This however is a high accuracy fool&#x0027;s gold. If we instead train the threshold <em>&#x03C4;</em> across the entire Restaurant domain and then apply it to each of the individual list pairs, the average f1-score drops by more than 15% to 73% (see row Rest. Domain). For instance, it attains an f1-score of .5 for Yelp-OT, as under the ND document model many unrelated URDs cluster closely together in the <span class="inline-equation"><span class="tex">$\mathbb {R}^n$</span>     </span> space.</p>    <p>Our experiments show that word embedding-based distance measures are marginally affected by the heterogenous content of URDs, less than 3% on average for WMD-G-NT (row Avg. / Std. and column NT in the section GOOGLE (WMD-G) of Table <a class="tbl" href="#tab4">4</a>). They remain consistent both vertically, i.e., across the pairs of entity record lists, and horizontally, i.e., across the document representation models. The last row of Table <a class="tbl" href="#tab4">4</a> gives the average f1-scores and the standard deviations. Based on the results reported in this row, we claim that WMD-G-NT is the most <em>accurate</em> (highest average) and most <em>consistent</em> (lowest standard deviation) of all the models.</p>    <p>Our explanation for the poor performance of the baselines, is that the URDs are generated by a diverse user population, with varied writing skills. Binary and TF-IDF document representation models perform well in classical information retrieval tasks since documents are in general created by individual users, but here two URDs of the same entity may have different unique words and thus reside in different regions of space over the vocabulary <em>L</em>. However, these documents become semantically close in the embedded space.</p>    <p>     <strong>Comparison with Record-based Matchers.</strong> We use <strong>Riddle</strong> to compare our method with two record-based methods [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0049">49</a>] on the task of RL. The two works report f1-scores of 89.8% and 94.6%, respectively. We obtain 96% with our best performing algorithm, WMD-G-NT. This is quite remarkable given that we do not use a single bit of data from the records themselves, such as phone numbers, addresses or names. This showcases the effectiveness of our NLP-driven technique and the usefulness of user reviews in the RL task.</p>    <div class="table-responsive" id="tab5">     <div class="table-caption">      <span class="table-number">Table 5:</span>      <span class="table-title">RL via clustering with Ricochet Sequential Rippling</span>     </div>     <table class="table">      <thead>       <tr>       <td style="text-align:center;">domain</td>       <td style="text-align:center;">source</td>       <td style="text-align:center;">prec.</td>       <td style="text-align:center;">rec.</td>       <td>f1-score</td>       </tr>      </thead>      <tbody>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">TA-OT</td>       <td style="text-align:center;">.91</td>       <td style="text-align:center;">.89</td>       <td>.89</td>       </tr>       <tr>       <td style="text-align:center;">Rest.</td>       <td style="text-align:center;">TA-Yelp</td>       <td style="text-align:center;">.89</td>       <td style="text-align:center;">.9</td>       <td>.9</td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">Yelp-OT</td>       <td style="text-align:center;">.88</td>       <td style="text-align:center;">.87</td>       <td>.88</td>       </tr>       <tr>       <td style="text-align:center;">Rest.</td>       <td style="text-align:center;">TA-OT-Yelp</td>       <td style="text-align:center;">.89</td>       <td style="text-align:center;">.84</td>       <td>.86</td>       </tr>       <tr>       <td style="text-align:center;">Hotel</td>       <td style="text-align:center;">TA-HC</td>       <td style="text-align:center;">.86</td>       <td style="text-align:center;">.86</td>       <td>.86</td>       </tr>      </tbody>     </table>    </div>    </section>    <section id="sec-25">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.4</span> Clustering and Deduplication</h3>     </div>    </header>    <p>In the previous experiments, we assumed that each data source was internally duplicate free. To study how our method performs when this assumption does not hold, we investigate the performance using a general clustering algorithm for the RL problem. In this investigation we artificially divide the UGC for a random sample of entities from each source, such that each entity may be represented up to 5 times in a given data source, each containing non-overlapping content. Specifically we generate the data sets examined here as follows: For each review source, we uniformly randomly select 10% of its entities. For each selected entity <em>e</em>, we uniformly randomly assign each of its reviews to one of <em>k</em> pseudo-entries, <em>e</em>     <sub>1</sub>, &#x2026;, <em>e<sub>k</sub>     </em>. For each <em>e</em>, <em>k</em> is selected randomly from the range [2, 5] subject to the constraint that each pseudo-entry has at least 100 reviews (we justify this choice in Section <a class="sec" href="#sec-26">6.5</a>). These <em>k</em> new entries are added to our review corpus and the original <em>e</em> is removed. This process generates a significantly larger data set than used in the previous study. For example, for the restaurant domain, it consists of 855, 202, and 594 entities for Yelp, TA, and OT, respectively. In addition, for a given entity <em>e</em>, any other entity is a possible match, whether from the same or a different source. This process generates a total of 1741 and 653 entities for the restaurant and hotel domains, respectively. The WMD distances are then calculated as before. As discussed in Section <a class="sec" href="#sec-17">5.4.2</a>, we use the Ricochet algorithms [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>], in particular the Sequential Rippling (SR) algorithm.</p>    <p>The goal now is to find for any given entry, those entries which refer to the same real world entity, both from its own data source and from separate data sources. Under this set-up, each entry may have anywhere from zero to fourteen correct matches (for <strong>TOY</strong>-ALL, zero to nine for the pairwise trials), which makes this a far more complicated task. The results reported here show our best performing model, G-WMD-NT.</p>    <p>We consider the clustering task pairwise for the <strong>TOY</strong> data for each pair of sources, as well as for all sources combined. As we show, the performance is only marginally worse when all sources are considered. The results of the general clustering approach are comparable to the duplicate free case utilized in the previous set of experiments. The average f1-score drops by only 4%, from 92% to 88%, despite this being a more difficult task. This shows that our methods can be applied in the presence of internal duplicates or when more than two data sources are being combined in one pass. The results reported in Table <a class="tbl" href="#tab5">5</a> are in terms of clusters, following the method used in the original paper [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>] for computing precision, recall, and f1-score.</p>    <div class="table-responsive" id="tab6">     <div class="table-caption">      <span class="table-number">Table 6:</span>      <span class="table-title">Review Size Ranging: <strong>TOY</strong> / <strong>HOTEL</strong>      </span>     </div>     <table class="table">      <tbody>       <tr>       <td style="text-align:left;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186018/images/www2018-27-graphic5.jpg" class="img-responsive" alt="" longdesc=""/>       </td>       </tr>      </tbody>     </table>    </div>    </section>    <section id="sec-26">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.5</span> Sensitivity to Volume of Reviews</h3>     </div>    </header>    <p>In this experiment we want to understand where our approach is most effective and where it begins to break down. We use our best performing method WMD-G-NT.</p>    <p>     <strong>Experiment Design.</strong> Consider a set of matched pairs <em>M</em> = {(<em>re</em>     <sub>1</sub>, <em>re</em>     <sub>2</sub>)|<em>re</em>     <sub>1</sub> &#x2208; <em>S</em>     <sub>1</sub>, <em>re</em>     <sub>2</sub> &#x2208; <em>S</em>     <sub>2</sub>}; a set <em>&#x03A9;</em> = {<em>&#x03C9;<sub>i</sub>     </em>} of <em>k</em> ranges of integer numbers, e.g., <em>&#x03C9;</em>     <sub>1</sub> = (0, 10], <em>&#x03C9;</em>     <sub>2</sub> = (10, 25] and so on; and <em>B</em> = {<em>b<sub>ij</sub>     </em>|1 &#x2264; <em>i</em>, <em>j</em> &#x2264; <em>k</em>} a set of buckets so that if (<em>re</em>     <sub>1</sub>, <em>re</em>     <sub>2</sub>) is in bucket <em>b<sub>ij</sub>     </em> then one of <em>re</em>     <sub>1</sub> or <em>re</em>     <sub>2</sub> has its number of reviews in the range <em>&#x03C9;<sub>i</sub>     </em> and the other in <em>&#x03C9;<sub>j</sub>     </em>. One iteration of the experiment has the following steps. First, we randomly and evenly distribute the pairs in <em>M</em> over <em>B</em>. Second, for each pair (<em>re</em>     <sub>1</sub>, <em>re</em>     <sub>2</sub>) in bucket <em>b<sub>ij</sub>     </em>, we randomly generate a number <em>m</em>     <sub>1</sub> &#x2208; <em>&#x03C9;<sub>i</sub>     </em> and a number <em>m</em>     <sub>2</sub> &#x2208; <em>&#x03C9;<sub>j</sub>     </em>. Third, we randomly select <em>m</em>     <sub>1</sub> reviews for <em>re</em>     <sub>1</sub> from the set of all reviews for <em>re</em>     <sub>1</sub>, and <em>m</em>     <sub>2</sub> reviews for <em>re</em>     <sub>2</sub> from the set of all reviews for <em>re</em>     <sub>2</sub>. Fourth, we run the matching algorithms and collect their f1-scores at each bucket.</p>    <p>We run the experiment on <strong>TOY</strong> and <strong>Hotel</strong>. <em>M</em> has 120 randomly chosen matched pairs in each case. <em>k</em> = 5 with ranges: <em>&#x03C9;</em>     <sub>1</sub> = (0, 10] (LE10), <em>&#x03C9;</em>     <sub>2</sub> = (10, 25], <em>&#x03C9;</em>     <sub>3</sub> = (25, 50], <em>&#x03C9;</em>     <sub>4</sub> = (50, 100], and <em>&#x03C9;</em>     <sub>5</sub> = (100, Z] (GT100), where <em>Z</em> &#x2265; 200. We iterate through each trial 10 times. The averaged values of the f1-scores are given in Table <a class="tbl" href="#tab6">6</a>.</p>    <p>     <strong>Outcome.</strong> We observe two main tendencies. (1) as we follow the diagonal from the top left to the bottom right, accuracy steadily improves. This agrees with the general intuition that more reviews leads to improved accuracy, as well as the convergence of review semantics in the limit. (2) further from the diagonal, when the disparity between the number of reviews for each record is high, accuracy suffers. These results suggest that our method as a standalone RL method is most effective whenever entity records have at least about 100 user reviews in practice, which is a modest number in today&#x0027;s Web.</p>    <div class="table-responsive" id="tab7">     <div class="table-caption">      <span class="table-number">Table 7:</span>      <span class="table-title">Record-based improvement. f1-scores with no reviews (records only), records + 20 reviews, records + 100 reviews. % improvement over records only reported.</span>     </div>     <table class="table">      <tbody>       <tr>       <td style="text-align:center;">        <strong>domain</strong>       </td>       <td style="text-align:center;">        <strong>recs only</strong>       </td>       <td style="text-align:center;">        <strong>recs+20 revs.</strong>       </td>       <td>        <strong>recs+100 revs.</strong>       </td>       </tr>       <tr>       <td style="text-align:center;">bike</td>       <td style="text-align:center;">.874</td>       <td style="text-align:center;">.938 / 7%</td>       <td>.977 / 12%</td>       </tr>       <tr>       <td style="text-align:center;">hotel</td>       <td style="text-align:center;">.807</td>       <td style="text-align:center;">.899 / 11%</td>       <td>.898 / 11%</td>       </tr>       <tr>       <td style="text-align:center;">restaurant</td>       <td style="text-align:center;">.907</td>       <td style="text-align:center;">.955 / 5%</td>       <td>.98 / 8%</td>       </tr>       <tr>       <td style="text-align:center;">TV</td>       <td style="text-align:center;">.747</td>       <td style="text-align:center;">.75 / .3 %</td>       <td>.788 / 6%</td>       </tr>       <tr>       <td style="text-align:center;">laptop</td>       <td style="text-align:center;">.849</td>       <td style="text-align:center;">.864 / 2%</td>       <td>.903 / 6%</td>       </tr>       <tr>       <td style="text-align:center;">mattress</td>       <td style="text-align:center;">.851</td>       <td style="text-align:center;">.861 / 1%</td>       <td>.878 / 3%</td>       </tr>      </tbody>     </table>    </div>    </section>    <section id="sec-27">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.6</span> UGC with Structured Data</h3>     </div>    </header>    <p>In this section we show that we obtain significant percentage f1-score improvement when we combine UGC-based techniques with record-based RL techniques. In many cases, only a small amount of UGC substantially improves the accuracy of the matching. This improvement is exhibited across multiple domains. In this experiment we use the publicly available record-based RL tool FEBRL [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>].</p>    <p>For this study we consider review text and record data from 6 very different domains: restaurant, hotel, TV, laptop, mattress, and bike. The record attributes are collected from the original data sources. For restaurant (<strong>TOY</strong>) and <strong>Hotel</strong>, the records come from different data sources. For the Bike, Mattress, TV, and Laptop domains, the records are all collected from a single data source. This is useful since we can easily construct gold standards. We use <strong>Amazon</strong> dataset to simulate the effect of combining data records from distinct data sources. We synthetically perturb the attribute values of a copy of the original record. We use standard practices to perturb the record-level data&#x2013; at random: swap two characters, delete one character, and insert one character&#x2013; which have been used to simulate common errors found in imprecise data sources [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>]. Each error is introduced with .5 probability in the record. In addition, with .05 probability a record field value is dropped completely.</p>    <p>We learn the best threshold model on the record data using an 80/20 train/test random split of data using FEBRL&#x0027;s optimal threshold classifier and run this classifier on the test set. For <em>k</em> &#x2208; {20, 40, &#x2026;, 100}, we take a sample of <em>k</em> reviews without replacement for each entity. (For domains from a single source, we take 2<em>k</em> reviews and disjointly split them randomly between the two matching entity records.) We use our G-WMD-NT model to compute the pairwise UGC similarity between the entities from each data source using each <em>k</em>-set of reviews. These pairwise similarities are appended to the set of record field similarities. We learn the optimal threshold classifier and run this on the test set.</p>    <p>The results in Table <a class="tbl" href="#tab7">7</a> show that for half of the domains, the addition of the information extracted from only 20 reviews can improve the f1-score of RL by at least 5%. This is useful in situations where the individual quantity of UGC may be limited and the record representations suffer from some inaccuracies. The structured and unstructured data can be incorporated to yield a higher performing matcher than either in isolation. As the number of reviews increases, the RL performance both improves and becomes more stable.</p>    <p>The TV domain is an interesting case study. We did not perturb the records for this domain. The record-based matcher yields an f1-score of only .75. The record data for the TV domain contains many fields with very similar values for example:</p>    <ul class="list-no-style">     <li id="list9" label="&#x2022;">&#x201C;Samsung UN75JU7100 75-Inch 4K Ultra HD 3D Smart LED TV (2015 Model)&#x201D;<br/></li>     <li id="list10" label="&#x2022;">&#x201C;Samsung UN50HU6950 50-Inch 4K Ultra HD 60Hz Smart LED TV (2014 Model)&#x201D;<br/></li>     <li id="list11" label="&#x2022;">&#x201C;Samsung UN55JS8500 55-Inch 4K Ultra HD 3D Smart LED TV (2015 Model)&#x201D;<br/></li>    </ul>    <p>These products differ by only a few characters, thus the string similarities between any two pairs are very high. The challenge for record-based RL techniques to delineate between true and false match pairings is greatly complicated when non-matches have very similar record representations, as can often be the case. In these situations, the additional information beyond the record representations, such as UGC, can prove very useful, given an RL technique that can make use of such information.</p>    </section>    <section id="sec-28">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.7</span> URD &#x2013; Entity Record Overlap</h3>     </div>    </header>    <p>Intuition might lead one to the assumption that the good accuracy of our method can straightforwardly be attributed to the frequent mentions of attribute values in an entity record across user reviews, like pieces of restaurant names (e.g., &#x2018;Parc&#x2019;) or cuisine (e.g., &#x2018;French&#x2019;). In this section, our goal is to (in)validate this intuitive statement. Specifically, we aim to compute the average overlap between an entity record <em>re</em> and its document vector <strong>d</strong>. A large overlap would confirm the statement, and thus, imply that the feature set of a regular record-oriented method and that proposed in this work are indistinguishable, a low overlap will disprove it, and show that the user generated content about entities brings a new set of features not available in their record representations.</p>    <p>We examine the overlap of words (tokens) from an entity record with the top 50 highest weighted words (i.e., most important words) from the vector representation. Recall that only those, or a subset thereof, are used in our algorithms (Section <a class="sec" href="#sec-23">6.2</a>). Let <em>W<sub>re</sub>     </em> be the set of words found in the attributes of <em>re</em>, and let <em>W</em>     <sub>      <strong>d</strong>     </sub> be the set of words which are the 50 highest weighted from the URD of <em>re</em>. We design a measure inspired from the f1-score measure, <em>f<sub>re</sub>     </em>, which is robust against the variation in the number of words across entity records. It is defined as follows: <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\[ P_{re} = \frac{|W_{re} \cap W_{\mathbf {d}}|}{|W_{re}|}, P_{\mathbf {d}} = \frac{|W_{re} \cap W_{\mathbf {d}}|}{|W_{\mathbf {d}}|}, f_{re} = \frac{2P_{re} \cdot R_{\mathbf {d}}}{(P_{re} + P_{\mathbf {d}})} \] </span>       <br/>      </div>     </div>    </p>    <p>     <em>f<sub>re</sub>     </em> has the classic properties of the <em>f1-score</em> measure, such as <em>f<sub>re</sub>     </em> &#x2208; [0, 1], for <em>W<sub>re</sub>     </em> = <em>W</em>     <sub>      <strong>d</strong>     </sub>, <em>f<sub>re</sub>     </em> = 1, and for <em>W<sub>re</sub>     </em>&#x2229;<em>W</em>     <sub>      <strong>d</strong>     </sub> = &#x2205;, <em>f<sub>re</sub>     </em> = 0. In addition, it has the desired property that <em>f<sub>re</sub>     </em> < < 1 when |<em>W<sub>re</sub>     </em>| < < |<em>W</em>     <sub>      <strong>d</strong>     </sub>|. The final measure <em>F<sub>re</sub>     </em> averages the <em>f<sub>re</sub>     </em>&#x2019;s over the set of all entity records <em>RE</em> in an application domain. In our experiment, <em>RE</em> is the set of all entity records in the <strong>TOY</strong> dataset.</p>    <div class="table-responsive" id="tab8">     <div class="table-caption">      <span class="table-number">Table 8:</span>      <span class="table-title">Review &#x2013; Record text overlap measure</span>     </div>     <table class="table">      <tbody>       <tr>       <td style="text-align:center;"/>       <td colspan="3" style="text-align:center;">        <strong>Domain</strong>        <hr/>       </td>       <td colspan="3" style="text-align:center;">        <strong>Google</strong>        <hr/>       </td>       </tr>       <tr>       <td style="text-align:center;"/>       <td style="text-align:center;">        <strong>OT</strong>       </td>       <td style="text-align:center;">        <strong>Yelp</strong>       </td>       <td style="text-align:center;">        <strong>TA</strong>       </td>       <td style="text-align:center;">        <strong>OT</strong>       </td>       <td style="text-align:center;">        <strong>Yelp</strong>       </td>       <td>        <strong>TA</strong>       </td>       </tr>       <tr>       <td style="text-align:center;">        <strong>avg.</strong>       </td>       <td style="text-align:center;">0.103</td>       <td style="text-align:center;">0.08</td>       <td style="text-align:center;">0.083</td>       <td style="text-align:center;">0.089</td>       <td style="text-align:center;">0.069</td>       <td>0.073</td>       </tr>       <tr>       <td style="text-align:center;">        <strong>std.</strong>       </td>       <td style="text-align:center;">0.047</td>       <td style="text-align:center;">0.04</td>       <td style="text-align:center;">0.048</td>       <td style="text-align:center;">0.045</td>       <td style="text-align:center;">0.042</td>       <td>0.046</td>       </tr>      </tbody>     </table>    </div>    <p>Table <a class="tbl" href="#tab8">8</a> summarizes the outcome of this study: average <em>F<sub>re</sub>     </em> and standard deviation across all entities in a domain are given. The table shows that there is very little overlap between the entity records and their URDs and that <em>there is a substantial amount of useful information beyond the record attributes that is not yet utilized for the task of RL</em>. Additionally, this shows that the high accuracy of our technique is not due to a small set of key words found in the attribute fields, for example, in entity names or street addresses. The information found in the record attributes has only a minimal impact at most, and it is the convergence of the reviews themselves that renders our technique effective.</p>    </section>    <section id="sec-29">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.8</span> Runtime</h3>     </div>    </header>    <p>We observe that the time requirements for WMD are higher than for the baselines. The greatest time cost is the calculation of the pairwise distance between vector representations. For the Euclidean baseline this calculation is roughly 2 &#x00D7; 10<sup>&#x2212; 4</sup> seconds per pair of records, for WMD it is roughly 2 &#x00D7; 10<sup>&#x2212; 2</sup> seconds per pair. For reasonably large datasets, the time demands of the WMD calculation can be high. For example, we compute the WMD for 222,623 entity pairs on average in <strong>TOY</strong>. Blocking would substantially help ameliorate the computational requirements of the WMD calculation by reducing the number of exact WMD calculations. Our focus in this work however is on the accuracy of the method. Future work includes the additional implementation of performance improvements.</p>    </section>   </section>   <section id="sec-30">    <header>    <div class="title-info">     <h2>      <span class="section-number">7</span> Conclusion</h2>    </div>    </header>    <p>In this paper we showed that social media content accompanying entities on the Web is a valuable resource in the task of RL. We utilized a word embedding-based distance to compute the distance between UGC documents. We argue the effectiveness of our proposed method in classic RL settings and empirically show that the proposed method is highly accurate in the presence of UGC despite not using any entity specific attributes, such as name or address. We also show that it can be combined with record-based methods where it can lead to a substantial improvement in effectiveness. Future work includes expanding the integration of our technique with traditional RL methods and extending our technique to incorporate user models in the document representation and document distances. For instance, for a user that posts multiple reviews or a single lengthy review, reducing the relative importance of a word that occurs multiple times therein.</p>   </section>   <section id="sec-31">    <header>    <div class="title-info">     <h2>      <span class="section-number">8</span> Acknowledgements</h2>    </div>    </header>    <p>The authors would like to thank the anonymous reviewers for their comments. This work was supported in part by the NSF grants 1546480 and 1527364.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">Arvind Arasu, Venkatesh Ganti, and Raghav Kaushik. 2006. Efficient exact set-similarity joins. In <em>      <em>VLDB</em>     </em>. 918&#x2013;929.</li>    <li id="BibPLXBIB0002" label="[2]">Javed&#x00A0;A. Aslam and Meredith Frost. 2003. An Information-theoretic Measure for Document Similarity. In <em>      <em>SIGIR</em>     </em>. 449&#x2013;450.</li>    <li id="BibPLXBIB0003" label="[3]">Roberto&#x00A0;J. Bayardo, Yiming Ma, and Ramakrishnan Srikant. 2007. Scaling up all pairs similarity search. In <em>      <em>WWW</em>     </em>. 131&#x2013;140.</li>    <li id="BibPLXBIB0004" label="[4]">Indrajit Bhattacharya and Lise Getoor. 2007. Collective entity resolution in relational data. <em>      <em>TKDD</em>     </em>1, Article 5 (March 2007). Issue 1.</li>    <li id="BibPLXBIB0005" label="[5]">Mikhail Bilenko and Raymond&#x00A0;J. Mooney. 2003. Adaptive Duplicate Detection Using Learnable String Similarity Measures. In <em>      <em>KDD</em>     </em>. 39&#x2013;48.</li>    <li id="BibPLXBIB0006" label="[6]">David&#x00A0;M. Blei, Andrew&#x00A0;Y. Ng, and Michael&#x00A0;I. Jordan. 2003. Latent Dirichlet Allocation. <em>      <em>JMLR</em>     </em>3(2003), 993&#x2013;1022.</li>    <li id="BibPLXBIB0007" label="[7]">Sung-Hyuk Cha. 2007. Comprehensive Survey on Distance/Similarity Measures between Probability Density Functions. <em>      <em>Inter. J. of Math. Models and Methods in Applied Sciences</em>     </em>1, 4 (2007), 300&#x2013;307.</li>    <li id="BibPLXBIB0008" label="[8]">Peter Christen. 2008. Febrl -: An Open Source Data Cleaning, Deduplication and Record Linkage System with a Graphical User Interface. In <em>      <em>KDD</em>     </em>. 1065&#x2013;1068.</li>    <li id="BibPLXBIB0009" label="[9]">Peter Christen. 2012. <em>      <em>Data Matching - Concepts and Techniques for Record Linkage, Entity Resolution, and Duplicate Detection</em>     </em>. Springer.</li>    <li id="BibPLXBIB0010" label="[10]">Pedro Domingos. 2004. Multi-relational record linkage. In <em>      <em>In Proceedings of the KDD-2004 Workshop on Multi-Relational Data Mining</em>     </em>. 31&#x2013;48.</li>    <li id="BibPLXBIB0011" label="[11]">Eduard&#x00A0;C. Dragut, Bhaskar Dasgupta, Brian&#x00A0;P. Beirne, Ali Neyestani, Badr Atassi, Clement Yu, and Weiyi Meng. 2014. Merging query results from local search engines for georeferenced objects. <em>      <em>ACM Transactions on the Web (TWEB)</em>     </em>8, 4 (2014).</li>    <li id="BibPLXBIB0012" label="[12]">Elena Ferrari and Bhavani&#x00A0;M. Thuraisingham. 2006. Guest editorial: special issue on privacy preserving data management. <em>      <em>VLDB J.</em>     </em>15, 4 (2006), 291&#x2013;292.</li>    <li id="BibPLXBIB0013" label="[13]">D. Gale and L.&#x00A0;S. Shapley. 1962. College Admissions and the Stability of Marriage. <em>      <em>Am. Math. Monthly</em>     </em>69, 1 (1962), 9&#x2013;15.</li>    <li id="BibPLXBIB0014" label="[14]">Dan Gusfield and Robert&#x00A0;W. Irving. 1989. <em>      <em>The Stable Marriage Problem: Structure and Algorithms</em>     </em>. MIT Press.</li>    <li id="BibPLXBIB0015" label="[15]">Oktie Hassanzadeh, Fei Chiang, Hyun&#x00A0;Chul Lee, and Ren&#x00E9;e&#x00A0;J Miller. 2009. Framework for evaluating clustering algorithms in duplicate detection. <em>      <em>Proceedings of the VLDB Endowment</em>     </em>2, 1 (2009), 1282&#x2013;1293.</li>    <li id="BibPLXBIB0016" label="[16]">Paul Jaccard. 1912. The Distribution of the Flora in the Alpine Zone. <em>      <em>New Phytologist</em>     </em>11, 2 (Feb. 1912), 37&#x2013;50.</li>    <li id="BibPLXBIB0017" label="[17]">Dmitri&#x00A0;V. Kalashnikov and Sharad Mehrotra. 2006. Domain-independent data cleaning via analysis of entity-relationship graph. <em>      <em>TODS</em>     </em>31 (2006), 716&#x2013;767. Issue 2.</li>    <li id="BibPLXBIB0018" label="[18]">Hung-sik Kim and Dongwon Lee. 2007. Parallel linkage. In <em>      <em>CIKM</em>     </em>. 283&#x2013;292.</li>    <li id="BibPLXBIB0019" label="[19]">Hung-sik Kim and Dongwon Lee. 2010. HARRA: fast iterative hashed record linkage for large-scale data collections. In <em>      <em>EDBT</em>     </em>. 525&#x2013;536.</li>    <li id="BibPLXBIB0020" label="[20]">Matt&#x00A0;J. Kusner, Yu Sun, Nicholas&#x00A0;I. Kolkin, and Kilian&#x00A0;Q. Weinberger. 2015. From Word Embeddings To Document Distances. In <em>      <em>ICML</em>     </em>. 957&#x2013;966.</li>    <li id="BibPLXBIB0021" label="[21]">R&#x00E9;mi Lebret and Ronan Collobert. 2014. Word Embeddings through Hellinger PCA. In <em>      <em>EACL</em>     </em>. 482&#x2013;490.</li>    <li id="BibPLXBIB0022" label="[22]">Xin Li, Paul Morie, and Dan Roth. 2004. Identification and Tracing of Ambiguous Names: Discriminative and Generative Approaches. In <em>      <em>AAAI</em>     </em>. 419&#x2013;424.</li>    <li id="BibPLXBIB0023" label="[23]">Yitan Li, Linli Xu, Fei Tian, Liang Jiang, Xiaowei Zhong, and Enhong Chen. 2015. Word Embedding Revisited: A New Representation Learning and Explicit Matrix Factorization Perspective. In <em>      <em>IJCAI</em>     </em>. 3650&#x2013;3656.</li>    <li id="BibPLXBIB0024" label="[24]">L&#x00E1;szl&#x00F3; Lov&#x00E1;sz and M.&#x00A0;D. Plummer. 1986. <em>      <em>Matching theory</em>     </em>. North-Holland.</li>    <li id="BibPLXBIB0025" label="[25]">Christopher&#x00A0;D. Manning, Prabhakar Raghavan, and Hinrich Sch&#x00FC;tze. 2008. <em>      <em>Introduction to Information Retrieval</em>     </em>. Cambridge University Press, New York, NY, USA.</li>    <li id="BibPLXBIB0026" label="[26]">Matthew Michelson and Craig&#x00A0;A. Knoblock. 2006. Learning Blocking Schemes for Record Linkage. In <em>      <em>AAAI</em>     </em>. 440&#x2013;445.</li>    <li id="BibPLXBIB0027" label="[27]">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. In <em>      <em>Workshop of ICLR</em>     </em>.</li>    <li id="BibPLXBIB0028" label="[28]">Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg&#x00A0;S Corrado, and Jeff Dean. 2013. Distributed Representations of Words and Phrases and their Compositionality. In <em>      <em>NIPS</em>     </em>. 3111&#x2013;3119.</li>    <li id="BibPLXBIB0029" label="[29]">Steven Minton, Claude Nanjo, Craig&#x00A0;A. Knoblock, Martin Michalowski, and Matthew Michelson. 2005. A Heterogeneous Field Matching Method for Record Linkage. In <em>      <em>ICDM</em>     </em>. 314&#x2013;321.</li>    <li id="BibPLXBIB0030" label="[30]">Gaspard Monge. 1781. M&#x00E9;moire sur la th&#x00E9;orie des d&#x00E9;blais et des remblais. <em>      <em>Histoire de l&#x0027;Academie Royale des Sciences de Paris, avec les M&#x00E9;moires de Math&#x00E9;matique et de Physique pour la m&#x00EA;me ann&#x00E9;e</em>     </em> (1781), 666&#x2013;704.</li>    <li id="BibPLXBIB0031" label="[31]">Erwan Moreau, Fran&#x00E7;ois Yvon, and Olivier Capp&#x00E9;. 2008. Robust Similarity Measures for Named Entities Matching. In <em>      <em>COLING</em>     </em>. 593&#x2013;600.</li>    <li id="BibPLXBIB0032" label="[32]">Giorgio Patrini, Richard Nock, Stephen Hardy, and Tiberio Caetano. 2016. Fast Learning from Distributed Datasets without Entity Matching. In <em>      <em>IJCAI</em>     </em>. 1909&#x2013;1917.</li>    <li id="BibPLXBIB0033" label="[33]">El&#x00A0;Kindi Rezig, Eduard&#x00A0;C. Dragut, Mourad Ouzzani, and Ahmed&#x00A0;K. Elmagarmid. 2015. Query-time record linkage and fusion over web databases. In <em>      <em>ICDE</em>     </em>. 42&#x2013;53.</li>    <li id="BibPLXBIB0034" label="[34]">S.&#x00A0;E. Robertson and S. Walker. 1994. Some Simple Effective Approximations to the 2-Poisson Model for Probabilistic Weighted Retrieval. In <em>      <em>SIGIR</em>     </em>. 232&#x2013;241.</li>    <li id="BibPLXBIB0035" label="[35]">Yossi Rubner, Carlo Tomasi, and Leonidas&#x00A0;J. Guibas. 1998. A Metric for Distributions with Applications to Image Databases. In <em>      <em>ICCV</em>     </em>. 59&#x2013;.</li>    <li id="BibPLXBIB0036" label="[36]">Gerard Salton and Christopher Buckley. 1988. Term-weighting Approaches in Automatic Text Retrieval. <em>      <em>Inf. Process. Manage.</em>     </em>24, 5 (Aug. 1988), 513&#x2013;523.</li>    <li id="BibPLXBIB0037" label="[37]">Sunita Sarawagi and Anuradha Bhamidipaty. 2002. Interactive deduplication using active learning. In <em>      <em>KDD</em>     </em>. 269&#x2013;278.</li>    <li id="BibPLXBIB0038" label="[38]">Parag Singla and Pedro Domingos. 2006. Entity Resolution with Markov Logic. In <em>      <em>ICDM</em>     </em>. 572&#x2013;582.</li>    <li id="BibPLXBIB0039" label="[39]">Richard Socher, John Bauer, Christopher&#x00A0;D. Manning, and Andrew&#x00A0;Y. Ng. 2013. Parsing with Compositional Vector Grammars. In <em>      <em>ACL</em>     </em>. 455&#x2013;465.</li>    <li id="BibPLXBIB0040" label="[40]">Rebecca&#x00A0;C. Steorts, Samuel&#x00A0;L. Ventura, Mauricio Sadinle, Stephen.&#x00A0;E. Fienberg, and Josep Domingo-Ferrer. 2014. <em>      <em>A Comparison of Blocking Methods for Record Linkage</em>     </em>. Springer, 253&#x2013;268.</li>    <li id="BibPLXBIB0041" label="[41]">Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio. 2010. Word Representations: A Simple and General Method for Semi-Supervised Learning. In <em>      <em>ACL</em>     </em>. 384&#x2013;394.</li>    <li id="BibPLXBIB0042" label="[42]">Rares Vernica, Michael&#x00A0;J. Carey, and Chen Li. 2010. Efficient Parallel Set-similarity Joins Using MapReduce. In <em>      <em>SIGMOD</em>     </em>. 495&#x2013;506.</li>    <li id="BibPLXBIB0043" label="[43]">Xiaojun Wan. 2007. A Novel Document Similarity Measure Based on Earth Mover&#x0027;s Distance. <em>      <em>Inf. Sci.</em>     </em>177, 18 (Sept. 2007), 3718&#x2013;3730.</li>    <li id="BibPLXBIB0044" label="[44]">Steven&#x00A0;Euijong Whang, David Menestrina, Georgia Koutrika, Martin Theobald, and Hector Garcia-Molina. 2009. Entity resolution with iterative blocking. In <em>      <em>SIGMOD</em>     </em>. 219&#x2013;232.</li>    <li id="BibPLXBIB0045" label="[45]">Derry&#x00A0;Tanti Wijaya, St&#x00E9;phane Bressan, J Joxan, and DT Wijaya. 2009. Ricochet: A Family of Unconstrained Algorithms for Graph Clustering.. In <em>      <em>DASFAA</em>     </em>. Springer, 153&#x2013;167.</li>    <li id="BibPLXBIB0046" label="[46]">Chuan Xiao, Wei Wang, Xuemin Lin, and Jeffrey&#x00A0;Xu Yu. 2008. Efficient similarity joins for near duplicate detection. In <em>      <em>WWW</em>     </em>. 15:1&#x2013;15:41.</li>    <li id="BibPLXBIB0047" label="[47]">Mohamed Yakout, Ahmed&#x00A0;K. Elmagarmid, Hazem Elmeleegy, Mourad Ouzzani, and Alan Qi. 2010. Behavior Based Record Linkage. <em>      <em>PVLDB</em>     </em>3, 1 (2010), 439&#x2013;448.</li>    <li id="BibPLXBIB0048" label="[48]">Jing Yuan, Lihong He, Eduard Dragut, Weiyi Meng, and Clement Yu. 2017. Result Merging for Structured Queries on the Deep Web with Active Relevance Weight Estimation. <em>      <em>Inf. Sys.</em>     </em>64 (2017), 93&#x2013;103.</li>    <li id="BibPLXBIB0049" label="[49]">Diego Zardetto, Monica Scannapieco, and Tiziana Catarci. 2010. Effective automated Object Matching. In <em>      <em>ICDE</em>     </em>. 757&#x2013;768.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a>These datasets will be shared upon individual requests.</p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break"    href="http://www.cs.utexas.edu/users/ml/riddle/data.html">www.cs.utexas.edu/users/ml/riddle/data.html</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License.<br/>ACM ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186018">https://doi.org/10.1145/3178876.3186018</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
