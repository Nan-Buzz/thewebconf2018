<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Demarcating Endogenous and Exogenous Opinion Diffusion Process on Social Networks</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/main.css"/><script src="https://dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Demarcating Endogenous and Exogenous Opinion Diffusion Process on Social Networks</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Abir</span>      <span class="surName">De</span><a class="fn" href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>,     IIT Kharagpur, <a href="mailto:abir.de@cse.iitkgp.ernet.in">abir.de@cse.iitkgp.ernet.in</a>     </div>     <div class="author">     <span class="givenName">Sourangshu</span>      <span class="surName">Bhattacharya</span>,     IIT Kharagpur, <a href="mailto:sourangshu@cse.iitkgp.ernet.in">sourangshu@cse.iitkgp.ernet.in</a>     </div>     <div class="author">     <span class="givenName">Niloy</span>      <span class="surName">Ganguly</span>,     IIT Kharagpur, <a href="mailto:niloy@cse.iitkgp.ernet.in">niloy@cse.iitkgp.ernet.in</a>     </div>        </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3178876.3186121" target="_blank">https://doi.org/10.1145/3178876.3186121</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>The networked opinion diffusion in online social networks (OSN) is governed by the two genres of opinions&#x2013;<em>endogenous</em> opinions that are driven by the influence of social contacts between users, and <em>exogenous</em> opinions which are formed by external effects like news, feeds etc. Such duplex opinion dynamics is led by users belonging to two categories&#x2013; <em>organic</em> users who generally post endogenous opinions and <em>extrinsic</em> users who are susceptible to externalities, and mostly post the exogenous messages. Precise demarcation of endogenous and exogenous messages offers an important cue to opinion modeling, thereby enhancing its predictive performance. On the other hand, accurate user selection aids to detect extrinsic users, which in turn helps in opinion shaping. In this paper, we design <font style="font-variant: small-caps">CherryPick</font>, a novel learning machinery that classifies the opinions and users by solving a joint inference task in message and user set, from a temporal stream of sentiment messages. Furthermore, we validate the efficacy of our proposal from both modeling and shaping perspectives. Moreover, for the latter, we formulate the opinion shaping problem in a novel framework of stochastic optimal control, in which the selected extrinsic users optimally post exogenous messages so as to guide the opinions of others in a desired way. On five datasets crawled from Twitter, <font style="font-variant: small-caps">CherryPick</font> offers a significant accuracy boost in terms of opinion forecasting, against several competitors. Furthermore, it can precisely determine the quality of a set of control users, which together with the proposed online shaping strategy, consistently steers the opinion dynamics more effectively than several state-of-the-art baselines.</small>     </p>    </div>    <div class="classifications">     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Abir De, Sourangshu Bhattacharya, and Niloy Ganguly. 2018. Demarcating Endogenous and Exogenous Opinion Diffusion Process on Social Networks. In <em>WWW 2018: The 2018 Web Conference,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 11 Pages. <a href="https://doi.org/10.1145/3178876.3186121" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3178876.3186121</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>Research on understanding opinion dynamics, from both modeling and control perspectives, abounds in literature, predominantly following two approaches&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0058">58</a>]. While the first approach that is grounded on the concepts of statistical physics, is barely data-driven and therefore shows poor predictive performance&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0058">58</a>], the second class of models aims to overcome such limitations, by learning a tractable linear model from transient opinion dynamics&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>]. Barring the individual limitations of these existing approaches, they all have looked into the opinion dynamics phenomenon through the tinted glass of a naive assumption &#x2013; that of absence or lack of external effects, despite empirical evidences advocating the presence of such signals&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0053">53</a>]. As a result, the existing models &#x201C;as it is&#x201D; only perform modestly in predicting the opinion dynamics.</p>    <p>Since a social network is an open system encouraging both inward and outward flow of information, a continuous flux of external information is funneled to its users, via a gamut of sources like news, feeds, etc. As a result, a networked opinion formation process that involves extensive interactive discussions between connected users, is also propelled by such external sources recommended to those users. Therefore, at the very outset, we observe two families of opinions &#x2013; <em>endogenous</em> opinions which evolve due to the influence from neighbors, and <em>exogenous</em> opinions that are driven mostly by the externalities. Such dual dynamics further brackets the users into two categories: <em>organic</em> users who predominantly express endogenous opinions, and <em>extrinsic</em> users who largely post exogenous contents&#x2013; together, they organically guide the coupled opinion diffusion process in a social network. In most practical situations, neither true labels of the posts (endogenous or exogenous), nor the users (organic or extrinsic) are available. Therefore, accurate unsupervised labeling of the users and their posts offers a sophisticated trait in opinion modeling&#x2013; thereby boosting the predictive performance for a broad spectrum of applications like pole-prediction, brand sentiment estimation, etc.</p>    <p>Besides prediction, accurate user classification has an immense potential impact on opinion shaping. An effective user categorization technique helps us spot extrinsic users, <em>i.e.</em> people who are susceptible to external posts. Such users can be easily actuated in an <em>opinion shaping</em> task, in which feeds or news are posted on their walls, in order to steer the opinions of others to a given state. The task of opinion shaping has been taken up recently by&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0055">55</a>], however none of the existing opinion shaping approaches aims to identify the extrinsic users, which renders the control strategies practically ineffective. Moreover, the approach in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0055">55</a>] assigns the control signals to each and every node, which in essence means that each user is a control user who governs the opinions of others; consequently, their proposal falls wayside of any practical importance. A couple of recent works&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0059">59</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0060">60</a>] adopt a similar direction, which, however, focus on entirely different applications, e.g. smart broadcasting and activity maximization.</p>    <p>In this paper, our goal is to demarcate endogenous and exogenous messages, classify organic and extrinsic users, and finally demonstrate the utility of our proposal both from opinion modeling and <em>especially opinion shaping</em> viewpoints, where for the latter, we devise an efficient control mechanism, in order to curate the overall opinion dynamics in a favorable manner.</p>    <p>     <strong>Proposed approach:</strong>We initiate our investigation by positing the dynamics of organic opinion in the presence of exogenous actions, using our previously proposed model SLANT&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>]. It allows users&#x2019; latent <em>endogenous</em> opinions to be modulated over time, by <em>both endogenous and exogenous</em> opinions of their neighbors, expressed as sentiment messages (Section <a class="sec" href="#sec-6">3</a>).</p>    <p>Subsequently, we propose <font style="font-variant: small-caps">CherryPick</font>, a principled learning mechanism that optimally demarcates the endogenous and exogenous opinions, and classifies organic and extrinsic users. In order to categorize messages as well as the corresponding users, we aim to select the set of events that comply with the organic dynamics with a high confidence, <em>i.e.</em> a low variance of influence estimation. To this end, we devise this problem as a joint inference task of both message and user category. We find that this proposed inference problem can be formulated as an instance of cardinality constrained multidimensional submodular maximization problem. To solve this optimization problem, we design a novel greedy approach which too, like an ordinary greedy submodular maximization algorithm, enjoys a (1 &#x2212; 1/<em>e</em>) approximation bound (Section <a class="sec" href="#sec-9">4</a>).</p>    <p>In order to show the efficacy of our user selection approach, we propose an opinion shaping task cast as a novel stochastic optimal control problem. In a marked departure from the prior works, we tackle the shaping problem by decoupling the intensities of the selected extrinsic users, into exogenous (&#x03B7;(<em>t</em>)) and endogenous parts (<em>&#x03BB;</em>(<em>t</em>)), where the exogenous rate is associated with a cost to limit the number of control messages. We find that the optimal value of this multidimensional control signal linearly depends on the current opinion, thus giving a simple, yet scalable closed loop solution to the shaping problem (Section <a class="sec" href="#sec-10">5</a>).</p>    <p>Finally, we perform experiments on a set of five diverse datasets crawled from Twitter and show that <font style="font-variant: small-caps">CherryPick</font> by classifying endogenous and exogenous messages, helps in achieving a substantial performance boost in forecasting opinions. Furthermore, we observe that the selected extrinsic users, along with the proposed shaping strategy, consistently steer the opinion dynamics of others more effectively than several baselines (Section <a class="sec" href="#sec-13">6</a>).</p>    <p>     <strong>Contributions:</strong> Summarizing, our main contributions in this paper are twofold: 1. <strong>An unsupervised demarcation approach:</strong> Our proposal offers <font style="font-variant: small-caps">CherryPick</font>, a novel <em>unsupervised</em> learning algorithm that jointly classifies a stream of unlabeled messages, and their users, in the scenario of opinion dynamics. In principle, <font style="font-variant: small-caps">CherryPick</font> is a greedy algorithm that maximizes a novel function <em>f</em>, an inverse measure of parameter variance. We find that <em>f</em> enjoys a joint submodular property in both user and message-set, affording provable approximation guarantees from the proposed algorithm. Despite complex inter-dependencies between the message streams, the presence of such an important function, we believe, is a surprising and key observation. 2. <strong>Opinion shaping by actuating extrinsic users:</strong> To establish the utility of extrinsic user identification, we develop a novel stochastic opinion control framework that computes the optimal control message intensities, with which the extrinsic users should post, so as to guide the opinion dynamics in a desired way. In a marked departure from prior works, our proposal offers a closed loop feedback control policy that computes the required message intensities online.</p>   </section>   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>     </div>    </header>    <p>Opinion modeling and their applications have been widely studied in different guises in many years. In this section, we review some of them, from three major perspectives&#x2013; (i) opinion dynamics modeling, (ii) opinion sensing, and (iii) opinion shaping. <strong>Opinion dynamics modeling.</strong> Modeling the evolution process of opinion flow over networks, mostly follows two approaches, based on (a) statistical physics and (b) data-driven techniques. The first type of models, e.g. Voter, Flocking, DeGroot, etc. is traditionally designed to capture various regulatory real-life phenomena e.g. consensus, polarization, clustering, coexistence etc.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0040">40</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0050">50</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0054">54</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0057">57</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0058">58</a>]. Voter model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>] is a discrete opinion model, where opinions are represented as nominal values, and copied from influencing neighbors in every step. This underlying principle is still a major workhorse for many discrete opinion models&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0040">40</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0050">50</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0054">54</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0057">57</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0058">58</a>]. In contrast to these models, Flocking and DeGroot are continuous opinion models. In Flocking model and its variations&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>], a node <em>i</em> having opinion <em>x<sub>i</sub>     </em> first selects the set of neighbors <em>j</em> with |<em>x<sub>i</sub>     </em> &#x2212; <em>x<sub>j</sub>     </em>| &#x2264; &#x03F5;, and then updates its own opinion by averaging these opinions. DeGroot model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>], on the other hand, allows a user to update her opinion with the average opinions of <em>all</em> her neighbors. In this model, the underlying influence matrix is row stochastic, enforcing consensus for a strongly connected graph. The second class of models, e.g. Biased Voter, AsLM, SLANT, etc. aims to learn a tractable linear model from a temporal message stream reflecting transient opinion dynamics&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>]. While a Biased Voter model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>] unifies various aspects of DeGroot and Flocking models, AsLM&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>] generalizes the DeGroot model by relaxing the structure of influence matrix. In contrast to these models that ignore the temporal effects of messages (post-rate), SLANT&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>] blends the opinion dynamics along with the message dynamics, using a stochastic generative model. However, all these approaches skirt the effect of externalities, which severely constrains their forecasting prowess. <strong>Opinion sensing:</strong> Sensing opinions, or mining sentiments from textual data traditionally relies on sophisticated NLP based machineries. See&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>] for details. Both these monographs provide a comprehensive survey. In general, LIWC&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0047">47</a>] is widely considered as benchmark tool to compute sentiments from rich textual data. On the other hand, Hannak <em>et al.</em> developed a simple yet effective method for sentiment mining from short informal text like tweets&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>], also used by &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>]. Recently, a class of works&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>] designs simple supervised strategies to sense opinion spams, and some of them&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>] also advocates the role of temporal signals on opinion spamming. Note that, exogenous opinions are fundamentally different from opinion spams. In contrast to a spam which is unsolicited and irrelevant to the discussion, an exogenous post is often relevant, yet just an informed reflection of some external news or feeds. Also, since spamminess of a message is its intrinsic property, it does not depend on the messages before it. However, an exogenous post when retweeted, can become endogenous (see Table&#x00A0;<a class="tbl" href="#tab3">3</a>). Furthermore, the opinion spam detection techniques rest on the principle of supervised classification that in turn requires labelled messages. However in the context of networked opinion dynamics, the messages (tweets) come unlabeled, which renders the spam detection techniques practically inapplicable for such scenarios. <strong>Opinion control:</strong> Opinion shaping has been studied mostly by the control theorists&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>]. These works emphasize consensus control, and therefore have limited applicability in most practical scenarios. Furthermore, most of them assume control opinions as continuous signals, whereas in practice, the expressed opinions are discrete events observed only through the messages or posts. Only very recently &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0055">55</a>] attempts to overcome these limitations by modeling control signals as discrete epochs, which, however, offers an approximate and computationally inefficient solution.</p>   </section>   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Model formulation</h2>     </div>    </header>    <p>In this section, we first revisit the model of opinion dynamics in the absence of exogenous actions&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>], and then describe the same in the presence of exogenous actions.</p>    <section id="sec-7">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Problem setup</h3>     </div>     </header>     <p>We use two sources of data as input: a directed social network <span class="inline-equation"><span class="tex">$\mathcal {G}=(\mathcal {V}, \mathcal {E})$</span>     </span> of users with the connections between them (e.g. friends, following, etc), and an aggregated history <span class="inline-equation"><span class="tex">$\mathcal {U}(T)$</span>     </span> of the messages posted by these users during a given time-window [0, <em>T</em>). In this paper, we summarize each message-event <span class="inline-equation"><span class="tex">$e_i \in \mathcal {U}(T)$</span>     </span> using only three components, the user <em>u<sub>i</sub>     </em> who has posted the message, the opinion or sentiment value <em>&#x03B6;<sub>i</sub>     </em> associated with the message, and the timestamp <em>t<sub>i</sub>     </em> of the post. Therefore, <span class="inline-equation"><span class="tex">$\mathcal {U}(T):=\lbrace e_i = (u_i, \zeta _i, t_i) | t_i {\lt} T\rbrace$</span>     </span>. We also use <span class="inline-equation"><span class="tex">$\mathcal {U}(t)$</span>     </span> to denote the set of messages collected until <em>t</em> < <em>T</em>.</p>     <p>In a spirit similar to the one proposed in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>], we assume that the history of events until time <em>t</em> influences the arrival process of events after time <em>t</em>. However, in a direct contrast to&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>] which skirts the potential influence from externalities, we posit that the message events belong to two categories&#x2013; <em>endogenous</em> and <em>exogenous</em>. At the very outset, the arrivals of endogenous events are driven by the previous events in the network, while exogenous events are the rest, originating from external influence, outside the given social network. Note that the distinction between endogenous and exogenous events is not directly observable from the data, but needs to be inferred from the characteristics of the event sequence. To this end, we denote <span class="inline-equation"><span class="tex">$\mathcal {H}(t)$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathcal {C}(t)$</span>     </span> as the sets of endogenous and exogenous events respectively, observed until time <em>t</em>, with <span class="inline-equation"><span class="tex">$\mathcal {U}(t) = \mathcal {H}(t) \cup \mathcal {C}(t)$</span>     </span>. At a user level, we denote <span class="inline-equation"><span class="tex">$\mathcal {H}_u(t) = \lbrace (u_i, m_i, t_i) | u_i = u\ \mbox{and}\, t_i{\lt}t\rbrace$</span>     </span> as the collection of all endogenous messages with sentiment <em>m<sub>i</sub>     </em>&#x2019;s, posted by user <em>u</em> until time <em>t</em>. Therefore, <span class="inline-equation"><span class="tex">$\cup _{u\in \mathcal {V}}\mathcal {H}_u(t)=\mathcal {H}(t)$</span>     </span>. To model the endogenous message dynamics, we represent the message times by a set of counting processes denoted as a vector N(<em>t</em>), in which the <em>u</em>-th entry, <span class="inline-equation"><span class="tex">$N_{u}(t) \in \lbrace 0\rbrace \cup \mathbb {Z}^+$</span>     </span>, counts the number of messages user <em>u</em> posted until time <em>t</em>. Then, we characterize the message rates with the conditional intensity function <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathbb {E}[d {N}(t)\, |\, \mathcal {U}(t)] = {\lambda }^*(t) \, dt, \end{equation} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$d {N}(t):=({dN_{u}(t)})_{u \in \mathcal {V}}$</span>     </span> counts the endogenous messages per user in the interval [<em>t</em>, <em>t</em> + <em>dt</em>) and <span class="inline-equation"><span class="tex">$ {\lambda }^*(t) := (\lambda _{u}^*(t))_{u \in \mathcal {V}}$</span>     </span> denotes the user intensities that depend on the history <span class="inline-equation"><span class="tex">$\mathcal {U}(t)$</span>     </span>. We denote the set of user that <em>u follows</em> by <span class="inline-equation"><span class="tex">$\mathcal {N}(u)$</span>     </span>. <strong>Opinion dynamics in absence of exogenous actions&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0014">14</a>]:</strong> For clarity, we briefly discuss the proposal by De <em>et al.</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>], that ignores the effect of exogenous messages. The user intensities <span class="inline-equation"><span class="tex">$\lambda _u^*(t)$</span>     </span> are generally modeled using multivariate Hawkes Process&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0036">36</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0046">46</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0048">48</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0049">49</a>]. In absence of exogenous actions, <em>i.e.</em>, when <span class="inline-equation"><span class="tex">$\mathcal {U}(t)=\mathcal {H}(t)$</span>     </span>, we have: <div class="table-responsive" id="eq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \lambda ^{*}_u(t) = \mu _u + \sum _{v \in \mathcal {N}(u)} b_{vu} \sum _{e_i \in \mathcal {H}_{v}(t)} \kappa (t - t_i). \end{equation} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div> Here, the first term, <em>&#x03BC;<sub>u</sub>     </em> &#x2265; 0, captures the posts by user <em>u</em> on her own initiative, and the second term, with <em>b<sub>vu</sub>     </em> &#x2265; 0, reflects the influence of previous posts on her intensity (self-excitation). The users&#x2019; latent opinions are represented as a history-dependent, multidimensional stochastic process x<sup>*</sup>(<em>t</em>): <div class="table-responsive" id="eq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} x^{*}_u(t) = \alpha _u + \sum _{v \in \mathcal {N}(u)} a_{vu} \sum _{e_i \in \mathcal {H}_{v}(t)} m_i g(t - t_i) \end{equation} </span>       <br/>       <span class="equation-number">(3)</span>      </div>     </div> where the first term, <span class="inline-equation"><span class="tex">$\alpha _u \in \mathbb {R}$</span>     </span>, models the original opinion a user <em>u</em> and the second term, with <span class="inline-equation"><span class="tex">$a_{vu} \in \mathbb {R}$</span>     </span>, models updates in user <em>u</em>&#x2019;s opinion due to the influence from previous messages of her neighbors. The influnce values, in practice, may depend on various network properties&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>]. Here, <em>&#x03BA;</em>(<em>t</em>) = <em>e</em>     <sup>&#x2212; <em>&#x03BD;t</em>     </sup> and <em>g</em>(<em>t</em>) = <em>e</em>     <sup>&#x2212; <em>&#x03C9;t</em>     </sup> (where <em>&#x03BD;</em>,&#x2009;<em>&#x03C9;</em> &#x2265; 0) denote exponential triggering kernels, which models the decay of influence over time. Finally, when a user <em>u</em> posts a message at time <em>t</em>, the <em>message sentiment <em>m</em> reflects the expressed opinion</em> which is sampled from a distribution <span class="inline-equation"><span class="tex">$p(m | x^*_u(t))$</span>     </span>. Here, the sentiment distribution <span class="inline-equation"><span class="tex">$p|x^* _u(t)$</span>     </span> is assumed to be normal, <em>i.e.</em>      <span class="inline-equation"><span class="tex">$p(m | x_u(t)) = \mathcal {N}(x_u(t), \sigma _u)$</span>     </span>.</p>    </section>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Opinion dynamics with exogenous events</h3>     </div>     </header>     <p>As introduced before, <span class="inline-equation"><span class="tex">$\mathcal {C}(t)$</span>     </span> is the collection of exogenous messages posted until time <em>t</em>. Similar to <span class="inline-equation"><span class="tex">$\mathcal {H}_u(t)$</span>     </span>, we also specify <span class="inline-equation"><span class="tex">$\mathcal {C}_u(t)=\lbrace (u_i,w_i,t_i)|t_i{\lt}t, u_i=u\rbrace$</span>     </span> as the set of exogenous messages posted by user <em>u</em> until time <em>t</em>. To make a clear distinction, we use <em>m<sub>i</sub>     </em> and <em>w<sub>i</sub>     </em> for endogenous and exogenous message sentiments (expressed opinions) respectively. In order to represent the arrival times of the exogenous message set <span class="inline-equation"><span class="tex">$\mathcal {C}(t)$</span>     </span>, we introduce an additional counting process M(<em>t</em>) that regulates the rate of publication of the corresponding opinions <em>w<sub>i</sub>     </em>. Note that, we do not aim to model the dynamics of exogenous events, since their source is not known to us. However, we assume that every exogenous post influences the subsequent endogenous events in the same manner as the previous endogenous events. This is because a recipient user cannot distinguish between exogenous or endogenous posts made by her neighbors. Now, we present the dynamics of latent opinion <span class="inline-equation"><span class="tex">$x^{*}_u(t)$</span>     </span> of user <em>u</em>, in the presence of exogenous messages in the following. <div class="table-responsive" id="eq3">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026; x^{*}_u(t) = \alpha _u + \sum _{v \in \mathcal {N}(u)} a_{vu} \Big (\sum _{e_i \in \mathcal {H}_{v}(t)} m_i g(t - t_i)+ \sum _{e_i \in \mathcal {C}_{v}(t)} w_i g(t - t_i)\Big) \end{align} </span>       <br/>       <span class="equation-number">(4)</span>      </div>     </div> where, the last term captures signals from exogenous posts. Similarly, the endogenous message rate <span class="inline-equation"><span class="tex">$\lambda _u ^* (t)$</span>     </span> of a user <em>u</em> evolves as, <div class="table-responsive" id="eq4">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026; \lambda ^{*}_u(t) = \mu _u + \sum _{v \in \mathcal {N}(u)} b_{vu} \Big (\sum _{e_i \in \mathcal {H}_{v}(t)} \kappa (t - t_i)+ \sum _{e_i \in \mathcal {C}_{v}(t)} \kappa (t - t_i)\Big). \end{align} </span>       <br/>       <span class="equation-number">(5)</span>      </div>     </div> Note that same parameters, <em>a<sub>vu</sub>     </em> and <em>b<sub>vu</sub>     </em>, are used to model the effect of endogenous and exogenous processes, on both opinion and message dynamics. The above equation can be equivalently written as: <div class="table-responsive" id="eq5">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026; {x}^{*}(t) = {\alpha }+ \int _0 ^t {A}g(t-s)\big [ {m}(s)\odot d {N}(s)+ {w}(s)\odot d {M}(s)\big ] \end{align} </span>       <br/>       <span class="equation-number">(6)</span>      </div>     </div>     <div class="table-responsive" id="eq6">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026; {\lambda }^{*}(t) = {\mu }+ \int _0 ^t {B}\kappa (t-s) \big [d {N}(s)+ d {M}(s)\big ]. \end{align} </span>       <br/>       <span class="equation-number">(7)</span>      </div>     </div> Here <span class="inline-equation"><span class="tex">$ {A}=(a_{vu})\in \mathbb {R}^{|\mathcal {V}|\times |\mathcal {V}|}$</span>     </span>, <span class="inline-equation"><span class="tex">$ {B}=(b_{vu})\in \mathbb {R}^{|\mathcal {V}|\times |\mathcal {V}|} _+$</span>     </span>, <span class="inline-equation"><span class="tex">$ {x}^*(t)=(x^*_u(t))_{u\in \mathcal {V}}$</span>     </span>. Similarly we define &#x03BB;<sup>*</sup>(<em>t</em>),&#x2009;m(<em>s</em>),&#x2009;w(<em>s</em>). Furthermore, the exogenous intensity is given by: <span class="inline-equation"><span class="tex">$\mathbb {E}[d {M}(t)|\mathcal {U}(t)]= {\eta }(t)$</span>     </span>. We do not aim to model &#x03B7;(<em>t</em>). However, we do utilize it during opinion shaping in section <a class="sec" href="#sec-10">5</a>.</p>     <p>By defining, P(<em>t</em>) &#x2254; N(<em>t</em>) + M(<em>t</em>), as the counting process associated with <span class="inline-equation"><span class="tex">$\mathcal {U}(t)$</span>     </span>, we further simplify Eqs.&#x00A0;(<a class="eqn" href="#eq5">6</a>) and &#x00A0;(<a class="eqn" href="#eq6">7</a>) as, <div class="table-responsive" id="eq7">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026; {x}^{*}(t) = {\alpha }+ {A}\int _0 ^t g(t-s)\big [ {\zeta }(s)\odot d {P}(s)\big ]\end{align} </span>       <br/>       <span class="equation-number">(8)</span>      </div>     </div>     <div class="table-responsive" id="eq8">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026; {\lambda }^{*}(t) = {\mu }+ \int _0 ^t \kappa (t-s) {B} {P}(s). \end{align} </span>       <br/>       <span class="equation-number">(9)</span>      </div>     </div>     </p>     <p>     <strong>SDE based representation:</strong> Given the triggering kernels to be exponential, the resulting opinion and event dynamics are Markovian, and therefore can be represented as jump stochastic differential equations. This representation will be subsequently used in Section <a class="sec" href="#sec-10">5</a> for opinion shaping, where the exogenous sentiments w(<em>t</em>) and posts represented by the counting process M(<em>t</em>), will act as the control signals to regulate the endogenous opinions x<sup>*</sup>(<em>t</em>).</p>     <div class="proposition" id="enc1">     <Label>Proposition 3.1.</Label>     <p>Given the triggering kernel <em>g</em>(<em>t</em>) = <em>e</em>      <sup>&#x2212; <em>&#x03C9;t</em>      </sup> and <em>&#x03BA;</em>(<em>t</em>) = <em>e</em>      <sup>&#x2212; <em>&#x03BD;t</em>      </sup>, the tuple (x<sup>*</sup>(<em>t</em>), &#x03BB;<sup>*</sup>(<em>t</em>)) following Eqs.&#x00A0;(<a class="eqn" href="#eq5">6</a>)-&#x00A0;(<a class="eqn" href="#eq6">7</a>), is a Markov process, whose dynamics are defined by the following marked jumped stochastic differential equations (SDE): <div class="table-responsive" id="eq9">       <div class="display-equation">        <span class="tex mytex">\begin{align} &#x0026;d {x}^{*}(t) = \omega ({\alpha }- {x}^{*}(t)) dt + {A}[ {m}(t) \odot d {N}(t) + {w}(t) \odot d {M}(t)] \nonumber \\ &#x0026;d {\lambda }^{*}(t) = \nu ({\mu }- {\lambda }^{*}(t)) dt + {B} \, d {N}(t)+ {B} d {M}(t). \end{align} </span>        <br/>        <span class="equation-number">(10)</span>       </div>      </div>     </p>     </div>     <p>The proposition can be easily proved by differentiating Eqs.&#x00A0;(<a class="eqn" href="#eq5">6</a>) and&#x00A0;(<a class="eqn" href="#eq6">7</a>) respectively. A formal proof is given in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>].</p>    </section>   </section>   <section id="sec-9">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Demarcation of messages and users</h2>     </div>    </header>    <p>In this section, we propose a novel technique for demarcating exogenous <span class="inline-equation"><span class="tex">$\mathcal {C}(T)$</span>     </span> and endogenous posts <span class="inline-equation"><span class="tex">$\mathcal {H}(T)$</span>     </span> from a stream of unlabelled messages <span class="inline-equation"><span class="tex">$\mathcal {U}(T)$</span>     </span> gathered during time [0, <em>T</em>). Additionally, we also set about the task of identifying <em>extrinsic</em> users from <em>organic</em> users. <em>Extrinsic</em> users are the ones who collectively post the majority of exogenous content, while <em>organic</em> users mostly discuss the opinions already circulating in the network. Then, based on the categorized posts, we find the optimal parameters &#x03B1;, &#x03BC;, A and B by solving a maximum likelihood estimation (MLE) problem. From now onwards, we would write <span class="inline-equation"><span class="tex">$\mathcal {U}(T)$</span>     </span>, <span class="inline-equation"><span class="tex">$\mathcal {H}(T)$</span>     </span>, <span class="inline-equation"><span class="tex">$\mathcal {C}(T)$</span>     </span> as <span class="inline-equation"><span class="tex">$\mathcal {U}_T$</span>     </span>, <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathcal {C}_T$</span>     </span> to lighten the notations. Furthermore, we denote the organic and extrinsic users as <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathbb {I}$</span>     </span> respectively, with <span class="inline-equation"><span class="tex">$\mathbb {I}=\mathcal {V}\backslash \mathcal {O}$</span>     </span>.</p>    <p>Now, we sail to design an unsupervised learning algorithm to isolate the endogenous events <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> and exogenous events <span class="inline-equation"><span class="tex">$\mathcal {C}_T$</span>     </span> from the stream of unlabeled sentiment messages <span class="inline-equation"><span class="tex">$\mathcal {U}_T$</span>     </span>, which is equivalent to assigning each event <span class="inline-equation"><span class="tex">$e\in \mathcal {U}_T$</span>     </span> into <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> or <span class="inline-equation"><span class="tex">$\mathcal {C}_T$</span>     </span>. This is achieved by extracting the set of events that comply with the endogenous dynamics with high confidence that in-turn is indicated by a low variance of estimated parameters. More in detail, given a candidate set of endogenous events <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> and a candidate set of organic users <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span>, the opinion parameters <span class="inline-equation"><span class="tex">$ {A}_{\mathcal {O}}=({A}_{u})_{u\in \mathcal {O}}, {\alpha }_{\mathcal {O}}=(\alpha _u)_{u\in \mathcal {O}}$</span>     </span> can be estimated by maximizing the likelihood <span class="inline-equation"><span class="tex">$\sum _{i}\log p(m_{u_i}|x^*_{u_i}(t_i))$</span>     </span>, <em>i.e.</em>, minimizing the following, <div class="table-responsive" id="eq10">     <div class="display-equation">      <span class="tex mytex">\begin{align} \underset{ {A}_{\mathcal {O}}, {\alpha }_{\mathcal {O}}}{\text{min}} &#x0026; \sum _{{{\scriptstyle {\begin{array}{*10c}\ e_i\in \mathcal {H}_T \\u\in \mathcal {O}\end{array}}}}}\sigma ^{-2} \Big (m_{u}(t_i) - \alpha _u -\int _{0}^{t_i} g(t-s)({\zeta }(s)\odot d {P}(s))^T {A}_{u}\Big)^2 \Big .\nonumber \\ &#x0026;+c|| {A}_\mathcal {O}||_F ^2+c|| {\alpha }_\mathcal {O}||_2 ^2. \end{align} </span>      <br/>      <span class="equation-number">(11)</span>     </div>     </div> Here, the first term is derived using the Gaussian nature of <span class="inline-equation"><span class="tex">$p|x_u^*(t)$</span>     </span> and the last two are the regularized terms. The optimal parameters (<span class="inline-equation"><span class="tex">$\hat{ {A}}_\mathcal {O},\ \hat{ {\alpha }}_\mathcal {O}$</span>     </span>) depend on the candidate set of endogenous messages <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span>. Moreover, various choices of <span class="inline-equation"><span class="tex">$\mathcal {O}\subseteq \mathcal {V}$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathcal {H}_T\subseteq \mathcal {U}_T$</span>     </span> give different <span class="inline-equation"><span class="tex">$ {A}_{\mathcal {O}}$</span>     </span> and <span class="inline-equation"><span class="tex">$ {\alpha }_{\mathcal {O}}$</span>     </span>, with different parameter variance. To this end, we compute the estimation covariance as, <div class="table-responsive" id="eq11">     <div class="display-equation">      <span class="tex mytex">\begin{align} \mathbb {\Sigma }(\mathcal {H}_T,\mathcal {O}):=\mathbb {E}(\hat{ {\theta }}- {\theta })(\hat{ {\theta }}- {\theta })^T, \ {\theta }:=\text{vec}([ {A}_\mathcal {O}, \ {\alpha }_\mathcal {O}]). \end{align} </span>      <br/>      <span class="equation-number">(12)</span>     </div>     </div> Here the expectation is taken over the noise process induced while getting the message sentiment <em>m<sub>i</sub>     </em>, from the opinion <span class="inline-equation"><span class="tex">$x_{u_i} ^*(t_i)$</span>     </span> according to distribution <span class="inline-equation"><span class="tex">$p(m_i|x^* _{u_i}(t_i))$</span>     </span>. Prior to going into the selection mechanism of <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span>, we first look into the expression of covariance matrix <span class="inline-equation"><span class="tex">$\mathbb {\Sigma }$</span>     </span> in the Lemma&#x00A0;<a class="enc" href="#enc2">2</a>. Note that, the inference problem given by Eq.&#x00A0;(<a class="eqn" href="#eq10">11</a>) is that of regularized least squares estimation, and so the covariance matrix for the optimal parameters can be derived in a closed form given in the following:</p>    <p>     <div class="lemma" id="enc2">     <Label>Lemma 4.1.</Label>     <p> For a given endogenous message-set <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>      </span> and organic user-set <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>      </span>, <div class="table-responsive" id="eq12">       <div class="display-equation">        <span class="tex mytex">\begin{align} \mathbb {\Sigma }(\mathcal {H}_T,\mathcal {O})=\mathop {\mathrm{diag}}_{u\in \mathcal {O}}\big (c {I}+\sigma ^{-2}\sum _{e_i\in \mathcal {H}_T} {\phi }^u _i {\phi }_i ^{uT}\big)^{-1} \end{align} </span>        <br/>        <span class="equation-number">(13)</span>       </div>      </div> where, <span class="inline-equation"><span class="tex">$ {\phi }^u _i=\mathbb {1}_{u_i=u}\big [\int _{0} ^{t_i} g(t-s) {\zeta }(s)\odot d {P}(s),\ 1].$</span>      </span>      <span class="inline-equation"><span class="tex">$ \mathbb {1_X}$</span>      </span> is the indicator function with respect to <em>X</em>.</p>     </div>    </p>    <p>Our objective is to identify <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span>, given their sizes <span class="inline-equation"><span class="tex">$N_\mathcal {O}$</span>     </span> and <span class="inline-equation"><span class="tex">$N_\mathcal {H}$</span>     </span> respectively, so that <span class="inline-equation"><span class="tex">$\mathbb {\Sigma }(\mathcal {H}_T,\mathcal {O})$</span>     </span> is small. Such a set of selected users <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span> and demarcated message-set <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> would then follow endogenous opinion dynamics more faithfully than their complements <span class="inline-equation"><span class="tex">$\mathcal {V}\backslash \mathcal {O}$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathcal {U}_T\backslash \mathcal {H}_T$</span>     </span> respectively. In order to compute the best candidate for <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span>, we need to minimize a suitable function <span class="inline-equation"><span class="tex">$\Omega (\mathcal {H}_T,\mathcal {O})$</span>     </span> which is some measure of <span class="inline-equation"><span class="tex">$\mathbb {\Sigma }(\mathcal {H}_T,\mathcal {O})$</span>     </span>. Now, we define, <div class="table-responsive" id="eq13">     <div class="display-equation">      <span class="tex mytex">\begin{align} &#x0026;\Omega (\mathcal {H}_T,\mathcal {O}):=\mathop {\mathrm{tr}}\left[\log \mathbb {\Sigma }(\mathcal {H}_T,\mathcal {O})\right], \end{align} </span>      <br/>      <span class="equation-number">(14)</span>     </div>     </div> where <span class="inline-equation"><span class="tex">$\log \mathbb {\Sigma }$</span>     </span> is the matrix logarithm of <span class="inline-equation"><span class="tex">$\mathbb {\Sigma }$</span>     </span>. We observe that, <span class="inline-equation"><span class="tex">$\mathop {\mathrm{tr}}\left[\log \mathbb {\Sigma }(\mathcal {H}_T,\mathcal {O})\right]= \log \left[ \mbox{det}(\mathbb {\Sigma }(\mathcal {H}_T,\mathcal {O})) \right]$</span>     </span>. Therefore <span class="inline-equation"><span class="tex">$\Omega (\mathcal {H}_T,\mathcal {O})$</span>     </span> can also be viewed as a complexity measure of <span class="inline-equation"><span class="tex">$\mathbb {\Sigma }(\mathcal {H}_T,\mathcal {O})$</span>     </span>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>], that makes it a good candidate for minimizing <span class="inline-equation"><span class="tex">$\mathbb {\Sigma }$</span>     </span>. In fact, minimizing <span class="inline-equation"><span class="tex">$\Omega (\mathcal {H}_T,\mathcal {O})$</span>     </span> is equivalent to minimizing the sum of logarithms of eigenvalues of <span class="inline-equation"><span class="tex">$\mathbb {\Sigma }$</span>     </span>, which would effectively make <span class="inline-equation"><span class="tex">$\mathbb {\Sigma }(\mathcal {H}_T,\mathcal {O})$</span>     </span> as small as possible. Hence, by defining <span class="inline-equation"><span class="tex">$ f(\mathcal {H}_T,\mathcal {O}):=-\Omega (\mathcal {H}_T,\mathcal {O})$</span>     </span>, we pose the following optimization problem to obtain the best cardinality constrained candidate sets <span class="inline-equation"><span class="tex">$\mathcal {H}_T,\ \text{and } \mathcal {O}$</span>     </span>: <div class="table-responsive" id="eq14">     <div class="display-equation">      <span class="tex mytex">\begin{align} &#x0026; \underset{\mathcal {O}\in \mathcal {V},\ \mathcal {H}_T \in \mathcal {U}_T}{\text{maximize}}f(\mathcal {H}_T,\mathcal {O})\nonumber \\ &#x0026; \text{subject to, } |\mathcal {O}|=N_\mathcal {O}, \ |\mathcal {H}_T|=N_\mathcal {H}\end{align} </span>      <br/>      <span class="equation-number">(15)</span>     </div>     </div>    </p>    <p>We will rely on a greedy heuristic for maximizing <em>f</em> (Algorithm&#x00A0;1), that, we would show later, gives an (1 &#x2212; 1/<em>e</em>) approximation bound. Before going to that, we first specify two properties defined for any multidimensional set function <em>h</em>(<em>X</em>     <sub>1</sub>, <em>X</em>     <sub>2</sub>) in general (Definition&#x00A0;<a class="enc" href="#enc3">3</a>) . We would show that, <em>f</em> specifically enjoys these properties, thereby affording an approximation guarantee from the proposed simple greedy algorithm.</p>    <p>     <div class="definition" id="enc3">     <Label>Definition 4.2.</Label>     <p> A multidimensional set function <em>h</em>(<em>X</em>      <sub>1</sub>, <em>X</em>      <sub>2</sub>) in two set arguments <em>X</em>      <sub>1</sub>&#x2286;<em>U</em>      <sub>1</sub> and <em>X</em>      <sub>2</sub>&#x2286;<em>U</em>      <sub>2</sub>, with <em>U</em>      <sub>1</sub>&#x2229;<em>U</em>      <sub>2</sub> = &#x2205;, is said to be (i) <strong>Conditionally submodular (monotone)</strong>, if <em>h</em> is submodular (monotone) in <em>X</em>      <sub>1</sub>, while keeping <em>X</em>      <sub>2</sub> fixed and vice versa; (ii) <strong>Jointly submodular</strong>, if for any two sets <span class="inline-equation"><span class="tex">$X_1\subseteq \overline{X}_1$</span>      </span> and <span class="inline-equation"><span class="tex">$X_2\subseteq \overline{X}_2$</span>      </span>, <span class="inline-equation"><span class="tex">$x\not\in \overline{X}_1$</span>      </span> and <span class="inline-equation"><span class="tex">$y\not\in \overline{X}_2$</span>      </span>, then <span class="inline-equation"><span class="tex">$h(X_1\cup x,X_2\cup y)-h(X_1,X_2)\ge h(\overline{X}_1\cup x,\overline{X}_2\cup y)-h(\overline{X}_1,\overline{X}_2)$</span>      </span>, and jointly monotone, if <em>h</em>(<em>X</em>      <sub>1</sub>&#x222A;<em>x</em>, <em>X</em>      <sub>2</sub>&#x222A;<em>y</em>) &#x2265; <em>h</em>(<em>X</em>      <sub>1</sub>, <em>X</em>      <sub>2</sub>).</p>     </div>    </p>    <p>Note that, the joint submodularity of <em>h</em>(<em>X</em>     <sub>1</sub>, <em>X</em>     <sub>2</sub>) is different from the traditional bisubmodular property which is often encountered in the submodular optimization literature&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0051">51</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0056">56</a>]. While a bisubmodular function <em>h</em>(<em>X</em>     <sub>1</sub>, <em>X</em>     <sub>2</sub>) is defined over two <em>similar type</em> of subsets <em>X</em>     <sub>1</sub> and <em>X</em>     <sub>2</sub> of same universal set <em>U</em> (<em>i.e. X</em>     <sub>1</sub>, <em>X</em>     <sub>2</sub>&#x2286;<em>U</em>), the input sets <em>X</em>     <sub>1</sub> and <em>X</em>     <sub>2</sub> in Definition&#x00A0;<a class="enc" href="#enc3">3</a> are very different subsets selected from two separate universal sets <em>U</em>     <sub>1</sub> and <em>U</em>     <sub>2</sub>. Indeed, in our context too, the set arguments <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span> for <em>f</em> of our proposal are drastically different subsets with two unalike universal sets <span class="inline-equation"><span class="tex">$(\mathcal {U}_T\text{ and }\mathcal {V})$</span>     </span>. Consequently, the existing techniques of bisubmodular optimization cannot be applied to solve&#x00A0;(<a class="eqn" href="#eq14">15</a>).</p>    <p>     <div class="theorem" id="enc4">     <Label>Theorem 4.3 (Characterizing f).</Label>     <p> (i) <span class="inline-equation"><span class="tex">$f(\mathcal {H}_T,\mathcal {O})$</span>      </span> is <strong>conditionally submodular and monotone</strong> in each of <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>      </span> and <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>      </span>. (ii) If <span class="inline-equation"><span class="tex">$\mathcal {V}(\mathcal {H}_T)$</span>      </span>      <span class="inline-equation"><span class="tex">$\subseteq \mathcal {O}$</span>      </span>, where <span class="inline-equation"><span class="tex">$\mathcal {V}(\mathcal {H}_T)$</span>      </span> is the set of users of the message set <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>      </span>, then <span class="inline-equation"><span class="tex">$f(\mathcal {H}_T,\mathcal {O})$</span>      </span> is <strong>jointly submodular and monotone</strong> in both <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>      </span> and <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>      </span>.</p>     </div>    </p>    <p>     <font style="font-variant: small-caps">Proof Idea:</font> The key to the proof of (i) relies on mapping the given set-function <em>f</em> to suitably chosen continuous functions <em>g</em>     <sub>1</sub>(<em>p</em>) and <em>g</em>     <sub>2</sub>(<em>p</em>), so that, <em>g</em>     <sub>1</sub>(1) > <em>g</em>     <sub>1</sub>(0) and <em>g</em>     <sub>2</sub>(1) < <em>g</em>     <sub>2</sub>(0) imply the conditional monotonicity and submodularity of <em>f</em> respectively. The rest of the proof of (i) focuses to show that <span class="inline-equation"><span class="tex">$\frac{d}{dp}g_1(p){\gt}0$</span>     </span> and <span class="inline-equation"><span class="tex">$\frac{d}{dp}g_2(p){\lt}0$</span>     </span> which ensures <em>g</em>     <sub>1</sub>(1) > <em>g</em>     <sub>1</sub>(0) and <em>g</em>     <sub>2</sub>(0) > <em>g</em>     <sub>2</sub>(1). Such a method is adopted in networked-controllability analysis&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0052">52</a>], that is generalized here for more complex networked dynamical systems. The proof of part (ii) follows directly from part (i) of the theorem. A detailed proof is provided in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>].</p>    <p>Note that, Part (ii) of the above theorem operates on an implicit assumption that, <span class="inline-equation"><span class="tex">$\mathcal {V}(\mathcal {H}_T)\subseteq \mathcal {O}$</span>     </span>; in words, the users of message set <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> belong to <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span>. Otherwise, if we suppose <span class="inline-equation"><span class="tex">$v\in \mathcal {V}(\mathcal {H}_T)$</span>     </span> but <span class="inline-equation"><span class="tex">$v\not\in \mathcal {O}$</span>     </span>, then the events posted by user <em>v</em>, <em>i.e.</em> the vectors <span class="inline-equation"><span class="tex">$ {\phi }^v _i$</span>     </span> are not contributing to <span class="inline-equation"><span class="tex">$f(\mathcal {H}_T,\mathcal {O})$</span>     </span>. Therefore <span class="inline-equation"><span class="tex">$f(\mathcal {H}_T\backslash \lbrace e_v\rbrace ,\mathcal {O})=f(\mathcal {H}_T,\mathcal {O})$</span>     </span>, where <em>e<sub>v</sub>     </em> is an message posted by user <em>v</em>. So, the assumption specifies a choice for minimal user-set <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span> for <span class="inline-equation"><span class="tex">$f(\mathcal {H}_T,\mathcal {O})$</span>     </span>, and hence is not restrictive.</p>    <p>     <strong>Maximization of </strong>     <span class="inline-equation"><span class="tex">$f(\mathcal {H}_T,\mathcal {O})$</span>     </span>     <strong>:</strong> Since <em>f</em> is jointly submodular in <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span>, its maximization requires further modification of the traditional greedy approach adopted for maximizing submodular function of a single set&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0044">44</a>]. The maximization routine is formally shown in Algorithm&#x00A0;1. At each step, it greedily adds event <em>e</em> to <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> and the user <em>u</em> to <span class="inline-equation"><span class="tex">$\mathcal {O}$</span>     </span> sequentially, by maximizing the marginal gain <span class="inline-equation"><span class="tex">$f(\mathcal {H}_T\cup \lbrace e\rbrace ,\mathcal {O}\cup \lbrace u\rbrace)-f(\mathcal {H}_T,\mathcal {O})$</span>     </span> (step 7, Algorithm&#x00A0;1) , until the total number of users reaches <span class="inline-equation"><span class="tex">$N_\mathcal {O}$</span>     </span> (step 5&#x2013;11). Once <span class="inline-equation"><span class="tex">$|\mathcal {O}|$</span>     </span> hits <span class="inline-equation"><span class="tex">$N_\mathcal {O}$</span>     </span>, it does not add any further user, but keeps choosing events <em>e</em> from <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span>, that maximizes <span class="inline-equation"><span class="tex">$f(\mathcal {H}_T\cup \lbrace e\rbrace ,\mathcal {O})-f(\mathcal {H}_T,\mathcal {O})$</span>     </span> until the <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> reaches <span class="inline-equation"><span class="tex">$N_\mathcal {H}$</span>     </span>. Perhaps surprisingly, the modified greedy algorithm too, achieves a constant (1 &#x2212; 1/<em>e</em>) fraction of maximum of <span class="inline-equation"><span class="tex">$f(\mathcal {H}_T,\mathcal {O})$</span>     </span>.</p>    <p>     <div class="lemma" id="enc5">     <Label>Lemma 4.4 (Solution-quality).</Label>     <p> Algorithm&#x00A0;1 admits an (1 &#x2212; 1/<em>e</em>) approximation bound for <span class="inline-equation"><span class="tex">$f(\mathcal {H}_T,\mathcal {O})$</span>      </span>.</p>     </div>    </p>    <p>The overview of the proof is similar (yet not identical) to that of ordinary submodular function&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>]. The key to the proof is sequentially updating the lower bound of the <em>f</em> obtained in Algorithm&#x00A0;1, using its joint submodularity. Such a lower bound, after a large number of updates, approaches to (1 &#x2212; 1/<em>e</em>). For the sake of brevity, the proof is omitted here, but is given in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>]. The users other than the selected organic ones <span class="inline-equation"><span class="tex">$\mathcal {I}=\mathcal {V}\backslash \mathcal {O}$</span>     </span> are the extrinsic users who would be actuated for steering the opinion of others during opinion control in Section&#x00A0;<a class="sec" href="#sec-10">5</a>.</p>    <p>     <img src="http://deliveryimages.acm.org/10.1145/3190000/3186121/images/www2018-130-img1.jpg" class="img-responsive" alt="" longdesc=""/>    </p>    <p>     <img src="http://deliveryimages.acm.org/10.1145/3190000/3186121/images/www2018-130-img2.jpg" class="img-responsive" alt="" longdesc=""/> The event-set <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> thus obtained would be used next to estimate all the parameters A, &#x03BC;, &#x03B1;, B (See Algorithm&#x00A0;2) by maximizing <span class="inline-equation"><span class="tex">$\mathcal {L}({\alpha }, {\mu }, {A}, {B}|\mathcal {H}_T,\mathcal {O})$</span>     </span> which is same as, <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\[ \sum _{e_i\in \mathcal {H}_T} p(m_{u_i}|x^* _{u_i}(t_i))+\sum _{e_i\in \mathcal {H}_T} \log (\lambda _{u _i}(t_i))-\sum _{u\in \mathcal {O}} \int _0 ^T \lambda ^* _u(s)ds. \] </span>      <br/>     </div>     </div> Since <span class="inline-equation"><span class="tex">$\mathcal {L}$</span>     </span> is concave function, one can maximize this efficiently. We adopt the method given by the authors in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>], which can accurately computes the parameters.</p>   </section>   <section id="sec-10">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Steering opinion dynamics</h2>     </div>    </header>    <p>In this section, we formally state the online opinion shaping problem, and then we tackle it from the perspective of stochastic control of jump SDEs (Eqs.&#x00A0;(<a class="eqn" href="#eq15">16</a>)). First, we modify the endogenous dynamics given by Eq.&#x00A0;(<a class="eqn" href="#eq9">10</a>) from control viewpoint. <div class="table-responsive" id="eq15">     <div class="display-equation">      <span class="tex mytex">\begin{align} d\mathbf {x}^{*}(t) =&#x0026; \omega ({\alpha }- \mathbf {x}^{*}(t)) dt + \mathbf {A}\mathbf {m}(t)\odot d {N}(t) + {C}d {M}^+(t)- {C}d {M}^-(t)\nonumber \\ d {\lambda }^{*}(t) = &#x0026;\nu ({\mu }- {\lambda }^{*}(t)) dt + \mathbf {B} \, d {N}(t)+ \mathbf {D} d {M}(t) \end{align} </span>      <br/>      <span class="equation-number">(16)</span>     </div>     </div> In words, a set of users control the endogenous opinion process x<sup>*</sup>(<em>t</em>), by posting positive (+ 1 opinion) and negative messages (&#x2212; 1 opinion) associated with counting process M<sup>+</sup>(<em>t</em>) and M<sup>&#x2212;</sup>(<em>t</em>). Here C and D are matrices of size <span class="inline-equation"><span class="tex">$|\mathcal {V}|\times |\mathcal {I}|$</span>     </span>. They are submatrices of A and B respectively, induced by the selected control users. That is, <span class="inline-equation"><span class="tex">$ {C}= {A}_{\mathcal {V},\mathcal {I}}$</span>     </span> and <span class="inline-equation"><span class="tex">$ {D}= {B}_{\mathcal {V},\mathcal {I}}$</span>     </span>. Our objective is to find the intensity of &#x03B7;<sup>&#x00B1;</sup>(<em>t</em>) of the control counting processes M<sup>&#x00B1;</sup>(<em>t</em>), that optimally steer the opinions of the users in a desired way. Additionally, we assume that <em>&#x03BE;</em>     <sub>max&#x2009;</sub>(B) < < 1. In reality, we actually found that most datasets satisfy this property, that is the temporal influences take quite small numbers.</p>    <section id="sec-11">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.1</span> The online opinion shaping problem</h3>     </div>     </header>     <p>Given a directed network <span class="inline-equation"><span class="tex">$\mathcal {G}=(\mathcal {V},\mathcal {E})$</span>     </span> and a small set of control users <span class="inline-equation"><span class="tex">$\mathcal {I}$</span>     </span>, we aim to find the optimal control intensity &#x03B7;<sup>&#x00B1;</sup>(<em>t</em>) that minimizes the expected value of a particular loss function <span class="inline-equation"><span class="tex">$\ell ({x}^*(t), {\lambda }^*(t), { {\eta }^\pm }(t))$</span>     </span> of the overall endogenous opinions of the network, and the control rates over a time window (<em>t</em>     <sub>0</sub>, <em>t<sub>f</sub>     </em>], <em>i.e.</em>, <div class="table-responsive" id="eq16">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026;\underset{ {\eta }^\pm (t)}{\text{min}} \ \mathbb {E}\big [\phi ({x}^*(t_f))\big . + \big . \int _{t_0}^{t_f} \ell ({x}^*(t), {\eta }^\pm (t)) \, dt \big ].\end{align} </span>       <br/>       <span class="equation-number">(17)</span>      </div>     </div>     <div class="table-responsive" id="eq17">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026;\text{We define $\ell ({x}^*(t), {\eta }^\pm (t))$ as,}\nonumber \\ &#x0026; \frac{1}{2} ({x}^{*}(t)- {x}^{\text{Track}})^T \, {Q}\, ({ {x}}^*(t)- {x}^{\text{Track}})+\sum _{s\in \lbrace +1,-1\rbrace } { {\eta }}^{sT}(t) \, {S}\, { {\eta }}^s(t)\nonumber \\ {} &#x0026;\text{&#x0026; } \phi ({x}^*(t_f)) = \frac{1}{2} ({x}^{*}(t_f)- {x}^{\text{Track}})^T \, {F}\, ({x}^{*}(t_f)- {x}^{\text{Track}}). \end{align} </span>       <br/>       <span class="equation-number">(18)</span>      </div>     </div> Here x<sup>Track</sup> is the desired opinion-vector to which the controller aims to steer. Furthermore, using penalty term for &#x03B7;<sup>&#x00B1;</sup>(<em>t</em>) in the expression of &#x2113;(x<sup>*</sup>(<em>t</em>), &#x03B7;<sup>&#x00B1;</sup>(<em>t</em>)), we will limit the number of posts we steer. Here Q, F and S are p.s.d matrices with Q<sub>      <em>ij</em>     </sub> &#x2265; 0, F<sub>      <em>ij</em>     </sub> &#x2265; 0 and S<sub>      <em>ij</em>     </sub> &#x2265; 0 for all <em>i</em>, <em>j</em> &#x2208; [<em>n</em>].</p>     <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">Forecasting performance across all the models using five datasets and 2 error metrics for <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|=0.8|\mathcal {U}_T|$</span>       </span> and <em>T<sub>f</sub>       </em> = 4 hrs. The yellow (cyan) cells reflect the best (second best) predictor. Numbers in the brackets denote percentage improvement over the nearest baseline.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">Dataset</th>        <th colspan="6" style="text-align:center;">        <strong>Mean squared error</strong>        <hr/>        </th>        <th colspan="6" style="text-align:center;">        <strong>Failure rate</strong>        <hr/>        </th>       </tr>       <tr>        <th style="text-align:left;"/>        <th style="text-align:left;">        <font style="font-variant: small-caps">CherryPick</font>        </th>        <th style="text-align:center;">SLANT</th>        <th style="text-align:center;">AsLM</th>        <th style="text-align:center;">DeGroot</th>        <th style="text-align:center;">Voter</th>        <th style="text-align:left;">B-Voter</th>        <th style="text-align:center;">        <font style="font-variant: small-caps">CherryPick</font>        </th>        <th style="text-align:center;">SLANT</th>        <th style="text-align:center;">AsLM</th>        <th style="text-align:center;">DeGroot</th>        <th style="text-align:center;">Voter</th>        <th>B-Voter</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:left;">Bollywood</td>        <td style="text-align:left;">0.104 (33.6)</td>        <td style="text-align:center;">0.157</td>        <td style="text-align:center;">0.667</td>        <td style="text-align:center;">0.752</td>        <td style="text-align:center;">0.889</td>        <td style="text-align:left;">0.693</td>        <td style="text-align:center;">0.043 (41.0)</td>        <td style="text-align:center;">0.072</td>        <td style="text-align:center;">0.517</td>        <td style="text-align:center;">0.584</td>        <td style="text-align:center;">0.550</td>        <td>0.584</td>       </tr>       <tr>        <td style="text-align:left;">Series</td>        <td style="text-align:left;">0.110 (48.2)</td>        <td style="text-align:center;">0.213</td>        <td style="text-align:center;">0.611</td>        <td style="text-align:center;">0.634</td>        <td style="text-align:center;">0.836</td>        <td style="text-align:left;">0.642</td>        <td style="text-align:center;">0.097 (23.2)</td>        <td style="text-align:center;">0.125</td>        <td style="text-align:center;">0.481</td>        <td style="text-align:center;">0.509</td>        <td style="text-align:center;">0.527</td>        <td>0.513</td>       </tr>       <tr>        <td style="text-align:left;">Soccer</td>        <td style="text-align:left;">0.090 (31.9)</td>        <td style="text-align:center;">0.132</td>        <td style="text-align:center;">0.543</td>        <td style="text-align:center;">0.588</td>        <td style="text-align:center;">1.201</td>        <td style="text-align:left;">0.702</td>        <td style="text-align:center;">0.028 (53.4)</td>        <td style="text-align:center;">0.061</td>        <td style="text-align:center;">0.427</td>        <td style="text-align:center;">0.449</td>        <td style="text-align:center;">0.452</td>        <td>0.452</td>       </tr>       <tr>        <td style="text-align:left;">Verdict</td>        <td style="text-align:left;">0.060 (33.3)</td>        <td style="text-align:center;">0.090</td>        <td style="text-align:center;">0.598</td>        <td style="text-align:center;">0.685</td>        <td style="text-align:center;">1.000</td>        <td style="text-align:left;">1.081</td>        <td style="text-align:center;">0.057 (22.3)</td>        <td style="text-align:center;">0.073</td>        <td style="text-align:center;">0.452</td>        <td style="text-align:center;">0.477</td>        <td style="text-align:center;">0.465</td>        <td>0.475</td>       </tr>       <tr>        <td style="text-align:left;">Elections</td>        <td style="text-align:left;">0.146 (24.1)</td>        <td style="text-align:center;">0.193</td>        <td style="text-align:center;">0.510</td>        <td style="text-align:center;">0.616</td>        <td style="text-align:center;">1.260</td>        <td style="text-align:left;">0.701</td>        <td style="text-align:center;">0.073 (26.1)</td>        <td style="text-align:center;">0.098</td>        <td style="text-align:center;">0.348</td>        <td style="text-align:center;">0.404</td>        <td style="text-align:center;">0.349</td>        <td>0.366</td>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec-12">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.2</span> Stochastic optimal control (SOC) algorithm</h3>     </div>     </header>     <p>At the very outset, our aim is to compute &#x03B7;<sup>&#x00B1;</sup>(<em>t</em>), by minimizing the loss proposed above (Eq.&#x00A0;(<a class="eqn" href="#eq17">18</a>)). To this aim, we first define an optimal cost-to-go function <em>J</em> and then, using the Bellman&#x0027;s principle of optimality&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>], we derive and finally solve the Hamilton-Jacobi-Bellman (HJB) equation to find the optimal control intensity.</p>     <p>While, solving such an SOC often follows the standard roadmap&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>] adopted here, the challenges across different milestones are quite application specific, and therefore lacks a unified solution proposal. Hence, in the context of our problem, we follow a similar direction, tackle the difficulties at different steps, and finally provides a novel closed form expression of the cost to go <em>J</em> that in turn is used to compute &#x03B7;<sup>&#x00B1;</sup>(<em>t</em>).</p>     <p>The optimal cost-to-go <em>J</em>(x<sup>*</sup>(<em>t</em>), &#x03BB;<sup>*</sup>(<em>t</em>), <em>t</em>) is defined as, <div class="table-responsive" id="eq18">      <div class="display-equation">       <span class="tex mytex">\begin{equation} J({x}^*(t), {\lambda }^*(t),t)= \underset{{ {\eta }^\pm }(t,t_f]}{\text{min}} \mathbb {E}\big [\phi ({x}^*(t_f))\big . + \big . \int _{t}^{t_f} \ell ({x}^*(t), {\eta }^\pm (t)) \, dt \big ] \end{equation} </span>       <br/>       <span class="equation-number">(19)</span>      </div>     </div> which is the minimum of the expected cost value of going from the state (x<sup>*</sup>(<em>t</em>), &#x03BB;<sup>*</sup>(<em>t</em>)) at time <em>t</em> to the final state at time <em>t<sub>f</sub>     </em>,</p>     <p>The value of this cost-to-go function <em>J</em>(x<sup>*</sup>(<em>t</em>), &#x03BB;<sup>*</sup>(<em>t</em>), <em>t</em>) would be used to find the optimal control &#x03B7;<sup>&#x00B1;</sup>(<em>t</em>). Therefore we set about for accurate estimation of <em>J</em>. To this aim, we first find the differential expression <em>dJ</em> using Bellman&#x0027;s principle of optimality&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>].</p>     <div class="theorem" id="enc6">     <Label>Theorem 5.1 (Differential HJB equation).</Label>     <p> &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0028">28</a>] The optimal cost-to-go function defined by Eq.&#x00A0;<a class="eqn" href="#eq18">19</a> satisfies the following differential equation: <div class="table-responsive" id="eq19">       <div class="display-equation">        <span class="tex mytex">\begin{align} \min _{ {\eta }^\pm (t, t+dt]} \big \lbrace \mathbb {E} \left[ dJ({x}^*(t), {\lambda }^*(t),t) \right] + \ell ({x}^*(t), {\eta }^\pm (t))dt \big \rbrace =0. \end{align} </span>        <br/>        <span class="equation-number">(20)</span>       </div>      </div>     </p>     </div>     <p>In order to solve Eq.&#x00A0;(<a class="eqn" href="#eq19">20</a>), we expand the differential <em>dJ</em> by using chain rule, <em>i.e.</em> differentiating w.r.t all the variables x<sup>*</sup>(<em>t</em>), &#x03BB;<sup>*</sup>(<em>t</em>) and <em>t</em>, and take into account of the jump process <em>d</em>N(<em>t</em>) and <em>d</em>M(<em>t</em>). Finally we have:</p>     <div class="lemma" id="enc7">     <Label>Lemma 5.2.</Label>     <p> The HJB equation given by Eq.&#x00A0;<a class="eqn" href="#eq19">20</a> on expanding satisfies the following: <div class="table-responsive">       <div class="display-equation">        <span class="tex mytex">\begin{align*} &#x0026;\min _{ {\eta }^\pm (t,t+dt]} \Big \lbrace \frac{\partial J}{\partial t}-\omega ({x}^*(t)- {\alpha })^T \frac{\partial J}{\partial {x}^*}-\nu ({\lambda }^*(t)- {\beta })^T \frac{\partial J}{\partial {\lambda }^*}\nonumber\end{align*} </span>        <br/>       </div>      </div>      <div class="table-responsive" id="eq20">       <div class="display-equation">        <span class="tex mytex">\begin{align} &#x0026;+\sum _{i \in \mathcal {V}}\lambda ^*_i(t) \mathbb {E}\Delta _{ {A}_i m_i, {B}_i}J+\sum _{i \in \mathbb {I}}\left[ {\eta }^+ _i(t)\Delta _{ {A}_i, {B}_i}J+ {\eta }^- _i(t)\Delta _{- {A}_i, {B}_i}J\right]\nonumber \\ &#x0026;+\ell ({x}^*(t), {\eta }^\pm (t))\Big \rbrace =0 \end{align} </span>        <br/>        <span class="equation-number">(21)</span>       </div>      </div> where <em>&#x0394;</em>      <sub>a, b</sub>      <em>J</em> is given by <em>&#x0394;</em>      <sub>a, b</sub>      <em>J</em> = <em>J</em>(x<sup>*</sup>(<em>t</em>) + a, &#x03BB;<sup>*</sup>(<em>t</em>) + b, <em>t</em>) &#x2212; <em>J</em>(x<sup>*</sup>(<em>t</em>), &#x03BB;<sup>*</sup>(<em>t</em>), <em>t</em>) and the expectation is taken over the noise induced due to sampling of <em>m<sub>i</sub>      </em> from <span class="inline-equation"><span class="tex">$x^* _i(t)$</span>      </span>(Proved in &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0001">1</a>]).</p>     </div>     <p>If we minimize over &#x03B7;<sup>&#x00B1;</sup> on the LHS of the HJB equation in Eq.&#x00A0;<a class="eqn" href="#eq20">21</a>, we have &#x03B7;<sup>&#x00B1;</sup> = &#x2212;S<sup>&#x2212; 1</sup>     <em>&#x0394;</em>     <sub>&#x00B1; A, B</sub>     <em>J</em>. Here <em>&#x0394;</em>     <sub>&#x00B1; A, B</sub> is a vector whose <em>i</em>     <sup>th</sup> element is <span class="inline-equation"><span class="tex">$\Delta _{\pm {A}_i, {B}_i}$</span>     </span> which is defined in the context of Lemma&#x00A0;<a class="enc" href="#enc7">7</a>. Substituting these optimal values of &#x03B7;<sup>&#x00B1;</sup> in the Eq.&#x00A0;<a class="eqn" href="#eq20">21</a>, we have: <div class="table-responsive" id="eq21">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026;0=\frac{\partial J}{\partial t}-\omega ({x}^*(t)- {\alpha })^T \frac{\partial J}{\partial {x}^*}-\nu ({\lambda }^*(t)- {\beta })^T \frac{\partial J}{\partial {\lambda }^*}\nonumber \\ &#x0026;+\sum _{i \in \mathcal {V}}\lambda ^* _i(t) \mathbb {E}\Delta _{ {A}_i m_i, {B}_i}J- \frac{1}{2}\sum _{s\in {\pm }} \Delta _{s {A}, {B}}J^T { {S}}^{-1}\Delta _{s {A}, {B}}J\nonumber \\ &#x0026;+\frac{1}{2} ({x}^{*}(t)- {x}^{\text{Track}})^T \, {Q}\, ({ {x}}^*(t)- {x}^{\text{Track}}) \end{align} </span>       <br/>       <span class="equation-number">(22)</span>      </div>     </div> with <em>J</em>(x<sup>*</sup>(<em>t<sub>f</sub>     </em>), &#x03BB;<sup>*</sup>(<em>t<sub>f</sub>     </em>), <em>t<sub>f</sub>     </em>) = <em>&#x03D5;</em>(x<sup>*</sup>(<em>t<sub>f</sub>     </em>)) as the terminal condition. Finally we reach the optimal solution of <em>J</em>(x<sup>*</sup>(<em>t</em>), &#x03BB;<sup>*</sup>(<em>t</em>), <em>t</em>) which is given by the following:</p>     <div class="lemma" id="enc8">     <Label>Lemma 5.3.</Label>     <p> The solution of the nonlinear differential equation given by Eq.&#x00A0;<a class="eqn" href="#eq21">22</a> in the space of all polynomials, is the following quadratic form (Proved in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0001">1</a>]): <div class="table-responsive" id="eq22">       <div class="display-equation">        <span class="tex mytex">\begin{align} &#x0026;J({x}^*(t), {\lambda }^*(t),t)= h(t) + {g}(t)^T {\lambda }^*(t) + {f}^T(t) {x}^*(t)\\&#x0026;+ {\lambda }^{*T}(t) {V}(t) {x}^*(t)+\frac{1}{2} {\lambda }^{*T}(t) {K}(t) {\lambda }^*(t)+\frac{1}{2} {x}^{*T}(t) {H}(t) {x}^*(t) \nonumber\end{align} </span>        <br/>        <span class="equation-number">(23)</span>       </div>      </div> where the coefficient-tuple &#x03A0;(<em>t</em>) = (h, g, f, V, K, H)(<em>t</em>) can be found by solving a set of six differential equations. For brevity the exact form of differential equations is given in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0001">1</a>]. <div class="table-responsive" id="eq23">       <div class="display-equation">        <span class="tex mytex">\begin{align} &#x0026;\dot{ {\Pi }}(t)=\mathbf {{Riccati}}({\Pi }(t)) \end{align} </span>        <br/>        <span class="equation-number">(24)</span>       </div>      </div>     </p>     </div>     <p>This matrix Riccati differential equation, can be solved using many well-known efficient numerical solvers&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0024">24</a>]. Finally, given the above <em>J</em>, we compute the optimal intensity as, <div class="table-responsive" id="eq24">      <div class="display-equation">       <span class="tex mytex">\begin{align} {\eta }^\pm =- {S}^{-1}\Delta _{\pm {A}, {B}}J \end{align} </span>       <br/>       <span class="equation-number">(25)</span>      </div>     </div> which was derived using the differential HJB equation.</p>     <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Real datasets statistics.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">        <strong>Dataset</strong>        </th>        <th style="text-align:center;">        <span class="inline-equation"><span class="tex">$\mathbf {|\mathcal {V}|}$</span>        </span>        </th>        <th style="text-align:center;">        <span class="inline-equation"><span class="tex">$\mathbf {|\mathcal {E}|}$</span>        </span>        </th>        <th style="text-align:center;">        <span class="inline-equation"><span class="tex">$|\mathcal {U}(T)|$</span>        </span>        </th>        <th style="text-align:center;">        <span class="inline-equation"><span class="tex">$\mathbf {\mathbb {E}[m]}$</span>        </span>        </th>        <th>std[<em>m</em>]</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:left;">Bollywood</td>        <td style="text-align:center;">1031</td>        <td style="text-align:center;">34952</td>        <td style="text-align:center;">46845</td>        <td style="text-align:center;">0.5101</td>        <td>0.2310</td>       </tr>       <tr>        <td style="text-align:left;">Series</td>        <td style="text-align:center;">947</td>        <td style="text-align:center;">10253</td>        <td style="text-align:center;">13203</td>        <td style="text-align:center;">-0.0216</td>        <td>0.3177</td>       </tr>       <tr>        <td style="text-align:left;">Soccer</td>        <td style="text-align:center;">703</td>        <td style="text-align:center;">4154</td>        <td style="text-align:center;">8319</td>        <td style="text-align:center;">0.1779</td>        <td>0.1521</td>       </tr>       <tr>        <td style="text-align:left;">Verdict</td>        <td style="text-align:center;">1059</td>        <td style="text-align:center;">17452</td>        <td style="text-align:center;">9950</td>        <td style="text-align:center;">0.5170</td>        <td>0.1870</td>       </tr>       <tr>        <td style="text-align:left;">Elections</td>        <td style="text-align:center;">533</td>        <td style="text-align:center;">20067</td>        <td style="text-align:center;">18704</td>        <td style="text-align:center;">-0.0186</td>        <td>0.7135</td>       </tr>      </tbody>     </table>     </div>    </section>   </section>   <section id="sec-13">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Experiments</h2>     </div>    </header>    <p>We provide a comprehensive evaluation of <font style="font-variant: small-caps">CherryPick</font> from both modeling and shaping viewpoints, across the following real datasets (also summarized in Table&#x00A0;<a class="tbl" href="#tab2">2</a>) corresponding to various real-world events, collected from Twitter.</p>    <p>1. <strong>Bollywood:</strong> Verdict that declared guilty to Salman Khan (a popular Bollywood movie star) for causing death of a person by rash and negligible driving, from May 5 to May 16, 2015.</p>    <p>2. <strong>Series:</strong> The promotion on the TV show &#x201C;Games of Thrones&#x201D;, from May 4 to May 12, 2015.</p>    <p>3. <strong>Soccer:</strong> Champions League final in 2015, between Juventus and Real Madrid, from May 8 to May 16, 2015.</p>    <p>4. <strong>Verdict:</strong> Verdict for the corruption-case against Jayalalitha, an Indian politician, from May 6 to May 17, 2015..</p>    <p>5. <strong>Elections:</strong> Presidential election in the United-States, from April 7 to 13, 2016.</p>    <p>For all datasets, we follow a very standard setup for both network construction and message sentiment computation&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0055">55</a>]. We built the follower-followee network for the users that posted related tweets using the Twitter rest API<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a>. Then, we filtered out users that posted less than 200 tweets during the account lifetime, follow less than 100 users, or have less than 50 followers. For each dataset, we compute the sentiment values of the messages using a popular sentiment analysis toolbox&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>]. Here, the sentiment takes values <em>m</em> &#x2208; [ &#x2212; 1, 1] and we consider the sentiment polarity to be simply sign(<em>m</em>). Note that, while other sentiment analysis tools&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0047">47</a>] can be used to extract sentiments from tweets, we appeal to&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>] due to two major reasons&#x2013; its ability of accurately extracting sentiments from short informal texts like tweets, and its wide usage in validating data-driven opinion models&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>].</p>    <section id="sec-14">     <header>     <div class="title-info">      <h3>       <span class="section-number">6.1</span> Effect of <font style="font-variant: small-caps">CherryPick</font> on opinion modeling</h3>     </div>     </header>     <p>We evaluate the efficacy of demarcation of endogenous and exogenous messages, by measuring the predictive prowess of the associated opinion model given by Eq.&#x00A0;(<a class="eqn" href="#eq3">4</a>), in comparison with five state-of-the-art opinion models, e.g. SLANT&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>], the asynchronous linear model (AsLM)&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0010">10</a>], DeGroot&#x0027;s model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>], the Voter model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0058">58</a>] and the Biased Voter model&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>].</p>     <p>     <strong>Evaluation protocol and metrics:</strong> Given a temporal stream of sentiment messages <span class="inline-equation"><span class="tex">$\mathcal {U}$</span>     </span>, we first split it into training and test set, where training set consists of first 90% of the total number of messages. We first demarcate these messages <span class="inline-equation"><span class="tex">$\mathcal {U}_T$</span>     </span>, say collected until time <em>T</em>, into endogenous <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span> and exogenous messages <span class="inline-equation"><span class="tex">$\mathcal {C}_T$</span>     </span>, and then estimate the parameters over the classified <span class="inline-equation"><span class="tex">$\mathcal {H}_T$</span>     </span>. During categorization, we took a range of values of pre-specified value of <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|$</span>     </span>      <span class="inline-equation"><span class="tex">$(N_\mathcal {H})$</span>     </span>, the pre-specified number of organic messages. However, we assumed <span class="inline-equation"><span class="tex">$\mathcal {O}=\mathcal {V}$</span>     </span> to extract the endogenous dynamics from all users (See Eq.&#x00A0;(<a class="eqn" href="#eq14">15</a>)). Note here we only assess the benefits of message classification proposal; the efficacy of user classification is discussed in the following subsection (Sec.&#x00A0;<a class="sec" href="#sec-15">6.2</a>). Finally, using this estimated model, we forecast the sentiment value <em>m</em> for each message in the test set given the history up to <em>T<sub>f</sub>     </em> hours before the time of the message as <span class="inline-equation"><span class="tex">$\hat{m} = E_{\mathcal {H}_T \backslash \mathcal {H}_{t-T_f}}[x^*_u(t) | \mathcal {H}_{t-T_f}]$</span>     </span> that we compute using an efficient simulation method given by&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>]. For predicting opinions using discrete models e.g. AsLM, DeGroot, Voter, and Biased Voter, which operate in discrete time, we run <span class="inline-equation"><span class="tex">$N_{T_f}$</span>     </span> rounds of simulation in (<em>t</em> &#x2212; <em>T<sub>f</sub>     </em>, <em>t</em>), where <span class="inline-equation"><span class="tex">$N_{T_f}$</span>     </span> is the number of posts during this interval. We measure the performance of our model along with the baselines, in terms of: (i) the <em>Mean squared error (MSE)</em> between the actual and the estimated sentiment value, <em>i.e.</em>, <span class="inline-equation"><span class="tex">$\mathbb {E}[(m-\hat{m})^2]$</span>     </span>, and (ii) the <em>Failure rate (FR)</em> which is the polarity prediction error, <em>i.e.</em>, <span class="inline-equation"><span class="tex">$\mathbb {E}[\mathbb {1}_{\mathop {\mathrm{sign}}(m) \ne \mathop {\mathrm{sign}}(\hat{m}})]$</span>     </span>.</p>     <p>     <strong>Comparison with baselines:</strong> Table&#x00A0;<a class="tbl" href="#tab1">1</a> dissects a comparative sketch of the prediction error of five state-of-the-art methods and our proposal for <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|={0.8|\mathcal {U}_T|}$</span>     </span>, and <em>T<sub>f</sub>     </em> = 4 hours. The left half of the table reports Mean square error, while the rest reports Failure rate. We observe that, <font style="font-variant: small-caps">CherryPick</font> offers a significant performance boost in comparison to all its competitors, including SLANT, an immediate counterpart of our proposal, which however, does not model exogenous signals.</p>     <p>     <em>Voter model and its variants&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0058">58</a>]:</em> The performance of Voter model and Biased Voter model are quite poor. Voter model allows a user to form her opinion, by randomly selecting opinion from one of her neighbors. Such an update strategy keeps the set of opinions invariant throughout the diffusion process. Hence, it operates in closed social network, as opposed to the reality where social networks are open system allowing signals to flow in and out. Biased Voter model aims to overcome some limitations of Voter model by introducing node weights. However it also ignores the effect of externalities, and it fares poorly than most other baselines.</p>     <p>     <em>Linear models&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0015">15</a>]:</em> The performance of linear models (AsLM and DeGroot) are better than the Voter models. These models attempt to capture the endogenous opinion dynamics via the edge-weights. However, they ignore the effect of posting time of messages on opinion diffusion, which constrains their predictive power.</p>     <p>     <em>SLANT&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0014">14</a>]:</em> Among all the baselines, we observe that SLANT is the best predictor. As opposed to the other models which do not consider the role of temporal dynamics, SLANT incorporates the influence of past messages on the opinion diffusion process. Furthermore, using the constant term &#x03B1;, it often aims to capture the overall effect of external signals, but succeeds only partially. Since it assumes all the collected messages are endogenous, it fails to probe the exogenous signals at individual user and message level, leaving a substantial space for improvement.</p>     <p>     <font style="font-variant: small-caps">CherryPick</font>     <em>:</em>      <font style="font-variant: small-caps">CherryPick</font> accurately captures the effect of temporal dynamics of historical data, as well as incorporates the effect of exogenous signals at the message and user level. Its principled demarcation paradigm aids to identify the endogenous messages. In contrast to SLANT and other competitors, the exogenous messages are no more modeled endogenously in this case. Using such a refined set of training data, the parameters are inferred more accurately, and as a result the estimated model precisely brings out the complex opinion dynamics, thereby showing a substantial performance boost in comparison to its competitors. In fact, due to the dropped-out exogenous messages, <font style="font-variant: small-caps">CherryPick</font> effectively uses a smaller amount of training data than its competitors, and yet outperforms them in terms of forecasting ability. This is because, the final training set used in parameter estimation is less noisy, and contains only the endogenous signals, thereby aiding in a better inference.</p>     <div class="table-responsive" id="tab3">     <div class="table-caption">      <span class="table-number">Table 3:</span>      <span class="table-title">Anecdotal examples for accurate message demarcation using <font style="font-variant: small-caps">CherryPick</font> on Elections dataset. Time in bracket indicates the posting time.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:left;">Class</th>        <th>Example tweets</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:left;">Exogenous (18:08:51)</td>        <td>#BREAKING: Donald Trump campaign manager will not be prosecuted. A total joke. : <em>M</em>        <sub>1</sub>        </td>       </tr>       <tr>        <td style="text-align:left;">Endogenous (18:18:17)</td>        <td>Sad! Donald Trump, quit your whining.: <em>M</em>        <sub>2</sub>        </td>       </tr>       <tr>        <td style="text-align:left;">Endogenous (18:32:09)</td>        <td>Trump is snake oil businessman.: <em>M</em>        <sub>3</sub>        </td>       </tr>       <tr>        <td style="text-align:left;">Endogenous (18:44:20)</td>        <td>Yes, Confirmed! Trump campaign manager won&#x0027;t be Prosecuted. Such a huge disaster. : <em>M</em>        <sub>4</sub>        </td>       </tr>       <tr>        <td style="text-align:left;">Exogenous (18:59:36)</td>        <td>Trump shows farsightedness by shaking hands with Russia. Liberals will never understand.: <em>M</em>        <sub>5</sub>        </td>       </tr>      </tbody>     </table>     </div>     <figure id="fig1">     <img src="http://deliveryimages.acm.org/10.1145/3190000/3186121/images/www2018-130-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Performance change with <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|$</span>       </span> for Verdict dataset.</span>     </div>     </figure>     <p>     <strong>Performance variation with</strong>      <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|$</span>     </span>: Figure&#x00A0;<a class="fig" href="#fig1">1</a> describes the variation of forecasting performance for different values of <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|$</span>     </span>, across two representative datasets. We observe that, upon increasing <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|$</span>     </span>, the prediction error first decreases and then increases, strongly indicating an optimum number of endogenous messages in the temporal data. A small value of <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|$</span>     </span>, overestimates the effect of exogenous signal, while a large value of <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|$</span>     </span> ignores its effect. A well-calibrated value for <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|$</span>     </span> optimally selects an appropriate set of messages, which helps in accurate opinion forecasting. Furthermore, we observe this optimal value of <span class="inline-equation"><span class="tex">$|\mathcal {H}_T|$</span>     </span> remains almost consistent throughout a moderate variation of <em>T<sub>f</sub>     </em>, which reflects a substantial robustness of our proposal.</p>     <p>     <strong>Illustration with examples.</strong> Table&#x00A0;<a class="tbl" href="#tab3">3</a> shows a few example messages from a conversation around US election (Elections dataset), that <font style="font-variant: small-caps">CherryPick</font> has successfully categorized. The conversation largely reflects negative or anti-trump sentiments (<em>M</em>     <sub>1</sub> to <em>M</em>     <sub>4</sub>). We observe that, <em>M</em>     <sub>1</sub> which is triggered by externalities, subsequently influences the generation of endogenous messages <em>M</em>     <sub>2</sub> to <em>M</em>     <sub>4</sub>. Note that, despite having a strong content similarity with <em>M</em>     <sub>1</sub>, <em>M</em>     <sub>4</sub> is not exogenous, since it is generated from the process of opinion formation internal to the system. Finally, we notice that <em>M</em>     <sub>5</sub> contains a positive opinion, and the node positing it seems not to be influenced by posts around its neighborhood rather has imported a new tweet (opinion) from &#x2018;outside&#x2019;. <font style="font-variant: small-caps">CherryPick</font> correctly spots it and labels as exogenous.</p>    </section>    <section id="sec-15">     <header>     <div class="title-info">      <h3>       <span class="section-number">6.2</span> Effect of <font style="font-variant: small-caps">CherryPick</font> on opinion shaping</h3>     </div>     </header>     <p>The performance of our proposed opinion control policy depends on two factors: (i) the prudence shown by <font style="font-variant: small-caps">CherryPick</font> in selecting control users <span class="inline-equation"><span class="tex">$\mathcal {I}$</span>     </span>, and (ii) the efficiency of the online opinion shaping framework (Sec&#x00A0;<a class="sec" href="#sec-10">5</a>) &#x2013; both of them are evaluated in this section. Since, we observe that most (> 90%) of the users in all the datasets have positive initial opinions (<em>&#x03B1;<sub>u</sub>     </em> > 0), choosing a loss function to steer opinion of each user to an extreme negative opinion, should appropriately test the shaping performance, and therefore, we set, x<sup>Track</sup> = &#x2212;1 (Eq.&#x00A0;(<a class="eqn" href="#eq17">18</a>)). To minimize the corresponding loss function, at each timestamp, the shaping algorithm supplies suitable pairs of the exogenous intensities &#x03B7;<sup>&#x00B1;</sup>(<em>t</em>) of the control users, which in turn regulate the number of control messages (M<sup>&#x00B1;</sup>(<em>t</em>)) , for guiding the opinion dynamics to reach the desired state. In this context, we define <span class="inline-equation"><span class="tex">$\overline{ {M}}^\pm (t_f)=\sum _{u\in \mathcal {V}} M^\pm _u(t_f)$</span>     </span> and <span class="inline-equation"><span class="tex">$\overline{ {M}}(t_f)=\overline{ {M}}^+(t_f)+\overline{ {M}}^-(t_f)$</span>     </span>.</p>     <p>     <strong>Baseline setup:</strong> We compare our proposal with KL-MPC proposed by Wang <em>et al.</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0055">55</a>], and three centrality based measures - PageRank, Degree and Closeness. The operational principle of the proposed strategy relies on accurate supervision of the number of exogenous posts for both positive and negative opinions. A fair competition between the shaping proposals would, therefore, require a uniformity in the total number of control messages <span class="inline-equation"><span class="tex">$\overline{ {M}}(t_f)$</span>     </span> across all the baselines. To this aim, we tune the parameters of KL-MPC, so that the corresponding number of control messages approximately matches with the value of <span class="inline-equation"><span class="tex">$\overline{ {M}}(t_f)$</span>     </span> obtained using our proposal. Furthermore, to understand the efficacy of the online algorithm, we used the same set of extrinsic users <span class="inline-equation"><span class="tex">$\mathcal {I}$</span>     </span> as control users in KL-MPC. The centrality based measures, on the other hand, distributes the intensities &#x03B7;<sup>&#x00B1;</sup>(<em>t</em>) proportionally with the users&#x2019; centrality scores in the network, thereby triggering same number of control messages across time.</p>     <p>     <strong>Metrics:</strong> We compare the performance using two measures: (i) <strong>loss</strong>(<em>t</em>) &#x2254; ||x<sup>*</sup>(<em>t</em>) &#x2212; x<sup>Track</sup>||<sup>2</sup>, <em>i.e.</em> the tracking error indicating how far is the current opinion from the target vector, and (ii) <em>latency</em>, denoted as <em>t</em>     <sub>&#x2212; 0.9</sub>, <em>i.e.</em> the time at which the mean opinion reaches &#x2212; 0.9 (<em>i.e.</em> 90% of target x<sup>Track</sup>). and (iii) <span class="inline-equation"><span class="tex">$ {\Delta }(t_f):=\int _0 ^{t_f}{\bf loss}(s)ds$</span>     </span>, area under the error curve. <figure id="fig2">      <img src="http://deliveryimages.acm.org/10.1145/3190000/3186121/images/www2018-130-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Temporal variation of opinion shaping performance for all the baselines, in terms of <strong>loss</strong>(<em>t</em>), with <span class="inline-equation"><span class="tex">$|\mathcal {O}|=0.8|\mathcal {V}|$</span>        </span> (<em>i.e.</em>        <span class="inline-equation"><span class="tex">$|\mathcal {I}|=0.2|\mathcal {V}|$</span>        </span>) and <span class="inline-equation"><span class="tex">$\overline{ {M}}(t_f)$</span>        </span> &#x2248; 200<em>K</em>, across two representative datasets.</span>      </div>     </figure>      <strong>Comparison with baselines.</strong>     </p>     <p>     <strong>Loss(<em>t</em>):</strong> Figure&#x00A0;<a class="fig" href="#fig2">2</a> gives a comparative analysis of our proposal with the other baselines in terms of <strong>loss</strong>(<em>t</em>), across two representative datasets. We observe that our method consistently outperforms the baselines. We also observe that the centrality based measures fare quite poorly. They assign the control power to the users heuristically and linearly, which renders them ineffective in opinion shaping. To some extent, the poor performance of these measures reveals that the structural properties alone are not very effective measures of influence in the context of opinion dynamics. The performance of KL-MPC is better than the centrality based measures. It is more principled, but gives an open loop and approximate solution. Hence, even after supplying it with high-quality control users (through <font style="font-variant: small-caps">CherryPick</font>, which the original proposal does not), it performs poorly than the closed-loop online control. Our proposal unifies the user classification, and an optimally designed, closed loop online shaping algorithm in a principled way. <font style="font-variant: small-caps">CherryPick</font> not only helps it to bring out the extrinsic users, but also offers a soft measure of influence in the context of opinion dynamics - thus emphatically establishing the superiority of our algorithm. <figure id="fig3">      <img src="http://deliveryimages.acm.org/10.1145/3190000/3186121/images/www2018-130-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 3:</span>       <span class="figure-title">Variation of latency i.e. the average time <span class="inline-equation"><span class="tex">$\bar{t}_{-0.9}$</span>        </span> required to reach a milestone opinion &#x2212; 0.9, against the number of control actions, for Soccer and Elections datasets, given <span class="inline-equation"><span class="tex">$|\mathcal {O}|=0.8|\mathcal {V}|$</span>        </span> (<em>i.e.</em>        <span class="inline-equation"><span class="tex">$|\mathcal {I}|=0.2|\mathcal {V}|$</span>        </span>).</span>      </div>     </figure>     <figure id="fig4">      <img src="http://deliveryimages.acm.org/10.1145/3190000/3186121/images/www2018-130-fig4.jpg" class="img-responsive" alt="Figure 4"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 4:</span>       <span class="figure-title">Variation of &#x0394;(<em>t<sub>f</sub>        </em>) with <span class="inline-equation"><span class="tex">$|\mathbb {I}|$</span>        </span>, for our online shaping method, across Verdict and Soccer datasets.</span>      </div>     </figure>      <strong>Latency:</strong> We next evaluate the performance our algorithm against the baselines, with respect to the total number of control messages. To do that, we compare latency, which is the time <em>t</em>     <sub>&#x2212; 0.9</sub> taken to reach a milestone of opinion &#x2212; 0.9, against <span class="inline-equation"><span class="tex">$\overline{ {M}}(t_f)$</span>     </span>, the number of control actions. Figure&#x00A0;<a class="fig" href="#fig3">3</a> describes the results, which shows that the proposed shaping method consistently reaches the milestone opinion faster than its competitors. Furthermore, our proposal shows a greater benefit at low budgets, i.e. it can efficiently steer the opinion dynamics even with a small number of messages.</p>     <p>     <strong>Performance variation with </strong>     <span class="inline-equation"><span class="tex">$|\mathbb {I}|$</span>     </span>     <strong>.</strong> Figure&#x00A0;<a class="fig" href="#fig4">4</a> summarizes the results for variation of cumulative loss &#x0394;(<em>t<sub>f</sub>     </em>), with the pre-selected user size <span class="inline-equation"><span class="tex">$|\mathbb {I}|$</span>     </span>. We observe that, as the budget increases, the control performance does not vary much with the number of users. From a practical viewpoint, often difficult challenges are associated with high budgets and high latency. In such a shaping problem, a small selected (through <font style="font-variant: small-caps">CherryPick</font>) number of control users can steer opinions of the users as effectively as a larger number of not-so effective control users, thus highlighting the power of <font style="font-variant: small-caps">CherryPick</font>.</p>    </section>   </section>   <section id="sec-16">    <header>     <div class="title-info">     <h2>      <span class="section-number">7</span> Conclusion</h2>     </div>    </header>    <p>The principal contribution of this paper lies in emphatically establishing the dual nature of message flow over online social network: injection of exogenous opinions and influence-based dynamics, internal to the network. The realization helps us to propose <font style="font-variant: small-caps">CherryPick</font>, a novel learning methodology to demarcate endogenous and exogenous opinions, identify organic and extrinsic users, and finally illustrate its utility from both opinion modeling and shaping perspective. To this aim, we formulated the user and message classification problem as a joint submodular optimization task in the set of users and messages, which we solved using an efficient greedy algorithm. Furthermore, in order to demonstrate the efficacy of user selection task, we developed the opinion shaping problem in a novel framework of stochastic optimal control, that outputs the intensities with which the selected users should post bipolar opinions, to steer the opinion dynamics in a favorable manner. Finally, on five datasets crawled from Twitter, we showed that our proposal consistently outperforms the existing algorithms in terms of both predictive and shaping prowess. The superior performance is even more remarkable considering the fact that we train our system on smaller (but relevant) amount of data than all competing models. We believe the framework developed here can be effectively used to understand several related traits observed on OSN like &#x2018;manufactured&#x2019; trending topics, which would be our one of the immediate future endeveours.</p>    <p>     <strong>Acknowledgement:</strong> This work was partially supported by Google India PhD Fellowship for Social Computing, DST project SB/S3/EECE/0249/2014.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">[n. d.]. Supplementary Material. ([n. d.]). <a class="link-inline force-break"      href="http://www.cnergres.iitkgp.ac.in/supp.pdf">http://www.cnergres.iitkgp.ac.in/supp.pdf</a>.</li>     <li id="BibPLXBIB0002" label="[2]">Claudio Altafini and Gabriele Lini. 2015. Predictable dynamics of opinion forming for networks with antagonistic interactions. <em>      <em>IEEE Trans. Automat. Control</em>     </em>60, 2 (2015), 342&#x2013;357.</li>     <li id="BibPLXBIB0003" label="[3]">Aris Anagnostopoulos, Ravi Kumar, and Mohammad Mahdian. 2008. Influence and correlation in social networks. In <em>      <em>KDD</em>     </em>.</li>     <li id="BibPLXBIB0004" label="[4]">Kazutoshi Ando, Satoru Fujishige, and Takeshi Naitoh. 1996. A characterization of bisubmodular functions. <em>      <em>Discrete Mathematics</em>     </em>148, 1-3 (1996), 299&#x2013;303.</li>     <li id="BibPLXBIB0005" label="[5]">D.&#x00A0;P. Bertsekas. 1995. <em>      <em>Dynamic programming and optimal control</em>     </em>. Vol.&#x00A0;1. Athena Scientific Belmont, MA.</li>     <li id="BibPLXBIB0006" label="[6]">Vincent&#x00A0;D Blondel, Julien&#x00A0;M Hendrickx, and John&#x00A0;N Tsitsiklis. 2009. On Krause&#x0027;s multi-agent consensus model with state-dependent connectivity. <em>      <em>IEEE transactions on Automatic Control</em>     </em>54, 11 (2009), 2586&#x2013;2597.</li>     <li id="BibPLXBIB0007" label="[7]">Xavier Castell&#x00F3;, V&#x00ED;ctor&#x00A0;M Egu&#x00ED;luz, and Maxi San&#x00A0;Miguel. 2006. Ordering dynamics with two non-excluding options: bilingualism in language competition. <em>      <em>New Journal of Physics</em>     </em>8, 12 (2006), 308.</li>     <li id="BibPLXBIB0008" label="[8]">P. Clifford and A. Sudbury. 1973. A model for spatial conflict. <em>      <em>Biometrika</em>     </em>60, 3 (1973), 581&#x2013;588.</li>     <li id="BibPLXBIB0009" label="[9]">A. Das, S. Gollapudi, and K. Munagala. 2014. Modeling opinion dynamics in social networks. In <em>      <em>WSDM</em>     </em>.</li>     <li id="BibPLXBIB0010" label="[10]">A. De, S. Bhattacharya, P. Bhattacharya, N. Ganguly, and S. Chakrabarti. 2014. Learning a Linear Influence Model from Transient Opinion Dynamics. In <em>      <em>CIKM</em>     </em>.</li>     <li id="BibPLXBIB0011" label="[11]">Abir De, Sourangshu Bhattacharya, Sourav Sarkar, Niloy Ganguly, and Soumen Chakrabarti. 2016. Discriminative link prediction using local, community, and global signals. <em>      <em>IEEE Transactions on Knowledge and Data Engineering</em>     </em>28, 8(2016), 2057&#x2013;2070.</li>     <li id="BibPLXBIB0012" label="[12]">Abir De, Maunendra&#x00A0;Sankar Desarkar, Niloy Ganguly, and Pabitra Mitra. 2012. Local learning of item dissimilarity using content and link structure. In <em>      <em>ACM RecSys</em>     </em>.</li>     <li id="BibPLXBIB0013" label="[13]">Abir De, Niloy Ganguly, and Soumen Chakrabarti. 2013. Discriminative link prediction using local links, node features and community structure. In <em>      <em>ICDM</em>     </em>.</li>     <li id="BibPLXBIB0014" label="[14]">Abir De, Isabel Valera, Niloy Ganguly, Sourangshu Bhattacharya, and Manuel Gomez&#x00A0;Rodriguez. 2016. Learning and Forecasting Opinion Dynamics in Social Networks. In <em>      <em>NIPS</em>     </em>.</li>     <li id="BibPLXBIB0015" label="[15]">M.&#x00A0;H. DeGroot. 1974. Reaching a consensus. <em>      <em>J. Amer. Statist. Assoc.</em>     </em>69, 345 (1974), 118&#x2013;121.</li>     <li id="BibPLXBIB0016" label="[16]">Jan&#x00A0;Christian Dittmer. 2001. Consensus formation under bounded confidence. <em>      <em>Nonlinear Analysis: Theory, Methods &#x0026; Applications</em>     </em>47, 7(2001), 4615&#x2013;4621.</li>     <li id="BibPLXBIB0017" label="[17]">Igor Douven and Alexander Riegler. 2009. Extending the Hegselmann&#x2013;Krause Model I. <em>      <em>Logic Journal of IGPL</em>     </em>18, 2 (2009), 323&#x2013;335.</li>     <li id="BibPLXBIB0018" label="[18]">Rick Durrett and Simon Levin. 1996. Spatial models for species-area curves. <em>      <em>Journal of Theoretical Biology</em>     </em>179, 2 (1996), 119&#x2013;127.</li>     <li id="BibPLXBIB0019" label="[19]">Seyed&#x00A0;Rasoul Etesami and Tamer Ba&#x015F;ar. 2015. Game-theoretic analysis of the Hegselmann-Krause model for opinion dynamics in finite dimensions. <em>      <em>IEEE Trans. Automat. Control</em>     </em>60, 7 (2015), 1886&#x2013;1897.</li>     <li id="BibPLXBIB0020" label="[20]">M. Farajtabar, Y. Wang, M. Gomez-Rodriguez, S. Li, H. Zha, and L. Song. 2015. COEVOLVE: A Joint Point Process Model for Information Diffusion and Network Co-evolution. In <em>      <em>NIPS</em>     </em>.</li>     <li id="BibPLXBIB0021" label="[21]">Noah&#x00A0;E Friedkin. 2015. The problem of social control and coordination of complex systems in sociology: A look at the community cleavage problem. <em>      <em>IEEE Control Systems</em>     </em>35, 3 (2015), 40&#x2013;51.</li>     <li id="BibPLXBIB0022" label="[22]">Jerome Friedman, Trevor Hastie, and Robert Tibshirani. 2008. Sparse inverse covariance estimation with the graphical lasso. <em>      <em>Biostatistics</em>     </em>9, 3 (2008), 432&#x2013;441.</li>     <li id="BibPLXBIB0023" label="[23]">Satoru Fujishige, Shin-ichi Tanigawa, and Yuichi Yoshida. 2014. Generalized skew bisubmodularity: A characterization and a min&#x2013;max theorem. <em>      <em>Discrete Optimization</em>     </em>12(2014), 1&#x2013;9.</li>     <li id="BibPLXBIB0024" label="[24]">C.&#x00A0;K. Garrett. 2013. <em>Numerical integration of matrix Riccati differential equations with solution singularities</em>. Ph.D. Dissertation. The University of Texas at Arlington.</li>     <li id="BibPLXBIB0025" label="[25]">Przemyslaw&#x00A0;A Grabowicz, Niloy Ganguly, and Krishna&#x00A0;P Gummadi. 2016. Distinguishing between Topical and Non-Topical Information Diffusion Mechanisms in Social Media.. In <em>      <em>ICWSM</em>     </em>. 151&#x2013;160.</li>     <li id="BibPLXBIB0026" label="[26]">Trisha Greenhalgh, Glenn Robert, Fraser Macfarlane, Paul Bate, and Olivia Kyriakidou. 2004. Diffusion of innovations in service organizations: systematic review and recommendations. <em>      <em>The Milbank Quarterly</em>     </em>82, 4 (2004), 581&#x2013;629.</li>     <li id="BibPLXBIB0027" label="[27]">Aniko Hannak, Eric Anderson, Lisa&#x00A0;Feldman Barrett, Sune Lehmann, Alan Mislove, and Mirek Riedewald. 2012. Tweetin&#x0027;in the Rain: Exploring Societal-Scale Effects of Weather on Mood.. In <em>      <em>ICWSM</em>     </em>.</li>     <li id="BibPLXBIB0028" label="[28]">F.&#x00A0;B. Hanson. 2007. <em>      <em>Applied stochastic processes and control for Jump-diffusions: modeling, analysis, and computation</em>     </em>. Vol.&#x00A0;13. Siam.</li>     <li id="BibPLXBIB0029" label="[29]">R. Hegselmann and U. Krause. [n. d.]. Opinion dynamics &#x0026; bounded confidence models, analysis, &#x0026; simulation. <em>      <em>Journal of Artificial Societies &#x0026; Social Simulation, &#x2019;02</em>     </em>5, 3([n. d.]).</li>     <li id="BibPLXBIB0030" label="[30]">P. Holme and M.&#x00A0;E. Newman. 2006. Nonequilibrium phase transition in the coevolution of networks and opinions. <em>      <em>Physical Review E</em>     </em>74, 5 (2006), 056108.</li>     <li id="BibPLXBIB0031" label="[31]">Anna Huber and Vladimir Kolmogorov. 2012. Towards Minimizing k-Submodular Functions.<em>      <em>ISCO</em>     </em>7422(2012), 451&#x2013;462.</li>     <li id="BibPLXBIB0032" label="[32]">Anna Huber, Andrei Krokhin, and Robert Powell. 2014. Skew bisubmodularity and valued CSPs. <em>      <em>SIAM J. Comput.</em>     </em>43, 3 (2014), 1064&#x2013;1084.</li>     <li id="BibPLXBIB0033" label="[33]">Santosh KC and Arjun Mukherjee. 2016. On the temporal dynamics of opinion spamming: Case studies on yelp. In <em>      <em>WWW</em>     </em>. 369&#x2013;379.</li>     <li id="BibPLXBIB0034" label="[34]">Andreas Krause and Daniel Golovin. 2014. Submodular function maximization.(2014).</li>     <li id="BibPLXBIB0035" label="[35]">Ulrich Krause. 2000. A discrete nonlinear and non-autonomous model of consensus formation. <em>      <em>Communications in difference equations</em>     </em>(2000), 227&#x2013;236.</li>     <li id="BibPLXBIB0036" label="[36]">Bhushan Kulkarni, Sumit Agarwal, Abir De, Sourangshu Bhattacharya, and Niloy Ganguly. 2017. SLANT+: A Nonlinear Model for Opinion Dynamics in Social Networks. In <em>      <em>ICDM</em>     </em>.</li>     <li id="BibPLXBIB0037" label="[37]">Huayi Li, Zhiyuan Chen, Arjun Mukherjee, Bing Liu, and Jidong Shao. 2015. Analyzing and Detecting Opinion Spam on a Large-scale Dataset via Temporal and Spatial Patterns.. In <em>      <em>ICWSM</em>     </em>. 634&#x2013;637.</li>     <li id="BibPLXBIB0038" label="[38]">Huayi Li, Geli Fei, Shuai Wang, Bing Liu, Weixiang Shao, Arjun Mukherjee, and Jidong Shao. 2017. Bimodal distribution and co-bursting in review spam detection. In <em>      <em>WWW</em>     </em>.</li>     <li id="BibPLXBIB0039" label="[39]">Bing Liu. 2012. Sentiment analysis and opinion mining. <em>      <em>Synthesis lectures on human language technologies</em>     </em>5, 1(2012), 1&#x2013;167.</li>     <li id="BibPLXBIB0040" label="[40]">Nazareno&#x00A0;GF Medeiros, Ana&#x00A0;TC Silva, and FG&#x00A0;Brady Moreira. 2006. Domain motion in the voter model with noise. <em>      <em>Physical Review E</em>     </em>73, 4 (2006), 046120.</li>     <li id="BibPLXBIB0041" label="[41]">Irinel-Constantin Mor, Antoine Girard, <em>et al.</em> 2011. Opinion dynamics with decaying confidence: Application to community detection in graphs. <em>      <em>IEEE Trans. Automat. Control</em>     </em>56, 8 (2011), 1862&#x2013;1873.</li>     <li id="BibPLXBIB0042" label="[42]">Irinel-Constantin Mor&#x0103;rescu, Samuel Martin, Antoine Girard, and Aur&#x00E9;lie Muller-Gueudin. 2016. Coordination in networks of linear impulsive agents. <em>      <em>IEEE Trans. Automat. Control</em>     </em>61, 9 (2016), 2402&#x2013;2415.</li>     <li id="BibPLXBIB0043" label="[43]">Seth&#x00A0;A Myers, Chenguang Zhu, and Jure Leskovec. 2012. Information diffusion and external influence in networks. In <em>      <em>KDD</em>     </em>.</li>     <li id="BibPLXBIB0044" label="[44]">George&#x00A0;L Nemhauser, Laurence&#x00A0;A Wolsey, and Marshall&#x00A0;L Fisher. 1978. An analysis of approximations for maximizing submodular set functions&#x2013;I. <em>      <em>Mathematical Programming</em>     </em>14, 1 (1978), 265&#x2013;294.</li>     <li id="BibPLXBIB0045" label="[45]">B. Pang and L. Lee. 2008. Opinion mining and sentiment analysis. <em>      <em>Foundations and trends in information retrieval</em>     </em>2, 1-2(2008), 1&#x2013;135.</li>     <li id="BibPLXBIB0046" label="[46]">Krunal Parmar, Samuel Bushi, Sourangshu Bhattacharya, and Surender Kumar. 2017. Forecasting Ad-Impressions on Online Retail Websites Using Non-homogeneous Hawkes Processes. In <em>      <em>CIKM</em>     </em>.</li>     <li id="BibPLXBIB0047" label="[47]">James&#x00A0;W Pennebaker, Martha&#x00A0;E Francis, and Roger&#x00A0;J Booth. 2001. Linguistic inquiry and word count: LIWC 2001. <em>      <em>Mahway: Lawrence Erlbaum Associates</em>     </em>71, 2001 (2001), 2001.</li>     <li id="BibPLXBIB0048" label="[48]">Bidisha Samanta, Abir De, Abhijnan Chakraborty, and Niloy Ganguly. 2017. LMPP: a large margin point process combining reinforcement and competition for modeling hashtag popularity. In <em>      <em>IJCAI</em>     </em>. 2679&#x2013;2685.</li>     <li id="BibPLXBIB0049" label="[49]">Bidisha Samanta, Abir De, and Niloy Ganguly. 2017. Strm: A sister tweet reinforcement process for modeling hashtag popularity. In <em>      <em>INFOCOM 2017</em>     </em>. IEEE, 1&#x2013;9.</li>     <li id="BibPLXBIB0050" label="[50]">Frank Schweitzer and Laxmidhar Behera. 2009. Nonlinear voter models: the transition from invasion to coexistence. <em>      <em>The European Physical Journal B-Condensed Matter and Complex Systems</em>     </em>67, 3(2009), 301&#x2013;318.</li>     <li id="BibPLXBIB0051" label="[51]">Ajit Singh, Andrew Guillory, and Jeff Bilmes. 2012. On bisubmodular maximization. In <em>      <em>AISTATS</em>     </em>.</li>     <li id="BibPLXBIB0052" label="[52]">Tyler&#x00A0;H Summers, Fabrizio&#x00A0;L Cortesi, and John Lygeros. 2016. On submodularity and controllability in complex dynamical networks. <em>      <em>IEEE Transactions on Control of Network Systems</em>     </em>3, 1 (2016), 91&#x2013;101.</li>     <li id="BibPLXBIB0053" label="[53]">Thomas&#x00A0;W Valente. 1996. Social network thresholds in the diffusion of innovations. <em>      <em>Social networks</em>     </em>18, 1 (1996), 69&#x2013;89.</li>     <li id="BibPLXBIB0054" label="[54]">Federico Vazquez, Paul&#x00A0;L Krapivsky, and Sidney Redner. 2003. Constrained opinion dynamics: Freezing and slow evolution. <em>      <em>Journal of Physics A: Mathematical and General</em>     </em>36, 3 (2003), L61.</li>     <li id="BibPLXBIB0055" label="[55]">Yichen Wang, Grady Williams, Evangelos Theodorou, and Le Song. 2017. Variational Policy for Guiding Point Processes. <em>      <em>arXiv preprint arXiv:1701.08585</em>     </em>(2017).</li>     <li id="BibPLXBIB0056" label="[56]">Justin Ward and Stanislav &#x017D;ivn&#x1EF3;. 2016. Maximizing k-submodular functions and beyond. <em>      <em>ACM Transactions on Algorithms</em>     </em>12, 4 (2016), 47.</li>     <li id="BibPLXBIB0057" label="[57]">E. Yildiz, A. Ozdaglar, D. Acemoglu, A. Saberi, and A. Scaglione. 2013. Binary opinion dynamics with stubborn agents. <em>      <em>ACM Transactions on Economics and Computation</em>     </em>1, 4(2013), 19.</li>     <li id="BibPLXBIB0058" label="[58]">M.&#x00A0;E. Yildiz, R. Pagliari, A. Ozdaglar, and A. Scaglione. 2010. Voting models in random networks. In <em>      <em>Information Theory and Applications Workshop</em>     </em>. 1&#x2013;7.</li>     <li id="BibPLXBIB0059" label="[59]">Ali Zarezade, Abir De, Hamid Rabiee, and Manuel Gomez-Rodriguez. 2017. Cheshire: An Online Algorithm for Activity Maximization in Social Networks. In <em>      <em>arXiv preprint arXiv:1703.02059</em>     </em>.</li>     <li id="BibPLXBIB0060" label="[60]">A. Zarezade, U. Upadhyay, H. Rabiee, and M. Gomez-Rodriguez. 2017. RedQueen: An Online Algorithm for Smart Broadcasting in Social Networks. In <em>      <em>WSDM &#x2019;17</em>     </em>.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>Now affiliated to MPI for Software Systems, Germany. Email: ade@mpi-sws.org</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a><a class="link-inline force-break" href="https://dev.twitter.com/rest/public">https://dev.twitter.com/rest/public</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186121">https://doi.org/10.1145/3178876.3186121</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
