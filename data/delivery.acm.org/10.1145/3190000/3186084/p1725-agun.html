<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Privacy and Efficiency Tradeoffs for Multiword Top K Search with Linear Additive Rank Scoring</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/main.css"/><script src="https://dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Privacy and Efficiency Tradeoffs for Multiword Top <em>K</em> Search with Linear Additive Rank Scoring</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Daniel</span>      <span class="surName">Agun</span>,     Department of Computer Science University of California at Santa Barbara     </div>     <div class="author">     <span class="givenName">Jinjin</span>      <span class="surName">Shao</span>,     Department of Computer Science University of California at Santa Barbara     </div>     <div class="author">     <span class="givenName">Shiyu</span>      <span class="surName">Ji</span>,     Department of Computer Science University of California at Santa Barbara     </div>     <div class="author">     <span class="givenName">Stefano</span>      <span class="surName">Tessaro</span>,     Department of Computer Science University of California at Santa Barbara     </div>     <div class="author">     <span class="givenName">Tao</span>      <span class="surName">Yang</span>,     Department of Computer Science University of California at Santa Barbara     </div>        </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3178876.3186104" target="_blank">https://doi.org/10.1145/3178876.3186104</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>This paper proposes a private ranking scheme with linear additive scoring for efficient top <em>K</em> keyword search on modest-sized cloud datasets. This scheme strikes for tradeoffs between privacy and efficiency by proposing single-round client-server collaboration with server-side partial ranking based on blinded feature weights with random masks. Client-side preprocessing includes query decomposition with chunked postings to facilitate earlier range intersection and fast access of server-side key-value stores. Server-side query processing deals with feature vector sparsity through optional feature matching and enables result filtering with query-dependent chunk-wide random masks for queries that yield too many matched documents. This paper provides details on indexing and run-time conjunctive query processing and presents an evaluation that assesses the accuracy, efficiency, and privacy tradeoffs of this scheme through five datasets with various sizes.</small>     </p>    </div>    <div class="classifications">     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Daniel Agun, Jinjin Shao, Shiyu Ji, Stefano Tessaro, and Tao Yang. 2018. Privacy and Efficiency Tradeoffs for Multiword Top <em>K</em> Search with Linear Additive Rank Scoring. In <em>WWW 2018: The 2018 Web Conference,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 11 Pages. <a href="https://doi.org/10.1145/3178876.3186104" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3178876.3186104</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-2">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction and Related Work</h2>     </div>    </header>    <p>As sensitive information is increasingly stored on the cloud, preserving privacy is a critical factor for users to adopt cloud-based information services including keyword search. A cloud server is often considered as <em>honest-but-curious</em>: namely such a server honestly executes protocol specification and hosted programs, but it may observe and infer the private information of a client during execution or by inspecting hosted data. To deal with such a server, searchable encryption&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>] can be used to conduct privacy-preserving server-side query matching with single keyword&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>], conjunctive multiwords using the OXT protocol&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>], or disjunctive multiwords&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>]. The studies including OXT do not support ranking, and efficient and secure top <em>K</em> ranking is an open research problem because of the challenge in achieving both.</p>    <p>The main challenge to perform server-side privacy-preserving top <em>K</em> ranking is that advanced ranking involves arithmetic computation based on raw features (defined in Section&#x00A0;<a class="sec" href="#sec-3">2</a>) and hiding feature information through encryption prevents the server from performing effective scoring and result comparison. On the other hand, unencrypted feature values can lend themselves to privacy attacks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>]. Homomorphic encryption&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>] is one idea offered to secure data while letting the server perform arithmetic calculations without decrypting the underlying data. For example, given feature values <em>f</em>     <sub>1</sub> and <em>f</em>     <sub>2</sub>, the server that uses a homomorphic encryption <em>E</em>() can compute <em>E</em>(<em>f</em>     <sub>1</sub> + <em>f</em>     <sub>2</sub>) using <em>E</em>(<em>f</em>     <sub>1</sub>) and <em>E</em>(<em>f</em>     <sub>2</sub>) without knowing <em>f</em>     <sub>1</sub> and <em>f</em>     <sub>2</sub>. But such a scheme is still not computationally feasible when many numbers are involved, because each addition or multiplication is extremely slow, not mentioning the ability of comparing two results using scores computed with homomorphic encryption. For example, homomorphic encryption does not allow the efficient comparison of <em>f</em>     <sub>1</sub> + <em>f</em>     <sub>2</sub> and <span class="inline-equation"><span class="tex">$f_1^{\prime }+f_2^{\prime }$</span>     </span> at the server even it can securely compute <em>E</em>(<em>f</em>     <sub>1</sub> + <em>f</em>     <sub>2</sub>) and <span class="inline-equation"><span class="tex">$E(f_1^{\prime }+f_2^{\prime })$</span>     </span>. Order-preserving encryption (e.g. &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>]) allows a sever to compare two encrypted numbers without knowing the actual numbers but it does not support additions or multiplication of encrypted numbers.</p>    <p>Another challenge is that advanced ranking considers a variety of features (e.g. &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0049">49</a>]) and feature vectors are often sparse with many zero values. Space usage can grow explosively if zeros are explicitly stored. Using a compact data structure representation without a proper defense can leak statistic information about index, which may lead to leakage-abuse attacks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>].</p>    <p>The previous work on similarity-based secure ranking&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0040">40</a>] converts each TFIDF-based feature vector into two random vectors. Index construction builds forward index after multiplying feature vectors with secret matrices. Online query processing transforms the given query vector with matrix multiplication also, and derives dot similarity of a transformed query vector with all encrypted document vectors, which results in time complexity as <em>O</em>(<em>T</em>     <sup>2</sup> + <em>DT</em>) where <em>D</em> is the number of documents and <em>T</em> is the dictionary size. To extend this model to consider proximity features such as word pairs, parameter <em>T</em> becomes very large. Inverted indexing is not feasible because offline and online matrix transformation with randomization yields dense feature and query vectors, and the space cost of the index becomes <em>O</em>(<em>DT</em>). Recent work in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>] follows the above matrix transformation while considering multi-user data ownership and dynamic document update. The datasets tested in &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0040">40</a>] are small with only thousands of documents or terms and high search cost with no inverted index support prohibits such an approach from handling a slightly larger dataset.</p>    <p>It appears implausible to develop a completely secure ranking scheme without resorting to heavyweight cryptography such as functional encryption&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>]. With a practical restriction towards fast response time, a server-hosted algorithm must deploy a compromised lightweight scheme to compute ranking scores and select results. Our strategy to address this private ranking open problem is to leverage the previous searchable encryption research and strike various tradeoffs in developing an efficient scheme with limited information leakage to a server. We adopt a client-server collaborative approach in which the server conducts efficient matching, additive scoring, and partial ranking while the client does query preprocessing and the final top result selection. Our design only uses one round of client-server communication since multi-round active communication between the server and client (e.g. &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>]) incurs a much higher communication cost and response latency.</p>    <p>We assume that a client owns a dataset and places the corresponding index on the cloud to be searchable by the client. This paper does not consider the multi-ownership of documents&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>] and it assumes the index on the cloud can be periodically refreshed, but without considering dynamic index update&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>]. The work on query scrambling in &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>] protects user privacy in issuing queries for private web search while assuming that the server owns searchable data and thus hosts unencrypted index. Our work is complementary with a different data ownership assumption. Our presentation assumes that a query contains at least two words because it is relatively easy to handle single-word queries by storing encrypted pre-ranked document IDs for each word on the server.</p>    <p>The <strong>contribution</strong> of this paper is an indexing and online search scheme with linear additive scoring for this open private top <em>K</em> search problem. It seeks a tradeoff with partial server-side result filtering in handling a modest-sized dataset. It is several orders of magnitude faster than the previous baseline solution&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>] while accommodating four categories of previously-developed ranking signals. Due to the page limit, this paper lists formal properties without presenting a detailed proof.</p>   </section>   <section id="sec-3">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Problem Definition and Design Considerations</h2>     </div>    </header>    <p>     <strong>Problem Definition:</strong> Given <em>D</em> document feature vectors with <em>T</em> features that a client owns, each document <em>d</em> has many feature values denoted as <span class="inline-equation"><span class="tex">$f_i^d$</span>     </span> and the client builds a searchable index and places it to the server. We focus on developing an indexing and top <em>K</em> search scheme so that the server can access encrypted matched document features for a query and compute their rank without knowing the underlying feature values within a reasonable response time for a modest-sized dataset. The server also should not learn the meaningful information when features are not involved in search.</p>    <p>We assume each search query contains a conjunction of keywords and adopt the posting intersection of query words based on a searchable encryption algorithm called OXT&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>]. Faster traditional intersection algorithms that traverse two or more postings&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>] simultaneously are not adopted because such a traversal leaks more information to the server. During the search process, a standard technique to ensure privacy is to use a deterministic pseudo random function (called PRF) to hide information including term IDs and document IDs.</p>    <p>     <strong>Ranking formula.</strong> We opt for a simple but popular rank score computing scheme which is a linear combination of document features. While such scoring [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0047">47</a>] delivers decent relevancy performance, multiple additive trees (e.g. &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0044">44</a>]) can achieve better relevance. However, making such a nonlinear ranking method private involves not only score addition and but also value comparison. There is no known encryption method available that can solve both issues within a single framework. A linear combination formula computes ranking score in a form of <span class="inline-equation"><span class="tex">$ \sum \alpha _i f_i^d$</span>     </span> where <em>&#x03B1;<sub>i</sub>     </em> is a coefficient of feature value <span class="inline-equation"><span class="tex">$f_i^d$</span>     </span> for document <em>d</em>. We assume all coefficients are static and can be embedded into feature values during index setup. Thus for the rest of the paper we will ignore these coefficients, and the linear additive rank formula is simplified as <span class="inline-equation"><span class="tex">$ \sum f_i^d.$</span>     </span>    </p>    <p>     <strong>Raw ranking features.</strong> We call a rank feature as <em>raw</em> if it is explicitly stored in the index and a rank feature as <em>composite</em> if it is computed based on other raw features. Our design is to make each basic feature in the above additive formula as a raw feature and the server retrieves and simply adds them without knowing the role of these values. This minimizes the chance that the server understands their semantic contributions to ranking signals.</p>    <p>We use the above additive formula to support four categories of ranking features used in the information retrieval literature: 1) Term-frequency based composite features such TFIDF and BM25&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>]. They can be represented as the summation of weighted raw word frequency and thus the above additive scheme supports such features. 2) Proximity composite features based on the sum of raw proximity term features. Such a proximity term can be a n-gram within a certain distance&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>] or a word pair&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0049">49</a>]. A traditional inverted index with positional information stores word positions explicitly&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>] and online ranking computes composite proximity features based on word positions in each document. While this scheme is space efficient, computing composite proximity features requires both order comparison and arithmetic calculation from word positions. As discussed in Section&#x00A0;<a class="sec" href="#sec-2">1</a>, there is a lack of encryption techniques to support both secure calculation and order comparison. Leaking relative word positions of each document may enable statistical attacks which reveal document content structure. Thus we opt to use a proximity formula expressed as the summation of raw features that directly model proximity terms. As a result, some of the previous proximity formulas are not be supported, for example, minimum aggregation&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>] and span coverage&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>]. 3) Document query specific features such as document-query click through rate. 4) Document specific features such as freshness and document quality. Both Category 3) and 4) are raw features and can fit naturally in the additive rank formula.</p>    <p>     <strong>Handling sparsity of raw ranking features.</strong> Raw features in Category 2), 3) and 4) often have many zero values. If all encrypted zero values are stored explicitly, it would greatly simplify the privacy preserving design, but the space cost would be explosively high and such a scheme would become impractical. One option of handling feature sparsity is to compactly store nonzero feature values for each document as a forward index and once documents that match a query are identified during query processing, encrypted document features can be retrieved using a hashed document ID. Another option is to embed feature values in the posting entries of the traditional inverted index&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>]. These options without a proper defense have a privacy risk that the server can inspect document feature vectors or postings directly and gather document statistical information such as word frequency distribution without client authorization and launch leakage-abuse attacks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>].</p>    <p>Our design for optional features which are often sparse is to use an online key-value store. Namely each matched document <em>d</em> involves the following two types of weights. 1) Required individual feature weight <span class="inline-equation"><span class="tex">$f_i^d$</span>     </span> for document <em>d</em>. When a feature is required, every matched document has a feature value stored in the index. 2) Optional feature weights <span class="inline-equation"><span class="tex">$O_t^d$</span>     </span> where 1 &#x2264; <em>t</em> &#x2264; <em>m</em>. When a feature is optional, the default value is zero when this feature value of a document is not available from the index.</p>    <p>     <strong>Feature encryption with mask blinding.</strong> To preserve privacy of feature values, we blind each feature value using a random mask with modular addition to hide this value from the server. This mask is generated in a deterministic way using a PRF, and is known to the client only. Formally, we store each feature value <em>f</em> in the index as [<em>f</em> + <em>R</em>] which is defined as <span class="inline-equation"><span class="tex">$f + R \bmod N$</span>     </span> where <em>R</em> is the feature mask computed as a PRF of the term ID and the document ID in the range from 0 to <em>N</em> &#x2212; 1. <em>N</em> is set to 2<sup>32</sup> for our implementation.</p>    <p>The square bracket notation in [<em>f</em> + <em>R</em>] also emphasizes that the server sees the computed value of expression <span class="inline-equation"><span class="tex">$f + R \bmod N$</span>     </span> but the server is not able to derive individual <em>f</em> or <em>R</em> value. As we explain below, the above scheme will allow the server to compute the rank score by adding masked feature values and to conduct partial comparison if choosing masks judiciously with a tradeoff. We did not adopt a homomorphic encryption scheme (e.g. &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>]) for feature blinding because it does not bring visible advantage while being less efficient and cannot support partial server-side ranking.</p>    <p>More specifically, for document <em>d</em>, weight of feature <span class="inline-equation"><span class="tex">$f_i^d$</span>     </span> in index is an integer and is stored as <span class="inline-equation"><span class="tex">$[f_i^d+R_i^d]$</span>     </span> with a random noise mask <span class="inline-equation"><span class="tex">$R_i^d$</span>     </span> and optional weight <span class="inline-equation"><span class="tex">$O_{t}^d$</span>     </span> is stored as <span class="inline-equation"><span class="tex">$[O_{t}^d+RO_{t}^d]$</span>     </span> with a random noise mask <span class="inline-equation"><span class="tex">$ RO_{t}^d$</span>     </span>. Given a query with <em>q</em> required features and <em>m</em> optional weights, the total rank score <em>F</em> plus the total score mask for document <em>d</em> including these masks under modulo <em>N</em> is: <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\[ [F+M]=[\sum _{i=1}^q [f_i^d +R_i^d] + \sum _{1\le t \le m, O_t \in X} [O_{t}^d +RO_{t}^d]] \] </span>      <br/>     </div>     </div> where <span class="inline-equation"><span class="tex">$M= \sum _{1\le t \le m, O_t \in X} O_{t}^d + \sum _{1\le t \le m, O_t \in X} RO_{t}^d$</span>     </span> and <em>O<sub>t</sub>     </em> &#x2208; <em>X</em> means that the corresponding optional feature can be found in the key-value store of index.</p>    <p>While the server can compute the above encrypted sum, as the feature masks are random and independent from one document to another, the server is not able to compare the relative rank order among matched documents. When the number of matched documents is modest, the server can send these results to the client along with a bitmap of optional features used for each document, which assists the client to remove the sum of masks in each rank score.</p>    <p>When there is a large number of matched documents in the server or client-server bandwidth is low, we want the server to conduct partial ranking so that results with low scores can be filtered out first before sending back to the client. That essentially becomes a two-stage ranking as a type of cascade ranking&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>]. In next section, we explore this possibility with several tradeoffs necessary to balance privacy and query response time efficiency.</p>   </section>   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Server-side Partial Ranking</h2>     </div>    </header>    <p>     <strong>Server-side partial ranking with uniform random masks.</strong> To allow the server to compare rank scores of matched documents, one option is to choose the same random masks for all documents of the same feature. With this relaxation, we change mask symbol <span class="inline-equation"><span class="tex">$R_i^d$</span>     </span> as <em>R<sub>i</sub>     </em>, and <span class="inline-equation"><span class="tex">$RO_i^d$</span>     </span> as <em>RO<sub>i</sub>     </em> in rank score formula of Section <a class="sec" href="#sec-3">2</a> so that the total mask sum is the same for all matched documents under the same set of matching optional terms and then the server can order these documents.</p>    <p>To support the above strategy, we need to address two issues. 1) As each random feature mask is selected uniformly from 0 to <em>N</em> &#x2212; 1, the masked feature weights and their summation may wrap around under modulo <em>N</em>, which can mislead server-side rank ordering. To let the server handle this wraparound without knowing actual rank scores or additional client-server interaction, we impose a constraint that the final rank score without feature masks is to be less than <span class="inline-equation"><span class="tex">$\frac{N}{2}$</span>     </span>. Given <em>q</em> + <em>m</em> required and optional features, each feature weight <em>w</em> should satisfy <span class="inline-equation"><span class="tex">$\max _{q, m}(q+m) w {\lt}\frac{N}{2}$</span>     </span>, namely its upper bound is <span class="inline-equation"><span class="tex">$\frac{N}{\max _{q,m}(2q+2m)}$</span>     </span>. For example, when <em>q</em> + <em>m</em> &#x2264; 32 and <em>N</em> = 2<sup>32</sup>, the upper bound of each feature weight is 2<sup>26</sup>. When <em>q</em> + <em>m</em> &#x2264; 1024, the upper bound is 2<sup>21</sup>. Our evaluation shows that ranking with 21-bit integer features is sufficient for the tested datasets. We will discuss the possible value of <em>q</em> + <em>m</em> at the end of this section.</p>    <p>     <div class="theorem" id="enc1">     <Label>Theorem 3.1.</Label>     <p> Given <em>q</em> + <em>m</em> required and optional features, each feature weight <em>w</em> satisfies <span class="inline-equation"><span class="tex">$\max _{q, m}(q+m) w {\lt} \frac{N}{2}$</span>      </span>. Let <em>F</em>      <sub>1</sub> and <em>F</em>      <sub>2</sub> be the rank scores of two documents under the same sum mask <em>M</em> where 0 &#x2264; <em>M</em> < <em>N</em>.</p>     <p>      <ul class="list-no-style">       <li id="list1" label="&#x2022;">If <span class="inline-equation"><span class="tex">$\left| [F_1+M]-[F_2+M] \right| {\lt}\frac{N}{2}$</span>        </span>, then [<em>F</em>        <sub>1</sub> + <em>M</em>] &#x2264; [<em>F</em>        <sub>2</sub> + <em>M</em>] if and only if <em>F</em>        <sub>1</sub> &#x2264; <em>F</em>        <sub>2</sub>.<br/></li>       <li id="list2" label="&#x2022;">If <span class="inline-equation"><span class="tex">$\left| [F_1+M]-[F_2+M] \right| {\gt}\frac{N}{2}$</span>        </span>, then [<em>F</em>        <sub>1</sub> + <em>M</em>] &#x2264; [<em>F</em>        <sub>2</sub> + <em>M</em>] if and only if <em>F</em>        <sub>1</sub> &#x2265; <em>F</em>        <sub>2</sub>.<br/></li>      </ul>     </p>     </div>    </p>    <p>The above theorem shows that when the server obtains two masked rank scores [<em>F</em>     <sub>1</sub> + <em>M</em>] and [<em>F</em>     <sub>2</sub> + <em>M</em>] with a possibility of wraparound, it can determine which score <em>F</em>     <sub>1</sub> or <em>F</em>     <sub>2</sub> is bigger without knowing actual values of <em>F</em>     <sub>1</sub> and <em>F</em>     <sub>2</sub>. That is done by checking if the difference of [<em>F</em>     <sub>1</sub> + <em>M</em>] and [<em>F</em>     <sub>2</sub> + <em>M</em>] is within <span class="inline-equation"><span class="tex">$\frac{N}{2}$</span>     </span> or not. Notice the difference cannot be equal to <span class="inline-equation"><span class="tex">$\frac{N}{2}$</span>     </span>. <figure id="fig1">     <img src="http://deliveryimages.acm.org/10.1145/3190000/3186084/images/www2018-93-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">The lattice relationship for optional feature matching cases when <em>q</em> = 3 and <em>m</em> = 3.</span>     </div>     </figure>    </p>    <p>2) Under the same query, different documents may be matched with a different set of optional features. There are 2<sup>     <em>m</em>     </sup> optional feature matching cases representing different combinations of matching these <em>m</em> optional terms. Note that the score masks are different across cases, so the server cannot directly compare between optional cases. Figure&#x00A0;<a class="fig" href="#fig1">1</a> illustrates the lattice relationship of score masks among optional feature matching cases for a query with 3 required terms and 3 optional terms. Each edge represents the subsuming relationship and namely a parent case subsumes terms used in the child case. All documents that correspond to the same optional feature matching case are comparable because their score masks have the same value. Thus the server can sort and select the top <em>K</em> results matching the same case. We use the following property of the lattice to remove unnecessary results across cases.</p>    <p>     <div class="theorem" id="enc2">     <Label>Theorem 3.2.</Label>     <p> Let <em>U</em> and <em>V</em> be two vertices in the lattice of optional feature matching cases and <em>V</em> is a parent node of <em>U</em> (<em>V</em> points to <em>U</em> in Figure&#x00A0;<a class="fig" href="#fig1">1</a>). Let <em>topK</em>(<em>U</em>) be the top <em>K</em> documents matched under Case <em>U</em>. For any document <em>d</em> matched in <em>U</em>, and <span class="inline-equation"><span class="tex">$d \not\in topK(U)$</span>      </span>, any document in <em>V</em> ranked below <em>d</em> or equally under Case <em>V</em> can be removed safely from <em>V</em>.</p>     </div>    </p>    <p>After the above lattice-based suppression, the server sends the top results from different matching cases to the client where further score deblinding and final top <em>K</em> result selection will take place.</p>    <p>     <strong>Query-dependent deblinding using chunk-wide runtime random masks.</strong> The above uniform masking strategy allows server-side partial ranking, but leads to the following leakage of information to the server.</p>    <ul class="list-no-style">     <li id="list3" label="&#x2022;">Given two documents <em>d</em> and <em>d</em>&#x2032; from the same feature mask <em>R</em>, the server can learn their relative weight difference <span class="inline-equation"><span class="tex">$[f^d+R]-[f^{d^\prime }+R]$</span>     </span> to get <span class="inline-equation"><span class="tex">$f^d - f^{d^\prime }$</span>     </span>.<br/></li>     <li id="list4" label="&#x2022;">The server may also use <span class="inline-equation"><span class="tex">$\frac{[f^d+R] -[f^s+R]}{[f^{d^{\prime }}+R]-[f^s+R]}$</span>     </span> to approximate <span class="inline-equation"><span class="tex">$\frac{f^d}{f^{d^{\prime }}}$</span>     </span> where <em>f<sup>s</sup>     </em> is the smallest feature value. Such an approximation can be reasonable if <em>f<sup>s</sup>     </em> happens to be small (e.g. 0).<br/></li>    </ul>    <p>To restrict the above leakage to a smaller scope, we propose a dynamic chunk-wide random masking strategy based on runtime query choices. Each feature has a <em>posting</em> list of document IDs containing nonzero feature values. Index construction divides this list into chunks and the random mask for each feature is the sum of a document specific mask and a chunk-specific mask. For certain queries when server-side partial ranking is triggered, runtime query processing removes document-specific masks in all involved features. In this case, matched documents within the same chunk share the same mask for the same feature and then the server is able to order documents matched under the same chunk.</p>    <p>A client triggers partial ranking on the server side only when the matched results can potentially exceed a threshold. To detect the above condition, we call a feature <em>popular</em> when the total number of documents for this feature with nonzero values is greater than a popularity threshold. Otherwise call this feature <em>unpopular</em>. When one of required features in a query is unpopular, the number of matched results cannot exceed the above threshold.</p>    <p>     <strong>Query decomposition.</strong> Following the above design and given a sorted document list of a feature, we decompose this list as a set of chunks with non-overlapping document ID ranges. Conceptually we view each feature ID as a term and each chunk as a subterm of the original term. Figure&#x00A0;<a class="fig" href="#fig2">2</a>(a) gives an example of feature chunking and query decomposition with query &#x201C;CD rate&#x201D;. The optional word-pair feature added is &#x201C;CD-rate&#x201D;. The posting of &#x201C;CD&#x201D; is decomposed into 4 chunks corresponding to 4 subterms <em>a</em>     <sub>1</sub>, <em>a</em>     <sub>2</sub>, <em>a</em>     <sub>3</sub>, and <em>a</em>     <sub>4</sub> and the posting of &#x201C;rate&#x201D; is decomposed into 5 chunks corresponding to <em>b</em>     <sub>1</sub>, <em>b</em>     <sub>2</sub>, <em>b</em>     <sub>3</sub>, <em>b</em>     <sub>4</sub>, and <em>b</em>     <sub>5</sub>. Similarly, the document list of optional feature &#x201C;CD rate&#x201D; is decomposed with only one chunk <em>c</em>     <sub>1</sub> based on document ID range partitioning. <figure id="fig2">     <img src="http://deliveryimages.acm.org/10.1145/3190000/3186084/images/www2018-93-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 2:</span>      <span class="figure-title">Chunking and query decomposition.</span>     </div>     </figure>    </p>    <p>Knowing the ID ranges of posting chunks, a client can perform an earlier range intersection and decompose the original query as a set of <strong>subqueries</strong>. Any document that matches any subquery satisfies the original query. For Figure&#x00A0;<a class="fig" href="#fig2">2</a>(b), the client can learn that only documents in ID ranges (6,13), (24,26), and (36,44) are possible to contain all required keywords, and equivalently, original query &#x201C;CD rate&#x201D; is converted into a disjunction of the 4 subqueries: <em>a</em>     <sub>1</sub>     <em>b</em>     <sub>2</sub> with optional <em>c</em>     <sub>1</sub>, <em>a</em>     <sub>3</sub>     <em>b</em>     <sub>3</sub> with optional <em>c</em>     <sub>1</sub>, <em>a</em>     <sub>4</sub>     <em>b</em>     <sub>4</sub>, and <em>a</em>     <sub>4</sub>     <em>b</em>     <sub>5</sub>.</p>    <p>Note that the proposed client-side query decomposition brings the following two extra benefits in addition to server-side partial ranking. 1) As we discuss in the next section, feature access is implemented as a hash table lookup. Query decomposition helps exploit locality-aware data partitioning, and thus reduces the memory footprint size during intersection and feature lookup when loading the relevant part of hash tables. We also have considered to avoid over exploitation of locality in data partitioning as there is a privacy tradeoff for blocked data access operations &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>]. 2) An intersection algorithm selects one required feature to start enumerating possible document candidates and typically it is the one with the smallest posting length&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>]. This is called <em>s</em>-term in OXT&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>] in which the server does learn the length of the s-term posting for each query during intersection. As the server accumulates such information after processing many queries, that may open a door to leakage-abuse attacks, and one counter measure is to pad the posting by adding bogus IDs, which disguises true counts&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>]. In our setting, as a query is decomposed into a sequence of subqueries, a client can select a start feature (essentially s-term) differently from one subquery to another, which greatly reduces the chance of leaking the posting length of single words.</p>    <p>     <strong>Tradeoff by limiting the number of optional features.</strong> As shown in next section, the server uses a bitmap record to memorize which optional features are matched for each document. Having a large number of optional features causes two disadvantages: 1) space overhead to maintain a long bitmap. 2) There are less matched results comparable at the server side based on the above lattice discussion. Both factors lead to more server-client communication overhead in sending back partially-ranked results.</p>    <p>When word pairs are used as raw text proximity features, to reduce the total number of word pairs, we combine word pair weights appearing in different sections of a document. Following the previous work&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>], indexing can impose a constraint that a word pair is included in the index only when the word distance of such a pair is within a limit. Our evaluation has used limit 9 in processing three test datasets. At runtime, given <em>q</em> words in a query, there are <span class="inline-equation"><span class="tex">${q \atopwithdelims ()2}$</span>     </span> word pairs, and if we let <span class="inline-equation"><span class="tex">$m= {q \atopwithdelims ()2}$</span>     </span>, there are <span class="inline-equation"><span class="tex">$2^{q \atopwithdelims ()2}$</span>     </span> lattice cases of using these word-pair features. For example, when <em>q</em> = 5, there are already 2<sup>10</sup> cases. When <em>q</em> = 7, the lattice size explodes to 2<sup>21</sup>. We impose a constraint that a client only demands optional word pairs that are within distance limit <em>L</em> in the query. For example with a 5-word query <em>w</em>     <sub>1</sub>, &#x22C5;&#x22C5;&#x22C5;, <em>w</em>     <sub>5</sub>, and <em>L</em> = 2, only distance pairs (<em>w</em>     <sub>1</sub>, <em>w</em>     <sub>2</sub>), (<em>w</em>     <sub>1</sub>, <em>w</em>     <sub>3</sub>), (<em>w</em>     <sub>2</sub>, <em>w</em>     <sub>3</sub>), (<em>w</em>     <sub>2</sub>, <em>w</em>     <sub>4</sub>), (<em>w</em>     <sub>3</sub>, <em>w</em>     <sub>4</sub>), (<em>w</em>     <sub>3</sub>, <em>w</em>     <sub>5</sub>), and (<em>w</em>     <sub>4</sub>, <em>w</em>     <sub>5</sub>) are taken as optional features. In general, the number of optional features <em>m</em> to consider based on word pairs is reduced from <span class="inline-equation"><span class="tex">${q \atopwithdelims ()2}$</span>     </span> to <span class="inline-equation"><span class="tex">${L \atopwithdelims ()2} +L(q-L)$</span>     </span> if <em>q</em> &#x2265; <em>L</em>, otherwise <span class="inline-equation"><span class="tex">${q \atopwithdelims ()2}$</span>     </span>. When we choose <em>L</em> = 2, then <em>m</em> = 2<em>q</em> &#x2212; 3. As shown in Section&#x00A0;<a class="sec" href="#sec-6">5</a> the relevance with <em>L</em> = 2 is acceptable in the tested datasets. In practice, we can assume <em>q</em> < 10 because typically trimming a query longer than such a length does not affect the relevance. Thus <em>m</em> &#x2264; 15 when optional features are only based on word pairs. In some applications, additional optional terms may be needed to improve ranking relevance such as freshness or authoritativeness of a document, thus <em>m</em> is typically under 24 and we use 3 bytes for the optional bit map in our evaluation.</p>   </section>   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Indexing and Query Processing</h2>     </div>    </header>    <p>In this section, we adopt the OXT searchable encryption&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0016">16</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>] for document matching and extend it for ranking. We present an indexing and query processing scheme to support feature blinding with dynamic chunk-wide random masking, and enable a client to safely trigger server-side partial ranking for selected queries involving popular features. This design prevents the server from learning anything formation about the features and posting of an encrypted word if such a word has never been searched.</p>    <p>     <strong>Data structure and high level search flow.</strong> Our search flow involves 3 key-value stores: 1) R-store saves meta information in feature posting chunks such as document ID range of chunks. That facilitates query decomposition at the client side. 2) S-store contains required feature values and is used by the search algorithm to identify the candidate documents. 3) X-store contains feature values accessible using a pair of document ID and feature ID.</p>    <p>Given a query, a client converts it into a sequence of subqueries using R-store. For each subquery, the client generates <em>n</em> required and optional feature IDs as <em>w</em>     <sub>1</sub>, <em>w</em>     <sub>2</sub>, &#x22C5;&#x22C5;&#x22C5;, <em>w<sub>n</sub>     </em> for the server to match documents and fetch their features. Let <em>d</em> be a candidate document ID that appears in the posting list of start feature <em>w</em>     <sub>1</sub>. To fetch another feature <em>w<sub>i</sub>     </em> of <em>d</em> where 2 &#x2264; <em>i</em> &#x2264; <em>n</em>, the online algorithm pairs two IDs <em>w<sub>i</sub>     </em> and <em>d</em> together as the key to access X-store. To preserve privacy, all IDs and intermediate values are hashed or encrypted using operators summarized in Table&#x00A0;<a class="tbl" href="#tab1">1</a> so that for any feature name and document ID, the server cannot access the posting list or feature values from the hosted X-store and R-store without authorization from the client. The server should not learn the identity of the query terms used during online search.</p>    <div class="table-responsive" id="tab1">     <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Function and operator symbols.</span>     </div>     <table class="table">     <tbody>      <tr>       <td style="text-align:left;">&#x2016;</td>       <td>Bitwise concatenation of two values.</td>      </tr>      <tr>       <td style="text-align:left;">        <em>PRF</em>(<em>k</em>, <em>a</em>)</td>       <td>A deterministic pseudo-random function of &#x201C;<em>a</em>&#x201D; using key <em>k</em> (e.g. SHA256 of <em>a</em>&#x2016;<em>k</em>). Among PRF keys used, <em>k</em>        <sub>0</sub>, &#x2026;, <em>k</em>        <sub>9</sub> are secret known by the client only. <em>k<sub>u</sub>        </em> is public to generate feature weight mask <em>R<sub>x</sub>        </em>.</td>      </tr>      <tr>       <td style="text-align:left;">        <em>E</em>(<em>k</em>, <em>a</em>)</td>       <td>Non-deterministic symmetric encryption of plaintext <em>a</em> using key <em>k</em> (e.g. AES using random initialization vector)</td>      </tr>      <tr>       <td style="text-align:left;">        <em>D</em>(<em>k</em>, <em>b</em>)</td>       <td>Symmetric decryption of <em>b</em> using key <em>k</em> s.t. <em>D</em>(<em>k</em>, <em>E</em>(<em>k</em>, <em>a</em>)) = <em>a</em> for any plaintext <em>a</em> and key <em>k</em>       </td>      </tr>      <tr>       <td style="text-align:left;">        <em>S</em>(<em>stag</em>)</td>       <td>Look up S-store with key <em>stag</em>, and return a chunk of encrypted feature posting.</td>      </tr>      <tr>       <td style="text-align:left;">        <em>X</em>(<em>xtag</em>)</td>       <td>Look up X-store with key <em>xtag</em>, and return the encrypted feature value if exists.</td>      </tr>      <tr>       <td style="text-align:left;">        <span class="inline-equation"><span class="tex">$(x_i)_{i=1}^n$</span>        </span>       </td>       <td>A list of elements <em>x<sub>i</sub>        </em> from <em>i</em> = 1 to <em>n</em>.</td>      </tr>     </tbody>     </table>    </div>    <p>     <strong>Encrypted inverted index setup.</strong> The input data set with feature vectors is converted into an inverted index format. The indexer controlled by a client builds the encrypted index and lets the server host the S-store and X-store. For each feature <em>w</em> of document <em>d</em> with value <em>f</em>, this indexer constructs a key-value pair for the X-store as follows. Define <em>p</em> as the position count of <em>d</em> in the posting and <em>c</em> is the chunk ID where <em>c</em> = &#x230A;<em>p</em>/<em>csize</em>&#x230B; and <em>csize</em> is the chunk size.</p>    <ul class="list-no-style">     <li id="list5" label="&#x2022;">The key is <span class="inline-equation"><span class="tex">$xtag=g^{\mathit {PRF}(k_5,w)\mathit {PRF}(k_2,d)}$</span>     </span> where <em>k</em>     <sub>5</sub> and <em>k</em>     <sub>2</sub> are secret hashing keys. Base <em>g</em> is a Diffie-Hellman constant for pseudo-random mapping&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0010">10</a>].<br/></li>     <li id="list6" label="&#x2022;">The value accessible through above key is: <span class="inline-equation"><span class="tex">$S(xtag)= f+R_c+R_x\mod {N}$</span>     </span> where <span class="inline-equation"><span class="tex">$R_x = \mathit {PRF}(k_u,g^{\mathit {PRF}(k_1,w)\mathit {PRF}(k_2,d)})$</span>     </span> and <em>R<sub>c</sub>     </em> = <em>PRF</em>(<em>k</em>     <sub>0</sub>, <em>w</em>&#x2016;<em>c</em>) represent the chunk specific and document specific masks, respectively.<br/></li>    </ul>    <p>When the above feature is required, the <em>d</em> and <em>f</em> values are also saved in the posting chunk <em>c</em> of document <em>w</em> in the S-store. The corresponding S-store key is <em>stag</em> = <em>PRF</em>(<em>k</em>     <sub>7</sub>, <em>w</em>&#x2016;<em>c</em>). The corresponding value is a chunk list of posting entries and each posting entry is an encrypted tuple (<em>e</em>, <em>y</em>, <em>f<sub>s</sub>     </em>) defined as follows.</p>    <ol class="list-no-style">     <li id="list7" label="(1)"><em>e</em> = <em>E</em>(<em>k<sub>e</sub>     </em>, <em>d</em>) which represents the encrypted document ID <em>d</em>. The encryption for <em>e</em> is semantically secure so that the server cannot learn anything except the length of the original document ID.<br/></li>     <li id="list8" label="(2)"><em>y</em> = <em>PRF</em>(<em>k</em>     <sub>4</sub>, <em>w</em>&#x2016;<em>p</em>)<sup>&#x2212; 1</sup>     <em>PRF</em>(<em>k</em>     <sub>2</sub>, <em>d</em>) is a blinded bridging number used when <em>w</em> is selected as a start feature for deriving the key to access the X-store during intersection proposed in &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0017">17</a>]. We extend its usage for feature fetching and will elaborate it later in the example below.<br/></li>     <li id="list9" label="(3)">Blinded feature <span class="inline-equation"><span class="tex">$f_s = u_{d} + f+R_c+R_s\mod {N}$</span>     </span> where <em>u<sub>d</sub>     </em> is the sum of document-specific Category 4 feature weights discussed in Section&#x00A0;<a class="sec" href="#sec-3">2</a>. <em>R<sub>s</sub>     </em> is the document-specific mask computed as <em>PRF</em>(<em>k</em>     <sub>3</sub>, <em>w</em>||<em>p</em>).<br/></li>    </ol>    <p>     <strong>Online search procedure</strong>. Figure&#x00A0;<a class="fig" href="#fig3">3</a> shows the three phases of query processing. <strong>Phase 1</strong>, which is conducted at client side, forms required and optional features for a given query and performs an earlier range intersection to derive subqueries after R-store lookup. Assume each subquery has <em>n</em> features with <em>n</em> corresponding chunk IDs: <span class="inline-equation"><span class="tex">$(w_{i}, c_{i})_{i=1}^{n}$</span>     </span>. All required features are placed before optional features in this feature sequence and <em>w</em>     <sub>1</sub> is selected as the start required feature. Then the key to access S-store is <em>stag</em> = <em>PRF</em>(<em>k</em>     <sub>7</sub>, <em>w</em>     <sub>1</sub>||<em>c</em>     <sub>1</sub>) and the key used in the server to decrypt an entry of posting <em>S</em>(<em>stag</em>) is <em>skey</em> = <em>PRF</em>(<em>k</em>     <sub>6</sub>, <em>w</em>     <sub>1</sub>||<em>c</em>     <sub>1</sub>). In addition, the client builds a special 2-dimensional token array for the server and each array element <em>tokens</em>[<em>i</em>][<em>j</em>] is defined as: <span class="inline-equation"><span class="tex">$ \mathit {xtoken}_i = g^{\mathit {PRF}(k_5,w_i)\mathit {PRF}(k_4, w_1 \vert \vert p)}$</span>     </span>, and <span class="inline-equation"><span class="tex">$\mathit {mtoken}_i = g^{\mathit {PRF}(k_1,w_i)\mathit {PRF}(k_4,w_1 \vert \vert p)}$</span>     </span> where 2 &#x2264; <em>i</em> &#x2264; <em>n</em>, 1 &#x2264; <em>j</em> &#x2264; <em>csize</em>, <em>csize</em> is the chunk size, and posting position <em>p</em> = <em>c</em>     <sub>1</sub>*<em>csize</em> + <em>j</em>. The corresponding document specific mask for the start feature is <em>R<sub>s</sub>     </em> = <em>PRF</em>(<em>k</em>     <sub>3</sub>, <em>w</em>     <sub>1</sub>||<em>p</em>). If the predicted result length does not exceed a threshold, the client will not turn on server-side result filtering and in that case, the second entry <em>mtoken<sub>i</sub>     </em> of each token array element and <em>R<sub>s</sub>     </em> information are voided, Finally the client sends <em>stag</em> and <em>skey</em> along with the token array and related mask <em>R<sub>s</sub>     </em> if needed to the server for the above subquery.</p>    <p>At <strong>Phase 2</strong>, after receiving the control information for each subquery, the server fetches the posting of <em>w</em>     <sub>1</sub> from S-store based on function call <em>S</em>(<em>stag</em>). For every posting entry (assume j-th entry) for <em>w</em>     <sub>1</sub> and <em>i</em>-th other feature, it uses the received token array <em>tokens</em>[<em>i</em>][<em>j</em>] to compute <em>xtag</em> to access X-store and also the document specific mask <em>R<sub>x</sub>     </em> when needed. The server accumulates the rank score with mask subtraction when needed (e.g. Line&#x00A0;21 of Figure&#x00A0;<a class="fig" href="#fig3">3</a>). When partial ranking is turned on, document scores under each optional feature lattice case are compared and filtered, and at most top <em>K</em> results are returned for each case. For each matched document sent back from the server to the client, the result tuple is in a format of (<em>e</em>, <em>F</em>, <em>O</em>, <em>j</em>), representing an encrypted document ID, an encrypted score, a bitmap on the optional features used, and the position of this document appeared in the posting chunk of <em>w</em>     <sub>1</sub>.</p>    <p>     <strong>Phase 3</strong> client post-processing removes score masks and compares all received documents to select the final top <em>K</em> results. <figure id="fig3">     <img src="http://deliveryimages.acm.org/10.1145/3190000/3186084/images/www2018-93-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 3:</span>      <span class="figure-title">Top <em>K</em> search.</span>     </div>     </figure>     <figure id="fig4">     <img src="http://deliveryimages.acm.org/10.1145/3190000/3186084/images/www2018-93-fig4.jpg" class="img-responsive" alt="Figure 4"       longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 4:</span>      <span class="figure-title">Example of client-server query processing.</span>     </div>     </figure>    </p>    <p>     <strong>Example.</strong> Figure&#x00A0;<a class="fig" href="#fig4">4</a> gives a runtime processing example for query &#x201C;CD rate&#x201D; with optional term &#x201C;CD-rate&#x201D;. After query decomposition and subqueries are generated, assume &#x201C;CD&#x201D; is the start feature of this subquery. The key to access S-store is <em>stag</em> = <em>PRF</em>(<em>k</em>, ``<em>CD</em>&#x2032;&#x2032;&#x2016;<em>c</em>) for chunk <em>c</em> of this feature&#x0027;s posting. After accessing S-store, assume <em>d</em> is a candidate document found from the posting of &#x201C;CD&#x201D; with corresponding tuple (<em>e</em>, <em>y</em>, <em>f<sub>s</sub>     </em>). To further access the X-store for features &#x201C;rate&#x201D;, the server computes the access key as <span class="inline-equation"><span class="tex">$xtag=\mathit {xtoken}_2^y$</span>     </span> and <em>R<sub>x</sub>     </em> = <em>PRF</em>(<em>k<sub>u</sub>     </em>, <em>mtoken</em>     <sub>2</sub>     <sup>     <em>y</em>     </sup>). Since <em>y</em> = <em>PRF</em>(<em>k</em>     <sub>4</sub>, ``<em>CD</em>&#x2032;&#x2032;&#x2016;<em>p</em>)<sup>&#x2212; 1</sup>     <em>PRF</em>(<em>k</em>     <sub>2</sub>, <em>d</em>) based on the index setup algorithm, we can verify that the server actually obtains the same values <span class="inline-equation"><span class="tex">$xtag=g^{\mathit {PRF}(k_5,``rate^{\prime \prime })\mathit {PRF}(k_2,d)}$</span>     </span> and <span class="inline-equation"><span class="tex">$R_x = \mathit {PRF}(k_u,g^{\mathit {PRF}(k_1,``rate^{\prime \prime })\mathit {PRF}(k_2,d)})$</span>     </span>, which match the index setup algorithm in building X-store. It means that without knowing values <em>k</em>     <sub>1</sub>, <em>k</em>     <sub>2</sub>, and <em>k</em>     <sub>5</sub>, the server can fetch and add the feature weight of word &#x201C;rate&#x201D; successfully after the query-specific authorization information such as the token array is issued by the client.</p>    <p>     <strong>Search complexity.</strong> The index space cost after encryption is proportional to the summation of all nonzero optional feature values plus the number of required feature IDs multiplied by the number of documents. The encrypted numbers cannot be compressed well because of randomization. For a query with <em>n</em> features and let &#x2211;(<em>Posting</em>(<em>w</em>     <sub>1</sub>)) denote the sum of the posting length of the start feature <em>w</em>     <sub>1</sub> for each subquery. The time cost for this query is <em>O</em>((<em>n</em> &#x2212; 1)&#x2211;|<em>Posting</em>(<em>w</em>     <sub>1</sub>)|). It is slower than that of &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>] which does not need to consider privacy-preserving and this represents a tradeoff for private search.</p>    <p>     <strong>Properties of query processing and leakage discussion.</strong> We present a more formal analysis of the worst-case leakage profile in Appendix&#x00A0;<a class="sec" href="#sec-8">A</a>. Two privacy properties of our scheme following that are listed below.</p>    <p>     <div class="theorem" id="enc3">     <Label>Theorem 4.1.</Label>     <p> If a feature ID has never been used in any search query, the server cannot learn the corresponding feature weight of any document.</p>     </div>    </p>    <p>     <div class="theorem" id="enc4">     <Label>Theorem 4.2.</Label>     <p> The server cannot learn the feature weight of a document for any unpopular word during or after query processing. That is true also for any popular word of a search query which involves at least one unpopular required word.</p>     </div>    </p>    <p>The above theorems show that if a feature such as a word that has never appeared in any past search query, the server is not able to inspect its feature value and learn any leakage of information on this feature used in any document. During the query processing, if a query that does not trigger partial server ranking (e.g. involve at least one unpopular word), the server cannot learn information on features or the final score of each document. In our evaluation with chunk-wide masks is 10,000, the percentage of popular words for CSIRO, TREC45, Aquaint, Clueweb and Enron are respectively 0.07%, 0.31%, 0.47%, 0.07%, and 0.1%. When sever-side result filtering is triggered for queries that involve only these popular words, there is some leakage of rank order and chunk-wide feature difference as discussed in Section&#x00A0;<a class="sec" href="#sec-4">3</a> which will be further discussed in Appendix&#x00A0;<a class="sec" href="#sec-8">A</a>. To restrict such leakage to a smaller scope, one strategy is make the relative ratio of chunk size over the posting length threshold as small as possible. In our tested datasets, this ratio is set to 2.1% with chunk size 210, since this is only for words that appear in over 10,000 documents.</p>   </section>   <section id="sec-6">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Evaluation</h2>     </div>    </header>    <p>     <strong>Implementation and datasets.</strong> We have implemented a prototype system with C++. Experiments are conducted on Linux Ubuntu 16.04 servers with 8 cores of 2.4 GHz AMD FX8320, 16GB memory. The code is compiled with optimization flag -O3. The following datasets are used: the TREC Disk 4&#x0026;5 dataset with TREC Robust 2004 topics 301-450 &#x0026;601-700, the CSIRO dataset with the TREC 2008 Enterprise Track Topics (CE051-CE127) queries, and the Aquaint dataset with TREC Robust 2005 query set of 50 topics. Table&#x00A0;<a class="tbl" href="#tab2">2</a> summarizes their key characteristics after stemming and index generation. Row 2 is the number of documents. Row 3 is the number of term and document ID pairs. Row 4 is the number of composite term and document ID pairs. An optional term composed of two words appears in the X-store with a document if these two words appear in a document within distance 9. Note the majority of the encrypted index size comes from these optional terms. If lower ranking relevance is acceptable the distance limit could be reduced to significantly reduce the size because X-store size is linearly proportional to the total number of document-feature pairs. Row 5, 6 and 7 are the size of R-store, S-store and X-store in bytes. Row 8 is the total index size in bytes. As the machines we run experiments are shared in a cloud environment, we control the search memory usage to under 2GB per machine. Due to memory constraints, we opt to use 1 server for CSIRO while distributing data to 8 and 5 servers respectively for Aquaint and TREC45. Intersection and score accumulation is conducted in parallel on those servers. At the end of this section, we also present our investigation in using a larger dataset from ClueWeb and the Enron email dataset.</p>    <div class="table-responsive" id="tab2">     <div class="table-caption">     <span class="table-number">Table 2:</span>     <span class="table-title">Size characteristics of datasets.</span>     </div>     <table class="table"> 			 <thead>      <tr>       <th style="text-align:center;">Dataset</th>       <th style="text-align:right;">CSIRO</th>       <th style="text-align:right;">TREC45</th>       <th style="text-align:right;">Aquaint</th>      </tr> 			 </thead>     <tbody>      <tr>       <td style="text-align:center;">#Doc</td>       <td style="text-align:right;">0.37M</td>       <td style="text-align:right;">0.53M</td>       <td style="text-align:right;">1.03M</td>      </tr>      <tr>       <td style="text-align:center;">word-doc</td>       <td style="text-align:right;">22M</td>       <td style="text-align:right;">109M</td>       <td style="text-align:right;">216M</td>      </tr>      <tr>       <td style="text-align:center;">wordpair-doc</td>       <td style="text-align:right;">146M</td>       <td style="text-align:right;">712M</td>       <td style="text-align:right;">1,357M</td>      </tr>      <tr>       <td style="text-align:center;">R-Store</td>       <td style="text-align:right;">0.31GB</td>       <td style="text-align:right;">1.25GB</td>       <td style="text-align:right;">1.13GB</td>      </tr>      <tr>       <td style="text-align:center;">S-Store</td>       <td style="text-align:right;">1.12GB</td>       <td style="text-align:right;">5.56GB</td>       <td style="text-align:right;">11.02GB</td>      </tr>      <tr>       <td style="text-align:center;">X-Store</td>       <td style="text-align:right;">2.42GB</td>       <td style="text-align:right;">11.82GB</td>       <td style="text-align:right;">22.53GB</td>      </tr>      <tr>       <td style="text-align:center;">Total Size</td>       <td style="text-align:right;">3.85GB</td>       <td style="text-align:right;">18.63GB</td>       <td style="text-align:right;">34.68GB</td>      </tr>     </tbody>     </table>    </div>    <p>For each document, we select features that perform well for text ranking based on the past work&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0049">49</a>]. We generate the feature value of a word that this document contains based on the BM25 coefficient differentiated by where they appear (title and body). We also compute optional features based on word pairs that appear within a limit in a document. The feature value for the word pairs is based on the squared inverse of word distance following the work in &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0049">49</a>] and if such a pair appears in the title or body of its document. We use AdaRank&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0047">47</a>] to guide feature weighting and relevance evaluation follows 3-fold cross-validation. Notice that with the conjunctive query requirement, our document matching retrieves may miss some labeled relevant results in some queries compared to a disjunctive assumption, which results in up-to 10% relevance difference in some cases.</p>    <p>Each document result returned from the server on average uses about 16 bytes and this includes an 8-byte encrypted document ID, 4-byte blinded score, 3-byte bitmap, and 1-byte position. We select 10,000 as the result size threshold that triggers server-side partial ranking. Notice that the average Internet connection globally has reached an average speed of 7.2Mbps in 2017&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>]. With this average connection speed, it takes 0.18 seconds to transmit 10,000 matched results with 16 bytes per result.</p>    <p>     <strong>Multiword search time.</strong> Table&#x00A0;<a class="tbl" href="#tab3">3</a> lists the average search response time and its cost breakdown when the number of search words varies. In this setting, X-store has 1024 partitions. A query response time includes the client-side time and the server side time for S-store lookup of candidate documents and X-store lookup for intersection and score accumulation. The client time reported includes R-store intersection and the token generation for the first subquery, and the server starts to search as soon as it receives the first subquery. There is no cost involved in X-store operations for <em>q</em> = 1 and its time is listed so we can observe the average time difference between single-word and multiword queries. When <em>q</em> increases from 2 to 3, the X-store time increases as more optional features are involved. But as there are less candidates found from S-store when <em>q</em> is 4 and 5 after earlier range intersection, the X-store time drops in all three query sets. The client-side time is modest, and it increases in all three datasets with more query words because there is more cost for range intersection and x-token generation. Time to compute a x-token is not insignificant because of integer exponentiation involved.</p>    <div class="table-responsive" id="tab3">     <div class="table-caption">     <span class="table-number">Table 3:</span>     <span class="table-title">Query processing cost of three datasets.</span>     </div>     <table class="table"> 			 <thead>      <tr>       <th colspan="2" style="text-align:center;"># Query words <em>q</em>        <hr/>       </th>       <th style="text-align:center;">1</th>       <th style="text-align:center;">2</th>       <th style="text-align:center;">3</th>       <th style="text-align:center;">4-5</th>      </tr> 			 </thead>     <tbody>      <tr>       <td rowspan="4" valign="middle" style="text-align:left;">CSIRO</td>       <td style="text-align:center;">Client</td>       <td style="text-align:center;">30.53</td>       <td style="text-align:center;">59.98</td>       <td style="text-align:center;">74.89</td>       <td style="text-align:center;">101.16</td>      </tr>      <tr>       <td style="text-align:center;">S-store</td>       <td style="text-align:center;">58.31</td>       <td style="text-align:center;">121.57</td>       <td style="text-align:center;">140.40</td>       <td style="text-align:center;">37.60</td>      </tr>      <tr style="border-bottom: solid 2px">       <td style="text-align:center;">X-store</td>       <td style="text-align:center;">0</td>       <td style="text-align:center;">59.21</td>       <td style="text-align:center;">137.87</td>       <td style="text-align:center;">64.09</td>      </tr>      <tr style="border-bottom: solid 2px">       <td style="text-align:center;">Total(ms)</td>       <td style="text-align:center;">89.62</td>       <td style="text-align:center;">283.86</td>       <td style="text-align:center;">427.98</td>       <td style="text-align:center;">248.51</td>      </tr>      <tr>       <td rowspan="4" valign="middle" style="text-align:left;">TREC45</td>       <td style="text-align:center;">Client</td>       <td style="text-align:center;">18.89</td>       <td style="text-align:center;">45.18</td>       <td style="text-align:center;">65.56</td>       <td style="text-align:center;">107.22</td>      </tr>      <tr>       <td style="text-align:center;">S-Store</td>       <td style="text-align:center;">146.79</td>       <td style="text-align:center;">191.30</td>       <td style="text-align:center;">222.33</td>       <td style="text-align:center;">119.67</td>      </tr>      <tr style="border-bottom: solid 2px">       <td style="text-align:center;">X-Store</td>       <td style="text-align:center;">0</td>       <td style="text-align:center;">85.56</td>       <td style="text-align:center;">284.15</td>       <td style="text-align:center;">260.11</td>      </tr>      <tr style="border-bottom: solid 2px">       <td style="text-align:center;">Total(ms)</td>       <td style="text-align:center;">166.42</td>       <td style="text-align:center;">405.64</td>       <td style="text-align:center;">717.34</td>       <td style="text-align:center;">693.00</td>      </tr>      <tr>       <td rowspan="4" valign="middle" style="text-align:left;">Aquaint</td>       <td style="text-align:center;">Client</td>       <td style="text-align:center;">25.87</td>       <td style="text-align:center;">47.38</td>       <td style="text-align:center;">54.17</td>       <td style="text-align:center;">66.35</td>      </tr>      <tr>       <td style="text-align:center;">S-store</td>       <td style="text-align:center;">261.81</td>       <td style="text-align:center;">147.60</td>       <td style="text-align:center;">146.67</td>       <td style="text-align:center;">90.60</td>      </tr>      <tr>       <td style="text-align:center;">X-store</td>       <td style="text-align:center;">0</td>       <td style="text-align:center;">89.47</td>       <td style="text-align:center;">218.52</td>       <td style="text-align:center;">200.95</td>      </tr>      <tr>       <td style="text-align:center;">Total(ms)</td>       <td style="text-align:center;">289.35</td>       <td style="text-align:center;">337.06</td>       <td style="text-align:center;">496.20</td>       <td style="text-align:center;">400.26</td>      </tr>     </tbody>     </table>    </div>    <p>Table&#x00A0;<a class="tbl" href="#tab4">4</a> lists the average search response time for 5 query posting length buckets. Each query falls into one column bucket based on the sum of the start feature posting length of its subqueries. This table validates that the query response time is approximately proportional to the posting length sum of the selected start features of all subqueries as discussed in Section&#x00A0;<a class="sec" href="#sec-5">4</a>.</p>    <div class="table-responsive" id="tab4">     <div class="table-caption">     <span class="table-number">Table 4:</span>     <span class="table-title">Impact of posting length on search time.</span>     </div>     <table class="table"> 			 <thead>      <tr>       <th style="text-align:center;"># Posting length (thousands)</th>       <th style="text-align:center;">0 - 2</th>       <th style="text-align:center;">2 - 4</th>       <th style="text-align:center;">4 - 6</th>       <th style="text-align:center;">6 - 8</th>       <th style="text-align:center;">8 - 10</th>      </tr> 			 </thead>     <tbody>      <tr>       <td style="text-align:center;">CSIRO (ms)</td>       <td style="text-align:center;">186.00</td>       <td style="text-align:center;">392.34</td>       <td style="text-align:center;">499.50</td>       <td style="text-align:center;">801.40</td>       <td style="text-align:center;">973.65</td>      </tr>      <tr>       <td style="text-align:center;">TREC45 (ms)</td>       <td style="text-align:center;">217.81</td>       <td style="text-align:center;">453.23</td>       <td style="text-align:center;">558.27</td>       <td style="text-align:center;">838.78</td>       <td style="text-align:center;">1049.26</td>      </tr>      <tr>       <td style="text-align:center;">Aquaint (ms)</td>       <td style="text-align:center;">134.47</td>       <td style="text-align:center;">343.56</td>       <td style="text-align:center;">479.21</td>       <td style="text-align:center;">770.15</td>       <td style="text-align:center;">909.97</td>      </tr>     </tbody>     </table>    </div>    <p>     <strong>A comparison with the baseline.</strong> We have also implemented and evaluated the baseline approach based on matrix transformation in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>] with the same machine resource setting. It takes over 48, 26, and 46 hours to process a query on average for CSIRO, TREC45, and Aquaint with 1, 5, and 8 machines, respectively. The forward index space cost is 105, 285, and 815 terabytes respectively as encrypted feature vectors are dense. The high cost is caused by the large number of features (<em>T</em>), which is about 39M, 73M, and 108M respectively in these datasets. When restricting the offline word-pair distance to be within 3 instead of 10, <em>T</em> is reduced approximately by half on average and the above cost is also shortened by half. Still our approach is several orders of magnitude faster. An optimization using tree search to speed up similarity computing as <em>O</em>(<em>T</em>log&#x2009;<em>D</em>) is discussed in &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0045">45</a>], but the worst case is still <em>O</em>(<em>TD</em>). Recall that <em>D</em> is the number of documents.</p>    <p>     <strong>Impact of query decomposition.</strong> Query decomposition with chunked postings enables earlier range intersection and S-store and X-store locality-aware partitioning. For range earlier intersection during query decomposition, we find that the intersection scope is reduced by 6%, 12%, and 21% for CSIRO, TREC45, and Aquaint, respectively. Without partitioning X-store, compared to a 1024-partition, search is about 42.5x, 17x, and 19.1x slower for queries with 2 words, 3 words, and 4-5 words, respectively. Thus the above decomposition is important to sustain low query response times.</p>    <div class="table-responsive" id="tab5">     <div class="table-caption">     <span class="table-number">Table 5:</span>     <span class="table-title">Return result reduction in top-10 search with threshold 10,000.</span>     </div>     <table class="table"> 			 <thead>      <tr>       <th colspan="2" style="text-align:center;">#Results returned<hr/>       </th>       <th style="text-align:center;">TREC Queries</th>       <th style="text-align:center;">Synthetic</th>      </tr> 			 </thead>     <tbody>      <tr>       <td rowspan="3" style="text-align:center;">CSIRO</td>       <td style="text-align:center;">No filter</td>       <td style="text-align:center;">11,607</td>       <td style="text-align:center;">33,093</td>      </tr>      <tr>       <td style="text-align:center;">Chunk 105</td>       <td style="text-align:center;">2,504</td>       <td style="text-align:center;">8,884</td>      </tr>      <tr>       <td style="text-align:center;">Chunk 210</td>       <td style="text-align:center;">1,288</td>       <td style="text-align:center;">6,159</td>      </tr>      <tr>       <td rowspan="3" style="text-align:center;">TREC45</td>       <td style="text-align:center;">No filter</td>       <td style="text-align:center;">20,985</td>       <td style="text-align:center;">127,538</td>      </tr>      <tr>       <td style="text-align:center;">Chunk 105</td>       <td style="text-align:center;">14,151</td>       <td style="text-align:center;">28,876</td>      </tr>      <tr>       <td style="text-align:center;">Chunk 210</td>       <td style="text-align:center;">8,708</td>       <td style="text-align:center;">20,596</td>      </tr>      <tr>       <td rowspan="3" style="text-align:center;">Aquaint</td>       <td style="text-align:center;">No filter</td>       <td style="text-align:center;">32,896</td>       <td style="text-align:center;">185,139</td>      </tr>      <tr>       <td style="text-align:center;">Chunk 105</td>       <td style="text-align:center;">25,561</td>       <td style="text-align:center;">38,333</td>      </tr>      <tr>       <td style="text-align:center;">Chunk 210</td>       <td style="text-align:center;">16,112</td>       <td style="text-align:center;">22,437</td>      </tr>     </tbody>     </table>    </div>    <p>     <strong>Effectiveness of server partial ranking.</strong> The average number of results returned from the sever for all 154 TREC queries without top K filtering in CSIRO, TREC45, and Aquaint is 849, 5490, and 5704 respectively. Table&#x00A0;<a class="tbl" href="#tab5">5</a> shows the average number of results for top <em>K</em> search with <em>K</em> = 10. The threshold to trigger partial ranking is 10,000 as discussed above. Column 3 is the average number of results for the 23 TREC queries that trigger partial ranking with posting chunk size 105 and 201 respectively. Rows marked as &#x201D;No filter&#x201D; are for the setting that search does not use server-side partial ranking. For Aquaint, there are 13 TREC queries triggered result filtering and 16,112 results are returned on average with chunk size 210 after filtering out 51% of all matched results. For a larger chunk size, there are more comparable matched documents under each subquery and there are more results filtered during partial ranking.</p>    <p>To evaluate the extreme situations, Column 4 is for handling 15 synthetic queries per dataset built based on only popular and stop words with a much larger number of return results. The partial ranking scheme is able to filter out more unnecessary return results also. For Aquaint, the server returns 22,437 results on average for synthetic queries after filtering out 87.9% of all matched results. In this case with a 7.2Mbps average global Internet connection speed&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>], result communication takes about 0.39 seconds.</p>    <p>     <strong>Relevancy impact with linear additive scoring and the number of optional terms.</strong> Table&#x00A0;<a class="tbl" href="#tab6">6</a> illustrates the NDCG@10 score of the linear model and LambdaMART&#x00A0;&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0044">44</a>] under different query word distance constraints <em>L</em> = 2, 5, &#x221E;. The distance restriction does not negatively degrade performance. Compared to LambdaMART, the linear scoring model delivers decent performance.</p>    <div class="table-responsive" id="tab6">     <div class="table-caption">     <span class="table-number">Table 6:</span>     <span class="table-title">Relevance with different numbers of word-pairs.</span>     </div>     <table class="table"> 			 <thead>      <tr>       <th colspan="2" style="text-align:center;">NDCG@10<hr/>       </th>       <th style="text-align:center;">L=2</th>       <th style="text-align:center;">L=5</th>       <th style="text-align:center;">L=&#x221E;</th>      </tr> 			 </thead>     <tbody>      <tr>       <td rowspan="2" style="text-align:center;">CSIRO</td>       <td style="text-align:center;">LambdaMART</td>       <td style="text-align:center;">0.4836</td>       <td style="text-align:center;">0.4842</td>       <td style="text-align:center;">0.4789</td>      </tr>      <tr>       <td style="text-align:center;">Linear</td>       <td style="text-align:center;">0.4311</td>       <td style="text-align:center;">0.4046</td>       <td style="text-align:center;">0.4317</td>      </tr>      <tr>       <td rowspan="2" style="text-align:center;">TREC45</td>       <td style="text-align:center;">LambdaMART</td>       <td style="text-align:center;">0.3823</td>       <td style="text-align:center;">0.3898</td>       <td style="text-align:center;">0.3866</td>      </tr>      <tr>       <td style="text-align:center;">Linear</td>       <td style="text-align:center;">0.4121</td>       <td style="text-align:center;">0.4012</td>       <td style="text-align:center;">0.3808</td>      </tr>      <tr>       <td rowspan="2" style="text-align:center;">Aquaint</td>       <td style="text-align:center;">LambdaMART</td>       <td style="text-align:center;">0.3256</td>       <td style="text-align:center;">0.3246</td>       <td style="text-align:center;">0.3131</td>      </tr>      <tr>       <td style="text-align:center;">Linear</td>       <td style="text-align:center;">0.3118</td>       <td style="text-align:center;">0.3227</td>       <td style="text-align:center;">0.317</td>      </tr>     </tbody>     </table>    </div>    <p>     <strong>ClueWeb.</strong> We have also investigated how our scheme handles a larger dataset using ClueWeb09 Category B dataset&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>] with 50 million web documents. The relevancy raw features include BM25-weighted single word weights and word pairs in the title and body sections, and document PageRank scores. The top team in the 2011 Web TREC has accomplished NDCG@20 of 0.24282 in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>] using the TREC 2011 Queries plus 450 out of the 684 queries from Million Query (MQ) TREC 2009&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>]. LambdaMART using our raw features obtains NDCG@20 of 0.2547, 0.2554, and 0.2601 with query word distance restriction <em>L</em> = 2, <em>L</em> = 5, and <em>L</em> = &#x221E;, respectively. The additive ranking scheme we use obtains 0.2512, 0.2530, and 0.2585 under these <em>L</em> values.</p>    <p>The search time for ClueWeb data is still reasonable as the client-side query processing does not require large memory and the server side can use more machines to distribute S-store and X-store for parallel processing. The client-server communication cost is a key concern and thus we select several different subsets of this ClueWeb dataset to assess the impact of database size change on server-side partial ranking. For all 684 queries from MQ TREC 2009 with judgment labels, Table&#x00A0;<a class="tbl" href="#tab7">7</a> lists the average return result size from Row 3 to Row 4 with two chunk sizes when the database size chosen varies from 3M to 50M ClubWeb documents. Row 6 and Row 7 show the average return result size for queries for top 10% of the largest result sizes after server-side filtering. When the database size is 5M and chunk size is 210, it would take about 0.46 seconds on average for the server to send 25,394 results back to the client with today&#x0027;s global average Internet speed 7.2 Mbps. The slowest 10% of queries can take 1.93 seconds with 107,195 results. Notice the top country-level average Internet connection is 28.6 Mbps&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] and with such a speed, the slowest 10% would take 0.486 seconds to deliver.</p>    <div class="table-responsive" id="tab7">     <div class="table-caption">     <span class="table-number">Table 7:</span>     <span class="table-title">Return result sizes in top-10 search with threshold 10,000 for ClueWeb subsets varying from 3M to 50M.</span>     </div>     <table class="table"> 			 <thead>      <tr>       <th colspan="2" style="text-align:center;"># Results returned<hr/>       </th>       <th style="text-align:center;">3M</th>       <th style="text-align:center;">5M</th>       <th style="text-align:center;">10M</th>       <th style="text-align:center;">30M</th>       <th style="text-align:center;">50M</th>      </tr> 					 </thead>     <tbody>      <tr>       <td rowspan="3" style="text-align:center;">All</td>       <td style="text-align:center;">No Filter</td>       <td style="text-align:center;">65,449</td>       <td style="text-align:center;">81,445</td>       <td style="text-align:center;">113,173</td>       <td style="text-align:center;">218,027</td>       <td style="text-align:center;">321,769</td>      </tr>      <tr>       <td style="text-align:center;">Chunk 105</td>       <td style="text-align:center;">25,273</td>       <td style="text-align:center;">31,866</td>       <td style="text-align:center;">46,442</td>       <td style="text-align:center;">90,138</td>       <td style="text-align:center;">134,240</td>      </tr>      <tr>       <td style="text-align:center;">Chunk 210</td>       <td style="text-align:center;">19,992</td>       <td style="text-align:center;">25,394</td>       <td style="text-align:center;">37,413</td>       <td style="text-align:center;">73,017</td>       <td style="text-align:center;">108,892</td>      </tr>      <tr>       <td rowspan="3" style="text-align:center;">Top 10%</td>       <td style="text-align:center;">No Filter</td>       <td style="text-align:center;">393,650</td>       <td style="text-align:center;">506,452</td>       <td style="text-align:center;">752,328</td>       <td style="text-align:center;">1,619,203</td>       <td style="text-align:center;">2,465,084</td>      </tr>      <tr>       <td style="text-align:center;">Chunk 105</td>       <td style="text-align:center;">97,710</td>       <td style="text-align:center;">147,156</td>       <td style="text-align:center;">234,872</td>       <td style="text-align:center;">508,292</td>       <td style="text-align:center;">812,515</td>      </tr>      <tr>       <td style="text-align:center;">Chunk 210</td>       <td style="text-align:center;">69,056</td>       <td style="text-align:center;">107,376</td>       <td style="text-align:center;">173,195</td>       <td style="text-align:center;">374,309</td>       <td style="text-align:center;">608,736</td>      </tr>     </tbody>     </table>    </div>    <p>     <strong>Enron email dataset.</strong> We have also studied this corporate email collection&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>] with about 0.5M messages from about 150 users. The average posting length of words in this dataset is 65 with 0.1% of them as popular words. Like other datasets we have studied, the posting length follows a long-tail Zipf distribution. We use 100 personal names from the email collection as test queries, and find all queries only contain unpopular words. Namely all of them have results less than 10,000 and the server only computes rank scores without filtering. If we lower the threshold to 1000, then the result filtering ratio after server-side partial ranking is over 50% on average. Because each email message is short, searching this dataset is much faster than TREC45 with a similar size.</p>   </section>   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Concluding Remarks</h2>     </div>    </header>    <p>The contribution of this work is a novel private top <em>K</em> ranking scheme with various tradeoffs to efficiently search cloud hosted data. A privacy analysis on limited leakage is provided. Our experiment shows that the response time is reasonable, and partial server ranking can effectively reduce the return result size for the tested datasets. The developed techniques address this open problem for a modest sized dataset. For a significantly larger dataset, the current techniques require fast client-server connection since the result size returned from the server even after partial ranking can be significant when all query words are popular. Deployment of faster Internet connection such as mobile 5G networks could extend the applicability of the proposed approach together with additional improvements. Another potential strategy to support a larger dataset is to adopt a trusted proxy with a fast server-proxy communication connection, if available. Then final supplemental ranking could be completed at such a proxy and the ranked results can be sent to the client with a smaller communication cost. Recently there is an advancement in neural network based ranking (e.g. &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0046">46</a>]) and our techniques can be applicable for document pre-ranking used in such work or directly integrating neural features.</p>    <p>     <strong>Acknowledgments</strong>. We thank Olaoluwa Osuntokun for initial code development, and the anonymous referees for their thorough comments. This work is supported in part by NSF IIS-1528041. Any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF.</p>   </section>  </section>  <section class="back-matter">   <Appendix>    <section id="sec-8">     <header>     <div class="title-info">      <h2>       <span class="section-number">A</span> Privacy Analysis</h2>     </div>     </header>     <p>The previous work&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>] analyzes the correctness of the derived leakage in a searchable encryption system by showing the information that any adversary can acquire during the execution of the real search protocol can be well simulated by an interactive experiment between this adversary and a simulation algorithm which only knows the leakage of the secure search system. This appendix analyzes the privacy of our ranking scheme following such semantic security with leakage.</p>     <p>     <strong>Notion:</strong> Let <em>&#x03A0;</em> be a searchable symmetric encryption scheme&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0017">17</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>], which consists of two algorithms: Algorithm &#x201C;EDBSetup&#x201D; distributes the keys to the client and server and encrypts inverted index; Algorithm &#x201C;Search&#x201D; executes the search protocol between the client and server. Let <span class="inline-equation"><span class="tex">$\mathcal {L}(\textsf {DB}, \textsf {q})$</span>     </span> be a leakage profile function, which takes the plaintext inverted index <span class="inline-equation"><span class="tex">$\textsf {DB}$</span>     </span> and a query sequence <span class="inline-equation"><span class="tex">$\textsf {q}$</span>     </span> as input, and outputs the leakage information of the whole system. For a security parameter <em>&#x03BB;</em> (roughly related to the number of bits in the key), for two efficient algorithms <em>A</em> (for Adversary) and <em>S</em> (for Simulator), define experiments <span class="inline-equation"><span class="tex">${\bf Real}_A^\Pi (\lambda)$</span>     </span> and <span class="inline-equation"><span class="tex">${\bf Ideal}_{A,S}^\Pi (\lambda)$</span>     </span> as:</p>     <ul class="list-no-style">     <li id="list10" label="&#x2022;"><span class="inline-equation"><span class="tex">${\bf Real}_A^\Pi (\lambda)$</span>      </span>: <em>A</em>(1<sup>       <em>&#x03BB;</em>      </sup>) chooses the plaintext inverted index <span class="inline-equation"><span class="tex">$\textsf {DB}$</span>      </span> and a list of queries <span class="inline-equation"><span class="tex">$\textsf {q}$</span>      </span>. The experiment runs <span class="inline-equation"><span class="tex">$(K, \textsf {EDB}) \leftarrow \textsf {EDBSetup}(\textsf {DB})$</span>      </span>, where <em>K</em> is the set of secret keys known only to the client, and <span class="inline-equation"><span class="tex">$\textsf {EDB}$</span>      </span> is the encrypted index. For each query in <span class="inline-equation"><span class="tex">$\textsf {q}$</span>      </span>, it secretly runs the algorithm <span class="inline-equation"><span class="tex">$\textsf {Search}$</span>      </span> with client input <em>K</em> and server input <span class="inline-equation"><span class="tex">$\textsf {EDB}$</span>      </span> and stores the transcript (i.e., all the communications between the client and server). Then the experiment gives <span class="inline-equation"><span class="tex">$\textsf {EDB}$</span>      </span> and the transcript to <em>A</em>, which returns and outputs a Boolean value in {0, 1} answering whether the transcript is produced by the real search protocol, which happens here, or the simulator.<br/></li>     <li id="list11" label="&#x2022;"><span class="inline-equation"><span class="tex">${\bf Ideal}_{A,S}^\Pi (\lambda)$</span>      </span>: <em>A</em>(1<sup>       <em>&#x03BB;</em>      </sup>) chooses <span class="inline-equation"><span class="tex">$\textsf {DB}$</span>      </span> and a list of queries <span class="inline-equation"><span class="tex">$\textsf {q}$</span>      </span>. The experiment secretly runs <span class="inline-equation"><span class="tex">$S(\mathcal {L}(\textsf {DB}, \textsf {q}))$</span>      </span> and gives its output (a synthetic transcript) to <em>A</em>, which returns and outputs a Boolean value in {0, 1} answering whether this output is produced by the real search protocol or the simulator <em>S</em>.<br/></li>     </ul>     <p>     <strong>Definition</strong>: &#x03A0; is <span class="inline-equation"><span class="tex">$\mathcal {L}$</span>     </span>-semantically-secure against non-adaptive attacks if for any efficient adversary <em>A</em> there exists an algorithm <em>S</em> such that the probability difference <span class="inline-equation"><span class="tex">$\Pr [{\bf Real}_A^\Pi (\lambda)=1] - \Pr [{\bf Ideal}_{A,S}^\Pi (\lambda)=1]$</span>     </span> is negligible, i.e., asymptotically less than <em>&#x03BB;</em>     <sup>&#x2212; <em>c</em>     </sup> for any integer <em>c</em>.</p>     <p>Following the above definition, our objective is to make the attacker <em>A</em> unable to tell apart the communications of the real secure protocol and the communications between the client and the simulator <em>S</em>. This notion is only for non-adaptive attacks, since in each experiment the attacker can only choose the queries at the beginning, and can never change the chosen queries during the interaction with the server. This assumption fits most scenarios since often a third-party attacker has little control over the queries that users issue. The only thing the attacker can know is the distribution of the queries. With the above definition, we can prove the following sketched theorem.</p>     <p>     <strong>Theorem (sketched)</strong>: With standard cryptographic assumptions, the search scheme in Section&#x00A0;<a class="sec" href="#sec-5">4</a> is <span class="inline-equation"><span class="tex">$\mathcal {L}$</span>     </span>-semantically-secure against non-adaptive attackers with the leakage profile <span class="inline-equation"><span class="tex">$\mathcal {L}$</span>     </span> (i.e., the information leaked to the attacker) given as follows.</p>     <ul class="list-no-style">     <li id="list12" label="&#x2022;">Size patterns: 1) The chunk size for partitioned posting lists. 2) The number of documents matching each subquery. 3) The length of the posting list for the s-term in each subquery.<br/></li>     <li id="list13" label="&#x2022;">Rank and feature patterns: 1) Rank order of encrypted document IDs for answering a query. 2) The difference between two document weights of the same feature within the same chunk, if the corresponding word has been searched.<br/></li>     <li id="list14" label="&#x2022;">Intersection patterns: 1) The overlapping pattern of s-tags and x-tokens sent during search. For any subquery, given any chunk in the posting of the s-term, the server knows which chunks in the posting of any non-s-term in the subquery have non-empty intersections with this chunk. 2) The identification of any two subqueries sharing the same s-term. 3) The intersection of the posting lists of two s-terms from two subqueries that the server knows they share at least one non-s-term.</li>     </ul>    </section>   </Appendix>   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">E. Agichtein, E. Brill, S. Dumais, and R. Ragno. Learning user interaction models for predicting web search result preferences. In <em>      <em>Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</em>     </em>, SIGIR &#x2019;06, pages 3&#x2013;10, New York, NY, USA, 2006. ACM.</li>     <li id="BibPLXBIB0002" label="[2]">R. Agrawal, J. Kiernan, R. Srikant, and Y. Xu. Order-preserving encryption for numeric data. In <em>      <em>SIGMOD 2004</em>     </em>, pages 563&#x2013;574, 2004.</li>     <li id="BibPLXBIB0003" label="[3]">Akamai.com. Akamai&#x0027;s State of the Internet. Q1 2017 Executive Summary, 2017.</li>     <li id="BibPLXBIB0004" label="[4]">A. Arampatzis, G. Drosatos, and P. S. Efraimidis. Versatile query scrambling for private web search. <em>      <em>Information Retrieval Journal</em>     </em>, 18(4):331&#x2013;358, 2015.</li>     <li id="BibPLXBIB0005" label="[5]">A. Arampatzis, P. Efraimidis, and G. Drosatos. Enhancing deniability against query-logs. In <em>      <em>European Conference on Information Retrieval</em>     </em>, pages 117&#x2013;128. Springer, 2011.</li>     <li id="BibPLXBIB0006" label="[6]">L. T. I. at&#x00A0;Carnegie Mellon&#x00A0;University. <em>&#x00A0;</em>The clueweb09 dataset, <a class="link-inline force-break"      href="http://boston.lti.cs.cmu.edu/data/clueweb09">http://boston.lti.cs.cmu.edu/data/clueweb09</a>.</li>     <li id="BibPLXBIB0007" label="[7]">R. Baeza-Yates and B. Ribeiro-Neto. <em>      <em>Modern Information Retrieval (2nd Edition)</em>     </em>. Addison Wesley, 2011.</li>     <li id="BibPLXBIB0008" label="[8]">J. Bai, Y. Chang, H. Cui, Z. Zheng, G. Sun, and X. Li. Investigation of partial query proximity in web search. <em>WWW &#x2019;08</em>, pages 1183&#x2013;1184, 2008.</li>     <li id="BibPLXBIB0009" label="[9]">A. Boldyreva, N. Chenette, Y. Lee, and A. O&#x0027;Neill. Order-preserving symmetric encryption. <em>EUROCRYPT &#x2019;09</em>, pages 224&#x2013;241, 2009.</li>     <li id="BibPLXBIB0010" label="[10]">D. Boneh. The decision diffie-hellman problem. <em>      <em>Algorithmic number theory</em>     </em>, pages 48&#x2013;63, 1998.</li>     <li id="BibPLXBIB0011" label="[11]">L. Boytsov and A. Belova. Evaluating learning-to-rank methods in the web track adhoc task. In <em>      <em>TREC</em>     </em>, 2011.</li>     <li id="BibPLXBIB0012" label="[12]">S. B&#x00FC;ttcher, C. L. A. Clarke, and B. Lushman. Term proximity scoring for ad-hoc retrieval on very large text collections. <em>SIGIR &#x2019;06</em>, pages 621&#x2013;622. ACM.</li>     <li id="BibPLXBIB0013" label="[13]">N. Cao, C. Wang, M. Li, K. Ren, and W. Lou. Privacy-preserving multi-keyword ranked search over encrypted cloud data. <em>      <em>IEEE Trans. Parallel Distrib. Syst.</em>     </em>, 25(1):222&#x2013;233, 2014.</li>     <li id="BibPLXBIB0014" label="[14]">B. Carterette, V. Pavlu, H. Fang, and E. Kanoulas. Million query track 2009 overview. In <em>      <em>TREC</em>     </em>, 2009.</li>     <li id="BibPLXBIB0015" label="[15]">D. Cash, P. Grubbs, J. Perry, and T. Ristenpart. Leakage-abuse attacks against searchable encryption. In <em>      <em>CCS&#x2019;15</em>     </em>, pages 668&#x2013;679. ACM, 2015.</li>     <li id="BibPLXBIB0016" label="[16]">D. Cash, J. Jaeger, S. Jarecki, C. S. Jutla, H. Krawczyk, M. Rosu, and M. Steiner. Dynamic searchable encryption in very-large databases: Data structures and implementation. In <em>      <em>NDSS 2014</em>     </em>, 2014.</li>     <li id="BibPLXBIB0017" label="[17]">D. Cash, S. Jarecki, C. S. Jutla, H. Krawczyk, M. Rosu, and M. Steiner. Highly-scalable searchable symmetric encryption with support for boolean queries. In <em>      <em>CRYPTO 2013</em>     </em>, pages 353&#x2013;373, 2013.</li>     <li id="BibPLXBIB0018" label="[18]">D. Cash and S. Tessaro. The locality of searchable symmetric encryption. In <em>      <em>EUROCRYPT 2014</em>     </em>, pages 351&#x2013;368, 2014.</li>     <li id="BibPLXBIB0019" label="[19]">J. S. Culpepper and A. Moffat. Efficient set intersection for inverted indexing. <em>      <em>ACM Trans. Inf. Syst.</em>     </em>, 29(1):1:1&#x2013;1:25, Dec. 2010.</li>     <li id="BibPLXBIB0020" label="[20]">R. Curtmola, J. Garay, S. Kamara, and R. Ostrovsky. Searchable symmetric encryption: Improved definitions and efficient constructions. <em>CCS &#x2019;06</em>, pages 79&#x2013;88. ACM, 2006.</li>     <li id="BibPLXBIB0021" label="[21]">T. Elsayed, N. Asadi, L. Wang, J. J. Lin, and D. Metzler. UMD and USC/ISI: TREC 2010 web track experiments with ivory. In <em>      <em>Proceedings of The Nineteenth Text REtrieval Conference, TREC 2010, Gaithersburg, Maryland, USA</em>     </em>, 2010.</li>     <li id="BibPLXBIB0022" label="[22]">C. Gentry. <em>      <em>A Fully Homomorphic Encryption Scheme</em>     </em>. PhD thesis, 2009.</li>     <li id="BibPLXBIB0023" label="[23]">O. Goldreich and R. Ostrovsky. Software protection and simulation on oblivious rams. <em>      <em>J. ACM</em>     </em>, 43(3):431&#x2013;473, May 1996.</li>     <li id="BibPLXBIB0024" label="[24]">J. Guo, Y. Fan, Q. Ai, and W. B. Croft. A deep relevance matching model for ad-hoc retrieval. In <em>      <em>Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</em>     </em>, CIKM &#x2019;16, pages 55&#x2013;64, New York, NY, USA, 2016. ACM.</li>     <li id="BibPLXBIB0025" label="[25]">H. Hu, J. Xu, C. Ren, and B. Choi. Processing private queries over untrusted data cloud through privacy homomorphism. In <em>      <em>ICDE</em>     </em>, pages 601&#x2013;612, 2011.</li>     <li id="BibPLXBIB0026" label="[26]">M. S. Islam, M. Kuzu, and M. Kantarcioglu. Access pattern disclosure on searchable encryption: Ramification, attack and mitigation. In <em>      <em>NDSS 2012</em>     </em>, 2012.</li>     <li id="BibPLXBIB0027" label="[27]">K. S. Jones, S. Walker, and S. E. Robertson. A probabilistic model of information retrieval: development and comparative experiments. <em>      <em>Inf. Process. Manage.</em>     </em>, 36(6):779&#x2013;808, Nov. 2000.</li>     <li id="BibPLXBIB0028" label="[28]">S. Kamara and T. Moataz. Boolean searchable symmetric encryption with worst-case sub-linear complexity. In <em>      <em>Annual International Conference on the Theory and Applications of Cryptographic Techniques</em>     </em>, pages 94&#x2013;124. Springer, 2017.</li>     <li id="BibPLXBIB0029" label="[29]">S. Kamara and C. Papamanthou. Parallel and dynamic searchable symmetric encryption. In <em>      <em>FC 2013</em>     </em>, pages 258&#x2013;274, 2013.</li>     <li id="BibPLXBIB0030" label="[30]">S. Kamara, C. Papamanthou, and T. Roeder. Dynamic searchable symmetric encryption. In <em>      <em>CCS&#x2019;12</em>     </em>, pages 965&#x2013;976, 2012.</li>     <li id="BibPLXBIB0031" label="[31]">M. Naveed, M. Prabhakaran, and C. A. Gunter. Dynamic searchable encryption via blind storage. <em>SP &#x2019;14</em>, pages 639&#x2013;654. IEEE Computer Society, 2014.</li>     <li id="BibPLXBIB0032" label="[32]">C. &#x00D6;rencik and E. Savas. An efficient privacy-preserving multi-keyword search over encrypted cloud data with ranking. <em>      <em>Distributed and Parallel Databases</em>     </em>, 32(1):119&#x2013;160, 2014.</li>     <li id="BibPLXBIB0033" label="[33]">P. Paillier. Public-key cryptosystems based on composite degree residuosity classes. In <em>      <em>EUROCRYPT &#x2019;99</em>     </em>, pages 223&#x2013;238, 1999.</li>     <li id="BibPLXBIB0034" label="[34]">R. A. Popa, F. H. Li, and N. Zeldovich. An ideal-security protocol for order-preserving encoding. <em>SP &#x2019;13</em>, pages 463&#x2013;477. IEEE Computer Society, 2013.</li>     <li id="BibPLXBIB0035" label="[35]">R. A. Popa, C. M. S. Redfield, N. Zeldovich, and H. Balakrishnan. Cryptdb: Protecting confidentiality with encrypted query processing. <em>SOSP &#x2019;11</em>, pages 85&#x2013;100. ACM, 2011.</li>     <li id="BibPLXBIB0036" label="[36]">D. Pouliot and C. V. Wright. The shadow nemesis: Inference attacks on efficiently deployable, efficiently searchable encryption. In <em>      <em>CCS&#x2019;16</em>     </em>, pages 1341&#x2013;1352. ACM, 2016.</li>     <li id="BibPLXBIB0037" label="[37]">C. Project. <em>&#x00A0;</em>The enron email dataset, <a class="link-inline force-break" target="_blank"     href="https://www.cs.cmu.edu/&#x00A0;enron/">https://www.cs.cmu.edu/&#x00A0;enron/</a>.</li>     <li id="BibPLXBIB0038" label="[38]">D. X. Song, D. Wagner, and A. Perrig. Practical techniques for searches on encrypted data. <em>SP &#x2019;00</em>. IEEE Computer Society, 2000.</li>     <li id="BibPLXBIB0039" label="[39]">E. Stefanov, E. Shi, and D. X. Song. Towards practical oblivious RAM. In <em>      <em>NDSS 2012</em>     </em>, 2012.</li>     <li id="BibPLXBIB0040" label="[40]">W. Sun, B. Wang, N. Cao, M. Li, W. Lou, Y. T. Hou, and H. Li. Verifiable privacy-preserving multi-keyword text search in the cloud supporting similarity-based ranking. <em>      <em>IEEE Trans. Parallel Distrib. Syst.</em>     </em>, 25(11):3025&#x2013;3035, 2014.</li>     <li id="BibPLXBIB0041" label="[41]">K. M. Svore, P. H. Kanani, and N. Khan. How good is a span of terms?: exploiting proximity to improve web retrieval. <em>SIGIR &#x2019;10</em>, pages 154&#x2013;161. ACM, 2010.</li>     <li id="BibPLXBIB0042" label="[42]">T. Tao and C. Zhai. An exploration of proximity measures in information retrieval. <em>SIGIR &#x2019;07</em>, pages 295&#x2013;302. ACM, 2007.</li>     <li id="BibPLXBIB0043" label="[43]">L. Wang, J. Lin, and D. Metzler. A cascade ranking model for efficient ranked retrieval. In <em>      <em>Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>     </em>, SIGIR &#x2019;11, pages 105&#x2013;114, New York, NY, USA, 2011. ACM.</li>     <li id="BibPLXBIB0044" label="[44]">Q. Wu, C. J. Burges, K. M. Svore, and J. Gao. Adapting boosting for information retrieval measures. <em>      <em>Inf. Retr.</em>     </em>, 13(3):254&#x2013;270, June 2010.</li>     <li id="BibPLXBIB0045" label="[45]">Z. Xia, X. Wang, X. Sun, and Q. Wang. A secure and dynamic multi-keyword ranked search scheme over encrypted cloud data. <em>      <em>IEEE Trans. Parallel Distrib. Syst.</em>     </em>, 27(2):340&#x2013;352, 2016.</li>     <li id="BibPLXBIB0046" label="[46]">C. Xiong, Z. Dai, J. Callan, Z. Liu, and R. Power. End-to-End Neural Ad-hoc Ranking with Kernel Pooling. In <em>      <em>Proceedings of the 40th International ACM SIGIR Conference on Research &#x0026; Development in Information Retrieval</em>     </em>. ACM, 2017.</li>     <li id="BibPLXBIB0047" label="[47]">J. Xu and H. Li. Adarank: a boosting algorithm for information retrieval. <em>SIGIR &#x2019;07</em>, pages 391&#x2013;398. ACM, 2007.</li>     <li id="BibPLXBIB0048" label="[48]">W. Zhang, Y. Lin, S. Xiao, J. Wu, and S. Zhou. Privacy preserving ranked multi-keyword search for multiple data owners in cloud computing. <em>      <em>IEEE Trans. Computers</em>     </em>, 65(5):1566&#x2013;1577, 2016.</li>     <li id="BibPLXBIB0049" label="[49]">J. Zhao and J. X. Huang. An enhanced context-sensitive proximity model for probabilistic information retrieval. In <em>      <em>SIGIR</em>     </em>, pages 1131&#x2013;1134, 2014.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186104">https://doi.org/10.1145/3178876.3186104</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
