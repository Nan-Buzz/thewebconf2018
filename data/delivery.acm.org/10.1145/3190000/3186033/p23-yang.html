<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>Leveraging Crowdsourcing Data For Deep Active Learning An Application: Learning Intents in Alexa</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/main.css"/><script src="../../../../dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../../dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main">  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">Leveraging Crowdsourcing Data For Deep Active Learning An Application: Learning Intents in Alexa</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author">     <span class="givenName">Jie</span>     <span class="surName">Yang</span><a class="fn" href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>,     Delft University of Technology, Delft, Netherlands, <a href="mailto:j.yang-3@tudelft.nl">j.yang-3@tudelft.nl</a>    </div>    <div class="author">     <span class="givenName">Thomas</span>     <span class="surName">Drake</span>,     Amazon Research, Seattle, WA, USA, <a href="mailto:draket@amazon.com">draket@amazon.com</a>    </div>    <div class="author">     <span class="givenName">Andreas</span>     <span class="surName">Damianou</span>,     Amazon Research, Cambridge, UK, <a href="mailto:damianou@amazon.com">damianou@amazon.com</a>    </div>    <div class="author">     <span class="givenName">Yoelle</span>     <span class="surName">Maarek</span>,     Amazon Research, Haifa, Israel, <a href="mailto:yoelle@yahoo.com">yoelle@yahoo.com</a>    </div>                    </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3178876.3186033" target="_blank">https://doi.org/10.1145/3178876.3186033</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>This paper presents a generic Bayesian framework that enables any deep learning model to actively learn from targeted crowds. Our framework inherits from recent advances in Bayesian deep learning, and extends existing work by considering the targeted crowdsourcing approach, where multiple annotators with unknown expertise contribute an uncontrolled amount (often limited) of annotations. Our framework leverages the low-rank structure in annotations to learn individual annotator expertise, which then helps to infer the true labels from noisy and sparse annotations. It provides a unified Bayesian model to simultaneously infer the true labels and train the deep learning model in order to reach an optimal learning efficacy. Finally, our framework exploits the uncertainty of the deep learning model during prediction as well as the annotators&#x2019; estimated expertise to minimize the number of required annotations and annotators for optimally training the deep learning model.</small>    </p>    <p>     <small>We evaluate the effectiveness of our framework for intent classification in Alexa (Amazon&#x0027;s personal assistant), using both synthetic and real-world datasets. Experiments show that our framework can accurately learn annotator expertise, infer true labels, and effectively reduce the amount of annotations in model training as compared to state-of-the-art approaches. We further discuss the potential of our proposed framework in bridging machine learning and crowdsourcing towards improved human-in-the-loop systems.</small>    </p>    </div>    <div class="classifications">    <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Deep Active Learning; Crowdsourcing; Conversational Agents</small>     </span>    </div>    <br/>    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Jie Yang, Thomas Drake, Andreas Damianou, and Yoelle Maarek. 2018. Leveraging Crowdsourcing Data For Deep Active Learning An Application: Learning Intents in Alexa. In <em>WWW 2018: The 2018 Web Conference,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 10 Pages. <a href="https://doi.org/10.1145/3178876.3186033" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3178876.3186033</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-5">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>    </div>    </header>    <p>Deep learning models have achieved remarkable success for automating various tasks, ranging from image recognition [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>], speech recognition [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>], to natural language processing [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0038">38</a>]. These models often require a large number of parameters, significantly greater than classic machine learning models, in order to capture complex patterns in the data and thus to achieve superior performance in prediction tasks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>]. Learning these parameters, however, typically requires large amount of labeled data. In fact, researchers have identified strong correlations between the capability of deep learning models, the number of parameters in the model, and the size of the training data [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>]. Obtaining these labels is a long, laborious, and usually costly process. Crowdsourcing provides a convenient means for data annotation at scale. For example, the ImageNet dataset [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>] &#x2013; one of the most popular datasets driving the advancement of deep learning techniques in computer vision &#x2013; is annotated by 49K workers recruited from Amazon Mechanical Turk<a class="fn" href="#fn2" id="foot-fn2"><sup>1</sup></a> over 3 years (2007-2010) for 3.2M images. In practice, data annotation for training machine learning models is one of the main applications of crowdsourcing&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>].</p>    <p>As of today, data annotation and model training are generally regarded as isolated processes. Task owners collect annotations from a supposedly unlimited source of annotators who are assumed to be anonymous and disposable, and then train the deep learning model for the application at hand. This assumption, however, does not hold for many tasks that are either subjective or knowledge intensive. An example of such a task, is the one we are considering in this paper: intent classification of users&#x2019; queries in conversational agents. Such a task is key to the effectiveness of personal assistants such as Amazon Alexa<a class="fn" href="#fn3" id="foot-fn3"><sup>2</sup></a> or Google Home<a class="fn" href="#fn4" id="foot-fn4"><sup>3</sup></a>. The true query intent is highly subjective, and is largely dependent on various contextual factors. As a result, annotations generated by anonymous, even if trained, workers cannot be fully trusted.</p>    <p>Crowdsourced data annotation requires certain type of workers. In our conversational agent application, the ideal annotators are the users who issued the queries. This is feasible only if the task allows for a natural, non obtrusive way for users to confirm their query intents, e.g., Alexa requires the user to confirm their intents by responding to the question &#x201C;do you want to shop?&#x201D;. This type of crowdsourcing, referred to <em>targeted crowdsourcing</em>, has been studied by Ipeirotis et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>]. Unlike the conventional notion of paid crowdsourcing, targeted crowdsourcing features a certain group of annotators of varying expertise. This leads to several challenges including identifying the right annotators and effectively engaging them. In this paper, we investigate <em>how to best train a deep learning model while minimizing the data annotation effort in targeted crowdsourcing</em>. This problem is important given the targeted annotators as valuable worker resources. In our conversational agent context, minimizing the amount of confirmation questions for users is critical to reduce the negative impact on customer experience.</p>    <p>We propose here to adopt an <em>active learning</em> approach, as it allows the model to choose the data from which it learns best&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>]. With active learning, models that are initially trained on a small dataset actively make decisions in order to select the most informative data samples, often based on the model&#x0027;s uncertainty. These data samples are then routed to <em>an expert</em> for annotation, and inserted into the training set for model retraining. With active learning, we can expect the model to be effectively trained with the minimum amount of contribution from crowds. Moreover, by performing active learning over time, the model can detect the changes in application environment and adapt accordingly, thereby continuously delivering high-quality prediction.</p>    <p>Despite the potential, enabling deep learning models to actively learn from targeted crowds is non-trivial for several reasons. First, deep learning models can rarely represent prediction uncertainty &#x2013; they usually perform prediction in a deterministic way. Second, while targeted crowds can provide better labels than explicitly recruited workers, annotation quality remains a significant issue. For example, annotators&#x2019; expertise (e.g., users&#x2019; familiarity with the application) can have a highly influential impact on the annotation quality. Furthermore, users may not even answer the confirmation question asked by conversational agents, or may give random responses when losing interest, which happens frequently in reality. Last but not least, annotations provided by targeted crowds can be highly sparse, making it particularly challenging to model annotator expertise or annotation quality. In contrast to conventional crowdsourcing, where requesters have control over the number of annotations contributed by individual workers, most annotators in targeted crowdsourcing may only contribute a small number of annotations due to the lack of engagement mechanisms.</p>    <p>To address these issues, this paper introduces a generic Bayesian framework that supports effective deep active learning from targeted crowds. Our framework inherits from recent advances in Bayesian deep learning [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>], and leverages dropout as a practical way for representing model uncertainty in deep learning. To resolve the annotation noise and sparsity issues, our framework exploits the low-rank structure in annotations and learns a low-dimensional representation of individual annotator expertise, which is then used to learn annotation reliability, so as to reduce annotation noise. Annotation reliability is further learned in a way conditioned on specific data samples, so that samples that are intrinsically more ambiguous can be identified. Using a Bayesian approach, our framework simultaneously infers the true label from noisy and sparse crowd annotations and trains the deep learning model to reach an optimal learning efficacy. This approach brings an additional benefit: the annotator selection process and the network training process influence each other, allowing the active learning to be tailored to the hidden representation and objective function of the neural network. This comes in contrast to schemes used in practice that employ one model with well-calibrated uncertainty (e.g., Gaussian processes [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>]) for active learning and a different model (e.g., a deep neural network) for prediction. In active learning settings, our framework exploits the uncertainty of the deep learning model in prediction as well as the learned annotator expertise in order to respectively minimize the number of required annotations and the number of annotators for optimally training the deep learning model.</p>    <p>The key contributions of our work include:</p>    <ul class="list-no-style">    <li id="list1" label="&#x2022;">Introducing the notion of deep active learning in targeted crowdsourcing settings.<br/></li>    <li id="list2" label="&#x2022;">Proposing a method for learning annotator expertise and inferring true labels from noisy and sparse crowd annotations, which takes advantage of the low-rank structure of the annotations.<br/></li>    </ul>    <ul class="list-no-style">    <li id="list3" label="&#x2022;">Defining a generic Bayesian framework that learns annotator expertise, infers true labels, and trains the deep learning model simultaneously. This framework further reduces annotation efforts to enable deep learning models to actively learn from crowds.<br/></li>    <li id="list4" label="&#x2022;">Validating our approach and framework via extensive experiments on both synthetic and real-world datasets. In particular, we demonstrate the effectiveness of our framework in Amazon&#x0027;s Alexa, one of today&#x0027;s major conversational agents.<br/></li>    </ul>    <p>To the best of our knowledge, this work is the first to study deep active learning from sparse and noisy crowd annotations. Our proposed framework is a generic one applicable to any deep learning model and in a variety of domains, e.g., natural language processing and computer vision.</p>   </section>   <section id="sec-6">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>    </div>    </header>    <p>In this section, we first discuss relevant work from the emerging field of human-in-the-loop paradigm, then we review existing work methodologically related to our proposed framework in Bayesian deep active learning and learning from crowds.</p>    <section id="sec-7">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.1</span> Human-in-the-Loop Systems</h3>     </div>    </header>    <p>Human-in-the-loop systems, or human-machine hybrid systems, are aimed at exploiting the complementarity between the intelligence of humans and the scalability of machines to solve complex tasks at scale [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0007">7</a>]. A number of human-in-the-loop systems have been proposed up to date. These include an early example of the ESP game [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0040">40</a>], and systems that demonstrate the amplified power of human intelligence when coupled with machines in solving complex tasks for automated systems (e.g., Recaptcha for OCR applications&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0041">41</a>]). More recent human-in-the-loop systems have been proposed to solve data-related problems in a variety of domains. For example, CrowdDB by Franklin et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0012">12</a>] for Databases, CrowdSearcher by Bozzon et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0002">2</a>] for Information Retrieval, and Zencrowd by Demartini et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>] for Semantic Web.</p>    <p>An important application area of human-in-the-loop systems is machine learning, by engaging crowds to annotate data for training supervised machine learning models. Examples include the ImageNet dataset for computer vision [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0010">10</a>] and many crowd annotated datasets for various natural language processing tasks, such as datasets for sentiment and opinion mining [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0030">30</a>] and question answering [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0019">19</a>], to name a few. An often neglected aspect of crowdsourced data annotation for machine learning is that data annotation and model training are generally regarded as isolated processes. This does not work well for subjective or knowledge-intensive tasks, for which workers are regarded as a valuable resource, with only specific workers able to provide high-quality annotations. A notion developed for this particular type of crowdsourcing is called <em>targeted crowdsourcing</em> by Ipeirotis and Gabrilovich [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>], which emphasizes the demand for worker expertise. A similar concept has been proposed as <em>nichesourcing</em> by De Boer et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0006">6</a>]. How to best train machine learning models while minimizing workers&#x2019; efforts in targeted crowdsourcing remains an open question. The problem becomes even more challenging for deep neural network based machine learning models (i.e., deep learning models) that are prevalent in many domains, due to the strong influence of the size of training data on model performance.</p>    </section>    <section id="sec-8">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.2</span> Bayesian Deep Active Learning</h3>     </div>    </header>    <p>To enable deep learning models to actively learn from crowds, we base our approach on Bayesian deep active learning [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0016">16</a>], which unifies deep learning with active learning using Bayesian methods. In the following, we briefly review related work that converges to the current notion of Bayesian deep active learning.</p>    <p>First, we consider the same model for driving the active labeling and the predictive learning task. In such a setting, the model selects unlabeled data samples which can provide the strongest training signal; these samples are labeled and used to supervise model training. The potential benefit of a data sample is generally measured by the model&#x0027;s uncertainty in making predictions for that sample, i.e., the so-called <em>uncertainty sampling</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0028">28</a>]. Other criteria also exist, e.g., how well a data sample will reduce the estimate of the expected error [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0032">32</a>], which attempts to select data samples that directly optimize prediction performance. Such a criterion, however, is less practical than model uncertainty as it is generally difficult to have an analytical expression for the expected prediction error. As a remark, the traditional notion of active learning assumes a single omniscient oracle that can provide genuine labels for any data samples, without any constraint on the amount of provided annotations.</p>    <p>Unlike probabilistic models (e.g., Bayesian networks), deep learning models only make deterministic predictions, making it rather challenging to represent model uncertainty, which is essential for active learning. A popular workaround has been to employ an active learning model (e.g., a Gaussian process) which is separate from the neural network classifier [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0023">23</a>]. A more consistent solution is to leverage recent developments in Bayesian deep learning. The Bayesian deep learning methods of interest can be generally categorized into two classes. The first class is based on stochastic gradient descent (SGD). Welling et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0042">42</a>] show that by adding the right amount of noise to the standard SGD the parameter will converge to samples from the true posterior distribution. The other class of methods is based on dropout, which is a technique originally proposed to prevent over-fitting in training deep learning models [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>]. It is proved by Gal et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>] that when preserving dropout during prediction the same way as in model training, the predictions are equivalent to sampling from the approximate true posterior distribution of the parameters, thus turning a deterministic predictive function into a stochastic (uncertain) one.</p>    <p>A recent paper [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0016">16</a>], perhaps the most closely related work to ours, proposes a method for Bayesian deep active learning based on dropout. It follows the conventional assumption of active learning: a single expert is able to provide high-quality annotations on demand. This is unrealistic in practice, especially for deep learning models which would require large amounts of annotated data. To the best of our knowledge, we are the first to investigate a principled approach to enable deep learning models to actively learn from crowds.</p>    </section>    <section id="sec-9">    <header>     <div class="title-info">      <h3>       <span class="section-number">2.3</span> Learning from Crowds</h3>     </div>    </header>    <p>While not focusing on deep learning models, there is a line of research [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0039">39</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0044">44</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0049">49</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0050">50</a>] that has investigated methods for enabling machine learning models to learn from crowds. The key problems here are two-fold: 1) infer the true label, and 2) train the model. The former problem often requires estimation of the reliability of annotations, which is further related to the expertise of annotators [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>] and the difficulty or clarity of tasks [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0046">46</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0047">47</a>].</p>    <p>In an early work, Dawid and Skene [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>] first study the problem of inferring true labels from multiple noisy labels and introduce an Expectation Maximization (EM) algorithm to model worker skills. Sheng et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0036">36</a>] shows that repeated-labeling by multiple annotators can significantly improve the quality of the labels using a simple majority voting label aggregation scheme. Whitehill et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0043">43</a>] generalize the work from Dawid and Skene by taking into account both worker expertise and task difficulty for label inference, and show better performance than majority voting.</p>    <p>Raykar et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0031">31</a>] first introduce the problem of learning-from-crowds to improve machine learning models. A Bayesian method is proposed to model the true label as a joint function that considers both crowd annotations and the output of a logistic regression classifier. The parameters of annotator expertise and the classifier are then learned by maximizing the likelihood of the observed data and crowd annotations. Their method, however, does not consider task properties (e.g., task type) as influential factors in annotation reliability. Yan et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>] extend the problem by considering the influence of task properties on annotation reliability. They formulate annotation reliability as a logistic function parameterized by both worker and task representations. In a slightly different scenario, Tian et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0039">39</a>] model the problem of &#x201C;schools of thought&#x201D;, where multiple correct labels can exist for a single data sample.</p>    <p>A closely related line of research incorporates active learning into learning-from-crowds, to reduce the cost in annotation. Yan et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0044">44</a>] extend their work in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>] to pick most uncertain data samples and most reliable workers for active learning. Fang et al.&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>] then consider the case when annotators are able to learn from one another to improve their annotation reliability. In a more recent work, Zhong et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0049">49</a>] further model the scenario when workers can explicitly express their annotation confidence by allowing them to choose an unsure option.</p>    <p>All these works, however, do not consider deep learning models as the target model to improve. Furthermore, none of them considers the targeted crowdsourcing scenarios where the annotations contributed by individual annotators are both noisy and sparse.</p>    </section>   </section>   <section id="sec-10">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> The DALC Framework</h2>    </div>    </header>    <p>This section introduces our proposed framework that we refer to as Deep Active Learning from targeted Crowds (DALC). We first formalize the problem, then introduce our method for 1) formulating any deep learning (DL) model in a Bayesian framework, and 2) learning from targeted crowds. We then describe the overall Bayesian framework that seamlessly unifies these two models and actively learns from targeted crowds to reduce the amount of annotations for training DL models.</p>    <p>    <strong>Problem Formalization.</strong>Throughout this paper we use boldface lowercase letters to denote vectors and boldface uppercase letters to denote matrices. For an arbitrary matrix <strong>M</strong>, we use <strong>M<sub>ij</sub>    </strong> to denote the entry at the <em>i</em>-th row and <em>j</em>-th column, and use <strong>M<sub>i:</sub>    </strong> to denote the vector at the <em>i</em>-th row. We use capital letters (e.g., <span class="inline-equation"><span class="tex">$\mathcal {P}$</span>    </span>) in calligraphic math font to denote sets. Let <span class="inline-equation"><span class="tex">$\mathcal {X} = \lbrace \mathbf {x}_1, \mathbf {x}_2, \ldots , \mathbf {x}_m\rbrace$</span>    </span> (<span class="inline-equation"><span class="tex">$\mathbf {x}_i\in \mathbb {R}^k$</span>    </span>) denote <em>m</em> data samples labeled by <em>n</em> annotators <span class="inline-equation"><span class="tex">$\mathcal {U} = \lbrace u_1, u_2, \ldots , u_n\rbrace$</span>    </span>. The labels form a sparse matrix <span class="inline-equation"><span class="tex">$\mathbf {L}\in \mathbb {R}^{m\times n}$</span>    </span> where <strong>L</strong>    <sub>     <em>ij</em>    </sub> is the label for sample <strong>x</strong>    <sub>     <em>i</em>    </sub> contributed by annotator <em>u<sub>j</sub>    </em>. The true labels &#x2013; which are unknown &#x2013; are denoted as <span class="inline-equation"><span class="tex">$\mathcal {Y} = \lbrace y_1, y_2, \ldots , y_m\rbrace$</span>    </span> for the <em>m</em> data samples. Given the observed data <span class="inline-equation"><span class="tex">$\mathcal {X}$</span>    </span> and annotations <strong>L</strong> contributed by <span class="inline-equation"><span class="tex">$\mathcal {U}$</span>    </span>, our goals is to infer the true labels <span class="inline-equation"><span class="tex">$\mathcal {Y}$</span>    </span> and train a deep learning model, whose parameters <span class="inline-equation"><span class="tex">$\mathcal {W}$</span>    </span>, i.e., the weight matrix and bias in each layer of the DL model, are to be learned.</p>    <section id="sec-11">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Bayesian Deep Learning</h3>     </div>    </header>    <p>DALC adopts the Bayesian approach to deep learning recently developed by Gal and Ghahramani [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>]. Specifically, we consider a generic DL model with parameters <span class="inline-equation"><span class="tex">$\mathcal {W}$</span>     </span> as a likelihood function: <div class="table-responsive" id="Xeq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} p(y_i|\mathbf {x}_i, \mathcal {W}) = \text{softmax}(f^{\mathcal {W}}(x_i)) \end{equation} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div> with <span class="inline-equation"><span class="tex">$f^{\mathcal {W}}(x_i)$</span>     </span> modeling the output of the network layers preceding the softmax layer. To formulate the DL model in a Bayesian framework, we first define a prior over the parameters <span class="inline-equation"><span class="tex">$\mathcal {W}$</span>     </span>: <div class="table-responsive" id="Xeq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathcal {W} \sim p(\mathcal {W}|K) \end{equation} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div> e.g., a standard Gaussian prior parameterized by <em>K</em> (the co-variance matrix). With this assumption, model training will result in a posterior distribution over the parameters, i.e., <span class="inline-equation"><span class="tex">$p(\mathcal {W}| \mathcal {D}_{train})$</span>     </span>, instead of point estimates, i.e., fixed values for the parameters. Note that here we assume that the true labels are given in the training data <span class="inline-equation"><span class="tex">$\mathcal {D}_{train} = (\mathcal {X}, \mathcal {Y})$</span>     </span>. We explain in Section&#x00A0;<a class="sec" href="#sec-14">4</a> how to infer the true labels from the observed data samples and noisy annotations.</p>    <p>     <strong>Training &#x0026; Prediction with Bayesian DL.</strong> In the following, we describe how to train the Bayesian DL model and make predictions with the trained model. These will be the building blocks in training the overall DALC framework, as we will show in Section&#x00A0;<a class="sec" href="#sec-14">4</a>.</p>    <p>Training the Bayesian DL model is exactly similar to training a normal DL model using the back-propagation method with dropout enabled. The prediction given an arbitrary input <strong>x</strong> can be described as a likelihood function: <div class="table-responsive" id="eq1">      <div class="display-equation">       <span class="tex mytex">\begin{equation} p(y|\mathbf {x}, \mathcal {D}_{train}) = \int p(y|\mathbf {x}, \mathcal {W}) p(\mathcal {W}| \mathcal {D}_{train}) d\mathcal {W} \end{equation} </span>       <br/>       <span class="equation-number">(3)</span>      </div>     </div> which provides a more robust prediction than non-Bayesian method as it considers the uncertainty of the learned parameters.</p>    <p>The problem of inferring the exact posterior distribution for the parameters, <span class="inline-equation"><span class="tex">$p(\mathcal {W}|\mathcal {D}_{train})$</span>     </span>, is almost always infeasible in Bayesian methods. Gal and Ghahramani [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>] propose Monte Carlo (MC) dropout, which is a simple yet effective method for performing approximate variational inference. MC dropout is based on dropout [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0037">37</a>], which is a widely used method in training DL models to prevent over-fitting. It is generally used during the model training process by randomly dropping hidden units of the network in each iteration. Gal and Ghahramani [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0015">15</a>] prove that by simply performing dropout during the forward pass in making predictions, the output is equivalent to the prediction when the parameters are sampled from a variational distribution of the true posterior. To give the intuition, the reason for the above is that test dropout gives us predictions from different versions of the network, which is equivalent to taking samples from a stochastic version of the network. Uncertainty can then be estimated based on the samples similarly to the Query by Committee [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0035">35</a>] principle, which looks at the degree of disagreement.</p>    <p>Formally, MC dropout is equivalent to sampling from a variational distribution <span class="inline-equation"><span class="tex">$q(\mathcal {W})$</span>     </span> that minimizes the Kullback-Leibler (KL) divergence to the true posterior <span class="inline-equation"><span class="tex">$p(\mathcal {W}| \mathcal {D}_{train})$</span>     </span>. Given this, we can then perform a Monte Carlo integration to approximate Equation&#x00A0;<a class="eqn" href="#eq1">3</a>: <div class="table-responsive" id="eq2">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \begin{split} p(y|\mathbf {x}, \mathcal {D}_{train}) &#x0026; \approx \int p(y|\mathbf {x}, \mathcal {W}) q(\mathcal {W}) d\mathcal {W} \\ &#x0026; \approx \frac{1}{T} \sum _{t=1}^T p(y|\mathbf {x}, \widehat{\mathcal {W}}) \end{split} \end{equation} </span>       <br/>       <span class="equation-number">(4)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$\widehat{\mathcal {W}}$</span>     </span> is sampled <em>T</em> times from <span class="inline-equation"><span class="tex">$q(\mathcal {W})$</span>     </span>, i.e., <span class="inline-equation"><span class="tex">$\widehat{\mathcal {W}} \sim q(\mathcal {W})$</span>     </span>. To summarize, MC dropout provides a practical way to approximately sample from the true posterior without explicitly calculating the intractable true posterior.</p>    </section>    <section id="sec-12">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Learning from Targeted Crowds</h3>     </div>    </header>    <p>The learning-from-targeted-crowds (LFTC) model formulates the relationship among the following objects: the data sample <strong>x</strong>     <sub>      <em>i</em>     </sub>, the true label <em>y<sub>i</sub>     </em>, the annotator <em>u<sub>j</sub>     </em>, and the noisy annotations <strong>L</strong>     <sub>      <em>ij</em>     </sub>. We assume the label <strong>L</strong>     <sub>      <em>ij</em>     </sub> contributed by annotator <em>u<sub>j</sub>     </em> to the data sample <em>x<sub>i</sub>     </em> is influenced by all of the following three factors:</p>    <ol class="list-no-style">     <li id="list5" label="(1)">the true label <em>y<sub>i</sub>      </em> &#x2013; approximating the true label with noisy annotations is one of our main goals;<br/></li>     <li id="list6" label="(2)">the data sample <strong>x</strong>      <sub>       <em>i</em>      </sub> &#x2013; it&#x0027;s a realistic assumption that for some data samples (e.g., more ambiguous) the annotation is more noisy;<br/></li>     <li id="list7" label="(3)">the annotator <em>u<sub>j</sub>      </em> &#x2013; the label is also dependent on annotator properties, e.g., expertise.<br/></li>    </ol>    <p>To formalize the relationships described above, we first represent each annotator <em>u<sub>j</sub>     </em> as a low-dimensional embedding vector <span class="inline-equation"><span class="tex">$\mathbf {u}_j\in \mathbb {R}^d$</span>     </span> where <em>d</em> &#x226A; min&#x2009;(<em>m</em>, <em>n</em>). Each dimension of <strong>u</strong>     <sub>      <em>j</em>     </sub> represents a latent topic &#x2013; which is to be learned from the data &#x2013; and each element in <strong>u</strong>     <sub>      <em>j</em>     </sub> can be viewed as user <em>u<sub>j</sub>     </em>&#x2019;s expertise in the corresponding topic. We then use a Bernoulli likelihood function to model the reliability of an annotation <strong>L</strong>     <sub>      <em>ij</em>     </sub> w.r.t. the true label <em>y<sub>i</sub>     </em>, parameterized by both the data sample <strong>x</strong>     <sub>      <em>i</em>     </sub> and the annotator <strong>u</strong>     <sub>      <em>j</em>     </sub>: <div class="table-responsive" id="eq3">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \begin{split} p(\mathbf {L}_{ij} | \mathbf {x}_i, \mathbf {u}_j, y_i) &#x0026; = (1-\eta _t(\mathbf {x}_i, \mathbf {u}_j))^{|\mathbf {L}_{ij} - y_i|}\eta _t(\mathbf {x}_i, \mathbf {u}_j)^{1-|\mathbf {L}_{ij} - y_i|} \end{split} \end{equation} </span>       <br/>       <span class="equation-number">(5)</span>      </div>     </div> that is, the probability of the annotation being correct is <em>&#x03B7;</em>(<strong>x</strong>     <sub>      <em>i</em>     </sub>, <strong>u</strong>     <sub>      <em>j</em>     </sub>), which is defined as follows: <div class="table-responsive" id="eq4">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \begin{split} \eta (\mathbf {x}_i, \mathbf {u}_j) &#x0026; = (1+\exp (-\mathbf {u}_j^\intercal \mathbf {F}\mathbf {x}_i))^{-1} \end{split} \end{equation} </span>       <br/>       <span class="equation-number">(6)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$\mathbf {F}\in \mathbb {R}^{d\times k}$</span>     </span> is a parameter matrix to be learned. <strong>F</strong> is as a linear operator that transforms a data sample <strong>x</strong>     <sub>      <em>i</em>     </sub> of an arbitrary dimension <em>k</em> to an embedding of a low-dimension <em>d</em>, i.e., <span class="inline-equation"><span class="tex">$\mathbf {F}\mathbf {x}_i \in \mathbb {R}^d$</span>     </span>, which is then combined with the annotator embedding <strong>u</strong>     <sub>      <em>j</em>     </sub> via an inner product, to ultimately represent the reliability of the annotation. Intuitively, <strong>F</strong>     <strong>x</strong>     <sub>      <em>i</em>     </sub> can be interpreted as the representation of the data sample <strong>x</strong>     <sub>      <em>i</em>     </sub> by latent topics: each element <strong>F</strong>     <strong>x</strong>     <sub>      <em>i</em>     </sub> represents the extent to which the data sample belongs to one of <em>k</em> latent topics. Considering the annotator&#x0027;s expertise over different latent topics represented by <strong>u</strong>     <sub>      <em>j</em>     </sub>, the product between <strong>F</strong>     <strong>x</strong>     <sub>      <em>i</em>     </sub> and <strong>u</strong>     <sub>      <em>j</em>     </sub> can therefore be interpreted as the reliability of <strong>u</strong>     <sub>      <em>j</em>     </sub>&#x2019;s annotation to <strong>x</strong>     <sub>      <em>i</em>     </sub>. We use sigmoid function in Equation&#x00A0;<a class="eqn" href="#eq4">6</a> to bound reliability between 0 and 1, with 0 standing for completely unreliable and 1 for fully reliable.</p>    <p>With Equation&#x00A0;<a class="eqn" href="#eq4">6</a>, we could obtain a reliability score <em>&#x03B7;</em>(<strong>x</strong>     <sub>      <em>i</em>     </sub>, <strong>u</strong>     <sub>      <em>j</em>     </sub>) for each individual annotation <strong>L</strong>     <sub>      <em>ij</em>     </sub>. Therefore, the sparse annotation matrix <strong>L</strong>     <sub>      <em>ij</em>     </sub> will result in a sparse matrix whose entries are the corresponding reliability scores (learning these scores is formally described in Section&#x00A0;<a class="sec" href="#sec-14">4</a>). Given the sparsity of the annotation matrix, the low-dimensional assumption of the representations of the annotators <strong>u</strong>     <sub>      <em>j</em>     </sub> and the data sample <strong>F</strong>     <strong>x</strong>     <sub>      <em>i</em>     </sub> is not only critical to effectively learn annotation reliability, but also realistic &#x2013; the number of latent topics are often much smaller than the number of annotators and data samples.</p>    <p>Following the Bayesian approach, we assume that annotator embeddings are generated from a prior Gaussian probability, namely: <div class="table-responsive" id="Xeq3">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \mathbf {u}_j \sim \mathcal {N}(0, \sigma ^2\mathbf {I}) \end{equation} </span>       <br/>       <span class="equation-number">(7)</span>      </div>     </div> where <em>&#x03C3;</em>     <sup>2</sup> is variance and <strong>I</strong> is the identity matrix. This prior regularizes the latent topics, which helps to improve the robustness of the model.</p>    <p>     <strong>Remarks.</strong> Without loss of generality, the above formulation considers the binary classification case. It can be easily extended to a multi-class classification setting, by modeling <strong>L</strong>     <sub>      <em>ij</em>     </sub> (and <em>y<sub>i</sub>     </em>) as a vector whose <em>r</em>-th entry takes value 1 if the annotation (and true label) is class <em>r</em>, and 0 otherwise. We use the following Bernoulli probability to model the reliability of annotations: <div class="table-responsive" id="Xeq4">      <div class="display-equation">       <span class="tex mytex">\begin{equation} p(\mathbf {L}_{ij}|\mathbf {x}_i, \mathbf {u}_j, y_i) = (1-\eta (\mathbf {x}_i, \mathbf {u}_j))^{\frac{1}{2}\Vert \mathbf {L}_{ij} - y_i\Vert _2^2}\eta (\mathbf {x}_i, \mathbf {u}_j)^{1-\frac{1}{2}\Vert \mathbf {L}_{ij} - y_i\Vert _2^2} \end{equation} </span>       <br/>       <span class="equation-number">(8)</span>      </div>     </div>    </p>    <figure id="fig1">     <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186033/images/www2018-42-fig1.svg" class="img-responsive" alt="Figure 1"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 1:</span>      <span class="figure-title">Graphical model of the DALC framework.</span>     </div>    </figure>    </section>    <section id="sec-13">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> The Overall Framework</h3>     </div>    </header>    <p>The overall framework is depicted as a graphical model in Figure&#x00A0;<a class="fig" href="#fig1">1</a>. It combines both the previously introduced DL model and the learning-from-crowd model in a unified Bayesian framework. The joint probability of the framework is given by: <div class="table-responsive" id="eq5">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \begin{aligned} &#x0026; p(y_i, \mathbf {u}_j, \mathbf {L}_{ij} | \mathbf {x}_i, K, \sigma) \\ = &#x0026; \underbrace{\int p(y_i|\mathbf {x}_i, \mathcal {W})p(\mathcal {W}|K)d\mathcal {W}}_\text{The Bayesian DL model} \underbrace{ \vphantom{\int } p(\mathbf {L}_{ij} | \mathbf {x}_i, \mathbf {u}_j, y_i) p(\mathbf {u_j}|\sigma)}_\text{The LFTC model} \end{aligned} \end{equation} </span>       <br/>       <span class="equation-number">(9)</span>      </div>     </div> where for the DL model we use the full Bayesian treatment for the parameter <span class="inline-equation"><span class="tex">$\mathcal {W}$</span>     </span>, which is critical for representing model uncertainty in active learning; while for LFTC it is sufficient to learn annotator expertise <strong>u</strong>     <sub>      <em>j</em>     </sub> by point estimates, therefore we use the prior distribution as a regularizer.</p>    <p>The DALC framework described above can learn the expertise of annotators across different data samples; simultaneously, it enables DL models to learn from sparse and noisy annotations. The learning process will be presented in the next section. Once DALC learns on an initial set of crowd annotations, it can actively select informative data samples and annotators with high-expertise for these samples to execute the annotation task. These annotated data samples will then be used to retrain the DL model, so as to improve model performance. With such an active learning procedure, the DL model is expected to reach the optimal performance with minimum amount annotation effort from the crowd.</p>    <p>     <strong>Active Learning.</strong>In active learning, DALC selects the <em>k</em> most informative data samples and the annotator with the highest expertise for each of these data samples. The expertise of an annotator <em>u<sub>j</sub>     </em> w.r.t. a data sample <strong>x</strong>     <sub>      <em>i</em>     </sub> is quantified by <em>&#x03B7;</em>(<strong>x</strong>     <sub>      <em>i</em>     </sub>, <strong>u</strong>     <sub>      <em>j</em>     </sub>), as given by Equation&#x00A0;<a class="eqn" href="#eq4">6</a>. The informativeness of a sample is defined by model uncertainty, quantified by Shannon entropy: <div class="table-responsive" id="eq6">      <div class="display-equation">       <span class="tex mytex">\begin{align} \text{uncertainty}(x) &#x0026; = H[y|x, \mathcal {D}_{train}] \nonumber \\ &#x0026; = - \sum _{c}p(y=c|x, \mathcal {D}_{train}) \log p(y=c|x, \mathcal {D}_{train}) \nonumber \\ &#x0026; = - \sum _{c}(\frac{1}{T}\sum _t \hat{p}_c^t) \log (\frac{1}{T}\sum _t \hat{p}_c^t) \end{align} </span>       <br/>       <span class="equation-number">(10)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$\frac{1}{T}\sum _t \hat{p}_c^t$</span>     </span> is the averaged predicted probability of class <em>c</em> for <em>x</em>, sampled <em>T</em> times by Monte Carlo dropout. Note that <span class="inline-equation"><span class="tex">$\mathcal {W}$</span>     </span> is marginalized in the above equation as in Equation&#x00A0;<a class="eqn" href="#eq2">4</a>.</p>    </section>   </section>   <section id="sec-14">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> The Optimization Method</h2>    </div>    </header>    <p>This section describes the optimization method to learn the parameters of the DALC framework, including the DL parameters <span class="inline-equation"><span class="tex">$\mathcal {W}$</span>    </span>, and the LFTC parameters <strong>u</strong>    <sub>     <em>j</em>    </sub> (1 &#x2264; <em>j</em> &#x2264; <em>n</em>) and <strong>F</strong>.</p>    <p>The parameters are learned by maximizing the likelihood of the observed annotations <strong>L</strong> given the data <span class="inline-equation"><span class="tex">$\mathcal {X}$</span>    </span> and the annotators <span class="inline-equation"><span class="tex">$\mathcal {U}$</span>    </span>. Denoting all the parameters as <em>&#x0398;</em>, the optimization in the log space is formulated as: <div class="table-responsive" id="eq7">     <div class="display-equation">      <span class="tex mytex">\begin{equation} \begin{split} \underset{\Theta }{\mathrm{argmax}} \log \prod _i \prod _j p(\mathbf {L}_{ij} | \mathbf {x}_i, K, \mathbf {u}_j) p(\mathbf {u}_j |\sigma) \\ = \underset{\Theta }{\mathrm{argmax}} \sum _i \sum _j \log \sum _{y_i} p(y_i, \mathbf {u}_j, \mathbf {L}_{ij}| \mathbf {x}_i, K, \sigma) \end{split} \end{equation} </span>      <br/>      <span class="equation-number">(11)</span>     </div>    </div> where <em>p</em>(<em>y<sub>i</sub>    </em>, <strong>u</strong>    <sub>     <em>j</em>    </sub>, <strong>L</strong>    <sub>     <em>ij</em>    </sub>|<strong>x</strong>    <sub>     <em>i</em>    </sub>, <em>K</em>, <em>&#x03C3;</em>) is given by Equation&#x00A0;<a class="eqn" href="#eq5">9</a>. The unknown variables <em>y<sub>i</sub>    </em> (1 &#x2264; <em>i</em> &#x2264; <em>m</em>) makes it computationally infeasible to directly solve the optimization problem. DALC employs the expectation maximization (EM) algorithm [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0009">9</a>] to solve the problem.</p>    <p>    <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186033/images/www2018-42-img1.svg" class="img-responsive" alt="" longdesc=""/>    </p>    <section id="sec-15">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> EM Algorithm for DALC</h3>     </div>    </header>    <p>The EM algorithm iteratively takes two steps, i.e., the E-step and the M-step. In each iteration, the E-step estimates the true labels given the current parameters; the M-step then updates the estimation of the parameters given the newly estimated true labels.</p>    <p>     <strong>E-step.</strong> Using the Bayes rule, the true label is given by: <div class="table-responsive" id="eq8">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \begin{split} p(y_i) &#x0026; \triangleq p(y_i|\mathbf {L}_{i:}, \mathbf {x}_i, K, \mathbf {u}_j) p(\mathbf {u}_j |\sigma) \\ &#x0026; \propto \int p(y_i|\mathbf {x}_i, \mathcal {W}) p(\mathcal {W}|K)d\mathcal {W} \prod _j p(\mathbf {L}_{ij}|\mathbf {x}_i, \mathbf {u}_j, y_i) p(\mathbf {u}_j |\sigma) \end{split} \end{equation} </span>       <br/>       <span class="equation-number">(12)</span>      </div>     </div>    </p>    <p>Therefore, the true label is calculated based on both output of the Bayesian DL model and the LFTC model, as it is a function of the DL discriminator and the model of annotators. The prediction by the Bayesian DL model with the prior can be done as in Equation&#x00A0;<a class="eqn" href="#eq1">3</a>, while the output of the LFTC model can be calculated by Equation&#x00A0;<a class="eqn" href="#eq3">5</a>.</p>    <p>     <strong>M-step.</strong> Given the true label estimated by the E-step, we maximize the following likelihood function to estimate the parameters: <div class="table-responsive" id="eq9">      <div class="display-equation">       <span class="tex mytex">\begin{align} \mathcal {L} = &#x0026; \sum _i \sum _j \sum _{y_i} p(y_i) \log p(y_i, \mathbf {u}_j, \mathbf {L}_{ij} | \mathbf {x}_i, K, \sigma) \nonumber \\ = &#x0026; \sum _i \sum _j \sum _{y_i} p(y_i) \log \bigg [ \int p(y_i|\mathbf {x}_i, \mathcal {W}) p(\mathcal {W}|K)d\mathcal {W} \bigg . \nonumber \\ &#x0026; \bigg . \times p(\mathbf {L}_{ij}|\mathbf {x}_i, \mathbf {u}_j, y_i) p(\mathbf {u}_j|\sigma) \bigg ] \nonumber \\ = &#x0026; \sum _i \sum _j \sum _{y_i} p(y_i) \int \log p(y_i|\mathbf {x}_i, \mathcal {W}) p(\mathcal {W}|K) d\mathcal {W} \end{align} </span>       <br/>       <span class="equation-number">(13)</span>      </div>     </div>     <div class="table-responsive" id="eq10">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026; + \sum _i \sum _j \sum _{y_i} p(y_i) \left[\log p(\mathbf {L}_{ij}|y_i, \mathbf {x}_i, \mathbf {u}_j) + \log p(\mathbf {u}_j|\sigma)\right] \end{align} </span>       <br/>       <span class="equation-number">(14)</span>      </div>     </div> where <em>p</em>(<em>y</em>) is obtained by E-step (Equation <a class="eqn" href="#eq8">12</a>). With the above equation, M-step can therefore be decomposed to two parts, namely, Equation&#x00A0;<a class="eqn" href="#eq9">13</a> and <a class="eqn" href="#eq10">14</a>, which are independent from each other. The first part (i.e., Equation&#x00A0;<a class="eqn" href="#eq9">13</a>) is exactly the same as the objective function for training a Bayesian DL model, i.e., the cross-entropy loss function. It therefore can be optimized using the standard back-propagation method. The second part (i.e., Equation&#x00A0;<a class="eqn" href="#eq10">14</a>) optimizes the LFTC model, which can be solved via a stochastic gradient ascent (SGA) method that will be given in the next subsection. The overall algorithm is given in Algorithm&#x00A0;1.</p>    <p>     <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186033/images/www2018-42-img2.svg" class="img-responsive" alt="" longdesc=""/>    </p>    </section>    <section id="sec-16">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Learning the LFTC Parameters</h3>     </div>    </header>    <p>Learning the LFTC parameters is equivalent to solving the following optimization problem: <div class="table-responsive" id="eq11">      <div class="display-equation">       <span class="tex mytex">\begin{align} \underset{\mathbf {u}_j (1\le j\le n), \mathbf {F}}{\mathrm{max}} \mathcal {J} = &#x0026; \sum _i \sum _j \underbrace{\sum _{y_i} p(y_i) \left[\log p(\mathbf {L}_{ij}|y_i, \mathbf {x}_i, \mathbf {u}_j) + \log p(\mathbf {u}_j|\sigma)\right]}_\text{$\mathcal {J}_{ij}$} \nonumber \\ = &#x0026; \sum _i \sum _j \underbrace{\sum _{y_i} p(y_i) \log p(\mathbf {L}_{ij}|y_i, \mathbf {x}_i, \mathbf {u}_j)}_\text{$\mathcal {J}_1$: log-likelihood} \nonumber \\ &#x0026; + \sum _i \sum _j \underbrace{\sum _{y_i} p(y_i) \log p(\mathbf {u}_j|\sigma)}_\text{$\mathcal {J}_2$: regularization} \end{align} </span>       <br/>       <span class="equation-number">(15)</span>      </div>     </div> where we use <span class="inline-equation"><span class="tex">$\mathcal {J}_{ij}$</span>     </span> to denote the objective function for learning parameters from a single annotation, and <span class="inline-equation"><span class="tex">$\mathcal {J}_1, \mathcal {J}_2$</span>     </span> to respectively denote the log-likelihood and the regularization parts of <span class="inline-equation"><span class="tex">$\mathcal {J}_{ij}$</span>     </span>. Note that for the sake of clarity for deriving the gradients in the rest of this subsection, we formulate the optimization problem as a maximization problem instead of a minimization problem. The optimization problem is non-convex w.r.t. the parameters <strong>u</strong>     <sub>      <em>j</em>     </sub> (1 &#x2264; <em>j</em> &#x2264; <em>n</em>) and <strong>F</strong>. To solve the problem, we use alternative SGA, in which we alternately update <strong>u</strong>     <sub>      <em>j</em>     </sub> (1 &#x2264; <em>j</em> &#x2264; <em>n</em>) and <strong>F</strong> until convergence.</p>    <p>To derive the gradient of the parameters for SGA, we first derive the gradient of <em>&#x03B7;</em>(<strong>x</strong>     <sub>      <em>i</em>     </sub>, <strong>u</strong>     <sub>      <em>j</em>     </sub>) as below: <div class="table-responsive" id="Xeq5">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \frac{\partial \mathcal {J}_{ij}}{\partial \eta (\mathbf {x}_i, \mathbf {u}_j)} = \frac{\partial \mathcal {J}_1}{\partial \eta (\mathbf {x}_i, \mathbf {u}_j)} = \frac{p(y_i=\mathbf {L}_{ij})}{\eta (\mathbf {x}_i, \mathbf {u}_j)} - \frac{p(y_i\ne \mathbf {L}_{ij})}{1-\eta (\mathbf {x}_i, \mathbf {u}_j)} \end{equation} </span>       <br/>       <span class="equation-number">(16)</span>      </div>     </div> The gradients of <strong>u</strong>     <sub>      <em>j</em>     </sub> and <strong>F</strong> w.r.t. <em>&#x03B7;</em>(<strong>x</strong>     <sub>      <em>i</em>     </sub>, <strong>u</strong>     <sub>      <em>j</em>     </sub>) are given by: <div class="table-responsive" id="Xeq6">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \begin{split} \frac{\partial \eta (\mathbf {x}_i, \mathbf {u}_j)}{\partial \mathbf {u}_j} &#x0026; = \eta (\mathbf {x}_i, \mathbf {u}_j)(1-\eta (\mathbf {x}_i, \mathbf {u}_j)) \mathbf {F}\mathbf {x}_i \\ \frac{\partial \eta (\mathbf {x}_i, \mathbf {u}_j)}{\partial \mathbf {F}} &#x0026; = \eta (\mathbf {x}_i, \mathbf {u}_j)(1-\eta (\mathbf {x}_i, \mathbf {u}_j)) \mathbf {u}_j\mathbf {x}_i^\intercal \end{split} \end{equation} </span>       <br/>       <span class="equation-number">(17)</span>      </div>     </div> In addition, the gradient of <strong>u</strong>     <sub>      <em>j</em>     </sub> w.r.t. <span class="inline-equation"><span class="tex">$\mathcal {J}_2$</span>     </span> is: <div class="table-responsive" id="Xeq7">      <div class="display-equation">       <span class="tex mytex">\begin{equation} \frac{\partial \mathcal {J}_2}{\partial \mathbf {u}_j} = - 2\lambda \mathbf {u}_j \end{equation} </span>       <br/>       <span class="equation-number">(18)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$\lambda = \frac{1}{\sigma ^2}$</span>     </span>. Finally, notice that both parts of the objective function <span class="inline-equation"><span class="tex">$\mathcal {J}_1$</span>     </span> and <span class="inline-equation"><span class="tex">$\mathcal {J}_2$</span>     </span> are relevant to <strong>u</strong>     <sub>      <em>j</em>     </sub> (1 &#x2264; <em>j</em> &#x2264; <em>n</em>), while only <span class="inline-equation"><span class="tex">$\mathcal {J}_1$</span>     </span> is relevant to <strong>F</strong>. Therefore, we have the following gradients for the LFTC parameters: <div class="table-responsive" id="eq12">      <div class="display-equation">       <span class="tex mytex">\begin{align} \frac{\partial \mathcal {J}_{ij}}{\partial \mathbf {u}_j} &#x0026; = \frac{\partial \mathcal {J}_1}{\partial \eta (\mathbf {x}_i, \mathbf {u}_j)} \times \frac{\partial \eta (\mathbf {x}_i, \mathbf {u}_j)}{\partial \mathbf {u}_j} + \frac{\partial \mathcal {J}_2}{\partial \mathbf {u}_j} \end{align} </span>       <br/>       <span class="equation-number">(19)</span>      </div>     </div>     <div class="table-responsive" id="eq13">      <div class="display-equation">       <span class="tex mytex">\begin{align} \frac{\partial \mathcal {J}_{ij}}{\partial \mathbf {F}} &#x0026; = \frac{\partial \mathcal {J}_1}{\partial \eta (\mathbf {x}_i, \mathbf {u}_j)} \times \frac{\partial \eta (\mathbf {x}_i, \mathbf {u}_j)}{\partial \mathbf {F}} \end{align} </span>       <br/>       <span class="equation-number">(20)</span>      </div>     </div> With these gradients, we can learn the LFTC parameters with alternative SGA. The overall algorithm is given in Algorithm&#x00A0;2.</p>    </section>   </section>   <section id="sec-17">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Experiments and Results</h2>    </div>    </header>    <p>In this section, we conduct experiments to evaluate the performance of our proposed DALC framework. We aim at answering the following questions: 1) how effectively DALC can infer the true labels, and learn annotator expertise and annotation reliability, 2) how effectively DALC can train DL models from noisy and sparse crowd annotations, and 3) how effective DALC is in reducing the amount of annotations while training a high-performance DL model.</p>    <section id="sec-18">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.1</span> Experimental Settings</h3>     </div>    </header>    <p>     <strong>Datasets.</strong>We use a real-world dataset from Amazon Alexa, which contains users&#x2019; queries and their confirmation on their query intents. The dataset contains 32,220 queries annotated by 10,006 users, who contribute a total of 49,958 annotations. The annotation matrix has a sparsity of 99.98%. In addition to user annotated data, Alexa further contains a separate training dataset of over 50K queries with golden labels (i.e., labels with high agreement among users measured by conversion rates and judged by experts). To investigate the capability of DALC in inferring the true labels and uncovering the ground truth annotator expertise and annotation reliability, we created a synthetic dataset by simulating user annotations based on golden labels in the Alexa dataset.</p>    <p>     <strong>Comparison Methods.</strong>To demonstrate the performance of our proposed framework in model training, we compare the following multi-annotator methods: 1) <strong>MV</strong>: infers the true labels with majority voting [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0036">36</a>]; 2) <strong>LFC</strong>: learns the true labels with learning-from-crowds [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0044">44</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>]; 3) <strong>STAL</strong>: Self-taught learning-from-crowds proposed in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>]; 4) <strong>DLC/LR</strong>: our proposed framework where the target machine learning model is a logistic regression model; 5) <strong>DLC/Sparse</strong>: our proposed framework where the target model is a DL model, which learns annotator expertise without low-rank approximation &#x2013; the same method used by [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0036">36</a>] and [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>]; 6) <strong>DLC</strong>: our framework where the target machine learning model is a DL model that learns annotator expertise with low-rank approximation. All compared methods, including ours, are aimed at training machine learning models on crowd annotations. We do not compare to methods designed only for output aggregation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0043">43</a>]. Note that all existing methods (MV, LFC, and STAL) train a logistic regression model, and that DLC/LR, DLC/Sparse and DLC are our proposed framework variants without the active learning process.</p>    <p>To demonstrate the effectiveness of DALC in active learning, we compare the following variants: 1) <strong>RD+DLC</strong>: randomly selects data samples and crowds for annotation; 2) <strong>AD+DLC</strong>: actively selects data samples while randomly selecting the crowds for annotation; 3) <strong>AC+DLC</strong>: randomly selects data samples while actively selecting the crowds for annotation; 4) <strong>DALC</strong>: actively selects both data samples and high-expertise annotators.</p>    <p>     <strong>DL Model &#x0026; Parameter Settings.</strong> We use a feed-forward neural network for the intent classification task in Alexa, which was proven to be more effective in practice than recurrent networks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0033">33</a>]. Optimal parameters are empirically found based on a held-out validation set. We apply a grid search in {0.0001, 0.001, 0.01, 0.1, 1} for both the learning rate and regularization coefficient. A grid search in {5, 10, 20, 50, 100} is applied for both the number of components of Gaussian Mixture Model in STAL and the number of latent topics (<em>d</em>) in our framework. For the DL model, the dimension of the embedding is set to 200 and the number of hidden units is selected from the option set {32, 64, 128, 256}. The dropout value is validated from the option set {0.10, 0.25, 0.50}. Model training is performed using a RMSprop stochastic gradient descent optimization algorithm [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0020">20</a>] with mini-batches of 128 data samples.</p>    <p>     <strong>Evaluation Metrics.</strong> We use accuracy and Area Under the ROC Curve (AUC) &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>] to measure the performance of the selected methods. Higher accuracy and AUC values indicate better performance.</p>    </section>    <section id="sec-19">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.2</span> Learning from Targeted Crowds</h3>     </div>    </header>    <p>For the 50K queries with golden labels in Alexa, we simulate 50K users by creating for each of them a random vector <strong>u</strong>     <sub>      <em>j</em>     </sub> of size <em>d</em> = 10, whose elements are sampled from a uniform distribution (&#x2212; 0.3, 0.6). We then generate a random matrix <strong>F</strong> whose elements are drawn from the same distribution. Based on <strong>u</strong>     <sub>      <em>j</em>     </sub> and <strong>F</strong> we calculate the annotation reliability for each query <strong>x</strong>     <sub>      <em>i</em>     </sub> as <span class="inline-equation"><span class="tex">$\eta (\mathbf {x}_i, \mathbf {u_j}) = (1+\exp (\mathbf {u}_j^\intercal \mathbf {F}\mathbf {x}_i))^{-1}$</span>     </span>. For individual users, the expertise is then represented by the percentage of correct annotations among all annotations they provide. Next, the annotations <strong>L</strong>     <sub>      <em>ij</em>     </sub> created by each user are assigned with either the same label as the golden label if <em>&#x03B7;</em>(<strong>x</strong>     <sub>      <em>i</em>     </sub>, <strong>u<sub>j</sub>     </strong>) > 0.5, or switched to a wrong label otherwise. Finally, we control for different annotation sparsity by randomly removing 1 &#x2212; <em>&#x03C1;</em> of the annotations for each user, where <em>&#x03C1;</em> &#x2208; {0.0001, 0.001, 0.01, 0.1}.</p>    <p>Figures&#x00A0;<a class="fig" href="#fig2">2</a> (a) and (b) show the histogram of annotation reliability and user expertise in the synthetic dataset with <em>&#x03C1;</em> = 0.0001, respectively. It can be observed that annotation reliability is Gaussian-distributed, with a mean value being around 0.65. User expertise, in contrast, is not Gaussian. This is due to the <em>discrepancy</em> between annotation reliability and annotation correctness: an annotation is correct as long as <em>&#x03B7;</em>(<strong>x</strong>     <sub>      <em>i</em>     </sub>, <strong>u<sub>j</sub>     </strong>) is greater than 0.5, either being 0.55 or 0.95. This will make an influence on the capability of DALC in learning annotation reliability, as we show later. <figure id="fig2">      <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186033/images/www2018-42-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Upper figures are the histograms of (a) annotation reliability and (b) user expertise in the synthetic dataset (<em>&#x03C1;</em> = 0.0001); lower figures are the scatter plots of (c) annotation reliability learned by DALC vs. the ground truth, and (d) user expertise learned by DALC vs. the ground truth (fitted by a linear function).</span>      </div>     </figure>    </p>    <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">Accuracy of labels inferred by DALC (row 2), correlation between the DALC learned annotation reliability, user expertise and the ground truth (rows 3 and 4).</span>     </div>     <table class="table">      <thead>       <tr>       <th style="text-align:left;">        <strong>Annotation Sparsity (1 &#x2212; <em>&#x03C1;</em>)</strong>       </th>       <th style="text-align:right;">0.0001</th>       <th style="text-align:right;">0.001</th>       <th style="text-align:right;">0.01</th>       <th style="text-align:right;">0.1</th>       </tr>      </thead>      <tbody>       <tr>       <td style="text-align:left;">Inferred Label Accuracy</td>       <td style="text-align:right;">99.06%</td>       <td style="text-align:right;">99.96%</td>       <td style="text-align:right;">99.98%</td>       <td style="text-align:right;">100%</td>       </tr>       <tr>       <td style="text-align:left;">Anno. Reliability Correlation</td>       <td style="text-align:right;">0.5751</td>       <td style="text-align:right;">0.5891</td>       <td style="text-align:right;">0.6323</td>       <td style="text-align:right;">0.6768</td>       </tr>       <tr>       <td style="text-align:left;">User Expertise Correlation</td>       <td style="text-align:right;">0.9438</td>       <td style="text-align:right;">0.9921</td>       <td style="text-align:right;">0.9956</td>       <td style="text-align:right;">0.9998</td>       </tr>      </tbody>     </table>    </div>    <p>     <strong>Inferring True Labels.</strong> Table&#x00A0;<a class="tbl" href="#tab1">1</a> (row 2) reports the accuracy of the labels inferred by DALC w.r.t. the golden labels. DALC shows strong capability in inferring the true labels, even for highly sparse annotations (e.g., <em>&#x03C1;</em> = 0.0001). Recall that the annotations have an average reliability of 0.65 (Figure&#x00A0;<a class="fig" href="#fig2">2</a> (a)). Despite this, we can observe that DALC can effectively recover the true labels from annotations that are both highly noisy and sparse.</p>    <p>     <strong>Annotation Reliability &#x0026; Annotator Expertise.</strong>Figures&#x00A0;<a class="fig" href="#fig2">2</a> (c) and (d) compare the user expertise and annotation reliability learned by DALC with the ground truth for the case when <em>&#x03C1;</em> = 0.0001. For conciseness, we do not visualize datasets of other sparsity; however, similar observations as below can be obtained. First, DALC shows good performance in discriminating low reliability annotations from highly reliable ones; and, the reliability learned by DALC shows a positive correlation with the ground truth annotation reliability &#x2013; this is verified by Table&#x00A0;<a class="tbl" href="#tab1">1</a> (row 3). However, we can observe that the correlation is not linear: the scatter plot of learned annotation reliability vs. the ground truth, as given in Figure&#x00A0;<a class="fig" href="#fig2">2</a> (c), exhibits a sigmoid shape. That is, the learned reliability for annotations whose ground truth reliability is greater than 0.5 can be as high as 1, though the lower bound increases for more reliable annotations. For annotations whose ground truth reliability is less than 0.5, the learned reliability can be as low as 0, thought the upper bound decreases for less reliable annotations. Such a phenomenon is due to the discrepancy between the annotation reliability and annotation correctness, as mentioned before. We note that the discrepancy, and as a result, the imperfectness in learning annotation reliability, is <em>unavoidable</em> since DALC learns the reliability of each single annotation by taking only annotations as the input, which is a challenging yet realistic task in real-applications. Finally, despite the imperfectness in learning reliability for individual annotation, DALC can accurately recover user expertise even for highly sparse annotations, as shown in Table&#x00A0;<a class="tbl" href="#tab1">1</a> (row 4) and Figure&#x00A0;<a class="fig" href="#fig2">2</a> (d).</p>    <p>In summary, DALC demonstrates strong capabilities in inferring the true labels and in learning annotator expertise, which are robust to data sparsity and noises.</p>    </section>    <section id="sec-20">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.3</span> Performance in Model Training</h3>     </div>    </header>    <p>We now compare the performance of our proposed framework in model training with state-of-the-art multi-annotator model training methods. Table&#x00A0;<a class="tbl" href="#tab2">2</a> compares our approach with benchmark methods in terms of accuracy and AUC on the Alexa dataset. From these results, we make the following observations.</p>    <p>Multi-annotator model training methods that use logistic regression to model the relationship between features and labels, including all existing methods (i.e., MV, LFC, and STAL) and DLC/LR, perform worse than deep learning based model training methods. The large gap between the performance of these two types of methods &#x2013; e.g., DLC/Sparse outperforms DLC/LR by 6% and 5% in terms of accuracy and AUC, respectively &#x2013; clearly shows the advantage of deep learning models.</p>    <p>Among logistic regression based methods, MV is outperformed by all the others, which implies the effectiveness of modeling annotator expertise in inferring true labels. LFC is outperformed by both STAL and DLC/LR. This is due to the fact that LFC suffers from the data sparsity problem in crowd annotations, as it takes the original feature representation of the data samples as input to model annotation reliability. In contrast, DLC/LR uncovers the low-rank structure of crowd annotations and maps original feature representations to low-dimensional representations for modeling annotation reliability, which greatly helps to resolve the annotation sparsity issue. Interestingly, STAL achieves comparable performance with DLC/LR. This is because while STAL is not specifically designed for coping with sparse annotations, the Gaussian Mixture Model employed by STAL reduces annotation dimensionality, which also helps to tackle the sparsity issue.</p>    <p>For the two variants of our proposed framework that train a deep learning model, DLC significantly outperforms DLC/Sparse (Paired t-test, <em>p</em>-value < 0.001), which again implies the effectiveness of modeling the low-rank structure of crowd annotations to resolve the sparsity issue. Notably, the improvement brought by low-rank modeling of crowd annotations for deep learning models is larger than that for logistic regression. This on the one hand, can be attributed to the capability of deep learning models in capturing complex patterns in the data, which boosts the upper bound performance of deep learning models; on the other hand, the observation also suggests that sparse modeling is an effective way to improve the performance of deep learning models.</p>    <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Performance of model trained using different multi-annotator methods on the Alexa dataset.</span>     </div>     <table class="table">      <thead>       <tr>       <th style="text-align:center;">        <strong>Methods</strong>       </th>       <th style="text-align:center;">        <strong>Accuracy</strong>       </th>       <th>        <strong>AUC</strong>       </th>       </tr>      </thead>      <tbody>       <tr>       <td style="text-align:center;">MV</td>       <td style="text-align:center;">0.6068</td>       <td>0.6302</td>       </tr>       <tr>       <td style="text-align:center;">LFC</td>       <td style="text-align:center;">0.6070</td>       <td>0.6304</td>       </tr>       <tr>       <td style="text-align:center;">STAL</td>       <td style="text-align:center;">0.6091</td>       <td>0.6325</td>       </tr>       <tr>       <td style="text-align:center;">DLC/LR</td>       <td style="text-align:center;">0.6093</td>       <td>0.6325</td>       </tr>       <tr>       <td style="text-align:center;">DLC/Sparse</td>       <td style="text-align:center;">0.6710</td>       <td>0.6860</td>       </tr>       <tr>       <td style="text-align:center;">DLC</td>       <td style="text-align:center;">        <strong>0.6886</strong>       </td>       <td>        <strong>0.7235</strong>       </td>       </tr>      </tbody>     </table>    </div>    <figure id="fig3">     <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186033/images/www2018-42-fig3.jpg" class="img-responsive" alt="Figure 3"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 3:</span>      <span class="figure-title">The learned expertise of users in the Alexa dataset.</span>     </div>    </figure>    <figure id="fig4">     <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186033/images/www2018-42-fig4.jpg" class="img-responsive" alt="Figure 4"      longdesc=""/>     <div class="figure-caption">      <span class="figure-number">Figure 4:</span>      <span class="figure-title">The impacts of different hyper-parameter settings, including the dimensionality of the latent topics (<em>d</em>) and the regularization coefficient <em>&#x03BB;</em>, on model training performance measured by accuracy (a) and AUC (b).</span>     </div>    </figure>    <p>     <strong>Distribution of Annotator Expertise.</strong> An advantage of our proposed framework is that it learns annotator expertise, which helps task owners understand the reliability of annotations. It can further be used for annotator selection in the active learning process, which will be discussed in the next subsection. The learned user expertise is shown in Figure&#x00A0;<a class="fig" href="#fig3">3</a>. The average user expertise in Alexa is 0.88, indicating that users can generally provide high-quality annotations. Such annotation quality, however, is not fully applicable for Alexa in production, which motivates the need for modeling user expertise and annotation reliability.</p>    <p>     <strong>Sensitivity to Hyper-parameters.</strong>We investigate the impact of the number of latent topics <em>d</em> and the regularization coefficient <em>&#x03BB;</em> which represents the regularization strength for annotator embeddings on the performance of the trained model. Results are shown in Figures&#x00A0;<a class="fig" href="#fig4">4</a> (a) and (b). As <em>d</em> varies from small to large, the performance of the trained model first increases then decreases, with the maximum reached at <em>d</em> = 10. Similar profile can be observed for <em>&#x03BB;</em>, i.e., the performance of the trained model first increases then decrease when <em>&#x03BB;</em> varies from small to large, with the optimal setting reached at <em>&#x03BB;</em> = 0.01. The performance variations across different hyper-parameter settings suggest the need for parameter selection in the task; the similarity in performance variation across <em>d</em> and <em>&#x03BB;</em> shows the robustness of DALC.</p>    </section>    <section id="sec-21">    <header>     <div class="title-info">      <h3>       <span class="section-number">5.4</span> Performance in Active Learning</h3>     </div>    </header>    <p>We now investigate the active learning performance of the compared methods on our real-world Alexa dataset. We separate the dataset into two parts, using 15K data samples for evaluating active learning performance and the rest of them to learn annotation reliability, which is used to guide the active selection of annotators. The active learning process is performed as follows. At each step, the model selects a certain amount of data samples with annotations, which is inserted to the existing training data to retrain the model; the performance of the retrained model is then measured using accuracy and AUC. Note that in each iteration the retrained model is used to select crowd annotations for the next iteration. Results are shown in Figure&#x00A0;<a class="fig" href="#fig5">5</a>.</p>    <p>With increased amount of newly selected data samples for model retraining, the performance generally increases. Both AC+DLC and AD+DLC outperform RD+DLC method, showing that the actively selected data samples and crowd annotations are both beneficial to model training. The fact that AD+DLC generally performs better than AC+DLC suggests that selecting the right data samples contributes more to the improvement of model performance. DALC outperforms all compared methods; when compared with the random selection method, it achieves an improvement of 1.03% in Accuracy and 2.41% in AUC when 15K data samples are selected. Interestingly, it can be observed that for DALC, a significant improvement margin over the compared methods is achieved when more than 10000 queries are selected. This confirms that deep learning models require large amount of data for model training, which further supports our motivation for using active learning to reduce crowd annotation efforts.</p>    <p>Most importantly, we observe no significant difference of model performance between DALC and DLC trained on the same amount of data samples. In other words, by selecting annotations contributed by high-expertise users, we are able to reduce the number of annotations from 23.6K to 15K (reduced by 36.53%) while preserving the same model performance. This clearly demonstrates the effectiveness of DALC in active learning. As a final remark, we note that our evaluation was limited to offline experiments; online settings require to further consider worker availability and possibly, the trade-off between labeling a new data sample and re-labeling an existing data sample [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>], which is left for future work. <figure id="fig5">      <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186033/images/www2018-42-fig5.jpg" class="img-responsive" alt="Figure 5"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 5:</span>       <span class="figure-title">Active learning performance of DALC variants on the Alexa dataset measured by accuracy (a) and AUC (b).</span>      </div>     </figure>    </p>    </section>   </section>   <section id="sec-22">    <header>    <div class="title-info">     <h2>      <span class="section-number">6</span> Conclusions</h2>    </div>    </header>    <p>We presented a Bayesian framework that unifies both the deep learning and the learning-from-targeted-crowd models, which are able to accurately learn annotator expertise and infer true labels from noisy and sparse crowd annotations. The framework enables any deep learning model to actively learn from targeted crowds, thus reducing the data annotation effort while reaching the optimal efficacy in training deep learning models. We extensively evaluated our framework in both synthetic and real-world datasets and showed that it consistently outperformed the state of the art. Our framework seamlessly connects deep learning models with targeted crowds; as a result, it opens up new research directions to explore worker/task modeling paradigm in crowdsourcing environments towards more advanced human-in-the-loop systems.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">Sungjin Ahn, Anoop Korattikara, and Max Welling. 2012. Bayesian Posterior Sampling via Stochastic Gradient Fisher Scoring. <em>      <em>arXiv preprint arXiv:1206.6380</em>     </em>(2012).</li>    <li id="BibPLXBIB0002" label="[2]">Alessandro Bozzon, Marco Brambilla, and Stefano Ceri. 2012. Answering Search Queries with Crowdsearcher. In <em>      <em>Proceedings of the 21st International Conference on World Wide Web (WWW)</em>     </em>. ACM, 1009&#x2013;1018.</li>    <li id="BibPLXBIB0003" label="[3]">Alessandro Bozzon, Piero Fraternali, Luca Galli, and Roula Karam. 2014. Modeling Crowdsourcing Scenarios in Socially-enabled Human Computation Applications. <em>      <em>Journal on Data Semantics (JoDS)</em>     </em>3, 3 (2014), 169&#x2013;188.</li>    <li id="BibPLXBIB0004" label="[4]">David&#x00A0;A Cohn, Zoubin Ghahramani, and Michael&#x00A0;I Jordan. 1996. Active Learning with Statistical Models. <em>      <em>Journal of Artificial Intelligence Research (JAIR)</em>     </em> (1996).</li>    <li id="BibPLXBIB0005" label="[5]">Alexander&#x00A0;Philip Dawid and Allan&#x00A0;M Skene. 1979. Maximum Likelihood Estimation of Observer Error-rates Using the EM Algorithm. <em>      <em>Applied statistics</em>     </em> (1979), 20&#x2013;28.</li>    <li id="BibPLXBIB0006" label="[6]">Victor De&#x00A0;Boer, Michiel Hildebrand, Lora Aroyo, Pieter De&#x00A0;Leenheer, Chris Dijkshoorn, Binyam Tesfa, and Guus Schreiber. Nichesourcing: Harnessing the Power of Crowds of Experts.. In <em>      <em>Knowledge Engineering and Knowledge Management</em>     </em>. Springer, 16&#x2013;20.</li>    <li id="BibPLXBIB0007" label="[7]">Gianluca Demartini. 2015. Hybrid Human&#x2013;machine Information Systems: Challenges and Opportunities. <em>      <em>Computer Networks</em>     </em>90(2015), 5&#x2013;13.</li>    <li id="BibPLXBIB0008" label="[8]">Gianluca Demartini, Djellel&#x00A0;Eddine Difallah, and Philippe Cudr&#x00E9;-Mauroux. 2012. ZenCrowd: Leveraging Probabilistic Reasoning and Crowdsourcing Techniques for Large-scale Entity Linking. In <em>      <em>Proceedings of the 21st International Conference on World Wide Web (WWW)</em>     </em>. ACM, 469&#x2013;478.</li>    <li id="BibPLXBIB0009" label="[9]">Arthur&#x00A0;P Dempster, Nan&#x00A0;M Laird, and Donald&#x00A0;B Rubin. 1977. Maximum Likelihood from Incomplete Data via the EM Algorithm. <em>      <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>     </em> (1977), 1&#x2013;38.</li>    <li id="BibPLXBIB0010" label="[10]">Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A Large-scale Hierarchical Image Database. In <em>      <em>Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>     </em>. IEEE, 248&#x2013;255.</li>    <li id="BibPLXBIB0011" label="[11]">Meng Fang, Xingquan Zhu, Bin Li, Wei Ding, and Xindong Wu. 2012. Self-taught Active Learning from Crowds. In <em>      <em>Proceedings of the 12th IEEE International Conference on Data Mining (ICDM)</em>     </em>. IEEE, 858&#x2013;863.</li>    <li id="BibPLXBIB0012" label="[12]">Michael&#x00A0;J Franklin, Donald Kossmann, Tim Kraska, Sukriti Ramesh, and Reynold Xin. 2011. CrowdDB: Answering Queries with Crowdsourcing. In <em>      <em>Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data (SIGMOD)</em>     </em>. ACM, 61&#x2013;72.</li>    <li id="BibPLXBIB0013" label="[13]">Jerome Friedman, Trevor Hastie, and Robert Tibshirani. 2001. <em>      <em>The Elements of Statistical Learning</em>     </em>. Vol.&#x00A0;1. Springer Series in Statistics.</li>    <li id="BibPLXBIB0014" label="[14]">Ujwal Gadiraju, Jie Yang, and Alessandro Bozzon. 2017. Clarity is a Worthwhile Quality &#x2013; On the Role of Task Clarity in Microtask Crowdsourcing. In <em>      <em>Proceedings of the 28th ACM Conference on Hypertext and Social Media (HyperText)</em>     </em>. 5&#x2013;14.</li>    <li id="BibPLXBIB0015" label="[15]">Yarin Gal and Zoubin Ghahramani. 2016. Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning. In <em>      <em>Proceedings of the 33rd International Conference on Machine Learning (ICML)</em>     </em>. 1050&#x2013;1059.</li>    <li id="BibPLXBIB0016" label="[16]">Yarin Gal, Riashat Islam, and Zoubin Ghahramani. 2017. Deep Bayesian Active Learning with Image Data. <em>      <em>Proceedings of the 34th International Conference on Machine Learning (ICML)</em>     </em> (2017).</li>    <li id="BibPLXBIB0017" label="[17]">Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. <em>      <em>Deep Learning</em>     </em>. MIT Press. <a class="link-inline force-break" href="http://www.deeplearningbook.org">http://www.deeplearningbook.org</a>.</li>    <li id="BibPLXBIB0018" label="[18]">Alex Graves, Abdelrahman Mohamed, and Geoffrey Hinton. 2013. Speech Recognition with Deep Recurrent Neural Networks. In <em>      <em>Proceedings of the 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>     </em>. IEEE, 6645&#x2013;6649.</li>    <li id="BibPLXBIB0019" label="[19]">Michael Heilman and Noah&#x00A0;A Smith. 2010. Rating Computer-generated Questions with Mechanical Turk. In <em>      <em>Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&#x0027;s Mechanical Turk</em>     </em>. 35&#x2013;40.</li>    <li id="BibPLXBIB0020" label="[20]">G Hinton, N Srivastava, and K Swersky. 2012. RMSProp: Divide the gradient by a running average of its recent magnitude. <em>      <em>Neural Networks for Machine Learning, Coursera Lecture 6e</em>     </em> (2012).</li>    <li id="BibPLXBIB0021" label="[21]">Geoffrey&#x00A0;E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan&#x00A0;R Salakhutdinov. 2012. Improving Neural Networks by Preventing Co-adaptation of Feature Detectors. <em>      <em>arXiv preprint arXiv:1207.0580</em>     </em>(2012).</li>    <li id="BibPLXBIB0022" label="[22]">Panagiotis&#x00A0;G Ipeirotis and Evgeniy Gabrilovich. 2014. Quizz: Targeted Crowdsourcing with a Billion (Potential) Users. In <em>      <em>Proceedings of the 23rd International Conference on World Wide Web (WWW)</em>     </em>. ACM, 143&#x2013;154.</li>    <li id="BibPLXBIB0023" label="[23]">Andreas Krause, Ajit Singh, and Carlos Guestrin. 2008. Near-optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies. <em>      <em>Journal of Machine Learning Research (JMLR)</em>     </em>9, Feb (2008), 235&#x2013;284.</li>    <li id="BibPLXBIB0024" label="[24]">Alex Krizhevsky, Ilya Sutskever, and Geoffrey&#x00A0;E Hinton. 2012. Imagenet Classification with Deep Convolutional Neural Networks. In <em>      <em>Advances in Neural Information Processing Systems (NIPS)</em>     </em>. 1097&#x2013;1105.</li>    <li id="BibPLXBIB0025" label="[25]">Edith Law and Luis&#x00A0;von Ahn. 2011. Human Computation. <em>      <em>Synthesis Lectures on Artificial Intelligence and Machine Learning</em>     </em>5, 3(2011), 1&#x2013;121.</li>    <li id="BibPLXBIB0026" label="[26]">Florian Laws, Christian Scheible, and Hinrich Sch&#x00FC;tze. 2011. Active Learning with Amazon Mechanical Turk. In <em>      <em>Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>     </em>. Association for Computational Linguistics, 1546&#x2013;1556.</li>    <li id="BibPLXBIB0027" label="[27]">Matthew Lease. 2011. On Quality Control and Machine Learning in Crowdsourcing. In <em>      <em>Proceedings of the 3rd Human Computation Workshop (HCOMP)</em>     </em>. AAAI, 97&#x2013;102.</li>    <li id="BibPLXBIB0028" label="[28]">David&#x00A0;D Lewis and William&#x00A0;A Gale. 1994. A Sequential Algorithm for Training Text Classifiers. In <em>      <em>Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)</em>     </em>. ACM, 3&#x2013;12.</li>    <li id="BibPLXBIB0029" label="[29]">Christopher&#x00A0;H Lin, Mausam, Daniel&#x00A0;S Weld, and others. 2014. To Re(label), or Not to Re(label). In <em>      <em>Proceedings of the 2nd AAAI Conference on Human Computation and Crowdsourcing (HCOMP)</em>     </em>. AAAI, 1&#x2013;8.</li>    <li id="BibPLXBIB0030" label="[30]">Bart Mellebeek, Francesc Benavent, Jens Grivolla, Joan Codina, Marta&#x00A0;R Costa-Jussa, and Rafael Banchs. 2010. Opinion Mining of Spanish Customer Comments with Non-expert Annotations on Mechanical Turk. In <em>      <em>Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&#x0027;s Mechanical Turk</em>     </em>. 114&#x2013;121.</li>    <li id="BibPLXBIB0031" label="[31]">Vikas&#x00A0;C Raykar, Shipeng Yu, Linda&#x00A0;H Zhao, Gerardo&#x00A0;Hermosillo Valadez, Charles Florin, Luca Bogoni, and Linda Moy. 2010. Learning from Crowds. <em>      <em>Journal of Machine Learning Research (JMLR)</em>     </em>11, Apr(2010), 1297&#x2013;1322.</li>    <li id="BibPLXBIB0032" label="[32]">Nicholas Roy and Andrew McCallum. 2001. Toward Optimal Active Learning Through Monte Carlo Estimation of Error Reduction. <em>      <em>Proceedings of the 18th International Conference on Machine Learning (ICML)</em>     </em> (2001), 441&#x2013;448.</li>    <li id="BibPLXBIB0033" label="[33]">David&#x00A0;E Rumelhart, Geoffrey&#x00A0;E Hinton, Ronald&#x00A0;J Williams, and others. 1988. Learning Representations by Back-propagating Errors. <em>      <em>Cognitive Modeling</em>     </em>5, 3 (1988), 1.</li>    <li id="BibPLXBIB0034" label="[34]">Burr Settles. 2010. Active Learning Literature Survey. <em>      <em>University of Wisconsin, Madison</em>     </em>52, 55-66 (2010), 11.</li>    <li id="BibPLXBIB0035" label="[35]">H&#x00A0;Sebastian Seung, Manfred Opper, and Haim Sompolinsky. 1992. Query by Committee. In <em>      <em>Proceedings of the 5th Annual Workshop on Computational Learning Theory (COLT)</em>     </em>. ACM, 287&#x2013;294.</li>    <li id="BibPLXBIB0036" label="[36]">Victor&#x00A0;S Sheng, Foster Provost, and Panagiotis&#x00A0;G Ipeirotis. 2008. Get Another Label? Improving Data Quality and Data Mining Using Multiple, Noisy Labelers. In <em>      <em>Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</em>     </em>. ACM, 614&#x2013;622.</li>    <li id="BibPLXBIB0037" label="[37]">Nitish Srivastava, Geoffrey&#x00A0;E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a Simple Way to Prevent Neural Networks from Overfitting.<em>      <em>Journal of Machine Learning Research (JMLR)</em>     </em>15, 1 (2014), 1929&#x2013;1958.</li>    <li id="BibPLXBIB0038" label="[38]">Ilya Sutskever, Oriol Vinyals, and Quoc&#x00A0;V Le. 2014. Sequence to Sequence Learning with Neural Networks. In <em>      <em>Advances in Neural Information Processing Systems (NIPS)</em>     </em>. 3104&#x2013;3112.</li>    <li id="BibPLXBIB0039" label="[39]">Yuandong Tian and Jun Zhu. 2012. Learning from Crowds in the Presence of Schools of Thought. In <em>      <em>Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</em>     </em>. ACM, 226&#x2013;234.</li>    <li id="BibPLXBIB0040" label="[40]">Luis Von&#x00A0;Ahn and Laura Dabbish. 2008. Designing Games with a Purpose. <em>      <em>Commun. ACM</em>     </em>51, 8 (2008), 58&#x2013;67.</li>    <li id="BibPLXBIB0041" label="[41]">Luis Von&#x00A0;Ahn, Benjamin Maurer, Colin McMillen, David Abraham, and Manuel Blum. 2008. Recaptcha: Human-based Character Recognition via Web Security Measures. <em>      <em>Science</em>     </em>321, 5895 (2008), 1465&#x2013;1468.</li>    <li id="BibPLXBIB0042" label="[42]">Max Welling and Yee&#x00A0;W Teh. 2011. Bayesian Learning via Sochastic Gradient Langevin Dynamics. In <em>      <em>Proceedings of the 28th International Conference on Machine Learning (ICML)</em>     </em>. 681&#x2013;688.</li>    <li id="BibPLXBIB0043" label="[43]">Jacob Whitehill, Ting-fan Wu, Jacob Bergsma, Javier&#x00A0;R Movellan, and Paul&#x00A0;L Ruvolo. 2009. Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise. In <em>      <em>Advances in Neural Information Processing Systems (NIPS)</em>     </em>. 2035&#x2013;2043.</li>    <li id="BibPLXBIB0044" label="[44]">Yan Yan, Glenn&#x00A0;M Fung, R&#x00F3;mer Rosales, and Jennifer&#x00A0;G Dy. 2011. Active Learning from Crowds. In <em>      <em>Proceedings of the 28th International Conference on Machine Learning (ICML)</em>     </em>. 1161&#x2013;1168.</li>    <li id="BibPLXBIB0045" label="[45]">Yan Yan, R&#x00F3;mer Rosales, Glenn Fung, Mark&#x00A0;W Schmidt, Gerardo&#x00A0;H Valadez, Luca Bogoni, Linda Moy, and Jennifer&#x00A0;G Dy. 2010. Modeling Annotator Expertise: Learning When Everybody Knows a Bit of Something. In <em>      <em>International Conference on Artificial Intelligence and Statistics (AISTATS)</em>     </em>. 932&#x2013;939.</li>    <li id="BibPLXBIB0046" label="[46]">Jie Yang, Claudia Hauff, Alessandro Bozzon, and Geert-Jan Houben. 2014. Asking the Right Question in Collaborative Q&#x0026;A Systems. In <em>      <em>Proceedings of the 25th ACM Conference on Hypertext and Social Media (HyperText)</em>     </em>. ACM, 179&#x2013;189.</li>    <li id="BibPLXBIB0047" label="[47]">Jie Yang, Judith Redi, Gianluca Demartini, and Alessandro Bozzon. 2016. Modeling Task Complexity in Crowdsourcing. In <em>      <em>Proceedings of the 4th AAAI Conference on Human Computation and Crowdsourcing (HCOMP)</em>     </em>. AAAI, 249&#x2013;258.</li>    <li id="BibPLXBIB0048" label="[48]">Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. 2016. Understanding Deep Learning Requires Rethinking Generalization. In <em>      <em>International Conference on Learning Representations (ICLR)</em>     </em>.</li>    <li id="BibPLXBIB0049" label="[49]">Jinhong Zhong, Ke Tang, and Zhi-Hua Zhou. 2015. Active Learning from Crowds with Unsure Option.. In <em>      <em>Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)</em>     </em>. 1061&#x2013;1068.</li>    <li id="BibPLXBIB0050" label="[50]">Denny Zhou, Sumit Basu, Yi Mao, and John&#x00A0;C Platt. 2012. Learning from the Wisdom of Crowds by Minimax Entropy. In <em>      <em>Advances in Neural Information Processing Systems (NIPS)</em>     </em>. 2195&#x2013;2203.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>This work was done while the first author was an intern at Amazon Research.</p>   <p id="fn2"><a href="#foot-fn2"><sup>1</sup></a><a class="link-inline force-break" href="https://www.mturk.com/">https://www.mturk.com/</a>   </p>   <p id="fn3"><a href="#foot-fn3"><sup>2</sup></a><a class="link-inline force-break" href="https://developer.amazon.com/alexa">https://developer.amazon.com/alexa</a>   </p>   <p id="fn4"><a href="#foot-fn4"><sup>3</sup></a><a class="link-inline force-break" href="https://madeby.google.com/home/">https://madeby.google.com/home/</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186033">https://doi.org/10.1145/3178876.3186033</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
