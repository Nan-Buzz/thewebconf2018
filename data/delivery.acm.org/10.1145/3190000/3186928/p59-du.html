<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>GPSP: Graph Partition and Space Projection based Approach for Heterogeneous Network Embedding</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/main.css"/><script src="https://dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">GPSP: Graph Partition and Space Projection based Approach for Heterogeneous Network Embedding</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Wenyu</span>      <span class="surName">Du</span>          <sup>1</sup>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences     </div>     <div class="author">     <span class="givenName">Shuai</span>      <span class="surName">Yu</span>          <sup>1</sup>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences     </div>     <div class="author">     <span class="givenName">Min</span>      <span class="surName">Yang</span>          <sup>1</sup>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences     </div>     <div class="author">     <span class="givenName">Qiang</span>      <span class="surName">Qu</span>          <sup>1</sup>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences     </div>     <div class="author">     <span class="givenName">Jia</span>      <span class="surName">Zhu</span>          <sup>2</sup>School of Computer Science, South China Normal University<a class="fn" href="#fn1" id="foot-fn1"><sup>&#x204E;</sup></a>,</div>            </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3184558.3186928" target="_blank">https://doi.org/10.1145/3184558.3186928</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3184558" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>In this paper, we propose <em>GPSP</em>, a novel <strong>G</strong>raph <strong>P</strong>artition and <strong>S</strong>pace <strong>P</strong>rojection based approach, to learn the representation of a heterogeneous network that consists of multiple types of nodes and links. Concretely, we first partition the heterogeneous network into homogeneous and bipartite subnetworks. Then, the projective relations hidden in bipartite subnetworks are extracted by learning the projective embedding vectors. Finally, we concatenate the projective vectors from bipartite subnetworks with the ones learned from homogeneous subnetworks to form the final representation of the heterogeneous network. Extensive experiments are conducted on a real-life dataset. The results demonstrate that <em>GPSP</em> outperforms the state-of-the-art baselines in two key network mining tasks: node classification and clustering<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>.</small>     </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Network Embedding; Network representation learning; Graph partition; Space projection</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Wenyu Du, Shuai Yu, Min Yang, Qiang Qu, and Jia Zhu. 2018. GPSP: Graph Partition and Space Projection based Approach for Heterogeneous Network Embedding. In <em>WWW '18 Companion: The 2018 Web Conference Companion,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France. ACM, New York, NY, USA</em> 3 Pages. <a href="https://doi.org/10.1145/3184558.3186928" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3184558.3186928</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-3">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>Network embedding, or network representation learning, is the task of learning latent representation that captures the internal relations of rich and complex network-structured data. Inspired by the recent success of deep neural networks in computer vision and natural language processing, several recent studies&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>] propose to employ deep neural networks to learn network embeddings. For example, DeepWalk&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] adopts Skip-gram&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>] to randomly generate walking paths in a network; and LINE&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>] tries to preserve two orders of proximity for nodes: first-order proximity (local) and second-order proximity (global).</p>    <p>Most existing studies focus on learning the representation of a homogeneous network that consists of singular type of nodes and relationships (links). However, in practice, many networks are often heterogeneous&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>], i.e., involving multiple types of nodes and relationships. The methods designed for homogeneous networks hardly learn the representations of such networks because they cannot distinguish different types of objects and relationships contained in the networks. Therefore, the learned representations lack heterogeneity behind the structural information.</p>    <p>To alleviate the aforementioned limitation, we propose a <strong>G</strong>raph <strong>P</strong>artition and <strong>S</strong>pace <strong>P</strong>rojection based approach (<em>GPSP</em>) to learn the representation of a heterogeneous network. First, an edge-based graph partition method is used to partition the heterogeneous network into two types of atomic subnetworks: i) homogeneous networks that contain singular type of nodes and relationships; ii) bipartite networks that contain two types of vertices and one type of relationship. Second, we apply classic network embedding models&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>] to learn the representations of homogeneous subnetworks. Third, for each bipartite subnetwork, the hidden projective relations are extracted by learning the projective embedding vectors for the related types of nodes. Finally, <em>GPSP</em> concatenates the projective node vectors from bipartite subnetworks with the node vectors learned from homogeneous subnetworks to form the final representation of the heterogeneous network.</p>    <p>The main contribution of our approach is threefold: i) we formalize the problem of bipartite network representation learning; ii) edge-type based graph partition and space projection are used to learn the representations of different types of nodes in different latent spaces; and iii) the experimental results demonstrate the effectiveness of <em>GPSP</em> in network mining tasks.</p>   </section>   <section id="sec-4">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Our Model</h2>     </div>    </header>    <p>The definitions of homogeneous network&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] and heterogeneous network&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>] are adopted. A bipartite network is defined:</p>    <p>     <div class="definition" id="enc1">     <Label>Definition 2.1.</Label>     <p>      <strong>A Bipartite Network</strong> is defined as a graph <em>G</em> = (<em>V</em>, <em>E</em>) where <em>V</em> = <em>V</em>      <sub>1</sub>&#x222A;<em>V</em>      <sub>2</sub> and <span class="inline-equation"><span class="tex">$E=E_{V_1V_2}$</span>      </span>. <em>V</em>      <sub>1</sub> and <em>V</em>      <sub>2</sub> are two types of vertex sets. In bipartite network each edge <span class="inline-equation"><span class="tex">$e_{v_1v_2}\in E_{V_1V_2}$</span>      </span> connects two different types of nodes <em>v</em>      <sub>1</sub> &#x2208; <em>V</em>      <sub>1</sub> and <em>v</em>      <sub>2</sub> &#x2208; <em>V</em>      <sub>2</sub>.</p>     </div>    </p>    <p>     <em>Edge-type based graph partition</em>.</p>    <p>For a heterogeneous network <em>G</em>, we first build a type-table to record all types of relationships in the network. The network is then partitioned into a minimum number of subnetworks, where each subnetwork is either a homogeneous network or a bipartite network.</p>    <p>     <em>Homogeneous network embedding</em>. For homogeneous subnetworks, we employ conventional embedding algorithms such as LINE and DeepWalk to learn <em>homogeneous embeddings</em>. The <em>GPSP</em> framework with LINE and DeepWalk algorithms are recorded as GPSP-LINE and GPSP-DeepWalk, respectively.</p>    <p>     <em>Bipartite network embedding</em>. Unlike homogeneous networks, each edge in bipartite networks connects two different types of nodes. After learning the representations of objects <em>O</em> and <em>P</em> in two different homogeneous networks (in two different low-dimensional spaces), we could treat the relationship between objects <em>O</em> and <em>P</em> in the bipartite networks as the implicit projection between two low-dimensional spaces. Based upon the projective relation between two types of nodes, space projection is performed to learn the <em>projective representations</em> of nodes. Equation 1 formulates the projective representation learning process. In a bipartite network that contains projective information from homogeneous network <em>A</em> to homogeneous network <em>B</em>, each node <em>A<sub>i</sub>     </em> in network <em>A</em> could learn a projective representation in network <em>B</em>, denoted as <span class="inline-equation"><span class="tex">$Embd_{A_i\rightarrow B}$</span>     </span>: <div class="table-responsive" id="Xeq1">     <div class="display-equation">      <span class="tex mytex">\begin{equation} Embd_{A_i\rightarrow B}= \frac{1}{N} \sum _{j=1}^N(Embd_{B_{j}}*w_{A_i B_j}) \end{equation} </span>      <br/>      <span class="equation-number">(1)</span>     </div>     </div> Where &#x2192; represents the projection relation in two spaces, {<em>B<sub>N</sub>     </em>} is the complete set of objects in network <em>B</em> that each <em>B<sub>j</sub>     </em> in <em>B<sub>N</sub>     </em> has <em>A<sub>i</sub>     </em> &#x2192; <em>B<sub>j</sub>     </em>. <span class="inline-equation"><span class="tex">$Embd_{B_{j}}$</span>     </span> is the learned homogeneous representation of <em>B<sub>j</sub>     </em>, and <span class="inline-equation"><span class="tex">$w_{A_i B_j}$</span>     </span> is the projective weight between nodes <em>A<sub>i</sub>     </em> and <em>B<sub>j</sub>     </em>.</p>    <p>     <em>Final homogeneous network embedding</em>. Finally, the learned homogeneous network embeddings and the bipartite network embeddings are concatenated to form the final homogeneous network embeddings in which each node contains one homogeneous embedding and potentially several projective embeddings from bipartite subnetworks. The final heterogeneous embedding contains the information from different latent spaces, thus it can be regarded as an ensemble embedding that improves the robustness and generalization performance of a set of embeddings.</p>   </section>   <section id="sec-5">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> Experiments</h2>     </div>    </header>    <section id="sec-6">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Dataset</h3>     </div>     </header>     <p>We construct an academic heterogeneous network, based on the dataset from AMiner Computer Science [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0006">6</a>]. The constructed network consists of two types of nodes: authors and papers, and three types of edges representing (i) authors coauthor with each other; (ii) authors write papers; (iii) papers cite other papers. After performing edge-based graph partition, two homogeneous subnetworks &#x2014;the coauthor network (Author-Author) and the citation network (Paper-Paper), and one bipartite network &#x2014;writing network (Author-Paper), are generated.</p>    </section>    <section id="sec-7">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Baseline methods</h3>     </div>     </header>     <p>We compare our approach with several strong baseline methods including Line [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0005">5</a>], DeepWalk [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>], and Metapath2vec [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>]. The dimensions for LINE-based embeddings and the rest are 256 and 128 respectively. We set the size of negative samples to 5. The number of random walks to start at each node in DeepWalk and Metapath2vec is 10, and the walk length is 40.</p>    </section>    <section id="sec-8">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.3</span> Multi-label node classification</h3>     </div>     </header>     <p>We first evaluate the performance of GPSP on the multi-label classification task. We adopt the labeled dataset generated by the study&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>], which groups authors into 8 categories based on authors&#x2019; research fields. Following the strategy in [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>], we try to match this label set with the author embeddings, and get 103,024 successfully matched author embeddings with their labels.</p>     <p>A SVM classifier is used to classify these embeddings. To evaluate the robustness of our model, we compare the performance of GPSP with competitors by varying the percentage of labeled data from 10% to 90%. The Micro-F1 and Macro-F1 scores are summarized in Table 1. GPSP-LINE and GSPS-DeepWalk substantially and consistently outperform the baseline methods by a noticeable margin on all experiments. Note that the metapath method&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>] has a poor performance in the experiments, probably because that metapath2vec heavily relies on well structured paths that are difficult to obtain in many applications.</p>     <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">Multi-label node classification results</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">Metric</td>        <td style="text-align:center;">Model</td>        <td style="text-align:center;">10%</td>        <td style="text-align:center;">30%</td>        <td style="text-align:center;">50%</td>        <td style="text-align:center;">70%</td>        <td>90%</td>       </tr>       <tr>        <td style="text-align:center;">Micro-F1</td>        <td style="text-align:center;">LINE</td>        <td style="text-align:center;">0.7062</td>        <td style="text-align:center;">0.7067</td>        <td style="text-align:center;">0.7074</td>        <td style="text-align:center;">0.7062</td>        <td>0.7075</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">DeepWalk</td>        <td style="text-align:center;">0.6992</td>        <td style="text-align:center;">0.7010</td>        <td style="text-align:center;">0.6992</td>        <td style="text-align:center;">0.6986</td>        <td>0.6988</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">metapath2vec</td>        <td style="text-align:center;">0.6546</td>        <td style="text-align:center;">0.6549</td>        <td style="text-align:center;">0.6547</td>        <td style="text-align:center;">0.6552</td>        <td>0.6529</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">metapath2vec++</td>        <td style="text-align:center;">0.6692</td>        <td style="text-align:center;">0.6681</td>        <td style="text-align:center;">0.6676</td>        <td style="text-align:center;">0.6677</td>        <td>0.6651</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">GPSP-LINE</td>        <td style="text-align:center;">        <strong>0.7512</strong>        </td>        <td style="text-align:center;">        <strong>0.7557</strong>        </td>        <td style="text-align:center;">        <strong>0.7564</strong>        </td>        <td style="text-align:center;">        <strong>0.7554</strong>        </td>        <td>        <strong>0.7552</strong>        </td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">GPSP-DeepWalk</td>        <td style="text-align:center;">        <strong>0.7275</strong>        </td>        <td style="text-align:center;">        <strong>0.7318</strong>        </td>        <td style="text-align:center;">        <strong>0.7324</strong>        </td>        <td style="text-align:center;">        <strong>0.7320</strong>        </td>        <td>        <strong>0.7318</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">Macro-F1</td>        <td style="text-align:center;">LINE</td>        <td style="text-align:center;">0.7032</td>        <td style="text-align:center;">0.7036</td>        <td style="text-align:center;">0.7043</td>        <td style="text-align:center;">0.7035</td>        <td>0.7036</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">DeepWalk</td>        <td style="text-align:center;">0.6964</td>        <td style="text-align:center;">0.6982</td>        <td style="text-align:center;">0.6965</td>        <td style="text-align:center;">0.6963</td>        <td>0.6961</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">metapath2vec</td>        <td style="text-align:center;">0.6307</td>        <td style="text-align:center;">0.6313</td>        <td style="text-align:center;">0.6322</td>        <td style="text-align:center;">0.6328</td>        <td>0.6301</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">metapath2vec++</td>        <td style="text-align:center;">0.6478</td>        <td style="text-align:center;">0.6473</td>        <td style="text-align:center;">0.6478</td>        <td style="text-align:center;">0.6473</td>        <td>0.6445</td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">GPSP-LINE</td>        <td style="text-align:center;">        <strong>0.7482</strong>        </td>        <td style="text-align:center;">        <strong>0.7527</strong>        </td>        <td style="text-align:center;">        <strong>0.7534</strong>        </td>        <td style="text-align:center;">        <strong>0.7526</strong>        </td>        <td>        <strong>0.7522</strong>        </td>       </tr>       <tr>        <td style="text-align:center;"/>        <td style="text-align:center;">GPSP-DeepWalk</td>        <td style="text-align:center;">        <strong>0.7253</strong>        </td>        <td style="text-align:center;">        <strong>0.7290</strong>        </td>        <td style="text-align:center;">        <strong>0.7298</strong>        </td>        <td style="text-align:center;">        <strong>0.7295</strong>        </td>        <td>        <strong>0.7289</strong>        </td>       </tr>      </tbody>     </table>     </div>    </section>    <section id="sec-9">     <header>     <div class="title-info">      <h3>       <span class="section-number">3.4</span> Node clustering</h3>     </div>     </header>     <p>To further evaluate the quality of the latent representations learned by GPSP, we also perform a node clustering task. We adopt simple K-means as our clustering algorithm, working on the learned latent representations. Here, <em>K</em> is assigned to 8. The evaluation metric is normalized mutual information (NMI), which measures the mutual information between the generated clusters and the labeled clusters.</p>     <p>The experimental results are demonstrated in Table 2. GPSP-DeepWalk achieves the best result, which improves 24% in terms of NMI over the original DeepWalk method.</p>     <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Node clustering results (NMI scores)</span>     </div>     <table class="table">      <tbody>       <tr>        <td style="text-align:center;">LINE</td>        <td style="text-align:center;">DeepWalk</td>        <td style="text-align:center;">metapath2v</td>        <td style="text-align:center;">metapath2v++</td>        <td style="text-align:center;">GPSP-LINE</td>        <td style="text-align:center;">GPSP-DeepWalk</td>       </tr>       <tr>        <td style="text-align:center;">0.2516</td>        <td style="text-align:center;">0.2873</td>        <td style="text-align:center;">0.2403</td>        <td style="text-align:center;">0.2470</td>        <td style="text-align:center;">        <strong>0.3118</strong>        </td>        <td style="text-align:center;">        <strong>0.3555</strong>        </td>       </tr>      </tbody>     </table>     </div>    </section>   </section>   <section id="sec-10">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Conclusion</h2>     </div>    </header>    <p>A novel heterogeneous network embedding model, <em>GPSP</em>, is proposed, which supports the representation learning of multiple types of nodes and edges. Extensive experiments show the superiority of GPSP by the benchmarks in two network mining tasks, node classification and clustering.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Yuxiao Dong, Nitesh&#x00A0;V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable Representation Learning for Heterogeneous Networks. In <em>      <em>SIGKDD</em>     </em>.</li>     <li id="BibPLXBIB0002" label="[2]">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. <em>      <em>arXiv</em>     </em> (2013).</li>     <li id="BibPLXBIB0003" label="[3]">Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In <em>      <em>SIGKDD</em>     </em>. 701&#x2013;710.</li>     <li id="BibPLXBIB0004" label="[4]">Qiang Qu, Siyuan Liu, Bin Yang, and Christian&#x00A0;S. Jensen. 2014. Integrating non-spatial preferences into spatial location queries. In <em>      <em>SSDBM</em>     </em>. 8:1&#x2013;8:12.</li>     <li id="BibPLXBIB0005" label="[5]">Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In <em>      <em>WWW</em>     </em>. 1067&#x2013;1077.</li>     <li id="BibPLXBIB0006" label="[6]">Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. 2008. Arnetminer: extraction and mining of academic social networks. In <em>      <em>SIGKDD</em>     </em>. 990&#x2013;998.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>&#x204E;</sup></a>Q. Qu is the corresponding author (qiang@siat.ac.cn). The work was partially supported by the CAS Pioneer Hundred Talents Program.</p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a>Data and codes are available at: https://github.com/Ange1o/GPSP.</p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5640-4/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3184558.3186928">https://doi.org/10.1145/3184558.3186928</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
