<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"> <head>  <title>Multi-instance Domain Adaptation for Vaccine Adverse Event Detection</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="https://dl.acm.org/pubs/lib/css/main.css"/><script src="https://dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="https://dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script> </head> <body id="main">  <section class="front-matter">   <section>    <header class="title-info">    <div class="journal-title">     <h1>      <span class="title">Multi-instance Domain Adaptation for Vaccine Adverse Event Detection</span>      <br/>      <span class="subTitle"/>     </h1>    </div>    </header>    <div class="authorGroup">    <div class="author">     <span class="givenName">Junxiang</span>     <span class="surName">Wang</span>,     George Mason University, Fairfax, Virginia, United States, <a href="mailto:jwang40@gmu.edu">jwang40@gmu.edu</a>    </div>    <div class="author">     <span class="givenName">Liang</span>     <span class="surName">Zhao</span>,     George Mason University, Fairfax, Virginia, United States, <a href="mailto:lzhao9@gmu.edu">lzhao9@gmu.edu</a>    </div>            </div>    <br/>    <div class="pubInfo">    <p>DOI: <a href="https://doi.org/10.1145/3178876.3186051" target="_blank">https://doi.org/10.1145/3178876.3186051</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">    <p>     <small>Detection of vaccine adversCM Reference Forme events is crucial to the discovery and improvement of problematic vaccines. To achieve it, traditionally formal reporting systems like VAERS support accurate but delayed surveillance, while recently social media have been mined for timely but noisy observations. Utilizing the complementary strengths of these two domains to boost the detection performance looks good but cannot be effectively achieved by existing methods due to significant differences between their data characteristics, including: 1) formal language v.s. informal language, 2) single-message per user v.s. multi-messages per user, and 3) one class v.s. binary class. In this paper, we propose a novel generic framework named Multi-instance Domain Adaptation (MIDA) to maximize the synergy between these two domains in the vaccine adverse event detection task for social media users. Specifically, we propose a generalized Maximum Mean Discrepancy (MMD) criterion to measure the semantic distances between the heterogeneous messages from these two domains in their shared latent semantic space. Then these message-level generalized MMD distances are synthesized by newly proposed mixed instance kernels to user-level distances. We finally minimize the distances between the samples of the partially-matched classes from these two domains. In order to solve the non-convex optimization problem, an efficient Alternating Direction Method of Multipliers (ADMM) based algorithm combined with the Convex-Concave Procedure (CCP) is developed to optimize parameters accurately. Extensive experiments demonstrated that our model outperformed the baselines by a large margin under six metrics. Case studies showed that formal reports and extracted adverse-relevant tweets by MIDA shared a similarity of keyword and description patterns.</small>    </p>    </div>    <div class="classifications">    <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Multi-instance learning</small>, </span>     <span class="keyword">      <small> Transfer learning</small>, </span>     <span class="keyword">      <small> Adverse event detection</small>     </span>    </div>    <br/>    <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Junxiang Wang and Liang Zhao. 2018. Multi-instance Domain Adaptation for Vaccine Adverse Event Detection. In <em>WWW 2018: The 2018 Web Conference,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France</em>. ACM, New York, NY, USA, 10 Pages. <a href="https://doi.org/10.1145/3178876.3186051" class="link-inline force-break"       target="_blank">https://doi.org/10.1145/3178876.3186051</a></small>     </p>    </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-3">    <header>    <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>    </div>    </header>    <p>In recent decades, information extraction from social media data such as Twitter data have demonstrated to be successful in the healthcare applications [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0019">19</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0014">14</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>]. Compared with existing adverse event reporting systems, social media have the following advantages: <strong>(1). Message timeliness:</strong> different from deliberate check from health experts, which may take months to release reports, messages regarding symptom descriptions of vaccine adverse events can be posted immediately by portable mobile devices [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0040">40</a>]. <strong>(2). Sensor ubiquity:</strong> social media can capture ubiquitous disease information from social sensors because they reflect the mood and trend of the public, which can be utilized to detect vaccine adverse events. However, social media still suffer from two challenges: <strong>1. Prohibitive labeling efforts:</strong> in order to obtain accurate labels, it is mandatory to check all messages of all users. For example, suppose a user has 100 messages on average, labeling 1,000 users amounts to checking 100,000 messages, which can not be completed manually. <strong>2. Class imbalance:</strong> in practice, the proportion of positive users, whose messages indicate adverse events, is very low. As a result, a classifier is biased towards negative users, causing high false negative rates.</p>    <p>Therefore, formal reports are accurate but with poor timeliness while social media are timely but more imbalanced and labor-intensive to label. To overcome their respective drawbacks, we innovatively propose to integrate their complementary strengths. However, the integration of these two domains is seriously challenged by several salient differences between their characteristics: <strong>1. Formal language versus informal language.</strong> Generally, word usage in the formal reports and social media are totally different: health experts or doctors tend to use formal words or terminologies in the formal reports whereas informal words are common in the social media messages. Table <a class="tbl" href="#tab1">1</a> gives two examples of formal reports and tweets, respectively. Keywords are shown in bold types. Medical terminologies like &#x2019;parotid&#x2019;, &#x2019;gland&#x2019; and &#x2019;malaise&#x2019; are frequently used in the formal reports while social media users tend to use informal words like &#x2019;damn&#x2019; and &#x2019;Ouch&#x2019;. Even some commonly used keywords both in the formal reports and social media messages like &#x2019;headache&#x2019; and &#x2019;sore&#x2019; differ in word frequencies. <strong>2. Single text versus multiple messages.</strong> Formal reports and social media also differ in structures: each reporter typically write only one report in formal reporting systems whereas each social media user can publish thousands of postings. The first Twitter example shown in Table <a class="tbl" href="#tab1">1</a> indicates that this user has multiple tweets, whereas every symptom text belongs to only one formal report. <strong>3. Binary class versus one class.</strong> Typically, social media users consist of a small portion of positive users and a majority of negative ones, whereas formal reports only belong to the positive class. As is illustrated in Table <a class="tbl" href="#tab1">1</a>, the first and the second Twitter user belong to the negative and the positive class, respectively.</p>    <div class="table-responsive" id="tab1">    <div class="table-caption">     <span class="table-number">Table 1:</span>     <span class="table-title">Two formal report and tweet examples, respectively: (+) stands for positive formal reports or tweets, (-) denotes negative tweets. Keywords are shown in bold types.</span>    </div>    <table class="table">     <thead>      <tr>       <th style="text-align:center;">Formal report</th>       <th>Tweet</th>      </tr>     </thead>     <tbody>      <tr>       <td style="text-align:center;">The patient started to</td>       <td>1. Flu shots in Town Lobby from 1-5 pm.(-)</td>      </tr>      <tr>       <td style="text-align:center;">feel an <strong>itching</strong> feeling.(+)</td>       <td>2. a flu shot for only 12 dollars.(-)</td>      </tr>      <tr>       <td style="text-align:center;">Swollen <strong>parotid glands</strong>,</td>       <td>1.<strong>Ouch</strong>! so sore my arms are!</td>      </tr>      <tr>       <td style="text-align:center;">fever, headache, <strong>malaise</strong>.(+)</td>       <td>       <strong>damn</strong> flu shot!(+)</td>      </tr>     </tbody>    </table>    </div>    <p>In order to simultaneously deal with these challenges, we propose a novel Multi-instance Domain Adaptation (MIDA) framework for vaccine adverse event detection by maximizing the synergy of formal reporting systems and social media data such as Twitter data. Specifically, given commonly used keywords both in formal reports and social media messages (e.g., tweets), a generalized MMD-based [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>] criterion is proposed to measure the difference between the heterogeneous messages from these two domains. These message-level distances are then synthesized to user-level by a novel mixed instance kernels induced by a <em>max rule</em>. Finally, a <em>partial class-matching strategy</em> is leveraged to optimize the seamless integration of the two domains with different number of classes for accurate adverse event detection. The parameter optimization of MIDA is a nonconvex problem, an Alternating Direction Method of Multipliers (ADMM) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0004">4</a>] based algorithm combined with the Convex-Concave Procedure [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>] has been developed to optimize variables in a distributive manner. One real vaccine adverse event detection dataset demonstrated that the MIDA outperformed all the baselines.</p>    <p>The main contributions of our research are summarized as follows:</p>    <ul class="list-no-style">    <li id="list1" label="&#x2022;"><strong>Design a generic framework MIDA for cross-domain adverse event detection.</strong> The adverse event detection techniques from formal reporting systems and social media mining focus on different but complementary aspects. Since their advantages complement with each other, MIDA is proposed to integrate the strengths of them to achieve a synergy.<br/></li>    <li id="list2" label="&#x2022;"><strong>Propose new models for multi-instance domain adaptation.</strong> To model the word frequency differences between formal reports and social media data such as tweets, we propose a generalized MMD-based criterion and new kernels induced by the max rule in the multi-instance learning setting.<br/></li>    <li id="list3" label="&#x2022;"><strong>Develop an efficient nonconvex optimization algorithm.</strong> The optimization problem is non-convex due to the introduction of the generalized MMD. An effective approach based on ADMM is developed to optimize it, where the non-convex subproblem is efficiently solved by sufficiently exploring its convex-concave property using CCP [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0021">21</a>], which ensures local convergence.<br/></li>    <li id="list4" label="&#x2022;"><strong>Conduct extensive experiments for performance evaluations.</strong> The results on the real-world adverse event dataset demonstrate that MIDA consistently dominated the performance. Sensitivity analysis and scalability analysis on several factors are discussed thoroughly. Case studies show that formal reports and extracted adverse-relevant tweets by MIDA shared a similarity of keyword and description patterns.<br/></li>    </ul>    <p>The rest of the paper is organized as follows. In Section <a class="sec" href="#sec-4">2</a>, we summarize recent research work related to this paper. In Section <a class="sec" href="#sec-5">3</a>, we present the problem formulation. In Section <a class="sec" href="#sec-8">4</a>, we propose the novel MIDA framework. In Section <a class="sec" href="#sec-15">5</a>, we develop an effective ADMM-based optimization algorithm. In Section <a class="sec" href="#sec-16">6</a>, extensive experiments are conducted to validate the effectiveness of our model. Section <a class="sec" href="#sec-27">7</a> concludes by summarizing the whole paper.</p>   </section>   <section id="sec-4">    <header>    <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>    </div>    </header>    <p>This section introduces related work in several research fields.</p>    <p>    <strong>Multi-instance learning.</strong> Multi-instance learning is a variant of traditional machine learning methods in which a data point is presented as a bag of multiple instances. Multi-instance classifiers are categorized as either <em>instance-level</em> or <em>bag-level</em> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>]. <em>Instance-level</em> classifiers score each instance without considering the characteristic of the whole bag. For example, the image classification of beaches and non-beaches is determined by their visual content [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>]; Kumar and Raj detected audio events based on a collection of audio recordings [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>]. <em>Bag-level</em> is more common than <em>instance-level</em>. For example, Dietterich et al. evaluated a drug as effective if it binded well with target binding sites [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0001">1</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>]. Andrews et al. gave instance-level and bag-level formulations as a maximum margin problem in their Support Vector Machines (SVM) settings [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>]. Zhou et al. developed two methods to discriminate bag labels with graph theory [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>]. However, to the best of our knowledge, very little work has applied multi-instance learning frameworks to social media applications.</p>    <p>    <strong>Transfer learning.</strong> The idea of transfer learning lies in learning objects in the target domain with the help of knowledge transfer from the source domain [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0027">27</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>]. Typically, transfer learning approaches are categoried as either homogeneous or heterogeneous. In homogeneous models, the source and the target share the same domain space, but probability distributions are totally different [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>]. For example, Daume III proposed an easy domain adaptation approach by feature augmentation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>]. Pan et al. aligned domain-specific words into unified clusters with the help of domain-independent words for sentiment analysis [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0026">26</a>]. Chattopadhyay et al. presented a novel framework that minimized conditional probability distribution differences between multiple subjects [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>]. For heterogeneous models, the source and the target are represented by different feature spaces. For example, Duan et al. projected the source and the target spaces into a common subspace and then two mapping functions were proposed to augment features [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>]. Kulis et al. transferred object models from the source to the target by a nonlinear transformation [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>]. Zhu et al. enriched the representation of targeted images with semantic concepts extracted from annotated source images by a matrix factorization approach [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>]. Most transfer learning work focused on the single instance, only several papers considered transfer learning in the multi-instance learning setting: Zhang and Si proposed a novel method where the target classifier was the linear combination of multiple source classifiers [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>]; Wang et al. transferred cross-category knowledge to boost the target learning task, and a data-dependent mixture model was presented to combine a weak classifier with multiple source classifiers [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0033">33</a>]; Wang et al. mapped a target multi-instance bag into a bag-level feature space by a domain transfer dictionary, then a linear adaptive function was applied to a bag-level feature vector [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>]. However, none of them focused on distance minimization between two domains.</p>    <p>    <strong>Adverse event surveillance and detection.</strong> Recently, healthcare topics on social media have begun to attract considerable attention of researchers. Flu surveillance is an important application to mention. For instance, Lee et al. detected seasonal flu by a real-time analysis of Twitter data [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>]; Chen et al. made inference about a user&#x0027;s hidden state according to his tweets during flu outbreaks, and state statistics were aggregated by geographic region [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>]. Signorini et al. kept track of H1N1 flu and measured flu activities [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>], while Lampos et al. utilized a Twitter microblogging service to track the flu-like illness in the United Kingdom[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>]. Drug-related adverse event detection is another popular application. For example, Metke et al. discussed the effect of the text-processing step on the drug adverse event detection performance [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>]. Yomtov and Gabrilovich aggregated search log of Internet users to extract drug-related adverse reactions [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>]. However, very little work has discussed the application of vaccine adverse event detection on social media.</p>   </section>   <section id="sec-5">    <header>    <div class="title-info">     <h2>      <span class="section-number">3</span> Problem Setup</h2>    </div>    </header>    <p>In this section, the problem addressed by this research is formulated in the formal reports as the source domain and the Twitter messages as the target domain. Section <a class="sec" href="#sec-6">3.1</a> defines the problem of vaccine adverse event detection; and Section <a class="sec" href="#sec-7">3.2</a> discusses challenges of the problem.</p>    <section id="sec-6">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.1</span> Problem Formulation</h3>     </div>    </header>     <p>The problem formulation addressed by this paper is given in this section. Table <a class="tbl" href="#tab2">2</a> displays important notations and descriptions. Formal reports and Twitter messages are considered as the source and the target domain, respectively. <em>K</em> denotes a common keyword set that represents symptom descriptions of vaccine adverse events in both domains, and <em>R</em> denotes the formal report set. The <em>j</em>th entry of the <em>i</em>th formal report <em>R<sub>i</sub>     </em>, denoted by <em>R</em>     <sub>      <em>i</em>, <em>j</em>     </sub>, is the count of the <em>j</em>th keyword in the <em>i</em>th formal report <em>R<sub>i</sub>     </em>. <em>r</em> is the number of formal reports. A tweet set is denoted as <em>D</em> = {<em>D<sub>u</sub>     </em>}<sub>      <em>u</em> &#x2208; <em>U</em>     </sub>, where a user set is denoted as <em>U</em> and the matrix <span class="inline-equation"><span class="tex">$D_u\in \mathbb {Z}^{n_u \times \vert K\vert }$</span>     </span> denotes tweets from user <em>u</em>. <em>n<sub>u</sub>     </em> refers to the number of tweets from user <em>u</em>. <em>D</em>     <sub>      <em>u</em>, <em>i</em>     </sub> stands for the <em>i</em>th tweet from user <em>u</em>. The <em>j</em>th entry of <em>D</em>     <sub>      <em>u</em>, <em>i</em>     </sub>, denoted by <em>D</em>     <sub>      <em>u</em>, <em>i</em>, <em>j</em>     </sub>, is the count of the <em>j</em>th keyword in the <em>i</em>th tweet from user <em>u</em>. A user set is denoted as <em>U</em>. <em>Y<sup>R</sup>     </em> = 1 represents health states indicated by formal reports, which belong to the positive class. <em>Y<sub>u</sub>     </em> &#x2208; {0, 1} denotes the health state of user <em>u</em>, <em>Y<sub>u</sub>     </em> = 1 implies that user <em>u</em> is regarded as a positive user (i.e. this user suffers from vaccine adverse events), while <em>Y<sub>u</sub>     </em> = 0 shows that user <em>u</em> is negative (i.e. this user receives safe vaccines). <em>Y</em> = {<em>Y<sub>u</sub>     </em>}<sub>      <em>u</em> &#x2208; <em>U</em>     </sub> denotes the health states of all users. The input matrix for user <em>u</em> is defined as <span class="inline-equation"><span class="tex">$X_u=[ {1}_{n_u \times 1},D_u]$</span>     </span> where <span class="inline-equation"><span class="tex">$ {1}_{n_u \times 1}$</span>     </span> is an all one vector. The dimension of <em>X<sub>u</sub>     </em> is <em>n<sub>u</sub>     </em> &#x00D7; (|<em>K</em>| + 1). <em>X</em>     <sub>      <em>u</em>, <em>i</em>     </sub> denotes the <em>i</em>th row of <em>X<sub>u</sub>     </em>. <em>X</em> = {<em>X<sub>u</sub>     </em>}<sub>      <em>u</em> &#x2208; <em>U</em>     </sub> denotes the input matrices of all users. Then vaccine adverse event detection problem can be formulated as follows:</p>    <p>     <strong>Problem Formulation</strong>: Given the input matrices <em>X</em> = {<em>X<sub>u</sub>     </em>}<sub>      <em>u</em> &#x2208; <em>U</em>     </sub> and formal reports <em>R</em>, the goal of the problem is to detect the health state of a user <em>u</em> &#x2208; <em>U</em> by learning the mapping <em>f</em>: <div class="table-responsive" id="eq1">      <div class="display-equation">       <span class="tex mytex">\begin{align} f:\lbrace X_{u,1},X_{u,2},\cdots ,X_{u,n_u} |R\rbrace \rightarrow Y_u \end{align} </span>       <br/>       <span class="equation-number">(1)</span>      </div>     </div>    <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Important notations and descriptions.</span>     </div>     <table class="table">      <thead>       <tr>       <th style="text-align:center;">Notations</th>       <th style="text-align:center;">Descriptions</th>       </tr>     </thead>     <tbody>       <tr>       <td style="text-align:center;">        <em>X<sub>u</sub>        </em>       </td>       <td style="text-align:center;">The input matrix from user <em>u</em>       </td>       </tr>       <tr>       <td style="text-align:center;">        <em>Y<sub>u</sub>        </em>       </td>       <td style="text-align:center;">The predefined label from user <em>u</em>       </td>       </tr>       <tr>       <td style="text-align:center;">        <em>K</em>       </td>       <td style="text-align:center;">The common keyword set</td>       </tr>       <tr>       <td style="text-align:center;">        <em>U</em>       </td>       <td style="text-align:center;">The user set</td>       </tr>       <tr>       <td style="text-align:center;">        <em>R</em>       </td>       <td style="text-align:center;">The formal report set</td>       </tr>       <tr>       <td style="text-align:center;">        <em>&#x03B2;</em>       </td>       <td style="text-align:center;">The coefficient vector of the keyword set.</td>       </tr>       <tr>       <td style="text-align:center;">        <em>c</em>       </td>       <td style="text-align:center;">The formal report and Twitter data fold.</td>       </tr>       <tr>       <td style="text-align:center;">        <em>n<sub>u</sub>        </em>       </td>       <td style="text-align:center;">The tweet number from user <em>u</em>.</td>       </tr>       <tr>       <td style="text-align:center;">        <em>U<sub>p</sub>        </em>       </td>       <td style="text-align:center;">The positive user set.</td>       </tr>       <tr>       <td style="text-align:center;">        <em>I</em>(<em>u</em>)</td>       <td style="text-align:center;">An index set from user <em>u</em>.</td>       </tr>      </tbody>     </table>    </div>    </p>    </section>    <section id="sec-7">    <header>     <div class="title-info">      <h3>       <span class="section-number">3.2</span> Challenges</h3>     </div>    </header>    <p>In order to solve the vaccine adverse event detection problem (<a class="eqn" href="#eq1">1</a>), we still need to tackle several challenges.<em>1) Distribution gap.</em> The formal report set <em>R</em> and the tweet set <em>D</em> share the same keyword space, but they differ in linguistic form and word frequency. <em>2) Structure difference.</em> According to the problem formulation, the <em>i</em>th formal report <em>R<sub>i</sub>     </em> is encoded by a vector, whereas the tweet set <em>D<sub>u</sub>     </em> is represented by <em>n<sub>u</sub>     </em> vectors. Different structures make distance measurement very difficult. <em>3) Class-pattern inconsistency.</em> All formal reports have predefined labels <em>Y<sup>R</sup>     </em> = 1, while a Twitter user <em>u</em> is labeled as <em>Y<sub>u</sub>     </em> where <em>Y<sub>u</sub>     </em> = {0, 1} has two possibilities. Thus in the next section, a novel multi-instance transfer learning model is proposed to address these problems in turn. <figure id="fig1">      <img src="http://deliveryimages.acm.org/10.1145/3190000/3186051/images/www2018-60-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 1:</span>       <span class="figure-title">The framework overview: combine Twitter data with formal reports to detect vaccine adverse events.</span>      </div>     </figure>    </p>    </section>   </section>   <section id="sec-8">    <header>    <div class="title-info">     <h2>      <span class="section-number">4</span> Multi-instance Domain Adaptation (MIDA) Model</h2>    </div>    </header>    <p>In this section, we develop the novel MIDA model. Specifically, a simple but effective max rule and a multi-instance classifier are discussed in Section <a class="sec" href="#sec-9">4.1</a>; Section <a class="sec" href="#sec-10">4.2</a> serves to minimize distances between formal reports and tweets; Section <a class="sec" href="#sec-11">4.3</a> gives the complete framework of our model, discusses several computational issues and shows the relationship between our model and several previous methods.</p>    <section id="sec-9">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> The Max Rule and Multi-instance Classifier</h3>     </div>    </header>    <p>We begin by establishing the mapping from social media users to their postings (e.g., tweets). Based on all the tweets of each user, the user is labeled as positive if at least one tweet is positive. Otherwise, that user is classified as negative. Suppose <em>p</em>     <sub>      <em>u</em>, <em>i</em>     </sub> denotes the probability that the <em>i</em>th tweet of user <em>u</em> is indicative of vaccine adverse events (i.e., positive). Based on the above intuition, the probability <em>p<sub>u</sub>     </em> that the user herself is positive, is calculated by the following <strong>max rule</strong>: <div class="table-responsive" id="eq2">      <div class="display-equation">       <span class="tex mytex">\begin{align} p_u=max_{i=1,\cdots ,n_u}p_{u,i} \end{align} </span>       <br/>       <span class="equation-number">(2)</span>      </div>     </div>    </p>    <p>As is displayed in Figure (<a class="fig" href="#fig1">1</a>), positive users are composed of at least one positive tweet, which are denoted by red circles and green triangles. The max rule assigns the first Twitter user in the right of Figure <a class="fig" href="#fig1">1</a> a positive label. The max rule leads to asymmetric property from users to tweets because a positive user entails only a tweet indicating adverse events.</p>    <p>We choose a logistic regression classifier because of its probability output. Suppose <em>&#x03B2;</em> is a coefficient vector where the <em>i</em> &#x2212; <em>th</em> element <em>&#x03B2;<sub>i</sub>     </em> denotes the weight of the <em>i</em> &#x2212; <em>th</em> keyword from the keyword set <em>K</em>, then <em>p</em>     <sub>      <em>u</em>, <em>i</em>     </sub> is represented by the following equation. <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{align*} &#x0026;p_{u,i}=logit(X_{u,i},\beta)\end{align*} </span>       <br/>      </div>     </div> where <em>logit</em>(&#x2022;) is a logit function. Since our ultimate goal is to learn a model in the Twitter domain, we adopt the empirical risk minimization principle[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0031">31</a>] and the log loss function for user <em>u Loss<sub>u</sub>     </em>(<em>&#x03B2;</em>) is given by the following equation. <div class="table-responsive" id="eq3">      <div class="display-equation">       <span class="tex mytex">\begin{align} Loss_u(\beta)=-Y_u\log (p_u)-(1-Y_u)\log (1-p_u) \end{align} </span>       <br/>       <span class="equation-number">(3)</span>      </div>     </div>    </p>    </section>    <section id="sec-10">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Heterogeneous Domains Adaption</h3>     </div>    </header>    <p>In order to achieve the seamless integration of the knowledge from formal reports and social media, heterogeneity between these two domains needs to be considered and addressed. As shown in Figure <a class="fig" href="#fig1">1</a>, their heterogeneity comes from three aspects: 1) formal reports and social media messages have different linguistic forms, denoted by circles and squares; 2) formal reports only have positive samples; and 3) each social media user has multiple instances (i.e., tweets) while each reporter only has a single instance (i.e., a formal report). To overcome the first two aspects, we propose a novel <strong>latent-space marginal distance measurement</strong>, while to overcome the third, we propose <strong>mixed instance kernels</strong>. The details are as follows.</p>    <p>     <strong>1. Latent-Space Marginal Distance Measurement.</strong> As shown in Figure <a class="fig" href="#fig1">1</a>, the closer the positive Twitter users are to reporters, the clearer the decision boundary is. Suppose <em>U<sub>p</sub>     </em> denotes positive Twitter user set, we aim to minimize the distance <em>Dist</em>     <sup>2</sup>(<em>R</em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) between formal reports and tweets of positive users. However, existing distance measurements such as the well-known non-parametric criterion Maximum Mean Discrepancy (MMD) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0024">24</a>] can not handle our problem (that first two aspects of the heterogeneity we mentioned) because it is not applicable to two domains with different numbers of classes and multiple instances. Therefore, a generalized MMD-based measurement has been proposed, which compares the distance of only positive samples in the both source and target domain in a reproducing kernel Hilbert space (RKHS) <em>H</em>, <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{align*} &#x0026;\min Dist^2(R,U_p;\beta)=\min \Vert \phi (R)/r-\phi (U_p)/n_p \Vert ^2_H\end{align*} </span>       <br/>      </div>     </div> where <em>n<sub>p</sub>     </em> = |<em>U<sub>p</sub>     </em>| denotes the number of positive users and <em>&#x03D5;</em>(&#x2022;): <em>R</em>&#x222A;<em>U<sub>p</sub>     </em> &#x2192; <em>H</em> is a feature mapping. Suppose <em>Ker</em>(&#x2022;, &#x2022;) is a kernel function induced by <em>&#x03D5;</em>(&#x2022;) such that <em>&#x03D5;</em>(<em>x</em>)<sup>      <em>T</em>     </sup>     <em>&#x03D5;</em>(<em>y</em>) = <em>Ker</em>(<em>x</em>, <em>y</em>), the generalized MMD can be transformed into <div class="table-responsive" id="eq4">      <div class="display-equation">       <span class="tex mytex">\begin{align} \nonumber &#x0026;\min \Vert \phi (R)/r-\phi (U_p)/n_p \Vert ^2_H\\\nonumber =&#x0026;\min \phi (R)^T\phi (R)/r^2-2\phi (R)^T\phi (U_p)/(r\times n_p)+\phi (U_p)^T\phi (U_p)/n_p^2\\ =&#x0026;\min \!Ker\!(R,\!R)\!/r^2\!-\!2Ker(R,\!U_p;\!\beta)/(r\!\times \!n_p)\!+\!Ker(U_p,\!U_p;\!\beta)\!/\!n_p^2 \end{align} </span>       <br/>       <span class="equation-number">(4)</span>      </div>     </div> where <em>Ker</em>(<em>R</em>, <em>R</em>), <em>Ker</em>(<em>R</em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) and <em>Ker</em>(<em>U<sub>p</sub>     </em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) denote the kernel inside <em>R</em>, the kernel between <em>R</em> and <em>U<sub>p</sub>     </em> and the kernel inside <em>U<sub>p</sub>     </em>, respectively. Considering <em>Ker</em>(<em>R</em>, <em>R</em>) as constant and <em>Ker</em>(<em>R</em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) and <em>Ker</em>(<em>R</em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) as similarity measurements dependent on <em>&#x03B2;</em> which will be defined in the later section, Equation (<a class="eqn" href="#eq4">4</a>) shows that minimizing the generalized MMD is equivalent of putting double weights on cross-domain similarity maximization <em>Ker</em>(<em>R</em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) at the cost of similarity minimization inside the Twitter domain <em>Ker</em>(<em>U<sub>p</sub>     </em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>). <figure id="fig2">      <img src="http://deliveryimages.acm.org/10.1145/3190000/3186051/images/www2018-60-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">The motivation of <em>mixed instance kernels</em>: <em>Ker</em>(<em>R</em>, <em>U<sub>p</sub>       </em>; <em>&#x03B2;</em>), denoted by the black double-headed arrow, is encoded by the similarity between formal reports and positive tweets; <em>Ker</em>(<em>U<sub>p</sub>       </em>, <em>U<sub>p</sub>       </em>; <em>&#x03B2;</em>), denoted by the blue double-headed arrow, is encoded by the similarity between two positive tweets.</span>      </div>     </figure>     <strong>2. Mixed Instance Kernels.</strong> Measuring the above distances between users and reporters (i.e., bags) require the characterization of their messages (i.e., instances), because the polarity of a user/reporter is determined by that of her messages. Mathematically, we need to determine kernels <em>Ker</em>(<em>R</em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) and <em>Ker</em>(<em>U<sub>p</sub>     </em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) in Equation (<a class="eqn" href="#eq4">4</a>). As shown in Figure <a class="fig" href="#fig1">1</a>, the polarity of a Twitter user is collectively determined by all her tweets (i.e., the multi-instance case) while the polarity of a reporter is determined by her one and only formal report (i.e., the single-instance case). However, there is no kernel to handle this hybrid of multi-instance and single-instance inputs. This motivates us to propose novel <em>mixed instance kernels</em>: as illustrated by Figure <a class="fig" href="#fig2">2</a>, kernel <em>Ker</em>(<em>R</em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>), denoted by the black double-headed arrow, is encoded by the similarity between formal reports and positive tweets determined by the max rule defined in Equation (<a class="eqn" href="#eq2">2</a>); kernel <em>Ker</em>(<em>U<sub>p</sub>     </em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>), denoted by the blue double-headed arrow, is encoded by the similarity between two positive tweets determined by the max rule defined in Equation (<a class="eqn" href="#eq2">2</a>) as well. Therefore, kernels <em>Ker</em>(<em>R</em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) and <em>Ker</em>(<em>U<sub>p</sub>     </em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) map user-level (i.e., bag-level) similarity measurements into message-level (i.e., instance-level) ones. Notations in Figure <a class="fig" href="#fig2">2</a> are formulated mathematically as follows. <div class="table-responsive" id="eq5">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026;Ker(R,U_p;\beta)=\sum \nolimits _{u\in U_p}\sum \nolimits _{i=1}^{r} Ker(D_{u,I(u)},R_i;\beta)\end{align} </span>       <br/>       <span class="equation-number">(5)</span>      </div>     </div>     <div class="table-responsive" id="eq6">      <div class="display-equation">       <span class="tex mytex">\begin{align} &#x0026;Ker(U_p\!,\!U_p;\!\beta)\!=\!\sum \nolimits _{u_1\in U_p}\!\sum \nolimits _{u_2\in U_p} \!Ker\!(\!D_{u_1,I(u_1)},\!D_{u_2,I(u_2)};\beta) \end{align} </span>       <br/>       <span class="equation-number">(6)</span>      </div>     </div> where an index set <span class="inline-equation"><span class="tex">$I(u)=\arg \max _{i} p_{u,i}$</span>     </span> is introduced auxiliarily, which records the index of the tweet selected by the max rule.</p>    <p>To reduce the complexity of the model, we introduce the triangular kernel <span class="inline-equation"><span class="tex">$Ker(x,y)=-\Vert x- y\Vert ^2_2$</span>     </span> [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0011">11</a>]. After integrating Equation (<a class="eqn" href="#eq5">5</a>) and (<a class="eqn" href="#eq6">6</a>) into Equation (<a class="eqn" href="#eq4">4</a>), we have <div class="table-responsive" id="eq7">      <div class="display-equation">       <span class="tex mytex">\begin{align} \nonumber &#x0026;\min Dist^2(R,U_p;\beta)=\min 2\sum \nolimits _{u\in U_p}\sum \nolimits _{i=1}^{r} \Vert D_{u,I(u)} \!-\!R_i\Vert ^2_2/(r\times n_p)\\ &#x0026;-\sum \nolimits _{u_1\in U_p}\sum \nolimits _{u_2\in U_p} \Vert D_{u_1,I(u_1)}-D_{u_2,I(u_2)}\Vert ^2/(n_p^2) \end{align} </span>       <br/>       <span class="equation-number">(7)</span>      </div>     </div> where the weighted distance measure &#x2016;&#x2022;&#x2016; is defined as <span class="inline-equation"><span class="tex">$\Vert x\Vert ^2_2=\sum \nolimits _{i=1}^{\vert K \vert } x_i^2\beta _{i+1}^2$</span>     </span> where <span class="inline-equation"><span class="tex">$\beta _{i+1}^2(i=1,\cdots ,\vert K\vert)$</span>     </span> represents the weight of the <em>i</em>th keyword.</p>    </section>    <section id="sec-11">    <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Overall Model</h3>     </div>    </header>    <p>The above consideration of new distance measurement and kernels lead to a new marginal domain adaption framework that jointly minimizes the empirical error and the difference between the two heterogeneous domains: <div class="table-responsive" id="eq8">      <div class="display-equation">       <span class="tex mytex">\begin{align} \beta ^*&#x0026;=\arg \min \nolimits _\beta L(\beta)+\lambda _2 Dist^2(R,U_p;\beta) \end{align} </span>       <br/>       <span class="equation-number">(8)</span>      </div>     </div> where <span class="inline-equation"><span class="tex">$L(\beta)=\sum \nolimits _{u\in U}Loss_u(\beta)+\lambda _1\Vert \beta \Vert _1$</span>     </span> such that <em>&#x03BB;</em>     <sub>1</sub> > 0 is a parameter for &#x2113;<sub>1</sub> regularization due to high sparsity of the feature set and <em>&#x03BB;</em>     <sub>2</sub> > 0 is a parameter which adjusts the weight between the <em>L</em>(<em>&#x03B2;</em>) and <em>Dist</em>     <sup>2</sup>(<em>R</em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>). <em>Loss<sub>u</sub>     </em>(<em>&#x03B2;</em>) and <em>Dist</em>     <sup>2</sup>(<em>R</em>, <em>U<sub>p</sub>     </em>; <em>&#x03B2;</em>) are given in Equation (<a class="eqn" href="#eq3">3</a>) and (<a class="eqn" href="#eq7">7</a>), respectively.</p>    <section id="sec-12">     <p><em>4.3.1 Computational Issues.</em> <strong>Initial instance pruning.</strong> Many positive users in the real Twitter dataset have many tweets, but most of them are irrelevant to adverse events and thus increase the complexity of the problem. Furthermore, they are similar to the tweets from negative users. Therefore it is necessary to prune them as a preprocessing step. One popular way is to build a Kernel Density Estimator (KDE) to model the distribution of the tweets from negative users [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0029">29</a>] [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0012">12</a>]. The other method is to build a one-class classifier like OSVM using event-irrelevant tweets [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0016">16</a>]. <strong>Data splitting.</strong> The other consideration is the huge computational burden of the generalized MMD with the rapid growing size of formal reports and the Twitter data. One intuitive but effective way is to split formal reports and Twitter data. Suppose <span class="inline-equation"><span class="tex">$R=\cup _{i=1}^c R^i$</span>      </span> and <span class="inline-equation"><span class="tex">$U_p=\cup _{i=1}^c U_p^i$</span>      </span> are split into <em>c</em> partitions where <em>c</em> is the number of partition, then <span class="inline-equation"><span class="tex">$Ker(R,U_p;\beta)=\sum \nolimits _{i=1}^c Ker(R^i,U_p^i;\beta)$</span>      </span> and <span class="inline-equation"><span class="tex">$Ker(U_p,U_p;\beta)=\sum \nolimits _{i=1}^c Ker(U_p^i,U_p^i;\beta)$</span>      </span>.</p>    </section>    <section id="sec-13">     <p><em>4.3.2 Model Generalization.</em> Our model can be further generalized to multiple source domains, the novelty of the generalization lies in the <em>weighted MMD scheme</em>. Suppose there are <em>m</em> source formal report data, each of which is represented as <em>F<sub>i</sub>      </em>(<em>i</em> = 1, &#x22C5;&#x22C5;&#x22C5;, <em>m</em>), then the MIDA model is formulated as: <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\begin{align*} &#x0026;\beta ^*\!=\!\arg \min \nolimits _{\beta ,w_i}\sum \nolimits _{u\in U}\!Loss_u(\beta)\!+\!\lambda _1\Vert \beta \Vert _1\!+\!\lambda _2 \sum _{i=1}^m w_i Dist^2(F_i,U_p;\beta)\\ &#x0026;s.t. \sum \nolimits _{i=1}^m w_i=1, w_i\geqslant 0(i=1,\cdots ,m)\end{align*} </span>       <br/>       </div>      </div> where <em>w<sub>i</sub>      </em>(<em>i</em> = 1, &#x22C5;&#x22C5;&#x22C5;, <em>m</em>) is an generalized MMD weight for the <em>i</em>-th formal report data source.</p>    </section>    <section id="sec-14">     <p><em>4.3.3 Relationship to Previous Related Approaches.</em> In this subsection, we show that several classic methods are special cases of our model.</p>     <p>      <strong>1. Generalization of logistic regression.</strong> Let <em>n<sub>u</sub>      </em> = 1 for <em>u</em> &#x2208; <em>U</em> and <em>R</em> = &#x2205;. The model then is reduced to a logistic regression with &#x2113;<sub>1</sub>-norm regularization [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0004">4</a>]. <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\begin{align*} &#x0026;\beta ^*\!=\!\arg \min \nolimits _\beta \!\sum \nolimits _{u\in U}Loss_u(\beta) +\!\lambda _1\!\Vert \beta \Vert _1\end{align*} </span>       <br/>       </div>      </div>     </p>     <p>      <strong>2. Generalization of logistic regression combined with transfer learning.</strong> Let <em>n<sub>u</sub>      </em> = 1 for <em>u</em> &#x2208; <em>U</em>. The model is then reduced to a logistic regression combined with transfer learning [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0009">9</a>]. <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\begin{align*} &#x0026;\beta ^*=\arg \min \nolimits _\beta \sum \nolimits _{u\in U} Loss_u(\beta) +\lambda _1\Vert \beta \Vert _1+\lambda _2 Dist^2(R,U_p;\beta)\end{align*} </span>       <br/>       </div>      </div>     </p>     <p>      <strong>3. Generalization of logistic regression combined with multi-instance learning.</strong> Let <em>R</em> = &#x2205;. The model is then reduced to a logistic regression combined with multi-instance learning [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0001">1</a>]. <div class="table-responsive">       <div class="display-equation">       <span class="tex mytex">\begin{align*} &#x0026;\beta ^*\!=\!\arg \min \nolimits _{\beta }\sum \nolimits _{u\in U}Loss_u(\beta)+\!\lambda _1\!\Vert \beta \Vert _1\end{align*} </span>       <br/>       </div>      </div>     </p>     <p>      <img src="http://deliveryimages.acm.org/10.1145/3190000/3186051/images/www2018-60-img1.svg" class="img-responsive" alt="" longdesc=""/>     </p>    </section>    </section>   </section>   <section id="sec-15">    <header>    <div class="title-info">     <h2>      <span class="section-number">5</span> Optimization</h2>    </div>    </header>    <p>The Equation (<a class="eqn" href="#eq8">8</a>) is a non-convex and non-smooth which is very difficult to be solved by traditional optimization methods. In most recent years, ever more work utilizes ADMM to solve non-convex and non-smooth problem effectively and efficiently [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0013">13</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>]. Here in order to solve Equation (<a class="eqn" href="#eq8">8</a>), we propose a new ADMM-based algorithm. To simplify the algorithm, we introduce an auxiliary variable <em>S</em> and reformulate the problem to its equivalence as follows: <div class="table-responsive" id="eq9">     <div class="display-equation">      <span class="tex mytex">\begin{align} \nonumber &#x0026;\beta ^*=\arg \min \nolimits _{\beta } \mathop \sum \nolimits _{u \in U}(\log (1+\exp (S_{u,I(u)}))-Y_u S_{u,I(u)}) +\lambda _1 \Vert \beta \Vert _1\\\nonumber &#x0026;\!-\!\lambda \!_2\!\sum \nolimits _{u_1\in U_p}\!\sum \nolimits _{u_2\in U_p}\!\sum \nolimits _{j=1}^{\vert K\vert } (D_{u_1,I(u_1),j}\!-\!D_{u_2,I(u_2),j})^2\!\beta _{j+1}\!^2\!/\!(n_p^2)\\ &#x0026;+2\lambda _2\sum \nolimits _{i=1}^{r}\sum \nolimits _{u\in U_p}\sum \nolimits _{j=1}^{\vert K\vert } (R_{i,j}-D_{u,I(u),j})^2\beta _{j+1}^2/(r\times n_p) \\\nonumber &#x0026;s.t. \ S_{u,i}=X_{u,i}\beta\end{align} </span>      <br/>      <span class="equation-number">(9)</span>     </div>    </div>    </p>    <p>The augmented Lagrangian function of Equation (<a class="eqn" href="#eq9">9</a>) is: <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\begin{align*} &#x0026;L_\rho (S,\beta ,h)=\sum \nolimits _{u \in U}(\log (1+\exp (S_{u,I(u)}))-Y_u S_{u,I(u)}) +\lambda _1 \Vert \beta \Vert _1\\ &#x0026;\!-\!\lambda _2\!\sum \nolimits _{u_1\in U_p}\!\sum \nolimits _{u_2\in U_p}\!\sum \nolimits _{j=1}^{\vert K\vert } (D_{u_1,I(u_1),j}\!-\!D_{u_2,I(u_2),j})^2\!\beta _{j+1}^2\!/\!(n_p^2)\\ &#x0026;+2\lambda _2\sum \nolimits _{i=1}^{r}\sum \nolimits _{u\in U_p}\sum \nolimits _{j=1}^{\vert K\vert } (R_{i,j}-D_{u,I(u),j})^2\beta _{j+1}^2/(r \times n_p)\\ &#x0026;+\rho /2\Vert S_{u,i}-X_{u,i}\beta +h_{u,i}\Vert ^2_2\end{align*} </span>      <br/>     </div>    </div> where <em>&#x03C1;</em> > 0 is a penalty parameter. The MIDA algorithm is shown in Algorithm 1. Concretely, Lines 8- 9 calculate residuals and Lines 4-7 update each parameter alternately by solving the sub-problems described below.</p>    <p>    <strong>Update <em>S</em>     <sup>      <em>k</em> + 1</sup>    </strong>    </p>    <p>The auxiliary variable <em>S</em> is updated as follows: <div class="table-responsive" id="eq10">     <div class="display-equation">      <span class="tex mytex">\begin{align} \nonumber &#x0026;S^{k+1} \leftarrow \arg \min \nolimits _S \sum \nolimits _{u\in U}(log(1+\exp (S_{u,I(u)}))-Y_u S_{u,I(u)})\\ &#x0026;+(\rho ^{k+1}/2)\Vert S -X\beta ^k+h^k \Vert ^2_2 \end{align} </span>      <br/>      <span class="equation-number">(10)</span>     </div>    </div> This subproblem is a logistic regression with an &#x2113;<sub>2</sub> penalty term. A fast iterative shrinkage-thresholding algorithm (FISTA) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] is applied to solve this problem because the log loss is differentiable so that each iteration has a close-form solution.</p>    <p>    <strong>Update <em>&#x03B2;</em>     <sup>      <em>k</em> + 1</sup>    </strong>    </p>    <p>The decision variable <em>&#x03B2;</em> is updated as follows: <div class="table-responsive" id="eq11">     <div class="display-equation">      <span class="tex mytex">\begin{align} \nonumber &#x0026;\beta ^{k+1} \leftarrow \arg \min \nolimits _{\beta } \lambda _1 \Vert \beta \Vert _1+\rho ^{k+1}/2\Vert S^{k+1}-X\beta +h^{k}\Vert ^2_2\\\nonumber &#x0026;-\!\lambda _2\!\sum \nolimits _{u_1\in U_p}\!\sum \nolimits _{u_2\in U_p}\!\sum \nolimits _{j=1}^{\vert K\vert } (D_{u_1,I(u_1),j}\!-\!D_{u_2,I(u_2),j})^2\!\beta _{j+1}^2\!/\!(n_p^2)\\ &#x0026;+2\lambda _2\sum \nolimits _{i=1}^{r}\sum \nolimits _{u\in U_p}\sum \nolimits _{j=1}^{\vert K\vert } (R_{i,j}\!-\!D_{u,I(u),j})^2\!\beta _{j+1}\!^2/(r \!\times \!n_p). \end{align} </span>      <br/>      <span class="equation-number">(11)</span>     </div>    </div>    </p>    <p>Even though this subproblem is nonconvex, it can be solved by Convex-Concave Procedure (CCP), which ensures local convergence [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>]. We split this objective function further, <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\begin{align*} &#x0026;l(\beta)=\lambda _1 \Vert \beta \Vert _1+\rho ^{k+1}/2\Vert S^{k+1}-X\beta +h^{k}\Vert ^2_2\\ &#x0026;+2\lambda _2\sum \nolimits _{i=1}^{r}\sum \nolimits _{u\in U_p}\sum \nolimits _{j=1}^{\vert K\vert } (R_{i,j}-D_{u,I(u),j})^2\beta _j^2/(r \times n_p)\\ &#x0026;m(\beta)=\lambda _2\!\sum \nolimits _{u_1\in U_p}\!\sum \nolimits _{u_2\in U_p}\!\sum \nolimits _{j=1}^{\vert K\vert } (D_{u_1,I(u_1),j}\!-\!D_{u_2,I(u_2),j})^2\!\beta _{j+1}^2\!/\!(n_p^2).\end{align*} </span>      <br/>     </div>    </div> then the optimization objective becomes: <div class="table-responsive">     <div class="display-equation">      <span class="tex mytex">\begin{align*} \beta ^{k+1}=\arg \min \nolimits _{\beta } l(\beta)-m(\beta)\end{align*} </span>      <br/>     </div>    </div> The algorithm of updating <em>&#x03B2;</em> is shown in Algorithm 2. The key idea of CCP is to convexify concave function <em>m</em>(<em>&#x03B2;</em>) by linearized function <span class="inline-equation"><span class="tex">$\tilde{m}(\beta)$</span>    </span>. Now the following problem can be solved by FISTA [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] again. <div class="table-responsive" id="eq12">     <div class="display-equation">      <span class="tex mytex">\begin{align} \beta ^{q+1}=\arg \min \nolimits _{\beta } l(\beta)-\tilde{m}(\beta) \end{align} </span>      <br/>      <span class="equation-number">(12)</span>     </div>    </div>    </p>    <p>Two important issues should be taken into account: one is to choose appropriate <em>&#x03C1;</em> and <em>&#x03BB;</em>    <sub>2</sub>. To guarantee the existence of the local optimum, the relationship between <em>&#x03C1;</em> and <em>&#x03BB;</em>    <sub>2</sub> can be set as <em>&#x03C1;</em> &#x2265; 10<em>&#x03BB;</em>    <sub>2</sub> empirically. Otherwise, the CCP will lead <em>&#x03B2;</em> to infinity. The other is the initial value of <em>&#x03B2;</em>, which affects convergence property and performance. It is recommended that an initial point of <em>&#x03B2;</em> be chosen from the coefficient of a trained logistic regression classifier.</p>    <p>    <img src="http://deliveryimages.acm.org/10.1145/3190000/3186051/images/www2018-60-img2.svg" class="img-responsive" alt="" longdesc=""/>    </p>   </section>   <section id="sec-16">    <header>    <div class="title-info">     <h2>      <span class="section-number">6</span> Experiments</h2>    </div>    </header>    <p>In this section, we evaluate the MIDA using a real adverse event detection dataset, which demonstrated the effectiveness and outstanding performance of MIDA compared with existing methods. Sensitivity analysis and scalability analysis on the effect of several factors were also explored. Case studies on the formal reports and extracted adverse-relevant tweets were analyzed as well. All experiments were conducted on a 64-bit machine with Intel(R) core(TM) quad-core processor (i3-3217U CPU@ 1.80GHZ) and 4.0GB memory.</p>    <section id="sec-17">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.1</span> Dataset Description</h3>     </div>    </header>    <p>The task of the first dataset is to detect whether Twitter users are affected by adverse event according to their tweets. The dataset consists of Twitter data and formal reports. They both were encoded by 234 keywords.</p>    <p>     <strong>Input Twitter Data Retrieval.</strong> Twitter data were analyzed in compliance with the Twitter policies<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a>. The Twitter data in this paper were retrieved by the following process. First, we queried the Twitter API to obtain the tweets that were potentially related to the topic &#x201D;flu shot&#x201D; by the query consisting of 113 keywords including &#x201D;flu&#x201D;, &#x201D;h1n1&#x201D;, &#x201D;vaccine&#x201D;. A total of 11,993,211,616 tweets for the period between Jan 1, 2011 and Apr 15, 2015 in the United States were retrieved. Second, from the retrieved tweet sets, the Twitter users who had indicated flu vaccination were identified by their tweets using the LibShortText [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0038">38</a>] text filter that was trained on 10,000 positive and another 10,000 negative tweets provided by Lamb et al. [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0019">19</a>]. The full text representations were used as the features in LibShortText. Then, we queried the Twitter API again for those users identified in the second step to obtain their tweets posted within 60 days since their vaccination were identified. The retrieved tweets formed our final Twitter data set, which contained 41,438 tweets from 1,572 users where 566 were labeled as positive users and 1,006 were negative.</p>    <p>     <strong>Formal Reports.</strong> We downloaded all raw data from the Vaccine Adverse Event Reporting Systems (VAERS) for the year 2016 in the Comma-separated Value (CSV) format<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a>. The VAERS data consisted of 29 columns including VAERS ID, report date, sex, age and symptom text. The symptom text column contained adverse event descriptions either from patients or doctors. Each element in the symptom text column was considered as a formal report. 2500 formal reports were extracted.</p>    </section>    <section id="sec-18">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.2</span> Experimental Protocol</h3>     </div>    </header>    <section id="sec-19">     <p><em>6.2.1 Parameter Settings and Metrics.</em> We considered the MIDA for comparison. Two tuning variables <em>&#x03BB;</em>      <sub>1</sub> and <em>&#x03BB;</em>      <sub>2</sub> are included in the algorithm, which were set to 0.01 and 1 based on a five-fold cross validation on the training set, respectively. In addition, the number of partition <em>c</em> was set to 100. The maximum number of iterations was set to 20.</p>     <p>Several metrics were utilized to evaluate model performance: the Accuracy (ACC) is the ratio of accurately labeled samples to all samples; the Precision (PR) is the ratio of accurately labeled as positive samples to all labeled as positive samples; the Recall (RE) defines the ratio of accurately labeled as positive samples to all positive samples; the F-score (FS) is the harmonic mean of precision and recall; the Receiver Operating Characteristic (ROC) curve delineates the classification ability of a model as its discrimination threshold varies; and the Area Under ROC curve (AUC) is an important measurement of classification ability; the Precision Recall (PR) curve is the other one to measure classification performance in which recall and precision are listed as the X axis and the Y axis, respectively. The Area Under PR curve (AUPR) is as important as AUC.</p>     <p>Besides model performance comparison, we also explored the effect of number of iterations on the AUC and that of number of formal reports and number of users on the running time per iteration.</p>    </section>    <section id="sec-20">     <p><em>6.2.2 Comparison Methods.</em> The following methods were utilized as baselines for the performance comparison. All parameters in the baselines were set based on the five-fold cross validation on the training set. Baselines were categorized by either multi-instance learning methods or transfer learning methods. Method 1 and 2 belong to multi-instance learning methods, they do not need formal reports. Method 3,4 and 5 belong to the transfer learning category. For them, the input matrix <em>X<sub>u</sub>      </em> was summed by column for user <em>u</em> &#x2208; <em>U</em> on the Twitter data.</p>     <p>1. Multi-instance Learning based on Fisher Vector representation (miFV) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0035">35</a>]. Multiple instances were mapped into a high dimensional vector by the Fisher Vector (FV) representation. The SVM was applied to train a classifier.</p>     <p>2. Multi-instance Learning based on the Vector of Locally Aggregated Descriptors representation (miVLAD) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0035">35</a>]. The idea of the miVLAD was very similar to miFV, except that instances were mapped by the Vector of Locally Aggregated Descriptors (VLAD) representation.</p>     <p>3. Joint Distribution Adaptation (JDA) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0024">24</a>]. JDA aimed to reduce both marginal distributions and conditional distributions between the source domain and target domain. It mapped two domains into a common Hilbert space.</p>     <p>4. Graph Co-Regularized Transfer Learning (GTL) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0023">23</a>]. GTL complemented empirical likelihood maximization with geometric structure preservation and integrated them seamlessly into a unified framework.</p>     <p>5. Adaptation Regularization based Transfer Learning (ARTL) [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0022">22</a>]. The propose of ARTL was to minimize structural risk, domain distribution difference and perverse manifold consistency simultaneously.</p>    </section>    </section>    <section id="sec-21">    <header>     <div class="title-info">      <h3>       <span class="section-number">6.3</span> Performance</h3>     </div>    </header>    <p>In this section, experimental results for the MIDA are analyzed for all the comparison methods. Table <a class="tbl" href="#tab3">3</a> summarizes prediction results of the MIDA compared with other methods on the Twitter dataset.</p>    <section id="sec-22">     <p><em>6.3.1 Model Performance on the Twitter Dataset.</em> The results demonstrated in Table <a class="tbl" href="#tab3">3</a> indicated that the MIDA performed better than any baseline. It ranked the first in the four metrics except the RE and the FS metric. As two most important metrics, the AUC and the AUPR, the MIDA dominated all baselines: the AUC of the MIDA was higher than 0.85, while that of ARTL was lower than 0.6; the AUPR of the MIDA exceeded 0.76, whereas that of the miVLAD was only 0.70. When it came to the ACC, the MIDA was about 0.16 better than the GTL. The MIDA also achieved a competitive score in the RE metrics, surpassing 0.53 whereas the PR of the JDA was only around 0.49. As for the PR, the MIDA performed 0.14 better than that of the JDA. Due to excellent performance in the PR and the RE metric, the MIDA was competitive in the FS metric, which was 0.13 better than the ARTL. The superiority of the MIDA consisted in effective utilization of formal reports by distribution matching, while multi-instance learning methods lacked formal reports and summation by column led to great information loss for transfer learning methods. Multi-instance learning methods outperformed transfer learning methods thoroughly. The ACCs of the miFV and the miVLAD were both higher than 0.76, whereas the best score of transfer learning methods, which was achieved by the JDA, was only lower than 0.72. The PR scores of the miFV and the miVLAD were in the vicinity of 0.71, 0.3 better than that of the GTL and the ARTL.</p>     <p>Figure <a class="fig" href="#fig3">3</a> shows the ROC and the PR curve of the MIDA and baselines. In the ROC curve, the X axis and the Y axis denote False Positive Rate (FPR) and True Positive Rate (TPR), respectively. In the PR curve, the X axis and the Y axis denote Recall and Precision, respectively. Overall, the ROC curve of the MIDA covered larger area than any baselines, which was consistent with Table <a class="tbl" href="#tab3">3</a>. The miFV and the miVLAD performed similarly: they both outperformed three transfer learning methods. The ARTL performed the worst of all baselines, which was slightly better than the random guess. The similar patterns were displayed in the PR curve: all baselines were surrounded by the MIDA. The PR curves of three transfer learning methods: the JDA, the GTL and the ARTL were surrounded by these of two multi-instance learning methods: the miFV and the miVLAD.</p>     <div class="table-responsive" id="tab3">      <div class="table-caption">       <span class="table-number">Table 3:</span>       <span class="table-title">Classification performance on the Twitter dataset under six metrics: the MIDA dominated all baselines.</span>      </div>      <table class="table">       <thead>       <tr>        <th style="text-align:center;">Method</th>        <th style="text-align:center;">ACC</th>        <th style="text-align:center;">PR</th>        <th style="text-align:center;">RE</th>        <th style="text-align:center;">FS</th>        <th style="text-align:center;">AUC</th>        <th>AUPR</th>       </tr>     </thead>     <tbody>       <tr>        <td style="text-align:center;">miFV</td>        <td style="text-align:center;">0.7754</td>        <td style="text-align:center;">0.7321</td>        <td style="text-align:center;">0.5965</td>        <td style="text-align:center;">         <strong>0.6570</strong>        </td>        <td style="text-align:center;">0.8451</td>        <td>0.7584</td>       </tr>       <tr>        <td style="text-align:center;">miVLAD</td>        <td style="text-align:center;">0.7614</td>        <td style="text-align:center;">0.6882</td>        <td style="text-align:center;">         <strong>0.6245</strong>        </td>        <td style="text-align:center;">0.6535</td>        <td style="text-align:center;">0.8227</td>        <td>0.7053</td>       </tr>       <tr>        <td style="text-align:center;">JDA</td>        <td style="text-align:center;">0.7163</td>        <td style="text-align:center;">0.6370</td>        <td style="text-align:center;">0.4938</td>        <td style="text-align:center;">0.5552</td>        <td style="text-align:center;">0.7091</td>        <td>0.4652</td>       </tr>       <tr>        <td style="text-align:center;">GTL</td>        <td style="text-align:center;">0.6158</td>        <td style="text-align:center;">0.4215</td>        <td style="text-align:center;">0.2061</td>        <td style="text-align:center;">0.2750</td>        <td style="text-align:center;">0.6310</td>        <td>0.4905</td>       </tr>       <tr>        <td style="text-align:center;">ARTL</td>        <td style="text-align:center;">0.5356</td>        <td style="text-align:center;">0.4108</td>        <td style="text-align:center;">0.6435</td>        <td style="text-align:center;">0.5003</td>        <td style="text-align:center;">0.5997</td>        <td>0.4494</td>       </tr>       <tr>        <td style="text-align:center;">MIDA</td>        <td style="text-align:center;">         <strong>0.7767</strong>        </td>        <td style="text-align:center;">         <strong>0.7735</strong>        </td>        <td style="text-align:center;">0.5333</td>        <td style="text-align:center;">0.6310</td>        <td style="text-align:center;">         <strong>0.8530</strong>        </td>        <td>         <strong>0.7642</strong>        </td>       </tr>       </tbody>      </table>     </div>     <figure id="fig3">      <img src="http://deliveryimages.acm.org/10.1145/3190000/3186051/images/www2018-60-fig3.jpg" class="img-responsive" alt="Figure 3"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 3:</span>       <span class="figure-title">ROC curve and PR curve under the Twitter dataset: the MIDA was superior to baselines.</span>      </div>     </figure>    </section>    <section id="sec-23">     <p><em>6.3.2 The effect of iterations on the residuals and the AUC.</em> We examined the effect of iterations on the residuals and the AUCs. The AUC metric was chosen because it reflected classification generalization while five other metrics were subject to change as the threshold varied.</p>     <p>Figure <a class="fig" href="#fig4">4</a>(a) shows the change of residuals <em>r</em> and <em>s</em> with respect to iteration. The primal residual <em>r</em> remained a smooth and steady decline while the dual residual <em>s</em> tumbled down rapidly at first, then increased slightly and finally decreased steadily to less than 2. The AUCs of training data and test data with regard to iteration are displayed in Figure <a class="fig" href="#fig4">4</a>(b). Surprisingly, the AUC of test data was better than that of training data. They both increased sharply at the beginning, then the increase began to decrease as the iteration continued. This trend reflected that tens of iteration were sufficient to practical applications for the ADMM algorithm [<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"       href="#BibPLXBIB0004">4</a>]. Another important point is that the AUCs of the training and the test data started at very high level. Therefore the ADMM algorithm achieved a satisfactory result even with several iterations. <figure id="fig4">       <img src="http://deliveryimages.acm.org/10.1145/3190000/3186051/images/www2018-60-fig4.jpg" class="img-responsive" alt="Figure 4"        longdesc=""/>       <div class="figure-caption">       <span class="figure-number">Figure 4:</span>       <span class="figure-title">The effect of iteration on the residuals and AUCs: <em>r</em> and <em>s</em> declined with iteration; the AUCs of both training and test data increased steadily with iteration.</span>       </div>      </figure>     </p>    </section>    <section id="sec-24">     <p><em>6.3.3 Running time per iteration.</em> In this subsection, the relationship between running time per iteration and two potential factors, namely, the number of users, the number of formal reports was explored. The running time was calculated by the average of 20 iterations. The result is shown in Table <a class="tbl" href="#tab4">4</a>. The number of users ranged from 100 to 1,500, with increasing 100 each time whereas the number of formal reports ranged from 500 to 2,500 and 500 was increased each time. Generally, the running time increased as the user set and the formal report set became larger. However, some exceptions were found in Table <a class="tbl" href="#tab4">4</a>: for example, when 800 users were available, the running time was reduced by 0.82 seconds from 2,000 to 2,500 formal reports. The reduce was 0.32 seconds with 900 users. We found that number of users had a more effect on running time per iteration than number of formal reports. For instance, when 2,000 formal reports were available, the running time was increased by 1.2 seconds from 300 users to 400 users. However, the increase was only 0.4 seconds from 2,000 to 2,500 formal reports with 300 users.</p>     <div class="table-responsive" id="tab4">      <div class="table-caption">       <span class="table-number">Table 4:</span>       <span class="table-title">The relation between running time per iteration (seconds) and number of formal reports and number of users: generally, running time per iteration increased with number of formal reports and number of users; number of users had a more effect on running time per iteration than number of formal reports.</span>      </div>      <table class="table">       <thead>       <tr>        <th colspan="6" style="text-align:center;">From 100 users to 500 users<hr/>        </th>       </tr>       <tr>        <th style="text-align:left;">Formal</th>        <th style="text-align:left;">100 users</th>        <th style="text-align:left;">200 users</th>        <th style="text-align:left;">300 users</th>        <th style="text-align:left;">400 users</th>        <th style="text-align:left;">500 users</th>       </tr> 						</thead> 						<tbody>       <tr>        <td style="text-align:left;">#report</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>        <td style="text-align:left;"/>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;">500</td>        <td style="text-align:left;">1.6225</td>        <td style="text-align:left;">1.7930</td>        <td style="text-align:left;">2.8969</td>        <td style="text-align:left;">3.5768</td>        <td style="text-align:left;">3.8594</td>       </tr>       <tr>        <td style="text-align:left;">1000</td>        <td style="text-align:left;">1.4199</td>        <td style="text-align:left;">1.7098</td>        <td style="text-align:left;">2.6765</td>        <td style="text-align:left;">3.4179</td>        <td style="text-align:left;">3.3053</td>       </tr>       <tr>        <td style="text-align:left;">1500</td>        <td style="text-align:left;">1.0185</td>        <td style="text-align:left;">1.7127</td>        <td style="text-align:left;">2.6551</td>        <td style="text-align:left;">3.3280</td>        <td style="text-align:left;">4.0004</td>       </tr>       <tr>        <td style="text-align:left;">2000</td>        <td style="text-align:left;">1.6106</td>        <td style="text-align:left;">1.9634</td>        <td style="text-align:left;">3.2525</td>        <td style="text-align:left;">4.4560</td>        <td style="text-align:left;">4.6050</td>       </tr>       <tr>        <td style="text-align:left;">2500</td>        <td style="text-align:left;">1.2893</td>        <td style="text-align:left;">2.3403</td>        <td style="text-align:left;">3.6309</td>        <td style="text-align:left;">4.4778</td>        <td style="text-align:left;">4.9070</td>       </tr>       <tr>        <td colspan="6" style="text-align:center;">From 600 users to 1000 users<hr/>        </td>       </tr>       <tr>        <td style="text-align:left;">Formal</td>        <td style="text-align:left;">600 users</td>        <td style="text-align:left;">700 users</td>        <td style="text-align:left;">800 users</td>        <td style="text-align:left;">900 users</td>        <td style="text-align:left;">1000 users</td>       </tr>       <tr>        <td style="text-align:left;">#report</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>        <td style="text-align:left;"/>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;">500</td>        <td style="text-align:left;">4.0152</td>        <td style="text-align:left;">4.1292</td>        <td style="text-align:left;">4.8341</td>        <td style="text-align:left;">4.8169</td>        <td style="text-align:left;">4.8815</td>       </tr>       <tr>        <td style="text-align:left;">1000</td>        <td style="text-align:left;">4.3464</td>        <td style="text-align:left;">4.9213</td>        <td style="text-align:left;">5.2131</td>        <td style="text-align:left;">5.2943</td>        <td style="text-align:left;">5.4708</td>       </tr>       <tr>        <td style="text-align:left;">1500</td>        <td style="text-align:left;">4.1058</td>        <td style="text-align:left;">3.9091</td>        <td style="text-align:left;">5.3806</td>        <td style="text-align:left;">5.6140</td>        <td style="text-align:left;">5.8158</td>       </tr>       <tr>        <td style="text-align:left;">2000</td>        <td style="text-align:left;">4.6901</td>        <td style="text-align:left;">5.4462</td>        <td style="text-align:left;">5.9321</td>        <td style="text-align:left;">6.0469</td>        <td style="text-align:left;">6.2645</td>       </tr>       <tr>        <td style="text-align:left;">2500</td>        <td style="text-align:left;">5.3191</td>        <td style="text-align:left;">5.4397</td>        <td style="text-align:left;">5.1165</td>        <td style="text-align:left;">5.6264</td>        <td style="text-align:left;">5.8152</td>       </tr>       <tr>        <td colspan="6" style="text-align:center;">From 1100 users to 1500 users<hr/>        </td>       </tr>       <tr>        <td style="text-align:left;">Formal</td>        <td style="text-align:left;">1100 users</td>        <td style="text-align:left;">1200 users</td>        <td style="text-align:left;">1300 users</td>        <td style="text-align:left;">1400 users</td>        <td style="text-align:left;">1500 users</td>       </tr>       <tr>        <td style="text-align:left;">#report</td>        <td style="text-align:left;"/>        <td style="text-align:left;"/>        <td style="text-align:left;"/>        <td style="text-align:left;"/>        <td style="text-align:left;"/>       </tr>       <tr>        <td style="text-align:left;">500</td>        <td style="text-align:left;">5.7781</td>        <td style="text-align:left;">6.2938</td>        <td style="text-align:left;">6.8072</td>        <td style="text-align:left;">6.9020</td>        <td style="text-align:left;">7.3748</td>       </tr>       <tr>        <td style="text-align:left;">1000</td>        <td style="text-align:left;">6.1258</td>        <td style="text-align:left;">7.3894</td>        <td style="text-align:left;">7.6492</td>        <td style="text-align:left;">7.8697</td>        <td style="text-align:left;">7.2863</td>       </tr>       <tr>        <td style="text-align:left;">1500</td>        <td style="text-align:left;">6.5922</td>        <td style="text-align:left;">7.6391</td>        <td style="text-align:left;">8.3772</td>        <td style="text-align:left;">8.4165</td>        <td style="text-align:left;">8.7627</td>       </tr>       <tr>        <td style="text-align:left;">2000</td>        <td style="text-align:left;">7.1287</td>        <td style="text-align:left;">7.8769</td>        <td style="text-align:left;">8.3860</td>        <td style="text-align:left;">9.1307</td>        <td style="text-align:left;">9.1151</td>       </tr>       <tr>        <td style="text-align:left;">2500</td>        <td style="text-align:left;">7.6745</td>        <td style="text-align:left;">8.2669</td>        <td style="text-align:left;">8.8098</td>        <td style="text-align:left;">9.6669</td>        <td style="text-align:left;">9.7889</td>       </tr>       </tbody>      </table>     </div>    </section>    <section id="sec-25">     <p><em>6.3.4 Scalability analysis.</em> To examine the scalability of the MIDA, we measured the training times of all methods when varying number of users and number of keywords. The training time was calculated by the average of 5-fold cross validation.</p>     <p>Figure <a class="fig" href="#fig5">5</a>(a) compares the running time for all methods when the number of users changed from 100 to 1500. Basically, the running time of all methods increased linearly with number of users. Among them, the ARTL and the GTL required the shortest running time compared with other methods. The miFV and the miVLAD were also very efficient even though they were multi-instance methods. Compared with all baselines, the MIDA performs the most work. However, the MIDA effectively reduced computational time by the parallel computing strategy of the ADMM. Surprisingly, the JDA was the slowest method among all baselines. It doubled the training time of the MIDA when 1,500 users were used for training.</p>     <p>To examine the scalability for an increasing number of keywords, Figure <a class="fig" href="#fig5">5</a>(b) illustrates the running time of all methods when number of keywords jumped from 10 to 234. Similar to the patterns shown in Figure <a class="fig" href="#fig5">5</a>(a), the running time of all methods increased linearly with number of keywords, which demonstrated that our MIDA was scalable with respect to number of keywords. Note that the ARTL, the GTL, the miFV and the miVLAD increased smoothly with number of keywords. The JDA skyrocketed to 300 seconds when 234 keywords were included for training. <figure id="fig5">       <img src="http://deliveryimages.acm.org/10.1145/3190000/3186051/images/www2018-60-fig5.jpg" class="img-responsive" alt="Figure 5"        longdesc=""/>       <div class="figure-caption">       <span class="figure-number">Figure 5:</span>       <span class="figure-title">Scalability on number of keywords and users: all methods increased linearly with the number of keywords and users.</span>       </div>      </figure>     </p>    </section>    <section id="sec-26">     <p><em>6.3.5 Case Studies.</em> We found some benefits from formal reports to improve classifier performance to detect adverse-relevant (i.e., positive) tweets. Figure <a class="fig" href="#fig6">6</a> compares the keyword patterns of formal reports, the adverse-relevant tweets and adverse-irrelevant (i.e., negative) tweets identified by our method. In each word cloud, the size of keywords is proportional to their frequencies in the tweet set or the formal report set. In every figure, several important and largest keywords are highlighted in red squares. In Figure <a class="fig" href="#fig6">6</a>(a), the largest keywords &#x2018;physician&#x2019;, &#x2018;medical&#x2019;, &#x2018;patients&#x2019; and &#x2018;dose&#x2019; were unique in the formal report domain, but several keywords were also shown to describe vaccine side effects like &#x2018;headache&#x2019;, &#x2018;swollen&#x2019;, &#x2018;arm&#x2019; and &#x2018;allergies&#x2019;. Figure <a class="fig" href="#fig6">6</a>(b) showed some largest symptom-descriptive keywords such as &#x2018;headache&#x2019;, &#x2018;sore&#x2019;, &#x2018;arm&#x2019;, &#x2018;allergies&#x2019; and &#x2018;throat&#x2019;. Among them, keywords &#x2018;headache&#x2019;, &#x2018;allergies&#x2019; and &#x2018;arm&#x2019; both appeared in Figure <a class="fig" href="#fig6">6</a>(a) and (b), indicating some common symptom descriptions were found in both formal reports and tweets. This implied that MIDA benefited from the adaptation from the formal report domain to the Twitter domain. In Figure <a class="fig" href="#fig6">6</a>(c), several largest keywords including &#x2018;bad&#x2019;, &#x2018;feeling&#x2019; and &#x2018;sick&#x2019; were general words, which showed that the identified negative tweets were relatively irrelevant to adverse events. The difference of keyword frequencies between Figure <a class="fig" href="#fig6">6</a>(b) and (c) and the similarity of that between Figure <a class="fig" href="#fig6">6</a>(a) and (b) justified the effectiveness of MIDA as shown in Figure <a class="fig" href="#fig1">1</a>: the similar adverse-relevant tweets are to formal reports, the more distinguishable adverse-relevant tweets are from adverse-irrelevant ones. <figure id="fig6">       <img src="http://deliveryimages.acm.org/10.1145/3190000/3186051/images/www2018-60-fig6.jpg" class="img-responsive" alt="Figure 6"        longdesc=""/>       <div class="figure-caption">       <span class="figure-number">Figure 6:</span>       <span class="figure-title">Keyword frequencies of formal reports and tweets: extracted adverse-relevant tweets shared a sense of similarity with formal reports, but were different from adverse-irrelevant tweets.</span>       </div>      </figure>     </p>     <p>To further explore the benefits of formal reports to MIDA in a deep insight, Table <a class="tbl" href="#tab5">5</a> illustrates five common symptoms found in both formal reports and tweets extracted by MIDA. Most of them were pain in a certain organ, such as arm pain, shoulder and neck pain and headache. The second and third column displayed formal reports and tweets which described the same symptom. We found that text descriptions were very similar in formal reports and tweets, which complied with the findings in Figure <a class="fig" href="#fig6">6</a>. For example, headache and arm pain were listed as two common symptoms recorded in Table <a class="tbl" href="#tab5">5</a>; correspondingly, keywords &#x2018;headache&#x2019; and &#x2018;arm&#x2019; were one of the most frequent keywords in Figure <a class="fig" href="#fig6">6</a> (a) and (b). This implies that despite word usage differences between formal reports and tweets, they share a sense of similarity in the keyword and description patterns. Therefore, the strategy of MIDA that adapting formal reports to tweets benefits the classifier.</p>     <div class="table-responsive" id="tab5">      <div class="table-caption">       <span class="table-number">Table 5:</span>       <span class="table-title">Five common symptom descriptions in both formal reports and adverse-relevant tweets extracted by MIDA: text descriptions in formal reports and tweets were similar.</span>      </div>      <table class="table">       <thead>       <tr>        <th style="text-align:center;">Symptoms</th>        <th style="text-align:center;">Formal Reports</th>        <th>Adverse-relevant Tweets</th>       </tr>       <tr>        <th style="text-align:center;"/>        <th style="text-align:center;"/>        <th>Extracted by MIDA</th>       </tr> 						</thead> 						<tbody>       <tr>        <td style="text-align:center;">arm pain</td>        <td style="text-align:center;">Arm pain for >7 days, sought medical treatment at clinic.</td>        <td>Not only did I fall down the steps, but I got my flu shot and my arm is sore.</td>       </tr>       <tr>        <td style="text-align:center;">shoulder and neck pain</td>        <td style="text-align:center;">overall aches and pain, but especially in back shoulder blade area and neck.</td>        <td>got my flu shot 30 minutes ago and the SERIOUS ache is spreading to my shoulder into my neck.</td>       </tr>       <tr>        <td style="text-align:center;">headache</td>        <td style="text-align:center;">An hour after getting the shot he got a headache and then started throwing up.</td>        <td>I feel that headache slowly coming back after getting shots.</td>       </tr>       <tr>        <td style="text-align:center;">runny nose</td>        <td style="text-align:center;">Pt received vaccine on 12/11/15.12/14/15 diarrhea, runny nose, cough.</td>        <td>Damn flu shots! now my nose startin to run.</td>       </tr>       <tr>        <td style="text-align:center;">throat pain</td>        <td style="text-align:center;">Shortly after patient was vaccinated, she started to feel an itching, tingling feeling in her throat.</td>        <td>Just got a shot! i dnt wanna get sick! I already have a sore throat now.</td>       </tr>       </tbody>      </table>     </div>    </section>    </section>   </section>   <section id="sec-27">    <header>    <div class="title-info">     <h2>      <span class="section-number">7</span> Conclusion</h2>    </div>    </header>    <p>Vaccine adverse event detection is a crucial problem for healthcare. Social media has started to be used to detect adverse events because of its message timeliness and sensor ubiquity. However, it still suffers from prohibitive labeling cost and class imbalance problem, which can be solved by formal reports. In this paper, we propose a novel Multi-instance Domain Adaptation (MIDA) model to minimize the domain differences between formal reports and Twitter data. An efficient algorithm has been developed to optimize parameters accurately. Various experiments demonstrated that our model was superior to all baselines under six metrics. Case studies showed that similar keyword and description patterns were shown in both formal reports and adverse-relevant tweets.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>    <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>    </div>    </header>    <ul class="bibUl">    <li id="BibPLXBIB0001" label="[1]">Jaume Amores. 2013. Multiple instance classification: Review, taxonomy and comparative study. <em>      <em>Artificial Intelligence</em>     </em>201, 4 (2013), 81&#x2013;105.</li>    <li id="BibPLXBIB0002" label="[2]">Stuart Andrews, Ioannis Tsochantaridis, and Thomas Hofmann. 2002. Support Vector Machines for Multiple-Instance Learning. <em>      <em>Advances in Neural Information Processing Systems</em>     </em>15, 2 (2002), 561&#x2013;568.</li>    <li id="BibPLXBIB0003" label="[3]">Amir Beck and Marc Teboulle. 2009. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. <em>      <em>SIAM journal on imaging sciences</em>     </em>2, 1 (2009), 183&#x2013;202.</li>    <li id="BibPLXBIB0004" label="[4]">Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. 2011. Distributed optimization and statistical learning via the alternating direction method of multipliers. <em>      <em>Foundations and Trends&#x00AE; in Machine Learning</em>     </em>3, 1(2011), 1&#x2013;122.</li>    <li id="BibPLXBIB0005" label="[5]">Rita Chattopadhyay, Qian Sun, Wei Fan, Ian Davidson, Sethuraman Panchanathan, and Jieping Ye. 2012. Multisource domain adaptation and its application to early detection of fatigue. <em>      <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em>     </em>6, 4(2012), 18.</li>    <li id="BibPLXBIB0006" label="[6]">Liangzhe Chen, K.&#x00A0;S. M.&#x00A0;Tozammel Hossain, Patrick Butler, Naren Ramakrishnan, and B.&#x00A0;Aditya Prakash. 2014. Flu Gone Viral: Syndromic Surveillance of Flu on Twitter Using Temporal Topic Models. In <em>      <em>IEEE International Conference on Data Mining</em>     </em>. 755&#x2013;760.</li>    <li id="BibPLXBIB0007" label="[7]">Hal Daum&#x00E9;&#x00A0;III. 2009. Frustratingly easy domain adaptation. <em>      <em>arXiv preprint arXiv:0907.1815</em>     </em>(2009).</li>    <li id="BibPLXBIB0008" label="[8]">Thomas&#x00A0;G Dietterich, Richard&#x00A0;H Lathrop, and Tom&#x00E1;s Lozano-P&#x00E9;rez. 1997. Solving the multiple instance problem with axis-parallel rectangles. <em>      <em>Artificial intelligence</em>     </em>89, 1-2 (1997), 31&#x2013;71.</li>    <li id="BibPLXBIB0009" label="[9]">Lixin Duan, Ivor&#x00A0;W Tsang, and Dong Xu. 2012. Domain transfer multiple kernel learning. <em>      <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>     </em>34, 3(2012), 465&#x2013;479.</li>    <li id="BibPLXBIB0010" label="[10]">Lixin Duan, Dong Xu, and Ivor Tsang. 2012. Learning with augmented features for heterogeneous domain adaptation. <em>      <em>arXiv preprint arXiv:1206.4660</em>     </em>(2012).</li>    <li id="BibPLXBIB0011" label="[11]">Fran&#x00E7;ois Fleuret and Hichem Sahbi. 2003. Scale-invariance of support vector machines based on the triangular kernel. In <em>      <em>3rd International Workshop on Statistical and Computational Theories of Vision</em>     </em>. 1&#x2013;13.</li>    <li id="BibPLXBIB0012" label="[12]">Zhouyu Fu and Antonio Robles-Kelly. 2009. An instance selection approach to multiple instance learning. In <em>      <em>Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on</em>     </em>. IEEE, 911&#x2013;918.</li>    <li id="BibPLXBIB0013" label="[13]">Mingyi Hong, Zhi-Quan Luo, and Meisam Razaviyayn. 2016. Convergence analysis of alternating direction method of multipliers for a family of nonconvex problems. <em>      <em>SIAM Journal on Optimization</em>     </em>26, 1 (2016), 337&#x2013;364.</li>    <li id="BibPLXBIB0014" label="[14]">Hayate Iso, Shoko Wakamiya, and Eiji Aramaki. 2016. Forecasting Word Model: Twitter-based Influenza Surveillance and Prediction.. In <em>      <em>COLING</em>     </em>. 76&#x2013;86.</li>    <li id="BibPLXBIB0015" label="[15]">L. K.2013. Real-time disease surveillance using Twitter data: demonstration on flu and cancer. In <em>      <em>ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>     </em>. 1474&#x2013;1477.</li>    <li id="BibPLXBIB0016" label="[16]">Shehroz&#x00A0;S Khan and Michael&#x00A0;G Madden. 2009. A survey of recent trends in one class classification. In <em>      <em>Irish Conference on Artificial Intelligence and Cognitive Science</em>     </em>. Springer, 188&#x2013;197.</li>    <li id="BibPLXBIB0017" label="[17]">Brian Kulis, Kate Saenko, and Trevor Darrell. 2011. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms. In <em>      <em>Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</em>     </em>. IEEE, 1785&#x2013;1792.</li>    <li id="BibPLXBIB0018" label="[18]">Anurag Kumar and Bhiksha Raj. 2016. Audio event detection using weakly labeled data. In <em>      <em>Proceedings of the 2016 ACM on Multimedia Conference</em>     </em>. ACM, 1038&#x2013;1047.</li>    <li id="BibPLXBIB0019" label="[19]">Alex Lamb, Michael&#x00A0;J Paul, and Mark Dredze. 2013. Separating Fact from Fear: Tracking Flu Infections on Twitter.. In <em>      <em>HLT-NAACL</em>     </em>. 789&#x2013;795.</li>    <li id="BibPLXBIB0020" label="[20]">Vasileios Lampos, Tijl De&#x00A0;Bie, and Nello Cristianini. 2010. Flu detector-tracking epidemics on Twitter. In <em>      <em>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>     </em>. Springer, 599&#x2013;602.</li>    <li id="BibPLXBIB0021" label="[21]">Thomas Lipp and Stephen Boyd. 2016. Variations and extension of the convex&#x2013;concave procedure. <em>      <em>Optimization and Engineering</em>     </em>17, 2 (2016), 263&#x2013;287.</li>    <li id="BibPLXBIB0022" label="[22]">Mingsheng Long, Jianmin Wang, Guiguang Ding, Sinno&#x00A0;Jialin Pan, and S&#x00A0;Yu Philip. 2014. Adaptation regularization: A general framework for transfer learning. <em>      <em>IEEE Transactions on Knowledge and Data Engineering</em>     </em>26, 5(2014), 1076&#x2013;1089.</li>    <li id="BibPLXBIB0023" label="[23]">Mingsheng Long, Jianmin Wang, Guiguang Ding, Dou Shen, and Qiang Yang. 2014. Transfer learning with graph co-regularization. <em>      <em>IEEE Transactions on Knowledge and Data Engineering</em>     </em>26, 7(2014), 1805&#x2013;1818.</li>    <li id="BibPLXBIB0024" label="[24]">Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, and Philip&#x00A0;S Yu. 2013. Transfer feature learning with joint distribution adaptation. In <em>      <em>Proceedings of the IEEE international conference on computer vision</em>     </em>. 2200&#x2013;2207.</li>    <li id="BibPLXBIB0025" label="[25]">Alejandro Metke-Jimenez, Sarvnaz Karimi, and Cecile Paris. 2014. Evaluation of text-processing algorithms for adverse drug event extraction from social media. In <em>      <em>International Workshop on Social Media Retrieval and Analysis</em>     </em>. 15&#x2013;20.</li>    <li id="BibPLXBIB0026" label="[26]">Sinno&#x00A0;Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang Yang, and Zheng Chen. 2010. Cross-domain sentiment classification via spectral feature alignment. In <em>      <em>Proceedings of the 19th international conference on World wide web</em>     </em>. ACM, 751&#x2013;760.</li>    <li id="BibPLXBIB0027" label="[27]">Sinno&#x00A0;Jialin Pan and Qiang Yang. 2010. A survey on transfer learning. <em>      <em>IEEE Transactions on knowledge and data engineering</em>     </em>22, 10(2010), 1345&#x2013;1359.</li>    <li id="BibPLXBIB0028" label="[28]">Michael&#x00A0;J Paul and Mark Dredze. 2011. You are what you Tweet: Analyzing Twitter for public health.<em>      <em>Icwsm</em>     </em>20(2011), 265&#x2013;272.</li>    <li id="BibPLXBIB0029" label="[29]">Duda Ro and Hart Pe. 1973. Pattern classification and scene analysis. (1973).</li>    <li id="BibPLXBIB0030" label="[30]">Alessio Signorini, Alberto&#x00A0;Maria Segre, and Philip&#x00A0;M Polgreen. 2011. The use of Twitter to track levels of disease activity and public concern in the US during the influenza A H1N1 pandemic. <em>      <em>PloS one</em>     </em>6, 5 (2011), e19467.</li>    <li id="BibPLXBIB0031" label="[31]">Vladimir&#x00A0;Naumovich Vapnik and Vlamimir Vapnik. 1998. <em>      <em>Statistical learning theory</em>     </em>. Vol.&#x00A0;1. Wiley New York.</li>    <li id="BibPLXBIB0032" label="[32]">Ke Wang, Jiayong Liu, and Daniel Gonz&#x00E1;lez. 2016. Domain transfer multi-instance dictionary learning. <em>      <em>Neural Computing and Applications</em>     </em>(2016), 1&#x2013;10.</li>    <li id="BibPLXBIB0033" label="[33]">Qifan Wang, Lingyun Ruan, and Luo Si. 2014. Adaptive Knowledge Transfer for Multiple Instance Learning in Image Classification.. In <em>      <em>AAAI</em>     </em>. 1334&#x2013;1340.</li>    <li id="BibPLXBIB0034" label="[34]">Yu Wang, Wotao Yin, and Jinshan Zeng. 2015. Global convergence of ADMM in nonconvex nonsmooth optimization. <em>      <em>arXiv preprint arXiv:1511.06324</em>     </em>(2015).</li>    <li id="BibPLXBIB0035" label="[35]">Xiu&#x00A0;Shen Wei, Jianxin Wu, and Zhi&#x00A0;Hua Zhou. 2014. Scalable Multi-instance Learning. In <em>      <em>IEEE International Conference on Data Mining</em>     </em>. 1037&#x2013;1042.</li>    <li id="BibPLXBIB0036" label="[36]">Karl Weiss, Taghi&#x00A0;M Khoshgoftaar, and DingDing Wang. 2016. A survey of transfer learning. <em>      <em>Journal of Big Data</em>     </em>3, 1 (2016), 9.</li>    <li id="BibPLXBIB0037" label="[37]">E Yomtov and E Gabrilovich. 2013. Postmarket Drug Surveillance Without Trial Costs: Discovery of Adverse Drug Reactions Through Large-Scale Analysis of Web Search Queries. <em>      <em>Journal of Medical Internet Research</em>     </em>15, 6 (2013), e124.</li>    <li id="BibPLXBIB0038" label="[38]">H Yu, C Ho, Y Juan, and C Lin. 2013. Libshorttext: A library for short-text classification and analysis. <em>      <em>Rapport interne, Department of Computer Science, National Taiwan University. Software available at <a href="http://www.csie.ntu.edu.tw/~cjlin/libshorttext" target="_blank">http://www.csie.ntu.edu.tw/~cjlin/libshorttext</a></em>     </em> (2013).</li>    <li id="BibPLXBIB0039" label="[39]">Dan Zhang and Luo Si. 2009. Multiple instance transfer learning. In <em>      <em>Data Mining Workshops, 2009. ICDMW&#x2019;09. IEEE International Conference on</em>     </em>. IEEE, 406&#x2013;411.</li>    <li id="BibPLXBIB0040" label="[40]">Liang Zhao, Feng Chen, Chang-Tien Lu, and Naren Ramakrishnan. 2016. Online Spatial Event Forecasting in Microblogs. <em>      <em>ACM Transactions on Spatial Algorithms and Systems (TSAS)</em>     </em>2, 4(2016), 15.</li>    <li id="BibPLXBIB0041" label="[41]">Zhi&#x00A0;Hua Zhou, Yu&#x00A0;Yin Sun, and Yu&#x00A0;Feng Li. 2008. Multi-instance learning by treating instances as non-I.I.D. samples. <em>      <em>Computer Science</em>     </em> (2008), 1249&#x2013;1256.</li>    <li id="BibPLXBIB0042" label="[42]">Yin Zhu, Yuqiang Chen, Zhongqi Lu, Sinno&#x00A0;Jialin Pan, Gui-Rong Xue, Yong Yu, and Qiang Yang. 2011. Heterogeneous Transfer Learning for Image Classification.. In <em>      <em>AAAI</em>     </em>.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">    <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class="link-inline force-break"    href="https://dev.Twitter.com/overview/terms/agreement-and-policy">https://dev.Twitter.com/overview/terms/agreement-and-policy</a>   </p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break"    href="https://vaers.hhs.gov/data/datasets.html?">https://vaers.hhs.gov/data/datasets.html?</a>   </p>   <div class="bibStrip">    <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>    <em>WWW '18, April 23-27, 2018, Lyon, France</em>    </p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License. ACM ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186051">https://doi.org/10.1145/3178876.3186051</a>    </p>   </div>  </section>  <div class="pubHistory">   <p/>  </div> </body> </html> 
