<!DOCTYPE html> <html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">  <head>  <title>Through a Gender Lens: Learning Usage Patterns of Emojis from Large-Scale Android Users</title>  <!-- Copyright (c) 2010-2015 The MathJax Consortium --><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>  <meta name="viewport" content="width=device-width; initial-scale=1.0;"></meta>  <meta http-equiv="X-UA-Compatible" content="IE=edge"></meta>  <link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/bootstrap.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/bootstrap-theme.min.css"/><link media="screen, print" rel="stylesheet"    href="../../../../dl.acm.org/pubs/lib/css/main.css"/><script src="../../../../dl.acm.org/pubs/lib/js/jquery.min.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/bootstrap.min.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/bibCit.js" type="text/javascript"></script>  <script src="../../../../dl.acm.org/pubs/lib/js/divTab.js" type="text/javascript"></script>  <script type="text/javascript"    src="../../../../dl.acm.org/pubs/lib/js/MathJax.js?config=TeX-AMS_CHTML"></script>  <script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>  </head>  <body id="main">  <section class="front-matter">   <section>    <header class="title-info">     <div class="journal-title">     <h1>      <span class="title">Through a Gender Lens: Learning Usage Patterns of Emojis from Large-Scale Android Users</span>      <br/>      <span class="subTitle"/>     </h1>     </div>    </header>    <div class="authorGroup">     <div class="author">     <span class="givenName">Zhenpeng</span>      <span class="surName">Chen</span>,     Key Lab of High-Confidence Software Technology, MoE (Peking University), Beijing, China, <a href="mailto:czp@pku.edu.cn">czp@pku.edu.cn</a>     </div>     <div class="author">     <span class="givenName">Xuan</span>      <span class="surName">Lu</span>,     Key Lab of High-Confidence Software Technology, MoE (Peking University), Beijing, China, <a href="mailto:luxuan@pku.edu.cn">luxuan@pku.edu.cn</a>     </div>     <div class="author">     <span class="givenName">Wei</span>      <span class="surName">Ai</span>,     School of Information, University of Michigan, Ann Arbor, USA, <a href="mailto:aiwei@umich.edu">aiwei@umich.edu</a>     </div>     <div class="author">     <span class="givenName">Huoran</span>      <span class="surName">Li</span>,     Key Lab of High-Confidence Software Technology, MoE (Peking University), Beijing, China, <a href="mailto:lihuoran@pku.edu.cn">lihuoran@pku.edu.cn</a>     </div>     <div class="author">     <span class="givenName">Qiaozhu</span>      <span class="surName">Mei</span>,     School of Information, University of Michigan, Ann Arbor, USA, <a href="mailto:qmei@umich.edu">qmei@umich.edu</a>     </div>     <div class="author">     <span class="givenName">Xuanzhe</span>      <span class="surName">Liu</span>,     Key Lab of High-Confidence Software Technology, MoE (Peking University), Beijing, China, <a href="mailto:xzl@pku.edu.cn">xzl@pku.edu.cn</a>     </div>                             </div>    <br/>    <div class="pubInfo">     <p>DOI: <a href="https://doi.org/10.1145/3178876.3186157" target="_blank">https://doi.org/10.1145/3178876.3186157</a>     <br/>WWW '18: <a href="https://doi.org/10.1145/3178876" target="_blank">Proceedings of The Web Conference 2018</a>, Lyon, France, April 2018</p>    </div>    <div class="abstract">     <p>     <small>Based on a large data set of emoji using behavior collected from smartphone users over the world, this paper investigates gender-specific usage of emojis. We present various interesting findings that evidence a considerable difference in emoji usage by female and male users. Such a difference is significant not just in a statistical sense; it is sufficient for a machine learning algorithm to accurately infer the gender of a user purely based on the emojis used in their messages. In real world scenarios where gender inference is a necessity, models based on emojis have unique advantages over existing models that are based on textual or contextual information. Emojis not only provide language-independent indicators, but also alleviate the risk of leaking private user information through the analysis of text and metadata.</small>     </p>    </div>    <div class="CCSconcepts">     <p> <small> <span style="font-weight:bold;">CCS Concepts:</span> &#x2022;<strong> Information systems </strong>&#x2192; <strong>Data mining;</strong> &#x2022;<strong> Human-centered computing </strong>&#x2192; <strong>User models;</strong> &#x2022;<strong> Social and professional topics </strong>&#x2192; <strong>Gender;</strong></small> </p>    </div>    <div class="classifications">     <div class="author">     <span style="font-weight:bold;">      <small>Keywords:</small>     </span>     <span class="keyword">      <small>Emojis; gender; user profiling; language-independent</small>     </span>     </div>     <br/>     <div class="AcmReferenceFormat">     <p>      <small>       <span style="font-weight:bold;">ACM Reference Format:</span>       <br/>       Zhenpeng Chen, Xuan Lu, Wei Ai, Huoran Li, Qiaozhu Mei, and Xuanzhe Liu. 2018. Through a Gender Lens: Learning Usage Patterns of Emojis from Large-Scale Android Users. In <em>WWW 2018: The 2018 Web Conference,</em>       <em>April 23&#x2013;27, 2018,</em>       <em> Lyon, France</em>. ACM, New York, NY, USA, 11 Pages. <a href="https://doi.org/10.1145/3178876.3186157" class="link-inline force-break"        target="_blank">https://doi.org/10.1145/3178876.3186157</a></small>     </p>     </div>    </div>   </section>  </section>  <section class="body">   <section id="sec-7">    <header>     <div class="title-info">     <h2>      <span class="section-number">1</span> Introduction</h2>     </div>    </header>    <p>On April 11, 2015, Andy Murray, a world-wide known tennis player, announced his wedding on Twitter.<a class="fn" href="#fn1" id="foot-fn1"><sup>1</sup></a> Unlike any other formal announcement, the Tweet consists of no word but 51 emojis.</p>    <p>This is just one of the many evidences that emojis have gained incredible popularity in recent years. Compared to traditional information carriers such as words, pictures, or even emoticons, emojis are considered to be both simple and lively, both expressive and compact, making them widely appreciated by Internet users, particularly by those who use smartphones. Emojis have also become an attractive new subject for scientific research. Interwoven into our daily communications, emojis are established as a ubiquitous language that bridges users who speak different languages and who are from different countries, cultures, and demographic groups&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>]. Various studies have been done to understand the semantics and sentiments of emojis&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0006">6</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0032">32</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0051">51</a>], which concluded that emojis present rich and clear meanings and emotions that can be generalized across language barriers.</p>    <p>Does ubiquity imply equality? Perhaps not. Previous work has also compared the usage of emojis across apps&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0046">46</a>], across platforms&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>], and even across cultures&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>]. Considerable differences are demonstrated between these groups in their interpretations and preferences of certain emojis. Our work adds to this literature by examining gender specific usage of emojis.</p>    <p>Why do we care about genders? Identifying the gender differences in user behaviors is always an important topic in user modeling and human computer interaction. For example, studies have demonstrated that difference exists in how females and males use non-verbal cues in face-to-face offline communications&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>]. Similar difference also frequently presents in online activities&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0044">44</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0054">54</a>]. Failing to consider this difference would compromise the quality of information services and interfaces provided to Internet users, such as recommender systems, online advertisements, and social networking tools, and in the long run it could result in inequality in expression and access to information. Indeed, many major information systems provide gender-customized services to their users &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0034">34</a>]. Even if gender information is not explicitly available, it is not uncommon to infer it from other information of the users, such as what they say and what they do, in order to improve user profiling and provide personalized services&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0055">55</a>], although it may be at the risk of privacy concerns&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0017">17</a>]. In the past decades, gender inference is quite hot and has been widely studied in the research communities such as Web minng, human computer interaction, information retrieval, and natural language processing&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0020">20</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0024">24</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0049">49</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0055">55</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0056">56</a>].</p>    <p>In this paper, we make the first effort to study the gender differences in using emojis. We present an empirical study based on the largest data set of gendered usage of emojis to date, which contains 134,419 anonymized Android-smartphone users from 183 countries, with self-reported genders, and their 401 million messages collected in three months, in 58 languages. A comprehensive statistical analysis is conducted to analyze various aspects of emoji usage. We find that there exist statistically significant differences between female and male users in emoji usage: (1) women are more likely to use emojis than men; (2) men and women have different preferences for emojis, some of which are consistent with the common beliefs of gender differences; (3) men and women have different preferences in using emojis to express sentiments, some of which are surprisingly different from the common beliefs.</p>    <p>These differences are not just significant in a statistical sense. In fact, they are so strong that a machine learning algorithm can be used to infer gender only from the emoji usage without accessing the textual or any other contextual information. Surprisingly, we find that the overall accuracy can reach 81.1% for all users, regardless of the language they use. The performance of our approach is comparable to the reported accuracy of the state-of-the-art that infers the genders of Twitter and Facebook users by their textual messages in English&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>] , and the performance is generalizable to non-English users. This result again provides strong evidence of emojis being used as a ubiquitous language. Compared to those built on natural language texts, machine learning models built on emojis are not only generalizable across linguistic barriers, but also more robust to privacy threats.</p>    <p>To the best of our knowledge, we make the first effort on analyzing gendered usage of emojis at scale. The major contributions of this paper are as follows:</p>    <ul class="list-no-style">     <li id="list1" label="&#x2022;">We describe the largest data set of gendered usage of emojis to date, covering anonymized users with explicit gender labels, in a large diversity of languages, and from many different countries.<br/></li>     <li id="list2" label="&#x2022;">We present a comprehensive empirical analysis on gendered usage of emojis and find that the emoji usage presents statistically significant differences between female and male users.<br/></li>     <li id="list3" label="&#x2022;">We construct an advanced machine learning model for gender inference purely based on the emojis in a user&#x0027;s messages. The derived model can achieve comparable accuracy to models built on natural English text and the performance is generalizable to non-English users.<br/></li>    </ul>    <p>The rest of this paper is organized as follows. Section&#x00A0;<a class="sec" href="#sec-8">2</a> summarizes related literature. Section&#x00A0;<a class="sec" href="#sec-9">3</a> describes the data set and how the ethical issues are resolved. Section&#x00A0;<a class="sec" href="#sec-10">4</a> investigates gender difference in emoji usage. Section&#x00A0;<a class="sec" href="#sec-14">5</a> presents machine learning models for gender inference purely based on emojis used in messages. Section&#x00A0;<a class="sec" href="#sec-20">6</a> compares our emoji-based models with text-based gender inference algorithms. Section&#x00A0;<a class="sec" href="#sec-21">7</a> and Section&#x00A0;<a class="sec" href="#sec-22">8</a> discuss the practical implications and the limitations of the study, followed by concluding remarks in Section&#x00A0;<a class="sec" href="#sec-23">9</a>.</p>   </section>   <section id="sec-8">    <header>     <div class="title-info">     <h2>      <span class="section-number">2</span> Related Work</h2>     </div>    </header>    <p>We start with a summary of the background and relevant literature.</p>    <p>     <strong>Emojis.</strong> The prevalence of emojis has been an attractive phenomenon of social innovation and appreciation. Emojis, graphic symbols carrying specific meanings, are widely used to represent real objects and express emotions. Much research effort has been spent to study the ubiquitous usage of emojis, including their general popularity &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0003">3</a>] and their different usage across apps&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0046">46</a>], across platforms&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>], and even across countries and cultures&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0028">28</a>]. Moreover, some researchers focus on the functionality of emojis in online text communication. Besides being used as replacements of content words, emojis are also used in non-verbal ways to decorate text, adjust tones, provide additional emotional or situational information, and engage the audience&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0010">10</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0042">42</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0047">47</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0057">57</a>]. Pohl <em>et al.</em> investigated gender distribution of Twitter users and found more females tweeting with emojis than males&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0035">35</a>]. Such primitive findings suggest potential gender difference in emoji usage and possible biases in analyses that have neglected this difference. We systematically study the gender specific usage of emojis and provide insights for future emoji analysis to consider the gender difference.</p>    <p>     <strong>Gender Difference.</strong> Gender difference is always an important research topic in sociological and psychological studies from which there are many interesting findings. For example, females are evidenced to show a greater number of facial activities than males&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0040">40</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0041">41</a>] and observers can identify emotional states more accurately from female faces than from male faces&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0039">39</a>]. With the advancement of data science methods, these hypotheses and conjectures about gender differences are measured and tested quantitatively through analyzing online behaviors of users at scale. For example, when the &#x201C;facial expressions&#x201D; (emoticons) become popular in text, researchers investigated the relationship between gender and emoticon usage and found superiority of females in using emoticons&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0044">44</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0054">54</a>], which verifies the sociological findings about non-verbal expressivity of females&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>]. In addition, gender is demonstrated to have effect in online communications. Specifically, women are found to prefer to write about personal topics on social media and to use pronouns, emotional words, interjections, and abbreviations, while men tend to write about philosophical topics, use standard dictionary words, proper names, numbers, technology words, and links&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0022">22</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0052">52</a>]. However, as trending non-verbal cues in computer-mediated communication, emojis have not been studied systematically from the gender perspective before this paper.</p>    <p>     <strong>Gender Inference.</strong> In recent years, identifying genders of users from their online activities has been an active research topic, given its considerable value in personalization and recommender systems. The techniques proposed for this purpose utilize various online information about users, such as their screen names&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0023">23</a>], the images they post on social networks&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0055">55</a>], their interaction behaviors&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0025">25</a>], and the textual content they generate&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0015">15</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0021">21</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0037">37</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0049">49</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0056">56</a>]. Most of the studies are conducted with texts using various linguistic cues such as word choices, paraphrase choices, emotions, and part-of-speeches. There is also very limited literature concerning non-English languages. Ciot <em>et al.</em> &#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0008">8</a>] attempted to apply existing English-based gender inference models to other languages and found them not working well. One important reason is the complex orthography of some languages such as Japanese. We use emojis, a ubiquitous language used worldwide and across language barriers, as an indicator of gender and compare the performance of emoji-based gender inference with existing text-based methods.</p>   </section>   <section id="sec-9">    <header>     <div class="title-info">     <h2>      <span class="section-number">3</span> The Data Set</h2>     </div>    </header>    <p>The data we use in this study are collected through the Kika Keyboard,<a class="fn" href="#fn2" id="foot-fn2"><sup>2</sup></a> a leading Android input method app on Google Play. With millions of downloads across the world, Kika supports 82 languages and was among the top 25 most downloaded apps on Google Play in 2015. The data set spans from December 4, 2016 to February 28, 2017, covering 134,419 active users with self-reported gender information and their 401 million messages.</p>    <p>With emoji inputs as a major feature, Kika supports all emojis released by the Unicode Standard.<a class="fn" href="#fn3" id="foot-fn3"><sup>3</sup></a> Our statistics show that 1,356 different kinds of emojis are used in this data set, and 83.9% users have used emojis at least once.</p>    <p>The data set has three advanced characteristics that have made this study feasible. First, essential meta information, including the genders and countries of users, is voluntarily reported by users. This supports the analysis of gender difference in emoji usage and provides the ground truth for gender inference. Due to the original design of Kika&#x0027;s information collection procedure, we consider only binary genders in this study, i.e., 53% females and 47% males in our data set. Second, data of users with 58 languages from 183 countries and regions are collected, which enables a cross-continent study of gendered patterns and makes it possible to evaluate the generality of our gender-inference approach across multiple languages. Third, because the input method runs at the system level, Kika collects timestamped messages from a wide range of apps, not limiting to the well-studied apps such as Twitter&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0005">5</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0056">56</a>]. This enables a more comprehensive analysis of emoji usage instead of being limited to context of social media.</p>    <p>Note that although the data set contains textual content, it is only used in two ways. One is to infer the language so that we can compare the performance of gender inference for users of different languages (see Section&#x00A0;<a class="sec" href="#sec-14">5</a>). The other is to reproduce the state-of-the-art text-based gender inference model in order to compare its performance with the proposed emoji-based model (see Section&#x00A0;<a class="sec" href="#sec-20">6</a>).</p>    <p>&#x2022; <strong>User Privacy and Ethical Consideration</strong>. The original data were collected by Kika for the purpose of improving user experience, with explicit user agreements and a strict policy of data collection, transmission, and storage. In this study, we take careful steps to protect user privacy and preserve the ethics of research. First, our work is approved by the Research Ethical Committee of the institutes (a.k.a, institutional review board, or IRB) of the authors. Second, the data set was completely anonymized by Kika before provided to the authors. Third, the data are stored and processed on a private, HIPPA-compliant cloud server, with strict access authorized by Kika. The whole process is compliant with the public privacy policy of the Kika company and the best known practice of data mining research.</p>   </section>   <section id="sec-10">    <header>     <div class="title-info">     <h2>      <span class="section-number">4</span> Gender Difference in Emoji Usage</h2>     </div>    </header>    <p>Previous studies have pointed out that females tend to be more non-verbally expressive than males&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0002">2</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0018">18</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0029">29</a>]. Researchers have also examined the gender difference in the usage of emoticons, precursors of emojis&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0011">11</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0048">48</a>]. In this section, we examine how emojis, a new type of non-verbal cues, are used by females and males. We start by comparing how frequently people use emojis.</p>    <section id="sec-11">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.1</span> Emoji Popularity</h3>     </div>     </header>     <p>As mentioned in Section&#x00A0;<a class="sec" href="#sec-9">3</a>, emojis are popularly used in our data set. Are emojis equally popular among female and male users? We measure the popularity by calculating the percentage of messages containing emojis (%emoji-msg). In general, 7.02% of messages sent by male users contain at least one emoji, while the percentage is 7.96% for female users, suggesting that females are more likely to use emojis (<em>p</em>-value &#x226A; 0.01, <em>z</em>-test&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0004">4</a>]).</p>     <p>To further understand the difference, we plot the cumulative distribution function (CDF) of the percentage of users by %emoji-msg for females and males, respectively. As demonstrated in Figure&#x00A0;<a class="fig" href="#fig1">1</a>, the CDF curves are both smooth while the female curve is flatter, which indicates a higher proportion of female users tend to include emojis in more messages. For example, 29.2% of male users use emojis in more than 5% of their messages, while the percentage of female users achieves 43.9%.</p>     <p>To ensure the robustness of our result, we break our data set into three months and compare the %emoji-msg for females and males in each month. The CDF curves in all three months show that female users have significantly higher tendency to use emojis. <figure id="fig1">      <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/www2018-166-fig1.jpg" class="img-responsive" alt="Figure 1"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 1:</span>       <span class="figure-title">Female users include emojis in a larger proportion of their messages.</span>      </div>     </figure>     </p>    </section>    <section id="sec-12">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.2</span> Emoji Preference</h3>     </div>     </header>     <p>The difference in %emoji-msg, however, does not tell us whether female and male users use different emojis. Do women and men have different preferences for certain emojis? Below we compare the choice of emojis from different genders.</p>     <p>&#x2022; <strong>Frequently Used Emojis</strong>. We start by comparing the go-to emojis, namely the most frequently used emojis by female and male users. As in Figure&#x00A0;<a class="fig" href="#fig2">2</a>, the emojis used by female or male users both follow a long-tail distribution. The 10 most used emojis by women are <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/22.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/2.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/25.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/28.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/30.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/24.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/15.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/26.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/16.png" class="img-responsive" alt="" longdesc=""/>, and <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/23.png" class="img-responsive" alt="" longdesc=""/>, while the 10 most used emojis by men are <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/22.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/2.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/25.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/28.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/30.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/16.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/24.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/26.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/31.png" class="img-responsive" alt="" longdesc=""/>, and <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/15.png" class="img-responsive" alt="" longdesc=""/>. Interestingly, female and male users have an overlap of 8 emojis in their 10 most-used emojis.</p>     <p>Beyond the similarities, however, at least two interesting differences can be observed from the two distributions. First, the most popular emoji <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/22.png" class="img-responsive" alt="" longdesc=""/> (face with tears of joy) accounts for 18.9% of male users&#x2019; emoji usage, but 22.1% for female users. The difference of 3.2% is non-negligible, as it is even higher than the usage proportion of the 5th most popular emoji for both women and men, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/30.png" class="img-responsive" alt="" longdesc=""/> (loudly crying face). The difference in favoring <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/22.png" class="img-responsive" alt="" longdesc=""/> results in a more skewed distribution of emojis used by female users. Second, although most of the favored emojis are the same, the rankings of <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/2.png" class="img-responsive" alt="" longdesc=""/> (red heart), <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/25.png" class="img-responsive" alt="" longdesc=""/> (smiling face with heart-eyes), <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/16.png" class="img-responsive" alt="" longdesc=""/> (sparkling heart), <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/24.png" class="img-responsive" alt="" longdesc=""/> (smiling face with smiling eyes), and <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/15.png" class="img-responsive" alt="" longdesc=""/> (two hearts) are different between the two genders. As expressing sentiment is an important intention of using emojis&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0047">47</a>], the difference in the distributions of top emojis suggests that men and women may convey their sentiments in different ways and we will discuss it in Section&#x00A0;<a class="sec" href="#sec-13">4.3</a>. <figure id="fig2">      <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/www2018-166-fig2.jpg" class="img-responsive" alt="Figure 2"       longdesc=""/>      <div class="figure-caption">       <span class="figure-number">Figure 2:</span>       <span class="figure-title">Ten most used emojis by female and male users.</span>      </div>     </figure>     </p>     <p>&#x2022; <strong>Discriminative Emojis</strong>. From the 6th most popular emoji, we start to see female and male users having different preferences for emojis. We need a more rigorous way to compare their choices on the less popular emojis. More specifically, can we find emojis that are strongly associated with either gender?</p>     <p>To answer this question, we use the <em>Mutual Information</em> (MI), which measures the mutual dependence between the usage of a certain emoji and the genders. Emojis with higher MIs are more informative in distinguishing women from men or vice versa.</p>     <p>Let <em>Y</em> &#x2208; {1, 0} denote the gender of a user (0 for female and 1 for male). Let <em>X</em> &#x2208; {1, 0} denote whether an emoji is used (<em>x</em> = 1) or not (<em>x</em> = 0) by this user. The MI for each emoji <em>e</em> can be computed as <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{equation*} \mbox{MI}(X;Y)_{e}=\sum _{x\in X}\sum _{y\in Y}p(x,y)_{e}\log \frac{p(x,y)_{e}}{p(x)_{e}p(y)_{e}},\end{equation*} </span>       <br/>      </div>     </div> where <em>p</em>(<em>x</em>)<sub>      <em>e</em>     </sub>, <em>p</em>(<em>y</em>)<sub>      <em>e</em>     </sub> are the marginal probabilities of <em>x</em> and <em>y</em>, and <em>p</em>(<em>x</em>, <em>y</em>)<sub>      <em>e</em>     </sub> is the joint probability of <em>x</em> and <em>y</em>. For example, <em>p</em>(0, 0)<sub>      <em>e</em>     </sub> is the probability that the emoji <em>e</em> is never used by a male user.</p>     <p>Table&#x00A0;<a class="tbl" href="#tab1">1</a> lists emojis with the highest MIs, including <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/12.png" class="img-responsive" alt="" longdesc=""/> (two women holding hands), <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/5.png" class="img-responsive" alt="" longdesc=""/> (birthday cake), <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/7.png" class="img-responsive" alt="" longdesc=""/> (party popper), etc. In addition, for each discriminative emoji <em>e</em>, we calculate <em>p</em>(<em>Female</em>|<em>e</em>), the probability that a user of <em>e</em> is female, and <em>p</em>(<em>Male</em>|<em>e</em>), the probability that a user of <em>e</em> is male.</p>     <p>As mentioned in Section&#x00A0;<a class="sec" href="#sec-9">3</a>, 53% users in our data set are females and the other 47% are males. We define the emoji <em>e</em> as a <em>male</em> emoji if <em>p</em>(<em>Male</em>|<em>e</em>) > 0.47, otherwise a <em>female</em> emoji. Statistics show that there are far more <em>female</em> emojis than <em>male</em> emojis, and the 10 most informative emojis in Table&#x00A0;<a class="tbl" href="#tab1">1</a> are all <em>female</em> emojis; such results are consistent with findings in linguistics literature&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0007">7</a>]. In other words, one is more likely to be a female if an emoji in Table&#x00A0;<a class="tbl" href="#tab1">1</a>, such as <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/12.png" class="img-responsive" alt="" longdesc=""/>, is ever used by this user. We also find some <em>male</em> emojis such as <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/1.png" class="img-responsive" alt="" longdesc=""/> (soccer ball), <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/32.png" class="img-responsive" alt="" longdesc=""/> (cigarette), and <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/37.png" class="img-responsive" alt="" longdesc=""/> (male sign). By comparison, we find that <em>female</em> emojis are fancier and more colorful than <em>male</em> emojis, which meets the common interpretations of gender difference. The existence of <em>female</em> emojis and <em>male</em> emojis evidences the different choice of emojis by female and male users, and suggests the potential of inferring gender through such patterns.</p>     <div class="table-responsive" id="tab1">     <div class="table-caption">      <span class="table-number">Table 1:</span>      <span class="table-title">A selection of discriminative emojis, ranked by mutual information with gender.</span>     </div>     <table class="table">      <thead>       <tr>        <th style="text-align:center;">Rank</th>        <th style="text-align:center;">MI</th>        <th style="text-align:center;">Emoji <em>e</em>        </th>        <th style="text-align:center;">        <em>p</em>(<em>Male</em>|<em>e</em>)</th>        <th style="text-align:center;">        <em>p</em>(<em>Female</em>|<em>e</em>)</th>       </tr>      </thead>      <tbody>       <tr>        <td style="text-align:center;">1</td>        <td style="text-align:center;">0.0223</td>        <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/12.png" class="img-responsive" alt="" longdesc=""/>        </td>        <td style="text-align:center;">0.126</td>        <td style="text-align:center;">        <strong>0.874</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">2</td>        <td style="text-align:center;">0.0160</td>        <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/5.png" class="img-responsive" alt="" longdesc=""/>        </td>        <td style="text-align:center;">0.236</td>        <td style="text-align:center;">        <strong>0.764</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">3</td>        <td style="text-align:center;">0.0145</td>        <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/7.png" class="img-responsive" alt="" longdesc=""/>        </td>        <td style="text-align:center;">0.275</td>        <td style="text-align:center;">        <strong>0.725</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">4</td>        <td style="text-align:center;">0.0139</td>        <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/4.png" class="img-responsive" alt="" longdesc=""/>        </td>        <td style="text-align:center;">0.232</td>        <td style="text-align:center;">        <strong>0.768</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">5</td>        <td style="text-align:center;">0.0139</td>        <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/14.png" class="img-responsive" alt="" longdesc=""/>        </td>        <td style="text-align:center;">0.267</td>        <td style="text-align:center;">        <strong>0.733</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">6</td>        <td style="text-align:center;">0.0120</td>        <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/6.png" class="img-responsive" alt="" longdesc=""/>        </td>        <td style="text-align:center;">0.225</td>        <td style="text-align:center;">        <strong>0.775</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">7</td>        <td style="text-align:center;">0.0111</td>        <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/3.png" class="img-responsive" alt="" longdesc=""/>        </td>        <td style="text-align:center;">0.187</td>        <td style="text-align:center;">        <strong>0.813</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">8</td>        <td style="text-align:center;">0.0104</td>        <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/15.png" class="img-responsive" alt="" longdesc=""/>        </td>        <td style="text-align:center;">0.310</td>        <td style="text-align:center;">        <strong>0.690</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">9</td>        <td style="text-align:center;">0.0096</td>        <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/19.png" class="img-responsive" alt="" longdesc=""/>        </td>        <td style="text-align:center;">0.292</td>        <td style="text-align:center;">        <strong>0.708</strong>        </td>       </tr>       <tr>        <td style="text-align:center;">10</td>        <td style="text-align:center;">0.0094</td>        <td style="text-align:center;">        <img src="../../../../deliveryimages.acm.org/10.1145/3190000/3186157/images/13.png" class="img-responsive" alt="" longdesc=""/>        </td>        <td style="text-align:center;">0.203</td>        <td style="text-align:center;">        <strong>0.797</strong>        </td>       </tr>      </tbody>     </table>     </div>     <p>&#x2022; <strong>Co-Used Emojis</strong>. Going one step further, could we compare the context in which the female and male use an emoji? Without messing with different languages, we examine a simple form of context &#x2013; the co-used emojis. What kind of emojis are frequently co-used by females and males? Is there gender difference in such co-usage patterns? To answer such questions, we construct a co-occurrence network for female users and one for male users, respectively. In both networks, the nodes are emojis, and an edge between two emojis is measured by the <em>Point Mutual Information</em> (PMI)&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0053">53</a>], which is formulated as <div class="table-responsive">      <div class="display-equation">       <span class="tex mytex">\begin{equation*} \mbox{PMI}(e_1,e_2)=\log \frac{p(e_1, e_2)}{p(e_1)p(e_2)},\end{equation*} </span>       <br/>      </div>     </div> where <em>p</em>(<em>e</em>     <sub>1</sub>) represents the probability that a message contains <em>e</em>     <sub>1</sub>, <em>p</em>(<em>e</em>     <sub>2</sub>) represents the probability of <em>e</em>     <sub>2</sub>, and <em>p</em>(<em>e</em>     <sub>1</sub>, <em>e</em>     <sub>2</sub>) represents the probability that a message contains both emojis.</p>     <p>For this network, we connect each emoji to five other emojis that have the largest positive PMI with it, with edges weighted by the corresponding PMI values. By applying the community detection functionality of <em>Gephi</em><a class="fn" href="#fn4" id="foot-fn4"><sup>4</sup></a> (with resolution as 0.2), we identify 55 communities from the emoji co-occurrence network of female users and 56 communities from the network of male users.<a class="fn" href="#fn5" id="foot-fn5"><sup>5</sup></a> The nodes within one community have more connections (larger PMI) with each other, while the nodes from different communities have fewer connections (lower PMI).</p>     <p><div id="earlylife_images">By comparing communities from the two networks, some interesting findings can be made. For example, we find a sport-related community with emojis like <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/1.png" class="img-responsive" alt="" longdesc=""/> (soccer ball) and <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/8.png" class="img-responsive" alt="" longdesc=""/> (basketball) from both of the two networks. However, males tend to use such emojis together with <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/9.png" class="img-responsive" alt="" longdesc=""/> (sports medal) and <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/10.png" class="img-responsive" alt="" longdesc=""/> (trophy), while female prefer to use them with <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/33.png" class="img-responsive" alt="" longdesc=""/> (shower), <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/34.png" class="img-responsive" alt="" longdesc=""/> (person taking bath) and <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/35.png" class="img-responsive" alt="" longdesc=""/> (bathtub). Such a result suggest that females and males may be talking about &#x201C;different things&#x201D; when they mention sports. Another example is the frequent co-occurrence of clothes-, shoes-, and bag-related emojis with <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/36.png" class="img-responsive" alt="" longdesc=""/> (shopping bags) by female users, which can not be observed from male users. These findings indicate interesting differences in co-used emojis of female and male users.</div></p>    </section>    <section id="sec-13">     <header>     <div class="title-info">      <h3>       <span class="section-number">4.3</span> Sentiment Expression</h3>     </div>     </header>     <p>Emojis were originally designed to help express sentiments in a compact and vivid way. Recent research also demonstrates that expressing sentiment is a main intention of using emojis&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0047">47</a>]. We infer that the gendered patterns of using emojis (i.e., frequency and preference) can be implicitly affected by the way sentiment is expressed. For example, it is widely believed that women are more emotional and more expressive than men&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0039">39</a>]. Can similar observations be made from the sentiments expressed through emojis?</p>     <p>To capture the overall sentiment information, we calculate sentiment scores for each emoji with their official names and annotations from the Unicode Website using LIWC (Linguistic Inquiry and Word Count).<a class="fn" href="#fn6" id="foot-fn6"><sup>6</sup></a> With positive (<em>posemo</em>) and negative (<em>negemo</em>) scores generated by LIWC, each emoji is labelled as <em>positive</em> (<em>posemo</em> > <em>negemo</em>), <em>negative</em> (<em>posemo</em> < <em>negemo</em>), or <em>neither</em>. We calculate the proportions of positive and negative emojis used by female and male users respectively and conduct a <em>z</em>-test to measure the difference. Note that when we apply multi-hypothesis tests, we use Bonferroni correction&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0050">50</a>] to adjust the <em>p</em>-values to obtain more strict and reliable results. Statistics show that female users are more likely to use both positive emojis (female: 50.87%, male: 50.25%, <em>p</em>-value &#x226A; 0.01) and negative emojis (female: 10.11%, male: 9.42%, <em>p</em>-value &#x226A; 0.01), which is consistent with the existing belief that women are more emotional than men&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0039">39</a>].</p>     <p>In addition to the general proportions, we look at the use of typical emotional emojis, i.e., the face-related emojis and heart-related emojis, and explore gender difference in using them. Indeed, we have 69 face-related emojis and 15 heart-related emojis in our data set, and the 84 emojis comprise 75.8% of total emoji usage for women and 75.5% for men.</p>     <p>In fact, the two kinds of emojis, the faces and the hearts, perfectly match two typical situations in traditional verbal communication studies. Women are reported to show more facial-related activities than men&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0040">40</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0041">41</a>], and they are more likely to express love in real life&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0033">33</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0038">38</a>]. In textual communications, the face-related emojis emphasize the facial expressions through the eyes, eyebrows, or mouth shapes. Different shapes are used to express different affects and meanings such as happiness (<img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/24.png" class="img-responsive" alt="" longdesc=""/>), depression (<img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/27.png" class="img-responsive" alt="" longdesc=""/>), and anger (<img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/29.png" class="img-responsive" alt="" longdesc=""/>). The heart-related emojis emphasize the color and shape of heart (such as <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/2.png" class="img-responsive" alt="" longdesc=""/>, <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/17.png" class="img-responsive" alt="" longdesc=""/>, and <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/18.png" class="img-responsive" alt="" longdesc=""/>) to convey love and affects in a more direct way. Does emoji usage show similar characteristics with the verbal communication situations? In other words, do female users use more face-emojis and heart-emojis than males?</p>     <p>We calculate the proportions of face- and heart-related emojis used by female and male users. Face-related emojis are obviously more frequently used than heart-related emojis by both female users and male users. It is understandable because we have far more face-related emojis than heart-related emojis in our data set. By comparing female and male users, we find that female users are significantly more likely to use face-related emojis (female: 58.17%, male: 56.11%, <em>p</em>-value &#x226A; 0.01). Such an observation is compliant with previous studies on verbal communication&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0029">29</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0040">40</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0041">41</a>]. However, we are surprised to find that male users are significantly more likely to use heart-related emojis than females (female: 17.62%, male: 19.41%, <em>p</em>-value &#x226A; 0.01). This is contrary to psychological literature where males are reported to be less willing to express love in real life&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0001">1</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0033">33</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0038">38</a>]. Such a finding implies that although men reserve to express their love in real life, they are more willing to express love through emojis in textual communication. To sum up, women and men have gendered preferences in conveying sentiments through emojis, and some of the preferences are quite different from common interpretations.</p>     <div class="table-responsive" id="tab2">     <div class="table-caption">      <span class="table-number">Table 2:</span>      <span class="table-title">Features used to build the emoji-based gender inference model.</span>     </div>     <table class="table"> 				 <thead>       <tr>        <th style="text-align:left;">Dimension</th>        <th style="text-align:right;"># of features</th>        <th style="text-align:left;">Description</th>       </tr> 						</thead>      <tbody>       <tr>        <td style="text-align:left;">Emoji frequency</td>        <td style="text-align:right;">9</td>        <td style="text-align:left;">The overall emoji usage frequency (%emoji-msg), the average/max/median number of emojis in a message, the proportion of messages using only emojis, the proportion of messages containing only one emoji, the proportion of messages containing multiple nonconsecutive emojis, the proportion of messages containing multiple consecutive emojis, and the proportion of messages containing the same emoji repeatedly.</td>       </tr>       <tr>        <td style="text-align:left;">Emoji preference</td>        <td style="text-align:right;">1,356</td>        <td style="text-align:left;">The usage proportion of each emoji to all emojis.</td>       </tr>       <tr>        <td style="text-align:left;">Sentiment expression</td>        <td style="text-align:right;">5</td>        <td style="text-align:left;">The proportion of positive emojis in total emoji usage, the proportion of negative emojis in total usage, the proportion of messages containing positive emojis, the proportion of messages containing negative emojis, and the proportion of messages containing both positive and negative emojis.</td>       </tr>      </tbody>     </table>     </div>    </section>   </section>   <section id="sec-14">    <header>     <div class="title-info">     <h2>      <span class="section-number">5</span> Power of Emojis in Inferring Gender</h2>     </div>    </header>    <p>In the previous section, we have compared how women and men use emojis. Not only do they use emoji in different frequencies, but they also have different preferences for selecting which emojis to use. However, how different they are remains a question. In this section, we answer this question by validating the predictive power of emojis. Formally, we attempt to predict the gender of a user purely by their patterns of using emojis.</p>    <section id="sec-15">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.1</span> Prediction Set-up</h3>     </div>     </header>     <p>As we have binary gender labels in our data set (i.e., female and male), we perform gender inference as a binary classification task. We apply several advanced machine models, including the Ridge Classifier (Ridge)&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0013">13</a>], the Random Forest Classifier (RF)&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0026">26</a>], the Gradient Boosting Classifier (GBC)&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0016">16</a>], and the SVM Classifier&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0009">9</a>] with a linear kernel. In specific, SVM Classifier with L1 penalization (SVC1) and L2 penalization (SVC2) are used. These algorithms can provide a representative coverage of machine learning methods.</p>     <p>&#x2022; <strong>Data Set</strong>. To obtain robust results, we consider only the users with at least 100 messages that contain emojis. The selected 39,372 users are randomly divided into two subsets, i.e., a training set with 31,872 users and a test set with the other 7,500 users.</p>     <p>&#x2022; <strong>Evaluation Metrics</strong>. Treating the self-reported gender as the ground-truth, we use the <em>accuracy</em> to measure the performance of gender inference models. It is measured as the percentage of number-correct over test-size. In addition, we also consider the <em>precision</em> of the predicted male and female users, respectively. In specific, we calculate <em>precision_M</em> as the proportion of true male users among those predicted as male, and <em>precision_F</em> as the proportion of true female users among those predicted as female. We adopt these two metrics because in real world applications (such as online advertising&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0027">27</a>]) it is the common practice to provide gender-specific treatments to users of whom the algorithm is confident about the genders and a general treatment to those whose genders are uncertain. It is therefore important for a gender inference algorithm to obtain a high precision.</p>     <p>&#x2022; <strong>Baseline</strong>. For comparison purposes, we consider a simple baseline according to the gender distribution in the test set. In the test set, we have 4,898 female users and 2,602 male users. Hence, the baseline accuracy is 0.653, the precision of female predictions is 0.653 and the precision of male predictions is 0.347.</p>    </section>    <section id="sec-16">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.2</span> Feature Extraction</h3>     </div>     </header>     <p>In Section&#x00A0;<a class="sec" href="#sec-10">4</a>, we have demonstrated the gender difference in three aspects. To train a good model for gender inference, we are inspired to craft 3 sets of features, namely emoji frequency, emoji preference, and sentiment expression. In total we extract 1,370 features for each user, as summarized in Table&#x00A0;<a class="tbl" href="#tab2">2</a>. It is true that some features may be collinear with others, but we will leave it to the classification algorithms to handle.</p>     <p>&#x2022; <strong>Emoji Frequency</strong>. Section&#x00A0;<a class="sec" href="#sec-11">4.1</a> has shown that female users are more likely to use emojis in messages, which prompts us to consider the frequency of emojis as features. As we dive into the emojis used in a message, we find that it is not enough to use a single feature %emoji-msg (i.e., percentage of messages with emoji). For example, people might use multiple emojis in a single message, either by repeating the same emojis like <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/23.png" class="img-responsive" alt="" longdesc=""/>     <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/23.png" class="img-responsive" alt="" longdesc=""/>     <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/23.png" class="img-responsive" alt="" longdesc=""/> or by rambling different emojis throughout the message. Sometimes emojis constitute the entire message. These patterns may correlate with the intention of why people use emojis&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0046">46</a>]. To fully capture these patterns about how emojis are used within messages, we construct 9 features. Aside <em>%emoji-msg</em>, the remaining 8 features are as follows.</p>     <p>First, for each message where at least one emoji is used (i.e., an emoji message), we calculate the number of emojis used in it and aggregate the numbers by user. For each user, we calculate <em>the average/max/median number of emojis in an emoji message</em>.</p>     <p>Second, we identify the messages where emojis are used in certain patterns, and count the proportion of such messages among emoji messages. These patterns include <em>emoji only</em>, <em>single emoji in text</em>, <em>multiple nonconsecutive emojis</em>, <em>multiple consecutive emojis</em>, and <em>repeating emojis</em>.</p>     <p>&#x2022; <strong>Emoji Preference</strong>. We have seen in Section&#x00A0;<a class="sec" href="#sec-12">4.2</a> that women and men have different preferences in choosing which emoji to use. Thus the summary statistics of different emojis used by a user could be discriminative in inferring genders. To this end, we calculate <em>usage proportion</em> of each emoji among all emojis typed by the user. The higher the proportion is, the more the user prefers an emoji. In this way, we extract 1,356 features. We have also noticed that women and men have different patterns of emoji co-usage. However, to avoid overfitting, we do not include such patterns in our model. Arguably, including those features could increase the predictive power of emojis.</p>     <p>&#x2022; <strong>Sentiment Expression</strong>. Female and male users can have their own preferences in expressing sentiments through emojis. Based on the results of sentiment classification of emojis (see Section&#x00A0;<a class="sec" href="#sec-13">4.3</a>), we consider the following 5 features. For each user, we consider <em>the proportion of positive emojis</em> and <em>the proportion of negative emojis</em> they used, <em>the proportion of messages containing positive emojis</em>, <em>the proportion of messages containing negative emojis</em>, and <em>the proportion of messages containing both positive and negative emojis</em>.</p>    </section>    <section id="sec-17">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.3</span> Model Evaluation</h3>     </div>     </header>     <p>We use the scikit-learn package in Python&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0014">14</a>] to train the machine learning models, Ridge, RF, GBC, SVC1, and SVC2, using the emoji-based features and the default hyper-parameter settings. In certain situations where we attempt to optimize the hyper-parameters, they are selected using the 5-fold cross validation on the training set by optimizing the accuracy. They include the regularization strength and normalization parameter for Ridge, the number of trees and the maximum depth of the tree for RF and GBC, and the dual and penalty parameter of the error term for SVC1 and SVC2. We report all the test results along with the baseline in Table&#x00A0;<a class="tbl" href="#tab3">3</a>.</p>     <div class="table-responsive" id="tab3">     <div class="table-caption">      <span class="table-number">Table 3:</span>      <span class="table-title">Machine learning models trained with default hyper-parameters outperform baseline. Performances with optimal hyper-parameters in parentheses.</span>     </div>     <table class="table"> 				 <thead>       <tr>        <th rowspan="2" style="text-align:left" style="text-valign:middle;">Model</th>        <th colspan="3" style="text-align:center;">Metrics</th>       </tr>       <tr>        <th style="text-align:right;">Accuracy</th>        <th style="text-align:right;">Precision_M</th>        <th style="text-align:right;">Precision_F</th>       </tr> 						</thead>      <tbody>       <tr>        <td style="text-align:left;">Ridge</td>        <td style="text-align:right;">0.702 (0.718)</td>        <td style="text-align:right;">0.726 (0.702)</td>        <td style="text-align:right;">0.699 (0.721)</td>       </tr>       <tr>        <td style="text-align:left;">RF</td>        <td style="text-align:right;">0.718 (0.758)</td>        <td style="text-align:right;">0.702 (0.838)</td>        <td style="text-align:right;">0.721 (0.743)</td>       </tr>       <tr>        <td style="text-align:left;">GBC</td>        <td style="text-align:right;">0.780 (0.811)</td>        <td style="text-align:right;">0.769 (0.775)</td>        <td style="text-align:right;">0.784 (0.826)</td>       </tr>       <tr>        <td style="text-align:left;">SVC1</td>        <td style="text-align:right;">0.731 (0.741)</td>        <td style="text-align:right;">0.726 (0.717)</td>        <td style="text-align:right;">0.732 (0.747)</td>       </tr>       <tr>        <td style="text-align:left;">SVC2</td>        <td style="text-align:right;">0.713 (0.735)</td>        <td style="text-align:right;">0.729 (0.714)</td>        <td style="text-align:right;">0.711 (0.740)</td>       </tr>       <tr>        <td style="text-align:left;">Baseline</td>        <td style="text-align:right;">0.653</td>        <td style="text-align:right;">0.347</td>        <td style="text-align:right;">0.653</td>       </tr>      </tbody>     </table>     </div>     <div class="table-responsive" id="tab4">     <div class="table-caption">      <span class="table-number">Table 4:</span>      <span class="table-title">Model performance in different languages, majority guess baseline in parentheses.</span>     </div>     <table class="table"> 				 <thead>       <tr>        <th rowspan="2" style="text-valign:middle" style="text-align:left;">Language</th>        <th rowspan="2" style="text-valign:middle" style="text-align:left;">Language Family</th>        <th colspan="3" style="text-align:center;">Metrics</th>       </tr>       <tr>        <th style="text-align:right;">Accuracy</th>        <th style="text-align:right;">Precision_M</th>        <th style="text-align:right;">Precision_F</th>       </tr> 						</thead>      <tbody>       <tr>        <td style="text-align:left;">English</td>        <td style="text-align:left;">Indo-European</td>        <td style="text-align:right;">0.824 (0.684)</td>        <td style="text-align:right;">0.744 (0.316)</td>        <td style="text-align:right;">0.857 (0.684)</td>       </tr>       <tr>        <td style="text-align:left;">Spanish</td>        <td style="text-align:left;">Indo-European</td>        <td style="text-align:right;">0.828 (0.653)</td>        <td style="text-align:right;">0.794 (0.347)</td>        <td style="text-align:right;">0.843 (0.653)</td>       </tr>       <tr>        <td style="text-align:left;">Portuguese</td>        <td style="text-align:left;">Indo-European</td>        <td style="text-align:right;">0.841 (0.665)</td>        <td style="text-align:right;">0.825 (0.335)</td>        <td style="text-align:right;">0.846 (0.665)</td>       </tr>       <tr>        <td style="text-align:left;">Tagalog</td>        <td style="text-align:left;">Austronesian</td>        <td style="text-align:right;">0.793 (0.664)</td>        <td style="text-align:right;">0.770 (0.336)</td>        <td style="text-align:right;">0.800 (0.664)</td>       </tr>       <tr>        <td style="text-align:left;">French</td>        <td style="text-align:left;">Indo-European</td>        <td style="text-align:right;">0.775 (0.645)</td>        <td style="text-align:right;">0.727 (0.355)</td>        <td style="text-align:right;">0.794 (0.645)</td>       </tr>       <tr>        <td style="text-align:left;">Italian</td>        <td style="text-align:left;">Indo-European</td>        <td style="text-align:right;">0.841 (0.661)</td>        <td style="text-align:right;">0.793 (0.339)</td>        <td style="text-align:right;">0.863 (0.661)</td>       </tr>       <tr>        <td style="text-align:left;">Arabic</td>        <td style="text-align:left;">Afro-Asiatic</td>        <td style="text-align:right;">0.764 (0.555)</td>        <td style="text-align:right;">0.854 (0.555)</td>        <td style="text-align:right;">0.690 (0.445)</td>       </tr>       <tr>        <td style="text-align:left;">Indonesian</td>        <td style="text-align:left;">Austronesian</td>        <td style="text-align:right;">0.756 (0.617)</td>        <td style="text-align:right;">0.745 (0.383)</td>        <td style="text-align:right;">0.760 (0.617)</td>       </tr>       <tr>        <td style="text-align:left;">Malay</td>        <td style="text-align:left;">Austronesian</td>        <td style="text-align:right;">0.756 (0.618)</td>        <td style="text-align:right;">0.758 (0.382)</td>        <td style="text-align:right;">0.756 (0.618)</td>       </tr>       <tr>        <td style="text-align:left;">German</td>        <td style="text-align:left;">Indo-European</td>        <td style="text-align:right;">0.783 (0.617)</td>        <td style="text-align:right;">0.852 (0.383)</td>        <td style="text-align:right;">0.761 (0.617)</td>       </tr>       <tr>        <td style="text-align:left;">Thai</td>        <td style="text-align:left;">Tai-Kadai</td>        <td style="text-align:right;">0.808 (0.727)</td>        <td style="text-align:right;">0.750 (0.273)</td>        <td style="text-align:right;">0.819 (0.727)</td>       </tr>      </tbody>     </table>     </div>     <p>All the five algorithms using emoji features outperform the baseline in <em>accuracy</em>, <em>precision_M</em>, and <em>precision_F</em> even with default hyper-parameters. Such results confirm our assumption that the difference of emoji usage by female and male users is sufficiently large so that it can be utilized to infer the gender.</p>     <p>With optimal hyper-parameters, GBC achieves the best accuracy and precision of female users, and RF obtains the best precision of male users. GBC achieves an accuracy as high as 0.811, which outperforms the baseline by 24%. Additionally, although the gender distribution is quite unbalanced (i.e., 65.3% female users and 34.7% male users), the <em>precision_M</em> and <em>precision_F</em> of GBC are quite balanced, indicating a relatively fair prediction model.</p>    </section>    <section id="sec-18">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.4</span> Generalizing to Specific Languages</h3>     </div>     </header>     <p>Due to the complexity of natural language processes, existing text based approaches often face the challenge of generalizability across languages. For example, models trained based on English text can hardly generalize to other languages, such as Japanese&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0008">8</a>].</p>     <p>The advantage of using emojis is that they can be used in different languages. Now that our model is trained without any textual information, can it be applied to different languages and predict the gender without even knowing a word? Beyond the overall performance, we would like to see how our model perform on each individual language. To answer this question, we identify the languages used by users in the test set with the tool <em>Language Identification</em>,<a class="fn" href="#fn7" id="foot-fn7"><sup>7</sup></a> and evaluate model performance in different languages.</p>     <p>We select 10 non-English languages with the most users, i.e., Spanish, Portuguese, Tagalog, French, Italian, Arabic, Indonesian, Malay, German, and Thai. The 10 languages cover four language families defined by ISO 639<a class="fn" href="#fn8" id="foot-fn8"><sup>8</sup></a> and can be considered as a reasonable representative of the language systems. Spanish, Portuguese, French, Italian, and German belong to Indo-European; Arabic belongs to Afro-Asiatic; Tagalog, Indonesian, and Malay belong to Austronesian; and Thai belongs to Tai-Kadai. The languages in different language families are genetically unrelated and geographically dispersed.</p>     <p>We construct 10 test sets with users of a specific non-English language in each set and a test set with only English-speaking users as well. By applying the GBC model with optimal hyper-parameters on the 11 test sets, we find satisfactory <em>accuracy</em>, <em>precision_M</em>, and <em>precision_F</em> for all the languages. As demonstrated in Table&#x00A0;<a class="tbl" href="#tab4">4</a>, our model significantly outperforms the baseline. For example, the <em>accuracy</em> in Italian users is 0.841, 27% higher than the baseline. In addition, the <em>precision_M</em> and <em>precision_F</em> are well balanced in each language. For example, the ratio of men and women in Thai users is 0.273:0.727, while our model achieves a <em>precision_M</em> of 0.750 and a <em>precision_F</em> of 0.819, which further supports the predictive power of emoji patterns for both female and male users in a specific language.</p>     <p>An interesting finding can be observed from Arabic users. Emojis are extremely predictive for male users, for the <em>precision_M</em> is as high as 0.854, 54% higher than the baseline. However, the <em>precision_F</em> is only 0.690, the lowest in all the 11 languages. A possible explanation might be the cultural effect on self-presentation online&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0019">19</a>], such as stricter self-censored behaviors for certain genders.</p>     <p>To sum up, the solid performance of the gender inference model on the 10 non-English languages suggests the advantage of the emoji-based approach over text-based models, the generalizability across languages. Although the predictive power of emoji usage patterns varies in different languages due to complex reasons, most results still support the robustness of the approach.</p>    </section>    <section id="sec-19">     <header>     <div class="title-info">      <h3>       <span class="section-number">5.5</span> Discussion</h3>     </div>     </header>     <p>Recall that we selected users who have more than 100 messages containing emojis. We next loosen the restriction in the test set to evaluate the feasibility of our model on relatively &#x201C;silent&#x201D; users. In specific, we select users with [80,100), [60,80), [40,60), [20,40), and [1,20) emoji messages to construct test sets and perform the pre-trained GBC model with optimal hyper-parameters on these sets. The number of users in these sets are 4,206, 5,515, 7,511, 12,662, and 43,309, respectively.</p>     <div class="table-responsive" id="tab5">     <div class="table-caption">      <span class="table-number">Table 5:</span>      <span class="table-title">Prediction performance of users with different numbers of emoji-messages, baseline in parentheses.</span>     </div>     <table class="table"> 				 <thead>       <tr>        <th rowspan="2" style="text-valign:middle" style="text-align:left;"># of emoji-msg</th>        <th colspan="3" style="text-align:center;">Metrics</th>       </tr>       <tr>        <th style="text-align:right;">Accuracy</th>        <th style="text-align:right;">Precision_M</th>        <th style="text-align:right;">Precision_F</th>       </tr> 						</thead>      <tbody>       <tr>        <td style="text-align:left;">[80,100)</td>        <td style="text-align:right;">0.748 (0.618)</td>        <td style="text-align:right;">0.709 (0.382)</td>        <td style="text-align:right;">0.766 (0.618)</td>       </tr>       <tr>        <td style="text-align:left;">[60,80)</td>        <td style="text-align:right;">0.744 (0.619)</td>        <td style="text-align:right;">0.692 (0.381)</td>        <td style="text-align:right;">0.770 (0.619)</td>       </tr>       <tr>        <td style="text-align:left;">[40,60)</td>        <td style="text-align:right;">0.712 (0.587)</td>        <td style="text-align:right;">0.672 (0.413)</td>        <td style="text-align:right;">0.635 (0.587)</td>       </tr>       <tr>        <td style="text-align:left;">[20,40)</td>        <td style="text-align:right;">0.675 (0.555)</td>        <td style="text-align:right;">0.635 (0.445)</td>        <td style="text-align:right;">0.707 (0.555)</td>       </tr>       <tr>        <td style="text-align:left;">[1,20)</td>        <td style="text-align:right;">0.608 (0.548)</td>        <td style="text-align:right;">0.595 (0.452)</td>        <td style="text-align:right;">0.664 (0.548)</td>       </tr>      </tbody>     </table>     </div>     <p>Results are shown in Table&#x00A0;<a class="tbl" href="#tab5">5</a> with comparison to baseline. Along with the decrease of emoji messages of users, our model shows a slight decrease in <em>accuracy</em>. Similar to findings in previous text-based studies&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0012">12</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0043">43</a>], the fewer messages a user sends, the less accurately one can infer their gender. Nevertheless, the emoji-based model still outperforms the baseline in every user group, suggesting that emoji usage patterns are predictive for genders even for relatively &#x201C;silent&#x201D; users.</p>    </section>   </section>   <section id="sec-20">    <header>     <div class="title-info">     <h2>      <span class="section-number">6</span> Emoji vs. Text</h2>     </div>    </header>    <p>We have demonstrated the predictive power of emoji usage patterns for gender inference by comparing the performance of emoji-based models with a naive baseline, i.e., the majority guess. While it is not surprising that emoji-based models outperform the naive baseline, a more interesting question is how they compare with the state-of-the-art text-based models. Most of these models are trained using English messages in social media like Facebook and Twitter. For example, Sap <em>et al.</em>&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>] derived predictive lexicon for genders from word usage on Facebook, Twitter, and in blogs. This lexicon is reported to achieve an accuracy of 91.9% on the same type of users.</p>    <p>In this section, we compare the performance of our emoji-based models with prediction models built based on textual content&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>] (referred as <em>text model</em>). To construct a comparable data set, we select users that meet the following criteria. First, each user must be an <strong>English</strong> speaker as identified by the <em>Language Identification</em> tool. Second, each user must have at least 50 emoji messages in total. Such criteria can make sure that we have enough data for each user.</p>    <p>We finally select 4,156 users and randomly divide them into the training set (3,306 users) and test set (850 users) with their English messages. In specific, the test set includes 564 female users (66.4%) and 286 male users (33.6%). For fair comparison, we implement the following four models and compare their performance:</p>    <ul class="list-no-style">     <li id="list4" label="&#x2022;">First, we apply the released model by&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0043">43</a>]<a class="fn" href="#fn9" id="foot-fn9"><sup>9</sup></a> (referred as the <strong>released text model</strong>) on test users.<br/>This model was trained on over ten thousand English users and demonstrated to be well generalizable across social media domains.<br/></li>     <li id="list5" label="&#x2022;">Second, to ensure a fair comparison between the <em>text model</em> and the <em>emoji model</em>, we train both models with the same data. Following the procedure described in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0043">43</a>], we compute the unigram frequency over the aggregate set of messages from each user as features and apply SVM with a linear kernel and L1 regularization to train the model that only considers text. We name this model the <strong>retrained text model</strong>.<br/></li>     <li id="list6" label="&#x2022;">Third, we train the <strong>emoji model</strong> on the same training set (with the GBC algorithm).<br/></li>     <li id="list7" label="&#x2022;">Finally, we would like to see if incorporating language-specific semantics helps the emoji model. Specifically, we recompute the sentiment scores of emojis based on their semantic nearest neighbors instead of their official descriptions. Based on our previous work&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0003">3</a>], we apply a state-of-the-art embedding algorithm, LINE&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"      href="#BibPLXBIB0045">45</a>], and use its second-order proximity to obtain the nearest neighbor words of each emoji. The new sentiment score is estimated as the mean sentiment scores of the nearest neighbors of the emoji. This model is referred as the <strong>semantic emoji model</strong>. Notice that the only contribution of textual content is to infer the semantics of emojis, and the gender inference model is still only based on emojis.<br/></li>    </ul>    <p>Except for the released text model, the other three models are all trained using both the default hyper-parameters and optimal hyper-parameters on the training set. The way to optimize the hyper-parameters are the same as described in Section&#x00A0;<a class="sec" href="#sec-14">5</a>. Test results of the four models are illustrated in Table&#x00A0;<a class="tbl" href="#tab6">6</a>, and we summarize our findings as follows:</p>    <ul class="list-no-style">     <li id="list8" label="&#x2022;">Released text model vs. retrained text model. Under the default hyper-parameter settings, the released text model can have a high <em>accuracy</em> of 0.800, while the result of the retrained text model is only 0.718. One possible reason is that the released text model is built upon a large-scale training corpus which might have a different distribution of the data used to retrain and test the text model.<br/></li>     <li id="list9" label="&#x2022;">Emoji model vs. retrained text model. When trained on the same data set, the emoji model and the retrained text model can obtain similar accuracy (0.736 vs. 0.718) under the default hyper-parameter settings. The emoji model has a higher <em>precision_F</em>, unless exhaustive hyper-parameter search is applied. In contrast, the retrained text model has a higher <em>precision_M</em>. Such a result suggests that the prediction power of emoji model is comparable to the state-of-the-art text-based model in predicting gender. Hyper-parameter tuning brings in a larger improvement for the text model than for the emoji model, which is reasonable as the text model has a much higher degree of freedom.<br/></li>     <li id="list10" label="&#x2022;">Emoji model vs. semantic emoji model. As expected, the semantic emoji model with language-specific semantics performs better. This encouraging result suggests that the performance of the emoji model can be improved with language-specific knowledge (not necessarily the textual content in the message). One may expect that other contexts of the language, such as country and culture, may further improve the emoji model, which we leave for future studies.<br/></li>    </ul>    <div class="table-responsive" id="tab6">     <div class="table-caption">     <span class="table-number">Table 6:</span>     <span class="table-title">Performance of gender inference models under default hyper-parameter settings, followed by performance with optimal hyper-parameters in parentheses.</span>     </div>     <table class="table"> 			 <thead>      <tr>        <th rowspan="2" style="text-valign:middle" style="text-align:left;">Model</th>       <th colspan="3" style="text-align:center;">Metrics</th>      </tr>      <tr>       <th style="text-align:right;">Accuracy</th>       <th style="text-align:right;">Precision_M</th>       <th style="text-align:right;">Precision_F</th>      </tr> 					 </thead>     <tbody>      <tr>       <td style="text-align:left;">Released text model</td>       <td style="text-align:right;">0.800</td>       <td style="text-align:right;">0.693</td>       <td style="text-align:right;">0.858</td>      </tr>      <tr>       <td style="text-align:left;">Retrained text model</td>       <td style="text-align:right;">0.718 (0.855)</td>       <td style="text-align:right;">0.871 (0.794)</td>       <td style="text-align:right;">0.706 (0.885)</td>      </tr>      <tr>       <td style="text-align:left;">Emoji model</td>       <td style="text-align:right;">0.736 (0.758)</td>       <td style="text-align:right;">0.728 (0.744)</td>       <td style="text-align:right;">0.738 (0.761)</td>      </tr>      <tr>       <td style="text-align:left;">Semantic emoji model</td>       <td style="text-align:right;">0.739 (0.769)</td>       <td style="text-align:right;">0.746 (0.747)</td>       <td style="text-align:right;">0.738 (0.775)</td>      </tr>      <tr>       <td style="text-align:left;">Baseline</td>       <td style="text-align:right;">0.664</td>       <td style="text-align:right;">0.336</td>       <td style="text-align:right;">0.664</td>      </tr>     </tbody>     </table>    </div>   </section>   <section id="sec-21">    <header>     <div class="title-info">     <h2>      <span class="section-number">7</span> Implications</h2>     </div>    </header>    <p>So far, we have found significant gender-specific differences in emoji usage. Utilizing these differences as features, one could infer the gender of a user from their emoji usage, independent to the language they use. We then discuss some practical implications of our findings: how they may benefit real world applications.</p>    <p>     <strong>Keyboard-layout Adaptation for Emojis.</strong> Based on the gender differences in emoji usage, the most straightforward application of the results is to improve user experience of the current smartphone keyboards. In current OS-native and third-party input method apps (IMA), emojis are always split into multiple categories and displayed in pages. Each page contains some emojis that are displayed in a rather fixed layout. When users want to type in an emoji, they have to swipe left or right to search for it. This approach is hardly user friendly: as the number of emoji grows, users may not be able to fast locate and select the desired emojis. Some efforts have been done to optimize emoji entry speed such as&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0036">36</a>]. Our analysis provides implications for smartphone-side IMA developers, not limited to Kika but also including other keyboard developers or even OS vendors, to optimize their keyboard layout. For example, the ranked list of emojis shown on a keyboard&#x0027;s layout should be gender-aware. Additionally, current keyboards can recommend the possible words or emojis that users may type in next. Based on our observations, keyboard developers can improve their algorithms from a gendered perspective. Furthermore, given the fact that emojis are ubiquitously popular even on PC (e.g., the &#x201C;touchbar&#x201D; feature provided in latest Apple Macbook model supports inputting emojis), the gender-specific usage patterns can be utilized there too.</p>    <p>     <strong>Generalized Gender Inference with Low Privacy Risk.</strong> Recently, &#x201C;sharing&#x201D; user profiles becomes a popular practice between Internet-based applications. For example, users are asked to associate their own social networking accounts with an app that can then acquire their profiles. Indeed, knowing the gender, age, and preferences has lots of technical benefits: user profiling, interface design, personalization, recommender systems, and online advertising. However, as a &#x201C;double-edged sword,&#x201D; such practice also risks user privacy. In practice, it is always a tradeoff between how much better service a user receives and how much their privacy is violated. For example, existing work built machine learning models for gender inference (or user profiling in general) based on text messages of a user and achieved satisfactory accuracy&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0007">7</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0056">56</a>]. Even though user IDs can be anonymized, such NLP techniques are still at the risk of accessing and leaking sensitive, private information of the users that are encoded in free text. For example, among the 7,137 natural language features<a class="fn" href="#fn10" id="foot-fn10"><sup>10</sup></a> extracted for gender reference reported in&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0043">43</a>], 507 of them can be found in the most popular 2,000 first names reported by nameberry<a class="fn" href="#fn11" id="foot-fn11"><sup>11</sup></a> and 209 of them match the most popular 1,000 surnames reported by mongabay.<a class="fn" href="#fn12" id="foot-fn12"><sup>12</sup></a> Some of the features also imply that there are other types of sensitive information in the free text messages, such as &#x201C;<font style="normal">&#x0024;</font>&#x201D;(transactions), &#x201C;@yahoo.com&#x201D; (email addresses), &#x201C;http&#x201D;(Websites), dates, time, and many numbers (age, phone numbers, personal identifiers, financial information, etc). Apparently, models trained purely based on emojis have much less risk of accessing or leaking private information of users, compared to those based on free text. From our results, it is encouraging that an emoji-based model does not sacrifice the accuracy of gender inference much compared to those based on free text. In scenarios where gender reference is a necessity, a better preservation of privacy is a big win. Indeed, an emoji-based model does not compromise the accuracy of gender inference, in many scenarios it may even improve the performance, such as when text content is not available or it is written in different languages.</p>   </section>   <section id="sec-22">    <header>     <div class="title-info">     <h2>      <span class="section-number">8</span> Limitations</h2>     </div>    </header>    <p>One potential limitation of this study is the coverage of our data set. With the current design, Kika only collects self-reported genders with a binary option: female and male. It is not clear whether our results can be generalized to other genders.<a class="fn" href="#fn13" id="foot-fn13"><sup>13</sup></a> There might also exist self-selection biases of Kika users when they report their genders.</p>    <p>Currently, we focus on the active users in the data set collected by the Kika keyboard. Kika is only one of the third-party input methods supporting emojis in the market, and most popular smartphone manufacturers do support emojis in their built-in input methods. Although we don&#x0027;t see any evidence of population bias in Kika users, we are not ruling out the possibility that the results of our study might not generalize to users of other emoji apps.</p>    <p>Indeed, there are still some confounding factors that can potentially influence our results. For example, previous work evidenced that the differences of emoji renderings across platforms give rise to diverse interpretations of emojis&#x00A0;[<a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0030">30</a>, <a class="bib" data-trigger="hover" data-toggle="popover" data-placement="top"     href="#BibPLXBIB0031">31</a>], which may influence the user behavior of choosing emojis. Our work targets on only Android users, and we currently cannot demonstrate whether the cross-platform issue matters. We do plan to reproduce our approach on iOS users.</p>   </section>   <section id="sec-23">    <header>     <div class="title-info">     <h2>      <span class="section-number">9</span> Conclusion</h2>     </div>    </header>    <p>In this paper, we have presented the first empirical study of emoji usage in smartphone from the gender perspective. Our study is based on a unique and large data set collected by Kika, an input method app. The data set covers 134,419 active users from 183 countries, their self-reported gender information, and their 401 million messages in 58 languages collected in three months. We conduct a multi-dimensional analysis of emoji usage from three aspects, i.e., emoji frequency, emoji preference, and sentiment expression via emojis, and find considerable differences in emoji usage between female and male users. The gender difference is not only statistically significant but also sufficient for accurate gender inference via machine learning algorithms. The gender inference model based on only emoji usage patterns achieves comparable performance to those built upon free text features, and it has a much lower risk of violating user privacy. With the language-independent characteristic, the use of emojis can be a reliable indicator for users in different languages, and the competitive performance of the emoji-based model is generalizable to non-English users.</p>   </section>   <section id="sec-24">    <header>     <div class="title-info">     <h2>Acknowledgment</h2>     </div>    </header>    <p>This work was supported by the National Key Research and Development Program under the grant No. 2016YFB1000801, the National Natural Science Foundation of China under grant numbers 61725201 and 61528201. The work of Wei Ai and Qiaozhu Mei was supported by the National Science Foundation under grant numbers 1054199, 1633370, 1131500, and 1620319. The authors would like to appreciate the invaluable supports from Dr. Conglei Yao and Mr. Ning Wang from Kika Tech, and Mr. Sheng Shen and Ms. Haotang Liu from Peking University. Xuanzhe Liu is the corresponding author of this work.</p>   </section>  </section>  <section class="back-matter">   <section id="ref-001">    <header>     <div class="title-info">     <h2 class="page-brake-head">REFERENCES</h2>     </div>    </header>    <ul class="bibUl">     <li id="BibPLXBIB0001" label="[1]">Fabes&#x00A0;Richard A and Martin&#x00A0;Carol Lynn. 1991. Gender and age stereotypes of emotionality. <em>      <em>Personality and Social Psychology Bulletin</em></em> 17, 5 (1991), 532&#x2013;540.</li>     <li id="BibPLXBIB0002" label="[2]">Steven&#x00A0;L. Ablon, Daniel&#x00A0;P. Brown, Edward&#x00A0;J. Khantzian, and John&#x00A0;E. Mack. 2013. <em>      <em>Explorations in affect development and meaning</em></em>. Routledge.</li>     <li id="BibPLXBIB0003" label="[3]">Wei Ai, Xuan Lu, Xuanzhe Liu, Ning Wang, Gang Huang, and Qiaozhu Mei. 2017. Untangling emoji popularity through semantic embeddings. In <em>      <em>Proceedings of the 11th International Conference on Weblogs and Social Media, ICWSM 2017</em></em>. 2&#x2013;11.</li>     <li id="BibPLXBIB0004" label="[4]">Fisher&#x00A0;Ronald Aylmer. 1925. <em>      <em>Statistical methods for research workers</em></em>. Genesis Publishing Pvt Ltd.</li>     <li id="BibPLXBIB0005" label="[5]">Francesco Barbieri, Germ&#x00E1;n Kruszewski, Francesco Ronzano, and Horacio Saggion. 2016. How cosmopolitan are emojis?: Exploring emojis usage and meaning over different languages with distributional semantics. In <em>      <em>Proceedings of the 2016 ACM Conference on Multimedia Conference, MM 2016</em></em>. 531&#x2013;535.</li>     <li id="BibPLXBIB0006" label="[6]">Francesco Barbieri, Francesco Ronzano, and Horacio Saggion. 2016. What does this emoji mean? A vector space skip-gram model for Twitter emojis. In <em>      <em>Proceedings of the 10th International Conference on Language Resources and Evaluation LREC 2016</em></em>.</li>     <li id="BibPLXBIB0007" label="[7]">John&#x00A0;D. Burger, John&#x00A0;C. Henderson, George Kim, and Guido Zarrella. 2011. Discriminating gender on Twitter. In <em>      <em>Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011</em></em>. 1301&#x2013;1309.</li>     <li id="BibPLXBIB0008" label="[8]">Morgane Ciot, Morgan Sonderegger, and Derek Ruths. 2013. Gender inference of Twitter users in non-English contexts. In <em>      <em>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013</em></em>. 1136&#x2013;1145.</li>     <li id="BibPLXBIB0009" label="[9]">Cortes Corinna and Vapnik Vladimir. 1995. Support vector machine. <em>      <em>Machine learning</em></em> 20, 3 (1995), 273&#x2013;297.</li>     <li id="BibPLXBIB0010" label="[10]">Henriette Cramer, Paloma de Juan, and Joel&#x00A0;R. Tetreault. 2016. Sender-intended functions of emojis in US messaging. In <em>      <em>Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services, MobileHCI 2016</em></em>. 504&#x2013;509.</li>     <li id="BibPLXBIB0011" label="[11]">Eli Dresner and Susan&#x00A0;C Herring. 2010. Functions of the nonverbal in CMC: Emoticons and illocutionary force. <em>      <em>Communication theory</em></em> 20, 3 (2010), 249&#x2013;268.</li>     <li id="BibPLXBIB0012" label="[12]">Benjamin&#x00A0;Van Durme. 2012. Streaming analysis of discourse participants. In <em>      <em>Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL 2012</em></em>. 48&#x2013;58.</li>     <li id="BibPLXBIB0013" label="[13]">Hoerl&#x00A0;Arthur E and Kennard&#x00A0;Robert W. 1970. Ridge regression: Biased estimation for nonorthogonal problems. <em>      <em>Technometrics</em></em> 12, 1 (1970), 55&#x2013;67.</li>     <li id="BibPLXBIB0014" label="[14]">Pedregosa Fabian, Varoquaux Ga&#x00EB;l, Gramfort Alexandre, Michel Vincent, Thirion Bertrand, Grisel Olivier, Blondel Mathieu, Prettenhofer Peter, Weiss Ron, Vincent Dubourg, <em>et al.</em> 2011. Scikit-learn: Machine learning in Python. <em>      <em>Journal of Machine Learning Research</em></em> 12, Oct (2011), 2825&#x2013;2830.</li>     <li id="BibPLXBIB0015" label="[15]">Lucie Flekova, Jordan Carpenter, Salvatore Giorgi, Lyle&#x00A0;H. Ungar, and Daniel Preotiuc-Pietro. 2016. Analyzing biases in human perception of user age and gender from text. In <em>      <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016</em></em>.</li>     <li id="BibPLXBIB0016" label="[16]">Friedman&#x00A0;Jerome H. 2002. Stochastic gradient boosting. <em>      <em>Computational Statistics &#x0026; Data Analysis</em></em> 38, 4 (2002), 367&#x2013;378.</li>     <li id="BibPLXBIB0017" label="[17]">Stratis Ioannidis, Andrea Montanari, Udi Weinsberg, Smriti Bhagat, Nadia Fawaz, and Nina Taft. 2014. Privacy tradeoffs in predictive analytics. In <em>      <em>ACM SIGMETRICS / International Conference on Measurement and Modeling of Computer Systems, SIGMETRICS 2014</em></em>. 57&#x2013;69.</li>     <li id="BibPLXBIB0018" label="[18]">Briton&#x00A0;Nancy J. and Judith&#x00A0;A. Hall.1995. Beliefs about female and male nonverbal communication. <em>      <em>Sex Roles</em></em> 32, 1 (1995), 79&#x2013;90.</li>     <li id="BibPLXBIB0019" label="[19]">Reed&#x00A0;Philip J, Spiro&#x00A0;Emma S, and Butts&#x00A0;Carter T. 2016. Thumbs up for privacy?: Differences in online self-disclosure behavior across national cultures. <em>      <em>Social Science Research</em></em> 59 (2016), 155&#x2013;170.</li>     <li id="BibPLXBIB0020" label="[20]">Bernard&#x00A0;J. Jansen and Lauren Solomon. 2010. Gender demographic targeting in sponsored search. In <em>      <em>Proceedings of the 28th International Conference on Human Factors in Computing Systems, CHI 2010</em></em>. 831&#x2013;840.</li>     <li id="BibPLXBIB0021" label="[21]">Anders Johannsen, Dirk Hovy, and Anders S&#x00F8;gaard. 2015. Cross-lingual syntactic variation over age and gender. In <em>      <em>Proceedings of the 19th Conference on Computational Natural Language Learning, CoNLL 2015</em></em>. 103&#x2013;112.</li>     <li id="BibPLXBIB0022" label="[22]">David Jurgens, Yulia Tsvetkov, and Dan Jurafsky. 2017. Writer Profiling Without the Writer&#x0027;s Text. In <em>      <em>Social Informatics - 9th International Conference, SocInfo 2017, Proceedings, Part II</em></em>. 537&#x2013;558.</li>     <li id="BibPLXBIB0023" label="[23]">Fariba Karimi, Claudia Wagner, Florian Lemmerich, Mohsen Jadidi, and Markus Strohmaier. 2016. Inferring gender from names on the web: A comparative evaluation of gender detection methods. In <em>      <em>Proceedings of the 25th International Conference on World Wide Web, WWW 2016</em></em>. 53&#x2013;54.</li>     <li id="BibPLXBIB0024" label="[24]">Eugene Kharitonov and Pavel Serdyukov. 2012. Gender-aware re-ranking. In <em>      <em>Proceedings of the 35th International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2012</em></em>. 1081&#x2013;1082.</li>     <li id="BibPLXBIB0025" label="[25]">Peter Kr&#x00E1;tky and Daniela Chud&#x00E1;. 2016. Estimating gender and age of web page visitors from the way they use their mouse. In <em>      <em>Proceedings of the 25th International Conference on World Wide Web, WWW 2016</em></em>. 61&#x2013;62.</li>     <li id="BibPLXBIB0026" label="[26]">Breiman Leo. 2001. Random forests. <em>      <em>Machine learning</em></em> 45, 1 (2001), 5&#x2013;32.</li>     <li id="BibPLXBIB0027" label="[27]">Cheng Li, Yue Lu, Qiaozhu Mei, Dong Wang, and Sandeep Pandey. 2015. Click-through Prediction for Advertising in Twitter Timeline. In <em>      <em>Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2015</em></em>. 1959&#x2013;1968.</li>     <li id="BibPLXBIB0028" label="[28]">Xuan Lu, Wei Ai, Xuanzhe Liu, Qian Li, Ning Wang, Gang Huang, and Qiaozhu Mei. 2016. Learning from the ubiquitous language: An empirical analysis of emoji usage of smartphone users. In <em>      <em>Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing, UbiComp 2016</em></em>. 770&#x2013;780.</li>     <li id="BibPLXBIB0029" label="[29]">LaFrance Marianne and Banaji Mahzarin. 1992. Toward a reconsideration of the gender-emotion relationship. <em>      <em>Emotion and Social Behavior</em></em> 14 (1992), 178&#x2013;201.</li>     <li id="BibPLXBIB0030" label="[30]">Hannah Miller, Daniel Kluver, Jacob Thebault-Spieker, Loren Terveen, and Brent Hecht. 2017. Understanding emoji ambiguity in context: The role of text in emoji-related miscommunication. In <em>      <em>Proceedings of the 11th International Conference on Web and Social Media, ICWSM 2017</em></em>. 152&#x2013;161.</li>     <li id="BibPLXBIB0031" label="[31]">Hannah Miller, Jacob Thebault-Spieker, Shuo Chang, Isaac&#x00A0;L. Johnson, Loren&#x00A0;G. Terveen, and Brent Hecht. 2016. &#x201C;Blissfully happy&#x201D; or &#x201C;ready to fight&#x201D;: Varying interpretations of emoji. In <em>      <em>Proceedings of the 10th International Conference on Web and Social Media, ICWSM 2016</em></em>. 259&#x2013;268.</li>     <li id="BibPLXBIB0032" label="[32]">Petra&#x00A0;Kralj Novak, Jasmina Smailovic, Borut Sluban, and Igor Mozetic. 2015. Sentiment of emojis. <em>      <em>PloS One</em></em> 10, 12 (2015).</li>     <li id="BibPLXBIB0033" label="[33]">Balswick&#x00A0;Jack O and Peek&#x00A0;Charles W. 1971. The inexpressive male: A tragedy of American society. <em>      <em>Family Coordinator</em></em> (1971), 363&#x2013;368.</li>     <li id="BibPLXBIB0034" label="[34]">Jahna Otterbacher, Jo Bates, and Paul&#x00A0;D. Clough. 2017. Competent men and warm women: Gender stereotypes and backlash in image search results. In <em>      <em>Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, CHI 2017</em></em>. 6620&#x2013;6631.</li>     <li id="BibPLXBIB0035" label="[35]">Henning Pohl, Christian Domin, and Michael Rohs. 2017. Beyond just text: semantic emoji similarity modeling to support expressive communication <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/11.png" class="img-responsive" alt="" longdesc=""/>     <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/20.png" class="img-responsive" alt="" longdesc=""/>     <img style="display: inline" src="http://delivery.acm.org/10.1145/3190000/3186157/images/21.png" class="img-responsive" alt="" longdesc=""/>. <em>      <em>ACM Transactions on Computer-Human Interaction (TOCHI)</em></em> 24, 1(2017), 6:1&#x2013;6:42.</li>     <li id="BibPLXBIB0036" label="[36]">Henning Pohl, Dennis Stanke, and Michael Rohs. 2016. EmojiZoom: emoji entry via large overview maps. In <em>      <em>Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services, MobileHCI 2016</em></em>. 510&#x2013;517.</li>     <li id="BibPLXBIB0037" label="[37]">Daniel Preotiuc-Pietro, Wei Xu, and Lyle&#x00A0;H. Ungar. 2016. Discovering user attribute stylistic differences via paraphrasing. In <em>      <em>Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI 2016</em></em>. 3030&#x2013;3037.</li>     <li id="BibPLXBIB0038" label="[38]">Wilkins Richard and Gareis Elisabeth. 2006. Emotion expression and the locution &#x201C;I love you&#x201D;: A cross-cultural study. <em>      <em>International Journal of Intercultural Relations</em></em> 30, 1 (2006), 51&#x2013;75.</li>     <li id="BibPLXBIB0039" label="[39]">Buck Ross, Miller&#x00A0;Robert E, and Caul&#x00A0;William F. 1974. Sex, personality, and physiological variables in the communication of affect via facial expression.<em>      <em>Journal of Personality and Social Psychology</em></em> 30, 4(1974), 587.</li>     <li id="BibPLXBIB0040" label="[40]">Buck Ross, Baron&#x00A0;Reuben M, Goodman Nancy, and Shapiro Beth. 1980. Unitization of spontaneous nonverbal behavior in the study of emotion communication. <em>      <em>Journal of Personality and Social Psychology</em></em> 39, 3(1980), 522&#x2013;529.</li>     <li id="BibPLXBIB0041" label="[41]">Buck Ross, Baron Reuben, and Barrette Dana. 1982. Temporal organization of spontaneous emotional expression: A segmentation analysis. <em>      <em>Journal of Personality and Social Psychology</em></em> 42, 3(1982), 506&#x2013;517.</li>     <li id="BibPLXBIB0042" label="[42]">Kelly Ryan and Leon Watts. 2015. Characterising the inventive appropriation of emoji as relationally meaningful in mediated close personal relationships. <em>      <em>Experiences of Technology Appropriation: Unanticipated Users, Usage, Circumstances, and Design</em></em> (2015).</li>     <li id="BibPLXBIB0043" label="[43]">Maarten Sap, Gregory&#x00A0;J. Park, Johannes&#x00A0;C. Eichstaedt, Margaret&#x00A0;L. Kern, David Stillwell, Michal Kosinski, Lyle&#x00A0;H. Ungar, and H.&#x00A0;Andrew Schwartz. 2014. Developing age and gender predictive lexica over social media. In <em>      <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014</em></em>. 1146&#x2013;1151.</li>     <li id="BibPLXBIB0044" label="[44]">Hwang&#x00A0;Ha Sung. 2014. Gender differences in emoticon use on mobile text messaging: evidence from a Korean sample. <em>      <em>International Journal of Journalism &#x0026; Mass Communication</em></em> 2014 (2014).</li>     <li id="BibPLXBIB0045" label="[45]">Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale information network embedding. In <em>      <em>Proceedings of the 24th International Conference on World Wide Web, WWW 2015</em></em>. 1067&#x2013;1077.</li>     <li id="BibPLXBIB0046" label="[46]">Channary Tauch and Eiman Kanjo. 2016. The roles of emojis in mobile phone notifications. In <em>      <em>Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing, UbiComp Adjunct 2016</em></em>. 1560&#x2013;1565.</li>     <li id="BibPLXBIB0047" label="[47]">Hu Tianran, Guo Han, Sun Hao, Nguyen&#x00A0;Thuy vy Thi, and Luo Jiebo. 2017. Spice up your chat: The intentions and sentiment effects of using emoji. In <em>      <em>Proceedings of the 11th International Conference on Weblogs and Social Media, ICWSM 2017</em></em>. 102&#x2013;111.</li>     <li id="BibPLXBIB0048" label="[48]">Chad Tossell, Philip&#x00A0;T. Kortum, Clayton Shepard, Laura&#x00A0;H. Barg-Walkow, Ahmad Rahmati, and Lin Zhong. 2012. A longitudinal study of emoticon use in text messaging from smartphones. <em>      <em>Computers in Human Behavior</em></em> 28, 2 (2012), 659&#x2013;663.</li>     <li id="BibPLXBIB0049" label="[49]">Svitlana Volkova and Yoram Bachrach. 2016. Inferring perceived demographics from user emotional tone and user-environment emotional contrast. In <em>      <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016</em></em>.</li>     <li id="BibPLXBIB0050" label="[50]">Dunnett&#x00A0;Charles W. 1955. A multiple comparison procedure for comparing several treatments with a control. <em>      <em>J. Amer. Statist. Assoc.</em></em> 50, 272 (1955), 1096&#x2013;1121.</li>     <li id="BibPLXBIB0051" label="[51]">Tigwell&#x00A0;Garreth W and Flatla&#x00A0;David R. 2016. Oh that&#x0027;s what you meant!: Reducing emoji misunderstanding. In <em>      <em>Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct, MobileHCI Adjunct 2016</em></em>. ACM, 859&#x2013;866.</li>     <li id="BibPLXBIB0052" label="[52]">Yi-Chia Wang, Moira Burke, and Robert&#x00A0;E. Kraut. 2013. Gender, topic, and audience response: an analysis of user-generated content on facebook. In <em>      <em>2013 ACM SIGCHI Conference on Human Factors in Computing Systems, CHI 2013</em></em>. 31&#x2013;34.</li>     <li id="BibPLXBIB0053" label="[53]">Church&#x00A0;Kenneth Ward and Hanks Patrick. 1990. Word association norms, mutual information, and lexicography. <em>      <em>Computational Linguistics</em></em> 16, 1 (1990), 22&#x2013;29.</li>     <li id="BibPLXBIB0054" label="[54]">Alecia Wolf. 2000. Emotional expression online: Gender differences in emoticon use. <em>      <em>Cyberpsy., Behavior, and Soc. Networking</em></em> 3, 5 (2000), 827&#x2013;833.</li>     <li id="BibPLXBIB0055" label="[55]">Quanzeng You, Sumit Bhatia, Tong Sun, and Jiebo Luo. 2014. The eyes of the beholder: Gender prediction using images posted in online social networks. In <em>      <em>2014 IEEE International Conference on Data Mining Workshops, ICDM Workshops 2014</em></em>. 1026&#x2013;1030.</li>     <li id="BibPLXBIB0056" label="[56]">Faiyaz&#x00A0;Al Zamal, Wendy Liu, and Derek Ruths. 2012. Homophily and latent attribute inference: Inferring latent attributes of Twitter users from neighbors. In <em>      <em>Proceedings of the Sixth International Conference on Weblogs and Social Media, ICWSM 2012</em></em>.</li>     <li id="BibPLXBIB0057" label="[57]">Rui Zhou, Jasmine Hentschel, and Neha Kumar. 2017. Goodbye text, hello emoji: Mobile communication on WeChat in China. In <em>      <em>Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, CHI 2017</em></em>.</li>    </ul>   </section>  </section>  <section id="foot-001" class="footnote">   <header>    <div class="title-info">     <h2>FOOTNOTE</h2>    </div>   </header>   <p id="fn1"><a href="#foot-fn1"><sup>1</sup></a><a class="link-inline force-break"     href="https://twitter.com/andy_murray/status/586811114744320000">https://twitter.com/andy_murray/status/586811114744320000</a>, retrieved on February 10, 2018.</p>   <p id="fn2"><a href="#foot-fn2"><sup>2</sup></a><a class="link-inline force-break"     href="https://play.google.com/store/apps/details?id=com.qisiemoji.inputmethod">https://play.google.com/store/apps/details?id=com.qisiemoji.inputmethod</a>, retrieved on February 10, 2018.</p>   <p id="fn3"><a href="#foot-fn3"><sup>3</sup></a><a class="link-inline force-break"     href="http://unicode.org/emoji/charts/full-emoji-list.html">http://unicode.org/emoji/charts/full-emoji-list.html</a>, retrieved on February 10, 2018.</p>   <p id="fn4"><a href="#foot-fn4"><sup>4</sup></a><a class="link-inline force-break" href="https://gephi.org/">https://gephi.org/</a>, retrieved on February 10, 2018.</p>   <p id="fn5"><a href="#foot-fn5"><sup>5</sup></a>Due to the random initialization of the algorithm, different runs can produce different communities. Our findings are consistent in different runs.</p>   <p id="fn6"><a href="#foot-fn6"><sup>6</sup></a><a class="link-inline force-break" href="http://liwc.wpengine.com">http://liwc.wpengine.com</a>, retrieved on February 10, 2018.</p>   <p id="fn7"><a href="#foot-fn7"><sup>7</sup></a><a class="link-inline force-break" href="https://pypi.python.org/pypi/langid">https://pypi.python.org/pypi/langid</a>, retrieved on February 10, 2018.</p>   <p id="fn8"><a href="#foot-fn8"><sup>8</sup></a><a class="link-inline force-break"     href="https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes">https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes</a>, retrieved on February 10, 2018.</p>   <p id="fn9"><a href="#foot-fn9"><sup>9</sup></a><a class="link-inline force-break" href="http://www.wwbp.org/lexica.html">http://www.wwbp.org/lexica.html</a>   </p>   <p id="fn10"><a href="#foot-fn10"><sup>10</sup></a><a class="link-inline force-break" href="http://www.wwbp.org/lexica.html">http://www.wwbp.org/lexica.html</a>, retrieved on February 10, 2018.</p>   <p id="fn11"><a href="#foot-fn11"><sup>11</sup></a><a class="link-inline force-break" href="https://nameberry.com/popular_names">https://nameberry.com/popular_names</a>, retrieved on February 10, 2018.</p>   <p id="fn12"><a href="#foot-fn12"><sup>12</sup></a><a class="link-inline force-break"     href="https://names.mongabay.com/data/1000.html">https://names.mongabay.com/data/1000.html</a>, retrieved on February 10, 2018.</p>   <p id="fn13"><a href="#foot-fn13"><sup>13</sup></a>For example, it has been reported that Facebook provides 71 gender options: <a class="link-inline force-break"     href="https://www.yahoo.com/news/gender-options-facebook-users-064847655.html">https://www.yahoo.com/news/gender-options-facebook-users-064847655.html</a>, retrieved on February 10, 2018.</p>   <div class="bibStrip"> <p>Corresponding author: <a href="mailto:xzl@pku.edu.cn">xzl@pku.edu.cn</a>.</p> <p>This paper is published under the Creative Commons Attribution 4.0 International (CC-BY&#x00A0;4.0) license. Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.</p>    <p>     <em>WWW '18, April 23-27, 2018, Lyon, France</em></p>    <p>&#x00A9; 2018; IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY&#x00A0;4.0 License.<br/>ACM ISBN 978-1-4503-5639-8/18/04.<br/>DOI: <a class="link-inline force-break" target="_blank"     href="https://doi.org/10.1145/3178876.3186157">https://doi.org/10.1145/3178876.3186157</a></p>   </div>  </section>  <div class="pubHistory">   <p/>  </div>  </body> </html> 
